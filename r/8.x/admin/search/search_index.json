{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Opencast Administration Guide Welcome to the Opencast Universe! Opencast is an open-source enterprise level lecture recording system. The core of the system delivers functionality for scheduling, media encoding, editing and content delivery. For lecture capture, Opencast provides capture agent software and third party appliances are available. An awesome community provides new features and support. The Software Opencast contains everything you need for scheduling captures, trimming, captioning, and conversion of output media to several formats and our engage components. The core can be deployed on one (all-in-one deployment) or many (distributed deployment) Linux servers so your Opencast installation can grow with the needs of your university. Release Documentation The Opencast Release Documentation is the official Opencast documentation for each release. It contains: Release Notes Upgrade Changelog Installation Guides Configuration Guides Basic Configuration Database Configuration HTTPS Configuration Workflow Configuration Encoding Configuration more... Module Documentation Atom and RSS Feed AWS S3 Distribution Media Module Stream Security Text Extraction Video Segmentation YouTube Publication more... Version Support Further Documentation In addition to this official documentation, further guides and tips can be found in the on the mailing lists, the IRC channel and at the regular meetings.","title":"Home"},{"location":"#opencast-administration-guide","text":"Welcome to the Opencast Universe! Opencast is an open-source enterprise level lecture recording system. The core of the system delivers functionality for scheduling, media encoding, editing and content delivery. For lecture capture, Opencast provides capture agent software and third party appliances are available. An awesome community provides new features and support.","title":"Opencast Administration Guide"},{"location":"#the-software","text":"Opencast contains everything you need for scheduling captures, trimming, captioning, and conversion of output media to several formats and our engage components. The core can be deployed on one (all-in-one deployment) or many (distributed deployment) Linux servers so your Opencast installation can grow with the needs of your university.","title":"The Software"},{"location":"#release-documentation","text":"The Opencast Release Documentation is the official Opencast documentation for each release. It contains: Release Notes Upgrade Changelog Installation Guides Configuration Guides Basic Configuration Database Configuration HTTPS Configuration Workflow Configuration Encoding Configuration more... Module Documentation Atom and RSS Feed AWS S3 Distribution Media Module Stream Security Text Extraction Video Segmentation YouTube Publication more... Version Support","title":"Release Documentation"},{"location":"#further-documentation","text":"In addition to this official documentation, further guides and tips can be found in the on the mailing lists, the IRC channel and at the regular meetings.","title":"Further Documentation"},{"location":"changelog/","text":"Changelog Opencast 8 Opencast 8.1 Released on January 29, 2020 [ #1341 ] - Spring Framework Dependency Specification [ #1340 ] - LDAP User Directory Dependencies [ #1339 ] - Add Missing Karaf Features [ #1338 ] - Sakai User Directory Dependencies [ #1328 ] - AngularJS Components 1.7.9 [ #1326 ] - Fix Image Extraction From Short Videos [ #1321 ] - Fix URL Parameters in Theodul Player [ #1300 ] - Allow Root In Bower [ #1299 ] - Fix AWS WOH OSGI dependencies [ #1266 ] - Allow capture agent users to read properties of series Fixed Security Issues CVE-2020-5231 \u2013 Users with ROLE_COURSE_ADMIN can create new users CVE-2020-5206 \u2013 Authentication Bypass For Endpoints With Anonymous Access CVE-2020-5222 \u2013 Hard-Coded Key Used For Remember-me Token CVE-2020-5230 \u2013 Unsafe Identifiers CVE-2020-5229 \u2013 Replace MD5 with bcrypt for password hashing CVE-2020-5228 \u2013 Public Access Via OAI-PMH Opencast 8.0 Released on December 17, 2019 [ #1292 ] - Release notes for Opencast 8.0 [ #1290 ] - Fix for MP3 with embedded image [ #1286 ] - Fix Role For Assets Quick Access [ #1278 ] - Editor Thumbnail Default [ #1274 ] - Update Security Configuration [ #1269 ] - Fix processing of odd video width [ #1256 ] - Remove publishedhours default statistics provider [ #1245 ] - AngularJS 1.7.9 Security Update [ #1216 ] - Simplify Editor URL Signing [ #1212 ] - Update paella player to 6.2.4 [ #1207 ] - Enable Browser Tests [ #1206 ] - Temporarily Ignore Failing Test [ #1203 ] - Warn about using H2 [ #1202 ] - Overhaul RPM Installation Guide [ #1199 ] - Fix Crowdin Upload [ #1197 ] - Fix Theodul Embed Configuration [ #1167 ] - Migrate IBM Watson transcription to shared persistence [ #1153 ] - Keep generated SMIL for partial tracks [ #1151 ] - (#1008): Better crop detect test #1085 [ #1146 ] - Remove unnecessary global package-lock.json [ #1141 ] - Consider file extension of uploaded asset [ #1134 ] - Do not use stack-overflow logo [ #1131 ] - Issue1123 TEMP FIX for Paella Player Build error [ #1110 ] - Build failed on captions-impl tests for non english OS [ #1108 ] - Fix external API versioning for EventsEndpoint [ #1103 ] - Fix PostreSQL Support [ #1102 ] - Clean-up Fast Testing Workflow [ #1101 ] - Filter jobs by transcription service provider ID [ #1073 ] - close esc function for new event and new series modals [ #1067 ] - Publication Button show fix [ #1100 ] - Player Scroll/Zoom Overlay [ #1098 ] - Fix displaying tracks with no tags in player [ #1095 ] - Add a new optional date_expected column to the transcription job table [ #1094 ] - Smarter etc/ hints in documentation [ #1093 ] - Provide access to file contents in the WFR [ #1091 ] - Remove inaccurate url-pattern ${element_uri} [ #1090 ] - Elasticsearch access_policy field increased in size [ #1086 ] - Fix CI Builds (Crop Tests) [ #1084 ] - Fix Player ID Parameter Parsing [ #1082 ] - Docs readme extended. [ #1079 ] - Remove Workflow Operations from Worker [ #1078 ] - Fix database docs [ #1075 ] - Remove State Mapping \u201cImporting\u201d [ #1074 ] - Navbar icons toggle [ #1071 ] - Fix Pull Request Template [ #1070 ] - Temporarily Ignore Service Registry Test [ #1066 ] - Major developer docs update [ #1065 ] - Remove the RoleProvider.getRoles() method [ #1063 ] - Only events with write access [ #1062 ] - start on used port [ #1059 ] - Hide Column Stop By Default [ #1058 ] - Custom LTI Series Tool Styles [ #1057 ] - Update ESLint [ #1055 ] - Move to GitHub Issues [ #1053 ] - Update mustache [ #1052 ] - Update bootbox [ #1050 ] - && MH-13425 - Feeds-Tab / adds a new tab in series properties. [ #1048 ] - Add an optional build step to clean easily clean the frontend caches [ #1047 ] - ServiceRegistry not updating database correctly when dispatching jobs [ #1044 ] - clean node, node_modules and bower_components folders [ #1042 ] - Update Admin Interface JS Test Libraries [ #1041 ] - Update ESLint [ #1039 ] - paella can filter which tracks to load depending on the user's device [ #1037 ] - Update paella player to 6.2.0 [ #1034 ] - Update Translation Key for Published Hours [ #1033 ] - Direct link to assets tab [ #1030 ] - Configure max open files [ #1029 ] - Update admin interface JS libraries [ #1028 ] - Update Engage JS Libraries [ #1027 ] - Update Markdownlint [ #1023 ] - fix invisible icon for specific zoom level [ #1022 ] - Automatic publication of streaming URLs [ #1021 ] - Moving mediapackages needs to handle missing version information [ #1020 ] - Logging [ #1016 ] - Update Deprecated EqualsUtil.hash(\u2026) [ #1015 ] - IDEA Settings [ #1014 ] - Don't start opencast on a used port [ #1009 ] - Shell information for developer distribution [ #1008 ] - Crop service [ #1007 ] - Update several JS libraries [ #1006 ] - Improve metadata handling in backend [ #1005 ] - Fix dropdown menus [ #1004 ] - eslint 6.1.0 [ #1003 ] - Update karma [ #1001 ] - Access org properties from publish-configure WOH [ #998 ] - Concat Operation Graphics [ #997 ] - Update Development Process Documentation [ #996 ] - Update commons-text [ #995 ] - Composer Should Not Overwrite Files [ #994 ] - Added name of the configuration file where properties of login details are modified [ #992 ] - switch to compatible file type filter definitions [ #990 ] - Upgrade chromedriver [ #985 ] - Update grunt-concurrent [ #983 ] - Update ESLint [ #978 ] - Mh 13617 Duplicate encoding profiles for PrepareAV/SelectStreams [ #973 ] - Don't consider raw fields updated [ #972 ] - Improve setting values from dublin core catalog [ #971 ] - NOJIRA: Add ALTER to necessary MySQL permissions [ #970 ] - Fix hello-world modules [ #968 ] - Resolution Based, Conditional Encoding [ #967 ] - Introduce general CatalogUIAdapter [ #966 ] - Update frontend-maven-plugin [ #965 ] - Update Logger [ #964 ] - Update Checkstyle [ #963 ] - Update Paella Build Dependencies [ #962 ] - Update Chromedriver [ #961 ] - Update autoprefixer to 9.6.0 [ #960 ] - Update Markdownlint [ #959 ] - Update Admin Interface Test Framework [ #957 ] - Clean-up Static Resource Servlet [ #956 ] - Re-introduce Prepare AV [ #954 ] - Fix bundle versions [ #952 ] - Cleanup workflows [ #951 ] - More Dependency Checks\u2026 [ #950 ] - Tag elements retrieved from asset manager [ #949 ] - Termination State Service to integrate with AWS AutoScaling Lifecycle [ #948 ] - add health-check endpoint [ #945 ] - -publication [ #943 ] - color \"blue\" for links in the admin ui [ #942 ] - Theodul player ui config [ #941 ] - More dependency fixes [ #937 ] - Workflow Condition Parser Location [ #936 ] - Drop distribution-service-streaming [ #935 ] - Drop Distribution \u201cadminworker\u201d [ #934 ] - Drop Migration Distribution [ #931 ] - Assembly Configuration [ #929 ] - Check dependencies at build time [ #928 ] - Admin Interface Browser Tests [ #927 ] - Metadata Transfer Operation [ #926 ] - Remove unused code [ #925 ] - Media Module Dependency Management [ #924 ] - Jettison Dependency Management [ #923 ] - Introduce ESLint to Media Module [ #922 ] - Support for exclusion pattern for URL signing [ #921 ] - Officially support URL signing keys that handle multiple URL prefixes [ #920 ] - Streaming Module Cleanup [ #919 ] - Fix dependencies for statistics- and workflow-condition-parser [ #918 ] - Remove module 'dataloader' [ #917 ] - Remove obviously unused classes [ #908 ] - Admin interface dependency update [ #906 ] - Media Module Configuration [ #899 ] - Fix Login Page [ #898 ] - Fix Spelling of Flavor [ #895 ] - Update Tesseract Code [ #894 ] - NOJIRA Speed up statistics api tests [ #893 ] - Dependency Fixes [ #892 ] - Drop Custom Logger Configuration [ #891 ] - Unnecessary LineReader [ #890 ] - NOJIRA: Remove statistics provider configs [ #889 ] - Limit accepted file types when uploading assets [ #887 ] - Collect and visualize published hours of video [ #885 ] - Rework workflow conditions, add string data type [ #883 ] - Remove inclusion of non-existent scripts in Admin UI [ #882 ] - Navigation of statistics broken [ #881 ] - JavaScript Dependency Management [ #880 ] - Improve icons and wording in video editor [ #879 ] - statistics csv export [ #876 ] - Add Hourly Data Resolution For Statistics [ #874 ] - Role support for workflows [ #872 ] - Remove pseudo-mechanism for workflow definition registration [ #869 ] - Remove unused method WorkflowDefinition.isPublished [ #865 ] - Empty node name causes exception [ #864 ] - Multitenancy support for workflows [ #863 ] - Improve URL signing performance [ #862 ] - add single step event deletion [ #861 ] - Add option to configure state mappings for workflows [ #860 ] - Remove unused fields from search index [ #858 ] - Improve navigation in video editor when zoom is active [ #857 ] - resume on past table page when leaving video editor [ #854 ] - move ingest-download Operation to worker [ #851 ] - Highlight main table rows on hover [ #850 ] - Add node name to host registration as a UI searchable alternative to hostname [ #849 ] - Upgrade Admin Interface Libraries (Including AngularJS) [ #848 ] - Remove method canLogin from interface User [ #847 ] - Fix License and Documentation Links [ #846 ] - Automatically Launch Logs for dist-develop [ #842 ] - Harmonizing the column names [ #841 ] - Expand log messages to add error detail [ #834 ] - Introduce basic statistics visualization capabilities [ #831 ] - userprovider for the d2l brightspace LMS [ #826 ] - url query string incorrect [ #825 ] - Remove leftover service [ #824 ] - Use Username In Workflows [ #823 ] - Automatic caption using Google speech to text api [ #816 ] - Change the default composer job load from 0.8 to 1.5 [ #784 ] - Admin UI new event media upload progress bar [ #757 ] - Timelinepreviews process first one only Opencast 7 Opencast 7.6 Released on January 29, 2020 CVE-2020-5231 - Users with ROLE_COURSE_ADMIN can create new users CVE-2020-5206 - Authentication Bypass For Endpoints With Anonymous Access CVE-2020-5222 - Hard-Coded Key Used For Remember-me Token CVE-2020-5230 - Unsafe Identifiers CVE-2020-5228 - Public Access Via OAI-PMH [ #1358 ] - Switch To HTTPS Maven Repository [ #1353 ] - Handle empty fields from REST docs in EventHttpServletRequest [ #1352 ] - Remove unsafe option in ffmpeg command for SMIL processing [ #1343 ] - ] Fixes Admin-UI Presenter's column [ #1333 ] - Switch to mvn.opencast.org [ #1329 ] - Remove Spring Request Logger Configuration [ #1325 ] - Secure FPS For Smil Processing [ #1318 ] - Remove Custom Plugin Repositories [ #1315 ] - Bump spring-security-oauth from 2.3.6.RELEASE to 2.3.7.RELEASE [ #1276 ] - Don't add the internal publication of the original event twice [ #1271 ] - Wrong encoding in video editor zoom box [ #1270 ] - S3 Distribution Fails [ #1265 ] - Some error operations referencing the wrong error-handler. [ #1246 ] - Remove default storage_id setting from asset Manager Opencast 7.5 Released on December 10, 2019 [ #1233 ] - Change bibliographicdate if technicaldate is changed. [ #1220 ] - Make Thumbnail Optional [ #1218 ] - [Documentation] Added path hint to upgrade.md [ #1170 ] - MH-9753: Prepare AV WOH can throw a NPE [ #1164 ] - CentOS basic installation guide rewording [ #1148 ] - VideoEditorServiceImpl: Fixed the file extension duplication with removeExtention from FilenameUtils. [ #1122 ] - fixes #1069 workflow tab shows scheduling info instead of workflows Opencast 7.4 Released on October 02, 2019 [ MH-13517 ][ #1092 ] - Set an absolute limit on solr query size [ MH-13476 ][ #1088 ] - Filter capture agent roles for ACLs [ #1087 ] - Issue 1068, Stop job dispatcher before unregistering hosts, junit MH-13675 [ MH-13706 ][ #1072 ] - fix the date cell of the events overview table in the admin UI [ #1056 ] - NOISSUE: CAS security example is very out of date Opencast 7.3 Released on September 19, 2019 [ MH-13716 ][ #1061 ] - Update xmlsec [ MH-13715 ][ #1060 ] - Check Markdown for newline character [ #1056 ] - CAS security example is very out of date [ MH-13707 ][ #1051 ] - Watermark missing [ MH-13706 ][ #1049 ] - Show bibliographic event dates on the events overview page [ MH-13701 ][ #1040 ] - Interpret source-audio-name correctly for composite operation [ MH-13699 ][ #1038 ] - Fix Workflow Index Rebuild ACL Handling [ MH-13697 ][ #1036 ] - Workflow Index Rebuild Memory [ MH-13684 ][ #1024 ] - Do not include auth token in republished URLs [ MH-12533 ][ #714 ] - Re-introduce ability to avoid data loss during ingest Opencast 7.2 Released on August 02, 2019 [ MH-13662 ][ #1000 ] - Update LTI Information Opencast 7.1 Released on July 09, 2019 [ MH-13656 ][ #993 ] - Fix Scheduler Index Rebuild [ MH-13655 ][ #991 ] - Scheduler Message Logging [ MH-13653 ][ #989 ] - Fully Migrate Scheduled Events [ MH-13652 ][ #988 ] - Don't save unchanged values in dropdown menus [ MH-13651 ][ #987 ] - Don't call submit of SingleSelect twice [ MH-13650 ][ #986 ] - Scheduler Migration Performance [ MH-13646 ][ #982 ] - Delete scheduled events [ MH-13645 ][ #981 ] - Only send delete comments message if we delete something [ MH-13642 ][ #977 ] - Fix Index Update Logging [ MH-13639 ][ #976 ] - Admin interface does not handle missing metadata well [ MH-13638 ][ #975 ] - Update NPM [ MH-13619 ][ #958 ] - Fix Logging in Video Segmenter [ MH-13615 ][ #953 ] - Fix Italian Translation [ MH-13610 ][ #947 ] - LDAP User Directory Fixes Opencast 7.0 Released on June 13, 2019 [ MH-13615 ][ #953 ] - Fix Italian Translation [ MH-13602 ][ #940 ] - Update jackson-databind to fix CVE-2019-12086 [ MH-13599 ][ #938 ] - Select well supported mime type by default [ MH-13593 ][ #933 ] - Incorrect default waveform colors [ MH-13569 ][ #913 ] - Change of PlayerRedirection variable from {{id}} to #{id} [ MH-13568 ][ #911 ] - Catch exception from overlapping RRule and return bad request [ MH-13566 ][ #910 ] - Accept duration as either string or number in scheduling JSON [ MH-13385 ][ #909 ] - Add release note about URL signing configuration changes [ MH-13375 ][ #907 ] - Handle empty-range errors correctly [ MH-13563 ][ #905 ] - Duplicated Variables in Media Module [ MH-13562 ][ #904 ] - ReferenceError in Media Module [ MH-13561 ][ #903 ] - Access to UI Configuration [ MH-13558 ][ #900 ] - Paella Track Filter [ MH-13554 ][ #897 ] - Theodul Zoom [ MH-13553 ][ #896 ] - Fix Paella Track Selection [ MH-13538 ][ #878 ] - Update jQuery [ MH-13531 ][ #873 ] - upgrade spring-security and jasig cas library to fix issue\u2026 [ MH-13529 ][ #871 ] - Don't warn about expected behavior [ MH-13528 ][ #870 ] - Non-Interactive FFmpeg [ MH-13525 ][ #867 ] - Update Admin Interface Libraries [ MH-13519 ][ #855 ] - Migrate mappings to Elastic Search 5.x [ MH-13505 ][ #844 ] - Update Admin Interface JavaScript Libraries [ MH-13504 ][ #843 ] - JavaScript Library Update [ MH-12047 ][ #832 ] - MH-13380 MH-13490 MH-13489 Add missing indexes [ MH-13477 ][ #819 ] - Faster Asset Manager Property Access [ MH-13465 ][ #807 ] - Prevent NullPointerException [ MH-13389 ][ #815 ] - More informative job load logging [ MH-13472 ][ #813 ] - Permissions for /play/ missing [ MH-13471 ][ #812 ] - Shibboleth SSO plugin to add roles for users on OC according to their EDUPERSONAFFILIATION. eg: \"ROLE_AAI_USER_AFFILIATION_student\" for \"student\" [ MH-13469 ][ #811 ] - Drop LastHeardFrom On Scheduler Messages [ MH-13468 ][ #810 ] - Capture Agent Registration Exception [ MH-13466 ][ #809 ] - Prevent Capture Agents From Modifying Metadata [ MH-13467 ][ #808 ] - opencast-security-cas feature can not be started [ #806 ] - extend the ingest-download-woh [ MH-12643 ][ #804 ] - Allow workspace to read from asset manager [ MH-13462 ][ #802 ] - Prevent Being Started By Root [ MH-13461 ][ #801 ] - Dependency Fixes & Dependency Checks [ MH-13460 ][ #800 ] - Update JavaScript Dependencies [ MH-13459 ][ #799 ] - Make Paella Use UI Configuration Service [ MH-13458 ][ #798 ] - Live Scheduler Dependencies [ MH-13457 ][ #797 ] - Dependency Update [ MH-13456 ][ #796 ] - Move Log Workflow Operation To Admin [ MH-13455 ][ #795 ] - Opencast Plug-in Features [ MH-13454 ][ #794 ] - Drop Unused Configuration Option Maps [ MH-13453 ][ #793 ] - Add more log output to WOH select-streams [ MH-13452 ][ #792 ] - Show creators correctly in delete modals [ MH-13450 ][ #790 ] - Remove unused class org.opencastproject.adminui.api.SortType [ MH-13448 ][ #789 ] - Make translation of creators consistent [ MH-13446 ][ #788 ] - Removed unfinished feature \"ACL transitions\" [ MH-13445 ][ #787 ] - Update Checkstyle [ MH-13443 ][ #783 ] - Don't use deprecated $http.success and $http.error methods [ MH-13439 ][ #782 ] - Dynamic Player Redirect [ MH-13438 ][ #781 ] - Simplify Streaming Format Check [ #780 ] - ACL documentation pointed to wrong config file [ MH-13436 ][ #778 ] - Improve error message for out of bounds image extraction [ MH-13421 ][ #776 ] - Remove unused workflowservice exceptions [ MH-13434 ][ #775 ] - Opencast Common Clean-up [ MH-13381 ][ #771 ] - Use Organization Identifier In Roles [ MH-13432 ][ #770 ] - Remove unused modals \"Job Details\" and \"Server Details\" [ MH-13431 ][ #769 ] - Remove unfinished feature \"Bulk Messaging\" [ MH-13430 ][ #768 ] - Fix Opencast Offline Builds [ MH-13428 ][ #766 ] - Remove unused library angular-scenario from admin ui tests [ MH-13426 ][ #765 ] - Remove unused Protractor end-to-end tests [ MH-13427 ][ #764 ] - Remove unused test resources [ MH-13381 ][ #763 ] - Use Organization Identifier in Workflows [ MH-13424 ][ #762 ] - Elasticsearch 5.6.15 [ MH-13423 ][ #761 ] - Possible NPE if debugging is enabled [ MH-13422 ][ #760 ] - Switch to markdownlint-cli [ MH-13420 ][ #759 ] - ngRepeat does not allow duplicates [ MH-13417 ][ #758 ] - UI Configuration Service Tests [ MH-13414 ][ #756 ] - extended metadata multivalue fields are not handled properly [ MH-13413 ][ #755 ] - UI Configuration Service Improvements [ MH-13412 ][ #754 ] - Deprecate PathSupport.concat(\u2026) [ MH-13411 ][ #753 ] - Fix UI Config Service Dependencies [ MH-13410 ][ #752 ] - Fix Broken Build Number [ MH-13397 ][ #751 ] - Remove unfinished feature \"Participation Management\" [ MH-13396 ][ #750 ] - Remove unfinished feature \"Location Blacklisting\" [ MH-13400 ][ #745 ] - Admin Index Test Cleanup [ MH-13399 ][ #744 ] - Update Elasticsearch Configuration [ MH-13395 ][ #742 ] - Remove unfinished feature \"Dashboard\" [ MH-13394 ][ #741 ] - Remove unfinished feature \"User Blacklisting\" [ MH-13393 ][ #738 ] - Remove leftover index resources [ MH-13392 ][ #737 ] - Added allowConflict parameter to methods and implemented [ #736 ] - Revert #523: Special handling of asset manager event removal [ MH-13390 ][ #735 ] - Quick-Filter by Presenter [ MH-13221 ][ #732 ] - Improve behaviour of single-select metadata fields [ MH-13385 ][ #731 ] - Simplify the configuration of the URL signing components [ MH-13384 ][ #730 ] - Remove duplicate joda-time dependency declaration [ MH-13277 ][ #729 ] - fix concurrent Map updates in scheduler [ MH-13382 ][ #727 ] - Minor Waveform Service Fixes [ MH-13379 ][ #726 ] - Simplify Mime Type Handling [ MH-13368 ][ #724 ] - Added color property to waveform operation handler [ MH-13376 ][ #722 ] - Fix OSGI Bindings [ MH-13374 ][ #720 ] - Update Node.js [ MH-13373 ][ #719 ] - Upgrade Admin Interface Libraries [ MH-13372 ][ #718 ] - Clean up orphaned asset manager properties [ MH-13371 ][ #717 ] - Drop unused angular-md5 [ MH-13370 ][ #716 ] - Don't configure unnecessary default credentials [ MH-13294 ][ #713 ] - Workflow for track replacement and cleanup Snapshots [ MH-13367 ][ #711 ] - External API series acl returns null pointer with missing acl [ #710 ] - adds an WOH, which can add catalogs to the MediaPackage of an workflow instance [ MH-13365 ][ #709 ] - inbox ingest into series and inbox retry [ MH-13364 ][ #707 ] - Fix hidden OSGI wiring errors [ #704 ] - Fixed a typo in the analyze-tracks description [ MH-13362 ][ #703 ] - Harmonize Admin Interface Menu Tooltips [ MH-13361 ][ #702 ] - Fix Scheduler Item Serialization [ MH-13360 ][ #701 ] - MH-13316: Watson transcripts improvements [ MH-13358 ][ #698 ] - Update JavaScript Dependencies [ #691 ] - Documentation: Developer Console: How to shutdown [ MH-13275 ][ #689 ] - Allows the workflow to select the audio track for composite videos [ MH-13350 ][ #688 ] - Theodul core HTML validation [ #687 ] - Documentation: Publish Engage Workflow OH [ MH-13344 ][ #685 ] - Enable AssetManager to reply NOT_MODIFIED [ #682 ] - add docs.opencast.org anchors for somewhat deep linking [ MH-13345 ][ #681 ] - Switch to Gson for Languages Endpoint [ MH-13342 ][ #678 ] - Don't try to create events with empty metadata [ #677 ] - Documentation: Dictionary service [ MH-13341 ][ #676 ] - Deleting Capture Agents Should Not Modify Users [ MH-13340 ][ #675 ] - Handle Empty Passwords [ MH-13339 ][ #674 ] - Handle Bad User Update Requests [ MH-13336 ][ #671 ] - Upgrade c3p0 [ #670 ] - Documentation: Analyze Audio WOH: Unbreak table [ MH-13331 ][ #667 ] - Fix ActiveMQ Defaults [ MH-13328 ][ #666 ] - Remove save button at top of videoeditor [ MH-13147 ][ #664 ] - OptimisticLockException in ServiceRegistry dispatchJob [ MH-13324 ][ #662 ] - Simplify Data Loader [ MH-13323 ][ #661 ] - Add documentation for list providers [ MH-13322 ][ #660 ] - Avoid . in Elasticsearch Field Names [ MH-13321 ][ #659 ] - Fix Series Item Serialization [ MH-13320 ][ #658 ] - Asset Manager Performance [ MH-13319 ][ #657 ] - Update Paella Binding Dependencies [ MH-13318 ][ #656 ] - Update to Apache Karaf 4.2.2 [ MH-13313 ][ #653 ] - Properly Use ACL Merge-Mode Configuration [ MH-13307 ][ #648 ] - Update Release Manager Documentation [ MH-13306 ][ #647 ] - Clean up MetadataUtils [ MH-13244 ][ #642 ] - Add override support to external api [ MH-13221 ][ #641 ] - Add placeholder to multi-select fields [ MH-13290 ][ #632 ] - Asset Manager Query Performance [ MH-13289 ][ #631 ] - Introduce Metadatafield Copy Constructor [ MH-13288 ][ #630 ] - Don't create incomplete metadata fields [ MH-13287 ][ #629 ] - Fix incorrect text metadatafield types [ MH-13286 ][ #628 ] - Remove unused functionality from MetadataField [ MH-13285 ][ #627 ] - Display workflow description [ #626 ] - Provide location of org.ops4j.pax.web.cfg [ MH-13284 ][ #625 ] - Update Elasticsearch to 2.x [ MH-12091 ][ #622 ] - Per-Tenant Capture Agent Users [ MH-13281 ][ #621 ] - Added property keep-last-snapshot for asset-delete WOH [ MH-13278 ][ #617 ] - Drop Unused Exception [ MH-13238 ][ #615 ] - don't throw related services straight into ERROR state just because job succeeded on current service [ MH-13277 ][ #614 ] - improve scheduler performance [ MH-13276 ][ #613 ] - Drop org.opencastproject.fun [ MH-13271 ][ #610 ] - Remove Useless ACL Check [ MH-13270 ][ #609 ] - Fix Message Item Serialization [ MH-13267 ][ #607 ] - Update Deprecated Code In UIRolesRoleProvider [ #605 ] - NOJIRA: Fix misspelled digest [ MH-13157 ][ #600 ] - Add multi-tenant support for all list providers [ MH-13262 ][ #596 ] - Changed for partial-error comment description to better description. [ MH-13261 ][ #595 ] - User Directory OSGI Service Definitions [ MH-13260 ][ #594 ] - Simplify Runtime Info UI [ MH-13259 ][ #593 ] - User/Role Directory Cleanup [ MH-13255 ][ #590 ] - Updated Deprecated Methods in Workspace Tests [ MH-13254 ][ #589 ] - Automate Dependency Checking [ MH-13253 ][ #588 ] - External Elasticsearch [ MH-13251 ][ #586 ] - Remove duplicate dependency [ MH-13247 ][ #582 ] - Deprecated Methods In Elasticsearch [ MH-12816 ][ #579 ] - Make waveform size configurable in WOH [ MH-13242 ][ #578 ] - Set disable_search_threshold for chosen globally [ MH-13241 ][ #577 ] - Filter Fileinstall Artifacts [ MH-13129 ][ #575 ] - More configuration options for thumbnails [ MH-13239 ][ #574 ] - Docs: Fix 'Edit on GitHub' link [ #573 ] - Documentation: Inbox [ MH-13234 ][ #565 ] - Workspace Deprecation Fixes [ MH-13231 ][ #564 ] - Allow entering multiple metadata values at once [ MH-13233 ][ #563 ] - add note about the jdk version use for build [ MH-13229 ][ #561 ] - External Library Updates [ MH-13227 ][ #559 ] - Update to Apache Karaf 4.2 [ MH-13226 ][ #558 ] - Update Docuemnation Landing Page [ MH-13224 ][ #556 ] - Drop commons-beanutils [ MH-13217 ][ #551 ] - pom.xml housekeeping [ MH-13213 ][ #548 ] - Separate External API Index [ MH-13212 ][ #546 ] - Fix external-api dependencies [ MH-13210 ][ #545 ] - Fix Deprecated IOUtils Usage [ #542 ] - Developer Installation Guide [ MH-13208 ][ #540 ] - Create a short contributor guide [ MH-13200 ][ #535 ] - Remove unused file acl-modal.html [ MH-13127 ][ #534 ] - Make table headers non-interactive by default [ MH-13198 ][ #529 ] - Properly Display Multiple Presenters [ MH-13197 ][ #528 ] - Separate Admin Interface Index [ MH-13195 ][ #526 ] - Fix Admin Interface Dependencies [ MH-13193 ][ #524 ] - Improve performance of event deletion (2) [ MH-13193 ][ #523 ] - Improve performance of event deletion (1) [ MH-13084 ][ #519 ] - Create a generic user interface configuration service [ MH-13054 ][ #518 ] - Update angular-ui-sortable, adapting build pipeline [ #515 ] - NOJIRA: Documentation: wait_timeout should be bigger than max.idle.time [ MH-13187 ][ #514 ] - Improve Track Stream Handling [ MH-13186 ][ #513 ] - Episode and Series ACL Handling [ MH-13185 ][ #511 ] - Don't include test web server [ MH-13183 ][ #505 ] - Add link to series details, out of the eventstable-view [ MH-13178 ][ #502 ] - Clean-up Series Dialog Code [ MH-13177 ][ #501 ] - Further Simplify MediaPackageElementFlavor [ MH-13175 ][ #499 ] - Remove Apache Tika for Generating Mimetypes [ MH-13174 ][ #498 ] - Simplify class MediaPackageElementFlavor [ MH-13155 ][ #497 ] - Make weekday preselection optional [ MH-13168 ][ #491 ] - Testcases to test a captureagent with Opencast integration. [ MH-13160 ][ #488 ] - Send actually required data in workflow messages [ MH-13161 ][ #483 ] - Simplify log statements [ MH-13158 ][ #480 ] - Use default functional interface for SecurityUtil#runAs [ MH-13153 ][ #477 ] - Workflow Service Code Cleanup [ MH-13151 ][ #475 ] - Update to Apache Karaf 4.1.6 [ MH-13148 ][ #472 ] - Internationalization support for series LTI tools [ MH-13140 ][ #466 ] - Clean-up REST Documentation Code [ MH-13061 ][ #450 ] - Display responsible person for workflows [ MH-13121 ][ #447 ] - Fix usertracking plugin in paella player [ MH-13124 ][ #446 ] - Unify linting for JavaScript and HTML [ MH-13082 ][ #440 ] - Fix LTI security vulnerability and refactor LTI and OAuth classes [ MH-13098 ][ #430 ] - Add start-workflow WOH [ MH-13062 ][ #401 ] - Added credentials for the Ingest Service. [ MH-13000 ][ #398 ] - Group \u201cEdit scheduled\u201d events by weekday [ MH-12782 ][ #209 ] - As an unprivileged user, I only want to see series and events that I have write access to. Opencast 6 Opencast 6.7 Released on December 8, 2019 [ #1200 ] - Fix Crowdin Deployment [ #1143 ] - Upgrade jackson to 2.9.10 (6.x) [ #1142 ] - Update apache commons-compress to 1.19 [ #1132 ] - Fixed the \"hide\" button in the Documentation. [ #1080 ] - Documentation reworked [ #1035 ] - Pushing to Maven Central [ #1026 ] - Adding Ansible script documentation [ #1019 ] - SMIL tests fail when doctype url can't be resolved Opencast 6.6 Released on August 2, 2019 [ MH-13674 ][ #1013 ] - Fix Cutting [ MH-13673 ][ #1012 ] - Workflow options not visually aligned [ MH-13672 ][ #1011 ] - Editor Maximum Height [ MH-13671 ][ #1010 ] - OAI-PMH autorepublish fails due to invalid urls [ MH-13648 ][ #984 ] - Asset Manager Concurrecy Issue [ MH-13644 ][ #980 ] - Sometimes paella does not play audio [ MH-13643 ][ #979 ] - Update to Paella 6.1.4 [ MH-13637 ][ #974 ] - Asset manager endpoint fix [ MH-13633 ][ #969 ] - Update spring-security-oauth [ MH-13611 ][ #955 ] - Duplicate events fix Opencast 6.5 Released on June 14, 2019 [ MH-13607 ][ #946 ] - Show composite duration in video editor [ MH-13606 ][ #944 ] - Don't archive smil on publication [ MH-13601 ][ #939 ] - OAI-PMH database access syncronization [ MH-13575 ][ #916 ] - Update paella player to 6.1.3 [ MH-13573 ][ #914 ] - Add .factorypath to .gitignore [ MH-13560 ][ #902 ] - Admin Role in Moodle User Provider [ MH-13546 ][ #888 ] - textextraction performance improvement [ MH-13544 ][ #886 ] - Video editor shows incorrect notification [ MH-13536 ][ #877 ] - OAI-PMH Remote Broken [ MH-13533 ][ #875 ] - Document parameter \"sign\" of GET /api/events/{id}/publications/* [ MH-13526 ][ #868 ] - Show unequal tracks correctly in editor [ MH-13521 ][ #859 ] - Switch to openJDK 8 on Travis [ MH-13503 ][ #856 ] - Job Dispatch Fairness [ MH-13330 ][ #853 ] - The video editor does not always close after the user presses \"Publish\" [ MH-13511 ][ #852 ] - Adding events in parallel does not work correctly [ MH-13501 ][ #840 ] - Match against user pattern for loadUser() lookups [ MH-13495 ][ #839 ] - Ignore old requests instead of cancelling [ #837 ] - Fix adaptive streaming configuration guide [ MH-13492 ][ #833 ] - Add language support for Italian [ MH-13486 ][ #829 ] - Cleanup NOTICES 6.x [ MH-13485 ][ #828 ] - Update paella player to 6.1.2 [ #827 ] - Change url query syntax to ? [ MH-13476 ][ #818 ] - Filter capture agent roles for ACLs Opencast 6.4 Released on April 01, 2019 [ MH-13449 ][ cc11441 ] - MH-13449, upgrade spring-security-oauth libs [ MH-13464 ][ #805 ] - Update paella player to 6.1.0 [ MH-13463 ][ #803 ] - WOH select-streams does not hide audio track as expected [ MH-13444 ][ #786 ] - Insecure Series Creation [ MH-13387 ][ #777 ] - Get ACLs of finished workflows from AssetManager Document encoding-profiles parameter in ComposeWorkflowHandler [ MH-13429 ][ #767 ] - Make sure series LTI tool respects provided series custom param Opencast 6.3 Released on March 05, 2019 [ MH-13402 ][ #749 ] - WOH select-tracks does not work with audio-only input [ MH-13404 ][ #748 ] - Improve Workspace Logging [ MH-13401 ][ #747 ] - Fix icon in Paella Player [ MH-13388 ][ #734 ] - Updating job load values for composer service on worker nodes \u2026 [ MH-13378 ][ #725 ] - Add mimetype audio/m4a [ MH-13377 ][ #723 ] - Fix scheduler rrule TimeZone issue [ MH-12631 ][ #721 ] - Drop the ORGANIZER field from the ical feed [ MH-13369 ][ #715 ] - Delete Capture Agents [ MH-12177 ][ #712 ] - TimeZone threadsafe and bulk schedule across DST (NEW) [ MH-13355 ][ #700 ] - Increase the default timeout for TrustedHttpClientImpl [ MH-13359 ][ #699 ] - Adding UTF-8 encoding for all remote services [ MH-13357 ][ #697 ] - Enable being able to disable 2 confusing Admin UI metadata: \"duration\" & \"created\" [ MH-13356 ][ #696 ] - Unnecessary Snapshots [ MH-13347 ][ #695 ] - Don't always look for orphaned properties [ MH-13354 ][ #694 ] - Asset Manager Property Performance [ MH-13352 ][ #693 ] - Unnecessary Format [ MH-13310 ][ #692 ] - Simplify AQueryBuilderImpl#always [ #686 ] - Document workaround steps for authentication with IBM Watson STT [ MH-13147 ][ #683 ] - 6.x): OptimisticLockException in ServiceRegistry dispatchJob [ MH-13343 ][ #679 ] - Load track into workspace with unique ID [ MH-13338 ][ #673 ] - Elasticsearch Upgrade Documentation [ MH-13337 ][ #672 ] - Admin UI workflow status translation keys added [ MH-13329 ][ #668 ] - Removing a capture agent resets the password of all Opencast users [ MH-13326 ][ #663 ] - No file/directory found when taking snapshot [ MH-13315 ][ #655 ] - Don't destroy Notifications service on destruction of the Notifications directive [ MH-13312 ][ #654 ] - Do not show outdated conflict information Opencast 6.2 Released on January 24, 2019 [ MH-13309 ][ #649 ] - return empty list when finding findUsersByUserName when the name param is empty. Opencast 6.1 Released on January 12, 2019 [ MH-13305 ][ #646 ] - MacOS installation update [ MH-13304 ][ #645 ] - Multi-value consistent with multi-select [ MH-13302 ][ #644 ] - Don't save unnecessarily in Multi-Select [ MH-13301 ][ #643 ] - Don't require event.publisher since it is a readonly field [ MH-13300 ][ #640 ] - Display multi-value fields correctly on summary pages [ MH-13299 ][ #639 ] - Make multi-select fields consistent again [ MH-13295 ][ #635 ] - Handle null for presentable value extraction [ MH-13283 ][ #624 ] - Fix Custom CXF Error Handler [ MH-13248 ][ #623 ] - Allow hidden workflow parameters Opencast 6.0 Released on December 10, 2018 [ #620 ] - Remove dropped translations [ MH-13230 ][ #616 ] - remove the need for passing an Accept header with external api requests [ MH-13272 ][ #611 ] - fix missing roles [ MH-13266 ][ #606 ] - Start date cross link does not work correctly [ MH-13215 ][ #602 ] - WorkflowOperationTagUtil throws a null pointer [ MH-13245 ][ #601 ] - Paella player does not show a single presentation video [ MH-13252 ][ #587 ] - Ineffective Synchronization of Elasticsearch Startup [ MH-13221 ][ #585 ] - Improve multi-select metadata fields [ MH-13250 ][ #584 ] - Thumbnail feature does not work for unprivileged users [ MH-13249 ][ #583 ] - Invalid Group Endpoint Registration [ MH-13237 ][ #576 ] - Track previews do not work with stream security [ MH-13214 ][ #570 ] - Fix HTTP Digest Authentication [ MH-13232 ][ #562 ] - Fix potentially negative fade-out start [ MH-13228 ][ #560 ] - Homogeneous Width of Shortcut Icons [ MH-13225 ][ #557 ] - Fix for exception in live scheduler service when rebuilding the admin ui index [ MH-13222 ][ #554 ] - Some fixes to tiered storage asset manager [ MH-13209 ][ #544 ] - Put CAS Feature In Distributions [ MH-13150 ][ #541 ] - Add note about CAAM to release notes [ MH-13201 ][ #538 ] - Convert uploaded images to appropriate size and format [ MH-13206 ][ #537 ] - Use correct mouse cursor in filters [ MH-13205 ][ #536 ] - Document, fix and improve thumbnail support [ MH-13196 ][ #527 ] - Unregister Resource Servlets of Bundles to be Removed [ MH-13192 ][ #522 ] - Improve performance of list requests [ MH-13191 ][ #521 ] - Improve performance of retrieving groups [ MH-13188 ][ #516 ] - Update paella player 6.0.3 [ MH-13154 ][ #512 ] - Unify vertical spacing in wizards [ MH-13184 ][ #508 ] - Update request-digest [ #507 ] - Remove documentation about unused workflow pause role [ MH-13162 ][ #506 ] - Show all series in edit-scheduled-events [ MH-13179 ][ #503 ] - Fix Video Editor Preview Mode Default [ MH-13176 ][ #500 ] - Bug fix update of Jackson [ MH-13170 ][ #496 ] - Fix workflow not selected in event details [ MH-13171 ][ #495 ] - Fix workflow configuration settings being displayed incorrectly [ MH-13173 ][ #494 ] - Do not hardcode value of ACL override [ MH-13169 ][ #492 ] - Update bibliographic metadata when technical metadata changes [ MH-13166 ][ #489 ] - OAI-PMH Message Handler Performance [ MH-13164 ][ #487 ] - Load catalog for snapshot message effeciently [ MH-13130 ][ #486 ] - java.lang.ClassCastException in AdminUserAndGroupLoader when starting up [ MH-13163 ][ #484 ] - Fix empty REST documentation notes [ MH-13159 ][ #481 ] - Fix mattermost notification operation issues [ MH-13111 ][ #479 ] - Fix display of metadata in series creation summary [ MH-13110 ][ #478 ] - Fix display of metadata in event creation summary [ MH-13150 ][ #474 ] - Opencast 6.0 release notes [ MH-13149 ][ #473 ] - Timed tiered storage test fails on fast systems [ MH-13051 ][ #471 ] - Fix dropdown placeholders [ #470 ] - Fix rest docs of GroupsEndpoint [ MH-13141 ][ #469 ] - Correctly initialize stats service [ MH-13142 ][ #468 ] - Error parsing non-existent schedule [ MH-13135 ][ #467 ] - Pending requests are not cancelled as expected [ MH-13139 ][ #465 ] - Documentation for the event publisher metadata [ MH-12819 ][ #464 ] - change extract-text encoding profile for better OCR results\u2026 [ MH-13137 ][ #462 ] - Less extensive statistics configuration [ MH-13136 ][ #461 ] - Add Danish Translation [ MH-13133 ][ #459 ] - TypeError: Cannot read property 'results' of null [ MH-13092 ][ #458 ] - Fix failing scheduling for non-english browsers [ MH-13132 ][ #457 ] - Fix REST Docs Overview Rendering [ MH-13131 ][ #456 ] - Fix Feed Service REST Docs [ #455 ] - Remove misleading - sign in tag woh docs [ MH-13125 ][ #451 ] - Remove unused configuration keys [ MH-13123 ][ #448 ] - Update paella player 6.0.2 [ MH-13117 ][ #445 ] - Mark NPM managed modules as private packages [ MH-13116 ][ #444 ] - Fix typo in paella error message [ MH-13115 ][ #443 ] - Update Node, NPM and Libs [ MH-13114 ][ #442 ] - Fix broken REST docs [ MH-13113 ][ #441 ] - Drop unused HTML page [ MH-13025 ][ #439 ] - Fix workflow-definitions URL [ MH-13109 ][ #438 ] - Update Paella Player to 6.0.x [ MH-13107 ][ #436 ] - Update admin interface build dependencies [ MH-13106 ][ #435 ] - Add Moodle groups to Moodle role provider [ MH-13105 ][ #434 ] - Fix minor mattermost notification operation issues [ MH-13104 ][ #433 ] - Add linter for LTI tools [ MH-13103 ][ #432 ] - Runtime UI NG JavaScript Dependencies [ MH-13102 ][ #431 ] - Add linter (checkstyle) for JavaScript to engage-paella-player module [ MH-13097 ][ #429 ] - Added a configuration parameter to be able to send HTML emails [ MH-13101 ][ #428 ] - Update paella dependencies [ MH-13100 ][ #427 ] - fix series view in Paella [ MH-13099 ][ #426 ] - Warn when default credentials are being used [ MH-13096 ][ #425 ] - Set workflow variables with duplicated media package IDs [ MH-13095 ][ #424 ] - Add linter (checkstyle) for JavaScript [ MH-13083 ][ #423 ] - Unify modal navigation [ MH-13094 ][ #422 ] - Use global NPM repository [ MH-13090 ][ #420 ] - Added support for blacklisting languages from the admin UI [ MH-12699 ][ #419 ] - Remove opencast-paella binding dependency on Admin server [ MH-13088 ][ #417 ] - Update Several Dependencies [ MH-13087 ][ #416 ] - Update Runtime UI Libraries [ MH-13086 ][ #415 ] - Update LTI Series Tool [ MH-13079 ][ #413 ] - Introduce REST Interface for AssetManager Properties [ MH-13060 ][ #412 ] - Add i18n support for workflow, operations, job and services status [ MH-13073 ][ #411 ] - Don't split series metadata fields by , [ MH-13074 ][ #410 ] - Clean up asset manager REST endpoints [ MH-13072 ][ #409 ] - Remove broken ltitool player [ MH-13071 ][ #408 ] - Update markdown linter [ MH-13070 ][ #407 ] - Update JS build and test libraries [ MH-13064 ][ #399 ] - Encoding profile mimetypes are mostly ignored [ MH-13058 ][ #395 ] - Remove unused font libraries [ MH-12688 ][ #392 ] - Add translations for comment filter values [ MH-13045 ][ #391 ] - Add missing i18n translations [ MH-13040 ][ #388 ] - Make options fit \u201cActions\u201d drop-down [ MH-12810 ][ #387 ] - External API 1.1.0 - Add filters for new fields [ MH-13037 ][ #386 ] - Remove unused External API roles [ MH-12690 ][ #384 ] - Add i18n support for capture agent statuses [ MH-12761 ][ #382 ] - Fixed event to listen to \"plugin.events.captionsFound\". [ MH-13028 ][ #381 ] - Clean up mockup [ MH-13022 ][ #378 ] - fixed LTI highly trusted keys being discarded [ #376 ] - Update and improve documentation for reviews [ MH-13027 ][ #374 ] - Update angular-translate to 2.18.1 [ MH-13026 ][ #373 ] - Update Mac OS X 'Install from source' documentation [ MH-13025 ][ #372 ] - Add workflow API to external API [ MH-13024 ][ #371 ] - Video editor does not display information when being opened while an event is being processed [ #369 ] - Documentation: message-broker: binding localhost [ #368 ] - Documentation: Update security.https.md [ MH-13016 ][ #362 ] - Workflow display order not working in editor screen [ MH-13013 ][ #359 ] - Unused code in scheduler [ MH-13008 ][ #358 ] - Prefill other input of startdate filter [ MH-13012 ][ #357 ] - The iterable metadata values should not be splitted by , [ MH-13010 ][ #356 ] - Series-Service-Remote incorrect character encoding [ MH-13009 ][ #355 ] - Update translations [ MH-13007 ][ #354 ] - Clarify Scheduler Calendar cutoff units in REST docs [ MH-12829 ][ #348 ] - Make admin-ui statistics configurable [ MH-12998 ][ #346 ] - Clear conflicts when closing \u201cEdit Scheduled Events\u201d modal [ MH-12996 ][ #345 ] - Add header row to conflict table in \u201cEdit scheduled\u201d [ MH-12995 ][ #344 ] - Fix conflict check not detecting some conflicts [ MH-12990 ][ #343 ] - User switching: Privilege escalation too restrictive [ MH-12993 ][ #342 ] - REST docs for Admin UI Event endpoint broken [ MH-12994 ][ #341 ] - Make \u201cTitle\u201d in \u201cEdit scheduled\u201d non-mandatory [ MH-12992 ][ #340 ] - Trigger conflict check in \u201cEdit scheduled\u201d on \u201cNext\u201d [ MH-12989 ][ #338 ] - Add missing roles for actions->edit scheduled [ #336 ] - Update version info [ MH-12987 ][ #335 ] - Prohibit changing a scheduled event to be in the past [ MH-12985 ][ #332 ] - Fix incorrect warnings in event modals [ MH-12803 ][ #329 ] - Fix for mp 'start' when event is created (affects live scheduler service) [ MH-12980 ][ #328 ] - Update documentation landign page [ MH-12930 ][ #327 ] - Fill creator metadata field with actual user when new event [ MH-12977 ][ #322 ] - Fix data placeholders in edit scheduled events [ MH-11918 ][ #321 ] - AWS S3 Asset Storage [ MH-12975 ][ #320 ] - Inconsistent access control handling [ MH-12738 ][ #319 ] - Tiered Storage for the Asset Manager [ MH-12969 ][ #317 ] - Eclipse IDE import Opencast XML style preferences [ MH-12972 ][ #316 ] - Drop unused getAclAttachments [ MH-12969 ][ #314 ] - Ensure formatting of OSGI configuration [ #313 ] - NOJIRA-live-schedule-fix-issue-in-documatation [ MH-12965 ][ #311 ] - Add more logging data to metadata parse WARN [ MH-12961 ][ #308 ] - Remove unused JavaScript library bootstrap from Admin UI [ MH-12960 ][ #307 ] - Remove unused JavaScript library backbone.js from Admin UI [ MH-12959 ][ #306 ] - Remove unused JavaScript library visualsearch.js [ MH-12956 ][ #305 ] - Incorrect permission check when requesting indexed workflows [ MH-12958 ][ #301 ] - image-convert WOH [ MH-12607 ][ #299 ] - Multiencode [ MH-12955 ][ #298 ] - ffmpeg expect floating timestamp values separated by '.' [ MH-12949 ][ #294 ] - Fix spacing between action items [ MH-12946 ][ #292 ] - add event summary input translation [ MH-12948 ][ #291 ] - Directly read XACML files [ MH-12905 ][ #289 ] - Opencast does not startup anymore [ MH-12911 ][ #266 ] - Hotkey cheat sheet [ MH-12813 ][ #265 ] - Add audio and video track selection to video editor [ MH-12607 ][ #264 ] - Process-Smil - edit and encode to multiple delivery formats [ MH-12918 ][ #261 ] - Use Karaf generated jre.properties [ MH-12904 ][ #252 ] - Paella player 5.3 update [ MH-12829 ][ #237 ] - Fix broken sub tabs of Event Details->Assets [ MH-12889 ][ #236 ] - Intuitive Merging of Video Segments [ MH-12828 ][ #233 ] - re-enable Scheduler service conflicts json REST endpoint [ MH-12885 ][ #232 ] - Capture Agent Access Management [ MH-12877 ][ #231 ] - Add new modal to edit multiple scheduled events at once [ MH-12871 ][ #220 ] - Ability to use user names in to/cc/bcc fields in send-email woh [ MH-12869 ][ #219 ] - Remove superfluous playback tool [ MH-12829 ][ #218 ] - Switch and rename event details tabs [ MH-12814 ][ #208 ] - Manually Select And Upload Thumbnails [ MH-12815 ][ #197 ] - delete series with events option [ MH-12826 ][ #193 ] - Make workflow processing settings persistent [ MH-12823 ][ #182 ] - Log Configuration and GELF Log4J with graylog [ #181 ] - adapt tracking default options to respect the EU GDPR [ MH-12822 ][ #179 ] - Remove old OCv2x security context fix artifacts [ MH-12607 ][ #172 ] - Harvard DCE), Demux Operation [ MH-12607 ][ #171 ] - Harvard DCE), Lossless Concat Operation [ MH-12804 ][ #170 ] - Introduce displayOrder for workflow definitions [ MH-12797 ][ #168 ] - Explain UI actions (added missing tooltips) [ MH-12820 ][ #167 ] - Mattermost-notification-workflowoperationhandler [ #165 ] - Be less quiet about errors on Travis [ MH-12797 ][ #164 ] - Explain UI Actions [ MH-12794 ][ #162 ] - turn off matomo notification [ MH-12793 ][ #161 ] - Collapse multiple, redundant composer process methods [ MH-12647 ][ #155 ] - MH-12756 extend external api [ MH-12786 ][ #154 ] - Undistinguishable Entries in Groups Editor User List [ MH-12784 ][ #153 ] - External API: Accept header not specified correctly [ MH-12091 ][ #150 ] - Implement per-tenant digest user for capture agents [ MH-12703 ][ #89 ] - Add userdirectory for Moodle [ MH-11621 ][ #56 ] - Option to marshal empty values in DublinCore XML catalog. Opencast 5 Opencast 5.5 Released on April 1, 2019 [ MH-12603 ][ #746 ] - Take 'ng' out of the youtube composite operation [ MH-13386 ][ #733 ] - Event status calculation wrong assumption fixed [ MH-13383 ][ #728 ] - don't smooth the waveform in the editor [ MH-13366 ][ #708 ] - Add REFERENCES permission to standard Opencast GRANT statement [ MH-13363 ][ #706 ] - Publish to OAI-PMH an allready published mediapackage \u2026 [ MH-13333 ][ #669 ] - Do not import properties in publish WF Opencast 5.4 Released on January 24, 2019 [ MH-13311 ][ #652 ] - WOH cover-image is broken SUREFIRE-1588: Resolving compilation issue on Debian and related distros [ MH-13244 ][ #581 ] - Improve concurrency of OAIPMH republication Opencast 5.3 Released on January 11, 2019 [ MH-13297 ][ #638 ] - FasterXML Jackson Bugfix Update [ MH-13296 ][ #637 ] - Disable buttons of start task wizard while the tasks are being submitted [ MH-12290 ][ #636 ] - prevent SAXParserFactory and SAXParser class load lag in series listprovider [ MH-13269 ][ #608 ] - Handle Authorization Errors [ MH-13263 ][ #598 ] - Invalid Ingest Encoding [ MH-13257 ][ #597 ] - Fix outdated command line argument for tesseract >= 4.0.0 [ MH-13258 ][ #592 ] - Broken User Provider Removal [ MH-13256 ][ #591 ] - Waveform operation fails [ MH-13243 ][ #580 ] - Asset Manager ACL Cache Updates [ #572 ] - Documentation: Opencast 5.2 was released in Nov [ #571 ] - Documentation: Linkfixes in OC5.x upgrade guide [ MH-12332 ][ #567 ] - disable workflows whose tags don't explicitly match the source type, UPLOAD|SCHEDULE 5.x Opencast 5.2 Released on November 13, 2018 [ MH-13144 ][ #553 ] - only set Job startDate if no set before [ MH-13216 ][ #550 ] - Fix Documentation Pages [ MH-13211 ][ #547 ] - engage-ui: Fix live schedule bug: event available before schedule [ MH-13190 ][ #520 ] - Factor out JpaGroupRoleProvider JaxRs REST to mitigate load cycle race [ MH-13189 ][ #517 ] - Fix paella xss security isues in opencast 5.x [ MH-13167 ][ #490 ] - Republishing metadata does not update all metadata [ MH-13152 ][ #476 ] - Reduce Workflow Messages [ MH-13138 ][ #463 ] - Fix media module language configuration [ MH-13108 ][ #437 ] - Prevent permission problem in Travis cache [ MH-13091 ][ #421 ] - Concat operation problem with FFMPEG 4.x [ MH-13069 ][ #406 ] - Update problematic admin interface libraries [ MH-12976 ][ #389 ] - custom role patterns not working [ MH-12387 ][ #350 ] - Fix CAS Opencast 5.1 Released on September 3, 2018 [ MH-13067 ][ #404 ] - Configuration panel does not work for default workflow [ MH-13049 ][ #400 ] - Fix video editor zoom dropdown showing wrong value [ MH-13055 ][ #396 ] - Stop making events with no ACL public on ingest [ MH-13048 ][ #394 ] - Improve stability of the series index rebuild [ MH-13047 ][ #393 ] - Document using Nginx for HTTPS [ MH-13044 ][ #390 ] - Organization server configuration documentation [ MH-12016 ][ #379 ] - Scrolling role fetch [ MH-13031 ][ #377 ] - Active transaction notification on top [ MH-13029 ][ #375 ] - Don't show old notifications [ MH-13023 ][ #370 ] - Let default value fulfill requirement [ MH-13018 ][ #367 ] - re-add recordings json to 5x (includes MH-12828 re-add conflicts.json) [ MH-13020 ][ #366 ] - Read listproviders as UTF-8 [ MH-13017 ][ #363 ] - JS syntax error in publish workflow [ MH-13015 ][ #361 ] - 5.x database upgrade scripts [ MH-13014 ][ #360 ] - Don't show stale search results [ MH-13006 ][ #353 ] - Waveform operation cleanup creates problem with asynchronous NFS [ MH-13003 ][ #352 ] - Implement detection of already recorded (as opposed to yet to be recorded, scheduled) events by the index service [ MH-13005 ][ #351 ] - Skip waveform operation when no tracks [ MH-13001 ][ #347 ] - Fixed live scheduler service pom [ MH-12988 ][ #337 ] - delete-scheduled-live Fix for scheduled live event not deleted [ MH-12986 ][ #333 ] - Admin UI deployed debugging: include source in SourceMap files [ MH-12981 ][ #331 ] - fix for local admin-ui develop finding main.css [ MH-12979 ][ #325 ] - Automatically test ddl scripts [ MH-12978 ][ #324 ] - Fix data-placeholder in add event wizard [ MH-12974 ][ #318 ] - Access denial to event for unprivileged user [ MH-12970 ][ #315 ] - Senseless XACML parsing [ MH-12966 ][ #312 ] - Do not pre-select-from option in metadata property sheets [ MH-12963 ][ #310 ] - Localize dates/times in add-event summary [ MH-12950 ][ #309 ] - Fix for workflow with no acl in solr index NOJIRA: Skip install of Crowdin if it is already installed [ MH-12957 ][ #300 ] - Defaults on tab Source in Add Event wizards are broken [ MH-12954 ][ #297 ] - wrong date format in coverimage file Opencast 5.0 Released on June 12, 2018 [ MH-12952 ][ #295 ] - animate WOH dependency version fixed [ MH-12946 ][ #290 ] - Fix summary of add-event-dialog [ MH-12944 ][ #288 ] - Remove bashism from start script [ MH-12905 ][ #287 ] - TEMPORARY Karaf config assembly workaround (KARAF-5693) [ MH-12943 ][ #286 ] - Minor Paella config REST endpoint improvements [ MH-12942 ][ #285 ] - Paella player config REST endpoint should be accessible by anonymous user [ MH-12941 ][ #284 ] - Gracefully handle empty flavors [ MH-12940 ][ #283 ] - Ensure admin configuration is applied [ MH-12864 ][ #282 ] - Don't attempt to parse 'undefined' [ MH-12938 ][ #281 ] - Fix NullPointerException if no flavor is set [ MH-12937 ][ #280 ] - Correctly place admin UI test helper [ MH-12936 ][ #279 ] - Handle invalid flavors [ MH-12935 ][ #278 ] - Update Docker image repository documentation [ MH-12934 ][ #277 ] - Update translations [ MH-12933 ][ #276 ] - Link documentation from Systemd unit [ MH-12932 ][ #275 ] - Kernel Build Failure [ MH-12922 ][ #272 ] - Job load fixes [ MH-12929 ][ #271 ] - Change paella URL to /paella/ui [ MH-12928 ][ #270 ] - Mitigation for KARAF-5526 [ MH-12926 ][ #269 ] - Prevent cluttering of logs by invalid access [ MH-12924 ][ #268 ] - fix missing dropdown arrow [ MH-12919 ][ #262 ] - REST Docs Dependencies [ MH-12917 ][ #260 ] - Remove debug logging [ MH-12916 ][ #259 ] - Admin Interface Configuration Defaults [ MH-12914 ][ #258 ] - Remove deprecated IOUtils.closeQuietly [ MH-12913 ][ #257 ] - Fix Admin Interface Deprecation Warnings [ MH-12868 ][ #255 ] - Make frame-by-frame skipping function in the editor use the \"actual\" framerate [ MH-12908 ][ #251 ] - Fix escaping of spaces [ MH-12907 ][ #250 ] - Fix segmentation default job load [ MH-12906 ][ #249 ] - Composoer should ignore system specific output pathes like /dev/null [ MH-12902 ][ #248 ] - closing videoeditor should continue in events list [ MH-12901 ][ #247 ] - Fix YouTube publication job loads [ MH-12900 ][ #246 ] - Fix search service job loads [ MH-12899 ][ #245 ] - Fix streaming distribution job load defaults [ MH-12898 ][ #244 ] - Fix download distribution job load defaults [ MH-12897 ][ #243 ] - Improve visibility of selected segments in the videoeditor [ MH-12896 ][ #242 ] - Clarify default player configuration [ MH-12894 ][ #240 ] - Update markdownlint [ MH-12893 ][ #239 ] - Added ability to configure the job load for the aws s3 distribution service. [ MH-12892 ][ #238 ] - Added ability to configure the job load for the transcription service. [ MH-12888 ][ #235 ] - Missing FFmpeg on Travis CI [ MH-12887 ][ #234 ] - Only set job date completed and runtime once. [ MH-12883 ][ #230 ] - Maven build of admin-ui module without frontend profile [ MH-12882 ][ #229 ] - Fix org.w3c.dom.smil version [ MH-12881 ][ #228 ] - Remove deprecated method [ MH-12880 ][ #227 ] - Remove redundant OSGI declarations [ MH-12879 ][ #226 ] - Default location of paella configuration [ MH-12878 ][ #224 ] - Don't verify NPM cache to speed up build process [ MH-12874 ][ #223 ] - NotFoundException handling for OAI-PMH retract operation with non published event [ MH-12872 ][ #222 ] - event can not be deleted [ MH-12873 ][ #221 ] - Speed up test builds [ MH-12864 ][ #215 ] - Readonly mode of fields not working correctly in property sheets [ MH-12807 ][ #213 ] - Do not overwrite owner [ MH-12863 ][ #212 ] - Fix default owner in SMIL endpoint [ MH-12862 ][ #211 ] - Line break after required marker in REST docs [ MH-12834 ][ #207 ] - Central documentation for filtering, sorting and pagination [ MH-12833 ][ #204 ] - Consistently use External API as name [ MH-12852 ][ #203 ] - Required fields not indicated in the event details and series details modals [ MH-12843 ][ #200 ] - Fix \u201cAdd Event\u201d Tab Index Update main readme Fix tabs and trailing spaces in docs [ MH-12839 ][ #196 ] - fix all pom.xml [ MH-12837 ][ #194 ] - external series API ACL is required [ MH-12832 ][ #192 ] - Update to commons-collection4 [ MH-12836 ][ #191 ] - Fix event-comment dependencies not correctly specified [ MH-12831 ][ #190 ] - Fixing dependencies NOJIRA fix engage paella url security rules NOJIRA Localization developer guide updated [ MH-12780 ][ #184 ] - Fix sorting jobs by identifier in Systems->Jobs [ MH-12824 ][ #183 ] - Speed up mvn site T/clarify wording of user tracking in documentation [ MH-12818 ][ #177 ] - Improve Sox service tests NOJIRA Crowdin project configuration updated NOJIRA Crowdin documentation updated [ MH-12771 ][ #173 ] - Document fields of External API 1.0.0 [ MH-12795 ][ #163 ] - REST docs don't respect @Produces annotation on class level [ MH-12788 ][ #157 ] - UTF-8 encoding settings in OAI-PMH publication service remote [ MH-12616 ][ #152 ] - Admin UI Flexible Asset Upload override or fallback display text [ MH-12775 ][ #146 ] - Add JavaScript source map generation [ MH-12768 ][ #142 ] - Minor XACMLAuthorizationService fixes [ MH-12825 ][ #139 ] - Add markdownlint to Travis CI [ MH-12760 ][ #160 ] - Cross-link column date in events table to enable the start date filter [ MH-12789 ][ #158 ] - Remove tabs and trailing spaces in LTI tools [ MH-12509 ][ #151 ] - Enable HTTP basic auth in default config [ MH-12759 ][ #149 ] - More Control Over Workflows [ MH-12779 ][ #147 ] - Support X-Forwarded-Proto header [ MH-12649 ][ #138 ] - clone workflow operation handler [ MH-12764 ][ #137 ] - update license information for admin-ui [ MH-12763 ][ #136 ] - Minor Composer Fixes [ MH-12762 ][ #135 ] - Fix Spaces In Configuration Fallback For Synfig Install clean up woh documentation Make Travis check for tabs in pom.xml files Add Mkdocs To Travis Builds [ MH-12757 ][ #128 ] - Fix ClassCastException [ MH-12755 ][ #127 ] - Fix workflow-workflowoperation dependencies [ MH-12746 ][ #126 ] - Update Checkstyle [ MH-12746 ][ #125 ] - Update Apache HTTPComponents [ MH-12746 ][ #124 ] - Update Mina [ MH-12746 ][ #123 ] - Remove commons-logging [ MH-12746 ][ #122 ] - Update Jackson [ MH-12752 ][ #121 ] - Ignore VSCode project data [ MH-12751 ][ #120 ] - Add Travis Badge [ MH-12735 ][ #119 ] - Remove Undocumented Operations [ MH-12746 ][ #115 ] - Library Update [ MH-12742 ][ #113 ] - Update to Karaf 4.0.10 [ MH-12744 ][ #111 ] - Fix migration bundle dependencies [ MH-12739 ][ #109 ] - Transcription Service updated to support Paella [ MH-12737 ][ #108 ] - OAI-PMH publication service [ MH-12732 ][ #106 ] - Remove Unused Remote Service Registry [ MH-12731 ][ #105 ] - Improve Recreating Series Index [ MH-12730 ][ #104 ] - Workflow Index Rebuild Performance [ MH-12711 ][ #100 ] - improve xacml parser [ MH-12726 ][ #99 ] - Add description to theme [ MH-12704 ][ #98 ] - Captions support for paella [ MH-12718 ][ #97 ] - Animate Service [ MH-12713 ][ #95 ] - Series cannot be created [ MH-12705 ][ #87 ] - Fix scheduler hot-deployment [ MH-12701 ][ #84 ] - Paella: Localization files + crowdin config file [ MH-12692 ][ #83 ] - update maven bundle plugin for java8 [ MH-12663 ][ #81 ] - Don't search for non-existing WFR files [ MH-12694 ][ #80 ] - Save\" button in the editor now stays on the same page. [ MH-12693 ][ #77 ] - Notes on how to enable, upgrade to HTTPS [ MH-12675 ][ #76 ] - Send default startdate to backend also if it hasn't been changed. [ MH-12656 ][ #75 ] - Updates to Theodul Matomo (formerly Piwik) Plugin [ MH-12684 ][ #69 ] - Make License List Provider More Flexible [ MH-12683 ][ #68 ] - Improve Video Editor Tests [ MH-12681 ][ #66 ] - update media package series catalogs on event metadata update [ MH-12677 ][ #65 ] - Be less technical about displaying the version number [ MH-12674 ][ #63 ] - Remove unused hard-coded list providers [ MH-12665 ][ #62 ] - Sort table on startup [ MH-12649 ][ #59 ] - clone workflow operation handler [ MH-12668 ][ #58 ] - Update packages of admin ui build pipeline Use $timeout instead of $interval to resolve MH-12667 [ MH-12661 ][ #52 ] - Update angular-translate to 2.17.0 [ MH-12660 ][ #51 ] - Scheduling Events by Specifying End Time [ MH-12658 ][ #50 ] - Disable Jasmine for Theodul [ MH-12653 ][ #46 ] - Authorization service should use workspace#read() wherever possible [ MH-12600 ][ #45 ] - Move userdirectory stuff from bundle kernel to userdirectory [ MH-12648 ][ #42 ] - As a system administrator, I want to use different encoding \u2026 [ MH-12645 ][ #39 ] - Created an option to rebuild index for an specific service [ MH-12644 ][ #37 ] - External API index schema fixes [ MH-12538 ][ #36 ] - Remove obsolete ACL distribution service and WOH distribute-acl [ MH-12639 ][ #35 ] - update angular-chosen to 1.8.0 [ MH-11984 ][ #32 ] - Allow customization of the username-to-user-role mapping [ MH-12367 ][ #30 ] - Renaming all database tables [ MH-12633 ][ #29 ] - Fix version of maven-dependency-plugin [ MH-12544 ][ #26 ] - Play Deleted Segments in Video Editor [ MH-12575 ][ #25 ] - Upgrade to AngularJS 1.5.11 [ MH-12595 ][ #24 ] - Improve Publications Usability [ MH-12613 ][ #23 ] - New WorkflowOperationHandler 'create-event' [ MH-12628 ][ #20 ] - MH-12629, MH-12630, Minor database fixes [ MH-10560 ][ #19 ] - Live Scheduler Service [ MH-12615 ][ #17 ] - Improve the languages drop-down menu [ MH-12623 ][ #16 ] - Improve workflow dropdown menu [ MH-12621 ][ #15 ] - submit paella player [ MH-12624 ][ #11 ] - Fix link to Karaf remote debugging documentation Update debs.md [ MH-12472 ][ #8 ] - FFmpeg Composer Implementation [ MH-12502 ][ #7 ] - Do Not Leave Files In Workspace [ MH-12477 ][ #6 ] - Operation To Log Workflow State [ MH-12555 ][ #5 ] - Add support for Piwik Media Analytics [ MH-10016 ][ #4 ] - Default Workflow [ MH-12603 ][ #2 ] - Consistent Workflow IDs [ MH-12622 ][ #1 ] - Surefire Versions Should Not Diverge Opencast 4 Opencast 4.5 Released on Oktober 30, 2018 [NOJIRA] - Fix wrong example in publish-configure documentation [MH-13075] - make ACL entries unique prior to running ACL comparisons [MH-13068] - workflow delete instance stability improvement [MH-13055] - Stop making events with no ACL public on ingest [MH-13032] - Asset Upload fix for missing reset() [MH-12953] - stop loading editor.json twice [NOJIRA] - Update the release process docs Opencast 4.4 Released on May 31, 2018 [MH-12923] - ServiceRegistry does not close db connction [MH-12841] - Opencast is ignoring permissions [MH-12840] - LTI user provider may allow LMS admins to become Opencast admins Opencast 4.3 Released on March 28, 2018 [MH-12774] - Fix differences in provided security configurations [MH-12773] - Fix that non-admins cannot add new assets [MH-12772] - Fix acces to assets for non-admins [MH-12789] - Remove tabs and trailing spaces in LTI tools [MH-12790] - Make LTI respect player configuration Opencast 4.2 Released on March 14, 2018 [MH-12766] - Metadata view and edit roles where at some places set incorrectly [MH-12765] - Navigating through series in the series details modal causes failing attempts to save ACLs [MH-12758] - Changing the ACLs does not trigger AssetManagerDecorators [MH-12747] - Heartbeat is broken [MH-12745] - Fix heartbeat config logging [MH-12743] - OAIPMH-Republish-Operation tries to republish to ASW3 [MH-12728] - Add LAST-MODIFIED to ical event properties [MH-12727] - OptimisticLockException on worker node can cause jobs to be stuck in DISPATCHING state [MH-12725] - Series/Events ACL update causes scheduled recordings in the series/the events to disappear from CA calendar [MH-12717] - Series metadata update causes scheduled recordings in the series to disappear from CA calendar [MH-12711] - XACML Parser should be more robust [MH-12707] - Fix problem with non-strict mode in URL-Signing [MH-12706] - Old zombie workflows cannot be stopped, suspended etc. [MH-12668] - Update admin ui build pipeline [MH-12651] - Scheduling repeating events through Admin UI is very slow Opencast 4.1 Released on Februar 7, 2018 [MH-12695] - Improve Synchronization in WorkflowService [MH-12689] - Flickering filter: When loading the page, all filters briefly appear and disappear again [MH-12687] - Date filters not working [MH-12685] - Performance issue in filters [MH-12682] - TimelinePreview Concurrency Problem [MH-12676] - List provider service implementation is not thread-safe [MH-12673] - Content-Type is not set for JavaScript files [MH-12664] - Ensure series can be deleted [MH-12662] - Special characters in modal window titles are double-escaped [MH-12657] - Users of non-admin groups cannot create events [MH-12652] - Scheduler service needs to restrict queries to episodes owned by it [MH-12641] - Asset manager conflict checks are very slow [MH-12638] - Migration bundle needs to have a higher runlevel [MH-12637] - Remove event id from episode DC catalog during migration [MH-12632] - Make index rebuild robust [MH-12631] - Drop the ORGANIZER field from the ical feed [MH-12627] - Start Task copies files into workspace [MH-12620] - Document ActiveMQ memory requirements [MH-12610] - Navigating through events in the event details modal causes failing attempts to save ACLs [MH-12609] - As a user, I expect scheduling of events to be working [MH-12606] - Using \"Start Task\" with a workflow containing an embedded script in the configuration which somehow modifies the input parameters does not update those values properly [MH-12602] - External API gives 500 error for migrated series that do not have creator field [MH-12601] - Fast Workflow Does Not Attach Series Metadata [MH-12582] - Editor WOH should not encode videos unless it is strictly necessary (to save time and resources) [MH-12495] - Job dispatching with loads needs optimization [MH-12476] - Delay start of job dispatching on startup [MH-10016] - Cannot Change Default Workflow Opencast 4.0 Released on December 8, 2017 [MH-12597] - When reindexing, some events may incorrectly be displayed as \"Scheduled\" instead of \"Processed\" or \"Failed\" [MH-12596] - Video Editor Ignores Workspace [MH-12594] - Description field in metadata editor doesn't handle newlines properly [MH-12591] - AssetManager reindex produces \"No organization found!\" warnings [MH-12590] - Fix Workflow WOH Workspace Mock [MH-12589] - Fix Timelinepreview Dependencies [MH-12588] - Stream Security Leaks Secrets [MH-12587] - ActiveMQ config ships with 3rd party tool enabled by default [MH-12583] - Reduce frequency of index rebuild messages for comments and asset manager [MH-12579] - Simplify XACML Handling [MH-12578] - Color of Crosslinks Makes Tables Look Noisy [MH-12574] - Audio keeps playing when leaving the playback or editor page [MH-12573] - Unprivileged users cannot delete events [MH-12572] - Dependency Fixes [MH-12570] - Admin UI Regressions And Minor Bugs [MH-12569] - Don't fail hard if attempting to distribute a non-track media package element to streaming server [MH-12568] - EditableSingleValue Has Focus Issues [MH-12567] - Index Service Dependencies [MH-12566] - Remove Unused Participation List Provider [MH-12560] - Streaming media distribution does not work in a distributed cluster [MH-12559] - CSS: Delete And Retract Dialogs For Events Are Messed up [MH-12558] - CSS: Buttons in Confirm Modals Too Big [MH-12557] - CSS: Checkbox Alignment in Tables [MH-12556] - Video Editor CSS Enhancements [MH-12554] - Downloading translations from Crowdin doesn't work anymore [MH-12553] - As an administrator, I want to configure the order in which the different adaptive streaming video qualities are listed [MH-12552] - The \"delete\" button in the Admin UI may leave the \"preview\" artifacts undeleted [MH-12551] - Redo changes of MH-11660 that got lost in means of a regression [MH-12550] - hasActiveTransaction is triggered permantly for edited jobs [MH-12548] - Matterhorn Kernel Test Issues [MH-12547] - Group related settings in custom.properties [MH-12546] - 3.x to 4.0 upgrade is ugly [MH-12545] - Multi Value Editable Loses Value on Blur [MH-12543] - Adjust Log Level During Build Time [MH-12542] - Fix Ingest Service API Dependencies [MH-12541] - Events not searchable after migration if event was subject to a workflow with two publish-engage operations [MH-12540] - Add documentation for WOH failing [MH-12539] - Add documentation for WOH include [MH-12537] - Admin UI Asset upload: Order Assets as listed in properties file (vs alphabetical) [MH-12535] - Add language support for Hebrew [MH-12534] - Broken Labels In Default Workflow [MH-12532] - The bundle workflow-workflowoperation creates (and leaves) temporary files in /tmp [MH-12529] - External API returns negative Event duration [MH-12526] - External (LDAP) users cannot not see their own role (ROLE_USER_XXXX) in the access policy of the events they create. [MH-12525] - Non-admin users cannot modify ACLs in their own events [MH-12523] - \"Submit\" button in retract modal is always disabled [MH-12522] - Improve Waveform Service Dependency Specification [MH-12520] - Duplicate Series When Double Clicking Create Button [MH-12519] - Improve Admin-NG Dependency Specification [MH-12518] - Ugly exception appears in stdout/Karaf console [MH-12517] - Some job data is not copied correctly [MH-12514] - Opencast Allows Multiple Simultaneous Workflows For Same Media Package [MH-12513] - MigrationService fails [MH-12512] - Frontend-Maven-Plugin configuration is missing the mandatory \"versionRange\" parameter [MH-12511] - Deleting an event with inconsistent search index state doesn't work [MH-12510] - System doesn't recover from ActiveMQ downtime [MH-12507] - Textanalyzer Has Nondeclared Dependencies [MH-12503] - Log statements do not require Object or String arrays to provide 3 parameters or more [MH-12500] - Fix incorrect usage of method \"URL#getFile()\" [MH-12499] - Admin UI event tools dialog can't be closed with the close button [MH-12498] - External API: Cannot get series if description field is empty [MH-12497] - Improve usability of admin UI forms [MH-12492] - AssetManager endpoint return server error on assets, which the user not allowed to read [MH-12489] - Failed test: MySQL DDL Scripts (Update) \ufffc [MH-12488] - Publish worklow always fail [MH-12480] - Waveform Operation Should Have Tests [MH-12479] - Waveform Operation Should Not leave Files In Workspace [MH-12475] - Make mimetypes consistent [MH-12470] - Prematurely deleted scheduler properties lead to undeletable events [MH-12469] - Auto Update OAIPMH republishes deleted Events [MH-12467] - Scheduled event fails due to not finding a workflow definition to use [MH-12465] - Propagate Changes of Series Extended Metadata to Events and OAI-PMH [MH-12463] - Hyphens in event/series search return no results [MH-12456] - Clean Up PathSupport [MH-12455] - FFmpeg does not terminate when Opencast is shut down [MH-12454] - PathSupport.changeFileExtension does not properly handle files with no extension [MH-12453] - TimelinePreview Path Handling [MH-12451] - Lock file utility method should throw exceptions [MH-12450] - Clean up *EncoderEngine code [MH-12449] - Ensure temporary files are deleted on composer failure [MH-12448] - Remove unconfigured send-mail WOH [MH-12447] - OAI-PMH autorepublish fails if series was deleted [MH-12446] - Do not leave ZIP files in workspace when a Workflow fails [MH-12445] - underlying code showing on metadata source tab when creating event [MH-12443] - editing event changes status from scheduled to finished [MH-12442] - Maven site is broken [MH-12436] - Add Christian Greweling to Comitters list [MH-12431] - Update Crowdin translations for r/4.x [MH-12428] - Performance Issue In Event Metadata [MH-12427] - Submit button in Editor typo [MH-12423] - Date Parse Error When Changing Certain Metadata [MH-12420] - Update frontend-maven-plugin [MH-12417] - Poor performace on scheduler /recordings/calendars [MH-12411] - Database user requires additional permissions [MH-12409] - Conductor logs ClassCastException when receiving DeleteSnapshot [MH-12407] - \"The task could not be created\" message by starting task on multiple events [MH-12406] - Splitting in the video editor while a video is playing causes time jump [MH-12401] - Video editor segment times stay blank (timing) [MH-12399] - Oaipmh Retract very slow [MH-12396] - Cannot select filter two times in a row from dropdown [MH-12395] - REST: Handle Scheduling Conflict [MH-12394] - Video editor allows the submission of an event with no active segments [MH-12390] - Gracefully handle unregistration of non-existing host [MH-12385] - Ingest Code Cleanup [MH-12382] - As a system administrator, I want to see the capture agent configuration in the user interface, so that I don't need to look into the database directly [MH-12380] - External API v1.0.0 Broken Due To StartDate Format Change [MH-12372] - Make waveform service more flexible by allowing pre- and post-filters to be configured [MH-12366] - authorization-manager depends on download-impl [MH-12365] - Losing ActiveMQ connection spams the logs [MH-12356] - As an administrator, I'd like to resolve or delete comments in workflows by comment reason only [MH-12355] - Include Wowza Adaptive Streaming Module in Opencast [MH-12354] - Admin UI Video Editor wont let you edit segements at the end [MH-12352] - Include support for user Groups in LDAP [MH-12350] - Recreate adminui-Index stops, if Asset of Event ist missing [MH-12349] - Exception handler should not throw an IO exception on deleting temporary directory [MH-12348] - As an administrator, I want to use the \"send-email\" WOH with multiple recipients and also use the CC and BCC fields [MH-12346] - Publications are not shown in the admin interface [MH-12330] - The series WOH only updates the series' title and ID on the episode's catalog, but sometimes more fields should be updated [MH-12328] - Update AngularJS from 1.3.x to 1.4.x [MH-12325] - Maven warning when building r/3.x [MH-12314] - As a developer, I expect the Admin UI tests being skipped if I build Opencast using -DskipTests [MH-12312] - Event Counter For \"Today\" [MH-12309] - Use Matching FontAwesome Icons [MH-12304] - Configurable Notification Durations [MH-12302] - Do Not Warn About Default Configuration [MH-12289] - Publish extended metadata to OAI-PMH [MH-12287] - prevent reload of Admin UI when opening the editor [MH-12286] - As an Opencast admin, I want to set workflow properties from an external script [MH-12284] - Unprivileged users cannot upload any files when creating or editing a theme [MH-12283] - Support MPEG DASH in Player [MH-12278] - NullPointerException in CleanupWorkflowOperationHandler [MH-12274] - Ingest service REST endpoint should be verbosable and expect input UTF-8 encoded [MH-12266] - As a user, I expect metadata changes to be propagated to third-party applications [MH-12259] - Ingest-download WOH fail on downloading publication elements [MH-12258] - Update angular-translate to version 2.15.2 [MH-12250] - Synchronize Dublin Core date created and start date in DC temporal [MH-12242] - Theodul: Quality selector does not display/load [MH-12234] - Cleanup WOH does not remove all files as it should do [MH-12227] - As a user, I don't want to be informed about services not being working correctly [MH-12223] - Oaipmh Publish is very slow [MH-12200] - Improve LDAP integration after the changes brought by MH-12016 [MH-12196] - Use a date and time picker instead of separate inputs for date and time in admin UI [MH-12191] - Add support for automated captions/transcripts (IBM Watson) [MH-12168] - As a user, I need cross-page links that help me to work more efficiently [MH-12166] - As a user, I'm not willing to perform that many clicks to actually use the filters [MH-12111] - Require Java 8 [MH-12104] - As a producer, I want to access assets of my tenant while a workflow is running [MH-12099] - Wrong started date/time on workflow details view [MH-12082] - Contribute Asset Manager/Scheduler work (ETH) [MH-12052] - As an Administrator, I'd like to know that ActiveMQ is running properly [MH-12000] - Cross-tenant URL signing [MH-11703] - Service error states not immediately visible in admin UI [MH-11458] - Update translations from crowdin [MH-11274] - Workflow Operations of Scheduled Event are not editable [MH-11195] - Ability to Search on part of a Series Identifier, instead of just exact match [MH-11042] - Admin UI NG tests fail in +5:30 timezone [MH-10156] - Misspelling in LtiLaunchAuthenticationHandler.java Opencast 3.x Opencast 3.7 Released on Oct 16, 2018 [ MH-12982 ] - 3.0 database upgrade error [ MH-13022 ] - Fix LTI highly trusted keys being discarded [ MH-13034 ] - Add lis_person_sourcedid back as LTI source field for the username [ MH-13082 ] - Fix LTI security vulnerability and refactor LTI and OAuth classes [ MH-13152 ] - Reduce Workflow Messages, backport of Lars fix for >=r/5.x [ MH-13156 ] - Set the auth scheme to digest for inter-server communication Opencast 3.6 Released on May 31, 2018 [MH-12910] - When switching between branches with different module naming schemes, the git tree is left unclean sometimes [MH-12860] - Opencast does not build at DEBUG logging level [MH-12841] - Opencast is ignoring permissions [MH-12840] - LTI user provider may allow LMS admins to become Opencast admins [MH-12830] - Fix mvn site generation [MH-12743] - OAIPMH-Republish-Operation tries to republish to ASW3 [MH-12441] - Fix multi-server configuration docs and config details [MH-12091] - Create a Capture Agent digest user with its own role Opencast 3.5 Released on February 6, 2018 [MH-12620] - Document ActiveMQ memory requirements [MH-12606] - Using \"Start Task\" with a workflow containing an embedded script in the configuration which somehow modifies the input parameters does not update those values properly [MH-12582] - Editor WOH should not encode videos unless it is strictly necessary (to save time and resources) [MH-12495] - Job dispatching with loads needs optimization [MH-12487] - Add job load settings to the default encoding profles [MH-12399] - Oaipmh Retract very slow Opencast 3.4 Released on December 4, 2017 [MH-12588] - Stream Security Leaks Secrets [MH-12587] - ActiveMQ config ships with 3rd party tool enabled by default [MH-12532] - The bundle workflow-workflowoperation creates (and leaves) temporary files in /tmp [MH-12516] - Oversize job acceptance logic is incorrect [MH-12505] - composer operations need to set job load from profile load when creating jobs [MH-12501] - Incorrect logging in inbox scanner [MH-12496] - Feeds point to removed embed player [MH-12494] - JMX bean unregistration causing stack traces in unit tests [MH-12478] - Waveform filenames are not unique [MH-12471] - Workspace Cleaner Minor Fix [MH-12464] - Job dispatching can be slowed down excessively by host loads query [MH-12439] - WorkspaceCleaner Should Clean All Files [MH-12437] - Admin UI ng fails mvn clean install if the node_modules exists [MH-12435] - Race condition when workspace file deletion removes collection [MH-12430] - Update Crowdin translations for r/3.x [MH-12422] - Adjust documentation to new Crowdin Opencast project [MH-12421] - Job dispatching halts because of http connection hang [MH-12415] - Improve performance of /api/events?withpublications=true [MH-12363] - org.json.simple.parser.JSONParser is not thread safe [MH-12000] - Cross-tenant URL signing [MH-11361] - date in engage is the creation date, not the recording date [MH-11042] - Admin UI NG tests fail in +5:30 timezone Opencast 3.3 Released on September 21, 2017 [MH-12383] - Upgrade/Unify Library Versions [MH-12413] - Don't present the user a previous/next item button if there is no previous/next item [MH-12405] - Catastrophic Oveload in Calendar generation [MH-12400] - Player: Embed Links disabled [MH-12393] - Retract workflow fails if run when a video is being played (with nfs storage) [MH-12389] - Set operation to failed when setting workflow to failed on exception path [MH-12386] - Update Postgresql Connector [MH-12384] - Catch possible NPE in FileSupport.delete() [MH-12366] - authorization-manager depends on download-impl [MH-12365] - Losing ActiveMQ connection spams the logs [MH-12364] - /broker/status endpoint returns incorrect 204 when ActiveMQ is shut down [MH-12362] - Less verbose logging for ExportWorkflowPropertiesWOH [MH-12360] - Race condition in workspace collection add and delete [MH-12359] - Milliseconds trim bug in videoeditor-workflowoperation formatTime() javaScript [MH-12358] - Only 6 series were displayed on the distribution node [MH-12353] - Theodul player does not load reliably after restart [MH-12350] - Recreate adminui-Index stops, if Asset of Event ist missing [MH-12329] - File copy can fail with jetty timeout [MH-12326] - Reduce log level for IllegalStateException in StaticResourceServlet [MH-12317] - AdminUI create every 5 seconds stats request and may crash on heavy server load [MH-12303] - Sort the REST endpoints alphabetically [MH-12131] - Migrate documentation of capture agent communication protocol to markdown [MH-12085] - Make file upload in Admin UI more flexible [MH-11768] - Timeline preview images Opencast 3.2 Released on August 16, 2017 [MH-12347] - Opencast generates invalid XML catalogs when a \"default\" (empty) Namespace is used. [MH-12345] - Ingest fails because /recordings/{id}/acls returns 500 if event has not ACLs [MH-12342] - A \"Scanner\" instance in the ExecuteServiceImpl class is not properly closed: possible resource leak [MH-12333] - Feed generator separates lists of tags incorrectly [MH-12327] - CAS Authentication is not working [MH-12324] - Reduce frequency of index update messages for rebuilds [MH-12318] - Remove Webconsole Default Installation [MH-12316] - IllegalStateException: Committed [MH-12315] - Database Query of Users from UserlistProvider is very slow [MH-12311] - Update Admin UI build tools [MH-12307] - OAI-PMH REST endpoint docs fix [MH-12305] - Admin UI should stop polling event stats if the event tab isn't shown [MH-12288] - Set default max idle time if not configured and log key pool parameters [MH-12280] - Create an Opencast group for Sakai instructors [MH-12278] - NullPointerException in CleanupWorkflowOperationHandler [MH-12275] - MH-12261 / Avoid race condition between index and cleanup operations [MH-12271] - MH-12261 / Update WFR put action to update files atomically [MH-12270] - Don't swallow unknown SMIL exceptions [MH-12263] - MH-12261 / FileSupport > link - copy file action should use overwrite argument (Throws FileFileAlreadyExists) [MH-12261] - Race condition leads to FileAlreadyExistsException and FileNotFoundException [MH-12079] - Misleading logging in some indexing message receivers [MH-12007] - Revive the Execute Service [MH-11542] - Failed test: Process video after cutting (Safari) [MH-10650] - Intermittent failure to detect hard links when starting a cluster [MH-10523] - Misleading exception parameter in getFileFromCollection Opencast 3.1 Released on July 14, 2017 [MH-12296] - getSeries Performance Issue [MH-12295] - Update Karaf to 4.0.9 [MH-12291] - Remove obsolete Speech Recognition API [MH-12279] - As a user, I expect the video editor to correctly visualize the audio track [MH-12253] - Example workflows are inconsistent in Formatting and Configuration of Publication Options [MH-12215] - Extended metadata should be applied on event create wizard [MH-12157] - Series index query performs bad on system with many series [MH-11742] - Document criteria for inclusion and exclusion of translations Opencast 3.0 Released on June 13, 2017 [MH-12257] - HttpsFilter is not called before OAuthProviderProcessingFilter [MH-12255] - OC cannot add PyCA capture agent when server ending with / [MH-12252] - LTI default launch goes to the wrong URL for sample tool [MH-12249] - Media Module: Paging forgets search parameters [MH-12248] - Capture Calendar Modification Caching Implementation is very Inefficient [MH-12247] - Archive Synchronization fix doesn't working in >=2.3 [MH-12235] - WOH partial-import: No track matching smil Track-id [MH-12230] - Notifications appear again although the user has closed them [MH-12228] - player controls: use dropup instead of a dropdown if controls are below the video [MH-12226] - Add documentation about configuration of publication channel names and icons [MH-12222] - As a user, I don't want an empty tab be presented to me since I don't necessarily understand, what that means [MH-12221] - As a user, I expect meaningful placeholder texts in the filter selection components [MH-12213] - Internal distribution fails if download url is not default [MH-12211] - As a service provider, I need to be able to deal with multiple users that have the same name [MH-12207] - Incorrect comment identifiers in some workflows [MH-12205] - Update version of javax.ws.rs - jsr311-api [MH-12204] - Rearrange the config [MH-12202] - ProxyMiddleware does ignore host port [MH-12199] - 3.x release notes mention \"comprehensive\" LDAP support, which is not (yet) true [MH-12198] - Remove outdated file location in LDAP documentation [MH-12197] - IllegalStateException: Response is committed [MH-12195] - Unprivileged users cannot view media package element details on Recordings->Events->\"Event Details\"->Assets->Media [MH-12193] - OAI-PMH distribution fails on adaptive streaming artifacts [MH-12189] - Sakai userdirectory provider is not properly bundled [MH-12183] - Theodul does not load [MH-12181] - As a course admin, I want to allow roles in the UI for ACLs that match a pattern [MH-12180] - Cannot specify ValuefFor probe-resolution woh [MH-12174] - The Admin UI temporarily displays wrong table content because data is not cleared upon page navigation [MH-12173] - The Admin UI temporarily displays wrong table content because data requests are not cancelled [MH-12170] - Safari does not display metadata once entered [MH-12169] - As a user, I expect search strings to match non-word boundaries in searchable dropdown lists [MH-12167] - As a user, I need to be able to search for values offered by the filters, so that I actually find the value I am looking for [MH-12156] - Fix version of matterhorn-engage-theodul-plugin-custom-piwik [MH-12153] - Reduce Database Space usage [MH-12149] - Upgrade Elastic Search to 1.7.6 [MH-12148] - Undocumented Archive WOH Requirements [MH-12147] - TOC links in REST docs overlap [MH-12142] - As a system administrator, I would like a documented hint that the user running Opencast needs RW access to the optional storage directory [MH-12141] - As service provider, I want to restrict access granted to tenant administrators [MH-12138] - Added release notes [MH-12137] - AWS S3 tries to distribute attachments from OAI-PMH distribution [MH-12133] - OAI-PMH Tests Fails Regularly [MH-12130] - Filters set by selecting a category in the dashboard are not shown [MH-12128] - REST docs are too eager to check for a valid value [MH-12126] - Fast workflow needs AWS distribution to default to false. [MH-12124] - Cutting a video multiple times results in multiple smil/cutting catalogs [MH-12121] - Update grunt-ng-annotate to 3.0.0 and grunt-contrib-uglify to 2.2.0 [MH-12120] - pub service oaipmh wants distribution api [MH-12117] - As an adopter I would like to get collect data with Piwik [MH-12115] - Republish Metadata to OAI-PMH fails [MH-12113] - Update outdated comment about the \"lifecycle-mapping\" plugin in the main pom.xml [MH-12112] - Update Node Version [MH-12110] - frontend-maven-plugin is executed on every module [MH-12109] - Creating comments does not work anymore [MH-12108] - Set Workflow Variables Based On Resolution [MH-12104] - As a producer, I want to access assets of my tenant while a workflow is running [MH-12103] - As a producer, I want to be able to execute WOH partial-import on archived sources [MH-12102] - Add Workflow Variables Based On Media Properties [MH-12084] - The class \"AsyncTimeoutRedirectFilter\" swallows almost all the exceptions [MH-12074] - Remove workflow MissedCaptureScanner and MissedIngestScanner [MH-12073] - Typo in rest_docs entry box [MH-12070] - Order the event counters to reflect the event lifecycle [MH-12067] - Initial REST Docs Search [MH-12066] - Missing feature.xml Installation [MH-12065] - Fix bundle info REST endpoint description [MH-12064] - Handle missing meta.abstract gracefully [MH-12060] - Simplify Default WOH [MH-12056] - As an Administrator, I'd like to add some custom roles for managing access [MH-12055] - Update REST Documentation Template [MH-12054] - Incorrect or misleading documentation about WOH conditional execution [MH-12049] - Update REST Documentation Overview [MH-12043] - Allow more then one additional authentication algorithms beside digest [MH-12038] - Fallback decoding for mediapackage date values in unixtime rather than W3CDTF [MH-12037] - NullPoiinterException when starting embedded Solr [MH-12035] - Setting Default Download Directory [MH-12034] - Make the UserAndRoleDirectoryService cache configurable [MH-12033] - Add indicator lights for capture agent status [MH-12032] - Add an authenticated ACL template [MH-12031] - Add additional docs for inspection WOH [MH-12029] - As a user, I want to use my existing AAI login for Opencast, too [MH-12023] - Make development builds faster [MH-12022] - /ingest/addTrackURL broken [MH-12019] - Ensure Test Files Are Deleted [MH-12017] - CoverImage WOH should provide metadata for recording start/end time [MH-12016] - Fix and improve user, group, role and provider handling [MH-12015] - Typo in External API role name [MH-12014] - Incorrect number of roles returned when limit is specified [MH-12013] - Contribute OAI-PMH work (ETH) [MH-12002] - Date & time format should be customizable in cover images [MH-11994] - UserIdRoleProvider should check user existence from user providers [MH-11993] - WOH partial-import should support output framerate [MH-11990] - Remove configuration file of removed module matterhorn-load-test [MH-11982] - As an Opencast administrator, I would like a dashboard counter for active recordings [MH-11979] - The video editor does not highlight the selected segment if it is cut [MH-11978] - Hotkeys for common tasks in Admin UI [MH-11977] - Remove Unused OSGI Bindings From IndexService [MH-11976] - Adjust DownloadDistribution Logs [MH-11975] - Update some maven plugins [MH-11971] - Update maven-surfire-test plugin to latest version [MH-11969] - Fullscreen button in embedded view of Theodul player missing after update to 2.2.4 [MH-11967] - Publish internal fails on Distrubuted System Admin/Engage [MH-11965] - Update to Karaf 4.0.8 [MH-11957] - Make availability check of WOH publish-configure configurable [MH-11956] - Allow fine-grained control of accurate frame count [MH-11954] - Fixing Javadoc Build [MH-11952] - HTML in Translations [MH-11944] - MH-11817 use keyboard shortcuts to control the editor [MH-11916] - Add convenience workflow instance variable to indicate whether a theme is involved [MH-11910] - WOH composite should be able to respect resolution of its input [MH-11904] - Missing IDClass Warnings [MH-11903] - Cannot Configure Authentication For Webconsole [MH-11902] - Update to latest 5.x MySQL connector [MH-11894] - Suppress context menu on video element [MH-11885] - Add support for search and filtering to Organization->Access Policies [MH-11881] - ArchiveRestEndpoint has conflicting endpoints [MH-11880] - Multiple issues with LDAP in branch 2.3.x [MH-11873] - org.ops4j.pax.web.pax-web-extender-whiteboard causes exception when shutting down [MH-11868] - redesign loginpages [MH-11861] - MH-11817 Change default view to editor in admin ui tools area [MH-11849] - Edit metadata fields by click inside and focus cursor in field [MH-11822] - Admin UI Video Editor - Improved Segment Controls [MH-11821] - Admin UI Video Editor - Comment and Metadata Editing [MH-11818] - Admin UI Video Editor - Improved playback and timeline [MH-11806] - Output Frame Rate on Concat Operation [MH-11797] - Upgrade Karaf to 4.0.6 [MH-11796] - Add support for watermarks to themes [MH-11782] - MH-11780 Create configure-by-dcterm workflow operation handler [MH-11781] - MH-11780 Create tag-by-dcterm workflow operation handler [MH-11780] - As a developer I want to be able to manipulate a workflow based on metadata in the Mediapackage [MH-11766] - enhance REST Ingest/addTrack Ingest/addCatalog Ingest/AddAttachment to add tags [MH-11761] - Captions for player [MH-11732] - Make distribution and retraction efficient [MH-11719] - When configuring LDAP with default file things are broken [MH-11717] - MH-11713 Not possible to add external roles to an ACL through the admin UI [MH-11715] - MH-11713 Externally provisioned roles should not be persisted [MH-11713] - Users may have roles in Opencast which are granted from an external system (e.g. LMS) [MH-11684] - WOH silence does not support tags [MH-11474] - Assigning a user to a certain \"ROLE_GROUP_<name>\" role does not really put the user in such group [MH-11466] - Improve handling of long strings in cover images [MH-11379] - Service to distribute delivery files to AWS S3 [MH-11229] - workflowoperation unit tests are incredible slow [MH-11036] - Adapt Fast Testing Workflow for Admin NG [MH-10871] - Sakai User Provider for Opencast-Sakai integration [MH-10819] - When creating a new event, metadata field can only be edited by clicking on the pencil icon [MH-10753] - Stale database connection causes job failure [MH-10310] - Add ERROR state for capture agent Opencast 2.3.x Opencast 2.3.5 Released on December 04, 2017 [MH-12588] - Stream Security Leaks Secrets [MH-12317] - AdminUI create every 5 seconds stats request and may crash on heavy server load [MH-12269] - Clarify in the documentation the recommendation of setting dispatchinterval to 0 applies to non-admin nodes only [MH-12190] - Script injection in Media Module and Player [MH-12000] - Cross-tenant URL signing [MH-11042] - Admin UI NG tests fail in +5:30 timezone Opencast 2.3.4 Released on August 03, 2017 [MH-12183] - Theodul does not load [MH-12203] - Unescaped event and series titles when editing event or series (XSS) [MH-12242] - Theodul: Quality selector does not display/load [MH-12246] - Series WOH does not apply series DublinCore catalogs [MH-12249] - Media Module: Paging forgets search parameters Opencast 2.3.3 Released on May 02, 2017 [MH-10558] - Mime type not identified for matroska / mkv files [MH-10595] - Incident service returns internal server error if cascade=true requested for deleted workflow [MH-10747] - Inputs for capture device should be pre-selected [MH-11736] - Difference in start time displayed in overview and metadata details [MH-11811] - Opencast build fails when system timezone is set to PDT (Pacific Daylight Time) [MH-12048] - Series drop-down not sorted alphabetically in filter [MH-12069] - Deleting an event leaves behind orphaned comments [MH-12095] - Server default timezone can be incorrect [MH-12106] - Preserve user attributes from providers during authentication [MH-12107] - Improve performance of Servers table in Admin UI [MH-12118] - Paging in media module is broken [MH-12129] - Media module only works with english localized browsers [MH-12130] - Filters set by selecting a category in the dashboard are not shown [MH-12148] - Undocumented Archive WOH Requirements [MH-12150] - Matroska files are not recognized [MH-12158] - Workflow job dispatching failures [MH-12162] - JpaJob object toString override for better log messages [MH-12163] - Events with stopped workflows sometimes cannot be deleted [MH-12164] - Updating serviceregistry config while running leaves Opencast in a non-functional state [MH-12190] - Script injection in Media Module and Player Opencast 2.3.2 Released on March 22, 2017 [MH-11224] - Attempting to view source metadata through the new admin UI generates a stack trace [MH-11340] - Uncaught NullPointer Exception in Karaf console from com.entwinemedia.fn.data.json.SimpleSerializer.toJson [MH-11616] - Search Service will not remove mp from index if it is not found in database [MH-11743] - event.hasPreview() broken [MH-11760] - Event edit warning cannot be removed [MH-11790] - Slide Previews and slide text are not shown in Theodul Engage player [MH-11817] - Unhide volume controls in video-editor [MH-11819] - Admin UI Video Editor - Improved Zoom Controls [MH-12009] - Admin UI Video Editor: Segmentation lost after publishing [MH-12058] - Ingests fail if specified workflow does not exist [MH-12059] - Catch invalid dates when indexing [MH-12061] - Reduce the number of activemq messages and log entries during index rebuild [MH-12062] - Improve robustness of scheduler re-indexing [MH-12063] - Catch incomplete archive entries when indexing [MH-12072] - Wrong destinationId for External API message receiver [MH-12084] - The class \"AsyncTimeoutRedirectFilter\" swallows almost all the exceptions [MH-12087] - Null bitrate can cause UI display of source media to fail [MH-12092] - Return event ID when event is created through Scheduler API [MH-12097] - SegmentVideoWorkflowOperation: Modules not included in Admin Presentation build. Opencast 2.3.1 Released on Janurary 25, 2017 [MH-11267] - Wrong notification text when deleting series [MH-11458] - Update translations from crowdin [MH-11687] - UI date formats are wrong for most of the English-speaking world [MH-11776] - CaptureAgentStateServiceImplTest incorrectly passes a non-long recording id, misses finding the NullPointer in Impl [MH-11960] - matterhorn-adminui-ng fails on first build [MH-11961] - Cannot access slidetext.xml should not break re-indexing [MH-11963] - Fix ingest REST docs [MH-11966] - Confusing AdminUI Groups Endpoint Documentation [MH-11967] - Publish internal fails on Distrubuted System Admin/Engage [MH-11983] - Only administrators should be allowed to assign the admin roles to other users [MH-11987] - Declare Admin UI Facade as module internal interface [MH-11988] - Advise to change karaf shutdown command in the docs [MH-11989] - Allow unknown as well as offline CAs to be removed via UI [MH-11992] - Compatibility issue when using contrib Wowza adaptive streaming module [MH-11998] - /info/me.json sometimes doesn't provide full information about the user [MH-12004] - Removing an recording does not remove all correspronding jobs [MH-12005] - UI shows inconsistent version due to missing version in cover-image-remote [MH-12006] - Security Issue Allowing Arbitrary Code Execution Opencast 2.3.0 Released on December 13, 2016 [MH-10342] - As an external device I want to immediate start and stop a capture [MH-11327] - De-couple smilImpl/wfrImpl from ingestImpl [MH-11378] - Conditionally synchronize Archive Service's add mediapackge [MH-11380] - As a customer, I want to integrate my third party application to Opencast, so that I can use Opencast content in my application [MH-11381] - Remove documentation of items that have never been implemented [MH-11411] - move dashboard to header [MH-11675] - Add documentation for External API to the Admin Guide [MH-11688] - Set java file encoding on startup [MH-11718] - As a producer, I want to be able to make workflow settings persistent so that I can reuse them later [MH-11725] - Give users a starting point how to report bugs [MH-11726] - Add AdminUI style guide to developer guide [MH-11728] - Use Apache Commons Lang 3 [MH-11729] - External API: Add documentation for Groups Endpoint [MH-11731] - Typofix Documentation [MH-11737] - Comment (mh_event_comment and mh_event_comment_reply) text field is VARCHAR(255) should be TEXT [MH-11740] - optimization of segmentation [MH-11741] - Admin UI has timezone issues [MH-11749] - External API: Add REST documentation for Endpoints [MH-11750] - Clean-Up Opencast Code Base [MH-11752] - Upgrade Karaf to 3.0.8 [MH-11756] - Admin UI NG Update CSS+HTML (1): FontAwesome, improve HTML, remove redundant images [MH-11763] - Counters hide series tab [MH-11772] - Admin UI source dropdowns inappropriately advance [MH-11774] - Admin UI Needs better documentation for debugging [MH-11775] - Library Update [MH-11783] - Custom publications labels not displayed when doing a mouse-over on Events->Published [MH-11784] - Remove Participation Management Code Pieces [MH-11786] - HttpsRequestWrapper wrongly sets the new URL [MH-11791] - As service provider I want to configure which kind of users can see the event counters [MH-11792] - NPM Proxy via Nexus [MH-11794] - NPM fails on first build [MH-11795] - Add support for title slides [MH-11799] - Maven bundle names too long [MH-11800] - LTI between Opencast and Moodle does not work [MH-11801] - Wowza streaming server needs flv: prefix for flv files [MH-11802] - Opencast Logo is missing in Player [MH-11803] - Player redirect is missing [MH-11804] - No video controls in embed mode [MH-11808] - Pre-select workflow in case only one option is available [MH-11809] - Fix syntax error in encoding profile composite.http [MH-11812] - Fix security configuration for ROLE_UI_TASKS_CREATE [MH-11813] - Agent state REST endpoint documentation [MH-11815] - As a user I expect changes to be reflected in the Admin UI immediately [MH-11817] - Admin UI Video Editor - Bug Fixes [MH-11817] - Display video details in preview player/ editor of the admin ui [MH-11817] - Improve Button Hover Indication [MH-11817] - Make Next/Last Frame controls in videoeditor better recognizeable [MH-11827] - Recordings->Events->\"Event Details\"->Metadata: Incorrect translation used [MH-11828] - exception-handler-workflow not set correctly [MH-11829] - High memory usage on the admin server by dispatching jobs [MH-11831] - As a service provider, I want to configure whether Opencast creates an admin user automatically [MH-11834] - Unable to set capture agent configuration as JSON [MH-11836] - Additional ACL actions of series are missing when creating a new event in that series [MH-11837] - Unprivileged users have no access to fonts [MH-11839] - typo in Event Details: Comments [MH-11841] - Wait for NFS shares before start Opencast service [MH-11842] - Revert accidental downgrade of grunt version [MH-11851] - org.opencastproject.security.admin/pass can't be changed [MH-11857] - Fix log output \"Unable to delete non existing object %s/%s\" [MH-11862] - Search API handles roles wrong [MH-11863] - WOH analyze-tracks & WOH failing cause exceptions when shutting down Opencast [MH-11864] - WOH tag shall implement AbstractWorkflowOperationHandler [MH-11865] - Videoeditor Preview mixes in 2 Audiofiles [MH-11866] - Search box in Organization >> Groups not working [MH-11867] - Filter box in Organization >> Groups not working [MH-11869] - Deleting Series with 'Actions' is not working [MH-11870] - Wordlength in other languages except english too long [MH-11871] - ElasticSearch shall bind to 127.0.0.1 [MH-11875] - ActiveMQ should not listen to all hosts by default [MH-11880] - Multiple issues with LDAP in branch 2.3.x [MH-11883] - Larger files may remain in system temp directory [MH-11886] - login pages throw errors on loading unnecessary scripts [MH-11888] - Organization Filter uses Provider where table uses Type [MH-11889] - Row size too large [MH-11890] - MySQL Connector Version Should Be Consistent [MH-11891] - Event counters query large amounts of useless data [MH-11895] - \u201cAdd Event\u201d Wizard Input Fields Broken [MH-11896] - Java Warnings in AbstractEventEndpoint [MH-11897] - Remove Deprecated StringHelper [MH-11898] - Fix Technical Duration Calculation [MH-11899] - Prevent Requesting Event Objects Multiple Times [MH-11900] - Minor Index Service Fixes [MH-11905] - Publish Configure WOH incorrectly retracts publications [MH-11912] - No slider in playback video player [MH-11919] - WOH image claims SUCCEEDED when actually skipping [MH-11920] - WOH prepare-av: Misleading log message [MH-11921] - WOH partial-import looses partial audio tracks in specific cases [MH-11950] - Javadocs build error [MH-11955] - Add en-GB to Languages Opencast 2.2.x Opencast 2.2.5 Released on June 7, 2017 [MH-11983] - Only admins should be able to modify other admins [MH-12006] - Security Issue Allowing Arbitrary Code Execution [MH-11962] - Missing slidetext.xml should not break re-indexing Opencast 2.2.4 Released on October 13, 2016 [MH-11831] - As a service provider, I want to configure whether Opencast creates an admin user automatically [MH-11851] - org.opencastproject.security.admin/pass can't be changed [MH-11862] - Search API handles roles wrong [MH-11875] - ActiveMQ should not listen to all hosts by default Opencast 2.2.3 Released on October 13, 2016 [MH-11285] - Improve developers documentation: remote debugger with karaf [MH-11741] - Admin UI has timezone issues [MH-11771] - Improve section localization in developer guide [MH-11773] - Embed player does not use space very well and has scaling problems [MH-11774] - Admin UI Needs better documentation for debugging [MH-11777] - Event Details->Comments and Event Details->Assets don't work for unprivileged users [MH-11787] - Add release dates to changelog [MH-11800] - LTI between Opencast and Moodle does not work [MH-11801] - Wowza streaming server needs flv: prefix for flv files Opencast 2.2.2 Released on September 14, 2016 [MH-11194] - created themes not showing up in series branding tab [MH-11572] - FFmpeg Inspection Service Test - accurateFrameCount [MH-11587] - SQL Error [MH-11714] - Fix unit test: Event controller #accessSave saves the event access [MH-11724] - Additional actions not available in create event wizard anymore [MH-11734] - Fix el7 RPM docs [MH-11735] - Fix Stream Security Documentation [MH-11744] - Actions->Start Task: Various localization bugs [MH-11748] - Inconsistent and incorrect use of translate directive [MH-11751] - Player won't work if there are no segments [MH-11755] - No quality selection in Theodul Player [MH-11759] - Make Inspector Unit Tests More Robust Opencast 2.2.1 Released on July 30, 2016 [MH-11092] - Every Browser has an other \"Remember me\" checkbox [MH-11169] - Trimming points not set correctly after workflow is finished [MH-11538] - \"No compatible source was found for this video\" videojs player error in iOS device [MH-11561] - Style (CSS): Setting a server in Maintenance (srv-det-01) [MH-11598] - Wizards should not re-use data that has entered before [MH-11644] - Missing Admin Interface Mock Data [MH-11653] - Jobs do not always proceed [MH-11655] - Jobs with high job load never get processed [MH-11659] - Warning is missing that metada and ACL cannot be edited while job is processing. [MH-11661] - Link on logo on the media module points to admin ui or welcome page, instead of something that is accessable for every user [MH-11664] - Incorrect Inconsistency status when built from tarball [MH-11665] - Systems->Servers & Systems->Services show wrong mean runtime and mean queue time [MH-11667] - Align main table content [MH-11668] - Missing segment previews let to an erro in the player [MH-11669] - Do not archive OCR texts [MH-11673] - Add documentation for additional ACL actions [MH-11674] - Add documentation for metadata configuration [MH-11679] - Page size cannot be changed in any table [MH-11681] - Add documentation for role-based visibility [MH-11682] - Remove useless roles from roles.txt [MH-11686] - Extended metadata tab not shown although user has the role ROLE_UI_EVENTS_DETAILS_METADATA_VIEW [MH-11690] - Various Documentation Improvements [MH-11692] - Remove Superfluous Mh-Db-Version [MH-11693] - Remove Superfluous Dependency Versions [MH-11694] - JavaDoc Generation Broken [MH-11702] - After an upgrade to 2.2.0, series are not displayed in the UI because the series creation date is now mandatory [MH-11720] - Opencast 2.2 requires Git to be installed at build time [MH-11727] - Fix unit test: adminNg.services.language #toLocalTime converts a zulu time string back to local time FAILED [MH-11730] - Make the automatic role prefix in LDAPUserProvider configurable Opencast 2.2.0 Released on June 15, 2016 [MH-9511] - Wrong log level in Tesseract [MH-9831] - ehcache and quartz phones home [MH-9950] - Update player dependencies [MH-10029] - Remove Unnecessary Image Conversion Step From TextAnalysisService [MH-10173] - Do not ignore exceptions when closing Closeable's [MH-10748] - Matterhorn has to be restarted to schedule an event on a new capture device [MH-10794] - Delete Action should be disabled if nothing is selected [MH-10869] - ActiveMQ Configuration and Connection Problems [MH-10870] - ActiveMQ Exceptions While Shutting Down Matterhorn [MH-10887] - Users can schedule events in the past [MH-10898] - Update Apache HttpComponents (3.1.7 \u2192 4.4.1) [MH-10923] - Theodul player : Filtering \"composite\" tags results in error when the composite workflow is used [MH-10942] - Events are not deselected after applying a task [MH-10965] - Theodul player : Videos not playable on IE10 [MH-10971] - Newly created Series don't show up in Series dropdown selection lists without page reload [MH-10978] - Unable to retract 'internal' publications [MH-10979] - Opencast needs to better distribute load across the available nodes [MH-10984] - Extend ingest service by partial upload [MH-11010] - Stream Security should be able to prevent cross-tenants access [MH-11014] - Add support for additional ACL actions [MH-11077] - The Publish Workflow will not retract already published material [MH-11097] - View modes not working correctly [MH-11107] - Group list pagination not working [MH-11121] - MacOS X Installation Guide Needs 2.1 Update [MH-11124] - Incorrect documentation on how to create users [MH-11128] - Docs about SilenceDetector threashold are incorrect [MH-11139] - Unable to find mimetype for mkv [MH-11140] - Forward and backward buttons are greyed out [MH-11143] - Link to Media Module in Admin UI [MH-11148] - Search box layout incorrect: Icon overlaps text [MH-11156] - Users: Search box not implemented [MH-11157] - Groups: Search box not implemented [MH-11165] - Sorting does not work on Systems->Jobs, Systems->Servers and Systems->Services [MH-11167] - Layout problem on Workflow Error Details view [MH-11183] - Capture->Locations: Search box not implemented [MH-11190] - Theodul Shortcuts: Description could be improved [MH-11191] - Event Details->Assets: Use human-readable units for duration, bitrates and sizes [MH-11192] - Audio level slider does not change audio level while dragging [MH-11199] - Playback & video editor don't work while workflow is running [MH-11209] - LTI Documentation needs to be incorporated into new docs [MH-11222] - Replace System.out.println with logger [MH-11229] - workflowoperation unit tests are incredible slow [MH-11252] - Some service configuration files are stored in the wrong directory [MH-11265] - Ensure configuration files end with newline characters [MH-11266] - Logger ConversionPattern stated twice [MH-11276] - HttpNotificationWorkflowOperationHandlerTest fails if a certain Domain Exists [MH-11280] - Opencast fails to compile due to missing dependencies in test-harness [MH-11281] - Enhance WOH image to support extraction of multiple images using multiple encoding profiles from multiple sources [MH-11282] - Enhance WOH composite to support single video streams [MH-11287] - Update Apereo/Apache License List [MH-11289] - Change text extraction documentation or file name [MH-11294] - Create admin-worker and ingest distribution [MH-11296] - HTTP method POST is not supported by this url in r/2.1.x [MH-11298] - Fix json-simple version specification [MH-11300] - WOH partial-import looses partial audio tracks beginning at position zero [MH-11304] - Documentation for WOH partial-import and load configuration not listed in pages configuration [MH-11306] - Change job dispatcher sort order to: restart jobs, non-wf jobs, creation date [MH-11307] - Distribution Service is not on Presentation Node [MH-11310] - Document encoding profiles used by WOH partial-import [MH-11311] - Use existing encoding profiles in WOH partial-import example [MH-11312] - Fix Encode WOH Documentation [MH-11313] - Update Parallel Encode Profiles [MH-11319] - Media Module Always Uses Second Attachment as Preview [MH-11320] - Missing Image Preparation for text Extraction [MH-11321] - Fix default workflow configuration panel [MH-11322] - Update WebM Profiles [MH-11355] - Slide texts are not shown correctly in theodul player, except the first segment there a now slide texts shown (\"No slide text available\"). In the XML file the texts are correct [MH-11356] - Update Documentation Index Page [MH-11357] - Notifications are not removed after a while [MH-11358] - Dismiss Button for comments has an inconsistent design [MH-11363] - Notification that server is not reachable is missing [MH-11364] - Reasons in Comments section are no longer translated [MH-11368] - Changing to Chinese translation doesn't work [MH-11369] - Series filter displays series id instead of series title [MH-11374] - Videoeditor: Times are wrong in zoomed waveform view [MH-11385] - Metadata summary not showing any metadata at event creation [MH-11386] - Silence Detection / Video Editor Waveform bug [MH-11389] - security 1 [MH-11391] - Improve Flavor creation and parsing [MH-11392] - Sorting by series.created does not work correctly [MH-11401] - Hiding of columns is globally broken [MH-11404] - Group editor shows users and roles twice [MH-11405] - Pagination broken for groups table [MH-11409] - Translation key EVENTS.EVENTS.GENERAL.SELECT_WORKFLOW_EMPTY is missing [MH-11413] - AdminUI comment dialog translations missing [MH-11414] - Logger is missing from several modules [MH-11415] - Incorrect Urlsigning Module Name [MH-11416] - Specify Opencast's Requirements [MH-11417] - Tab names of modals not vertically centered [MH-11419] - Tables not drawn correctly [MH-11422] - add event tab titles not translated [MH-11427] - Can't get host details from Serviceregistry REST endpoint [MH-11428] - Default Workflow Option Does Not Work [MH-11430] - Prevent user from accidentally press \"Save & process\" in Video Editor multiple times [MH-11431] - Prevent users from accidentally pressing the Delete/Retract button multiple times [MH-11432] - JSHint settings are missing [MH-11434] - \"The task could not be created\" error notification always appear when starting a task on multiple events [MH-11435] - Fix code style errors in Gruntfile.js [MH-11436] - Matterhorn on Login/Welcome Page [MH-11437] - Resource Problems On Login Page [MH-11438] - Resource Problem on Welcome Page [MH-11439] - Event description not available in WOH cover-image [MH-11441] - Clicking on Logo in top left corner will nmot get you to the start page [MH-11443] - Seeking is not possible before pressing play button at least once?!? [MH-11446] - Remove eclipse-gemini repository from main pom.xml [MH-11447] - Scheduling conflicts reporting completely broken [MH-11448] - Tipps on developing on admin ui ng [MH-11450] - Fix Defaults For Documentation Links [MH-11453] - Correctly link the stream security documentation [MH-11457] - Remove duplicate keys from Admin UI english translation [MH-11458] - Update translations from crowdin [MH-11459] - Logger Logs Nullpointer on Error [MH-11462] - Cover WOH is not included in a useful way [MH-11464] - setting personal preferences in admin UI fails [MH-11468] - There are unused ressources [MH-11475] - Fix typos in English master translation [MH-11476] - Series->Actions->Delete displays wrong notifications [MH-11477] - Editing status of series displays wrong notification when saving fails for all series [MH-11480] - Replace horizontal ellipsis [MH-11481] - Workflows started by unprivileged users hang [MH-11492] - forward and backward section not working in safari [MH-11509] - Failed test: Sorting groups list (grp-lis-01) [MH-11511] - Failed test: Manual set time in textbook for IE11 [MH-11512] - hello world does not follow import statements rules [MH-11518] - Language selector is always displayed in system language [MH-11519] - Languages are only distinguished by main language [MH-11520] - Remove company logos [MH-11521] - ActiveMQ Library Configuration [MH-11522] - DataLoader Default Value [MH-11523] - Working file repository default value [MH-11524] - Distribution Service Default Values [MH-11532] - Wider language support in player [MH-11534] - Add language support for Chinese Simplified [MH-11535] - Add documentation about Crowdin to Developer Guide [MH-11536] - Remove Commercial Code From Core [MH-11537] - Execute Service WOH Cannot be Built [MH-11539] - Remove Old MH Logos in Favor of Opencast SVG Logos [MH-11544] - Admin UI links used inconsistently [MH-11546] - Pagination buttons too small for large numbers [MH-11548] - The \"Edit\" button at the top-right corner of the tables doesn't support localization [MH-11550] - Update Migration documentation 2.1 to 2.2 [MH-11554] - Filtering does not work on Systems->Jobs, Systems->Servers and Systems->Services [MH-11555] - Localisation of Recordings->Events and Recordings->Series buggy [MH-11556] - Failed test: Filter locations (T1733, Filter by status does not work) [MH-11559] - outdated shortcurts configuration prevents player from loading. [MH-11571] - Elasticsearch shutdown command handler crash opencast [MH-11573] - Do not hide warnings [MH-11574] - Jetty Error on Large Workflow Instances [MH-11575] - Inspection Service Tests Fail With Certain FFmpeg Versions [MH-11576] - Servlet Filter Improvements [MH-11578] - Improve default order of columns in Systems->Jobs [MH-11579] - Admin UI mockup data for Systems->Jobs incomplete [MH-11580] - Unit tests for Admin UI language selection broken [MH-11581] - Systems->Jobs table not working correctly [MH-11583] - Fix Code Style [MH-11588] - Create side-by-side preview for video editor [MH-11589] - Feedback button does not work [MH-11590] - The WorkflowServiceImpl constructor sets the \"waitForResources\" argument incorrectly [MH-11594] - Add language support for Galician [MH-11595] - Fix admin ui unit tests for tableService [MH-11597] - Building matterhorn-engage-theodul-plugin-video-videojs reports a lot of code style issues [MH-11600] - Failed test: i18n (gen-int-01) [MH-11601] - current language can have undefined state [MH-11604] - Date picker for setting up the schedule is always french [MH-11605] - Disabling link to mediaplayer creates a broken link and missing logo [MH-11606] - Add language support for Greek [MH-11608] - Add documentation for WOH cleanup [MH-11613] - WOH editor fails when input has uneven width or height [MH-11614] - Partial matches not working anymore [MH-11617] - Add language support for Dutch [MH-11620] - Non privileged user can not login on presentation node [MH-11623] - Server statistics: Slow Query [MH-11624] - Workflow owners do not necessarily have access to their workflows: user comparison fails [MH-11627] - NullPointerException when creating a new Solr index [MH-11629] - Hide Some Confusing Warnings [MH-11630] - Service registry lacks of getActiveJobs() function [MH-11631] - Remove columns \"Blacklisted from\" and \"Blacklisted until\" from Capture->Locations [MH-11632] - Library Bugfix Upgrade [MH-11636] - Adjust FFmpegComposer Logging for Newer FFmpeg Versions [MH-11637] - Add language support for Swedish [MH-11638] - Improve Encoding Profiles [MH-11639] - Media module login form has poor usability and bugs [MH-11642] - Remove binding to non-existing method in WOH analyze-tracks [MH-11643] - Add language support for Polish [MH-11645] - Open AdminUI menu links in new tab does not work [MH-11646] - Add documentation for WOH comment [MH-11652] - Unit tests for servicesController broken [MH-11654] - Failed ingest jobs block system from dispatching other jobs [MH-11656] - Add documentation for WOH copy [MH-11657] - Improve documentation for workflow execution conditions [MH-11658] - Better quality for video editor previews [MH-11663] - Hide Participation Management from UI since not yet working [MH-11666] - Not all WOH listed in WOH overview Opencast 2.1.x Opencast 2.1.2 Released on May 10, 2016 [MH-9831] - ehcache and quartz phones home [MH-11121] - MacOS X Installation Guide Needs 2.1 Update [MH-11124] - Incorrect documentation on how to create users [MH-11128] - Docs about SilenceDetector threashold are incorrect [MH-11209] - LTI Documentation needs to be incorporated into new docs [MH-11229] - workflowoperation unit tests are incredible slow [MH-11283] - post-mediapackage WOH breaks further processing [MH-11287] - Update Apereo/Apache License List [MH-11296] - HTTP method POST is not supported by this url in r/2.1.x [MH-11298] - Fix json-simple version specification [MH-11307] - Distribution Service is not on Presentation Node [MH-11319] - Media Module Always Uses Second Attachment as Preview [MH-11320] - Missing Image Preparation for text Extraction [MH-11321] - Fix default workflow configuration panel [MH-11323] - Workflow Docs are Incorrect [MH-11332] - Document acceptance criteria for proposals [MH-11356] - Update Documentation Index Page [MH-11377] - Opencast does not have an ingest assembly Opencast 2.1.1 Released on January 22, 2016 [MH-11107] - Group list pagination not working [MH-11265] - Ensure configuration files end with newline characters [MH-11266] - Logger ConversionPattern stated twice [MH-11276] - HttpNotificationWorkflowOperationHandlerTest fails if a certain Domain Exists [MH-11280] - Opencast fails to compile due to missing dependencies in test-harness Opencast 2.1.0 Released on December 22, 2015 [MH-10637] - Hello World service [MH-10651] - Workspace cleaner job param in wrong units (ms vs s) and wrong logic [MH-10714] - Two clock icons at the time stamp of a comment [MH-10805] - The confirmation dialog are not translated [MH-10818] - The creation date is presented as ISO string in the event metadata [MH-10869] - ActiveMQ Configuration and Connection Problems [MH-10874] - Plugin does not properly handle multiple keys [MH-10875] - Include search capabilities into mkdocs documentation build [MH-10890] - Update Apache Commons Lang (2.6 \u2192 3.4) [MH-10908] - Assemblie Module Names Too Long [MH-10908] - Consistency in Documentation: Presentation Server VS Engage Server [MH-10908] - Misconfigured Checkstyle Plug-in in Assemblies [MH-10919] - Top row for setting roles in the access policy for an event is not showing the right value [MH-10953] - Spanish layout is broken [MH-10955] - Make sure recent versions of mkdocs work [MH-10956] - Update Synchronize.js [MH-10985] - As an operator I want to check the health status of Opencast [MH-10986] - Scheduling around DST change fails [MH-10987] - Improve workflow query to accept paging by index [MH-10988] - Rewrite workspace to fix several small issues [MH-10989] - Improve working file repository stream response [MH-11007] - Remove 3rd party tool script [MH-11026] - Several invalid links in the Opencast User Guides [MH-11031] - Missing option to create new event using files ingested from the inbox [MH-11036] - Adapt Fast Testing Workflow for Admin NG [MH-11051] - Fix WOH Documentation [MH-11069] - When creating new series, warning about read/write requirements is shown twice. [MH-11072] - The ACL editor needs enhanced validation [MH-11074] - Admin UI Test: New Event API Resource assembles the metadata for SCHEDULE_MULTIPLE with DST change is failing [MH-11083] - Clean-up Codebase after Karaf [MH-11085] - Make sure bundle cache is cleared when restarting [MH-11086] - Shorten File Names in Log Output [MH-11088] - translation error in theodul player [MH-11089] - Theodul player seems not to work with Internet Explorer at all [MH-11093] - single video screen size jump when clicked [MH-11094] - Problems in Theodul controls plugin due to wrong resolves of merge conflicts [MH-11095] - Make assemblies more user firedly [MH-11096] - Errors when loading admin-ng login page [MH-11099] - Removing one role from an Access Policy (acl-det-05) [MH-11101] - Creating a Theme with 2 bumper videos - In and Out (thm-new-01) [MH-11109] - Event details tab cannot handle long event titles well [MH-11110] - minor updates to ffmpeg video-editor and silence detection based on gregs review of the feature in 1.6.3 [MH-11111] - Formatting issues in \u201cTheodul Pass Player - URL Parameters\u201d [MH-11114] - Remove System.out.println from FileReadDeleteTest [MH-11120] - Several Services Fail During Shutdown [MH-11122] - Create Service Files (Systemd/SysV-Init) [MH-11126] - Fix Translation for 2.1 [MH-11133] - i18n: Theme Detail view layout broken in Spanish [MH-11135] - Create Release Manager Docs [MH-11137] - Comment reasons are not working correctly [MH-11138] - Clock icon displayed twice next to comment creation date [MH-11141] - Playback Speed in player needs more useful defaults [MH-11142] - fix translations for shortcuts [MH-11144] - update documentation regarding property for mediamodule logo [MH-11147] - Missing translations: FILTERS.USERS.PROVIDER.LABEL & FILTERS.USERS.ROLE.LABEL [MH-11149] - Filter locations: Translations FILTERS.AGENTS.NAME.LABEL & FILTERS.AGENTS.STATUS.LABEL missing [MH-11151] - Plaback speed from menu [MH-11152] - Editing ACL: Translation for USERS.ACLS.DETAILS.ACCESS.ACCESS_POLICY.DESCRIPTION missing [MH-11153] - Access Policy Details: Cannot navigate to previous or next ACL [MH-11154] - New Access Policy: Translation for USERS.ACLS.NEW.ACCESS.ACCESS_POLICY.DESCRIPTION missing [MH-11155] - ACL Editor: Role not displayed at all [MH-11158] - Playback Tool: Time can be edited, but editing has no effect [MH-11159] - Users sorting: Sort order for 'Name' not correct [MH-11160] - Create Group overwrites existing groups without warning [MH-11162] - security_sample_cas.xml in MH 2.0.1 Points to Wrong Welcome Page [MH-11166] - Number of rows not displayed on Systems->Servers [MH-11176] - Cannot playback a recording via LTI in 2.x [MH-11177] - Fix Player OSGI Dependencies [MH-11178] - Prevent FFmpeg Experimental AAC Encoder Bug to Affect Opencast [MH-11180] - Update video.js to latest 4.x version [MH-11181] - Flash streaming with multi-quality video does not work [MH-11185] - Event Details->Assets->: Asset size is always 0 [MH-11186] - Event Details->Assets->Media->Media Details: Superfluous row 'Flavor' [MH-11187] - Configuration->Themes: Number of rows not displayed correctly [MH-11189] - Actions->Start Task: User can press create button multiple times [MH-11193] - Setting audio level slider to \"zero\" does not set the actual audio level to \"zero\" [MH-11196] - REST docs cannot be found in new admin ui [MH-11198] - Event dashboard seems not to support i18n [MH-11201] - Maven Assembly Plug-in Listed Twice [MH-11202] - FFmpeg video editor operation is synchronized [MH-11212] - Main Pom Clean-Up [MH-11218] - Karaf based Solr configuration [MH-11221] - ComposerServiceImpl creates incorrect incidents and error messages [MH-11223] - Remove unused files [MH-11234] - Admin-NG throws a couple of 404 errors [MH-11236] - Security ACL see security list [MH-11237] - Service files are missing [MH-11238] - Silence-detection does not read configuration value for ffmpeg binary path [MH-11248] - Publish-Engage Workflow Operation Documentation is Missing Configuration Keys [MH-11249] - Apply-ACL WOH not properly replaced by Seried-WOH in Documentation [MH-11250] - Put temporary files in karaf data not in opencast.storage [MH-11251] - Capture-Admin Tests May Fail When Executed Too Fast [MH-11257] - Deprecated Mkdocs Config [MH-11258] - Make host configuration easier Opencast 2.0.x Opencast 2.0.2 Released on December 22, 2015 [MH-10235] - Users are unable to determine the Version of Matterhorn [MH-10484] - Remove Mediainfo from 3rd-Party-Tools [MH-10558] - Mime type not identified for matroska / mkv files [MH-10588] - Improve MySQL DDL to make it consistent again [MH-10759] - Write QA documentation for Access Policies [MH-10759] - Write QA documentation for Series [MH-10759] - Write QA documentation for Themes [MH-10818] - The creation date is presented as ISO string in the event metadata [MH-10918] - Improve the representation of the attachments/catalogs/media/publications in the event details [MH-10956] - Update Synchronize.js [MH-10964] - The Opencast start script does not work on Mac OS X [MH-10976] - Eclipse (m2e) throws NullPointerException erros due to a missing property in the pom.xml file [MH-11007] - Remove 3rd party tool script [MH-11007] - Switch subtitle embedder to FFmpeg [MH-11026] - Several invalid links in the Opencast User Guides [MH-11038] - Make ListProviderScanner Scanner Less verbose [MH-11048] - admin ui tries to load missing library [MH-11051] - Fix WOH Documentation [MH-11060] - ActiveMQ settings filename fix (r/2.0.x) [MH-11068] - Table 'mh_bundleinfo' doesn't exist [MH-11110] - minor updates to ffmpeg video-editor and silence detection based on gregs review of the feature in 1.6.3 [MH-11176] - Cannot playback a recording via LTI in 2.x [MH-11177] - Fix Player OSGI Dependencies [MH-11181] - Flash streaming with multi-quality video does not work [MH-11202] - FFmpeg video editor operation is synchronized [MH-11221] - ComposerServiceImpl creates incorrect incidents and error messages [MH-11236] - Security ACL see security list [MH-11238] - Silence-detection does not read configuration value for ffmpeg binary path [MH-11256] - Opencast docs do not build anymore Opencast 2.0.1 Released on September 3, 2015 [MH-10822] - Possible to create new access policy template without a role with read/write permissions [MH-10938] - Missing views counter in player [MH-10941] - Usertracking Service Missing Endpoint [MH-10955] - Make sure recent versions of mkdocs work [MH-10962] - Add missing licenses to NOTICES [MH-10968] - Add note about ffmpeg/libav on Ubuntu [MH-10975] - async loading of translations [MH-10995] - Gathering workflow statistics for JMX causes extreme performance issues Opencast 2.0.0 Released on July 17, 2015 [MH-9950] - \"Clean up\"/Split up nested functions in the core routine (core.js) [MH-9950] - Load CSS files in the core HTML file, not the JavaScript [MH-9950] - Scrolling is required to see the controls if they are configured to be below the video. [MH-9950] - Some Keys don't work [MH-9950] - Theodul Core Jasmine Tests Sometimes Failing [MH-10029] - FFmpeg based Videosegmenter [MH-10140] - Capture agent with no configuration is always shown as \"idle\" [MH-10202] - No ACL in new series when ingested a new mediapackage with a new series. [MH-10230] - Typos on the welcome page [MH-10332] - Remove Mediainfo Inspection Service [MH-10382] - Add a UI Element to Easily Unregister Capture Agents [MH-10419] - Improve user tracking tables [MH-10510] - Move Workflow Operation Handler into their own Packages [MH-10550] - Non-Interactive Foreground Mode For Matterhorn [MH-10572] - ShibbolethLoginHandler: 500 Error when login the first time [MH-10594] - Re-configure Start Scripts for Different Deployment Types [MH-10615] - Enable Optional Compiler Arguments [MH-10620] - Port Silence Detector from GStreamer to FFmpeg [MH-10622] - Wave Generation Improvement [MH-10623] - Set Sensible Default for Workspace Cleanup Period [MH-10624] - Fixes for FFmpeg Videosegmenter (Set Binary) [MH-10630] - Extending common functionality [MH-10631] - Scheduler service authorization handling [MH-10635] - Text extractor dead lock [MH-10640] - several problems with the metadata form to create a new event [MH-10656] - Login Screen: Placeholder and Focus [MH-10658] - Email template: diverse problems [MH-10664] - What is a template in Access Policy and how do I create it? [MH-10665] - 404 for variables.json [MH-10667] - Previous Button does not always work [MH-10681] - Time is missing when a workflow operation has been started and stopped [MH-10683] - Remove Capture Agent [MH-10683] - Remove the Capture Agent integration tests [MH-10684] - Admin UI seems only unresponsive if server is down [MH-10689] - I should get a warning, if I leave the Admin UI while I still create an event (upload a file) [MH-10698] - workflow after videoeditor does not produce any */delivery flavors [MH-10700] - Service Registry throws NPE exception on startup [MH-10704] - Workflows fail if adding themes [MH-10705] - Row counter in Jobs table is 1 too much [MH-10707] - Unit Test Failure [MH-10710] - NullPointerException in VideoSegmentationWOH [MH-10711] - OptimisticLockException after ingest [MH-10712] - Workflow cleanup out of memory error [MH-10713] - Cache util blocks forever [MH-10726] - Archive operation should use filesystem copy rather than http download [MH-10736] - Engage is currently broken and won't play videos but Theodule does [MH-10740] - NPE in ToolsEndpoint [MH-10746] - There is no event status column [MH-10758] - Issues found in production use of Theodul: changing icons, seeking in Chrome, using configured logos, wording, layout... [MH-10759] - Write QA documentation for Events [MH-10759] - Write QA documentation for Groups [MH-10759] - Write QA documentation for Servers [MH-10759] - Write QA documentation for Services [MH-10763] - Remove Old Confirations [MH-10765] - Operation details doesn't show operation attributes when state is instantiated [MH-10768] - Workflow operations table in the events details should refresh automatically [MH-10769] - Add (x) icon in the events and series tableview to allow deletion of single Events/Series [MH-10770] - Some captions of tabs are not yet translated [MH-10772] - Ensure that buttons order is consistent in the actions column [MH-10773] - Allow to have free-text value for presenters, contributors, organizers or publishers [MH-10774] - ACL editing should be locked on the Series level when events of the series are being processed [MH-10775] - All the roles with read/write rights can be deleted from the ACL editor in Events/Series details [MH-10776] - Include Spanish and French translation into Theodul. [MH-10780] - Specify Requirements [MH-10781] - Respect tags while filtering for suitable tracks in Theodul player [MH-10792] - Pom.xml Extra Modules [MH-10798] - Event Details tile shows hash identifier [MH-10799] - Videoeditor operation does not properly handle missing preview formats [MH-10804] - It is unclear in which timezone you schedule in the admin-ui [MH-10807] - New event POST request contains every series and user [MH-10808] - Disable Demo Users [MH-10810] - Rename upgrade script form 1.6 to 2.0 [MH-10812] - Use bundles.configuration.location in admin ng settings.yml [MH-10814] - Pressing play while buffering breaks player [MH-10816] - Move Message Broker Configuration to Global Config [MH-10821] - Severe Issue with Scheduled Events [MH-10829] - Unchecking \"Remember me\" checkbox has no effect when logged out. Pressing the browsers back button you're still logged in an d can use all functions. [MH-10836] - Issues with matterhorn-engage-theodul-plugin-archetype [MH-10837] - Bulk deletion of events doesn't work correctly [MH-10843] - different video qualities are not filtered correctly. [MH-10845] - Summary of \"Add Events\" and \"Add Series\" shows irrelevant data [MH-10847] - Missing with-role directive in \"Start Task\" option in Actions dropdown [MH-10848] - Event conflict endpoint returns Server error 500 [MH-10849] - Temporary videoeditor files get not deleted [MH-10850] - Interface MatterhornConstans has a typo [MH-10853] - Improve admin UI ng workflows [MH-10855] - Task Menu displays wrong UI [MH-10864] - Remove Trailing Spaces From Less Files [MH-10866] - Documentation: Incorrect Repository Links [MH-10868] - Linebreak before last segment in player [MH-10873] - capture-admin-service-impl tests randomly failing [MH-10876] - Admin UI NG makes calls to remote resources [MH-10880] - Remote base keeps try to call a service [MH-10881] - Wrong links to r/2.0.x on documentation page [MH-10884] - WokflowOperation getTimeInQueue should return 0 if value is NULL [MH-10888] - Theodul player: audio-only does not work - player checked for unavailable size. [MH-10901] - Execute Service is not in main pom.xml and will not be built [MH-10902] - ./modules/matterhorn-publication-service-youtube/ obsolete [MH-10905] - FFmpeg videoeditor only works with audio and video available [MH-10911] - Remove executable flag from non-executables [MH-10912] - Init scripts contain undefined references to DEBUG_PORT and DEBUG_SUSPEND [MH-10913] - Add Event: License Metadata Field Text [MH-10924] - Update to new Opencast logos [MH-10926] - Extensive PhantomJS warnings when building admin-ng [MH-10928] - Adjust loglevel in DictionaryService [MH-10929] - Cutting and Review are skipped when config is set to do so [MH-10930] - Fix missing German translation [MH-10934] - Once set, one cannot remove some metadata in the create event dialog [MH-10938] - Missing views counter in player [MH-10939] - Task Summary does not display configuration values [MH-10946] - Fix Opencast 2 Installation Guides [MH-10950] - Fix DDL Readme [MH-10952] - Fix matterhorn-execute-operations naming [MH-10957] - Add License Guide for Developers","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#opencast-8","text":"","title":"Opencast 8"},{"location":"changelog/#opencast-81","text":"Released on January 29, 2020 [ #1341 ] - Spring Framework Dependency Specification [ #1340 ] - LDAP User Directory Dependencies [ #1339 ] - Add Missing Karaf Features [ #1338 ] - Sakai User Directory Dependencies [ #1328 ] - AngularJS Components 1.7.9 [ #1326 ] - Fix Image Extraction From Short Videos [ #1321 ] - Fix URL Parameters in Theodul Player [ #1300 ] - Allow Root In Bower [ #1299 ] - Fix AWS WOH OSGI dependencies [ #1266 ] - Allow capture agent users to read properties of series","title":"Opencast 8.1"},{"location":"changelog/#fixed-security-issues","text":"CVE-2020-5231 \u2013 Users with ROLE_COURSE_ADMIN can create new users CVE-2020-5206 \u2013 Authentication Bypass For Endpoints With Anonymous Access CVE-2020-5222 \u2013 Hard-Coded Key Used For Remember-me Token CVE-2020-5230 \u2013 Unsafe Identifiers CVE-2020-5229 \u2013 Replace MD5 with bcrypt for password hashing CVE-2020-5228 \u2013 Public Access Via OAI-PMH","title":"Fixed Security Issues"},{"location":"changelog/#opencast-80","text":"Released on December 17, 2019 [ #1292 ] - Release notes for Opencast 8.0 [ #1290 ] - Fix for MP3 with embedded image [ #1286 ] - Fix Role For Assets Quick Access [ #1278 ] - Editor Thumbnail Default [ #1274 ] - Update Security Configuration [ #1269 ] - Fix processing of odd video width [ #1256 ] - Remove publishedhours default statistics provider [ #1245 ] - AngularJS 1.7.9 Security Update [ #1216 ] - Simplify Editor URL Signing [ #1212 ] - Update paella player to 6.2.4 [ #1207 ] - Enable Browser Tests [ #1206 ] - Temporarily Ignore Failing Test [ #1203 ] - Warn about using H2 [ #1202 ] - Overhaul RPM Installation Guide [ #1199 ] - Fix Crowdin Upload [ #1197 ] - Fix Theodul Embed Configuration [ #1167 ] - Migrate IBM Watson transcription to shared persistence [ #1153 ] - Keep generated SMIL for partial tracks [ #1151 ] - (#1008): Better crop detect test #1085 [ #1146 ] - Remove unnecessary global package-lock.json [ #1141 ] - Consider file extension of uploaded asset [ #1134 ] - Do not use stack-overflow logo [ #1131 ] - Issue1123 TEMP FIX for Paella Player Build error [ #1110 ] - Build failed on captions-impl tests for non english OS [ #1108 ] - Fix external API versioning for EventsEndpoint [ #1103 ] - Fix PostreSQL Support [ #1102 ] - Clean-up Fast Testing Workflow [ #1101 ] - Filter jobs by transcription service provider ID [ #1073 ] - close esc function for new event and new series modals [ #1067 ] - Publication Button show fix [ #1100 ] - Player Scroll/Zoom Overlay [ #1098 ] - Fix displaying tracks with no tags in player [ #1095 ] - Add a new optional date_expected column to the transcription job table [ #1094 ] - Smarter etc/ hints in documentation [ #1093 ] - Provide access to file contents in the WFR [ #1091 ] - Remove inaccurate url-pattern ${element_uri} [ #1090 ] - Elasticsearch access_policy field increased in size [ #1086 ] - Fix CI Builds (Crop Tests) [ #1084 ] - Fix Player ID Parameter Parsing [ #1082 ] - Docs readme extended. [ #1079 ] - Remove Workflow Operations from Worker [ #1078 ] - Fix database docs [ #1075 ] - Remove State Mapping \u201cImporting\u201d [ #1074 ] - Navbar icons toggle [ #1071 ] - Fix Pull Request Template [ #1070 ] - Temporarily Ignore Service Registry Test [ #1066 ] - Major developer docs update [ #1065 ] - Remove the RoleProvider.getRoles() method [ #1063 ] - Only events with write access [ #1062 ] - start on used port [ #1059 ] - Hide Column Stop By Default [ #1058 ] - Custom LTI Series Tool Styles [ #1057 ] - Update ESLint [ #1055 ] - Move to GitHub Issues [ #1053 ] - Update mustache [ #1052 ] - Update bootbox [ #1050 ] - && MH-13425 - Feeds-Tab / adds a new tab in series properties. [ #1048 ] - Add an optional build step to clean easily clean the frontend caches [ #1047 ] - ServiceRegistry not updating database correctly when dispatching jobs [ #1044 ] - clean node, node_modules and bower_components folders [ #1042 ] - Update Admin Interface JS Test Libraries [ #1041 ] - Update ESLint [ #1039 ] - paella can filter which tracks to load depending on the user's device [ #1037 ] - Update paella player to 6.2.0 [ #1034 ] - Update Translation Key for Published Hours [ #1033 ] - Direct link to assets tab [ #1030 ] - Configure max open files [ #1029 ] - Update admin interface JS libraries [ #1028 ] - Update Engage JS Libraries [ #1027 ] - Update Markdownlint [ #1023 ] - fix invisible icon for specific zoom level [ #1022 ] - Automatic publication of streaming URLs [ #1021 ] - Moving mediapackages needs to handle missing version information [ #1020 ] - Logging [ #1016 ] - Update Deprecated EqualsUtil.hash(\u2026) [ #1015 ] - IDEA Settings [ #1014 ] - Don't start opencast on a used port [ #1009 ] - Shell information for developer distribution [ #1008 ] - Crop service [ #1007 ] - Update several JS libraries [ #1006 ] - Improve metadata handling in backend [ #1005 ] - Fix dropdown menus [ #1004 ] - eslint 6.1.0 [ #1003 ] - Update karma [ #1001 ] - Access org properties from publish-configure WOH [ #998 ] - Concat Operation Graphics [ #997 ] - Update Development Process Documentation [ #996 ] - Update commons-text [ #995 ] - Composer Should Not Overwrite Files [ #994 ] - Added name of the configuration file where properties of login details are modified [ #992 ] - switch to compatible file type filter definitions [ #990 ] - Upgrade chromedriver [ #985 ] - Update grunt-concurrent [ #983 ] - Update ESLint [ #978 ] - Mh 13617 Duplicate encoding profiles for PrepareAV/SelectStreams [ #973 ] - Don't consider raw fields updated [ #972 ] - Improve setting values from dublin core catalog [ #971 ] - NOJIRA: Add ALTER to necessary MySQL permissions [ #970 ] - Fix hello-world modules [ #968 ] - Resolution Based, Conditional Encoding [ #967 ] - Introduce general CatalogUIAdapter [ #966 ] - Update frontend-maven-plugin [ #965 ] - Update Logger [ #964 ] - Update Checkstyle [ #963 ] - Update Paella Build Dependencies [ #962 ] - Update Chromedriver [ #961 ] - Update autoprefixer to 9.6.0 [ #960 ] - Update Markdownlint [ #959 ] - Update Admin Interface Test Framework [ #957 ] - Clean-up Static Resource Servlet [ #956 ] - Re-introduce Prepare AV [ #954 ] - Fix bundle versions [ #952 ] - Cleanup workflows [ #951 ] - More Dependency Checks\u2026 [ #950 ] - Tag elements retrieved from asset manager [ #949 ] - Termination State Service to integrate with AWS AutoScaling Lifecycle [ #948 ] - add health-check endpoint [ #945 ] - -publication [ #943 ] - color \"blue\" for links in the admin ui [ #942 ] - Theodul player ui config [ #941 ] - More dependency fixes [ #937 ] - Workflow Condition Parser Location [ #936 ] - Drop distribution-service-streaming [ #935 ] - Drop Distribution \u201cadminworker\u201d [ #934 ] - Drop Migration Distribution [ #931 ] - Assembly Configuration [ #929 ] - Check dependencies at build time [ #928 ] - Admin Interface Browser Tests [ #927 ] - Metadata Transfer Operation [ #926 ] - Remove unused code [ #925 ] - Media Module Dependency Management [ #924 ] - Jettison Dependency Management [ #923 ] - Introduce ESLint to Media Module [ #922 ] - Support for exclusion pattern for URL signing [ #921 ] - Officially support URL signing keys that handle multiple URL prefixes [ #920 ] - Streaming Module Cleanup [ #919 ] - Fix dependencies for statistics- and workflow-condition-parser [ #918 ] - Remove module 'dataloader' [ #917 ] - Remove obviously unused classes [ #908 ] - Admin interface dependency update [ #906 ] - Media Module Configuration [ #899 ] - Fix Login Page [ #898 ] - Fix Spelling of Flavor [ #895 ] - Update Tesseract Code [ #894 ] - NOJIRA Speed up statistics api tests [ #893 ] - Dependency Fixes [ #892 ] - Drop Custom Logger Configuration [ #891 ] - Unnecessary LineReader [ #890 ] - NOJIRA: Remove statistics provider configs [ #889 ] - Limit accepted file types when uploading assets [ #887 ] - Collect and visualize published hours of video [ #885 ] - Rework workflow conditions, add string data type [ #883 ] - Remove inclusion of non-existent scripts in Admin UI [ #882 ] - Navigation of statistics broken [ #881 ] - JavaScript Dependency Management [ #880 ] - Improve icons and wording in video editor [ #879 ] - statistics csv export [ #876 ] - Add Hourly Data Resolution For Statistics [ #874 ] - Role support for workflows [ #872 ] - Remove pseudo-mechanism for workflow definition registration [ #869 ] - Remove unused method WorkflowDefinition.isPublished [ #865 ] - Empty node name causes exception [ #864 ] - Multitenancy support for workflows [ #863 ] - Improve URL signing performance [ #862 ] - add single step event deletion [ #861 ] - Add option to configure state mappings for workflows [ #860 ] - Remove unused fields from search index [ #858 ] - Improve navigation in video editor when zoom is active [ #857 ] - resume on past table page when leaving video editor [ #854 ] - move ingest-download Operation to worker [ #851 ] - Highlight main table rows on hover [ #850 ] - Add node name to host registration as a UI searchable alternative to hostname [ #849 ] - Upgrade Admin Interface Libraries (Including AngularJS) [ #848 ] - Remove method canLogin from interface User [ #847 ] - Fix License and Documentation Links [ #846 ] - Automatically Launch Logs for dist-develop [ #842 ] - Harmonizing the column names [ #841 ] - Expand log messages to add error detail [ #834 ] - Introduce basic statistics visualization capabilities [ #831 ] - userprovider for the d2l brightspace LMS [ #826 ] - url query string incorrect [ #825 ] - Remove leftover service [ #824 ] - Use Username In Workflows [ #823 ] - Automatic caption using Google speech to text api [ #816 ] - Change the default composer job load from 0.8 to 1.5 [ #784 ] - Admin UI new event media upload progress bar [ #757 ] - Timelinepreviews process first one only","title":"Opencast 8.0"},{"location":"changelog/#opencast-7","text":"","title":"Opencast 7"},{"location":"changelog/#opencast-76","text":"Released on January 29, 2020 CVE-2020-5231 - Users with ROLE_COURSE_ADMIN can create new users CVE-2020-5206 - Authentication Bypass For Endpoints With Anonymous Access CVE-2020-5222 - Hard-Coded Key Used For Remember-me Token CVE-2020-5230 - Unsafe Identifiers CVE-2020-5228 - Public Access Via OAI-PMH [ #1358 ] - Switch To HTTPS Maven Repository [ #1353 ] - Handle empty fields from REST docs in EventHttpServletRequest [ #1352 ] - Remove unsafe option in ffmpeg command for SMIL processing [ #1343 ] - ] Fixes Admin-UI Presenter's column [ #1333 ] - Switch to mvn.opencast.org [ #1329 ] - Remove Spring Request Logger Configuration [ #1325 ] - Secure FPS For Smil Processing [ #1318 ] - Remove Custom Plugin Repositories [ #1315 ] - Bump spring-security-oauth from 2.3.6.RELEASE to 2.3.7.RELEASE [ #1276 ] - Don't add the internal publication of the original event twice [ #1271 ] - Wrong encoding in video editor zoom box [ #1270 ] - S3 Distribution Fails [ #1265 ] - Some error operations referencing the wrong error-handler. [ #1246 ] - Remove default storage_id setting from asset Manager","title":"Opencast 7.6"},{"location":"changelog/#opencast-75","text":"Released on December 10, 2019 [ #1233 ] - Change bibliographicdate if technicaldate is changed. [ #1220 ] - Make Thumbnail Optional [ #1218 ] - [Documentation] Added path hint to upgrade.md [ #1170 ] - MH-9753: Prepare AV WOH can throw a NPE [ #1164 ] - CentOS basic installation guide rewording [ #1148 ] - VideoEditorServiceImpl: Fixed the file extension duplication with removeExtention from FilenameUtils. [ #1122 ] - fixes #1069 workflow tab shows scheduling info instead of workflows","title":"Opencast 7.5"},{"location":"changelog/#opencast-74","text":"Released on October 02, 2019 [ MH-13517 ][ #1092 ] - Set an absolute limit on solr query size [ MH-13476 ][ #1088 ] - Filter capture agent roles for ACLs [ #1087 ] - Issue 1068, Stop job dispatcher before unregistering hosts, junit MH-13675 [ MH-13706 ][ #1072 ] - fix the date cell of the events overview table in the admin UI [ #1056 ] - NOISSUE: CAS security example is very out of date","title":"Opencast 7.4"},{"location":"changelog/#opencast-73","text":"Released on September 19, 2019 [ MH-13716 ][ #1061 ] - Update xmlsec [ MH-13715 ][ #1060 ] - Check Markdown for newline character [ #1056 ] - CAS security example is very out of date [ MH-13707 ][ #1051 ] - Watermark missing [ MH-13706 ][ #1049 ] - Show bibliographic event dates on the events overview page [ MH-13701 ][ #1040 ] - Interpret source-audio-name correctly for composite operation [ MH-13699 ][ #1038 ] - Fix Workflow Index Rebuild ACL Handling [ MH-13697 ][ #1036 ] - Workflow Index Rebuild Memory [ MH-13684 ][ #1024 ] - Do not include auth token in republished URLs [ MH-12533 ][ #714 ] - Re-introduce ability to avoid data loss during ingest","title":"Opencast 7.3"},{"location":"changelog/#opencast-72","text":"Released on August 02, 2019 [ MH-13662 ][ #1000 ] - Update LTI Information","title":"Opencast 7.2"},{"location":"changelog/#opencast-71","text":"Released on July 09, 2019 [ MH-13656 ][ #993 ] - Fix Scheduler Index Rebuild [ MH-13655 ][ #991 ] - Scheduler Message Logging [ MH-13653 ][ #989 ] - Fully Migrate Scheduled Events [ MH-13652 ][ #988 ] - Don't save unchanged values in dropdown menus [ MH-13651 ][ #987 ] - Don't call submit of SingleSelect twice [ MH-13650 ][ #986 ] - Scheduler Migration Performance [ MH-13646 ][ #982 ] - Delete scheduled events [ MH-13645 ][ #981 ] - Only send delete comments message if we delete something [ MH-13642 ][ #977 ] - Fix Index Update Logging [ MH-13639 ][ #976 ] - Admin interface does not handle missing metadata well [ MH-13638 ][ #975 ] - Update NPM [ MH-13619 ][ #958 ] - Fix Logging in Video Segmenter [ MH-13615 ][ #953 ] - Fix Italian Translation [ MH-13610 ][ #947 ] - LDAP User Directory Fixes","title":"Opencast 7.1"},{"location":"changelog/#opencast-70","text":"Released on June 13, 2019 [ MH-13615 ][ #953 ] - Fix Italian Translation [ MH-13602 ][ #940 ] - Update jackson-databind to fix CVE-2019-12086 [ MH-13599 ][ #938 ] - Select well supported mime type by default [ MH-13593 ][ #933 ] - Incorrect default waveform colors [ MH-13569 ][ #913 ] - Change of PlayerRedirection variable from {{id}} to #{id} [ MH-13568 ][ #911 ] - Catch exception from overlapping RRule and return bad request [ MH-13566 ][ #910 ] - Accept duration as either string or number in scheduling JSON [ MH-13385 ][ #909 ] - Add release note about URL signing configuration changes [ MH-13375 ][ #907 ] - Handle empty-range errors correctly [ MH-13563 ][ #905 ] - Duplicated Variables in Media Module [ MH-13562 ][ #904 ] - ReferenceError in Media Module [ MH-13561 ][ #903 ] - Access to UI Configuration [ MH-13558 ][ #900 ] - Paella Track Filter [ MH-13554 ][ #897 ] - Theodul Zoom [ MH-13553 ][ #896 ] - Fix Paella Track Selection [ MH-13538 ][ #878 ] - Update jQuery [ MH-13531 ][ #873 ] - upgrade spring-security and jasig cas library to fix issue\u2026 [ MH-13529 ][ #871 ] - Don't warn about expected behavior [ MH-13528 ][ #870 ] - Non-Interactive FFmpeg [ MH-13525 ][ #867 ] - Update Admin Interface Libraries [ MH-13519 ][ #855 ] - Migrate mappings to Elastic Search 5.x [ MH-13505 ][ #844 ] - Update Admin Interface JavaScript Libraries [ MH-13504 ][ #843 ] - JavaScript Library Update [ MH-12047 ][ #832 ] - MH-13380 MH-13490 MH-13489 Add missing indexes [ MH-13477 ][ #819 ] - Faster Asset Manager Property Access [ MH-13465 ][ #807 ] - Prevent NullPointerException [ MH-13389 ][ #815 ] - More informative job load logging [ MH-13472 ][ #813 ] - Permissions for /play/ missing [ MH-13471 ][ #812 ] - Shibboleth SSO plugin to add roles for users on OC according to their EDUPERSONAFFILIATION. eg: \"ROLE_AAI_USER_AFFILIATION_student\" for \"student\" [ MH-13469 ][ #811 ] - Drop LastHeardFrom On Scheduler Messages [ MH-13468 ][ #810 ] - Capture Agent Registration Exception [ MH-13466 ][ #809 ] - Prevent Capture Agents From Modifying Metadata [ MH-13467 ][ #808 ] - opencast-security-cas feature can not be started [ #806 ] - extend the ingest-download-woh [ MH-12643 ][ #804 ] - Allow workspace to read from asset manager [ MH-13462 ][ #802 ] - Prevent Being Started By Root [ MH-13461 ][ #801 ] - Dependency Fixes & Dependency Checks [ MH-13460 ][ #800 ] - Update JavaScript Dependencies [ MH-13459 ][ #799 ] - Make Paella Use UI Configuration Service [ MH-13458 ][ #798 ] - Live Scheduler Dependencies [ MH-13457 ][ #797 ] - Dependency Update [ MH-13456 ][ #796 ] - Move Log Workflow Operation To Admin [ MH-13455 ][ #795 ] - Opencast Plug-in Features [ MH-13454 ][ #794 ] - Drop Unused Configuration Option Maps [ MH-13453 ][ #793 ] - Add more log output to WOH select-streams [ MH-13452 ][ #792 ] - Show creators correctly in delete modals [ MH-13450 ][ #790 ] - Remove unused class org.opencastproject.adminui.api.SortType [ MH-13448 ][ #789 ] - Make translation of creators consistent [ MH-13446 ][ #788 ] - Removed unfinished feature \"ACL transitions\" [ MH-13445 ][ #787 ] - Update Checkstyle [ MH-13443 ][ #783 ] - Don't use deprecated $http.success and $http.error methods [ MH-13439 ][ #782 ] - Dynamic Player Redirect [ MH-13438 ][ #781 ] - Simplify Streaming Format Check [ #780 ] - ACL documentation pointed to wrong config file [ MH-13436 ][ #778 ] - Improve error message for out of bounds image extraction [ MH-13421 ][ #776 ] - Remove unused workflowservice exceptions [ MH-13434 ][ #775 ] - Opencast Common Clean-up [ MH-13381 ][ #771 ] - Use Organization Identifier In Roles [ MH-13432 ][ #770 ] - Remove unused modals \"Job Details\" and \"Server Details\" [ MH-13431 ][ #769 ] - Remove unfinished feature \"Bulk Messaging\" [ MH-13430 ][ #768 ] - Fix Opencast Offline Builds [ MH-13428 ][ #766 ] - Remove unused library angular-scenario from admin ui tests [ MH-13426 ][ #765 ] - Remove unused Protractor end-to-end tests [ MH-13427 ][ #764 ] - Remove unused test resources [ MH-13381 ][ #763 ] - Use Organization Identifier in Workflows [ MH-13424 ][ #762 ] - Elasticsearch 5.6.15 [ MH-13423 ][ #761 ] - Possible NPE if debugging is enabled [ MH-13422 ][ #760 ] - Switch to markdownlint-cli [ MH-13420 ][ #759 ] - ngRepeat does not allow duplicates [ MH-13417 ][ #758 ] - UI Configuration Service Tests [ MH-13414 ][ #756 ] - extended metadata multivalue fields are not handled properly [ MH-13413 ][ #755 ] - UI Configuration Service Improvements [ MH-13412 ][ #754 ] - Deprecate PathSupport.concat(\u2026) [ MH-13411 ][ #753 ] - Fix UI Config Service Dependencies [ MH-13410 ][ #752 ] - Fix Broken Build Number [ MH-13397 ][ #751 ] - Remove unfinished feature \"Participation Management\" [ MH-13396 ][ #750 ] - Remove unfinished feature \"Location Blacklisting\" [ MH-13400 ][ #745 ] - Admin Index Test Cleanup [ MH-13399 ][ #744 ] - Update Elasticsearch Configuration [ MH-13395 ][ #742 ] - Remove unfinished feature \"Dashboard\" [ MH-13394 ][ #741 ] - Remove unfinished feature \"User Blacklisting\" [ MH-13393 ][ #738 ] - Remove leftover index resources [ MH-13392 ][ #737 ] - Added allowConflict parameter to methods and implemented [ #736 ] - Revert #523: Special handling of asset manager event removal [ MH-13390 ][ #735 ] - Quick-Filter by Presenter [ MH-13221 ][ #732 ] - Improve behaviour of single-select metadata fields [ MH-13385 ][ #731 ] - Simplify the configuration of the URL signing components [ MH-13384 ][ #730 ] - Remove duplicate joda-time dependency declaration [ MH-13277 ][ #729 ] - fix concurrent Map updates in scheduler [ MH-13382 ][ #727 ] - Minor Waveform Service Fixes [ MH-13379 ][ #726 ] - Simplify Mime Type Handling [ MH-13368 ][ #724 ] - Added color property to waveform operation handler [ MH-13376 ][ #722 ] - Fix OSGI Bindings [ MH-13374 ][ #720 ] - Update Node.js [ MH-13373 ][ #719 ] - Upgrade Admin Interface Libraries [ MH-13372 ][ #718 ] - Clean up orphaned asset manager properties [ MH-13371 ][ #717 ] - Drop unused angular-md5 [ MH-13370 ][ #716 ] - Don't configure unnecessary default credentials [ MH-13294 ][ #713 ] - Workflow for track replacement and cleanup Snapshots [ MH-13367 ][ #711 ] - External API series acl returns null pointer with missing acl [ #710 ] - adds an WOH, which can add catalogs to the MediaPackage of an workflow instance [ MH-13365 ][ #709 ] - inbox ingest into series and inbox retry [ MH-13364 ][ #707 ] - Fix hidden OSGI wiring errors [ #704 ] - Fixed a typo in the analyze-tracks description [ MH-13362 ][ #703 ] - Harmonize Admin Interface Menu Tooltips [ MH-13361 ][ #702 ] - Fix Scheduler Item Serialization [ MH-13360 ][ #701 ] - MH-13316: Watson transcripts improvements [ MH-13358 ][ #698 ] - Update JavaScript Dependencies [ #691 ] - Documentation: Developer Console: How to shutdown [ MH-13275 ][ #689 ] - Allows the workflow to select the audio track for composite videos [ MH-13350 ][ #688 ] - Theodul core HTML validation [ #687 ] - Documentation: Publish Engage Workflow OH [ MH-13344 ][ #685 ] - Enable AssetManager to reply NOT_MODIFIED [ #682 ] - add docs.opencast.org anchors for somewhat deep linking [ MH-13345 ][ #681 ] - Switch to Gson for Languages Endpoint [ MH-13342 ][ #678 ] - Don't try to create events with empty metadata [ #677 ] - Documentation: Dictionary service [ MH-13341 ][ #676 ] - Deleting Capture Agents Should Not Modify Users [ MH-13340 ][ #675 ] - Handle Empty Passwords [ MH-13339 ][ #674 ] - Handle Bad User Update Requests [ MH-13336 ][ #671 ] - Upgrade c3p0 [ #670 ] - Documentation: Analyze Audio WOH: Unbreak table [ MH-13331 ][ #667 ] - Fix ActiveMQ Defaults [ MH-13328 ][ #666 ] - Remove save button at top of videoeditor [ MH-13147 ][ #664 ] - OptimisticLockException in ServiceRegistry dispatchJob [ MH-13324 ][ #662 ] - Simplify Data Loader [ MH-13323 ][ #661 ] - Add documentation for list providers [ MH-13322 ][ #660 ] - Avoid . in Elasticsearch Field Names [ MH-13321 ][ #659 ] - Fix Series Item Serialization [ MH-13320 ][ #658 ] - Asset Manager Performance [ MH-13319 ][ #657 ] - Update Paella Binding Dependencies [ MH-13318 ][ #656 ] - Update to Apache Karaf 4.2.2 [ MH-13313 ][ #653 ] - Properly Use ACL Merge-Mode Configuration [ MH-13307 ][ #648 ] - Update Release Manager Documentation [ MH-13306 ][ #647 ] - Clean up MetadataUtils [ MH-13244 ][ #642 ] - Add override support to external api [ MH-13221 ][ #641 ] - Add placeholder to multi-select fields [ MH-13290 ][ #632 ] - Asset Manager Query Performance [ MH-13289 ][ #631 ] - Introduce Metadatafield Copy Constructor [ MH-13288 ][ #630 ] - Don't create incomplete metadata fields [ MH-13287 ][ #629 ] - Fix incorrect text metadatafield types [ MH-13286 ][ #628 ] - Remove unused functionality from MetadataField [ MH-13285 ][ #627 ] - Display workflow description [ #626 ] - Provide location of org.ops4j.pax.web.cfg [ MH-13284 ][ #625 ] - Update Elasticsearch to 2.x [ MH-12091 ][ #622 ] - Per-Tenant Capture Agent Users [ MH-13281 ][ #621 ] - Added property keep-last-snapshot for asset-delete WOH [ MH-13278 ][ #617 ] - Drop Unused Exception [ MH-13238 ][ #615 ] - don't throw related services straight into ERROR state just because job succeeded on current service [ MH-13277 ][ #614 ] - improve scheduler performance [ MH-13276 ][ #613 ] - Drop org.opencastproject.fun [ MH-13271 ][ #610 ] - Remove Useless ACL Check [ MH-13270 ][ #609 ] - Fix Message Item Serialization [ MH-13267 ][ #607 ] - Update Deprecated Code In UIRolesRoleProvider [ #605 ] - NOJIRA: Fix misspelled digest [ MH-13157 ][ #600 ] - Add multi-tenant support for all list providers [ MH-13262 ][ #596 ] - Changed for partial-error comment description to better description. [ MH-13261 ][ #595 ] - User Directory OSGI Service Definitions [ MH-13260 ][ #594 ] - Simplify Runtime Info UI [ MH-13259 ][ #593 ] - User/Role Directory Cleanup [ MH-13255 ][ #590 ] - Updated Deprecated Methods in Workspace Tests [ MH-13254 ][ #589 ] - Automate Dependency Checking [ MH-13253 ][ #588 ] - External Elasticsearch [ MH-13251 ][ #586 ] - Remove duplicate dependency [ MH-13247 ][ #582 ] - Deprecated Methods In Elasticsearch [ MH-12816 ][ #579 ] - Make waveform size configurable in WOH [ MH-13242 ][ #578 ] - Set disable_search_threshold for chosen globally [ MH-13241 ][ #577 ] - Filter Fileinstall Artifacts [ MH-13129 ][ #575 ] - More configuration options for thumbnails [ MH-13239 ][ #574 ] - Docs: Fix 'Edit on GitHub' link [ #573 ] - Documentation: Inbox [ MH-13234 ][ #565 ] - Workspace Deprecation Fixes [ MH-13231 ][ #564 ] - Allow entering multiple metadata values at once [ MH-13233 ][ #563 ] - add note about the jdk version use for build [ MH-13229 ][ #561 ] - External Library Updates [ MH-13227 ][ #559 ] - Update to Apache Karaf 4.2 [ MH-13226 ][ #558 ] - Update Docuemnation Landing Page [ MH-13224 ][ #556 ] - Drop commons-beanutils [ MH-13217 ][ #551 ] - pom.xml housekeeping [ MH-13213 ][ #548 ] - Separate External API Index [ MH-13212 ][ #546 ] - Fix external-api dependencies [ MH-13210 ][ #545 ] - Fix Deprecated IOUtils Usage [ #542 ] - Developer Installation Guide [ MH-13208 ][ #540 ] - Create a short contributor guide [ MH-13200 ][ #535 ] - Remove unused file acl-modal.html [ MH-13127 ][ #534 ] - Make table headers non-interactive by default [ MH-13198 ][ #529 ] - Properly Display Multiple Presenters [ MH-13197 ][ #528 ] - Separate Admin Interface Index [ MH-13195 ][ #526 ] - Fix Admin Interface Dependencies [ MH-13193 ][ #524 ] - Improve performance of event deletion (2) [ MH-13193 ][ #523 ] - Improve performance of event deletion (1) [ MH-13084 ][ #519 ] - Create a generic user interface configuration service [ MH-13054 ][ #518 ] - Update angular-ui-sortable, adapting build pipeline [ #515 ] - NOJIRA: Documentation: wait_timeout should be bigger than max.idle.time [ MH-13187 ][ #514 ] - Improve Track Stream Handling [ MH-13186 ][ #513 ] - Episode and Series ACL Handling [ MH-13185 ][ #511 ] - Don't include test web server [ MH-13183 ][ #505 ] - Add link to series details, out of the eventstable-view [ MH-13178 ][ #502 ] - Clean-up Series Dialog Code [ MH-13177 ][ #501 ] - Further Simplify MediaPackageElementFlavor [ MH-13175 ][ #499 ] - Remove Apache Tika for Generating Mimetypes [ MH-13174 ][ #498 ] - Simplify class MediaPackageElementFlavor [ MH-13155 ][ #497 ] - Make weekday preselection optional [ MH-13168 ][ #491 ] - Testcases to test a captureagent with Opencast integration. [ MH-13160 ][ #488 ] - Send actually required data in workflow messages [ MH-13161 ][ #483 ] - Simplify log statements [ MH-13158 ][ #480 ] - Use default functional interface for SecurityUtil#runAs [ MH-13153 ][ #477 ] - Workflow Service Code Cleanup [ MH-13151 ][ #475 ] - Update to Apache Karaf 4.1.6 [ MH-13148 ][ #472 ] - Internationalization support for series LTI tools [ MH-13140 ][ #466 ] - Clean-up REST Documentation Code [ MH-13061 ][ #450 ] - Display responsible person for workflows [ MH-13121 ][ #447 ] - Fix usertracking plugin in paella player [ MH-13124 ][ #446 ] - Unify linting for JavaScript and HTML [ MH-13082 ][ #440 ] - Fix LTI security vulnerability and refactor LTI and OAuth classes [ MH-13098 ][ #430 ] - Add start-workflow WOH [ MH-13062 ][ #401 ] - Added credentials for the Ingest Service. [ MH-13000 ][ #398 ] - Group \u201cEdit scheduled\u201d events by weekday [ MH-12782 ][ #209 ] - As an unprivileged user, I only want to see series and events that I have write access to.","title":"Opencast 7.0"},{"location":"changelog/#opencast-6","text":"","title":"Opencast 6"},{"location":"changelog/#opencast-67","text":"Released on December 8, 2019 [ #1200 ] - Fix Crowdin Deployment [ #1143 ] - Upgrade jackson to 2.9.10 (6.x) [ #1142 ] - Update apache commons-compress to 1.19 [ #1132 ] - Fixed the \"hide\" button in the Documentation. [ #1080 ] - Documentation reworked [ #1035 ] - Pushing to Maven Central [ #1026 ] - Adding Ansible script documentation [ #1019 ] - SMIL tests fail when doctype url can't be resolved","title":"Opencast 6.7"},{"location":"changelog/#opencast-66","text":"Released on August 2, 2019 [ MH-13674 ][ #1013 ] - Fix Cutting [ MH-13673 ][ #1012 ] - Workflow options not visually aligned [ MH-13672 ][ #1011 ] - Editor Maximum Height [ MH-13671 ][ #1010 ] - OAI-PMH autorepublish fails due to invalid urls [ MH-13648 ][ #984 ] - Asset Manager Concurrecy Issue [ MH-13644 ][ #980 ] - Sometimes paella does not play audio [ MH-13643 ][ #979 ] - Update to Paella 6.1.4 [ MH-13637 ][ #974 ] - Asset manager endpoint fix [ MH-13633 ][ #969 ] - Update spring-security-oauth [ MH-13611 ][ #955 ] - Duplicate events fix","title":"Opencast 6.6"},{"location":"changelog/#opencast-65","text":"Released on June 14, 2019 [ MH-13607 ][ #946 ] - Show composite duration in video editor [ MH-13606 ][ #944 ] - Don't archive smil on publication [ MH-13601 ][ #939 ] - OAI-PMH database access syncronization [ MH-13575 ][ #916 ] - Update paella player to 6.1.3 [ MH-13573 ][ #914 ] - Add .factorypath to .gitignore [ MH-13560 ][ #902 ] - Admin Role in Moodle User Provider [ MH-13546 ][ #888 ] - textextraction performance improvement [ MH-13544 ][ #886 ] - Video editor shows incorrect notification [ MH-13536 ][ #877 ] - OAI-PMH Remote Broken [ MH-13533 ][ #875 ] - Document parameter \"sign\" of GET /api/events/{id}/publications/* [ MH-13526 ][ #868 ] - Show unequal tracks correctly in editor [ MH-13521 ][ #859 ] - Switch to openJDK 8 on Travis [ MH-13503 ][ #856 ] - Job Dispatch Fairness [ MH-13330 ][ #853 ] - The video editor does not always close after the user presses \"Publish\" [ MH-13511 ][ #852 ] - Adding events in parallel does not work correctly [ MH-13501 ][ #840 ] - Match against user pattern for loadUser() lookups [ MH-13495 ][ #839 ] - Ignore old requests instead of cancelling [ #837 ] - Fix adaptive streaming configuration guide [ MH-13492 ][ #833 ] - Add language support for Italian [ MH-13486 ][ #829 ] - Cleanup NOTICES 6.x [ MH-13485 ][ #828 ] - Update paella player to 6.1.2 [ #827 ] - Change url query syntax to ? [ MH-13476 ][ #818 ] - Filter capture agent roles for ACLs","title":"Opencast 6.5"},{"location":"changelog/#opencast-64","text":"Released on April 01, 2019 [ MH-13449 ][ cc11441 ] - MH-13449, upgrade spring-security-oauth libs [ MH-13464 ][ #805 ] - Update paella player to 6.1.0 [ MH-13463 ][ #803 ] - WOH select-streams does not hide audio track as expected [ MH-13444 ][ #786 ] - Insecure Series Creation [ MH-13387 ][ #777 ] - Get ACLs of finished workflows from AssetManager Document encoding-profiles parameter in ComposeWorkflowHandler [ MH-13429 ][ #767 ] - Make sure series LTI tool respects provided series custom param","title":"Opencast 6.4"},{"location":"changelog/#opencast-63","text":"Released on March 05, 2019 [ MH-13402 ][ #749 ] - WOH select-tracks does not work with audio-only input [ MH-13404 ][ #748 ] - Improve Workspace Logging [ MH-13401 ][ #747 ] - Fix icon in Paella Player [ MH-13388 ][ #734 ] - Updating job load values for composer service on worker nodes \u2026 [ MH-13378 ][ #725 ] - Add mimetype audio/m4a [ MH-13377 ][ #723 ] - Fix scheduler rrule TimeZone issue [ MH-12631 ][ #721 ] - Drop the ORGANIZER field from the ical feed [ MH-13369 ][ #715 ] - Delete Capture Agents [ MH-12177 ][ #712 ] - TimeZone threadsafe and bulk schedule across DST (NEW) [ MH-13355 ][ #700 ] - Increase the default timeout for TrustedHttpClientImpl [ MH-13359 ][ #699 ] - Adding UTF-8 encoding for all remote services [ MH-13357 ][ #697 ] - Enable being able to disable 2 confusing Admin UI metadata: \"duration\" & \"created\" [ MH-13356 ][ #696 ] - Unnecessary Snapshots [ MH-13347 ][ #695 ] - Don't always look for orphaned properties [ MH-13354 ][ #694 ] - Asset Manager Property Performance [ MH-13352 ][ #693 ] - Unnecessary Format [ MH-13310 ][ #692 ] - Simplify AQueryBuilderImpl#always [ #686 ] - Document workaround steps for authentication with IBM Watson STT [ MH-13147 ][ #683 ] - 6.x): OptimisticLockException in ServiceRegistry dispatchJob [ MH-13343 ][ #679 ] - Load track into workspace with unique ID [ MH-13338 ][ #673 ] - Elasticsearch Upgrade Documentation [ MH-13337 ][ #672 ] - Admin UI workflow status translation keys added [ MH-13329 ][ #668 ] - Removing a capture agent resets the password of all Opencast users [ MH-13326 ][ #663 ] - No file/directory found when taking snapshot [ MH-13315 ][ #655 ] - Don't destroy Notifications service on destruction of the Notifications directive [ MH-13312 ][ #654 ] - Do not show outdated conflict information","title":"Opencast 6.3"},{"location":"changelog/#opencast-62","text":"Released on January 24, 2019 [ MH-13309 ][ #649 ] - return empty list when finding findUsersByUserName when the name param is empty.","title":"Opencast 6.2"},{"location":"changelog/#opencast-61","text":"Released on January 12, 2019 [ MH-13305 ][ #646 ] - MacOS installation update [ MH-13304 ][ #645 ] - Multi-value consistent with multi-select [ MH-13302 ][ #644 ] - Don't save unnecessarily in Multi-Select [ MH-13301 ][ #643 ] - Don't require event.publisher since it is a readonly field [ MH-13300 ][ #640 ] - Display multi-value fields correctly on summary pages [ MH-13299 ][ #639 ] - Make multi-select fields consistent again [ MH-13295 ][ #635 ] - Handle null for presentable value extraction [ MH-13283 ][ #624 ] - Fix Custom CXF Error Handler [ MH-13248 ][ #623 ] - Allow hidden workflow parameters","title":"Opencast 6.1"},{"location":"changelog/#opencast-60","text":"Released on December 10, 2018 [ #620 ] - Remove dropped translations [ MH-13230 ][ #616 ] - remove the need for passing an Accept header with external api requests [ MH-13272 ][ #611 ] - fix missing roles [ MH-13266 ][ #606 ] - Start date cross link does not work correctly [ MH-13215 ][ #602 ] - WorkflowOperationTagUtil throws a null pointer [ MH-13245 ][ #601 ] - Paella player does not show a single presentation video [ MH-13252 ][ #587 ] - Ineffective Synchronization of Elasticsearch Startup [ MH-13221 ][ #585 ] - Improve multi-select metadata fields [ MH-13250 ][ #584 ] - Thumbnail feature does not work for unprivileged users [ MH-13249 ][ #583 ] - Invalid Group Endpoint Registration [ MH-13237 ][ #576 ] - Track previews do not work with stream security [ MH-13214 ][ #570 ] - Fix HTTP Digest Authentication [ MH-13232 ][ #562 ] - Fix potentially negative fade-out start [ MH-13228 ][ #560 ] - Homogeneous Width of Shortcut Icons [ MH-13225 ][ #557 ] - Fix for exception in live scheduler service when rebuilding the admin ui index [ MH-13222 ][ #554 ] - Some fixes to tiered storage asset manager [ MH-13209 ][ #544 ] - Put CAS Feature In Distributions [ MH-13150 ][ #541 ] - Add note about CAAM to release notes [ MH-13201 ][ #538 ] - Convert uploaded images to appropriate size and format [ MH-13206 ][ #537 ] - Use correct mouse cursor in filters [ MH-13205 ][ #536 ] - Document, fix and improve thumbnail support [ MH-13196 ][ #527 ] - Unregister Resource Servlets of Bundles to be Removed [ MH-13192 ][ #522 ] - Improve performance of list requests [ MH-13191 ][ #521 ] - Improve performance of retrieving groups [ MH-13188 ][ #516 ] - Update paella player 6.0.3 [ MH-13154 ][ #512 ] - Unify vertical spacing in wizards [ MH-13184 ][ #508 ] - Update request-digest [ #507 ] - Remove documentation about unused workflow pause role [ MH-13162 ][ #506 ] - Show all series in edit-scheduled-events [ MH-13179 ][ #503 ] - Fix Video Editor Preview Mode Default [ MH-13176 ][ #500 ] - Bug fix update of Jackson [ MH-13170 ][ #496 ] - Fix workflow not selected in event details [ MH-13171 ][ #495 ] - Fix workflow configuration settings being displayed incorrectly [ MH-13173 ][ #494 ] - Do not hardcode value of ACL override [ MH-13169 ][ #492 ] - Update bibliographic metadata when technical metadata changes [ MH-13166 ][ #489 ] - OAI-PMH Message Handler Performance [ MH-13164 ][ #487 ] - Load catalog for snapshot message effeciently [ MH-13130 ][ #486 ] - java.lang.ClassCastException in AdminUserAndGroupLoader when starting up [ MH-13163 ][ #484 ] - Fix empty REST documentation notes [ MH-13159 ][ #481 ] - Fix mattermost notification operation issues [ MH-13111 ][ #479 ] - Fix display of metadata in series creation summary [ MH-13110 ][ #478 ] - Fix display of metadata in event creation summary [ MH-13150 ][ #474 ] - Opencast 6.0 release notes [ MH-13149 ][ #473 ] - Timed tiered storage test fails on fast systems [ MH-13051 ][ #471 ] - Fix dropdown placeholders [ #470 ] - Fix rest docs of GroupsEndpoint [ MH-13141 ][ #469 ] - Correctly initialize stats service [ MH-13142 ][ #468 ] - Error parsing non-existent schedule [ MH-13135 ][ #467 ] - Pending requests are not cancelled as expected [ MH-13139 ][ #465 ] - Documentation for the event publisher metadata [ MH-12819 ][ #464 ] - change extract-text encoding profile for better OCR results\u2026 [ MH-13137 ][ #462 ] - Less extensive statistics configuration [ MH-13136 ][ #461 ] - Add Danish Translation [ MH-13133 ][ #459 ] - TypeError: Cannot read property 'results' of null [ MH-13092 ][ #458 ] - Fix failing scheduling for non-english browsers [ MH-13132 ][ #457 ] - Fix REST Docs Overview Rendering [ MH-13131 ][ #456 ] - Fix Feed Service REST Docs [ #455 ] - Remove misleading - sign in tag woh docs [ MH-13125 ][ #451 ] - Remove unused configuration keys [ MH-13123 ][ #448 ] - Update paella player 6.0.2 [ MH-13117 ][ #445 ] - Mark NPM managed modules as private packages [ MH-13116 ][ #444 ] - Fix typo in paella error message [ MH-13115 ][ #443 ] - Update Node, NPM and Libs [ MH-13114 ][ #442 ] - Fix broken REST docs [ MH-13113 ][ #441 ] - Drop unused HTML page [ MH-13025 ][ #439 ] - Fix workflow-definitions URL [ MH-13109 ][ #438 ] - Update Paella Player to 6.0.x [ MH-13107 ][ #436 ] - Update admin interface build dependencies [ MH-13106 ][ #435 ] - Add Moodle groups to Moodle role provider [ MH-13105 ][ #434 ] - Fix minor mattermost notification operation issues [ MH-13104 ][ #433 ] - Add linter for LTI tools [ MH-13103 ][ #432 ] - Runtime UI NG JavaScript Dependencies [ MH-13102 ][ #431 ] - Add linter (checkstyle) for JavaScript to engage-paella-player module [ MH-13097 ][ #429 ] - Added a configuration parameter to be able to send HTML emails [ MH-13101 ][ #428 ] - Update paella dependencies [ MH-13100 ][ #427 ] - fix series view in Paella [ MH-13099 ][ #426 ] - Warn when default credentials are being used [ MH-13096 ][ #425 ] - Set workflow variables with duplicated media package IDs [ MH-13095 ][ #424 ] - Add linter (checkstyle) for JavaScript [ MH-13083 ][ #423 ] - Unify modal navigation [ MH-13094 ][ #422 ] - Use global NPM repository [ MH-13090 ][ #420 ] - Added support for blacklisting languages from the admin UI [ MH-12699 ][ #419 ] - Remove opencast-paella binding dependency on Admin server [ MH-13088 ][ #417 ] - Update Several Dependencies [ MH-13087 ][ #416 ] - Update Runtime UI Libraries [ MH-13086 ][ #415 ] - Update LTI Series Tool [ MH-13079 ][ #413 ] - Introduce REST Interface for AssetManager Properties [ MH-13060 ][ #412 ] - Add i18n support for workflow, operations, job and services status [ MH-13073 ][ #411 ] - Don't split series metadata fields by , [ MH-13074 ][ #410 ] - Clean up asset manager REST endpoints [ MH-13072 ][ #409 ] - Remove broken ltitool player [ MH-13071 ][ #408 ] - Update markdown linter [ MH-13070 ][ #407 ] - Update JS build and test libraries [ MH-13064 ][ #399 ] - Encoding profile mimetypes are mostly ignored [ MH-13058 ][ #395 ] - Remove unused font libraries [ MH-12688 ][ #392 ] - Add translations for comment filter values [ MH-13045 ][ #391 ] - Add missing i18n translations [ MH-13040 ][ #388 ] - Make options fit \u201cActions\u201d drop-down [ MH-12810 ][ #387 ] - External API 1.1.0 - Add filters for new fields [ MH-13037 ][ #386 ] - Remove unused External API roles [ MH-12690 ][ #384 ] - Add i18n support for capture agent statuses [ MH-12761 ][ #382 ] - Fixed event to listen to \"plugin.events.captionsFound\". [ MH-13028 ][ #381 ] - Clean up mockup [ MH-13022 ][ #378 ] - fixed LTI highly trusted keys being discarded [ #376 ] - Update and improve documentation for reviews [ MH-13027 ][ #374 ] - Update angular-translate to 2.18.1 [ MH-13026 ][ #373 ] - Update Mac OS X 'Install from source' documentation [ MH-13025 ][ #372 ] - Add workflow API to external API [ MH-13024 ][ #371 ] - Video editor does not display information when being opened while an event is being processed [ #369 ] - Documentation: message-broker: binding localhost [ #368 ] - Documentation: Update security.https.md [ MH-13016 ][ #362 ] - Workflow display order not working in editor screen [ MH-13013 ][ #359 ] - Unused code in scheduler [ MH-13008 ][ #358 ] - Prefill other input of startdate filter [ MH-13012 ][ #357 ] - The iterable metadata values should not be splitted by , [ MH-13010 ][ #356 ] - Series-Service-Remote incorrect character encoding [ MH-13009 ][ #355 ] - Update translations [ MH-13007 ][ #354 ] - Clarify Scheduler Calendar cutoff units in REST docs [ MH-12829 ][ #348 ] - Make admin-ui statistics configurable [ MH-12998 ][ #346 ] - Clear conflicts when closing \u201cEdit Scheduled Events\u201d modal [ MH-12996 ][ #345 ] - Add header row to conflict table in \u201cEdit scheduled\u201d [ MH-12995 ][ #344 ] - Fix conflict check not detecting some conflicts [ MH-12990 ][ #343 ] - User switching: Privilege escalation too restrictive [ MH-12993 ][ #342 ] - REST docs for Admin UI Event endpoint broken [ MH-12994 ][ #341 ] - Make \u201cTitle\u201d in \u201cEdit scheduled\u201d non-mandatory [ MH-12992 ][ #340 ] - Trigger conflict check in \u201cEdit scheduled\u201d on \u201cNext\u201d [ MH-12989 ][ #338 ] - Add missing roles for actions->edit scheduled [ #336 ] - Update version info [ MH-12987 ][ #335 ] - Prohibit changing a scheduled event to be in the past [ MH-12985 ][ #332 ] - Fix incorrect warnings in event modals [ MH-12803 ][ #329 ] - Fix for mp 'start' when event is created (affects live scheduler service) [ MH-12980 ][ #328 ] - Update documentation landign page [ MH-12930 ][ #327 ] - Fill creator metadata field with actual user when new event [ MH-12977 ][ #322 ] - Fix data placeholders in edit scheduled events [ MH-11918 ][ #321 ] - AWS S3 Asset Storage [ MH-12975 ][ #320 ] - Inconsistent access control handling [ MH-12738 ][ #319 ] - Tiered Storage for the Asset Manager [ MH-12969 ][ #317 ] - Eclipse IDE import Opencast XML style preferences [ MH-12972 ][ #316 ] - Drop unused getAclAttachments [ MH-12969 ][ #314 ] - Ensure formatting of OSGI configuration [ #313 ] - NOJIRA-live-schedule-fix-issue-in-documatation [ MH-12965 ][ #311 ] - Add more logging data to metadata parse WARN [ MH-12961 ][ #308 ] - Remove unused JavaScript library bootstrap from Admin UI [ MH-12960 ][ #307 ] - Remove unused JavaScript library backbone.js from Admin UI [ MH-12959 ][ #306 ] - Remove unused JavaScript library visualsearch.js [ MH-12956 ][ #305 ] - Incorrect permission check when requesting indexed workflows [ MH-12958 ][ #301 ] - image-convert WOH [ MH-12607 ][ #299 ] - Multiencode [ MH-12955 ][ #298 ] - ffmpeg expect floating timestamp values separated by '.' [ MH-12949 ][ #294 ] - Fix spacing between action items [ MH-12946 ][ #292 ] - add event summary input translation [ MH-12948 ][ #291 ] - Directly read XACML files [ MH-12905 ][ #289 ] - Opencast does not startup anymore [ MH-12911 ][ #266 ] - Hotkey cheat sheet [ MH-12813 ][ #265 ] - Add audio and video track selection to video editor [ MH-12607 ][ #264 ] - Process-Smil - edit and encode to multiple delivery formats [ MH-12918 ][ #261 ] - Use Karaf generated jre.properties [ MH-12904 ][ #252 ] - Paella player 5.3 update [ MH-12829 ][ #237 ] - Fix broken sub tabs of Event Details->Assets [ MH-12889 ][ #236 ] - Intuitive Merging of Video Segments [ MH-12828 ][ #233 ] - re-enable Scheduler service conflicts json REST endpoint [ MH-12885 ][ #232 ] - Capture Agent Access Management [ MH-12877 ][ #231 ] - Add new modal to edit multiple scheduled events at once [ MH-12871 ][ #220 ] - Ability to use user names in to/cc/bcc fields in send-email woh [ MH-12869 ][ #219 ] - Remove superfluous playback tool [ MH-12829 ][ #218 ] - Switch and rename event details tabs [ MH-12814 ][ #208 ] - Manually Select And Upload Thumbnails [ MH-12815 ][ #197 ] - delete series with events option [ MH-12826 ][ #193 ] - Make workflow processing settings persistent [ MH-12823 ][ #182 ] - Log Configuration and GELF Log4J with graylog [ #181 ] - adapt tracking default options to respect the EU GDPR [ MH-12822 ][ #179 ] - Remove old OCv2x security context fix artifacts [ MH-12607 ][ #172 ] - Harvard DCE), Demux Operation [ MH-12607 ][ #171 ] - Harvard DCE), Lossless Concat Operation [ MH-12804 ][ #170 ] - Introduce displayOrder for workflow definitions [ MH-12797 ][ #168 ] - Explain UI actions (added missing tooltips) [ MH-12820 ][ #167 ] - Mattermost-notification-workflowoperationhandler [ #165 ] - Be less quiet about errors on Travis [ MH-12797 ][ #164 ] - Explain UI Actions [ MH-12794 ][ #162 ] - turn off matomo notification [ MH-12793 ][ #161 ] - Collapse multiple, redundant composer process methods [ MH-12647 ][ #155 ] - MH-12756 extend external api [ MH-12786 ][ #154 ] - Undistinguishable Entries in Groups Editor User List [ MH-12784 ][ #153 ] - External API: Accept header not specified correctly [ MH-12091 ][ #150 ] - Implement per-tenant digest user for capture agents [ MH-12703 ][ #89 ] - Add userdirectory for Moodle [ MH-11621 ][ #56 ] - Option to marshal empty values in DublinCore XML catalog.","title":"Opencast 6.0"},{"location":"changelog/#opencast-5","text":"","title":"Opencast 5"},{"location":"changelog/#opencast-55","text":"Released on April 1, 2019 [ MH-12603 ][ #746 ] - Take 'ng' out of the youtube composite operation [ MH-13386 ][ #733 ] - Event status calculation wrong assumption fixed [ MH-13383 ][ #728 ] - don't smooth the waveform in the editor [ MH-13366 ][ #708 ] - Add REFERENCES permission to standard Opencast GRANT statement [ MH-13363 ][ #706 ] - Publish to OAI-PMH an allready published mediapackage \u2026 [ MH-13333 ][ #669 ] - Do not import properties in publish WF","title":"Opencast 5.5"},{"location":"changelog/#opencast-54","text":"Released on January 24, 2019 [ MH-13311 ][ #652 ] - WOH cover-image is broken SUREFIRE-1588: Resolving compilation issue on Debian and related distros [ MH-13244 ][ #581 ] - Improve concurrency of OAIPMH republication","title":"Opencast 5.4"},{"location":"changelog/#opencast-53","text":"Released on January 11, 2019 [ MH-13297 ][ #638 ] - FasterXML Jackson Bugfix Update [ MH-13296 ][ #637 ] - Disable buttons of start task wizard while the tasks are being submitted [ MH-12290 ][ #636 ] - prevent SAXParserFactory and SAXParser class load lag in series listprovider [ MH-13269 ][ #608 ] - Handle Authorization Errors [ MH-13263 ][ #598 ] - Invalid Ingest Encoding [ MH-13257 ][ #597 ] - Fix outdated command line argument for tesseract >= 4.0.0 [ MH-13258 ][ #592 ] - Broken User Provider Removal [ MH-13256 ][ #591 ] - Waveform operation fails [ MH-13243 ][ #580 ] - Asset Manager ACL Cache Updates [ #572 ] - Documentation: Opencast 5.2 was released in Nov [ #571 ] - Documentation: Linkfixes in OC5.x upgrade guide [ MH-12332 ][ #567 ] - disable workflows whose tags don't explicitly match the source type, UPLOAD|SCHEDULE 5.x","title":"Opencast 5.3"},{"location":"changelog/#opencast-52","text":"Released on November 13, 2018 [ MH-13144 ][ #553 ] - only set Job startDate if no set before [ MH-13216 ][ #550 ] - Fix Documentation Pages [ MH-13211 ][ #547 ] - engage-ui: Fix live schedule bug: event available before schedule [ MH-13190 ][ #520 ] - Factor out JpaGroupRoleProvider JaxRs REST to mitigate load cycle race [ MH-13189 ][ #517 ] - Fix paella xss security isues in opencast 5.x [ MH-13167 ][ #490 ] - Republishing metadata does not update all metadata [ MH-13152 ][ #476 ] - Reduce Workflow Messages [ MH-13138 ][ #463 ] - Fix media module language configuration [ MH-13108 ][ #437 ] - Prevent permission problem in Travis cache [ MH-13091 ][ #421 ] - Concat operation problem with FFMPEG 4.x [ MH-13069 ][ #406 ] - Update problematic admin interface libraries [ MH-12976 ][ #389 ] - custom role patterns not working [ MH-12387 ][ #350 ] - Fix CAS","title":"Opencast 5.2"},{"location":"changelog/#opencast-51","text":"Released on September 3, 2018 [ MH-13067 ][ #404 ] - Configuration panel does not work for default workflow [ MH-13049 ][ #400 ] - Fix video editor zoom dropdown showing wrong value [ MH-13055 ][ #396 ] - Stop making events with no ACL public on ingest [ MH-13048 ][ #394 ] - Improve stability of the series index rebuild [ MH-13047 ][ #393 ] - Document using Nginx for HTTPS [ MH-13044 ][ #390 ] - Organization server configuration documentation [ MH-12016 ][ #379 ] - Scrolling role fetch [ MH-13031 ][ #377 ] - Active transaction notification on top [ MH-13029 ][ #375 ] - Don't show old notifications [ MH-13023 ][ #370 ] - Let default value fulfill requirement [ MH-13018 ][ #367 ] - re-add recordings json to 5x (includes MH-12828 re-add conflicts.json) [ MH-13020 ][ #366 ] - Read listproviders as UTF-8 [ MH-13017 ][ #363 ] - JS syntax error in publish workflow [ MH-13015 ][ #361 ] - 5.x database upgrade scripts [ MH-13014 ][ #360 ] - Don't show stale search results [ MH-13006 ][ #353 ] - Waveform operation cleanup creates problem with asynchronous NFS [ MH-13003 ][ #352 ] - Implement detection of already recorded (as opposed to yet to be recorded, scheduled) events by the index service [ MH-13005 ][ #351 ] - Skip waveform operation when no tracks [ MH-13001 ][ #347 ] - Fixed live scheduler service pom [ MH-12988 ][ #337 ] - delete-scheduled-live Fix for scheduled live event not deleted [ MH-12986 ][ #333 ] - Admin UI deployed debugging: include source in SourceMap files [ MH-12981 ][ #331 ] - fix for local admin-ui develop finding main.css [ MH-12979 ][ #325 ] - Automatically test ddl scripts [ MH-12978 ][ #324 ] - Fix data-placeholder in add event wizard [ MH-12974 ][ #318 ] - Access denial to event for unprivileged user [ MH-12970 ][ #315 ] - Senseless XACML parsing [ MH-12966 ][ #312 ] - Do not pre-select-from option in metadata property sheets [ MH-12963 ][ #310 ] - Localize dates/times in add-event summary [ MH-12950 ][ #309 ] - Fix for workflow with no acl in solr index NOJIRA: Skip install of Crowdin if it is already installed [ MH-12957 ][ #300 ] - Defaults on tab Source in Add Event wizards are broken [ MH-12954 ][ #297 ] - wrong date format in coverimage file","title":"Opencast 5.1"},{"location":"changelog/#opencast-50","text":"Released on June 12, 2018 [ MH-12952 ][ #295 ] - animate WOH dependency version fixed [ MH-12946 ][ #290 ] - Fix summary of add-event-dialog [ MH-12944 ][ #288 ] - Remove bashism from start script [ MH-12905 ][ #287 ] - TEMPORARY Karaf config assembly workaround (KARAF-5693) [ MH-12943 ][ #286 ] - Minor Paella config REST endpoint improvements [ MH-12942 ][ #285 ] - Paella player config REST endpoint should be accessible by anonymous user [ MH-12941 ][ #284 ] - Gracefully handle empty flavors [ MH-12940 ][ #283 ] - Ensure admin configuration is applied [ MH-12864 ][ #282 ] - Don't attempt to parse 'undefined' [ MH-12938 ][ #281 ] - Fix NullPointerException if no flavor is set [ MH-12937 ][ #280 ] - Correctly place admin UI test helper [ MH-12936 ][ #279 ] - Handle invalid flavors [ MH-12935 ][ #278 ] - Update Docker image repository documentation [ MH-12934 ][ #277 ] - Update translations [ MH-12933 ][ #276 ] - Link documentation from Systemd unit [ MH-12932 ][ #275 ] - Kernel Build Failure [ MH-12922 ][ #272 ] - Job load fixes [ MH-12929 ][ #271 ] - Change paella URL to /paella/ui [ MH-12928 ][ #270 ] - Mitigation for KARAF-5526 [ MH-12926 ][ #269 ] - Prevent cluttering of logs by invalid access [ MH-12924 ][ #268 ] - fix missing dropdown arrow [ MH-12919 ][ #262 ] - REST Docs Dependencies [ MH-12917 ][ #260 ] - Remove debug logging [ MH-12916 ][ #259 ] - Admin Interface Configuration Defaults [ MH-12914 ][ #258 ] - Remove deprecated IOUtils.closeQuietly [ MH-12913 ][ #257 ] - Fix Admin Interface Deprecation Warnings [ MH-12868 ][ #255 ] - Make frame-by-frame skipping function in the editor use the \"actual\" framerate [ MH-12908 ][ #251 ] - Fix escaping of spaces [ MH-12907 ][ #250 ] - Fix segmentation default job load [ MH-12906 ][ #249 ] - Composoer should ignore system specific output pathes like /dev/null [ MH-12902 ][ #248 ] - closing videoeditor should continue in events list [ MH-12901 ][ #247 ] - Fix YouTube publication job loads [ MH-12900 ][ #246 ] - Fix search service job loads [ MH-12899 ][ #245 ] - Fix streaming distribution job load defaults [ MH-12898 ][ #244 ] - Fix download distribution job load defaults [ MH-12897 ][ #243 ] - Improve visibility of selected segments in the videoeditor [ MH-12896 ][ #242 ] - Clarify default player configuration [ MH-12894 ][ #240 ] - Update markdownlint [ MH-12893 ][ #239 ] - Added ability to configure the job load for the aws s3 distribution service. [ MH-12892 ][ #238 ] - Added ability to configure the job load for the transcription service. [ MH-12888 ][ #235 ] - Missing FFmpeg on Travis CI [ MH-12887 ][ #234 ] - Only set job date completed and runtime once. [ MH-12883 ][ #230 ] - Maven build of admin-ui module without frontend profile [ MH-12882 ][ #229 ] - Fix org.w3c.dom.smil version [ MH-12881 ][ #228 ] - Remove deprecated method [ MH-12880 ][ #227 ] - Remove redundant OSGI declarations [ MH-12879 ][ #226 ] - Default location of paella configuration [ MH-12878 ][ #224 ] - Don't verify NPM cache to speed up build process [ MH-12874 ][ #223 ] - NotFoundException handling for OAI-PMH retract operation with non published event [ MH-12872 ][ #222 ] - event can not be deleted [ MH-12873 ][ #221 ] - Speed up test builds [ MH-12864 ][ #215 ] - Readonly mode of fields not working correctly in property sheets [ MH-12807 ][ #213 ] - Do not overwrite owner [ MH-12863 ][ #212 ] - Fix default owner in SMIL endpoint [ MH-12862 ][ #211 ] - Line break after required marker in REST docs [ MH-12834 ][ #207 ] - Central documentation for filtering, sorting and pagination [ MH-12833 ][ #204 ] - Consistently use External API as name [ MH-12852 ][ #203 ] - Required fields not indicated in the event details and series details modals [ MH-12843 ][ #200 ] - Fix \u201cAdd Event\u201d Tab Index Update main readme Fix tabs and trailing spaces in docs [ MH-12839 ][ #196 ] - fix all pom.xml [ MH-12837 ][ #194 ] - external series API ACL is required [ MH-12832 ][ #192 ] - Update to commons-collection4 [ MH-12836 ][ #191 ] - Fix event-comment dependencies not correctly specified [ MH-12831 ][ #190 ] - Fixing dependencies NOJIRA fix engage paella url security rules NOJIRA Localization developer guide updated [ MH-12780 ][ #184 ] - Fix sorting jobs by identifier in Systems->Jobs [ MH-12824 ][ #183 ] - Speed up mvn site T/clarify wording of user tracking in documentation [ MH-12818 ][ #177 ] - Improve Sox service tests NOJIRA Crowdin project configuration updated NOJIRA Crowdin documentation updated [ MH-12771 ][ #173 ] - Document fields of External API 1.0.0 [ MH-12795 ][ #163 ] - REST docs don't respect @Produces annotation on class level [ MH-12788 ][ #157 ] - UTF-8 encoding settings in OAI-PMH publication service remote [ MH-12616 ][ #152 ] - Admin UI Flexible Asset Upload override or fallback display text [ MH-12775 ][ #146 ] - Add JavaScript source map generation [ MH-12768 ][ #142 ] - Minor XACMLAuthorizationService fixes [ MH-12825 ][ #139 ] - Add markdownlint to Travis CI [ MH-12760 ][ #160 ] - Cross-link column date in events table to enable the start date filter [ MH-12789 ][ #158 ] - Remove tabs and trailing spaces in LTI tools [ MH-12509 ][ #151 ] - Enable HTTP basic auth in default config [ MH-12759 ][ #149 ] - More Control Over Workflows [ MH-12779 ][ #147 ] - Support X-Forwarded-Proto header [ MH-12649 ][ #138 ] - clone workflow operation handler [ MH-12764 ][ #137 ] - update license information for admin-ui [ MH-12763 ][ #136 ] - Minor Composer Fixes [ MH-12762 ][ #135 ] - Fix Spaces In Configuration Fallback For Synfig Install clean up woh documentation Make Travis check for tabs in pom.xml files Add Mkdocs To Travis Builds [ MH-12757 ][ #128 ] - Fix ClassCastException [ MH-12755 ][ #127 ] - Fix workflow-workflowoperation dependencies [ MH-12746 ][ #126 ] - Update Checkstyle [ MH-12746 ][ #125 ] - Update Apache HTTPComponents [ MH-12746 ][ #124 ] - Update Mina [ MH-12746 ][ #123 ] - Remove commons-logging [ MH-12746 ][ #122 ] - Update Jackson [ MH-12752 ][ #121 ] - Ignore VSCode project data [ MH-12751 ][ #120 ] - Add Travis Badge [ MH-12735 ][ #119 ] - Remove Undocumented Operations [ MH-12746 ][ #115 ] - Library Update [ MH-12742 ][ #113 ] - Update to Karaf 4.0.10 [ MH-12744 ][ #111 ] - Fix migration bundle dependencies [ MH-12739 ][ #109 ] - Transcription Service updated to support Paella [ MH-12737 ][ #108 ] - OAI-PMH publication service [ MH-12732 ][ #106 ] - Remove Unused Remote Service Registry [ MH-12731 ][ #105 ] - Improve Recreating Series Index [ MH-12730 ][ #104 ] - Workflow Index Rebuild Performance [ MH-12711 ][ #100 ] - improve xacml parser [ MH-12726 ][ #99 ] - Add description to theme [ MH-12704 ][ #98 ] - Captions support for paella [ MH-12718 ][ #97 ] - Animate Service [ MH-12713 ][ #95 ] - Series cannot be created [ MH-12705 ][ #87 ] - Fix scheduler hot-deployment [ MH-12701 ][ #84 ] - Paella: Localization files + crowdin config file [ MH-12692 ][ #83 ] - update maven bundle plugin for java8 [ MH-12663 ][ #81 ] - Don't search for non-existing WFR files [ MH-12694 ][ #80 ] - Save\" button in the editor now stays on the same page. [ MH-12693 ][ #77 ] - Notes on how to enable, upgrade to HTTPS [ MH-12675 ][ #76 ] - Send default startdate to backend also if it hasn't been changed. [ MH-12656 ][ #75 ] - Updates to Theodul Matomo (formerly Piwik) Plugin [ MH-12684 ][ #69 ] - Make License List Provider More Flexible [ MH-12683 ][ #68 ] - Improve Video Editor Tests [ MH-12681 ][ #66 ] - update media package series catalogs on event metadata update [ MH-12677 ][ #65 ] - Be less technical about displaying the version number [ MH-12674 ][ #63 ] - Remove unused hard-coded list providers [ MH-12665 ][ #62 ] - Sort table on startup [ MH-12649 ][ #59 ] - clone workflow operation handler [ MH-12668 ][ #58 ] - Update packages of admin ui build pipeline Use $timeout instead of $interval to resolve MH-12667 [ MH-12661 ][ #52 ] - Update angular-translate to 2.17.0 [ MH-12660 ][ #51 ] - Scheduling Events by Specifying End Time [ MH-12658 ][ #50 ] - Disable Jasmine for Theodul [ MH-12653 ][ #46 ] - Authorization service should use workspace#read() wherever possible [ MH-12600 ][ #45 ] - Move userdirectory stuff from bundle kernel to userdirectory [ MH-12648 ][ #42 ] - As a system administrator, I want to use different encoding \u2026 [ MH-12645 ][ #39 ] - Created an option to rebuild index for an specific service [ MH-12644 ][ #37 ] - External API index schema fixes [ MH-12538 ][ #36 ] - Remove obsolete ACL distribution service and WOH distribute-acl [ MH-12639 ][ #35 ] - update angular-chosen to 1.8.0 [ MH-11984 ][ #32 ] - Allow customization of the username-to-user-role mapping [ MH-12367 ][ #30 ] - Renaming all database tables [ MH-12633 ][ #29 ] - Fix version of maven-dependency-plugin [ MH-12544 ][ #26 ] - Play Deleted Segments in Video Editor [ MH-12575 ][ #25 ] - Upgrade to AngularJS 1.5.11 [ MH-12595 ][ #24 ] - Improve Publications Usability [ MH-12613 ][ #23 ] - New WorkflowOperationHandler 'create-event' [ MH-12628 ][ #20 ] - MH-12629, MH-12630, Minor database fixes [ MH-10560 ][ #19 ] - Live Scheduler Service [ MH-12615 ][ #17 ] - Improve the languages drop-down menu [ MH-12623 ][ #16 ] - Improve workflow dropdown menu [ MH-12621 ][ #15 ] - submit paella player [ MH-12624 ][ #11 ] - Fix link to Karaf remote debugging documentation Update debs.md [ MH-12472 ][ #8 ] - FFmpeg Composer Implementation [ MH-12502 ][ #7 ] - Do Not Leave Files In Workspace [ MH-12477 ][ #6 ] - Operation To Log Workflow State [ MH-12555 ][ #5 ] - Add support for Piwik Media Analytics [ MH-10016 ][ #4 ] - Default Workflow [ MH-12603 ][ #2 ] - Consistent Workflow IDs [ MH-12622 ][ #1 ] - Surefire Versions Should Not Diverge","title":"Opencast 5.0"},{"location":"changelog/#opencast-4","text":"","title":"Opencast 4"},{"location":"changelog/#opencast-45","text":"Released on Oktober 30, 2018 [NOJIRA] - Fix wrong example in publish-configure documentation [MH-13075] - make ACL entries unique prior to running ACL comparisons [MH-13068] - workflow delete instance stability improvement [MH-13055] - Stop making events with no ACL public on ingest [MH-13032] - Asset Upload fix for missing reset() [MH-12953] - stop loading editor.json twice [NOJIRA] - Update the release process docs","title":"Opencast 4.5"},{"location":"changelog/#opencast-44","text":"Released on May 31, 2018 [MH-12923] - ServiceRegistry does not close db connction [MH-12841] - Opencast is ignoring permissions [MH-12840] - LTI user provider may allow LMS admins to become Opencast admins","title":"Opencast 4.4"},{"location":"changelog/#opencast-43","text":"Released on March 28, 2018 [MH-12774] - Fix differences in provided security configurations [MH-12773] - Fix that non-admins cannot add new assets [MH-12772] - Fix acces to assets for non-admins [MH-12789] - Remove tabs and trailing spaces in LTI tools [MH-12790] - Make LTI respect player configuration","title":"Opencast 4.3"},{"location":"changelog/#opencast-42","text":"Released on March 14, 2018 [MH-12766] - Metadata view and edit roles where at some places set incorrectly [MH-12765] - Navigating through series in the series details modal causes failing attempts to save ACLs [MH-12758] - Changing the ACLs does not trigger AssetManagerDecorators [MH-12747] - Heartbeat is broken [MH-12745] - Fix heartbeat config logging [MH-12743] - OAIPMH-Republish-Operation tries to republish to ASW3 [MH-12728] - Add LAST-MODIFIED to ical event properties [MH-12727] - OptimisticLockException on worker node can cause jobs to be stuck in DISPATCHING state [MH-12725] - Series/Events ACL update causes scheduled recordings in the series/the events to disappear from CA calendar [MH-12717] - Series metadata update causes scheduled recordings in the series to disappear from CA calendar [MH-12711] - XACML Parser should be more robust [MH-12707] - Fix problem with non-strict mode in URL-Signing [MH-12706] - Old zombie workflows cannot be stopped, suspended etc. [MH-12668] - Update admin ui build pipeline [MH-12651] - Scheduling repeating events through Admin UI is very slow","title":"Opencast 4.2"},{"location":"changelog/#opencast-41","text":"Released on Februar 7, 2018 [MH-12695] - Improve Synchronization in WorkflowService [MH-12689] - Flickering filter: When loading the page, all filters briefly appear and disappear again [MH-12687] - Date filters not working [MH-12685] - Performance issue in filters [MH-12682] - TimelinePreview Concurrency Problem [MH-12676] - List provider service implementation is not thread-safe [MH-12673] - Content-Type is not set for JavaScript files [MH-12664] - Ensure series can be deleted [MH-12662] - Special characters in modal window titles are double-escaped [MH-12657] - Users of non-admin groups cannot create events [MH-12652] - Scheduler service needs to restrict queries to episodes owned by it [MH-12641] - Asset manager conflict checks are very slow [MH-12638] - Migration bundle needs to have a higher runlevel [MH-12637] - Remove event id from episode DC catalog during migration [MH-12632] - Make index rebuild robust [MH-12631] - Drop the ORGANIZER field from the ical feed [MH-12627] - Start Task copies files into workspace [MH-12620] - Document ActiveMQ memory requirements [MH-12610] - Navigating through events in the event details modal causes failing attempts to save ACLs [MH-12609] - As a user, I expect scheduling of events to be working [MH-12606] - Using \"Start Task\" with a workflow containing an embedded script in the configuration which somehow modifies the input parameters does not update those values properly [MH-12602] - External API gives 500 error for migrated series that do not have creator field [MH-12601] - Fast Workflow Does Not Attach Series Metadata [MH-12582] - Editor WOH should not encode videos unless it is strictly necessary (to save time and resources) [MH-12495] - Job dispatching with loads needs optimization [MH-12476] - Delay start of job dispatching on startup [MH-10016] - Cannot Change Default Workflow","title":"Opencast 4.1"},{"location":"changelog/#opencast-40","text":"Released on December 8, 2017 [MH-12597] - When reindexing, some events may incorrectly be displayed as \"Scheduled\" instead of \"Processed\" or \"Failed\" [MH-12596] - Video Editor Ignores Workspace [MH-12594] - Description field in metadata editor doesn't handle newlines properly [MH-12591] - AssetManager reindex produces \"No organization found!\" warnings [MH-12590] - Fix Workflow WOH Workspace Mock [MH-12589] - Fix Timelinepreview Dependencies [MH-12588] - Stream Security Leaks Secrets [MH-12587] - ActiveMQ config ships with 3rd party tool enabled by default [MH-12583] - Reduce frequency of index rebuild messages for comments and asset manager [MH-12579] - Simplify XACML Handling [MH-12578] - Color of Crosslinks Makes Tables Look Noisy [MH-12574] - Audio keeps playing when leaving the playback or editor page [MH-12573] - Unprivileged users cannot delete events [MH-12572] - Dependency Fixes [MH-12570] - Admin UI Regressions And Minor Bugs [MH-12569] - Don't fail hard if attempting to distribute a non-track media package element to streaming server [MH-12568] - EditableSingleValue Has Focus Issues [MH-12567] - Index Service Dependencies [MH-12566] - Remove Unused Participation List Provider [MH-12560] - Streaming media distribution does not work in a distributed cluster [MH-12559] - CSS: Delete And Retract Dialogs For Events Are Messed up [MH-12558] - CSS: Buttons in Confirm Modals Too Big [MH-12557] - CSS: Checkbox Alignment in Tables [MH-12556] - Video Editor CSS Enhancements [MH-12554] - Downloading translations from Crowdin doesn't work anymore [MH-12553] - As an administrator, I want to configure the order in which the different adaptive streaming video qualities are listed [MH-12552] - The \"delete\" button in the Admin UI may leave the \"preview\" artifacts undeleted [MH-12551] - Redo changes of MH-11660 that got lost in means of a regression [MH-12550] - hasActiveTransaction is triggered permantly for edited jobs [MH-12548] - Matterhorn Kernel Test Issues [MH-12547] - Group related settings in custom.properties [MH-12546] - 3.x to 4.0 upgrade is ugly [MH-12545] - Multi Value Editable Loses Value on Blur [MH-12543] - Adjust Log Level During Build Time [MH-12542] - Fix Ingest Service API Dependencies [MH-12541] - Events not searchable after migration if event was subject to a workflow with two publish-engage operations [MH-12540] - Add documentation for WOH failing [MH-12539] - Add documentation for WOH include [MH-12537] - Admin UI Asset upload: Order Assets as listed in properties file (vs alphabetical) [MH-12535] - Add language support for Hebrew [MH-12534] - Broken Labels In Default Workflow [MH-12532] - The bundle workflow-workflowoperation creates (and leaves) temporary files in /tmp [MH-12529] - External API returns negative Event duration [MH-12526] - External (LDAP) users cannot not see their own role (ROLE_USER_XXXX) in the access policy of the events they create. [MH-12525] - Non-admin users cannot modify ACLs in their own events [MH-12523] - \"Submit\" button in retract modal is always disabled [MH-12522] - Improve Waveform Service Dependency Specification [MH-12520] - Duplicate Series When Double Clicking Create Button [MH-12519] - Improve Admin-NG Dependency Specification [MH-12518] - Ugly exception appears in stdout/Karaf console [MH-12517] - Some job data is not copied correctly [MH-12514] - Opencast Allows Multiple Simultaneous Workflows For Same Media Package [MH-12513] - MigrationService fails [MH-12512] - Frontend-Maven-Plugin configuration is missing the mandatory \"versionRange\" parameter [MH-12511] - Deleting an event with inconsistent search index state doesn't work [MH-12510] - System doesn't recover from ActiveMQ downtime [MH-12507] - Textanalyzer Has Nondeclared Dependencies [MH-12503] - Log statements do not require Object or String arrays to provide 3 parameters or more [MH-12500] - Fix incorrect usage of method \"URL#getFile()\" [MH-12499] - Admin UI event tools dialog can't be closed with the close button [MH-12498] - External API: Cannot get series if description field is empty [MH-12497] - Improve usability of admin UI forms [MH-12492] - AssetManager endpoint return server error on assets, which the user not allowed to read [MH-12489] - Failed test: MySQL DDL Scripts (Update) \ufffc [MH-12488] - Publish worklow always fail [MH-12480] - Waveform Operation Should Have Tests [MH-12479] - Waveform Operation Should Not leave Files In Workspace [MH-12475] - Make mimetypes consistent [MH-12470] - Prematurely deleted scheduler properties lead to undeletable events [MH-12469] - Auto Update OAIPMH republishes deleted Events [MH-12467] - Scheduled event fails due to not finding a workflow definition to use [MH-12465] - Propagate Changes of Series Extended Metadata to Events and OAI-PMH [MH-12463] - Hyphens in event/series search return no results [MH-12456] - Clean Up PathSupport [MH-12455] - FFmpeg does not terminate when Opencast is shut down [MH-12454] - PathSupport.changeFileExtension does not properly handle files with no extension [MH-12453] - TimelinePreview Path Handling [MH-12451] - Lock file utility method should throw exceptions [MH-12450] - Clean up *EncoderEngine code [MH-12449] - Ensure temporary files are deleted on composer failure [MH-12448] - Remove unconfigured send-mail WOH [MH-12447] - OAI-PMH autorepublish fails if series was deleted [MH-12446] - Do not leave ZIP files in workspace when a Workflow fails [MH-12445] - underlying code showing on metadata source tab when creating event [MH-12443] - editing event changes status from scheduled to finished [MH-12442] - Maven site is broken [MH-12436] - Add Christian Greweling to Comitters list [MH-12431] - Update Crowdin translations for r/4.x [MH-12428] - Performance Issue In Event Metadata [MH-12427] - Submit button in Editor typo [MH-12423] - Date Parse Error When Changing Certain Metadata [MH-12420] - Update frontend-maven-plugin [MH-12417] - Poor performace on scheduler /recordings/calendars [MH-12411] - Database user requires additional permissions [MH-12409] - Conductor logs ClassCastException when receiving DeleteSnapshot [MH-12407] - \"The task could not be created\" message by starting task on multiple events [MH-12406] - Splitting in the video editor while a video is playing causes time jump [MH-12401] - Video editor segment times stay blank (timing) [MH-12399] - Oaipmh Retract very slow [MH-12396] - Cannot select filter two times in a row from dropdown [MH-12395] - REST: Handle Scheduling Conflict [MH-12394] - Video editor allows the submission of an event with no active segments [MH-12390] - Gracefully handle unregistration of non-existing host [MH-12385] - Ingest Code Cleanup [MH-12382] - As a system administrator, I want to see the capture agent configuration in the user interface, so that I don't need to look into the database directly [MH-12380] - External API v1.0.0 Broken Due To StartDate Format Change [MH-12372] - Make waveform service more flexible by allowing pre- and post-filters to be configured [MH-12366] - authorization-manager depends on download-impl [MH-12365] - Losing ActiveMQ connection spams the logs [MH-12356] - As an administrator, I'd like to resolve or delete comments in workflows by comment reason only [MH-12355] - Include Wowza Adaptive Streaming Module in Opencast [MH-12354] - Admin UI Video Editor wont let you edit segements at the end [MH-12352] - Include support for user Groups in LDAP [MH-12350] - Recreate adminui-Index stops, if Asset of Event ist missing [MH-12349] - Exception handler should not throw an IO exception on deleting temporary directory [MH-12348] - As an administrator, I want to use the \"send-email\" WOH with multiple recipients and also use the CC and BCC fields [MH-12346] - Publications are not shown in the admin interface [MH-12330] - The series WOH only updates the series' title and ID on the episode's catalog, but sometimes more fields should be updated [MH-12328] - Update AngularJS from 1.3.x to 1.4.x [MH-12325] - Maven warning when building r/3.x [MH-12314] - As a developer, I expect the Admin UI tests being skipped if I build Opencast using -DskipTests [MH-12312] - Event Counter For \"Today\" [MH-12309] - Use Matching FontAwesome Icons [MH-12304] - Configurable Notification Durations [MH-12302] - Do Not Warn About Default Configuration [MH-12289] - Publish extended metadata to OAI-PMH [MH-12287] - prevent reload of Admin UI when opening the editor [MH-12286] - As an Opencast admin, I want to set workflow properties from an external script [MH-12284] - Unprivileged users cannot upload any files when creating or editing a theme [MH-12283] - Support MPEG DASH in Player [MH-12278] - NullPointerException in CleanupWorkflowOperationHandler [MH-12274] - Ingest service REST endpoint should be verbosable and expect input UTF-8 encoded [MH-12266] - As a user, I expect metadata changes to be propagated to third-party applications [MH-12259] - Ingest-download WOH fail on downloading publication elements [MH-12258] - Update angular-translate to version 2.15.2 [MH-12250] - Synchronize Dublin Core date created and start date in DC temporal [MH-12242] - Theodul: Quality selector does not display/load [MH-12234] - Cleanup WOH does not remove all files as it should do [MH-12227] - As a user, I don't want to be informed about services not being working correctly [MH-12223] - Oaipmh Publish is very slow [MH-12200] - Improve LDAP integration after the changes brought by MH-12016 [MH-12196] - Use a date and time picker instead of separate inputs for date and time in admin UI [MH-12191] - Add support for automated captions/transcripts (IBM Watson) [MH-12168] - As a user, I need cross-page links that help me to work more efficiently [MH-12166] - As a user, I'm not willing to perform that many clicks to actually use the filters [MH-12111] - Require Java 8 [MH-12104] - As a producer, I want to access assets of my tenant while a workflow is running [MH-12099] - Wrong started date/time on workflow details view [MH-12082] - Contribute Asset Manager/Scheduler work (ETH) [MH-12052] - As an Administrator, I'd like to know that ActiveMQ is running properly [MH-12000] - Cross-tenant URL signing [MH-11703] - Service error states not immediately visible in admin UI [MH-11458] - Update translations from crowdin [MH-11274] - Workflow Operations of Scheduled Event are not editable [MH-11195] - Ability to Search on part of a Series Identifier, instead of just exact match [MH-11042] - Admin UI NG tests fail in +5:30 timezone [MH-10156] - Misspelling in LtiLaunchAuthenticationHandler.java","title":"Opencast 4.0"},{"location":"changelog/#opencast-3x","text":"","title":"Opencast 3.x"},{"location":"changelog/#opencast-37","text":"Released on Oct 16, 2018 [ MH-12982 ] - 3.0 database upgrade error [ MH-13022 ] - Fix LTI highly trusted keys being discarded [ MH-13034 ] - Add lis_person_sourcedid back as LTI source field for the username [ MH-13082 ] - Fix LTI security vulnerability and refactor LTI and OAuth classes [ MH-13152 ] - Reduce Workflow Messages, backport of Lars fix for >=r/5.x [ MH-13156 ] - Set the auth scheme to digest for inter-server communication","title":"Opencast 3.7"},{"location":"changelog/#opencast-36","text":"Released on May 31, 2018 [MH-12910] - When switching between branches with different module naming schemes, the git tree is left unclean sometimes [MH-12860] - Opencast does not build at DEBUG logging level [MH-12841] - Opencast is ignoring permissions [MH-12840] - LTI user provider may allow LMS admins to become Opencast admins [MH-12830] - Fix mvn site generation [MH-12743] - OAIPMH-Republish-Operation tries to republish to ASW3 [MH-12441] - Fix multi-server configuration docs and config details [MH-12091] - Create a Capture Agent digest user with its own role","title":"Opencast 3.6"},{"location":"changelog/#opencast-35","text":"Released on February 6, 2018 [MH-12620] - Document ActiveMQ memory requirements [MH-12606] - Using \"Start Task\" with a workflow containing an embedded script in the configuration which somehow modifies the input parameters does not update those values properly [MH-12582] - Editor WOH should not encode videos unless it is strictly necessary (to save time and resources) [MH-12495] - Job dispatching with loads needs optimization [MH-12487] - Add job load settings to the default encoding profles [MH-12399] - Oaipmh Retract very slow","title":"Opencast 3.5"},{"location":"changelog/#opencast-34","text":"Released on December 4, 2017 [MH-12588] - Stream Security Leaks Secrets [MH-12587] - ActiveMQ config ships with 3rd party tool enabled by default [MH-12532] - The bundle workflow-workflowoperation creates (and leaves) temporary files in /tmp [MH-12516] - Oversize job acceptance logic is incorrect [MH-12505] - composer operations need to set job load from profile load when creating jobs [MH-12501] - Incorrect logging in inbox scanner [MH-12496] - Feeds point to removed embed player [MH-12494] - JMX bean unregistration causing stack traces in unit tests [MH-12478] - Waveform filenames are not unique [MH-12471] - Workspace Cleaner Minor Fix [MH-12464] - Job dispatching can be slowed down excessively by host loads query [MH-12439] - WorkspaceCleaner Should Clean All Files [MH-12437] - Admin UI ng fails mvn clean install if the node_modules exists [MH-12435] - Race condition when workspace file deletion removes collection [MH-12430] - Update Crowdin translations for r/3.x [MH-12422] - Adjust documentation to new Crowdin Opencast project [MH-12421] - Job dispatching halts because of http connection hang [MH-12415] - Improve performance of /api/events?withpublications=true [MH-12363] - org.json.simple.parser.JSONParser is not thread safe [MH-12000] - Cross-tenant URL signing [MH-11361] - date in engage is the creation date, not the recording date [MH-11042] - Admin UI NG tests fail in +5:30 timezone","title":"Opencast 3.4"},{"location":"changelog/#opencast-33","text":"Released on September 21, 2017 [MH-12383] - Upgrade/Unify Library Versions [MH-12413] - Don't present the user a previous/next item button if there is no previous/next item [MH-12405] - Catastrophic Oveload in Calendar generation [MH-12400] - Player: Embed Links disabled [MH-12393] - Retract workflow fails if run when a video is being played (with nfs storage) [MH-12389] - Set operation to failed when setting workflow to failed on exception path [MH-12386] - Update Postgresql Connector [MH-12384] - Catch possible NPE in FileSupport.delete() [MH-12366] - authorization-manager depends on download-impl [MH-12365] - Losing ActiveMQ connection spams the logs [MH-12364] - /broker/status endpoint returns incorrect 204 when ActiveMQ is shut down [MH-12362] - Less verbose logging for ExportWorkflowPropertiesWOH [MH-12360] - Race condition in workspace collection add and delete [MH-12359] - Milliseconds trim bug in videoeditor-workflowoperation formatTime() javaScript [MH-12358] - Only 6 series were displayed on the distribution node [MH-12353] - Theodul player does not load reliably after restart [MH-12350] - Recreate adminui-Index stops, if Asset of Event ist missing [MH-12329] - File copy can fail with jetty timeout [MH-12326] - Reduce log level for IllegalStateException in StaticResourceServlet [MH-12317] - AdminUI create every 5 seconds stats request and may crash on heavy server load [MH-12303] - Sort the REST endpoints alphabetically [MH-12131] - Migrate documentation of capture agent communication protocol to markdown [MH-12085] - Make file upload in Admin UI more flexible [MH-11768] - Timeline preview images","title":"Opencast 3.3"},{"location":"changelog/#opencast-32","text":"Released on August 16, 2017 [MH-12347] - Opencast generates invalid XML catalogs when a \"default\" (empty) Namespace is used. [MH-12345] - Ingest fails because /recordings/{id}/acls returns 500 if event has not ACLs [MH-12342] - A \"Scanner\" instance in the ExecuteServiceImpl class is not properly closed: possible resource leak [MH-12333] - Feed generator separates lists of tags incorrectly [MH-12327] - CAS Authentication is not working [MH-12324] - Reduce frequency of index update messages for rebuilds [MH-12318] - Remove Webconsole Default Installation [MH-12316] - IllegalStateException: Committed [MH-12315] - Database Query of Users from UserlistProvider is very slow [MH-12311] - Update Admin UI build tools [MH-12307] - OAI-PMH REST endpoint docs fix [MH-12305] - Admin UI should stop polling event stats if the event tab isn't shown [MH-12288] - Set default max idle time if not configured and log key pool parameters [MH-12280] - Create an Opencast group for Sakai instructors [MH-12278] - NullPointerException in CleanupWorkflowOperationHandler [MH-12275] - MH-12261 / Avoid race condition between index and cleanup operations [MH-12271] - MH-12261 / Update WFR put action to update files atomically [MH-12270] - Don't swallow unknown SMIL exceptions [MH-12263] - MH-12261 / FileSupport > link - copy file action should use overwrite argument (Throws FileFileAlreadyExists) [MH-12261] - Race condition leads to FileAlreadyExistsException and FileNotFoundException [MH-12079] - Misleading logging in some indexing message receivers [MH-12007] - Revive the Execute Service [MH-11542] - Failed test: Process video after cutting (Safari) [MH-10650] - Intermittent failure to detect hard links when starting a cluster [MH-10523] - Misleading exception parameter in getFileFromCollection","title":"Opencast 3.2"},{"location":"changelog/#opencast-31","text":"Released on July 14, 2017 [MH-12296] - getSeries Performance Issue [MH-12295] - Update Karaf to 4.0.9 [MH-12291] - Remove obsolete Speech Recognition API [MH-12279] - As a user, I expect the video editor to correctly visualize the audio track [MH-12253] - Example workflows are inconsistent in Formatting and Configuration of Publication Options [MH-12215] - Extended metadata should be applied on event create wizard [MH-12157] - Series index query performs bad on system with many series [MH-11742] - Document criteria for inclusion and exclusion of translations","title":"Opencast 3.1"},{"location":"changelog/#opencast-30","text":"Released on June 13, 2017 [MH-12257] - HttpsFilter is not called before OAuthProviderProcessingFilter [MH-12255] - OC cannot add PyCA capture agent when server ending with / [MH-12252] - LTI default launch goes to the wrong URL for sample tool [MH-12249] - Media Module: Paging forgets search parameters [MH-12248] - Capture Calendar Modification Caching Implementation is very Inefficient [MH-12247] - Archive Synchronization fix doesn't working in >=2.3 [MH-12235] - WOH partial-import: No track matching smil Track-id [MH-12230] - Notifications appear again although the user has closed them [MH-12228] - player controls: use dropup instead of a dropdown if controls are below the video [MH-12226] - Add documentation about configuration of publication channel names and icons [MH-12222] - As a user, I don't want an empty tab be presented to me since I don't necessarily understand, what that means [MH-12221] - As a user, I expect meaningful placeholder texts in the filter selection components [MH-12213] - Internal distribution fails if download url is not default [MH-12211] - As a service provider, I need to be able to deal with multiple users that have the same name [MH-12207] - Incorrect comment identifiers in some workflows [MH-12205] - Update version of javax.ws.rs - jsr311-api [MH-12204] - Rearrange the config [MH-12202] - ProxyMiddleware does ignore host port [MH-12199] - 3.x release notes mention \"comprehensive\" LDAP support, which is not (yet) true [MH-12198] - Remove outdated file location in LDAP documentation [MH-12197] - IllegalStateException: Response is committed [MH-12195] - Unprivileged users cannot view media package element details on Recordings->Events->\"Event Details\"->Assets->Media [MH-12193] - OAI-PMH distribution fails on adaptive streaming artifacts [MH-12189] - Sakai userdirectory provider is not properly bundled [MH-12183] - Theodul does not load [MH-12181] - As a course admin, I want to allow roles in the UI for ACLs that match a pattern [MH-12180] - Cannot specify ValuefFor probe-resolution woh [MH-12174] - The Admin UI temporarily displays wrong table content because data is not cleared upon page navigation [MH-12173] - The Admin UI temporarily displays wrong table content because data requests are not cancelled [MH-12170] - Safari does not display metadata once entered [MH-12169] - As a user, I expect search strings to match non-word boundaries in searchable dropdown lists [MH-12167] - As a user, I need to be able to search for values offered by the filters, so that I actually find the value I am looking for [MH-12156] - Fix version of matterhorn-engage-theodul-plugin-custom-piwik [MH-12153] - Reduce Database Space usage [MH-12149] - Upgrade Elastic Search to 1.7.6 [MH-12148] - Undocumented Archive WOH Requirements [MH-12147] - TOC links in REST docs overlap [MH-12142] - As a system administrator, I would like a documented hint that the user running Opencast needs RW access to the optional storage directory [MH-12141] - As service provider, I want to restrict access granted to tenant administrators [MH-12138] - Added release notes [MH-12137] - AWS S3 tries to distribute attachments from OAI-PMH distribution [MH-12133] - OAI-PMH Tests Fails Regularly [MH-12130] - Filters set by selecting a category in the dashboard are not shown [MH-12128] - REST docs are too eager to check for a valid value [MH-12126] - Fast workflow needs AWS distribution to default to false. [MH-12124] - Cutting a video multiple times results in multiple smil/cutting catalogs [MH-12121] - Update grunt-ng-annotate to 3.0.0 and grunt-contrib-uglify to 2.2.0 [MH-12120] - pub service oaipmh wants distribution api [MH-12117] - As an adopter I would like to get collect data with Piwik [MH-12115] - Republish Metadata to OAI-PMH fails [MH-12113] - Update outdated comment about the \"lifecycle-mapping\" plugin in the main pom.xml [MH-12112] - Update Node Version [MH-12110] - frontend-maven-plugin is executed on every module [MH-12109] - Creating comments does not work anymore [MH-12108] - Set Workflow Variables Based On Resolution [MH-12104] - As a producer, I want to access assets of my tenant while a workflow is running [MH-12103] - As a producer, I want to be able to execute WOH partial-import on archived sources [MH-12102] - Add Workflow Variables Based On Media Properties [MH-12084] - The class \"AsyncTimeoutRedirectFilter\" swallows almost all the exceptions [MH-12074] - Remove workflow MissedCaptureScanner and MissedIngestScanner [MH-12073] - Typo in rest_docs entry box [MH-12070] - Order the event counters to reflect the event lifecycle [MH-12067] - Initial REST Docs Search [MH-12066] - Missing feature.xml Installation [MH-12065] - Fix bundle info REST endpoint description [MH-12064] - Handle missing meta.abstract gracefully [MH-12060] - Simplify Default WOH [MH-12056] - As an Administrator, I'd like to add some custom roles for managing access [MH-12055] - Update REST Documentation Template [MH-12054] - Incorrect or misleading documentation about WOH conditional execution [MH-12049] - Update REST Documentation Overview [MH-12043] - Allow more then one additional authentication algorithms beside digest [MH-12038] - Fallback decoding for mediapackage date values in unixtime rather than W3CDTF [MH-12037] - NullPoiinterException when starting embedded Solr [MH-12035] - Setting Default Download Directory [MH-12034] - Make the UserAndRoleDirectoryService cache configurable [MH-12033] - Add indicator lights for capture agent status [MH-12032] - Add an authenticated ACL template [MH-12031] - Add additional docs for inspection WOH [MH-12029] - As a user, I want to use my existing AAI login for Opencast, too [MH-12023] - Make development builds faster [MH-12022] - /ingest/addTrackURL broken [MH-12019] - Ensure Test Files Are Deleted [MH-12017] - CoverImage WOH should provide metadata for recording start/end time [MH-12016] - Fix and improve user, group, role and provider handling [MH-12015] - Typo in External API role name [MH-12014] - Incorrect number of roles returned when limit is specified [MH-12013] - Contribute OAI-PMH work (ETH) [MH-12002] - Date & time format should be customizable in cover images [MH-11994] - UserIdRoleProvider should check user existence from user providers [MH-11993] - WOH partial-import should support output framerate [MH-11990] - Remove configuration file of removed module matterhorn-load-test [MH-11982] - As an Opencast administrator, I would like a dashboard counter for active recordings [MH-11979] - The video editor does not highlight the selected segment if it is cut [MH-11978] - Hotkeys for common tasks in Admin UI [MH-11977] - Remove Unused OSGI Bindings From IndexService [MH-11976] - Adjust DownloadDistribution Logs [MH-11975] - Update some maven plugins [MH-11971] - Update maven-surfire-test plugin to latest version [MH-11969] - Fullscreen button in embedded view of Theodul player missing after update to 2.2.4 [MH-11967] - Publish internal fails on Distrubuted System Admin/Engage [MH-11965] - Update to Karaf 4.0.8 [MH-11957] - Make availability check of WOH publish-configure configurable [MH-11956] - Allow fine-grained control of accurate frame count [MH-11954] - Fixing Javadoc Build [MH-11952] - HTML in Translations [MH-11944] - MH-11817 use keyboard shortcuts to control the editor [MH-11916] - Add convenience workflow instance variable to indicate whether a theme is involved [MH-11910] - WOH composite should be able to respect resolution of its input [MH-11904] - Missing IDClass Warnings [MH-11903] - Cannot Configure Authentication For Webconsole [MH-11902] - Update to latest 5.x MySQL connector [MH-11894] - Suppress context menu on video element [MH-11885] - Add support for search and filtering to Organization->Access Policies [MH-11881] - ArchiveRestEndpoint has conflicting endpoints [MH-11880] - Multiple issues with LDAP in branch 2.3.x [MH-11873] - org.ops4j.pax.web.pax-web-extender-whiteboard causes exception when shutting down [MH-11868] - redesign loginpages [MH-11861] - MH-11817 Change default view to editor in admin ui tools area [MH-11849] - Edit metadata fields by click inside and focus cursor in field [MH-11822] - Admin UI Video Editor - Improved Segment Controls [MH-11821] - Admin UI Video Editor - Comment and Metadata Editing [MH-11818] - Admin UI Video Editor - Improved playback and timeline [MH-11806] - Output Frame Rate on Concat Operation [MH-11797] - Upgrade Karaf to 4.0.6 [MH-11796] - Add support for watermarks to themes [MH-11782] - MH-11780 Create configure-by-dcterm workflow operation handler [MH-11781] - MH-11780 Create tag-by-dcterm workflow operation handler [MH-11780] - As a developer I want to be able to manipulate a workflow based on metadata in the Mediapackage [MH-11766] - enhance REST Ingest/addTrack Ingest/addCatalog Ingest/AddAttachment to add tags [MH-11761] - Captions for player [MH-11732] - Make distribution and retraction efficient [MH-11719] - When configuring LDAP with default file things are broken [MH-11717] - MH-11713 Not possible to add external roles to an ACL through the admin UI [MH-11715] - MH-11713 Externally provisioned roles should not be persisted [MH-11713] - Users may have roles in Opencast which are granted from an external system (e.g. LMS) [MH-11684] - WOH silence does not support tags [MH-11474] - Assigning a user to a certain \"ROLE_GROUP_<name>\" role does not really put the user in such group [MH-11466] - Improve handling of long strings in cover images [MH-11379] - Service to distribute delivery files to AWS S3 [MH-11229] - workflowoperation unit tests are incredible slow [MH-11036] - Adapt Fast Testing Workflow for Admin NG [MH-10871] - Sakai User Provider for Opencast-Sakai integration [MH-10819] - When creating a new event, metadata field can only be edited by clicking on the pencil icon [MH-10753] - Stale database connection causes job failure [MH-10310] - Add ERROR state for capture agent","title":"Opencast 3.0"},{"location":"changelog/#opencast-23x","text":"","title":"Opencast 2.3.x"},{"location":"changelog/#opencast-235","text":"Released on December 04, 2017 [MH-12588] - Stream Security Leaks Secrets [MH-12317] - AdminUI create every 5 seconds stats request and may crash on heavy server load [MH-12269] - Clarify in the documentation the recommendation of setting dispatchinterval to 0 applies to non-admin nodes only [MH-12190] - Script injection in Media Module and Player [MH-12000] - Cross-tenant URL signing [MH-11042] - Admin UI NG tests fail in +5:30 timezone","title":"Opencast 2.3.5"},{"location":"changelog/#opencast-234","text":"Released on August 03, 2017 [MH-12183] - Theodul does not load [MH-12203] - Unescaped event and series titles when editing event or series (XSS) [MH-12242] - Theodul: Quality selector does not display/load [MH-12246] - Series WOH does not apply series DublinCore catalogs [MH-12249] - Media Module: Paging forgets search parameters","title":"Opencast 2.3.4"},{"location":"changelog/#opencast-233","text":"Released on May 02, 2017 [MH-10558] - Mime type not identified for matroska / mkv files [MH-10595] - Incident service returns internal server error if cascade=true requested for deleted workflow [MH-10747] - Inputs for capture device should be pre-selected [MH-11736] - Difference in start time displayed in overview and metadata details [MH-11811] - Opencast build fails when system timezone is set to PDT (Pacific Daylight Time) [MH-12048] - Series drop-down not sorted alphabetically in filter [MH-12069] - Deleting an event leaves behind orphaned comments [MH-12095] - Server default timezone can be incorrect [MH-12106] - Preserve user attributes from providers during authentication [MH-12107] - Improve performance of Servers table in Admin UI [MH-12118] - Paging in media module is broken [MH-12129] - Media module only works with english localized browsers [MH-12130] - Filters set by selecting a category in the dashboard are not shown [MH-12148] - Undocumented Archive WOH Requirements [MH-12150] - Matroska files are not recognized [MH-12158] - Workflow job dispatching failures [MH-12162] - JpaJob object toString override for better log messages [MH-12163] - Events with stopped workflows sometimes cannot be deleted [MH-12164] - Updating serviceregistry config while running leaves Opencast in a non-functional state [MH-12190] - Script injection in Media Module and Player","title":"Opencast 2.3.3"},{"location":"changelog/#opencast-232","text":"Released on March 22, 2017 [MH-11224] - Attempting to view source metadata through the new admin UI generates a stack trace [MH-11340] - Uncaught NullPointer Exception in Karaf console from com.entwinemedia.fn.data.json.SimpleSerializer.toJson [MH-11616] - Search Service will not remove mp from index if it is not found in database [MH-11743] - event.hasPreview() broken [MH-11760] - Event edit warning cannot be removed [MH-11790] - Slide Previews and slide text are not shown in Theodul Engage player [MH-11817] - Unhide volume controls in video-editor [MH-11819] - Admin UI Video Editor - Improved Zoom Controls [MH-12009] - Admin UI Video Editor: Segmentation lost after publishing [MH-12058] - Ingests fail if specified workflow does not exist [MH-12059] - Catch invalid dates when indexing [MH-12061] - Reduce the number of activemq messages and log entries during index rebuild [MH-12062] - Improve robustness of scheduler re-indexing [MH-12063] - Catch incomplete archive entries when indexing [MH-12072] - Wrong destinationId for External API message receiver [MH-12084] - The class \"AsyncTimeoutRedirectFilter\" swallows almost all the exceptions [MH-12087] - Null bitrate can cause UI display of source media to fail [MH-12092] - Return event ID when event is created through Scheduler API [MH-12097] - SegmentVideoWorkflowOperation: Modules not included in Admin Presentation build.","title":"Opencast 2.3.2"},{"location":"changelog/#opencast-231","text":"Released on Janurary 25, 2017 [MH-11267] - Wrong notification text when deleting series [MH-11458] - Update translations from crowdin [MH-11687] - UI date formats are wrong for most of the English-speaking world [MH-11776] - CaptureAgentStateServiceImplTest incorrectly passes a non-long recording id, misses finding the NullPointer in Impl [MH-11960] - matterhorn-adminui-ng fails on first build [MH-11961] - Cannot access slidetext.xml should not break re-indexing [MH-11963] - Fix ingest REST docs [MH-11966] - Confusing AdminUI Groups Endpoint Documentation [MH-11967] - Publish internal fails on Distrubuted System Admin/Engage [MH-11983] - Only administrators should be allowed to assign the admin roles to other users [MH-11987] - Declare Admin UI Facade as module internal interface [MH-11988] - Advise to change karaf shutdown command in the docs [MH-11989] - Allow unknown as well as offline CAs to be removed via UI [MH-11992] - Compatibility issue when using contrib Wowza adaptive streaming module [MH-11998] - /info/me.json sometimes doesn't provide full information about the user [MH-12004] - Removing an recording does not remove all correspronding jobs [MH-12005] - UI shows inconsistent version due to missing version in cover-image-remote [MH-12006] - Security Issue Allowing Arbitrary Code Execution","title":"Opencast 2.3.1"},{"location":"changelog/#opencast-230","text":"Released on December 13, 2016 [MH-10342] - As an external device I want to immediate start and stop a capture [MH-11327] - De-couple smilImpl/wfrImpl from ingestImpl [MH-11378] - Conditionally synchronize Archive Service's add mediapackge [MH-11380] - As a customer, I want to integrate my third party application to Opencast, so that I can use Opencast content in my application [MH-11381] - Remove documentation of items that have never been implemented [MH-11411] - move dashboard to header [MH-11675] - Add documentation for External API to the Admin Guide [MH-11688] - Set java file encoding on startup [MH-11718] - As a producer, I want to be able to make workflow settings persistent so that I can reuse them later [MH-11725] - Give users a starting point how to report bugs [MH-11726] - Add AdminUI style guide to developer guide [MH-11728] - Use Apache Commons Lang 3 [MH-11729] - External API: Add documentation for Groups Endpoint [MH-11731] - Typofix Documentation [MH-11737] - Comment (mh_event_comment and mh_event_comment_reply) text field is VARCHAR(255) should be TEXT [MH-11740] - optimization of segmentation [MH-11741] - Admin UI has timezone issues [MH-11749] - External API: Add REST documentation for Endpoints [MH-11750] - Clean-Up Opencast Code Base [MH-11752] - Upgrade Karaf to 3.0.8 [MH-11756] - Admin UI NG Update CSS+HTML (1): FontAwesome, improve HTML, remove redundant images [MH-11763] - Counters hide series tab [MH-11772] - Admin UI source dropdowns inappropriately advance [MH-11774] - Admin UI Needs better documentation for debugging [MH-11775] - Library Update [MH-11783] - Custom publications labels not displayed when doing a mouse-over on Events->Published [MH-11784] - Remove Participation Management Code Pieces [MH-11786] - HttpsRequestWrapper wrongly sets the new URL [MH-11791] - As service provider I want to configure which kind of users can see the event counters [MH-11792] - NPM Proxy via Nexus [MH-11794] - NPM fails on first build [MH-11795] - Add support for title slides [MH-11799] - Maven bundle names too long [MH-11800] - LTI between Opencast and Moodle does not work [MH-11801] - Wowza streaming server needs flv: prefix for flv files [MH-11802] - Opencast Logo is missing in Player [MH-11803] - Player redirect is missing [MH-11804] - No video controls in embed mode [MH-11808] - Pre-select workflow in case only one option is available [MH-11809] - Fix syntax error in encoding profile composite.http [MH-11812] - Fix security configuration for ROLE_UI_TASKS_CREATE [MH-11813] - Agent state REST endpoint documentation [MH-11815] - As a user I expect changes to be reflected in the Admin UI immediately [MH-11817] - Admin UI Video Editor - Bug Fixes [MH-11817] - Display video details in preview player/ editor of the admin ui [MH-11817] - Improve Button Hover Indication [MH-11817] - Make Next/Last Frame controls in videoeditor better recognizeable [MH-11827] - Recordings->Events->\"Event Details\"->Metadata: Incorrect translation used [MH-11828] - exception-handler-workflow not set correctly [MH-11829] - High memory usage on the admin server by dispatching jobs [MH-11831] - As a service provider, I want to configure whether Opencast creates an admin user automatically [MH-11834] - Unable to set capture agent configuration as JSON [MH-11836] - Additional ACL actions of series are missing when creating a new event in that series [MH-11837] - Unprivileged users have no access to fonts [MH-11839] - typo in Event Details: Comments [MH-11841] - Wait for NFS shares before start Opencast service [MH-11842] - Revert accidental downgrade of grunt version [MH-11851] - org.opencastproject.security.admin/pass can't be changed [MH-11857] - Fix log output \"Unable to delete non existing object %s/%s\" [MH-11862] - Search API handles roles wrong [MH-11863] - WOH analyze-tracks & WOH failing cause exceptions when shutting down Opencast [MH-11864] - WOH tag shall implement AbstractWorkflowOperationHandler [MH-11865] - Videoeditor Preview mixes in 2 Audiofiles [MH-11866] - Search box in Organization >> Groups not working [MH-11867] - Filter box in Organization >> Groups not working [MH-11869] - Deleting Series with 'Actions' is not working [MH-11870] - Wordlength in other languages except english too long [MH-11871] - ElasticSearch shall bind to 127.0.0.1 [MH-11875] - ActiveMQ should not listen to all hosts by default [MH-11880] - Multiple issues with LDAP in branch 2.3.x [MH-11883] - Larger files may remain in system temp directory [MH-11886] - login pages throw errors on loading unnecessary scripts [MH-11888] - Organization Filter uses Provider where table uses Type [MH-11889] - Row size too large [MH-11890] - MySQL Connector Version Should Be Consistent [MH-11891] - Event counters query large amounts of useless data [MH-11895] - \u201cAdd Event\u201d Wizard Input Fields Broken [MH-11896] - Java Warnings in AbstractEventEndpoint [MH-11897] - Remove Deprecated StringHelper [MH-11898] - Fix Technical Duration Calculation [MH-11899] - Prevent Requesting Event Objects Multiple Times [MH-11900] - Minor Index Service Fixes [MH-11905] - Publish Configure WOH incorrectly retracts publications [MH-11912] - No slider in playback video player [MH-11919] - WOH image claims SUCCEEDED when actually skipping [MH-11920] - WOH prepare-av: Misleading log message [MH-11921] - WOH partial-import looses partial audio tracks in specific cases [MH-11950] - Javadocs build error [MH-11955] - Add en-GB to Languages","title":"Opencast 2.3.0"},{"location":"changelog/#opencast-22x","text":"","title":"Opencast 2.2.x"},{"location":"changelog/#opencast-225","text":"Released on June 7, 2017 [MH-11983] - Only admins should be able to modify other admins [MH-12006] - Security Issue Allowing Arbitrary Code Execution [MH-11962] - Missing slidetext.xml should not break re-indexing","title":"Opencast 2.2.5"},{"location":"changelog/#opencast-224","text":"Released on October 13, 2016 [MH-11831] - As a service provider, I want to configure whether Opencast creates an admin user automatically [MH-11851] - org.opencastproject.security.admin/pass can't be changed [MH-11862] - Search API handles roles wrong [MH-11875] - ActiveMQ should not listen to all hosts by default","title":"Opencast 2.2.4"},{"location":"changelog/#opencast-223","text":"Released on October 13, 2016 [MH-11285] - Improve developers documentation: remote debugger with karaf [MH-11741] - Admin UI has timezone issues [MH-11771] - Improve section localization in developer guide [MH-11773] - Embed player does not use space very well and has scaling problems [MH-11774] - Admin UI Needs better documentation for debugging [MH-11777] - Event Details->Comments and Event Details->Assets don't work for unprivileged users [MH-11787] - Add release dates to changelog [MH-11800] - LTI between Opencast and Moodle does not work [MH-11801] - Wowza streaming server needs flv: prefix for flv files","title":"Opencast 2.2.3"},{"location":"changelog/#opencast-222","text":"Released on September 14, 2016 [MH-11194] - created themes not showing up in series branding tab [MH-11572] - FFmpeg Inspection Service Test - accurateFrameCount [MH-11587] - SQL Error [MH-11714] - Fix unit test: Event controller #accessSave saves the event access [MH-11724] - Additional actions not available in create event wizard anymore [MH-11734] - Fix el7 RPM docs [MH-11735] - Fix Stream Security Documentation [MH-11744] - Actions->Start Task: Various localization bugs [MH-11748] - Inconsistent and incorrect use of translate directive [MH-11751] - Player won't work if there are no segments [MH-11755] - No quality selection in Theodul Player [MH-11759] - Make Inspector Unit Tests More Robust","title":"Opencast 2.2.2"},{"location":"changelog/#opencast-221","text":"Released on July 30, 2016 [MH-11092] - Every Browser has an other \"Remember me\" checkbox [MH-11169] - Trimming points not set correctly after workflow is finished [MH-11538] - \"No compatible source was found for this video\" videojs player error in iOS device [MH-11561] - Style (CSS): Setting a server in Maintenance (srv-det-01) [MH-11598] - Wizards should not re-use data that has entered before [MH-11644] - Missing Admin Interface Mock Data [MH-11653] - Jobs do not always proceed [MH-11655] - Jobs with high job load never get processed [MH-11659] - Warning is missing that metada and ACL cannot be edited while job is processing. [MH-11661] - Link on logo on the media module points to admin ui or welcome page, instead of something that is accessable for every user [MH-11664] - Incorrect Inconsistency status when built from tarball [MH-11665] - Systems->Servers & Systems->Services show wrong mean runtime and mean queue time [MH-11667] - Align main table content [MH-11668] - Missing segment previews let to an erro in the player [MH-11669] - Do not archive OCR texts [MH-11673] - Add documentation for additional ACL actions [MH-11674] - Add documentation for metadata configuration [MH-11679] - Page size cannot be changed in any table [MH-11681] - Add documentation for role-based visibility [MH-11682] - Remove useless roles from roles.txt [MH-11686] - Extended metadata tab not shown although user has the role ROLE_UI_EVENTS_DETAILS_METADATA_VIEW [MH-11690] - Various Documentation Improvements [MH-11692] - Remove Superfluous Mh-Db-Version [MH-11693] - Remove Superfluous Dependency Versions [MH-11694] - JavaDoc Generation Broken [MH-11702] - After an upgrade to 2.2.0, series are not displayed in the UI because the series creation date is now mandatory [MH-11720] - Opencast 2.2 requires Git to be installed at build time [MH-11727] - Fix unit test: adminNg.services.language #toLocalTime converts a zulu time string back to local time FAILED [MH-11730] - Make the automatic role prefix in LDAPUserProvider configurable","title":"Opencast 2.2.1"},{"location":"changelog/#opencast-220","text":"Released on June 15, 2016 [MH-9511] - Wrong log level in Tesseract [MH-9831] - ehcache and quartz phones home [MH-9950] - Update player dependencies [MH-10029] - Remove Unnecessary Image Conversion Step From TextAnalysisService [MH-10173] - Do not ignore exceptions when closing Closeable's [MH-10748] - Matterhorn has to be restarted to schedule an event on a new capture device [MH-10794] - Delete Action should be disabled if nothing is selected [MH-10869] - ActiveMQ Configuration and Connection Problems [MH-10870] - ActiveMQ Exceptions While Shutting Down Matterhorn [MH-10887] - Users can schedule events in the past [MH-10898] - Update Apache HttpComponents (3.1.7 \u2192 4.4.1) [MH-10923] - Theodul player : Filtering \"composite\" tags results in error when the composite workflow is used [MH-10942] - Events are not deselected after applying a task [MH-10965] - Theodul player : Videos not playable on IE10 [MH-10971] - Newly created Series don't show up in Series dropdown selection lists without page reload [MH-10978] - Unable to retract 'internal' publications [MH-10979] - Opencast needs to better distribute load across the available nodes [MH-10984] - Extend ingest service by partial upload [MH-11010] - Stream Security should be able to prevent cross-tenants access [MH-11014] - Add support for additional ACL actions [MH-11077] - The Publish Workflow will not retract already published material [MH-11097] - View modes not working correctly [MH-11107] - Group list pagination not working [MH-11121] - MacOS X Installation Guide Needs 2.1 Update [MH-11124] - Incorrect documentation on how to create users [MH-11128] - Docs about SilenceDetector threashold are incorrect [MH-11139] - Unable to find mimetype for mkv [MH-11140] - Forward and backward buttons are greyed out [MH-11143] - Link to Media Module in Admin UI [MH-11148] - Search box layout incorrect: Icon overlaps text [MH-11156] - Users: Search box not implemented [MH-11157] - Groups: Search box not implemented [MH-11165] - Sorting does not work on Systems->Jobs, Systems->Servers and Systems->Services [MH-11167] - Layout problem on Workflow Error Details view [MH-11183] - Capture->Locations: Search box not implemented [MH-11190] - Theodul Shortcuts: Description could be improved [MH-11191] - Event Details->Assets: Use human-readable units for duration, bitrates and sizes [MH-11192] - Audio level slider does not change audio level while dragging [MH-11199] - Playback & video editor don't work while workflow is running [MH-11209] - LTI Documentation needs to be incorporated into new docs [MH-11222] - Replace System.out.println with logger [MH-11229] - workflowoperation unit tests are incredible slow [MH-11252] - Some service configuration files are stored in the wrong directory [MH-11265] - Ensure configuration files end with newline characters [MH-11266] - Logger ConversionPattern stated twice [MH-11276] - HttpNotificationWorkflowOperationHandlerTest fails if a certain Domain Exists [MH-11280] - Opencast fails to compile due to missing dependencies in test-harness [MH-11281] - Enhance WOH image to support extraction of multiple images using multiple encoding profiles from multiple sources [MH-11282] - Enhance WOH composite to support single video streams [MH-11287] - Update Apereo/Apache License List [MH-11289] - Change text extraction documentation or file name [MH-11294] - Create admin-worker and ingest distribution [MH-11296] - HTTP method POST is not supported by this url in r/2.1.x [MH-11298] - Fix json-simple version specification [MH-11300] - WOH partial-import looses partial audio tracks beginning at position zero [MH-11304] - Documentation for WOH partial-import and load configuration not listed in pages configuration [MH-11306] - Change job dispatcher sort order to: restart jobs, non-wf jobs, creation date [MH-11307] - Distribution Service is not on Presentation Node [MH-11310] - Document encoding profiles used by WOH partial-import [MH-11311] - Use existing encoding profiles in WOH partial-import example [MH-11312] - Fix Encode WOH Documentation [MH-11313] - Update Parallel Encode Profiles [MH-11319] - Media Module Always Uses Second Attachment as Preview [MH-11320] - Missing Image Preparation for text Extraction [MH-11321] - Fix default workflow configuration panel [MH-11322] - Update WebM Profiles [MH-11355] - Slide texts are not shown correctly in theodul player, except the first segment there a now slide texts shown (\"No slide text available\"). In the XML file the texts are correct [MH-11356] - Update Documentation Index Page [MH-11357] - Notifications are not removed after a while [MH-11358] - Dismiss Button for comments has an inconsistent design [MH-11363] - Notification that server is not reachable is missing [MH-11364] - Reasons in Comments section are no longer translated [MH-11368] - Changing to Chinese translation doesn't work [MH-11369] - Series filter displays series id instead of series title [MH-11374] - Videoeditor: Times are wrong in zoomed waveform view [MH-11385] - Metadata summary not showing any metadata at event creation [MH-11386] - Silence Detection / Video Editor Waveform bug [MH-11389] - security 1 [MH-11391] - Improve Flavor creation and parsing [MH-11392] - Sorting by series.created does not work correctly [MH-11401] - Hiding of columns is globally broken [MH-11404] - Group editor shows users and roles twice [MH-11405] - Pagination broken for groups table [MH-11409] - Translation key EVENTS.EVENTS.GENERAL.SELECT_WORKFLOW_EMPTY is missing [MH-11413] - AdminUI comment dialog translations missing [MH-11414] - Logger is missing from several modules [MH-11415] - Incorrect Urlsigning Module Name [MH-11416] - Specify Opencast's Requirements [MH-11417] - Tab names of modals not vertically centered [MH-11419] - Tables not drawn correctly [MH-11422] - add event tab titles not translated [MH-11427] - Can't get host details from Serviceregistry REST endpoint [MH-11428] - Default Workflow Option Does Not Work [MH-11430] - Prevent user from accidentally press \"Save & process\" in Video Editor multiple times [MH-11431] - Prevent users from accidentally pressing the Delete/Retract button multiple times [MH-11432] - JSHint settings are missing [MH-11434] - \"The task could not be created\" error notification always appear when starting a task on multiple events [MH-11435] - Fix code style errors in Gruntfile.js [MH-11436] - Matterhorn on Login/Welcome Page [MH-11437] - Resource Problems On Login Page [MH-11438] - Resource Problem on Welcome Page [MH-11439] - Event description not available in WOH cover-image [MH-11441] - Clicking on Logo in top left corner will nmot get you to the start page [MH-11443] - Seeking is not possible before pressing play button at least once?!? [MH-11446] - Remove eclipse-gemini repository from main pom.xml [MH-11447] - Scheduling conflicts reporting completely broken [MH-11448] - Tipps on developing on admin ui ng [MH-11450] - Fix Defaults For Documentation Links [MH-11453] - Correctly link the stream security documentation [MH-11457] - Remove duplicate keys from Admin UI english translation [MH-11458] - Update translations from crowdin [MH-11459] - Logger Logs Nullpointer on Error [MH-11462] - Cover WOH is not included in a useful way [MH-11464] - setting personal preferences in admin UI fails [MH-11468] - There are unused ressources [MH-11475] - Fix typos in English master translation [MH-11476] - Series->Actions->Delete displays wrong notifications [MH-11477] - Editing status of series displays wrong notification when saving fails for all series [MH-11480] - Replace horizontal ellipsis [MH-11481] - Workflows started by unprivileged users hang [MH-11492] - forward and backward section not working in safari [MH-11509] - Failed test: Sorting groups list (grp-lis-01) [MH-11511] - Failed test: Manual set time in textbook for IE11 [MH-11512] - hello world does not follow import statements rules [MH-11518] - Language selector is always displayed in system language [MH-11519] - Languages are only distinguished by main language [MH-11520] - Remove company logos [MH-11521] - ActiveMQ Library Configuration [MH-11522] - DataLoader Default Value [MH-11523] - Working file repository default value [MH-11524] - Distribution Service Default Values [MH-11532] - Wider language support in player [MH-11534] - Add language support for Chinese Simplified [MH-11535] - Add documentation about Crowdin to Developer Guide [MH-11536] - Remove Commercial Code From Core [MH-11537] - Execute Service WOH Cannot be Built [MH-11539] - Remove Old MH Logos in Favor of Opencast SVG Logos [MH-11544] - Admin UI links used inconsistently [MH-11546] - Pagination buttons too small for large numbers [MH-11548] - The \"Edit\" button at the top-right corner of the tables doesn't support localization [MH-11550] - Update Migration documentation 2.1 to 2.2 [MH-11554] - Filtering does not work on Systems->Jobs, Systems->Servers and Systems->Services [MH-11555] - Localisation of Recordings->Events and Recordings->Series buggy [MH-11556] - Failed test: Filter locations (T1733, Filter by status does not work) [MH-11559] - outdated shortcurts configuration prevents player from loading. [MH-11571] - Elasticsearch shutdown command handler crash opencast [MH-11573] - Do not hide warnings [MH-11574] - Jetty Error on Large Workflow Instances [MH-11575] - Inspection Service Tests Fail With Certain FFmpeg Versions [MH-11576] - Servlet Filter Improvements [MH-11578] - Improve default order of columns in Systems->Jobs [MH-11579] - Admin UI mockup data for Systems->Jobs incomplete [MH-11580] - Unit tests for Admin UI language selection broken [MH-11581] - Systems->Jobs table not working correctly [MH-11583] - Fix Code Style [MH-11588] - Create side-by-side preview for video editor [MH-11589] - Feedback button does not work [MH-11590] - The WorkflowServiceImpl constructor sets the \"waitForResources\" argument incorrectly [MH-11594] - Add language support for Galician [MH-11595] - Fix admin ui unit tests for tableService [MH-11597] - Building matterhorn-engage-theodul-plugin-video-videojs reports a lot of code style issues [MH-11600] - Failed test: i18n (gen-int-01) [MH-11601] - current language can have undefined state [MH-11604] - Date picker for setting up the schedule is always french [MH-11605] - Disabling link to mediaplayer creates a broken link and missing logo [MH-11606] - Add language support for Greek [MH-11608] - Add documentation for WOH cleanup [MH-11613] - WOH editor fails when input has uneven width or height [MH-11614] - Partial matches not working anymore [MH-11617] - Add language support for Dutch [MH-11620] - Non privileged user can not login on presentation node [MH-11623] - Server statistics: Slow Query [MH-11624] - Workflow owners do not necessarily have access to their workflows: user comparison fails [MH-11627] - NullPointerException when creating a new Solr index [MH-11629] - Hide Some Confusing Warnings [MH-11630] - Service registry lacks of getActiveJobs() function [MH-11631] - Remove columns \"Blacklisted from\" and \"Blacklisted until\" from Capture->Locations [MH-11632] - Library Bugfix Upgrade [MH-11636] - Adjust FFmpegComposer Logging for Newer FFmpeg Versions [MH-11637] - Add language support for Swedish [MH-11638] - Improve Encoding Profiles [MH-11639] - Media module login form has poor usability and bugs [MH-11642] - Remove binding to non-existing method in WOH analyze-tracks [MH-11643] - Add language support for Polish [MH-11645] - Open AdminUI menu links in new tab does not work [MH-11646] - Add documentation for WOH comment [MH-11652] - Unit tests for servicesController broken [MH-11654] - Failed ingest jobs block system from dispatching other jobs [MH-11656] - Add documentation for WOH copy [MH-11657] - Improve documentation for workflow execution conditions [MH-11658] - Better quality for video editor previews [MH-11663] - Hide Participation Management from UI since not yet working [MH-11666] - Not all WOH listed in WOH overview","title":"Opencast 2.2.0"},{"location":"changelog/#opencast-21x","text":"","title":"Opencast 2.1.x"},{"location":"changelog/#opencast-212","text":"Released on May 10, 2016 [MH-9831] - ehcache and quartz phones home [MH-11121] - MacOS X Installation Guide Needs 2.1 Update [MH-11124] - Incorrect documentation on how to create users [MH-11128] - Docs about SilenceDetector threashold are incorrect [MH-11209] - LTI Documentation needs to be incorporated into new docs [MH-11229] - workflowoperation unit tests are incredible slow [MH-11283] - post-mediapackage WOH breaks further processing [MH-11287] - Update Apereo/Apache License List [MH-11296] - HTTP method POST is not supported by this url in r/2.1.x [MH-11298] - Fix json-simple version specification [MH-11307] - Distribution Service is not on Presentation Node [MH-11319] - Media Module Always Uses Second Attachment as Preview [MH-11320] - Missing Image Preparation for text Extraction [MH-11321] - Fix default workflow configuration panel [MH-11323] - Workflow Docs are Incorrect [MH-11332] - Document acceptance criteria for proposals [MH-11356] - Update Documentation Index Page [MH-11377] - Opencast does not have an ingest assembly","title":"Opencast 2.1.2"},{"location":"changelog/#opencast-211","text":"Released on January 22, 2016 [MH-11107] - Group list pagination not working [MH-11265] - Ensure configuration files end with newline characters [MH-11266] - Logger ConversionPattern stated twice [MH-11276] - HttpNotificationWorkflowOperationHandlerTest fails if a certain Domain Exists [MH-11280] - Opencast fails to compile due to missing dependencies in test-harness","title":"Opencast 2.1.1"},{"location":"changelog/#opencast-210","text":"Released on December 22, 2015 [MH-10637] - Hello World service [MH-10651] - Workspace cleaner job param in wrong units (ms vs s) and wrong logic [MH-10714] - Two clock icons at the time stamp of a comment [MH-10805] - The confirmation dialog are not translated [MH-10818] - The creation date is presented as ISO string in the event metadata [MH-10869] - ActiveMQ Configuration and Connection Problems [MH-10874] - Plugin does not properly handle multiple keys [MH-10875] - Include search capabilities into mkdocs documentation build [MH-10890] - Update Apache Commons Lang (2.6 \u2192 3.4) [MH-10908] - Assemblie Module Names Too Long [MH-10908] - Consistency in Documentation: Presentation Server VS Engage Server [MH-10908] - Misconfigured Checkstyle Plug-in in Assemblies [MH-10919] - Top row for setting roles in the access policy for an event is not showing the right value [MH-10953] - Spanish layout is broken [MH-10955] - Make sure recent versions of mkdocs work [MH-10956] - Update Synchronize.js [MH-10985] - As an operator I want to check the health status of Opencast [MH-10986] - Scheduling around DST change fails [MH-10987] - Improve workflow query to accept paging by index [MH-10988] - Rewrite workspace to fix several small issues [MH-10989] - Improve working file repository stream response [MH-11007] - Remove 3rd party tool script [MH-11026] - Several invalid links in the Opencast User Guides [MH-11031] - Missing option to create new event using files ingested from the inbox [MH-11036] - Adapt Fast Testing Workflow for Admin NG [MH-11051] - Fix WOH Documentation [MH-11069] - When creating new series, warning about read/write requirements is shown twice. [MH-11072] - The ACL editor needs enhanced validation [MH-11074] - Admin UI Test: New Event API Resource assembles the metadata for SCHEDULE_MULTIPLE with DST change is failing [MH-11083] - Clean-up Codebase after Karaf [MH-11085] - Make sure bundle cache is cleared when restarting [MH-11086] - Shorten File Names in Log Output [MH-11088] - translation error in theodul player [MH-11089] - Theodul player seems not to work with Internet Explorer at all [MH-11093] - single video screen size jump when clicked [MH-11094] - Problems in Theodul controls plugin due to wrong resolves of merge conflicts [MH-11095] - Make assemblies more user firedly [MH-11096] - Errors when loading admin-ng login page [MH-11099] - Removing one role from an Access Policy (acl-det-05) [MH-11101] - Creating a Theme with 2 bumper videos - In and Out (thm-new-01) [MH-11109] - Event details tab cannot handle long event titles well [MH-11110] - minor updates to ffmpeg video-editor and silence detection based on gregs review of the feature in 1.6.3 [MH-11111] - Formatting issues in \u201cTheodul Pass Player - URL Parameters\u201d [MH-11114] - Remove System.out.println from FileReadDeleteTest [MH-11120] - Several Services Fail During Shutdown [MH-11122] - Create Service Files (Systemd/SysV-Init) [MH-11126] - Fix Translation for 2.1 [MH-11133] - i18n: Theme Detail view layout broken in Spanish [MH-11135] - Create Release Manager Docs [MH-11137] - Comment reasons are not working correctly [MH-11138] - Clock icon displayed twice next to comment creation date [MH-11141] - Playback Speed in player needs more useful defaults [MH-11142] - fix translations for shortcuts [MH-11144] - update documentation regarding property for mediamodule logo [MH-11147] - Missing translations: FILTERS.USERS.PROVIDER.LABEL & FILTERS.USERS.ROLE.LABEL [MH-11149] - Filter locations: Translations FILTERS.AGENTS.NAME.LABEL & FILTERS.AGENTS.STATUS.LABEL missing [MH-11151] - Plaback speed from menu [MH-11152] - Editing ACL: Translation for USERS.ACLS.DETAILS.ACCESS.ACCESS_POLICY.DESCRIPTION missing [MH-11153] - Access Policy Details: Cannot navigate to previous or next ACL [MH-11154] - New Access Policy: Translation for USERS.ACLS.NEW.ACCESS.ACCESS_POLICY.DESCRIPTION missing [MH-11155] - ACL Editor: Role not displayed at all [MH-11158] - Playback Tool: Time can be edited, but editing has no effect [MH-11159] - Users sorting: Sort order for 'Name' not correct [MH-11160] - Create Group overwrites existing groups without warning [MH-11162] - security_sample_cas.xml in MH 2.0.1 Points to Wrong Welcome Page [MH-11166] - Number of rows not displayed on Systems->Servers [MH-11176] - Cannot playback a recording via LTI in 2.x [MH-11177] - Fix Player OSGI Dependencies [MH-11178] - Prevent FFmpeg Experimental AAC Encoder Bug to Affect Opencast [MH-11180] - Update video.js to latest 4.x version [MH-11181] - Flash streaming with multi-quality video does not work [MH-11185] - Event Details->Assets->: Asset size is always 0 [MH-11186] - Event Details->Assets->Media->Media Details: Superfluous row 'Flavor' [MH-11187] - Configuration->Themes: Number of rows not displayed correctly [MH-11189] - Actions->Start Task: User can press create button multiple times [MH-11193] - Setting audio level slider to \"zero\" does not set the actual audio level to \"zero\" [MH-11196] - REST docs cannot be found in new admin ui [MH-11198] - Event dashboard seems not to support i18n [MH-11201] - Maven Assembly Plug-in Listed Twice [MH-11202] - FFmpeg video editor operation is synchronized [MH-11212] - Main Pom Clean-Up [MH-11218] - Karaf based Solr configuration [MH-11221] - ComposerServiceImpl creates incorrect incidents and error messages [MH-11223] - Remove unused files [MH-11234] - Admin-NG throws a couple of 404 errors [MH-11236] - Security ACL see security list [MH-11237] - Service files are missing [MH-11238] - Silence-detection does not read configuration value for ffmpeg binary path [MH-11248] - Publish-Engage Workflow Operation Documentation is Missing Configuration Keys [MH-11249] - Apply-ACL WOH not properly replaced by Seried-WOH in Documentation [MH-11250] - Put temporary files in karaf data not in opencast.storage [MH-11251] - Capture-Admin Tests May Fail When Executed Too Fast [MH-11257] - Deprecated Mkdocs Config [MH-11258] - Make host configuration easier","title":"Opencast 2.1.0"},{"location":"changelog/#opencast-20x","text":"","title":"Opencast 2.0.x"},{"location":"changelog/#opencast-202","text":"Released on December 22, 2015 [MH-10235] - Users are unable to determine the Version of Matterhorn [MH-10484] - Remove Mediainfo from 3rd-Party-Tools [MH-10558] - Mime type not identified for matroska / mkv files [MH-10588] - Improve MySQL DDL to make it consistent again [MH-10759] - Write QA documentation for Access Policies [MH-10759] - Write QA documentation for Series [MH-10759] - Write QA documentation for Themes [MH-10818] - The creation date is presented as ISO string in the event metadata [MH-10918] - Improve the representation of the attachments/catalogs/media/publications in the event details [MH-10956] - Update Synchronize.js [MH-10964] - The Opencast start script does not work on Mac OS X [MH-10976] - Eclipse (m2e) throws NullPointerException erros due to a missing property in the pom.xml file [MH-11007] - Remove 3rd party tool script [MH-11007] - Switch subtitle embedder to FFmpeg [MH-11026] - Several invalid links in the Opencast User Guides [MH-11038] - Make ListProviderScanner Scanner Less verbose [MH-11048] - admin ui tries to load missing library [MH-11051] - Fix WOH Documentation [MH-11060] - ActiveMQ settings filename fix (r/2.0.x) [MH-11068] - Table 'mh_bundleinfo' doesn't exist [MH-11110] - minor updates to ffmpeg video-editor and silence detection based on gregs review of the feature in 1.6.3 [MH-11176] - Cannot playback a recording via LTI in 2.x [MH-11177] - Fix Player OSGI Dependencies [MH-11181] - Flash streaming with multi-quality video does not work [MH-11202] - FFmpeg video editor operation is synchronized [MH-11221] - ComposerServiceImpl creates incorrect incidents and error messages [MH-11236] - Security ACL see security list [MH-11238] - Silence-detection does not read configuration value for ffmpeg binary path [MH-11256] - Opencast docs do not build anymore","title":"Opencast 2.0.2"},{"location":"changelog/#opencast-201","text":"Released on September 3, 2015 [MH-10822] - Possible to create new access policy template without a role with read/write permissions [MH-10938] - Missing views counter in player [MH-10941] - Usertracking Service Missing Endpoint [MH-10955] - Make sure recent versions of mkdocs work [MH-10962] - Add missing licenses to NOTICES [MH-10968] - Add note about ffmpeg/libav on Ubuntu [MH-10975] - async loading of translations [MH-10995] - Gathering workflow statistics for JMX causes extreme performance issues","title":"Opencast 2.0.1"},{"location":"changelog/#opencast-200","text":"Released on July 17, 2015 [MH-9950] - \"Clean up\"/Split up nested functions in the core routine (core.js) [MH-9950] - Load CSS files in the core HTML file, not the JavaScript [MH-9950] - Scrolling is required to see the controls if they are configured to be below the video. [MH-9950] - Some Keys don't work [MH-9950] - Theodul Core Jasmine Tests Sometimes Failing [MH-10029] - FFmpeg based Videosegmenter [MH-10140] - Capture agent with no configuration is always shown as \"idle\" [MH-10202] - No ACL in new series when ingested a new mediapackage with a new series. [MH-10230] - Typos on the welcome page [MH-10332] - Remove Mediainfo Inspection Service [MH-10382] - Add a UI Element to Easily Unregister Capture Agents [MH-10419] - Improve user tracking tables [MH-10510] - Move Workflow Operation Handler into their own Packages [MH-10550] - Non-Interactive Foreground Mode For Matterhorn [MH-10572] - ShibbolethLoginHandler: 500 Error when login the first time [MH-10594] - Re-configure Start Scripts for Different Deployment Types [MH-10615] - Enable Optional Compiler Arguments [MH-10620] - Port Silence Detector from GStreamer to FFmpeg [MH-10622] - Wave Generation Improvement [MH-10623] - Set Sensible Default for Workspace Cleanup Period [MH-10624] - Fixes for FFmpeg Videosegmenter (Set Binary) [MH-10630] - Extending common functionality [MH-10631] - Scheduler service authorization handling [MH-10635] - Text extractor dead lock [MH-10640] - several problems with the metadata form to create a new event [MH-10656] - Login Screen: Placeholder and Focus [MH-10658] - Email template: diverse problems [MH-10664] - What is a template in Access Policy and how do I create it? [MH-10665] - 404 for variables.json [MH-10667] - Previous Button does not always work [MH-10681] - Time is missing when a workflow operation has been started and stopped [MH-10683] - Remove Capture Agent [MH-10683] - Remove the Capture Agent integration tests [MH-10684] - Admin UI seems only unresponsive if server is down [MH-10689] - I should get a warning, if I leave the Admin UI while I still create an event (upload a file) [MH-10698] - workflow after videoeditor does not produce any */delivery flavors [MH-10700] - Service Registry throws NPE exception on startup [MH-10704] - Workflows fail if adding themes [MH-10705] - Row counter in Jobs table is 1 too much [MH-10707] - Unit Test Failure [MH-10710] - NullPointerException in VideoSegmentationWOH [MH-10711] - OptimisticLockException after ingest [MH-10712] - Workflow cleanup out of memory error [MH-10713] - Cache util blocks forever [MH-10726] - Archive operation should use filesystem copy rather than http download [MH-10736] - Engage is currently broken and won't play videos but Theodule does [MH-10740] - NPE in ToolsEndpoint [MH-10746] - There is no event status column [MH-10758] - Issues found in production use of Theodul: changing icons, seeking in Chrome, using configured logos, wording, layout... [MH-10759] - Write QA documentation for Events [MH-10759] - Write QA documentation for Groups [MH-10759] - Write QA documentation for Servers [MH-10759] - Write QA documentation for Services [MH-10763] - Remove Old Confirations [MH-10765] - Operation details doesn't show operation attributes when state is instantiated [MH-10768] - Workflow operations table in the events details should refresh automatically [MH-10769] - Add (x) icon in the events and series tableview to allow deletion of single Events/Series [MH-10770] - Some captions of tabs are not yet translated [MH-10772] - Ensure that buttons order is consistent in the actions column [MH-10773] - Allow to have free-text value for presenters, contributors, organizers or publishers [MH-10774] - ACL editing should be locked on the Series level when events of the series are being processed [MH-10775] - All the roles with read/write rights can be deleted from the ACL editor in Events/Series details [MH-10776] - Include Spanish and French translation into Theodul. [MH-10780] - Specify Requirements [MH-10781] - Respect tags while filtering for suitable tracks in Theodul player [MH-10792] - Pom.xml Extra Modules [MH-10798] - Event Details tile shows hash identifier [MH-10799] - Videoeditor operation does not properly handle missing preview formats [MH-10804] - It is unclear in which timezone you schedule in the admin-ui [MH-10807] - New event POST request contains every series and user [MH-10808] - Disable Demo Users [MH-10810] - Rename upgrade script form 1.6 to 2.0 [MH-10812] - Use bundles.configuration.location in admin ng settings.yml [MH-10814] - Pressing play while buffering breaks player [MH-10816] - Move Message Broker Configuration to Global Config [MH-10821] - Severe Issue with Scheduled Events [MH-10829] - Unchecking \"Remember me\" checkbox has no effect when logged out. Pressing the browsers back button you're still logged in an d can use all functions. [MH-10836] - Issues with matterhorn-engage-theodul-plugin-archetype [MH-10837] - Bulk deletion of events doesn't work correctly [MH-10843] - different video qualities are not filtered correctly. [MH-10845] - Summary of \"Add Events\" and \"Add Series\" shows irrelevant data [MH-10847] - Missing with-role directive in \"Start Task\" option in Actions dropdown [MH-10848] - Event conflict endpoint returns Server error 500 [MH-10849] - Temporary videoeditor files get not deleted [MH-10850] - Interface MatterhornConstans has a typo [MH-10853] - Improve admin UI ng workflows [MH-10855] - Task Menu displays wrong UI [MH-10864] - Remove Trailing Spaces From Less Files [MH-10866] - Documentation: Incorrect Repository Links [MH-10868] - Linebreak before last segment in player [MH-10873] - capture-admin-service-impl tests randomly failing [MH-10876] - Admin UI NG makes calls to remote resources [MH-10880] - Remote base keeps try to call a service [MH-10881] - Wrong links to r/2.0.x on documentation page [MH-10884] - WokflowOperation getTimeInQueue should return 0 if value is NULL [MH-10888] - Theodul player: audio-only does not work - player checked for unavailable size. [MH-10901] - Execute Service is not in main pom.xml and will not be built [MH-10902] - ./modules/matterhorn-publication-service-youtube/ obsolete [MH-10905] - FFmpeg videoeditor only works with audio and video available [MH-10911] - Remove executable flag from non-executables [MH-10912] - Init scripts contain undefined references to DEBUG_PORT and DEBUG_SUSPEND [MH-10913] - Add Event: License Metadata Field Text [MH-10924] - Update to new Opencast logos [MH-10926] - Extensive PhantomJS warnings when building admin-ng [MH-10928] - Adjust loglevel in DictionaryService [MH-10929] - Cutting and Review are skipped when config is set to do so [MH-10930] - Fix missing German translation [MH-10934] - Once set, one cannot remove some metadata in the create event dialog [MH-10938] - Missing views counter in player [MH-10939] - Task Summary does not display configuration values [MH-10946] - Fix Opencast 2 Installation Guides [MH-10950] - Fix DDL Readme [MH-10952] - Fix matterhorn-execute-operations naming [MH-10957] - Add License Guide for Developers","title":"Opencast 2.0.0"},{"location":"releasenotes/","text":"Opencast 8: Release Notes Features Improved integration of external statistics providers (InfluxDB) Hourly scale for data exports Visualization of statistics in the Admin UI Limit accepted file types when uploading assets Support for exclusion pattern for URL signing Add option to configure state mappings for workflows Assembly configuration Multi-tenancy support for workflows Role support for workflows Video-crop service Paella Player 6.2.4 Multiple audio tracks support on Paella Player Feeds-tab: adds a new tab in series properties for ATOM and RSS Feeds Custom LTI series tool styles Show only events with write access in the Admin UI Access org properties from publish-configure WOH Resolution based, conditional encoding Termination State Service to integrate with AWS AutoScaling Lifecycle Health check endpoint Officially support URL signing keys that handle multiple URL prefixes Support for exclusion pattern for URL signing User-provider for the d2l Brightspace LMS Provide access to file contents in the Working File Repository Automatic caption using Google speech to text API Admin UI: new event media upload progress bar Opencast Plug-in features for Karaf Single step delete of events Improvements Resume on past table page when leaving video editor JavaScript dependency management Highlight main table rows on hover Reduces job payload size in database Improved URL signing performance ingest-download operation moved to worker Media Module configuration now in the organization configuration file Sensible names for hosts instead of URLs Improved icons and wording in video editor Improved delete-event submit button Extended the ingest-download-woh Tag elements retrieved from asset manager Improve navigation in video editor when zoom is active Switch to compatible file type filter definitions Improved setting values from Dublin Core catalog Don't start Opencast on a used port ESLint used in Theodul Core Theodul Player scroll/zoom overlay to use shift + scroll wheel zoom Removed State Mapping \"Importing\" Hide column \"Stop\" by default Fixed Workflow Index rebuild ACL handling Reduced memory needed for Workflow Index rebuild Ansible script documentation Automatic publication of streaming URLs S3 compatibility - Endpoint configuration for Amazon S3 alternatives added Theodul player ui config Re-introduce ability to avoid data loss during ingest Configuration changes etc/org.opencastproject.adminui.cfg has a new option retract.workflow.id which contains the id of the workflow used to retract events when deleting. API changes Removed REST endpoints for modifying workflow definitions DELETE /workflow/definition/{id} PUT /workflow/definition Aditional Notes About 8.1 Opencast 8.1 fixes a number of security issues. Upgrading is strongly recommended. Take a look at the security advisories for more details. One change is that the OAI-PMH endpoint is no longer publicly accessible by default. If you need it to be, you can easily change that in the security configuration at etc/security/mh_default_org.xml . Fixed Security Issues CVE-2020-5231 \u2013 Users with ROLE_COURSE_ADMIN can create new users CVE-2020-5206 \u2013 Authentication Bypass For Endpoints With Anonymous Access CVE-2020-5222 \u2013 Hard-Coded Key Used For Remember-me Token CVE-2020-5230 \u2013 Unsafe Identifiers CVE-2020-5229 \u2013 Replace MD5 with bcrypt for password hashing CVE-2020-5228 \u2013 Public Access Via OAI-PMH Release Schedule Date Phase October 1st 2019 Feature Freeze Nov 4th - Nov 10th 2019 Translation week Nov 11th - Nov 24th 2019 Public QA phase December 17th 2019 Release of Opencast 8.0 Release managers Karen Dolan (Harvard University DCE) R\u00fcdiger Rolf (Osnabr\u00fcck University)","title":"Release Notes"},{"location":"releasenotes/#opencast-8-release-notes","text":"","title":"Opencast 8: Release Notes"},{"location":"releasenotes/#features","text":"Improved integration of external statistics providers (InfluxDB) Hourly scale for data exports Visualization of statistics in the Admin UI Limit accepted file types when uploading assets Support for exclusion pattern for URL signing Add option to configure state mappings for workflows Assembly configuration Multi-tenancy support for workflows Role support for workflows Video-crop service Paella Player 6.2.4 Multiple audio tracks support on Paella Player Feeds-tab: adds a new tab in series properties for ATOM and RSS Feeds Custom LTI series tool styles Show only events with write access in the Admin UI Access org properties from publish-configure WOH Resolution based, conditional encoding Termination State Service to integrate with AWS AutoScaling Lifecycle Health check endpoint Officially support URL signing keys that handle multiple URL prefixes Support for exclusion pattern for URL signing User-provider for the d2l Brightspace LMS Provide access to file contents in the Working File Repository Automatic caption using Google speech to text API Admin UI: new event media upload progress bar Opencast Plug-in features for Karaf Single step delete of events","title":"Features"},{"location":"releasenotes/#improvements","text":"Resume on past table page when leaving video editor JavaScript dependency management Highlight main table rows on hover Reduces job payload size in database Improved URL signing performance ingest-download operation moved to worker Media Module configuration now in the organization configuration file Sensible names for hosts instead of URLs Improved icons and wording in video editor Improved delete-event submit button Extended the ingest-download-woh Tag elements retrieved from asset manager Improve navigation in video editor when zoom is active Switch to compatible file type filter definitions Improved setting values from Dublin Core catalog Don't start Opencast on a used port ESLint used in Theodul Core Theodul Player scroll/zoom overlay to use shift + scroll wheel zoom Removed State Mapping \"Importing\" Hide column \"Stop\" by default Fixed Workflow Index rebuild ACL handling Reduced memory needed for Workflow Index rebuild Ansible script documentation Automatic publication of streaming URLs S3 compatibility - Endpoint configuration for Amazon S3 alternatives added Theodul player ui config Re-introduce ability to avoid data loss during ingest","title":"Improvements"},{"location":"releasenotes/#configuration-changes","text":"etc/org.opencastproject.adminui.cfg has a new option retract.workflow.id which contains the id of the workflow used to retract events when deleting.","title":"Configuration changes"},{"location":"releasenotes/#api-changes","text":"Removed REST endpoints for modifying workflow definitions DELETE /workflow/definition/{id} PUT /workflow/definition","title":"API changes"},{"location":"releasenotes/#aditional-notes-about-81","text":"Opencast 8.1 fixes a number of security issues. Upgrading is strongly recommended. Take a look at the security advisories for more details. One change is that the OAI-PMH endpoint is no longer publicly accessible by default. If you need it to be, you can easily change that in the security configuration at etc/security/mh_default_org.xml .","title":"Aditional Notes About 8.1"},{"location":"releasenotes/#fixed-security-issues","text":"CVE-2020-5231 \u2013 Users with ROLE_COURSE_ADMIN can create new users CVE-2020-5206 \u2013 Authentication Bypass For Endpoints With Anonymous Access CVE-2020-5222 \u2013 Hard-Coded Key Used For Remember-me Token CVE-2020-5230 \u2013 Unsafe Identifiers CVE-2020-5229 \u2013 Replace MD5 with bcrypt for password hashing CVE-2020-5228 \u2013 Public Access Via OAI-PMH","title":"Fixed Security Issues"},{"location":"releasenotes/#release-schedule","text":"Date Phase October 1st 2019 Feature Freeze Nov 4th - Nov 10th 2019 Translation week Nov 11th - Nov 24th 2019 Public QA phase December 17th 2019 Release of Opencast 8.0","title":"Release Schedule"},{"location":"releasenotes/#release-managers","text":"Karen Dolan (Harvard University DCE) R\u00fcdiger Rolf (Osnabr\u00fcck University)","title":"Release managers"},{"location":"upgrade/","text":"Upgrading Opencast from 7.x to 8.x This guide describes how to upgrade Opencast 7.x to 8.x. In case you need information about how to upgrade older versions of Opencast, please refer to older release notes . How to Upgrade Stop your current Opencast instance Replace Opencast with the new version Back-up Opencast files and database (optional) Upgrade the database Remove search index data folder Start Opencast Rebuild Admin UI and External API index You can find the database upgrade script in docs/upgrade/7_to_8/ .","title":"Upgrade"},{"location":"upgrade/#upgrading-opencast-from-7x-to-8x","text":"This guide describes how to upgrade Opencast 7.x to 8.x. In case you need information about how to upgrade older versions of Opencast, please refer to older release notes .","title":"Upgrading Opencast from 7.x to 8.x"},{"location":"upgrade/#how-to-upgrade","text":"Stop your current Opencast instance Replace Opencast with the new version Back-up Opencast files and database (optional) Upgrade the database Remove search index data folder Start Opencast Rebuild Admin UI and External API index You can find the database upgrade script in docs/upgrade/7_to_8/ .","title":"How to Upgrade"},{"location":"version-support/","text":"Supported Versions Opencast has a standing policy of supporting the current version, and the previous version. In general terms, this means a roughly 1 year support cycle for any given release due to our half year major releases. Support, in this context, means development time: building fixes, applying them, and releasing those changes. For example, as of the time of writing we currently support versions 6.x, and 5.x. Once version 7.0 releases, version 5.x will no longer be supported, but 6.x will. Questions for older releases will still be answered on list, but developer time will usually not be allocated to fixing issues on those versions any longer.","title":"Version Support"},{"location":"version-support/#supported-versions","text":"Opencast has a standing policy of supporting the current version, and the previous version. In general terms, this means a roughly 1 year support cycle for any given release due to our half year major releases. Support, in this context, means development time: building fixes, applying them, and releasing those changes. For example, as of the time of writing we currently support versions 6.x, and 5.x. Once version 7.0 releases, version 5.x will no longer be supported, but 6.x will. Questions for older releases will still be answered on list, but developer time will usually not be allocated to fixing issues on those versions any longer.","title":"Supported Versions"},{"location":"configuration/","text":"Opencast Configuration Guides These guides will help you to configure Opencast. If you are a first-time user, please make sure to at lease have a look at the basic configuration guide . General Configuration Basic Configuration Database Configuration HTTPS Configuration Encoding Profile Configuration List Providers Load Configuration Log Configuration User Statistics and Privacy Configuration Message Broker Configuration Metadata Configuration Multi Tenancy Configuration Authentication, Autorization and User Management CAS Security Configuration LDAP Authentication and Authorization (without CAS) Moodle User Provider Sakai User Provider Brightspace User Provider Authentication and Authorization Infrastructure (AAI) Access Control Lists Stream Security Workflow Configuration Workflow Operation Handler External API Configuration OAI-PMH Configuration External Monitoring Admin UI Configuration Event Filters Manual Asset Upload Languages Statistics Thumbnails","title":"Overview"},{"location":"configuration/#opencast-configuration-guides","text":"These guides will help you to configure Opencast. If you are a first-time user, please make sure to at lease have a look at the basic configuration guide .","title":"Opencast Configuration Guides"},{"location":"configuration/#general-configuration","text":"Basic Configuration Database Configuration HTTPS Configuration Encoding Profile Configuration List Providers Load Configuration Log Configuration User Statistics and Privacy Configuration Message Broker Configuration Metadata Configuration Multi Tenancy Configuration Authentication, Autorization and User Management CAS Security Configuration LDAP Authentication and Authorization (without CAS) Moodle User Provider Sakai User Provider Brightspace User Provider Authentication and Authorization Infrastructure (AAI) Access Control Lists Stream Security Workflow Configuration Workflow Operation Handler External API Configuration OAI-PMH Configuration External Monitoring Admin UI Configuration Event Filters Manual Asset Upload Languages Statistics Thumbnails","title":"General Configuration"},{"location":"configuration/acl/","text":"Access Control List Configuration This document describes how Opencast stores and handles access control settings for series and episodes and what configuration options related to this are available. Access Control Lists An access control list (ACL) in the context of Opencast consists of a global deny rule (no one is allowed access) and a set of roles with rules attached to define access. Hence, it is effectively a white-listing of roles to grant access and it means that all roles and/or actions not defined in an access control list are denied access. For example, the following rule defines read access for role 1 and read/write access for role 2: role action access ROLE1 read true ROLE2 read true write true Opencast can also deny access locally (e.g. deny write access for role 1) which can be interesting if merging of ACLs is used. But this is not handled in the user interface and using this should therefore be avoided. System administrators are an exception to these rules. A user with ROLE_ADMIN will always be granted access, regardless of the rule-set attached to an event. Organizational administrators are also granted access in some cases. Global Rules In case an event has no custom access control list defined, a global rule set is associated with the event. The global rules consist only of the general deny rule. Hence, no access is allowed to anyone except administrators.. Series and Episode Rules Access control lists can be specified both on series and on episode level. This means that multiple rule sets can be attached to an episode which is part of a series. Opencast can handle this in multiple ways. The handling is specified by the merge mode configured in etc/org.opencastproject.authorization.xacml.XACMLAuthorizationService.cfg . It defines the relationship between series and episode access control lists, if both are attached to an event. If only one list is attached, its rules are always active. If multiple lists are attached, the following modes define Opencast's behavior: Merge Mode \u201coverride\u201d (Default) The episode ACL takes precedence over the series ACL. This means that the series ACL will be completely ignored as soon as the episode has an ACL, no matter what rules are set in either. This allows users to define general rules for a series which can be completely redefined on an episode and which are not influenced by changes later made to the series. This is also a very simple rule and thus easy to understand. Example: ROLE1 ROLE2 ROLE3 read write read write read write series allow allow allow allow episode allow allow active allow allow Merge Mode \u201croles\u201d Series and episode ACLs are merged based on the roles defined within. If both the series and the episode define a rule for a specific role (user or group), the episode's rule takes precedence. Rules for roles defined in one ACL only are always part of the resulting active ACL. Example: ROLE1 ROLE2 ROLE3 read write read write read write series allow allow allow allow episode allow allow active allow allow allow allow Merge Mode \u201cactions\u201d ACLs are merged based on the actions (read, write, \u2026) contained within both ACLs. If a rule is specified for a tuple of role and action in both ACLs, the rule specified in the episode ACL takes precedence. Example: ROLE1 ROLE2 ROLE3 read write read write read write series allow allow allow allow episode allow allow active allow allow allow allow allow Switching Modes Switching modes is not necessarily simple since access control lists are cached at several places. Hence, while changing this value will have an immediate effect on newly processed videos, an index rebuild is inevitable to update cached data and republications to update old events may be necessary. Updating Series Permissions Depending on the admin interface configuration in etc/org.opencastproject.organization-mh_default_org.cfg , the admin interface behaves differently when series access control lists are modified and may also overwrite episode rules of that series. Possible modes of operation are: always: When modifying series permissions, automatically remove all permission rules specific to single episodes belonging to the series. This enforces that every episode has the rules of the series in effect as soon as they are changed. never: Only update the series permissions but never replace permissions set on event level. This may mean that updated rules have no effect on already existing events. optional (default): Like never but present users with a button in the series permission dialog which allows them to replace the event specific permissions easily if they want to. Templates Templates of access control lists can be specified for the administrative user interface. They are a convenient way to apply a defined set of rules all at once instead of applying each rule one after another. Templates stored in etc/acl/ are loaded at start-up for all organizations. Templates can also be created and managed in the admin interface. Additional Actions Opencast uses two default actions for access authorization on events: read allows a role to access (read the value of) objects write allows a role to modify (write to) objects More actions can be added but are usually ignored by Opencast. Though they may be handy to specify rules for external applications. In case you need other actions, you can configure the admin interface to allow adding additional ones. These are configured in etc/listprovides/acl.additional.actions.properties . For example, this would configure the two actions, Upload and Download , to be available in the permission editor of the admin interface: list.name=ACL.ACTIONS # This list provider allows you to configure custom actions that can be added # to ACLs. The default actions are read and write. # The pattern for adding them is # UI_LABEL=actionId # Upload=myorg_upload Download=myorg_downlaod Using a unique prefix for your custom actions like this example did with myorg_ is recommended to make it unlikely that later Opencast versions introduce the same action in a different context.","title":"Access Control Lists"},{"location":"configuration/acl/#access-control-list-configuration","text":"This document describes how Opencast stores and handles access control settings for series and episodes and what configuration options related to this are available.","title":"Access Control List Configuration"},{"location":"configuration/acl/#access-control-lists","text":"An access control list (ACL) in the context of Opencast consists of a global deny rule (no one is allowed access) and a set of roles with rules attached to define access. Hence, it is effectively a white-listing of roles to grant access and it means that all roles and/or actions not defined in an access control list are denied access. For example, the following rule defines read access for role 1 and read/write access for role 2: role action access ROLE1 read true ROLE2 read true write true Opencast can also deny access locally (e.g. deny write access for role 1) which can be interesting if merging of ACLs is used. But this is not handled in the user interface and using this should therefore be avoided. System administrators are an exception to these rules. A user with ROLE_ADMIN will always be granted access, regardless of the rule-set attached to an event. Organizational administrators are also granted access in some cases.","title":"Access Control Lists"},{"location":"configuration/acl/#global-rules","text":"In case an event has no custom access control list defined, a global rule set is associated with the event. The global rules consist only of the general deny rule. Hence, no access is allowed to anyone except administrators..","title":"Global Rules"},{"location":"configuration/acl/#series-and-episode-rules","text":"Access control lists can be specified both on series and on episode level. This means that multiple rule sets can be attached to an episode which is part of a series. Opencast can handle this in multiple ways. The handling is specified by the merge mode configured in etc/org.opencastproject.authorization.xacml.XACMLAuthorizationService.cfg . It defines the relationship between series and episode access control lists, if both are attached to an event. If only one list is attached, its rules are always active. If multiple lists are attached, the following modes define Opencast's behavior:","title":"Series and Episode Rules"},{"location":"configuration/acl/#merge-mode-override-default","text":"The episode ACL takes precedence over the series ACL. This means that the series ACL will be completely ignored as soon as the episode has an ACL, no matter what rules are set in either. This allows users to define general rules for a series which can be completely redefined on an episode and which are not influenced by changes later made to the series. This is also a very simple rule and thus easy to understand. Example: ROLE1 ROLE2 ROLE3 read write read write read write series allow allow allow allow episode allow allow active allow allow","title":"Merge Mode \u201coverride\u201d (Default)"},{"location":"configuration/acl/#merge-mode-roles","text":"Series and episode ACLs are merged based on the roles defined within. If both the series and the episode define a rule for a specific role (user or group), the episode's rule takes precedence. Rules for roles defined in one ACL only are always part of the resulting active ACL. Example: ROLE1 ROLE2 ROLE3 read write read write read write series allow allow allow allow episode allow allow active allow allow allow allow","title":"Merge Mode \u201croles\u201d"},{"location":"configuration/acl/#merge-mode-actions","text":"ACLs are merged based on the actions (read, write, \u2026) contained within both ACLs. If a rule is specified for a tuple of role and action in both ACLs, the rule specified in the episode ACL takes precedence. Example: ROLE1 ROLE2 ROLE3 read write read write read write series allow allow allow allow episode allow allow active allow allow allow allow allow","title":"Merge Mode \u201cactions\u201d"},{"location":"configuration/acl/#switching-modes","text":"Switching modes is not necessarily simple since access control lists are cached at several places. Hence, while changing this value will have an immediate effect on newly processed videos, an index rebuild is inevitable to update cached data and republications to update old events may be necessary.","title":"Switching Modes"},{"location":"configuration/acl/#updating-series-permissions","text":"Depending on the admin interface configuration in etc/org.opencastproject.organization-mh_default_org.cfg , the admin interface behaves differently when series access control lists are modified and may also overwrite episode rules of that series. Possible modes of operation are: always: When modifying series permissions, automatically remove all permission rules specific to single episodes belonging to the series. This enforces that every episode has the rules of the series in effect as soon as they are changed. never: Only update the series permissions but never replace permissions set on event level. This may mean that updated rules have no effect on already existing events. optional (default): Like never but present users with a button in the series permission dialog which allows them to replace the event specific permissions easily if they want to.","title":"Updating Series Permissions"},{"location":"configuration/acl/#templates","text":"Templates of access control lists can be specified for the administrative user interface. They are a convenient way to apply a defined set of rules all at once instead of applying each rule one after another. Templates stored in etc/acl/ are loaded at start-up for all organizations. Templates can also be created and managed in the admin interface.","title":"Templates"},{"location":"configuration/acl/#additional-actions","text":"Opencast uses two default actions for access authorization on events: read allows a role to access (read the value of) objects write allows a role to modify (write to) objects More actions can be added but are usually ignored by Opencast. Though they may be handy to specify rules for external applications. In case you need other actions, you can configure the admin interface to allow adding additional ones. These are configured in etc/listprovides/acl.additional.actions.properties . For example, this would configure the two actions, Upload and Download , to be available in the permission editor of the admin interface: list.name=ACL.ACTIONS # This list provider allows you to configure custom actions that can be added # to ACLs. The default actions are read and write. # The pattern for adding them is # UI_LABEL=actionId # Upload=myorg_upload Download=myorg_downlaod Using a unique prefix for your custom actions like this example did with myorg_ is recommended to make it unlikely that later Opencast versions introduce the same action in a different context.","title":"Additional Actions"},{"location":"configuration/asset-manager/","text":"Asset Manager Configuration How can I use a different storage backend? Configure an alternate storage backend, and then either use the REST endpoints or the Move Storage workflow operation as part of a workflow. Note that the REST endpoints trigger workflows, the workflow operation handlers are generally only useful as part of an automated storage tiering system. REST Endpoints The REST endpoints can be accessed from $server_url/assets/docs . The value of $server_url is set during basic configuration . There is no other current user interface for storage tiering at this time. Config Options File System Based Asset Store Configure the file system based asset store in custom.properties . org.opencastproject.episode.rootdir The path where the file system based asset store of the default implementation stores the assets. This key is optional. org.opencastproject.storage.dir This is Opencast\u2019s general config key to configure the base path of everything storage related. If no storage directory is configured explicitely, the file system based asset store will use ${org.opencastproject.storage.dir}/archive as its base path.","title":"Asset Manager"},{"location":"configuration/asset-manager/#asset-manager-configuration","text":"","title":"Asset Manager Configuration"},{"location":"configuration/asset-manager/#how-can-i-use-a-different-storage-backend","text":"Configure an alternate storage backend, and then either use the REST endpoints or the Move Storage workflow operation as part of a workflow. Note that the REST endpoints trigger workflows, the workflow operation handlers are generally only useful as part of an automated storage tiering system.","title":"How can I use a different storage backend?"},{"location":"configuration/asset-manager/#rest-endpoints","text":"The REST endpoints can be accessed from $server_url/assets/docs . The value of $server_url is set during basic configuration . There is no other current user interface for storage tiering at this time.","title":"REST Endpoints"},{"location":"configuration/asset-manager/#config-options","text":"","title":"Config Options"},{"location":"configuration/asset-manager/#file-system-based-asset-store","text":"Configure the file system based asset store in custom.properties . org.opencastproject.episode.rootdir The path where the file system based asset store of the default implementation stores the assets. This key is optional. org.opencastproject.storage.dir This is Opencast\u2019s general config key to configure the base path of everything storage related. If no storage directory is configured explicitely, the file system based asset store will use ${org.opencastproject.storage.dir}/archive as its base path.","title":"File System Based Asset Store"},{"location":"configuration/basic/","text":"Basic Configuration This guide will help you to change the basic configuration settings which are required or at least strongly recommended for each Opencast installation. This is basically what you should do, right after installing Opencast on your machine. All settings are made to files residing in the Opencast configuration directory. In most cases, that should be either /etc/opencast/ or /opt/opencast/etc/ . Edit the files using the editor of your choice, e.g.: vim /etc/opencast/custom.properties Step 1: Setting the Server URL By default, only connections from the local machine are accepted by Opencast. You want to change this if the system should be accessible within a network. First, find the property org.opencastproject.server.url in your custom.properties configuration file and set it to your own domain name: org.opencastproject.server.url=http://example.com:8080 Note: This value will be written to all generated mediapackages and thus cannot be changed easily for already processed media. At least not without an extra amount of work involving modifications to the database. That is why you should think about this setting carefully. Second, adjust the binding address in your org.ops4j.pax.web.cfg configuration file. The binding address can be set to 0.0.0.0 for general network access. The property to modify is: org.ops4j.pax.web.listening.addresses=127.0.0.1 It may be necessary to adjust the jetty http connector idleTimeout value for processing large files in some configurations. To do so, uncomment this line in org.ops4j.pax.web.cfg : org.ops4j.pax.web.config.file=${karaf.etc}/jetty-opencast.xml and modify the host and if necessary port values in jetty-opencast.xml to match the ops4j configuration: <Set name=\"host\">127.0.0.1</Set> If you are deploying to the cloud then your servers may not have useful hostnames. The node name is a descriptive title for this Opencast instance, eg Admin, worker-01, etc. and can be used as an alternative in the Admin UI. org.opencastproject.server.nodename=AllInOne Step 2: Setting the Login Details There are two authentication methods for Opencast. HTTP Digest authentication and form-based authentication. Both methods need a username and a password. Change the password for both! The important keys in the 'custom.properties' configuration file are: org.opencastproject.security.admin.user The user for the administrative account. This is set to admin by default. org.opencastproject.security.admin.pass The password for the administrative account. This is set to opencast by default. org.opencastproject.security.digest.user The user for the communication between Opencast nodes, as well as for capture agents. This is set to opencast_system_account by default. org.opencastproject.security.digest.pass The password for the communication between Opencast nodes and capture agents. This is set to CHANGE_ME by default. Note: The digest credentials are also used for internal communication of Opencast servers. So these keys have to be set to the same value on each of you Opencast nodes (Core, Worker, Capture Agent, \u2026) Step 3: Change the default shutdown command Karaf provides a socket over wich you can send a shutdown command. The socket does not provide any kind of authentication. Therefore anyone who obtains write access to this socket is able to shutdown karaf and everything that runs on it. There is a default karaf.shutdown.command defined in custom.properties . Change this to something secret. Step 4: Setting up Apache ActiveMQ Message Broker Since version 2.0, Opencast requires a running Apache ActiveMQ instance with a specific configuration. The message broker is mostly run on the admin server of Opencast but can be run separately. It needs to be started before Opencast. For more details about the setup, have a look at the Apache ActiveMQ configuration guide . Step 5: Database Configuration Opencast uses an integrated HSQL database by default. While you will find it perfectly functional, it has certain drawbacks: It is rather slow It cannot be used for distributed set-ups Upgrading Opencast with this database is not possible For testing, it is totally fine to keep the internal database, but you are highly encouraged to switch to a stand-alone database for productional use. For more information about database configuration, have a look at the Database Configuration section. Step 6: Setting the Storage Directory (optional) Even though it is not important for all systems \u2013 on test setups you can probably omit this \u2013 you will often want to set the storage directory. This directory is used to store all media, metadata, \u2026 Often, an NFS mount is used for this. You can set the directory by changing org.opencastproject.storage.dir like: org.opencastproject.storage.dir=/media/mhdatamount Please keep in mind that the user running Opencast must have read/write permissions to the storage directory.","title":"Basic"},{"location":"configuration/basic/#basic-configuration","text":"This guide will help you to change the basic configuration settings which are required or at least strongly recommended for each Opencast installation. This is basically what you should do, right after installing Opencast on your machine. All settings are made to files residing in the Opencast configuration directory. In most cases, that should be either /etc/opencast/ or /opt/opencast/etc/ . Edit the files using the editor of your choice, e.g.: vim /etc/opencast/custom.properties","title":"Basic Configuration"},{"location":"configuration/basic/#step-1-setting-the-server-url","text":"By default, only connections from the local machine are accepted by Opencast. You want to change this if the system should be accessible within a network. First, find the property org.opencastproject.server.url in your custom.properties configuration file and set it to your own domain name: org.opencastproject.server.url=http://example.com:8080 Note: This value will be written to all generated mediapackages and thus cannot be changed easily for already processed media. At least not without an extra amount of work involving modifications to the database. That is why you should think about this setting carefully. Second, adjust the binding address in your org.ops4j.pax.web.cfg configuration file. The binding address can be set to 0.0.0.0 for general network access. The property to modify is: org.ops4j.pax.web.listening.addresses=127.0.0.1 It may be necessary to adjust the jetty http connector idleTimeout value for processing large files in some configurations. To do so, uncomment this line in org.ops4j.pax.web.cfg : org.ops4j.pax.web.config.file=${karaf.etc}/jetty-opencast.xml and modify the host and if necessary port values in jetty-opencast.xml to match the ops4j configuration: <Set name=\"host\">127.0.0.1</Set> If you are deploying to the cloud then your servers may not have useful hostnames. The node name is a descriptive title for this Opencast instance, eg Admin, worker-01, etc. and can be used as an alternative in the Admin UI. org.opencastproject.server.nodename=AllInOne","title":"Step 1: Setting the Server URL"},{"location":"configuration/basic/#step-2-setting-the-login-details","text":"There are two authentication methods for Opencast. HTTP Digest authentication and form-based authentication. Both methods need a username and a password. Change the password for both! The important keys in the 'custom.properties' configuration file are: org.opencastproject.security.admin.user The user for the administrative account. This is set to admin by default. org.opencastproject.security.admin.pass The password for the administrative account. This is set to opencast by default. org.opencastproject.security.digest.user The user for the communication between Opencast nodes, as well as for capture agents. This is set to opencast_system_account by default. org.opencastproject.security.digest.pass The password for the communication between Opencast nodes and capture agents. This is set to CHANGE_ME by default. Note: The digest credentials are also used for internal communication of Opencast servers. So these keys have to be set to the same value on each of you Opencast nodes (Core, Worker, Capture Agent, \u2026)","title":"Step 2: Setting the Login Details"},{"location":"configuration/basic/#step-3-change-the-default-shutdown-command","text":"Karaf provides a socket over wich you can send a shutdown command. The socket does not provide any kind of authentication. Therefore anyone who obtains write access to this socket is able to shutdown karaf and everything that runs on it. There is a default karaf.shutdown.command defined in custom.properties . Change this to something secret.","title":"Step 3: Change the default shutdown command"},{"location":"configuration/basic/#step-4-setting-up-apache-activemq-message-broker","text":"Since version 2.0, Opencast requires a running Apache ActiveMQ instance with a specific configuration. The message broker is mostly run on the admin server of Opencast but can be run separately. It needs to be started before Opencast. For more details about the setup, have a look at the Apache ActiveMQ configuration guide .","title":"Step 4: Setting up Apache ActiveMQ Message Broker"},{"location":"configuration/basic/#step-5-database-configuration","text":"Opencast uses an integrated HSQL database by default. While you will find it perfectly functional, it has certain drawbacks: It is rather slow It cannot be used for distributed set-ups Upgrading Opencast with this database is not possible For testing, it is totally fine to keep the internal database, but you are highly encouraged to switch to a stand-alone database for productional use. For more information about database configuration, have a look at the Database Configuration section.","title":"Step 5: Database Configuration"},{"location":"configuration/basic/#step-6-setting-the-storage-directory-optional","text":"Even though it is not important for all systems \u2013 on test setups you can probably omit this \u2013 you will often want to set the storage directory. This directory is used to store all media, metadata, \u2026 Often, an NFS mount is used for this. You can set the directory by changing org.opencastproject.storage.dir like: org.opencastproject.storage.dir=/media/mhdatamount Please keep in mind that the user running Opencast must have read/write permissions to the storage directory.","title":"Step 6: Setting the Storage Directory (optional)"},{"location":"configuration/database/","text":"Database Configuration Opencast ships with embedded JDBC drivers for the H2, MySQL and MariaDB databases. The built-in H2 database is used by default and needs no configuration, but it is strongly recommended to use MariaDB for production. performance gain. Notice: H2 is neither supported for updates, nor for distributed systems. Use it for testing only! Other databases Running Opencast with PostgreSQL should be possible and there is some community support for this. While it should work, the support for this is unofficial and we cannot guarantee that every new feature is well tested on that platform. The EclipseLink JPA implementation which is used in Opencast supports other databases as well and it should be possible to attach other database engines. Setting up MariaDB/MySQL Requirements Before following this guide, you should have: Installed the Opencast Core System Followed the Basic Configuration instructions Step 0: Set-up MariaDB/MySQL This step is not Opencast-specific and may be different depending on your scenario (e.g. if you want to have a dedicated database server). It shall only be a guide for people with no experience setting up MariaDB/MySQL to help them get started. MariaDB is used for this guide but if your distribution includes MySQL instead, the installation should be very much the same. First, install the MariaDB server. On RedHat-based systems, use: yum install mariadb mariadb-server Afterward, start the server and set it up to start automatically after each reboot: systemctl start mariadb.service systemctl enable mariadb.service Now you have MariaDB running, but without a properly configured root account (no password, etc.) which might pose a security risk. MariaDB includes a useful tool to secure your database server. You can launch it by executing (yes, it is still called mysql\u2026): mysql_secure_installation It will guide you through the steps of setting up a root account with password, etc. Step 1: Create an Opencast Database The first step, if you have not already done this, is to create a database for Opencast. You can use the following SQL code to to that. For executing the SQL, use the MariaDB/MySQL client (run mysql from your shell) or use a graphical tool like phpMyAdmin. For now, we will use the MySQL shell client and the default administrative (root) user. Launch the client with: mysql -u root -p You will be asked for the password of the user root. When logged in, you will end up in the MariaDB/MySQL shell. Next, create a database called opencast by executing: CREATE DATABASE opencast CHARACTER SET utf8 COLLATE utf8_general_ci; Then create a user opencast with a password and grant it all necessary rights: GRANT SELECT,INSERT,UPDATE,DELETE,CREATE TEMPORARY TABLES ON opencast.* TO 'opencast'@'localhost' IDENTIFIED BY 'opencast_password'; The rights granted here are all that is needed to run Opencast. To execute the migration scripts used to initialize (see next section) and upgrade the database schema upon releases of new versions of Opencast, you need more. If you don't want to do this using the root user (which normally can do anything), but with a dedicated user called admin for the sake of the example, you should grant that user the following rights: GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,ALTER,DROP,INDEX,TRIGGER,CREATE TEMPORARY TABLES,REFERENCES ON opencast.* TO 'admin'@'localhost' IDENTIFIED BY 'opencast_admin_password'; You can choose other names for the users and the database, and you should use a different password. In a distributed system, apart from 'username'@'localhost' (which would allow access from the local machine only), you should grant a external user access to the database by running the same command for a user like 'username'@'10.0.1.%' , where the 10.0.1.% specifies the IP range allowed to access the server with % being a wildcard for \"anything\". For more details on MariaDB/MySQL user creation have a look at any of the following links: MariaDB Reference Manual :: GRANT statement MySQL Reference Manual :: Adding User Accounts . Finally, leave the client and restart the database server to enable the new user(s): systemctl restart mariadb.service Step 2: Set up the Database Structure To set up the database structure you can (and should!) use the Opencast ddl scripts. You can find them in \u2026/docs/scripts/ddl/mysql5.sql or download them from GitHub. To import the database structure using the MariaDB client, switch to the directory that contains the mysql5.sql file, run the client with a user priviledged to create the database structure and switch to the database you want to use (e.g. opencast ): mysql -u root -p opencast Run the ddl script: mysql> source mysql5.sql; Alternatively, you can import the script directly from the command line: mysql -u root -p opencast < \u2026/docs/scripts/ddl/mysql5.sql Now, ensure the MariaDB wait_timeout in mariadb.cnf or mysql.cnf is bigger than org.opencastproject.db.jdbc.pool.max.idle.time in Opencast's custom.properties . Raising the max_connections in mariadb.cnf parameter might be required, too, depending on your installation's size. Reload the configuration into MariaDB, then connect to your database as user opencast and verify the values by executing SHOW VARIABLES LIKE %_timeout; . A MySQLNonTransientConnectionException , for instance \u201cA PooledConnection that has already signaled a Connection error is still in use\u201d, in your Opencast logs might indicate a problem with this configuration. Step 3: Configure Opencast The following changes must be made in \u2026/etc/custom.properties ( /etc/opencast/custom.properties in a package installation). Change the following configuration key (uncomment if necessary): org.opencastproject.db.ddl.generation=false If set to true, the database structure will be generated automatically. It works, but without all the database optimizations implemented in the DDL scripts used in the step 2. While convenient for development, you should never set this to true in a production environment. Configure Opencast to use MariaDB/MySQL: org.opencastproject.db.vendor=MySQL Configure Opencast to use the JDBC driver for MariaDB/MySQL: org.opencastproject.db.jdbc.driver=com.mysql.jdbc.Driver Configure the host where Opencast should find the database ( localhost ) and the database name ( opencast ). Adjust the names in this example to match your configuration: org.opencastproject.db.jdbc.url=jdbc:mysql://localhost/opencast Configure the username and password which Opencast should use to access the database: org.opencastproject.db.jdbc.user=opencast org.opencastproject.db.jdbc.pass=opencast_password","title":"Database"},{"location":"configuration/database/#database-configuration","text":"Opencast ships with embedded JDBC drivers for the H2, MySQL and MariaDB databases. The built-in H2 database is used by default and needs no configuration, but it is strongly recommended to use MariaDB for production. performance gain. Notice: H2 is neither supported for updates, nor for distributed systems. Use it for testing only!","title":"Database Configuration"},{"location":"configuration/database/#other-databases","text":"Running Opencast with PostgreSQL should be possible and there is some community support for this. While it should work, the support for this is unofficial and we cannot guarantee that every new feature is well tested on that platform. The EclipseLink JPA implementation which is used in Opencast supports other databases as well and it should be possible to attach other database engines.","title":"Other databases"},{"location":"configuration/database/#setting-up-mariadbmysql","text":"","title":"Setting up MariaDB/MySQL"},{"location":"configuration/database/#requirements","text":"Before following this guide, you should have: Installed the Opencast Core System Followed the Basic Configuration instructions","title":"Requirements"},{"location":"configuration/database/#step-0-set-up-mariadbmysql","text":"This step is not Opencast-specific and may be different depending on your scenario (e.g. if you want to have a dedicated database server). It shall only be a guide for people with no experience setting up MariaDB/MySQL to help them get started. MariaDB is used for this guide but if your distribution includes MySQL instead, the installation should be very much the same. First, install the MariaDB server. On RedHat-based systems, use: yum install mariadb mariadb-server Afterward, start the server and set it up to start automatically after each reboot: systemctl start mariadb.service systemctl enable mariadb.service Now you have MariaDB running, but without a properly configured root account (no password, etc.) which might pose a security risk. MariaDB includes a useful tool to secure your database server. You can launch it by executing (yes, it is still called mysql\u2026): mysql_secure_installation It will guide you through the steps of setting up a root account with password, etc.","title":"Step 0: Set-up MariaDB/MySQL"},{"location":"configuration/database/#step-1-create-an-opencast-database","text":"The first step, if you have not already done this, is to create a database for Opencast. You can use the following SQL code to to that. For executing the SQL, use the MariaDB/MySQL client (run mysql from your shell) or use a graphical tool like phpMyAdmin. For now, we will use the MySQL shell client and the default administrative (root) user. Launch the client with: mysql -u root -p You will be asked for the password of the user root. When logged in, you will end up in the MariaDB/MySQL shell. Next, create a database called opencast by executing: CREATE DATABASE opencast CHARACTER SET utf8 COLLATE utf8_general_ci; Then create a user opencast with a password and grant it all necessary rights: GRANT SELECT,INSERT,UPDATE,DELETE,CREATE TEMPORARY TABLES ON opencast.* TO 'opencast'@'localhost' IDENTIFIED BY 'opencast_password'; The rights granted here are all that is needed to run Opencast. To execute the migration scripts used to initialize (see next section) and upgrade the database schema upon releases of new versions of Opencast, you need more. If you don't want to do this using the root user (which normally can do anything), but with a dedicated user called admin for the sake of the example, you should grant that user the following rights: GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,ALTER,DROP,INDEX,TRIGGER,CREATE TEMPORARY TABLES,REFERENCES ON opencast.* TO 'admin'@'localhost' IDENTIFIED BY 'opencast_admin_password'; You can choose other names for the users and the database, and you should use a different password. In a distributed system, apart from 'username'@'localhost' (which would allow access from the local machine only), you should grant a external user access to the database by running the same command for a user like 'username'@'10.0.1.%' , where the 10.0.1.% specifies the IP range allowed to access the server with % being a wildcard for \"anything\". For more details on MariaDB/MySQL user creation have a look at any of the following links: MariaDB Reference Manual :: GRANT statement MySQL Reference Manual :: Adding User Accounts . Finally, leave the client and restart the database server to enable the new user(s): systemctl restart mariadb.service","title":"Step 1: Create an Opencast Database"},{"location":"configuration/database/#step-2-set-up-the-database-structure","text":"To set up the database structure you can (and should!) use the Opencast ddl scripts. You can find them in \u2026/docs/scripts/ddl/mysql5.sql or download them from GitHub. To import the database structure using the MariaDB client, switch to the directory that contains the mysql5.sql file, run the client with a user priviledged to create the database structure and switch to the database you want to use (e.g. opencast ): mysql -u root -p opencast Run the ddl script: mysql> source mysql5.sql; Alternatively, you can import the script directly from the command line: mysql -u root -p opencast < \u2026/docs/scripts/ddl/mysql5.sql Now, ensure the MariaDB wait_timeout in mariadb.cnf or mysql.cnf is bigger than org.opencastproject.db.jdbc.pool.max.idle.time in Opencast's custom.properties . Raising the max_connections in mariadb.cnf parameter might be required, too, depending on your installation's size. Reload the configuration into MariaDB, then connect to your database as user opencast and verify the values by executing SHOW VARIABLES LIKE %_timeout; . A MySQLNonTransientConnectionException , for instance \u201cA PooledConnection that has already signaled a Connection error is still in use\u201d, in your Opencast logs might indicate a problem with this configuration.","title":"Step 2: Set up the Database Structure"},{"location":"configuration/database/#step-3-configure-opencast","text":"The following changes must be made in \u2026/etc/custom.properties ( /etc/opencast/custom.properties in a package installation). Change the following configuration key (uncomment if necessary): org.opencastproject.db.ddl.generation=false If set to true, the database structure will be generated automatically. It works, but without all the database optimizations implemented in the DDL scripts used in the step 2. While convenient for development, you should never set this to true in a production environment. Configure Opencast to use MariaDB/MySQL: org.opencastproject.db.vendor=MySQL Configure Opencast to use the JDBC driver for MariaDB/MySQL: org.opencastproject.db.jdbc.driver=com.mysql.jdbc.Driver Configure the host where Opencast should find the database ( localhost ) and the database name ( opencast ). Adjust the names in this example to match your configuration: org.opencastproject.db.jdbc.url=jdbc:mysql://localhost/opencast Configure the username and password which Opencast should use to access the database: org.opencastproject.db.jdbc.user=opencast org.opencastproject.db.jdbc.pass=opencast_password","title":"Step 3: Configure Opencast"},{"location":"configuration/encoding/","text":"Encoding Profile Configuration A workflow defines which operations are applied to media ingested into Opencast and the order of these operations. An operation can be something general like \u201cencode this video\u201d. The encoding profiles then specify exactly how a media is ancoded, which filters are applied, which codecs are used and in which container these will be stored, \u2026 Opencast comes with a set of such profiles generating files for both online playback and download. These profiles are build to work for everyone, meaning that in most cases optimization can be done according to local needs. So modifying these profiles or building new ones often makes sense. This document will help you modify or augment Opencast's default encoding profiles for audio, video and still images. Default Profiles and Possible Settings This section contains some notes about the default profiles, explaining some thoughts behind those profiles and pointing at things you might want to change depending on your local set-up. A/V-Muxing: From lossless to safe The audio/video muxing ( profile.mux-av.work ) is applied if audio and video is sent to Opencast separately. The basic idea behind this is, to combine these separate files into one file which can later be converted in one step. Possible settings: If you get an audio and a video file separately, it is possible to just copy the streams and put them together into a new file. This is very fast (you only have to copy the streams) and most importantly, it is lossless, as no re-encoding is done. The question is: What a/v container format can/should you use for such an operation. You can try to use the video container the input video came in and just add the audio. This means that you will never have an unexpected video container you don't know of. I.e. if you put an .mp4 video in, it still uses and .mp4 container after musing, etc. This might, however, lead to problems if you throw in an audio file that cannot be muxed in the specific container format (i.e. you have a FLAC audio file and an FLV container). This is, what Opencast does at the moment. To circumvent the container problem, we could also use a container format which can hold almost everything (i.e. mkv) regardless of the input. This would mean that Opencast can handle more combinations of a/v streams but you will always end up with a Matroska file after muxing. Of cause, you can then encode it to mp4, etc. later on. The safest option for muxing is to always re-encode the streams. It is far slower than re-using the existing bit streams. It also, always means a quality loss. Create an Encoding Profile This section will help you to understand how you can modify an existing profile or create a completely new one. Creating a new encoding profile is a matter of creating a configuration file and placing it in the encoding profiles watch folder. Encoding Profile Folder The <config_dir>/encoding folder allows you to quickly augment Opencast's existing behavior, simply by modifying or adding new configuration files. The file names should follow the pattern *.properties . The Encoding Profile Encoding profiles consist of a set of key-value pairs that conform to the following pattern: profile.<name>.<context>.<property> = <value> For example: profile.mp4.http.name = Enocde Mp4 files for download All profiles should have the following properties: .name .input = [audio|visual|stream|image] .output = [audio|visual|stream|image] .suffix .ffmpeg.command For example: // My audio/video encoding profile profile.my-av-profile.http.name = my audio/video encoding profile profile.my-av-profile.http.input = visual profile.my-av-profile.http.output = visual profile.my-av-profile.http.suffix = -encoded.enc profile.my-av-profile.http.ffmpeg.command = -i #{in.video.path} -c:v venc -c:a aenc #{out.dir}/#{out.name}#{out.suffix} The most important part of this profile is the ffmpeg.command . This line specifies FFmpeg command line options using #{expression} for string replacement. FFmpeg To create a new profile you have basically one task to do: Find an appropriate FFmpeg command line for whatever you want to do. For more information about FFmpeg, its options and how you can build FFmpeg with additional functionality have a look at the Official FFmpeg Wiki . For trying out new encoding settings, just call FFmpeg from the command line. Using a Profile Once defined, use your encoding profile in your workflow by setting the encoding-profile property to the profiles name: <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode presenter using my audio/video encoding profile\"> <configurations> <configuration key=\"source-flavor\">presenter/work</configuration> <configuration key=\"target-flavor\">presenter/delivery</configuration> <configuration key=\"target-tags\">rss, atom, captioning</configuration> <configuration key=\"encoding-profile\">my-av-profile.http</configuration> </configuration> </operation> Have a look at the Workflow Configuration section for more details about workflows and workflow operations.","title":"Encoding"},{"location":"configuration/encoding/#encoding-profile-configuration","text":"A workflow defines which operations are applied to media ingested into Opencast and the order of these operations. An operation can be something general like \u201cencode this video\u201d. The encoding profiles then specify exactly how a media is ancoded, which filters are applied, which codecs are used and in which container these will be stored, \u2026 Opencast comes with a set of such profiles generating files for both online playback and download. These profiles are build to work for everyone, meaning that in most cases optimization can be done according to local needs. So modifying these profiles or building new ones often makes sense. This document will help you modify or augment Opencast's default encoding profiles for audio, video and still images.","title":"Encoding Profile Configuration"},{"location":"configuration/encoding/#default-profiles-and-possible-settings","text":"This section contains some notes about the default profiles, explaining some thoughts behind those profiles and pointing at things you might want to change depending on your local set-up.","title":"Default Profiles and Possible Settings"},{"location":"configuration/encoding/#av-muxing-from-lossless-to-safe","text":"The audio/video muxing ( profile.mux-av.work ) is applied if audio and video is sent to Opencast separately. The basic idea behind this is, to combine these separate files into one file which can later be converted in one step. Possible settings: If you get an audio and a video file separately, it is possible to just copy the streams and put them together into a new file. This is very fast (you only have to copy the streams) and most importantly, it is lossless, as no re-encoding is done. The question is: What a/v container format can/should you use for such an operation. You can try to use the video container the input video came in and just add the audio. This means that you will never have an unexpected video container you don't know of. I.e. if you put an .mp4 video in, it still uses and .mp4 container after musing, etc. This might, however, lead to problems if you throw in an audio file that cannot be muxed in the specific container format (i.e. you have a FLAC audio file and an FLV container). This is, what Opencast does at the moment. To circumvent the container problem, we could also use a container format which can hold almost everything (i.e. mkv) regardless of the input. This would mean that Opencast can handle more combinations of a/v streams but you will always end up with a Matroska file after muxing. Of cause, you can then encode it to mp4, etc. later on. The safest option for muxing is to always re-encode the streams. It is far slower than re-using the existing bit streams. It also, always means a quality loss.","title":"A/V-Muxing: From lossless to safe"},{"location":"configuration/encoding/#create-an-encoding-profile","text":"This section will help you to understand how you can modify an existing profile or create a completely new one. Creating a new encoding profile is a matter of creating a configuration file and placing it in the encoding profiles watch folder.","title":"Create an Encoding Profile"},{"location":"configuration/encoding/#encoding-profile-folder","text":"The <config_dir>/encoding folder allows you to quickly augment Opencast's existing behavior, simply by modifying or adding new configuration files. The file names should follow the pattern *.properties .","title":"Encoding Profile Folder"},{"location":"configuration/encoding/#the-encoding-profile","text":"Encoding profiles consist of a set of key-value pairs that conform to the following pattern: profile.<name>.<context>.<property> = <value> For example: profile.mp4.http.name = Enocde Mp4 files for download All profiles should have the following properties: .name .input = [audio|visual|stream|image] .output = [audio|visual|stream|image] .suffix .ffmpeg.command For example: // My audio/video encoding profile profile.my-av-profile.http.name = my audio/video encoding profile profile.my-av-profile.http.input = visual profile.my-av-profile.http.output = visual profile.my-av-profile.http.suffix = -encoded.enc profile.my-av-profile.http.ffmpeg.command = -i #{in.video.path} -c:v venc -c:a aenc #{out.dir}/#{out.name}#{out.suffix} The most important part of this profile is the ffmpeg.command . This line specifies FFmpeg command line options using #{expression} for string replacement.","title":"The Encoding Profile"},{"location":"configuration/encoding/#ffmpeg","text":"To create a new profile you have basically one task to do: Find an appropriate FFmpeg command line for whatever you want to do. For more information about FFmpeg, its options and how you can build FFmpeg with additional functionality have a look at the Official FFmpeg Wiki . For trying out new encoding settings, just call FFmpeg from the command line.","title":"FFmpeg"},{"location":"configuration/encoding/#using-a-profile","text":"Once defined, use your encoding profile in your workflow by setting the encoding-profile property to the profiles name: <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode presenter using my audio/video encoding profile\"> <configurations> <configuration key=\"source-flavor\">presenter/work</configuration> <configuration key=\"target-flavor\">presenter/delivery</configuration> <configuration key=\"target-tags\">rss, atom, captioning</configuration> <configuration key=\"encoding-profile\">my-av-profile.http</configuration> </configuration> </operation> Have a look at the Workflow Configuration section for more details about workflows and workflow operations.","title":"Using a Profile"},{"location":"configuration/external-api/","text":"External API Configuration The External API is an integral part of Opencast and therefore does not need to be enabled. To be able to access the External API, you need to configure a user that is authorized to do so. Perform the following steps to get the External API running: Enable basic authentication (see section Authentication) Create a new user or choose an existing user (administrative user interface) Authorize the user to access the External API (see section Authorization) Test whether access works (see section Testing) Authentication The External API currenlty only supports basic authentication. To enable basic authentication, uncomment the following blocks in /etc/security/mh_default.org : <!-- Basic authentication <sec:custom-filter after=\"BASIC_AUTH_FILTER\" ref=\"basicAuthenticationFilter\" /> --> <!-- Basic authentication <bean id=\"basicEntryPoint\" class=\"org.springframework.security.web.authentication.www.BasicAuthenticationEntryPoint\"> <property name=\"realmName\" value=\"Opencast\"/> </bean> --> <!-- Basic authentication <bean id=\"basicAuthenticationFilter\" class=\"org.springframework.security.web.authentication.www.BasicAuthenticationFilter\"> <property name=\"authenticationManager\" ref=\"authenticationManager\"/> <property name=\"authenticationEntryPoint\" ref=\"basicEntryPoint\"/> </bean> --> Note: Since basic authentication involves sending unencrypted passwords over the network, it is strongly recommended to use HTTPS. Authorization The External API supports fine-grained access control on request level allowing it to be tailored to your specific needs. A number of roles are used to authorize access to individual endpoints. Those roles can be configured directly in the Opencast administrative user interface. Note: Users owning the role ROLE_ADMIN have full access to the External API. Base API ROLE METHOD URL ROLE_API GET /api /api/info/* /api/info/me/* /api/version /api/version/* Events API ROLE METHOD URL ROLE_API_EVENTS_CREATE POST /api/events ROLE_API_EVENTS_VIEW GET /api/events /api/events/* ROLE_API_EVENTS_EDIT PUT POST /api/events/* /api/events/* ROLE_API_EVENTS_DELETE DELETE /api/events/* ROLE_API_EVENTS_ACL_VIEW GET /api/events/*/acl ROLE_API_EVENTS_ACL_EDIT PUT POST /api/events/*/acl /api/events/*/acl/* ROLE_API_EVENTS_ACL_DELETE DELETE /api/events/*/acl/*/* ROLE_API_EVENTS_MEDIA_VIEW GET /api/events/*/media /api/events/*/media/* ROLE_API_EVENTS_METADATA_VIEW GET /api/events/*/metadata /api/events/*/metadata/* ROLE_API_EVENTS_METADATA_EDIT PUT /api/events/*/metadata /api/events/*/metadata/* ROLE_API_EVENTS_METADATA_DELETE DELETE /api/events/*/metadata /api/events/*/metadata/* ROLE_API_EVENTS_PUBLICATIONS_VIEW GET /api/events/*/publications /api/events/*/publications/* ROLE_API_EVENTS_SCHEDULING_EDIT PUT /api/events/*/scheduling ROLE_API_EVENTS_SCHEDULING_VIEW GET /api/events/*/scheduling Series API ROLE METHOD URL ROLE_API_SERIES_CREATE POST /api/series ROLE_API_SERIES_VIEW GET /api/series /api/series/* ROLE_API_SERIES_EDIT PUT /api/series/* ROLE_API_SERIES_ACL_VIEW GET /api/series/*/acl ROLE_API_SERIES_ACL_EDIT PUT /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_METADATA_VIEW GET /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_METADATA_EDIT PUT /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_METADATA_DELETE DELETE /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_PROPERTIES_VIEW GET /api/series/*/properties ROLE_API_SERIES_PROPERTIES_EDIT PUT /api/series/*/properties ROLE_API_SERIES_DELETE DELETE /api/series/* Statistics API ROLE METHOD URL ROLE_API_STATISTICS_VIEW GET /api/statistics/providers /api/statistics/providers/* ROLE_API_STATISTICS_VIEW POST /api/statistics/data/query Groups API ROLE METHOD URL ROLE_API_GROUPS_CREATE POST /api/groups ROLE_API_GROUPS_VIEW GET /api/groups /api/groups/* ROLE_API_GROUPS_EDIT PUT POST /api/groups/* /api/groups/*/members/* ROLE_API_GROUPS_DELETE DELETE /api/groups/* Security API ROLE METHOD URL ROLE_API_SECURITY_EDIT POST /api/security/sign Agents API ROLE METHOD URL ROLE_API_CAPTURE_AGENTS_VIEW GET /api/agents /api/agents/* Administrative API ROLE METHOD URL ROLE_ADMIN POST /api/recreateIndex Workflow API ROLE METHOD URL ROLE_API_WORKFLOW_INSTANCE_CREATE POST /api/workflow ROLE_API_WORKFLOW_INSTANCE_VIEW GET /api/workflow /api/workflow/* ROLE_API_WORKFLOW_INSTANCE_EDIT PUT /api/workflow/* ROLE_API_WORKFLOW_INSTANCE_DELETE DELETE /api/workflow/* ROLE_API_WORKFLOW_DEFINITION_VIEW GET /api/workflow-definitions /api/workflow-definitions/* User- and Role-switching The External API supports user- and role-switching, i.e. it is possible to perform requests on behalf of another user or role. The be able to perform this kind of requests, the user doing the actual requests needs to own ROLE_SUDO. For more details on this API, please take a look at the developer documentation under External API. Testing curl -u <api-user>:<api-user-passowrd> <admin-node>/api/info/me should return a JSON containing information about the user api-user . Accessing Distribution Artefacts A major use case of the External API is to provide External Applications secure access to distribution artefacts. For this purpose, Opencast comes with a special workflow operation: WOH publish-configure (see ConfigurablePublishWorkflowOperationHandler ) creates publication elements that do not just contain a single URL to the publication channel, but also contain URLs for each of the attachments and tracks that have been published. Note: Secure access to distribution artefacts requires stream security to be enabled, see Stream Security Configuration .","title":"External API"},{"location":"configuration/external-api/#external-api-configuration","text":"The External API is an integral part of Opencast and therefore does not need to be enabled. To be able to access the External API, you need to configure a user that is authorized to do so. Perform the following steps to get the External API running: Enable basic authentication (see section Authentication) Create a new user or choose an existing user (administrative user interface) Authorize the user to access the External API (see section Authorization) Test whether access works (see section Testing)","title":"External API Configuration"},{"location":"configuration/external-api/#authentication","text":"The External API currenlty only supports basic authentication. To enable basic authentication, uncomment the following blocks in /etc/security/mh_default.org : <!-- Basic authentication <sec:custom-filter after=\"BASIC_AUTH_FILTER\" ref=\"basicAuthenticationFilter\" /> --> <!-- Basic authentication <bean id=\"basicEntryPoint\" class=\"org.springframework.security.web.authentication.www.BasicAuthenticationEntryPoint\"> <property name=\"realmName\" value=\"Opencast\"/> </bean> --> <!-- Basic authentication <bean id=\"basicAuthenticationFilter\" class=\"org.springframework.security.web.authentication.www.BasicAuthenticationFilter\"> <property name=\"authenticationManager\" ref=\"authenticationManager\"/> <property name=\"authenticationEntryPoint\" ref=\"basicEntryPoint\"/> </bean> --> Note: Since basic authentication involves sending unencrypted passwords over the network, it is strongly recommended to use HTTPS.","title":"Authentication"},{"location":"configuration/external-api/#authorization","text":"The External API supports fine-grained access control on request level allowing it to be tailored to your specific needs. A number of roles are used to authorize access to individual endpoints. Those roles can be configured directly in the Opencast administrative user interface. Note: Users owning the role ROLE_ADMIN have full access to the External API. Base API ROLE METHOD URL ROLE_API GET /api /api/info/* /api/info/me/* /api/version /api/version/* Events API ROLE METHOD URL ROLE_API_EVENTS_CREATE POST /api/events ROLE_API_EVENTS_VIEW GET /api/events /api/events/* ROLE_API_EVENTS_EDIT PUT POST /api/events/* /api/events/* ROLE_API_EVENTS_DELETE DELETE /api/events/* ROLE_API_EVENTS_ACL_VIEW GET /api/events/*/acl ROLE_API_EVENTS_ACL_EDIT PUT POST /api/events/*/acl /api/events/*/acl/* ROLE_API_EVENTS_ACL_DELETE DELETE /api/events/*/acl/*/* ROLE_API_EVENTS_MEDIA_VIEW GET /api/events/*/media /api/events/*/media/* ROLE_API_EVENTS_METADATA_VIEW GET /api/events/*/metadata /api/events/*/metadata/* ROLE_API_EVENTS_METADATA_EDIT PUT /api/events/*/metadata /api/events/*/metadata/* ROLE_API_EVENTS_METADATA_DELETE DELETE /api/events/*/metadata /api/events/*/metadata/* ROLE_API_EVENTS_PUBLICATIONS_VIEW GET /api/events/*/publications /api/events/*/publications/* ROLE_API_EVENTS_SCHEDULING_EDIT PUT /api/events/*/scheduling ROLE_API_EVENTS_SCHEDULING_VIEW GET /api/events/*/scheduling Series API ROLE METHOD URL ROLE_API_SERIES_CREATE POST /api/series ROLE_API_SERIES_VIEW GET /api/series /api/series/* ROLE_API_SERIES_EDIT PUT /api/series/* ROLE_API_SERIES_ACL_VIEW GET /api/series/*/acl ROLE_API_SERIES_ACL_EDIT PUT /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_METADATA_VIEW GET /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_METADATA_EDIT PUT /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_METADATA_DELETE DELETE /api/series/*/metadata /api/series/*/metadata/* ROLE_API_SERIES_PROPERTIES_VIEW GET /api/series/*/properties ROLE_API_SERIES_PROPERTIES_EDIT PUT /api/series/*/properties ROLE_API_SERIES_DELETE DELETE /api/series/* Statistics API ROLE METHOD URL ROLE_API_STATISTICS_VIEW GET /api/statistics/providers /api/statistics/providers/* ROLE_API_STATISTICS_VIEW POST /api/statistics/data/query Groups API ROLE METHOD URL ROLE_API_GROUPS_CREATE POST /api/groups ROLE_API_GROUPS_VIEW GET /api/groups /api/groups/* ROLE_API_GROUPS_EDIT PUT POST /api/groups/* /api/groups/*/members/* ROLE_API_GROUPS_DELETE DELETE /api/groups/* Security API ROLE METHOD URL ROLE_API_SECURITY_EDIT POST /api/security/sign Agents API ROLE METHOD URL ROLE_API_CAPTURE_AGENTS_VIEW GET /api/agents /api/agents/* Administrative API ROLE METHOD URL ROLE_ADMIN POST /api/recreateIndex Workflow API ROLE METHOD URL ROLE_API_WORKFLOW_INSTANCE_CREATE POST /api/workflow ROLE_API_WORKFLOW_INSTANCE_VIEW GET /api/workflow /api/workflow/* ROLE_API_WORKFLOW_INSTANCE_EDIT PUT /api/workflow/* ROLE_API_WORKFLOW_INSTANCE_DELETE DELETE /api/workflow/* ROLE_API_WORKFLOW_DEFINITION_VIEW GET /api/workflow-definitions /api/workflow-definitions/* User- and Role-switching The External API supports user- and role-switching, i.e. it is possible to perform requests on behalf of another user or role. The be able to perform this kind of requests, the user doing the actual requests needs to own ROLE_SUDO. For more details on this API, please take a look at the developer documentation under External API.","title":"Authorization"},{"location":"configuration/external-api/#testing","text":"curl -u <api-user>:<api-user-passowrd> <admin-node>/api/info/me should return a JSON containing information about the user api-user .","title":"Testing"},{"location":"configuration/external-api/#accessing-distribution-artefacts","text":"A major use case of the External API is to provide External Applications secure access to distribution artefacts. For this purpose, Opencast comes with a special workflow operation: WOH publish-configure (see ConfigurablePublishWorkflowOperationHandler ) creates publication elements that do not just contain a single URL to the publication channel, but also contain URLs for each of the attachments and tracks that have been published. Note: Secure access to distribution artefacts requires stream security to be enabled, see Stream Security Configuration .","title":"Accessing Distribution Artefacts"},{"location":"configuration/inbox/","text":"InboxScannerService Overview Besides ingesting media packages using the REST service of the IngestService, dedicated inbox directories located in the file system can be scanned by Opencast. This, for example, allows adding media packages to Opencast by copying it to a specific location using scripting/SFTP without the need for any HTTP traffic. Opencast periodically scans the specified location for new files. Each directory may result in digest for a separate organization or with a different default workflow. Step 1: Configure an InboxScannerService Adjust etc/org.opencastproject.ingest.scanner.InboxScannerService-inbox.cfg . The -inbox suffix of the file name is variable and multiple files can be created with different settings for different directories to be watched. Step 2: Testing the inbox In order to test the inbox scanner service, either put valid media package zip or a single media file into the scanned directory. Note that even if the poll interval is small, it may take a little longer until the media package is visible in the admin interface because extracting and/or copying the media files will take some time. Example media package Media packages contain media files and metadata files describing them. Opencast is able to generate media packages using the ZipWorkflowOperation . Create the follwing files: manifest.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <mediapackage xmlns:oc=\"http://mediapackage.opencastporject.org\"> <title>A media package courtesy by the inbox scanner.</title> <media> <track id=\"track-1\" type=\"presenter/source\"> <url>presenter.mkv</url> </track> <track id=\"track-2\" type=\"presentation/source\"> <url>presentation.mkv</url> </track> </media> <metadata> <catalog id=\"catalog-1\" type=\"dublincore/episode\"> <mimetype>text/xml</mimetype> <url>episode.xml</url> </catalog> </metadata> </mediapackage> Note: You can create a valid empty media package using the /ingest/createMediaPackage REST endpoint. episode.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <dublincore xmlns=\"http://www.opencastproject.org/xsd/1.0/dublincore/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:oc=\"http://www.opencastproject.org/matterhorn\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance/\" xsi:schemaLocation=\"http://www.opencastproject.org http://www.opencastproject.org/schema.xsd\"> <dcterms:title>A media package courtesy by the inbox scanner.</dcterms:title> </dublincore> presentation.mkv binary video file of your choice presenter.mkv binary video file of your choice Then run: zip -j --compression-method store oc-package.zip /path/to/files/* And move the zip media package file to your inbox directory: mv oc-package.zip /path/to/inbox/ You will now see Opencast working on your file: admin_1 | 2016-11-22 15:04:54,631 | INFO | (Ingestor:114) - Install [53e6bda0 thread=db] package.zip admin_1 | 2016-11-22 15:04:54,634 | INFO | (IngestServiceImpl:433) - Ingesting zipped mediapackage admin_1 | 2016-11-22 15:04:55,296 | INFO | (IngestServiceImpl:469) - Storing zip entry 17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360.mkv in working file repository collection '17701' admin_1 | 2016-11-22 15:06:30,059 | INFO | (IngestServiceImpl:482) - Zip entry 17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360.mkv stored at https://opencast.example.com/files/collection/17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360_1.mkv admin_1 | 2016-11-22 15:06:30,272 | INFO | (IngestServiceImpl:469) - Storing zip entry 17701/episode.xml in working file repository collection '17701' admin_1 | 2016-11-22 15:06:30,287 | INFO | (IngestServiceImpl:482) - Zip entry 17701/episode.xml stored at https://opencast.example.com/files/collection/17701/episode_2.xml admin_1 | 2016-11-22 15:06:30,314 | INFO | (IngestServiceImpl:516) - Ingesting mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 is named 'A media package courtesy by the inbox scanner.' admin_1 | 2016-11-22 15:06:30,315 | INFO | (IngestServiceImpl:530) - Ingested mediapackage element 77bf879f-817e-403c-b35e-fd97dee31261/track-1 is located at http://opencast.example.com/files/collection/17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360_1.mkv admin_1 | 2016-11-22 15:06:30,338 | INFO | (IngestServiceImpl:530) - Ingested mediapackage element 77bf879f-817e-403c-b35e-fd97dee31261/catalog-1 is located at http://opencast.example.com/files/collection/17701/episode_2.xml admin_1 | 2016-11-22 15:06:30,339 | INFO | (IngestServiceImpl:544) - Initiating processing of ingested mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 admin_1 | 2016-11-22 15:06:30,340 | INFO | (IngestServiceImpl:1068) - Starting a new workflow with ingested mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 based on workflow definition 'schedule-and-upload' admin_1 | 2016-11-22 15:06:30,340 | INFO | (IngestServiceImpl:1359) - Ingested mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 is processed using workflow template 'schedule-and-upload', specified during ingest admin_1 | 2016-11-22 15:06:30,354 | INFO | (IngestServiceImpl:1120) - Starting new workflow with ingested mediapackage '77bf879f-817e-403c-b35e-fd97dee31261' using the specified template 'schedule-and-upload' admin_1 | 2016-11-22 15:06:32,229 | INFO | (IngestServiceImpl:546) - Ingest of mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 done admin_1 | 2016-11-22 15:06:32,303 | INFO | (Ingestor$1$1:130) - Ingested package.zip as a mediapackage from inbox admin_1 | 2016-11-22 15:06:33,627 | INFO | (WorkflowServiceImpl:843) - [>a508b423] Scheduling workflow 17702 for execution admin_1 | 2016-11-22 15:06:38,720 | INFO | (DefaultsWorkflowOperationHandler:120) - Configuration key 'flagForCutting' of ... ... and the workflow continues Logs produced by Opencast 2.2.2 Docker","title":"Inbox"},{"location":"configuration/inbox/#inboxscannerservice","text":"","title":"InboxScannerService"},{"location":"configuration/inbox/#overview","text":"Besides ingesting media packages using the REST service of the IngestService, dedicated inbox directories located in the file system can be scanned by Opencast. This, for example, allows adding media packages to Opencast by copying it to a specific location using scripting/SFTP without the need for any HTTP traffic. Opencast periodically scans the specified location for new files. Each directory may result in digest for a separate organization or with a different default workflow.","title":"Overview"},{"location":"configuration/inbox/#step-1-configure-an-inboxscannerservice","text":"Adjust etc/org.opencastproject.ingest.scanner.InboxScannerService-inbox.cfg . The -inbox suffix of the file name is variable and multiple files can be created with different settings for different directories to be watched.","title":"Step 1: Configure an InboxScannerService"},{"location":"configuration/inbox/#step-2-testing-the-inbox","text":"In order to test the inbox scanner service, either put valid media package zip or a single media file into the scanned directory. Note that even if the poll interval is small, it may take a little longer until the media package is visible in the admin interface because extracting and/or copying the media files will take some time.","title":"Step 2: Testing the inbox"},{"location":"configuration/inbox/#example-media-package","text":"Media packages contain media files and metadata files describing them. Opencast is able to generate media packages using the ZipWorkflowOperation . Create the follwing files: manifest.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <mediapackage xmlns:oc=\"http://mediapackage.opencastporject.org\"> <title>A media package courtesy by the inbox scanner.</title> <media> <track id=\"track-1\" type=\"presenter/source\"> <url>presenter.mkv</url> </track> <track id=\"track-2\" type=\"presentation/source\"> <url>presentation.mkv</url> </track> </media> <metadata> <catalog id=\"catalog-1\" type=\"dublincore/episode\"> <mimetype>text/xml</mimetype> <url>episode.xml</url> </catalog> </metadata> </mediapackage> Note: You can create a valid empty media package using the /ingest/createMediaPackage REST endpoint. episode.xml <?xml version=\"1.0\" encoding=\"utf-8\"?> <dublincore xmlns=\"http://www.opencastproject.org/xsd/1.0/dublincore/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:oc=\"http://www.opencastproject.org/matterhorn\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance/\" xsi:schemaLocation=\"http://www.opencastproject.org http://www.opencastproject.org/schema.xsd\"> <dcterms:title>A media package courtesy by the inbox scanner.</dcterms:title> </dublincore> presentation.mkv binary video file of your choice presenter.mkv binary video file of your choice Then run: zip -j --compression-method store oc-package.zip /path/to/files/* And move the zip media package file to your inbox directory: mv oc-package.zip /path/to/inbox/ You will now see Opencast working on your file: admin_1 | 2016-11-22 15:04:54,631 | INFO | (Ingestor:114) - Install [53e6bda0 thread=db] package.zip admin_1 | 2016-11-22 15:04:54,634 | INFO | (IngestServiceImpl:433) - Ingesting zipped mediapackage admin_1 | 2016-11-22 15:04:55,296 | INFO | (IngestServiceImpl:469) - Storing zip entry 17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360.mkv in working file repository collection '17701' admin_1 | 2016-11-22 15:06:30,059 | INFO | (IngestServiceImpl:482) - Zip entry 17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360.mkv stored at https://opencast.example.com/files/collection/17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360_1.mkv admin_1 | 2016-11-22 15:06:30,272 | INFO | (IngestServiceImpl:469) - Storing zip entry 17701/episode.xml in working file repository collection '17701' admin_1 | 2016-11-22 15:06:30,287 | INFO | (IngestServiceImpl:482) - Zip entry 17701/episode.xml stored at https://opencast.example.com/files/collection/17701/episode_2.xml admin_1 | 2016-11-22 15:06:30,314 | INFO | (IngestServiceImpl:516) - Ingesting mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 is named 'A media package courtesy by the inbox scanner.' admin_1 | 2016-11-22 15:06:30,315 | INFO | (IngestServiceImpl:530) - Ingested mediapackage element 77bf879f-817e-403c-b35e-fd97dee31261/track-1 is located at http://opencast.example.com/files/collection/17701/presenter_c20e7623_81e3_4a78_8738_f7a619141360_1.mkv admin_1 | 2016-11-22 15:06:30,338 | INFO | (IngestServiceImpl:530) - Ingested mediapackage element 77bf879f-817e-403c-b35e-fd97dee31261/catalog-1 is located at http://opencast.example.com/files/collection/17701/episode_2.xml admin_1 | 2016-11-22 15:06:30,339 | INFO | (IngestServiceImpl:544) - Initiating processing of ingested mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 admin_1 | 2016-11-22 15:06:30,340 | INFO | (IngestServiceImpl:1068) - Starting a new workflow with ingested mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 based on workflow definition 'schedule-and-upload' admin_1 | 2016-11-22 15:06:30,340 | INFO | (IngestServiceImpl:1359) - Ingested mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 is processed using workflow template 'schedule-and-upload', specified during ingest admin_1 | 2016-11-22 15:06:30,354 | INFO | (IngestServiceImpl:1120) - Starting new workflow with ingested mediapackage '77bf879f-817e-403c-b35e-fd97dee31261' using the specified template 'schedule-and-upload' admin_1 | 2016-11-22 15:06:32,229 | INFO | (IngestServiceImpl:546) - Ingest of mediapackage 77bf879f-817e-403c-b35e-fd97dee31261 done admin_1 | 2016-11-22 15:06:32,303 | INFO | (Ingestor$1$1:130) - Ingested package.zip as a mediapackage from inbox admin_1 | 2016-11-22 15:06:33,627 | INFO | (WorkflowServiceImpl:843) - [>a508b423] Scheduling workflow 17702 for execution admin_1 | 2016-11-22 15:06:38,720 | INFO | (DefaultsWorkflowOperationHandler:120) - Configuration key 'flagForCutting' of ... ... and the workflow continues Logs produced by Opencast 2.2.2 Docker","title":"Example media package"},{"location":"configuration/listproviders/","text":"List Providers Opencast supports fully configurable key-value lists. To add a new list, simply create a file with the extension .properties in etc/listproviders . The list will be loaded or updated automatically. The Java properties file format is used with the following special keys to configure the list: Key Type Description Mandatory Default list.name String The list's unique identifier within a tenant yes n/a list.default String The name of the default key no n/a list.translatable Boolean Whether the values are supposed to be translatable no false list.org String The organisation ID no \"*\" Note that it is up to the client to handle the keys list.default and list.translatable . Multi-Tenancy The key list.org can be used to configure lists for specific tenants in multi-tenant setups. It defaults to * which means that the list is available for all tenants. The following logic is used to locate a list with a given list name LISTNAME : Return the list LISTNAME specific to the current tenant If not found, return the list LISTNAME available for all tenants If not found, return no list While the filename of the list does not affect the list itself, we recommend to include the organisation identifier in the filename. Example /etc/listproviders/mylist-org-a.properties list.name=MYLIST key=value /etc/listproviders/mylist-org-b.properties list.name=MYLIST list.org=org-b key-org-b=value-org-b On org-b , the key-value pair for the list MYLIST is [\"key-org-b\", \"value-org-b\"] due to the tenant specific configuration. On org-a , the key-value pair for the list MYLIST is [\"key\", \"value\"] . Since there is no tenant specific configuration for org-a , the defaults are used.","title":"List Providers"},{"location":"configuration/listproviders/#list-providers","text":"Opencast supports fully configurable key-value lists. To add a new list, simply create a file with the extension .properties in etc/listproviders . The list will be loaded or updated automatically. The Java properties file format is used with the following special keys to configure the list: Key Type Description Mandatory Default list.name String The list's unique identifier within a tenant yes n/a list.default String The name of the default key no n/a list.translatable Boolean Whether the values are supposed to be translatable no false list.org String The organisation ID no \"*\" Note that it is up to the client to handle the keys list.default and list.translatable .","title":"List Providers"},{"location":"configuration/listproviders/#multi-tenancy","text":"The key list.org can be used to configure lists for specific tenants in multi-tenant setups. It defaults to * which means that the list is available for all tenants. The following logic is used to locate a list with a given list name LISTNAME : Return the list LISTNAME specific to the current tenant If not found, return the list LISTNAME available for all tenants If not found, return no list While the filename of the list does not affect the list itself, we recommend to include the organisation identifier in the filename.","title":"Multi-Tenancy"},{"location":"configuration/listproviders/#example","text":"/etc/listproviders/mylist-org-a.properties list.name=MYLIST key=value /etc/listproviders/mylist-org-b.properties list.name=MYLIST list.org=org-b key-org-b=value-org-b On org-b , the key-value pair for the list MYLIST is [\"key-org-b\", \"value-org-b\"] due to the tenant specific configuration. On org-a , the key-value pair for the list MYLIST is [\"key\", \"value\"] . Since there is no tenant specific configuration for org-a , the defaults are used.","title":"Example"},{"location":"configuration/load/","text":"Load Configuration This guide will help you to set up the load configuration settings which are strongly recommended for each Opencast installation. These settings control how many jobs are running on your various hardware nodes. These settings can be left at their defaults initially, but as your installation grows you will likely wish to fine-tune these to get the best performance you can out of your hardware. Background: What is a load value Every job obviously imposes a certain amount of load on its processing system, the question is how can we quantify this? The settings this document will walk you through are estimates of the load placed on your system(s) by each job type. This means that every individual instance of that job type will count for a certain amount of load, and Opencast will refuse to process more than a certain configurable amount of load at any given time on a given node. These loads are tracked on a per-node basis, so a job running on one node imposes no load on another. As an example, say we have a worker with 8 cores. With Opencast 1.x all jobs, even expensive jobs like encoding, had an effective load value of 1.0. This meant that Opencast would schedule up to 8 encodes on worker 1! Obviously this is not ideal, since most encoding jobs consume multiple cores. Since Opencast 2.1 you can now specify on an encoding profile level how much load is imposed on a node. Likewise, all other jobs (video segmentation, publishing, etc) also now have configurable loads. Job loads can be any floating point value between 0.0, and Java's MAXFLOAT. Fractional loads are supported, since many of the jobs that Opencast spawns as a regular part of its workflows are very small. There is no sanity checking for the configured loads, aside from assuring they are not negative. This means that improperly set load values can cause deadlocks! Fortunately, this is easy to fix. See Troubleshooting for more details. Step 1: Determine your load values This is a very subjective process, but is arguably the most imporant: How much load does each job and encoding profile add to your system? We have tried our best to set useful loads for each job, however these are only estimates. If your installation has, for example, hardware assisted encoding then your encoding jobs may be very inexpensive. In general, it is safe to assume that the first load value from the output of uptime is a good estimate of the load imposed by a job. Note: These job loads are specific for each node in the cluster. This means that for any given job, each node can have a different load value associated. For instance, if worker A has no job load specified for its encoding profiles, and worker B has job loads specified then any encoding jobs created by A will have the default load (1.5), and jobs created by B will have a different, presumably higher load. There are edge cases where this may be useful, but in most cases this will only cause confusion. It is therefore highly recommended that these settings be put into your configuration management system, and be applied on a cluster level to ensure consistency across all nodes. Step 2: Setting the load values for system jobs Each Opencast instance has its own maximum load. By default this is set to the number of CPU cores present in the system. If you wish to change this, set the org.opencastproject.server.maxload key in config.properties to the maximum load you want this node to accept. Keep in mind that exceeding the number of CPU cores present in the system is not recommended. The load values for the non-encoding jobs are set in the configuration files in the etc directory. Search this directory for files that contain the string job.load to find the relevant configuration keys. These configuration keys control the load for each job type. For example, the job.load.download.distribute configuration key controls the load placed on the system when a download distribution job is running. Note: Ingest jobs are a special case in Opencast. Because of their immediate nature there is no way to limit the number of running jobs. However, these jobs will block other jobs from running on the ingest/admin nodes if enough ingests running concurrently. Step 3: Setting the load values for encoding profiles Each encoding profile can have a load value associated with it. By default, we have not set any, which means that the default value of 1.5 is used. To set the load associated with a profile, you simply add a .jobload key to the profile. For example, the composite encoding profile is prefixed with profile.composite.http . If we want to set a different job load than the default, we would create the profile.composite.http.jobload key, and set it to an appropriate job value. Step 4: Restart Opencast Many of these configuration files are only read on startup, so restarting Opencast is strongly recommended. Troubleshooting Help, my system has deadlocked, or there are jobs which are always queued even if the system is otherwise idle This can be caused by setting a job weight that exceeds the maximum load for all services of a given type. For example, if you have a single worker with 8 cores and set an encoding job to have a jobload of 9. Fortunately, there is a simple resolution to this issue. Jobs which have already been created do not update their load values, even after restarting Opencast. To resolve a deadlock caused by job loads follow these instructions. First determine the queued job's ID from the admin UI. This will be an integer greater than zero. We will call this $jobid. Once you have the job ID, follow these steps: Stop Opencast Log into your database Make sure you are using the right schema. Currently the default is called opencast Update the job's load This will look something like UPDATE oc_job SET job\\_load=0.0 WHERE id=$jobid Log out of your database Change the load specified in the configuration file to an appropriate value This may need to happen across all nodes! Restart Opencast","title":"Load"},{"location":"configuration/load/#load-configuration","text":"This guide will help you to set up the load configuration settings which are strongly recommended for each Opencast installation. These settings control how many jobs are running on your various hardware nodes. These settings can be left at their defaults initially, but as your installation grows you will likely wish to fine-tune these to get the best performance you can out of your hardware.","title":"Load Configuration"},{"location":"configuration/load/#background-what-is-a-load-value","text":"Every job obviously imposes a certain amount of load on its processing system, the question is how can we quantify this? The settings this document will walk you through are estimates of the load placed on your system(s) by each job type. This means that every individual instance of that job type will count for a certain amount of load, and Opencast will refuse to process more than a certain configurable amount of load at any given time on a given node. These loads are tracked on a per-node basis, so a job running on one node imposes no load on another. As an example, say we have a worker with 8 cores. With Opencast 1.x all jobs, even expensive jobs like encoding, had an effective load value of 1.0. This meant that Opencast would schedule up to 8 encodes on worker 1! Obviously this is not ideal, since most encoding jobs consume multiple cores. Since Opencast 2.1 you can now specify on an encoding profile level how much load is imposed on a node. Likewise, all other jobs (video segmentation, publishing, etc) also now have configurable loads. Job loads can be any floating point value between 0.0, and Java's MAXFLOAT. Fractional loads are supported, since many of the jobs that Opencast spawns as a regular part of its workflows are very small. There is no sanity checking for the configured loads, aside from assuring they are not negative. This means that improperly set load values can cause deadlocks! Fortunately, this is easy to fix. See Troubleshooting for more details.","title":"Background: What is a load value"},{"location":"configuration/load/#step-1-determine-your-load-values","text":"This is a very subjective process, but is arguably the most imporant: How much load does each job and encoding profile add to your system? We have tried our best to set useful loads for each job, however these are only estimates. If your installation has, for example, hardware assisted encoding then your encoding jobs may be very inexpensive. In general, it is safe to assume that the first load value from the output of uptime is a good estimate of the load imposed by a job. Note: These job loads are specific for each node in the cluster. This means that for any given job, each node can have a different load value associated. For instance, if worker A has no job load specified for its encoding profiles, and worker B has job loads specified then any encoding jobs created by A will have the default load (1.5), and jobs created by B will have a different, presumably higher load. There are edge cases where this may be useful, but in most cases this will only cause confusion. It is therefore highly recommended that these settings be put into your configuration management system, and be applied on a cluster level to ensure consistency across all nodes.","title":"Step 1: Determine your load values"},{"location":"configuration/load/#step-2-setting-the-load-values-for-system-jobs","text":"Each Opencast instance has its own maximum load. By default this is set to the number of CPU cores present in the system. If you wish to change this, set the org.opencastproject.server.maxload key in config.properties to the maximum load you want this node to accept. Keep in mind that exceeding the number of CPU cores present in the system is not recommended. The load values for the non-encoding jobs are set in the configuration files in the etc directory. Search this directory for files that contain the string job.load to find the relevant configuration keys. These configuration keys control the load for each job type. For example, the job.load.download.distribute configuration key controls the load placed on the system when a download distribution job is running. Note: Ingest jobs are a special case in Opencast. Because of their immediate nature there is no way to limit the number of running jobs. However, these jobs will block other jobs from running on the ingest/admin nodes if enough ingests running concurrently.","title":"Step 2: Setting the load values for system jobs"},{"location":"configuration/load/#step-3-setting-the-load-values-for-encoding-profiles","text":"Each encoding profile can have a load value associated with it. By default, we have not set any, which means that the default value of 1.5 is used. To set the load associated with a profile, you simply add a .jobload key to the profile. For example, the composite encoding profile is prefixed with profile.composite.http . If we want to set a different job load than the default, we would create the profile.composite.http.jobload key, and set it to an appropriate job value.","title":"Step 3: Setting the load values for encoding profiles"},{"location":"configuration/load/#step-4-restart-opencast","text":"Many of these configuration files are only read on startup, so restarting Opencast is strongly recommended.","title":"Step 4: Restart Opencast"},{"location":"configuration/load/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"configuration/load/#help-my-system-has-deadlocked-or-there-are-jobs-which-are-always-queued-even-if-the-system-is-otherwise-idle","text":"This can be caused by setting a job weight that exceeds the maximum load for all services of a given type. For example, if you have a single worker with 8 cores and set an encoding job to have a jobload of 9. Fortunately, there is a simple resolution to this issue. Jobs which have already been created do not update their load values, even after restarting Opencast. To resolve a deadlock caused by job loads follow these instructions. First determine the queued job's ID from the admin UI. This will be an integer greater than zero. We will call this $jobid. Once you have the job ID, follow these steps: Stop Opencast Log into your database Make sure you are using the right schema. Currently the default is called opencast Update the job's load This will look something like UPDATE oc_job SET job\\_load=0.0 WHERE id=$jobid Log out of your database Change the load specified in the configuration file to an appropriate value This may need to happen across all nodes! Restart Opencast","title":"Help, my system has deadlocked, or there are jobs which are always queued even if the system is otherwise idle"},{"location":"configuration/log/","text":"Log The settings for logging can be found in: .../etc/org.ops4j.pax.logging.cfg Each Log4J appender can be configured in a similar fashion to the graylog example down below. The following requirements have to be met: * It needs to be a Log4J appender * The used bundle needs to be a fragment-bundle Graylog To have all log data available and accessible in one central location one can use graylog. A guide to install graylog can be found here . Add gelfj-X.X.X.jar (works up to version 1.1.14) to the appropriate folder in the karaf system folder (e.g. /system/org/graylog2/gelfj/X.X.X/gelfj-X.X.X.jar ) The directory has the same structure as a maven repository! It is important that the appender jar is a valid fragment-bundle of org.ops4j.pax.logging.pax-logging-service . That means the jar MANIFEST.MF must contain this section Fragment-Host: org.ops4j.pax.logging.pax-logging-service . Add the following line at the beginning of the startup.properties file: mvn\\:org.graylog2/gelfj/X.X.X = 7 We use startlevel 7 here, because it's need to be loaded before the pax-logging . Add this custom logging configuration example to the org.ops4j.pax.logging.cfg file # Async wrapper for send queue in case of GELF destination is unavailable log4j.appender.gelfasync=org.apache.log4j.AsyncAppender log4j.appender.gelfasync.blocking=false log4j.appender.gelfasync.bufferSize=20000 log4j.appender.gelfasync.appenders=gelf # Define the GELF destination log4j.appender.gelf=org.graylog2.log.GelfAppender log4j.appender.gelf.graylogHost=<HOSTNAME OF GRAYLOG INPUT> log4j.appender.gelf.graylogPort=<PORT OF GRAYLOG INPUT> log4j.appender.gelf.originHost=<NAME OF SERVICE> log4j.appender.gelf.facility=karaf log4j.appender.gelf.layout=org.apache.log4j.PatternLayout log4j.appender.gelf.extractStacktrace=true log4j.appender.gelf.addExtendedInformation=true log4j.appender.gelf.includeLocation=true log4j.appender.gelf.additionalFields={'environment': 'EXAMPLE-ENV', 'application': 'EXAMPLE-APP'} Note: The default protocol is UDP to use TCP instead, prefix hostname with tcp: . Add the new appender to the rootLogger log4j.rootLogger=WARN, stdout, osgi:*, gelfasync Example Configuration # Define the GELF destination log4j.appender.gelf=org.graylog2.log.GelfAppender log4j.appender.gelf.graylogHost=tcp:graylog.opencast.org log4j.appender.gelf.graylogPort=12290 log4j.appender.gelf.originHost=test.opencast.org log4j.appender.gelf.facility=karaf log4j.appender.gelf.layout=org.apache.log4j.PatternLayout log4j.appender.gelf.extractStacktrace=true log4j.appender.gelf.addExtendedInformation=true log4j.appender.gelf.includeLocation=true log4j.appender.gelf.additionalFields={'environment': 'OPENCAST-TEST-ENV', 'application': 'OC-ADMIN'} You can find further gelf appender documentation here .","title":"Log"},{"location":"configuration/log/#log","text":"The settings for logging can be found in: .../etc/org.ops4j.pax.logging.cfg Each Log4J appender can be configured in a similar fashion to the graylog example down below. The following requirements have to be met: * It needs to be a Log4J appender * The used bundle needs to be a fragment-bundle","title":"Log"},{"location":"configuration/log/#graylog","text":"To have all log data available and accessible in one central location one can use graylog. A guide to install graylog can be found here . Add gelfj-X.X.X.jar (works up to version 1.1.14) to the appropriate folder in the karaf system folder (e.g. /system/org/graylog2/gelfj/X.X.X/gelfj-X.X.X.jar ) The directory has the same structure as a maven repository! It is important that the appender jar is a valid fragment-bundle of org.ops4j.pax.logging.pax-logging-service . That means the jar MANIFEST.MF must contain this section Fragment-Host: org.ops4j.pax.logging.pax-logging-service . Add the following line at the beginning of the startup.properties file: mvn\\:org.graylog2/gelfj/X.X.X = 7 We use startlevel 7 here, because it's need to be loaded before the pax-logging . Add this custom logging configuration example to the org.ops4j.pax.logging.cfg file # Async wrapper for send queue in case of GELF destination is unavailable log4j.appender.gelfasync=org.apache.log4j.AsyncAppender log4j.appender.gelfasync.blocking=false log4j.appender.gelfasync.bufferSize=20000 log4j.appender.gelfasync.appenders=gelf # Define the GELF destination log4j.appender.gelf=org.graylog2.log.GelfAppender log4j.appender.gelf.graylogHost=<HOSTNAME OF GRAYLOG INPUT> log4j.appender.gelf.graylogPort=<PORT OF GRAYLOG INPUT> log4j.appender.gelf.originHost=<NAME OF SERVICE> log4j.appender.gelf.facility=karaf log4j.appender.gelf.layout=org.apache.log4j.PatternLayout log4j.appender.gelf.extractStacktrace=true log4j.appender.gelf.addExtendedInformation=true log4j.appender.gelf.includeLocation=true log4j.appender.gelf.additionalFields={'environment': 'EXAMPLE-ENV', 'application': 'EXAMPLE-APP'} Note: The default protocol is UDP to use TCP instead, prefix hostname with tcp: . Add the new appender to the rootLogger log4j.rootLogger=WARN, stdout, osgi:*, gelfasync","title":"Graylog"},{"location":"configuration/log/#example-configuration","text":"# Define the GELF destination log4j.appender.gelf=org.graylog2.log.GelfAppender log4j.appender.gelf.graylogHost=tcp:graylog.opencast.org log4j.appender.gelf.graylogPort=12290 log4j.appender.gelf.originHost=test.opencast.org log4j.appender.gelf.facility=karaf log4j.appender.gelf.layout=org.apache.log4j.PatternLayout log4j.appender.gelf.extractStacktrace=true log4j.appender.gelf.addExtendedInformation=true log4j.appender.gelf.includeLocation=true log4j.appender.gelf.additionalFields={'environment': 'OPENCAST-TEST-ENV', 'application': 'OC-ADMIN'} You can find further gelf appender documentation here .","title":"Example Configuration"},{"location":"configuration/message-broker/","text":"Message Broker Configuration Since version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user interface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the admin node). Required Version ActiveMQ 5.10 or above Installation If you use the Opencast package repository, simply install the activemq-dist package. If you are running RHEL, CentOS or Fedora you can use the ActiveMQ-dist Copr RPM repository Newer Debian based operating systems contain a sufficient new version, however the ActiveMQ configuration file will require modification to function correctly. You can download binary distributions from the Apache ActiveMQ website Configuration What you need to do: Set-up required message queues for Opencast Point all your Opencast nodes to your message broker. Configure authentication and access control The first task is easy. Opencast comes with a ActiveMQ configuration file, located at docs/scripts/activemq/activemq.xml (RPM repo: /usr/share/opencast/docs/scripts/activemq/activemq.xml ). This file will give you a basic configuration with all queues set-up and accepting connections from the local host over TCP port 61616 . Replacing the default ActiveMQ configuration with this file will already give you a fully functional ActiveMQ set-up for an all-in-one server. You will find the configuration in the usually locations, e.g. /etc/activemq/ . On Debian you first need to activate or create a new ActiveMQ instance. For more details on that see /usr/share/doc/activemq/README.Debian . Note that the default configuration needs to be adjusted for distributed set-ups since: ActiveMQ listens to localhost only ( activemq.xml ) Opencast tries to connect to ActiveMQ locally ( custom.properties ) No password is set ( activemq.xml , custom.properties ) Connection The ActiveMQ connection is configured in the custom.properties . The default configuration points to a local installation of ActiveMQ. You can easily configure this to point somewhere else: activemq.broker.url = failover://tcp://example.opencast.org:61616 Bind Host The default configuration tells ActiveMQ to listen to 127.0.0.1 only. On a distributed system, you want to set this to 0.0.0.0 to listen to all hosts by changing the transportConnector : <transportConnector name=\"openwire\" uri=\"tcp://127.0.0.1:61616?...\"/> Username and Password ActiveMQ can secure its message queues by requiring login credentials. This section will go through the steps of setting up a username and a password. Have a look at the ActiveMQ security site for details about using alternative authentication and authorization providers. Create ActiveMQ Admin User First, you need to create a new user that will have access to the queues. This is configured in the users.properties configuration file in the configuration directory for ActiveMQ. It is a list of the format username = password so, for example, we could create a new admin user with the following file contents: admin=password Create ActiveMQ Admin Group The next step is to provide a group that will have our user in it and will secure access to the message queues. This is configured in the file groups.properties in the configuration directory for ActiveMQ. It is a list of the format group = user1,user2,\u2026 . For example: groups=user1,user2,user3 To set-up our new user to be a part of the admins group: admins=admin Configure Users and Groups Configuration Files Next, we need to make sure that ActiveMQ is using our users.properties and groups.properties files to authenticate and authorize users. The login.config file should be in the ActiveMQ configuration directory and contain: activemq { org.apache.activemq.jaas.PropertiesLoginModule required org.apache.activemq.jaas.properties.user=\"users.properties\" org.apache.activemq.jaas.properties.group=\"groups.properties\"; }; Configure Message Broker Security The final step to secure the ActiveMQ queues is to limit access to a specific group. This can be done by editing activemq.xml in the ActiveMQ configuration directory. In this file, we need to add some XML in between these tags: <broker></broker> We will add the following plugin configuration: <plugins> <jaasAuthenticationPlugin configuration=\"activemq\" /> <authorizationPlugin> <map> <authorizationMap> <authorizationEntries> <authorizationEntry queue=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" /> <authorizationEntry topic=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" /> <authorizationEntry topic=\"ActiveMQ.Advisory.>\" read=\"admins\" write=\"admins\" admin=\"admins\"/> </authorizationEntries> </authorizationMap> </map> </authorizationPlugin> </plugins> The jaasAuthenticationPlugin configures the broker to use our login.config file for the authentication. <jaasAuthenticationPlugin configuration=\"activemq\" /> The property: configuration=activemq needs to match the name given for surrounding object in login.config i.e. activemq{}; The authorizationEntry restricts read, write and admin access for queues and topics to members of the group admins. Configure Opencast to Connect with Username and Password to Message Broker Now that we have secured the queues, Opencast will complain that it is unable to connect, using the current username and password. The username and password used above need to be added to the custom.properties file of Opencast. There are two properties to set: activemq.broker.username=admin activemq.broker.password=password Firewall Do not forget that ActiveMQ uses the TCP port 61616 (default configuration) for communication. You probably want to allow communication over this port in your firewall on a distributed setup or explicitly forbid public access on an all-in-one installation. Memory settings When ActiveMQ is under heavy load it may require additional RAM. There are two places to change this: In docs/scripts/activemq/activemq.xml : ... <systemUsage> <systemUsage> <memoryUsage> <!--<memoryUsage percentOfJvmHeap=\"70\" />--> <memoryUsage limit=\"2048 MB\"/> ... This controls the allowed memory of ActiveMQ inside of its JVM instance. For more information see the ActiveMQ documentation In /usr/share/activemq/bin/env : ACTIVEMQ_OPTS_MEMORY=\"-Xms64M -Xmx4G\" These are the classic JVM minimum and maximum memory flags.","title":"Message Broker"},{"location":"configuration/message-broker/#message-broker-configuration","text":"Since version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user interface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the admin node).","title":"Message Broker Configuration"},{"location":"configuration/message-broker/#required-version","text":"ActiveMQ 5.10 or above","title":"Required Version"},{"location":"configuration/message-broker/#installation","text":"If you use the Opencast package repository, simply install the activemq-dist package. If you are running RHEL, CentOS or Fedora you can use the ActiveMQ-dist Copr RPM repository Newer Debian based operating systems contain a sufficient new version, however the ActiveMQ configuration file will require modification to function correctly. You can download binary distributions from the Apache ActiveMQ website","title":"Installation"},{"location":"configuration/message-broker/#configuration","text":"What you need to do: Set-up required message queues for Opencast Point all your Opencast nodes to your message broker. Configure authentication and access control The first task is easy. Opencast comes with a ActiveMQ configuration file, located at docs/scripts/activemq/activemq.xml (RPM repo: /usr/share/opencast/docs/scripts/activemq/activemq.xml ). This file will give you a basic configuration with all queues set-up and accepting connections from the local host over TCP port 61616 . Replacing the default ActiveMQ configuration with this file will already give you a fully functional ActiveMQ set-up for an all-in-one server. You will find the configuration in the usually locations, e.g. /etc/activemq/ . On Debian you first need to activate or create a new ActiveMQ instance. For more details on that see /usr/share/doc/activemq/README.Debian . Note that the default configuration needs to be adjusted for distributed set-ups since: ActiveMQ listens to localhost only ( activemq.xml ) Opencast tries to connect to ActiveMQ locally ( custom.properties ) No password is set ( activemq.xml , custom.properties )","title":"Configuration"},{"location":"configuration/message-broker/#connection","text":"The ActiveMQ connection is configured in the custom.properties . The default configuration points to a local installation of ActiveMQ. You can easily configure this to point somewhere else: activemq.broker.url = failover://tcp://example.opencast.org:61616","title":"Connection"},{"location":"configuration/message-broker/#bind-host","text":"The default configuration tells ActiveMQ to listen to 127.0.0.1 only. On a distributed system, you want to set this to 0.0.0.0 to listen to all hosts by changing the transportConnector : <transportConnector name=\"openwire\" uri=\"tcp://127.0.0.1:61616?...\"/>","title":"Bind Host"},{"location":"configuration/message-broker/#username-and-password","text":"ActiveMQ can secure its message queues by requiring login credentials. This section will go through the steps of setting up a username and a password. Have a look at the ActiveMQ security site for details about using alternative authentication and authorization providers.","title":"Username and Password"},{"location":"configuration/message-broker/#create-activemq-admin-user","text":"First, you need to create a new user that will have access to the queues. This is configured in the users.properties configuration file in the configuration directory for ActiveMQ. It is a list of the format username = password so, for example, we could create a new admin user with the following file contents: admin=password","title":"Create ActiveMQ Admin User"},{"location":"configuration/message-broker/#create-activemq-admin-group","text":"The next step is to provide a group that will have our user in it and will secure access to the message queues. This is configured in the file groups.properties in the configuration directory for ActiveMQ. It is a list of the format group = user1,user2,\u2026 . For example: groups=user1,user2,user3 To set-up our new user to be a part of the admins group: admins=admin","title":"Create ActiveMQ Admin Group"},{"location":"configuration/message-broker/#configure-users-and-groups-configuration-files","text":"Next, we need to make sure that ActiveMQ is using our users.properties and groups.properties files to authenticate and authorize users. The login.config file should be in the ActiveMQ configuration directory and contain: activemq { org.apache.activemq.jaas.PropertiesLoginModule required org.apache.activemq.jaas.properties.user=\"users.properties\" org.apache.activemq.jaas.properties.group=\"groups.properties\"; };","title":"Configure Users and Groups Configuration Files"},{"location":"configuration/message-broker/#configure-message-broker-security","text":"The final step to secure the ActiveMQ queues is to limit access to a specific group. This can be done by editing activemq.xml in the ActiveMQ configuration directory. In this file, we need to add some XML in between these tags: <broker></broker> We will add the following plugin configuration: <plugins> <jaasAuthenticationPlugin configuration=\"activemq\" /> <authorizationPlugin> <map> <authorizationMap> <authorizationEntries> <authorizationEntry queue=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" /> <authorizationEntry topic=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" /> <authorizationEntry topic=\"ActiveMQ.Advisory.>\" read=\"admins\" write=\"admins\" admin=\"admins\"/> </authorizationEntries> </authorizationMap> </map> </authorizationPlugin> </plugins> The jaasAuthenticationPlugin configures the broker to use our login.config file for the authentication. <jaasAuthenticationPlugin configuration=\"activemq\" /> The property: configuration=activemq needs to match the name given for surrounding object in login.config i.e. activemq{}; The authorizationEntry restricts read, write and admin access for queues and topics to members of the group admins.","title":"Configure Message Broker Security"},{"location":"configuration/message-broker/#configure-opencast-to-connect-with-username-and-password-to-message-broker","text":"Now that we have secured the queues, Opencast will complain that it is unable to connect, using the current username and password. The username and password used above need to be added to the custom.properties file of Opencast. There are two properties to set: activemq.broker.username=admin activemq.broker.password=password","title":"Configure Opencast to Connect with Username and Password to Message Broker"},{"location":"configuration/message-broker/#firewall","text":"Do not forget that ActiveMQ uses the TCP port 61616 (default configuration) for communication. You probably want to allow communication over this port in your firewall on a distributed setup or explicitly forbid public access on an all-in-one installation.","title":"Firewall"},{"location":"configuration/message-broker/#memory-settings","text":"When ActiveMQ is under heavy load it may require additional RAM. There are two places to change this: In docs/scripts/activemq/activemq.xml : ... <systemUsage> <systemUsage> <memoryUsage> <!--<memoryUsage percentOfJvmHeap=\"70\" />--> <memoryUsage limit=\"2048 MB\"/> ... This controls the allowed memory of ActiveMQ inside of its JVM instance. For more information see the ActiveMQ documentation In /usr/share/activemq/bin/env : ACTIVEMQ_OPTS_MEMORY=\"-Xms64M -Xmx4G\" These are the classic JVM minimum and maximum memory flags.","title":"Memory settings"},{"location":"configuration/metadata/","text":"Overview In Opencast, metadata is stored in so-called metadata catalogs. For each event or series, an arbiraty number of such configurable metadata catalog can be managed. A common set of metadata has been standarized to form a common basis (standard metadata), whereas administrators can configure Opencast to support other metadata sets (extended metadata). This document provides an overview over Opencast's metadata capabilities and its configuration. Standard Metadata For both events and series, a common set of metadata is supported by Opencast out-of-the box. Since metadata catalogs are referenced from within media package, flavors can be used to identify a specific metadata catalog. The following flavors are treated by Opencast as standard metadata in means of Opencast expects them to be present: dublincore/episode holds the standard metadata of an event dublincore/series holds the standard metadata of a series Opencast assumes specific metadata fields to be present in the standard metadata in means of defining hard-coded filters, table columns and search indices. To adjust the standard metadata to your specific needs, you can configure them in /opt/opencast/etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg and /opt/opencast/etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common.cfg . For details on how to configure metadata catalogs, see section Configuring Metadata Catalogs. As mentioned above, however, Opencast expects specific metafields to be present to work correctly. In case you want to map metadata specific to your use case, you might consider to use the extended metadata capbilities of Opencast described in the next section. Extended Metadata For both events and series, Opencast support an arbitrary number of customized metadata catalogs. To add extended metadata catalogs, create a configuration file with a valid filename of the form org.opencastproject.ui.metadata.CatalogUIAdapterFactory-<name>.cfg in /opt/opencast/etc. on the admin node. For details on how to configure metadata catalogs, see section Configuring Metadata Catalogs. Limitations: Cannot be sorted, searched or filtered Cannot be displayed in tables Metadata Catalog Configuration The metadata configuration file format can be logically split up into different parts: Part 1: General catalog information Configuration key Example Description type events Two different types of catalog UI adapters may be configured, such for events and others for series. organization mh_default_org A custom catalog definition is mapped 1:1 to an organization and is available to this one organization only. flavor mycompany/episode The catalog must be of a certain flavor. For a events catalog, the flavor consists of the form type/subtype whereas for series you only need to define the subtype. Attention: For series catalogs, the type (the part before the slash '/') is used as element type. title My Personal Catalog Name This is the title that is displayed in the UI. It should be something that is readable by humans. Part 2: XML serialization information The only supported serialization of catalogs is currently the XML file format. The file follows the recommendation of the Dublin Core Metadata Initiative. Configuration key Example Description xml.rootElement.name mycatalog The name of the XML root element xml.rootElement.namespace.URI http://myorg.com/metadata/catalog The URI of the XML namespace of the root element Namespace bindings To properly serialize to XML each prefix has to be bound to an XML namespace. Multiple namespace bindings can be configured, each identified by its unique name. Configuration key Example Description xml.namespaceBinding.{name}.URI http://myorg.com/metadata/terms The URI of the XML namespace xml.namespaceBinding.{name}.prefix myterms The prefix used to identify elements of the namespace Part 3: Catalog fields configuration {field-id} must be a unique identifier for each property for a given catalog and can be the same as the input or output id to make it easy to find. Configuration key Example Description property.{field-id}.inputID* title The id used to identify this property in the catalog e.g. The name of the property inside the xml file of a Dublin Core catalog. If an outputID is not specified then this inputID is used for both the catalog and the front end id. This value is mandatory. property.{field-id}.outputID title The id used inside the json for this property. If this value is missing then the inputID will be used instead. property.{field-id}.namespace http://purl.org/dc/terms/ The URL that represents the namespace for this property. Different properties in the same catalog can have different namespaces. property.{field-id}.label \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\" or \"Event Title\" The label to show for this property in the UI. If there is a i18n support for a label that should be the value used so that it will be translated, if you don't mind it being locked to one translation just put that single value in. property.{field-id}.type text The type of the metadata field. property.{field-id}.pattern yyyy-MM-dd Applies to date and time types for now. It is used to format their values using the java DateTimeFormatter values** property.{field-id}.delimiter ; For mixed_text and iterable_text type fields, a string at which inputs into the corresponding fields are split into individual values for easier bulk entry of lists. The default is no delimiter, in which case no splitting takes place. property.{field-id}.readOnly false If the property can be edited in the UI or if it should only be displayed. property.{field-id}.required true If the property has to have a value before the metadata can be saved (the UI's save button will be disabled until all of the required fields are entered) property.{field-id}.collectionID USERS The id of the list provider that will be used to validate the input in the backend. So for example entering a username that doesn't exist will throw an error in this case. property.{field-id}.listprovider USERS The id of the list provider that will be used as a drop down option for that field. So for example using the USERS list provider means that in the front end the user will be able to choose the field value from the list of users in Opencast. property.{field-id}.order 3 Defines the order of properties where this property should be oriented in the UI i.e. 0 means the property should come first, 1 means it should come second etc. Giving two properties the same number will cause them to be next to one another but doesn't guarantee one above or below the other. * Mandatory field attribute ** See https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html Field types Type Description Example value in catalog Example value in UI JSON response example boolean Represents a true / false value in the UI that is represented by a check box. false false date A Java Date object that can include the year, month, day, hour, minute second ... and is formatted by the pattern value. 2014-12-10T16:29:43Z 2014-12-10 text A text input value for entering in one line of text. It supports more, it just won't increase in size for the interface. This is the Title This is the Title text_long A textarea which allows for more than 1 row of text Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. { \"id\": \"notesEpisode\", \"readOnly\": false, \"value\": \"\", \"label\": \"Notes\", \"required\": false, \"type\":\"text_long\" } iterable_text A text input value for entering in a list of text objects that are comma separated in the front end but stored separately in the catalog. Adam,Basil,Lukas value : [\"Adam\",\"Basil\",\"Lukas\"] { \"id\": \"contributor\", \"readOnly\": true, \"value\": [\"Adam\", \"Basil\", \"Lukas\"], \"label\": \"Contributor(s)\", \"required\": false, \"type\": \"text\" } start_date The start date portion of a Dublin Core Catalog Period. start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF; 2014-11-04 start_time The start time portion of a Dublin Core Catalog Period. start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF; 19:00:00 duration The duration of the event portion of a Dublin Core Catalog Period. start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF; 01:00:00 Workflow Configuration Since the extended metadata don't have the dublincore/* flavor, a tagging operation for the archive has to be added for the extended catalogs. In our examples below, we use ext/episode as a flavor, so the following operation should be added to the workflows <!-- Tag the extended metadata catalogs for publishing --> <operation id=\"tag\" description=\"Tagging extended metadata catalogs for archival and/or publication\"> <configurations> <configuration key=\"source-flavors\">ext/*</configuration> <configuration key=\"target-tags\">+archive</configuration> </configurations> </operation> If you want the extended metadata to be published the same way as the standard metadata, you can update the existing tagging operation for dublincore metadata the following way <!-- Tag the incoming metadata catalogs for publishing --> <operation id=\"tag\" description=\"Tagging metadata catalogs for archival and publication\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,ext/*</configuration> <configuration key=\"target-tags\">+archive,+engage-download</configuration> </configurations> </operation> Configuring the events publisher metadata field The metadata field can be used in two ways, and its meaning varies slightly: The publisher is the creator of the event: when an event is created, this field is filled automatically with the logged in user. It cannot be modified on creation of the event nor later. The publisher is responsible for uploading the content but may not be the creator of the event in the UI: in this case, when the event is created, the publisher is selected from a list provider that includes the logged in user (selected by default) and it is also modifiable later, but then the logged in user is not selectable. The configuration is done in the file: etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg . First option is the default one and the configuration is as follows: property.publisher.inputID=publisher property.publisher.label=EVENTS.EVENTS.DETAILS.METADATA.PUBLISHER property.publisher.type=text property.publisher.readOnly=true property.publisher.required=false property.publisher.order=16 To configure the second option: property.publisher.inputID=publisher property.publisher.label=EVENTS.EVENTS.DETAILS.METADATA.PUBLISHER property.publisher.type=text property.publisher.readOnly=false property.publisher.required=true property.publisher.listprovider=YOUR_LIST_PROVIDER property.publisher.order=16 If you want to use the publishers as list provider, you must set up the provider in this way: property.publisher.listprovider=EVENTS.PUBLISHER In both cases, you can filter events by publisher.","title":"Metadata"},{"location":"configuration/metadata/#overview","text":"In Opencast, metadata is stored in so-called metadata catalogs. For each event or series, an arbiraty number of such configurable metadata catalog can be managed. A common set of metadata has been standarized to form a common basis (standard metadata), whereas administrators can configure Opencast to support other metadata sets (extended metadata). This document provides an overview over Opencast's metadata capabilities and its configuration.","title":"Overview"},{"location":"configuration/metadata/#standard-metadata","text":"For both events and series, a common set of metadata is supported by Opencast out-of-the box. Since metadata catalogs are referenced from within media package, flavors can be used to identify a specific metadata catalog. The following flavors are treated by Opencast as standard metadata in means of Opencast expects them to be present: dublincore/episode holds the standard metadata of an event dublincore/series holds the standard metadata of a series Opencast assumes specific metadata fields to be present in the standard metadata in means of defining hard-coded filters, table columns and search indices. To adjust the standard metadata to your specific needs, you can configure them in /opt/opencast/etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg and /opt/opencast/etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common.cfg . For details on how to configure metadata catalogs, see section Configuring Metadata Catalogs. As mentioned above, however, Opencast expects specific metafields to be present to work correctly. In case you want to map metadata specific to your use case, you might consider to use the extended metadata capbilities of Opencast described in the next section.","title":"Standard Metadata"},{"location":"configuration/metadata/#extended-metadata","text":"For both events and series, Opencast support an arbitrary number of customized metadata catalogs. To add extended metadata catalogs, create a configuration file with a valid filename of the form org.opencastproject.ui.metadata.CatalogUIAdapterFactory-<name>.cfg in /opt/opencast/etc. on the admin node. For details on how to configure metadata catalogs, see section Configuring Metadata Catalogs. Limitations: Cannot be sorted, searched or filtered Cannot be displayed in tables","title":"Extended Metadata"},{"location":"configuration/metadata/#metadata-catalog-configuration","text":"The metadata configuration file format can be logically split up into different parts:","title":"Metadata Catalog Configuration"},{"location":"configuration/metadata/#part-1-general-catalog-information","text":"Configuration key Example Description type events Two different types of catalog UI adapters may be configured, such for events and others for series. organization mh_default_org A custom catalog definition is mapped 1:1 to an organization and is available to this one organization only. flavor mycompany/episode The catalog must be of a certain flavor. For a events catalog, the flavor consists of the form type/subtype whereas for series you only need to define the subtype. Attention: For series catalogs, the type (the part before the slash '/') is used as element type. title My Personal Catalog Name This is the title that is displayed in the UI. It should be something that is readable by humans.","title":"Part 1: General catalog information"},{"location":"configuration/metadata/#part-2-xml-serialization-information","text":"The only supported serialization of catalogs is currently the XML file format. The file follows the recommendation of the Dublin Core Metadata Initiative. Configuration key Example Description xml.rootElement.name mycatalog The name of the XML root element xml.rootElement.namespace.URI http://myorg.com/metadata/catalog The URI of the XML namespace of the root element Namespace bindings To properly serialize to XML each prefix has to be bound to an XML namespace. Multiple namespace bindings can be configured, each identified by its unique name. Configuration key Example Description xml.namespaceBinding.{name}.URI http://myorg.com/metadata/terms The URI of the XML namespace xml.namespaceBinding.{name}.prefix myterms The prefix used to identify elements of the namespace","title":"Part 2: XML serialization information"},{"location":"configuration/metadata/#part-3-catalog-fields-configuration","text":"{field-id} must be a unique identifier for each property for a given catalog and can be the same as the input or output id to make it easy to find. Configuration key Example Description property.{field-id}.inputID* title The id used to identify this property in the catalog e.g. The name of the property inside the xml file of a Dublin Core catalog. If an outputID is not specified then this inputID is used for both the catalog and the front end id. This value is mandatory. property.{field-id}.outputID title The id used inside the json for this property. If this value is missing then the inputID will be used instead. property.{field-id}.namespace http://purl.org/dc/terms/ The URL that represents the namespace for this property. Different properties in the same catalog can have different namespaces. property.{field-id}.label \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\" or \"Event Title\" The label to show for this property in the UI. If there is a i18n support for a label that should be the value used so that it will be translated, if you don't mind it being locked to one translation just put that single value in. property.{field-id}.type text The type of the metadata field. property.{field-id}.pattern yyyy-MM-dd Applies to date and time types for now. It is used to format their values using the java DateTimeFormatter values** property.{field-id}.delimiter ; For mixed_text and iterable_text type fields, a string at which inputs into the corresponding fields are split into individual values for easier bulk entry of lists. The default is no delimiter, in which case no splitting takes place. property.{field-id}.readOnly false If the property can be edited in the UI or if it should only be displayed. property.{field-id}.required true If the property has to have a value before the metadata can be saved (the UI's save button will be disabled until all of the required fields are entered) property.{field-id}.collectionID USERS The id of the list provider that will be used to validate the input in the backend. So for example entering a username that doesn't exist will throw an error in this case. property.{field-id}.listprovider USERS The id of the list provider that will be used as a drop down option for that field. So for example using the USERS list provider means that in the front end the user will be able to choose the field value from the list of users in Opencast. property.{field-id}.order 3 Defines the order of properties where this property should be oriented in the UI i.e. 0 means the property should come first, 1 means it should come second etc. Giving two properties the same number will cause them to be next to one another but doesn't guarantee one above or below the other. * Mandatory field attribute ** See https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html Field types Type Description Example value in catalog Example value in UI JSON response example boolean Represents a true / false value in the UI that is represented by a check box. false false date A Java Date object that can include the year, month, day, hour, minute second ... and is formatted by the pattern value. 2014-12-10T16:29:43Z 2014-12-10 text A text input value for entering in one line of text. It supports more, it just won't increase in size for the interface. This is the Title This is the Title text_long A textarea which allows for more than 1 row of text Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. { \"id\": \"notesEpisode\", \"readOnly\": false, \"value\": \"\", \"label\": \"Notes\", \"required\": false, \"type\":\"text_long\" } iterable_text A text input value for entering in a list of text objects that are comma separated in the front end but stored separately in the catalog. Adam,Basil,Lukas value : [\"Adam\",\"Basil\",\"Lukas\"] { \"id\": \"contributor\", \"readOnly\": true, \"value\": [\"Adam\", \"Basil\", \"Lukas\"], \"label\": \"Contributor(s)\", \"required\": false, \"type\": \"text\" } start_date The start date portion of a Dublin Core Catalog Period. start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF; 2014-11-04 start_time The start time portion of a Dublin Core Catalog Period. start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF; 19:00:00 duration The duration of the event portion of a Dublin Core Catalog Period. start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF; 01:00:00 Workflow Configuration Since the extended metadata don't have the dublincore/* flavor, a tagging operation for the archive has to be added for the extended catalogs. In our examples below, we use ext/episode as a flavor, so the following operation should be added to the workflows <!-- Tag the extended metadata catalogs for publishing --> <operation id=\"tag\" description=\"Tagging extended metadata catalogs for archival and/or publication\"> <configurations> <configuration key=\"source-flavors\">ext/*</configuration> <configuration key=\"target-tags\">+archive</configuration> </configurations> </operation> If you want the extended metadata to be published the same way as the standard metadata, you can update the existing tagging operation for dublincore metadata the following way <!-- Tag the incoming metadata catalogs for publishing --> <operation id=\"tag\" description=\"Tagging metadata catalogs for archival and publication\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,ext/*</configuration> <configuration key=\"target-tags\">+archive,+engage-download</configuration> </configurations> </operation>","title":"Part 3: Catalog fields configuration"},{"location":"configuration/metadata/#configuring-the-events-publisher-metadata-field","text":"The metadata field can be used in two ways, and its meaning varies slightly: The publisher is the creator of the event: when an event is created, this field is filled automatically with the logged in user. It cannot be modified on creation of the event nor later. The publisher is responsible for uploading the content but may not be the creator of the event in the UI: in this case, when the event is created, the publisher is selected from a list provider that includes the logged in user (selected by default) and it is also modifiable later, but then the logged in user is not selectable. The configuration is done in the file: etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg . First option is the default one and the configuration is as follows: property.publisher.inputID=publisher property.publisher.label=EVENTS.EVENTS.DETAILS.METADATA.PUBLISHER property.publisher.type=text property.publisher.readOnly=true property.publisher.required=false property.publisher.order=16 To configure the second option: property.publisher.inputID=publisher property.publisher.label=EVENTS.EVENTS.DETAILS.METADATA.PUBLISHER property.publisher.type=text property.publisher.readOnly=false property.publisher.required=true property.publisher.listprovider=YOUR_LIST_PROVIDER property.publisher.order=16 If you want to use the publishers as list provider, you must set up the provider in this way: property.publisher.listprovider=EVENTS.PUBLISHER In both cases, you can filter events by publisher.","title":"Configuring the events publisher metadata field"},{"location":"configuration/monitoring/","text":"Monitoring To assist in the operation of Opencast an application health-check is available. This will quickly return the state of the specific node, whether it is running properly, has minor issues or is unavailable for some reason e.g. in maintenance mode. Regular calls to the health-check from whatever monitoring software you choose to use will give you confidence that the Opencast nodes are running correctly and alert you when they are not. For larger deployments the health-check can be used by load-balancers* and trigger fail-overs if one of the nodes goes down. * The only nodes that make sense to load-balance are the externally facing ones, ingest and presentation . Calling the Health-Check The Runtime module provides the health-check endpoint at /info/health and a simple HTTP GET request will return a HTTP status code indicating the health of the node and response in JSON providing further details. curl \"http://oc-admin.example.com/info/health\" The HTTP status code will just indicate whether the node is running or not, the response contains a status field that indicates the actual health of the node. The status can have the values pass , warn and fail . The response implements the health-check format proposed here https://inadarei.github.io/rfc-healthcheck . The table below shows the HTTP status codes the health-check status and the conditions for which they can occur. status notes HTTP code meaning pass n/a 200 All is OK warn service(s) in WARN state 200 Partially working service here warn services(s) in ERROR state 200 Look for service on another node fail maintenance 503 Node not available, try again later fail disabled 503 Node not available, try another node fail offline 503 Node not running, try another node In all cases where the health-check status is not pass the JSON response provides more details. A summary of the problem(s) are list in the notes field. In the case of services in non NORMAL states these are listing the checks field. An example response for a warn status is shown below { \"description\" : \"Opencast node's health status\", \"releaseId\" : \"8\", \"serviceId\" : \"http://oc-admin.example.com\", \"version\" : \"1\", \"status\" : \"warn\", \"notes\" : [ \"service(s) in WARN state\", \"service(s) in ERROR state\" ], \"checks\" : { \"service:states\" : [ { \"changed\" : \"Tue Jun 04 11:10:12 BST 2019\", \"links\" : { \"path\" : \"service1\" }, \"observedValue\" : \"WARNING\", \"componentId\" : \"service1\" }, { \"changed\" : \"Tue Jun 04 11:15:27 BST 2019\", \"links\" : { \"path\" : \"service2\" }, \"observedValue\" : \"ERROR\", \"componentId\" : \"service2\" } ] } }","title":"External Monitoring"},{"location":"configuration/monitoring/#monitoring","text":"To assist in the operation of Opencast an application health-check is available. This will quickly return the state of the specific node, whether it is running properly, has minor issues or is unavailable for some reason e.g. in maintenance mode. Regular calls to the health-check from whatever monitoring software you choose to use will give you confidence that the Opencast nodes are running correctly and alert you when they are not. For larger deployments the health-check can be used by load-balancers* and trigger fail-overs if one of the nodes goes down. * The only nodes that make sense to load-balance are the externally facing ones, ingest and presentation .","title":"Monitoring"},{"location":"configuration/monitoring/#calling-the-health-check","text":"The Runtime module provides the health-check endpoint at /info/health and a simple HTTP GET request will return a HTTP status code indicating the health of the node and response in JSON providing further details. curl \"http://oc-admin.example.com/info/health\" The HTTP status code will just indicate whether the node is running or not, the response contains a status field that indicates the actual health of the node. The status can have the values pass , warn and fail . The response implements the health-check format proposed here https://inadarei.github.io/rfc-healthcheck . The table below shows the HTTP status codes the health-check status and the conditions for which they can occur. status notes HTTP code meaning pass n/a 200 All is OK warn service(s) in WARN state 200 Partially working service here warn services(s) in ERROR state 200 Look for service on another node fail maintenance 503 Node not available, try again later fail disabled 503 Node not available, try another node fail offline 503 Node not running, try another node In all cases where the health-check status is not pass the JSON response provides more details. A summary of the problem(s) are list in the notes field. In the case of services in non NORMAL states these are listing the checks field. An example response for a warn status is shown below { \"description\" : \"Opencast node's health status\", \"releaseId\" : \"8\", \"serviceId\" : \"http://oc-admin.example.com\", \"version\" : \"1\", \"status\" : \"warn\", \"notes\" : [ \"service(s) in WARN state\", \"service(s) in ERROR state\" ], \"checks\" : { \"service:states\" : [ { \"changed\" : \"Tue Jun 04 11:10:12 BST 2019\", \"links\" : { \"path\" : \"service1\" }, \"observedValue\" : \"WARNING\", \"componentId\" : \"service1\" }, { \"changed\" : \"Tue Jun 04 11:15:27 BST 2019\", \"links\" : { \"path\" : \"service2\" }, \"observedValue\" : \"ERROR\", \"componentId\" : \"service2\" } ] } }","title":"Calling the Health-Check"},{"location":"configuration/multi.tenancy/","text":"Multi Tenancy Configuration Introduction A single Opencast instance can handle mutliple tenants, each of which have their own recordings in the system. Opencast refers to tenants as organizations , and an HTTP request to the Opencast installation is mapped to an organization using the server name. Therefore, a Opencast instance will usually be set up with multiple DNS names pointing to the same IP, for example: admin.example.org tenant1-admin.example.org tenant2-admin.example.org should all resolve to the same IP. A tenant configuration thus consists mainly of the DNS name that is mapped to that tenant. Default Setup Out of the box, Opencast has one tenant configured, called mh_default_org that is mapped to the server name localhost:8080 . As long as there is one tenant configuration only, Opencast will map every request to that tenant regardless of the server name. As soon as a second tenant configuration is available, requests will be mapped to organizations using the server name, and an HTTP status code 404 will be returned for requests that hit the Opencast intallation that cannot be mapped to any organization. Limitations Multi tenancy in Opencast is working, however it is not fully finished. Certain objects are still shared amongst organizations, most notably workflow definitions, RSS/Atom feeds and encoding profiles. Adding A Tenant To add a tenant to the installation, two things need to be put in place: a tenant configuration and a set of security rules. For this example we have a three node install of admin.opencast.org , worker.opencast.org , and presentation.opencast.org . Assume that the new tenant is called tenant1 and should be mapped to tenant1-*.opencast.org . Tenant Configuration Create a file called org.opencastproject.organization-tenant1.cfg in the etc/ directory of your Opencast installation, on each of the nodes. As an example, this is what the admin node looks like: id=tenant1 name=Tenant 1 server=tenant1-admin.opencast.org,tenant1-presentation.opencast.org port=8080 admin_role=ROLE_ADMIN anonymous_role=ROLE_ANONYMOUS # Admin and Presentation Server Urls prop.org.opencastproject.admin.ui.url=https://tenant1-admin.opencast.org prop.org.opencastproject.engage.ui.url=https://tenant1-presentation.opencast.org # Default properties for the user interface prop.logo_mediamodule=/engage/ui/img/logo/opencast-icon.svg prop.logo_player=/engage/ui/img/logo/opencast.svg There are more options available than in this example. The easiest way of creating that file is probably to create a copy of the already existing org.opencastproject.organization-mh_default_org.cfg . Note, the default organization file org.opencastproject.organization-mh_default_org.org must refer to the actual server names: server=admin.opencast.org This file sets the default organization that is selected. This is currently required because some Opencast components do not support multitenancy. Note that if you are running Apache httpd with mod_proxy in front of the Opencast installation, the port number will be -1 in both files. Security Configuration Create a file called tenant1.xml in /etc/security. This file specifies access rules for individual urls that specify which roles are needed in order to access a given url. In addition, it allows to define the directory services that are used to authenticate users. The file follows the standard ways on configuring Spring Security and you are free to add anything that can go into a Spring Security configuration. The easiest way of creating that file is probably to create a copy of the already existing mh_default_org.xml . Other Configuration Two additional files should be copied: org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg should be copied to org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common-tenant1.cfg , and org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common.cfg should be copied to org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common-tenant1.cfg . In each of the new configuration files, change organization key to match the tenant id, and change the common-metadata key to false. Create a copy of the files for each tenant. Note: The original ...-common.cfg files must have their common-metadata keys set to true, otherwise metadata will only be available in one tenant and you will experience a number of odd errors.","title":"Multi Tenancy"},{"location":"configuration/multi.tenancy/#multi-tenancy-configuration","text":"","title":"Multi Tenancy Configuration"},{"location":"configuration/multi.tenancy/#introduction","text":"A single Opencast instance can handle mutliple tenants, each of which have their own recordings in the system. Opencast refers to tenants as organizations , and an HTTP request to the Opencast installation is mapped to an organization using the server name. Therefore, a Opencast instance will usually be set up with multiple DNS names pointing to the same IP, for example: admin.example.org tenant1-admin.example.org tenant2-admin.example.org should all resolve to the same IP. A tenant configuration thus consists mainly of the DNS name that is mapped to that tenant.","title":"Introduction"},{"location":"configuration/multi.tenancy/#default-setup","text":"Out of the box, Opencast has one tenant configured, called mh_default_org that is mapped to the server name localhost:8080 . As long as there is one tenant configuration only, Opencast will map every request to that tenant regardless of the server name. As soon as a second tenant configuration is available, requests will be mapped to organizations using the server name, and an HTTP status code 404 will be returned for requests that hit the Opencast intallation that cannot be mapped to any organization.","title":"Default Setup"},{"location":"configuration/multi.tenancy/#limitations","text":"Multi tenancy in Opencast is working, however it is not fully finished. Certain objects are still shared amongst organizations, most notably workflow definitions, RSS/Atom feeds and encoding profiles.","title":"Limitations"},{"location":"configuration/multi.tenancy/#adding-a-tenant","text":"To add a tenant to the installation, two things need to be put in place: a tenant configuration and a set of security rules. For this example we have a three node install of admin.opencast.org , worker.opencast.org , and presentation.opencast.org . Assume that the new tenant is called tenant1 and should be mapped to tenant1-*.opencast.org .","title":"Adding A Tenant"},{"location":"configuration/multi.tenancy/#tenant-configuration","text":"Create a file called org.opencastproject.organization-tenant1.cfg in the etc/ directory of your Opencast installation, on each of the nodes. As an example, this is what the admin node looks like: id=tenant1 name=Tenant 1 server=tenant1-admin.opencast.org,tenant1-presentation.opencast.org port=8080 admin_role=ROLE_ADMIN anonymous_role=ROLE_ANONYMOUS # Admin and Presentation Server Urls prop.org.opencastproject.admin.ui.url=https://tenant1-admin.opencast.org prop.org.opencastproject.engage.ui.url=https://tenant1-presentation.opencast.org # Default properties for the user interface prop.logo_mediamodule=/engage/ui/img/logo/opencast-icon.svg prop.logo_player=/engage/ui/img/logo/opencast.svg There are more options available than in this example. The easiest way of creating that file is probably to create a copy of the already existing org.opencastproject.organization-mh_default_org.cfg . Note, the default organization file org.opencastproject.organization-mh_default_org.org must refer to the actual server names: server=admin.opencast.org This file sets the default organization that is selected. This is currently required because some Opencast components do not support multitenancy. Note that if you are running Apache httpd with mod_proxy in front of the Opencast installation, the port number will be -1 in both files.","title":"Tenant Configuration"},{"location":"configuration/multi.tenancy/#security-configuration","text":"Create a file called tenant1.xml in /etc/security. This file specifies access rules for individual urls that specify which roles are needed in order to access a given url. In addition, it allows to define the directory services that are used to authenticate users. The file follows the standard ways on configuring Spring Security and you are free to add anything that can go into a Spring Security configuration. The easiest way of creating that file is probably to create a copy of the already existing mh_default_org.xml .","title":"Security Configuration"},{"location":"configuration/multi.tenancy/#other-configuration","text":"Two additional files should be copied: org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg should be copied to org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common-tenant1.cfg , and org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common.cfg should be copied to org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common-tenant1.cfg . In each of the new configuration files, change organization key to match the tenant id, and change the common-metadata key to false. Create a copy of the files for each tenant. Note: The original ...-common.cfg files must have their common-metadata keys set to true, otherwise metadata will only be available in one tenant and you will experience a number of odd errors.","title":"Other Configuration"},{"location":"configuration/oaipmh/","text":"OAI-PMH Configuration Overview OAI-PMH is an XML based protocol for metadata exchange using HTTP as the transport layer. An OAI-PMH system consists of two parts, a repository on the one and the harvester on the other end. The repository is an HTTP accessible server that exposes metadata to its client, the harvester. OAI-PMH repositories will be accessed using URLs of the form: <OAI-PMH server> + <OAI-PMH mount point> + <OAI-PMH Repository> Step 1: Configure the URL of the OAI-PMH server The property to configure the OAI-PMH server URL can be found in etc/org.opencastproject.organization-mh_default_org.cfg : prop.org.opencastproject.oaipmh.server.hosturl=http://localhost:8080 Step 2: Configure the OAI-PMH mount point The property to configure the OAI-PMH mount point can be found in etc/custom.properties : org.opencastproject.oaipmh.mountpoint=/oaipmh Step 3: Configure the OAI-PMH default repository In case the repository is not included in the URL, the OAI-PMH default repository will be selected. The property to configure the OAI-PMH default repository can be found in etc/org.opencastproject.oaipmh.server.OaiPmhServer.cfg default-repository=default Step 4: Allow access to OAI-PMH mount point Make sure that the OAI-PMH mount point is accessible. For example, if the OAI-PMH mount point has been set to /oaipmh , the following two lines <sec:intercept-url pattern=\"/oaipmh/**\" method=\"GET\" access=\"ROLE_ANONYMOUS\"/> <sec:intercept-url pattern=\"/oaipmh/**\" method=\"POST\" access=\"ROLE_ANONYMOUS\"/> should be present in etc/security/mh_default_org.xml . Note that the OAI-PMH specification demands both GET and POST requests and that it does not feature any access restrictions. If you need to restrict access to OAI-PMH consider using Spring security or an iptables approach.","title":"OAI-PMH"},{"location":"configuration/oaipmh/#oai-pmh-configuration","text":"","title":"OAI-PMH Configuration"},{"location":"configuration/oaipmh/#overview","text":"OAI-PMH is an XML based protocol for metadata exchange using HTTP as the transport layer. An OAI-PMH system consists of two parts, a repository on the one and the harvester on the other end. The repository is an HTTP accessible server that exposes metadata to its client, the harvester. OAI-PMH repositories will be accessed using URLs of the form: <OAI-PMH server> + <OAI-PMH mount point> + <OAI-PMH Repository>","title":"Overview"},{"location":"configuration/oaipmh/#step-1-configure-the-url-of-the-oai-pmh-server","text":"The property to configure the OAI-PMH server URL can be found in etc/org.opencastproject.organization-mh_default_org.cfg : prop.org.opencastproject.oaipmh.server.hosturl=http://localhost:8080","title":"Step 1: Configure the URL of the OAI-PMH server"},{"location":"configuration/oaipmh/#step-2-configure-the-oai-pmh-mount-point","text":"The property to configure the OAI-PMH mount point can be found in etc/custom.properties : org.opencastproject.oaipmh.mountpoint=/oaipmh","title":"Step 2: Configure the OAI-PMH mount point"},{"location":"configuration/oaipmh/#step-3-configure-the-oai-pmh-default-repository","text":"In case the repository is not included in the URL, the OAI-PMH default repository will be selected. The property to configure the OAI-PMH default repository can be found in etc/org.opencastproject.oaipmh.server.OaiPmhServer.cfg default-repository=default","title":"Step 3: Configure the OAI-PMH default repository"},{"location":"configuration/oaipmh/#step-4-allow-access-to-oai-pmh-mount-point","text":"Make sure that the OAI-PMH mount point is accessible. For example, if the OAI-PMH mount point has been set to /oaipmh , the following two lines <sec:intercept-url pattern=\"/oaipmh/**\" method=\"GET\" access=\"ROLE_ANONYMOUS\"/> <sec:intercept-url pattern=\"/oaipmh/**\" method=\"POST\" access=\"ROLE_ANONYMOUS\"/> should be present in etc/security/mh_default_org.xml . Note that the OAI-PMH specification demands both GET and POST requests and that it does not feature any access restrictions. If you need to restrict access to OAI-PMH consider using Spring security or an iptables approach.","title":"Step 4: Allow access to OAI-PMH mount point"},{"location":"configuration/security.aai/","text":"Authentication and Authorization Infrastructure (AAI) Configuration This page describes how to configure Opencast to take advantage of the Authentication and Authorization Infrastructure (AAI). Prerequesites This guides assumes that you know how to setup and configure a Shibboleth Service Provider, i.e. you are assumed to already have performed the following steps: Registeration of your Shibboleth Service Provider at your Shibboleth Federation Service Registry Setup and configuration of Shibboleth on the servers you want to use it Configuration of your web server In case you require help on this, contact the institution responsilbe for managing the Shibboleth Federation you are part of. An informative list of Shibboleth Federations can be found on: https://refeds.org/federations Step 1: Configuration of the AAI Login handler Opencast ships with a configurable AAI Login handler that needs to be adjusted to your environment. The configuration can be found in etc/org.opencastproject.security.aai.ConfigurableLoginHandler.cfg . First off all, enable the AAI login handler: enabled=true For bootstrapping purposes, you might want to configure the AAI bootstrap user: bootstrap.user.id=<AAI ID> That user will be assigned ROLE_ADMIN at login time. This enables you to access the administrative UI and configure user authorization without the need to fiddle with the database directly. Once user authorization has been setup, disable the AAI bootstrap user. Since the HTTP request header names required by the AAI login handler are specific to Shibboleth Federations, you will need to first adjust the following properties. Set the following header names to the correct values: header.given_name = \"<Name of Shibboleth attribute>\" header.surname = \"<Name of Shibboleth attribute>\" header.email = \"<Name of Shibboleth attribute>\" header.home_organization = \"<Name of Shibboleth attribute>\" Optionally, you can configure the name of some basic roles the AAI login handler will assign to authenticated users. The prefix of the user role will determine what unique role a given Shibboleth user has. The role is of the form role.user.prefix + Unique ID provided by Shibboleth . role.user.prefix = \"ROLE_AAI_USER_\" To indicate the AAI home organization a user belongs to, the organization membership role is assigned to the user. The role is of the form role.organization.prefix + Home Organization provided by Shibboleth + role.organization.suffix role.organization.prefix = \"ROLE_AAI_ORG_\" role.organization.suffix = \"_MEMBER\" To indicate the fact that a user has authenticated himself using Shibboleth, the login handler assigns the role as specified by the property role.federation . role.federation = \"ROLE_AAI_USER\" Step 2: Spring Security Configuration In order to take advantage of Shibboleth authentication, you will need to uncomment the following lines found in etc/security/mh_default_org.xml : The Shibboleth header authentification filter needs to be enabled to get access to the Shibboleth information within the HTTP request headers. <!-- Shibboleth header authentication filter --> <sec:custom-filter ref=\"shibbolethHeaderFilter\" position=\"PRE_AUTH_FILTER\"/> To ensure that a logout is not just logging out the user from the Opencast application but also from Shibboleth, you will need to configure the logout-success-url: <!-- Enables log out --> <sec:logout logout-success-url=\"/Shibboleth.sso/Logout?return=www.opencast.org\" /> IMPORTANT: In the section Shibboleth Support , be sure to adapt the value of principalRequestHeader to the respective name of the Shibboleth attribute you use in your Shibboleth Federation: <!-- ###################### --> <!-- # Shibboleth Support # --> <!-- ###################### --> <!-- General Shibboleth header extration filter --> <bean id=\"shibbolethHeaderFilter\" class=\"org.opencastproject.security.shibboleth.ShibbolethRequestHeaderAuthenticationFilter\"> <property name=\"principalRequestHeader\" value=\"<Shibboleth attribute name>\"/> <property name=\"authenticationManager\" ref=\"authenticationManager\" /> <property name=\"userDetailsService\" ref=\"userDetailsService\" /> <property name=\"userDirectoryService\" ref=\"userDirectoryService\" /> <property name=\"shibbolethLoginHandler\" ref=\"configurableLoginHandler\" /> <property name=\"exceptionIfHeaderMissing\" value=\"false\" /> </bean> <!-- AAI specific header extractor and user generator --> <bean id=\"configurableLoginHandler\" class=\"org.opencastproject.security.aai.ConfigurableLoginHandler\"> <property name=\"securityService\" ref=\"securityService\" /> <property name=\"userReferenceProvider\" ref=\"userReferenceProvider\" /> </bean> <bean id=\"preauthAuthProvider\" class=\"org.springframework.security.web.authentication.preauth.PreAuthenticatedAuthenticationProvider\"> <property name=\"preAuthenticatedUserDetailsService\"> <bean id=\"userDetailsServiceWrapper\" class=\"org.springframework.security.core.userdetails.UserDetailsByNameServiceWrapper\"> <property name=\"userDetailsService\" ref=\"userDetailsService\"/> </bean> </property> </bean> Finally be sure to enable the user reference provider to enable support for externally provided users: <osgi:reference id=\"userReferenceProvider\" cardinality=\"1..1\" interface=\"org.opencastproject.userdirectory.api.UserReferenceProvider\" /> Since the Opencast login page is not used when Shibboleth authentication is in place, there is no point in redirecting unauthenticated requests to the Opencast login form. You can redirect them directly to the administrative user interface which is supposed to be protected by Shibboleth. <!-- Redirects unauthenticated requests to the login form --> <bean id=\"userEntryPoint\" class=\"org.springframework.security.web.authentication.LoginUrlAuthenticationEntryPoint\"> <property name=\"loginFormUrl\" value=\"/admin-ng/index.html\" /> </bean> Last but not least, you need to add the preauthAuthProvider authentication provider to the authentication-manager : <sec:authentication-manager alias=\"authenticationManager\"> <sec:authentication-provider ref=\"preauthAuthProvider\"> <sec:authentication-provider user-service-ref=\"userDetailsService\"> <sec:password-encoder hash=\"md5\"><sec:salt-source user-property=\"username\" /></sec:password-encoder> </sec:authentication-provider> </sec:authentication-manager> Step 3: Protecting HTML pages by Shibboleth It is important to understand that Shibboleth is only used to protect content that is accessed by human users. Access to APIs is protected by other means of authentication as, for example, digest authentication. To protect HTML pages, you will need to adapt the configuration of your web server: <LocationMatch \\.(htm|html)$> AuthType shibboleth ShibRequireSession On ShibUseHeaders On require valid-user </LocationMatch>","title":"Authentication and Authorization Infrastructure (AAI)"},{"location":"configuration/security.aai/#authentication-and-authorization-infrastructure-aai-configuration","text":"This page describes how to configure Opencast to take advantage of the Authentication and Authorization Infrastructure (AAI).","title":"Authentication and Authorization Infrastructure (AAI) Configuration"},{"location":"configuration/security.aai/#prerequesites","text":"This guides assumes that you know how to setup and configure a Shibboleth Service Provider, i.e. you are assumed to already have performed the following steps: Registeration of your Shibboleth Service Provider at your Shibboleth Federation Service Registry Setup and configuration of Shibboleth on the servers you want to use it Configuration of your web server In case you require help on this, contact the institution responsilbe for managing the Shibboleth Federation you are part of. An informative list of Shibboleth Federations can be found on: https://refeds.org/federations","title":"Prerequesites"},{"location":"configuration/security.aai/#step-1-configuration-of-the-aai-login-handler","text":"Opencast ships with a configurable AAI Login handler that needs to be adjusted to your environment. The configuration can be found in etc/org.opencastproject.security.aai.ConfigurableLoginHandler.cfg . First off all, enable the AAI login handler: enabled=true For bootstrapping purposes, you might want to configure the AAI bootstrap user: bootstrap.user.id=<AAI ID> That user will be assigned ROLE_ADMIN at login time. This enables you to access the administrative UI and configure user authorization without the need to fiddle with the database directly. Once user authorization has been setup, disable the AAI bootstrap user. Since the HTTP request header names required by the AAI login handler are specific to Shibboleth Federations, you will need to first adjust the following properties. Set the following header names to the correct values: header.given_name = \"<Name of Shibboleth attribute>\" header.surname = \"<Name of Shibboleth attribute>\" header.email = \"<Name of Shibboleth attribute>\" header.home_organization = \"<Name of Shibboleth attribute>\" Optionally, you can configure the name of some basic roles the AAI login handler will assign to authenticated users. The prefix of the user role will determine what unique role a given Shibboleth user has. The role is of the form role.user.prefix + Unique ID provided by Shibboleth . role.user.prefix = \"ROLE_AAI_USER_\" To indicate the AAI home organization a user belongs to, the organization membership role is assigned to the user. The role is of the form role.organization.prefix + Home Organization provided by Shibboleth + role.organization.suffix role.organization.prefix = \"ROLE_AAI_ORG_\" role.organization.suffix = \"_MEMBER\" To indicate the fact that a user has authenticated himself using Shibboleth, the login handler assigns the role as specified by the property role.federation . role.federation = \"ROLE_AAI_USER\"","title":"Step 1: Configuration of the AAI Login handler"},{"location":"configuration/security.aai/#step-2-spring-security-configuration","text":"In order to take advantage of Shibboleth authentication, you will need to uncomment the following lines found in etc/security/mh_default_org.xml : The Shibboleth header authentification filter needs to be enabled to get access to the Shibboleth information within the HTTP request headers. <!-- Shibboleth header authentication filter --> <sec:custom-filter ref=\"shibbolethHeaderFilter\" position=\"PRE_AUTH_FILTER\"/> To ensure that a logout is not just logging out the user from the Opencast application but also from Shibboleth, you will need to configure the logout-success-url: <!-- Enables log out --> <sec:logout logout-success-url=\"/Shibboleth.sso/Logout?return=www.opencast.org\" /> IMPORTANT: In the section Shibboleth Support , be sure to adapt the value of principalRequestHeader to the respective name of the Shibboleth attribute you use in your Shibboleth Federation: <!-- ###################### --> <!-- # Shibboleth Support # --> <!-- ###################### --> <!-- General Shibboleth header extration filter --> <bean id=\"shibbolethHeaderFilter\" class=\"org.opencastproject.security.shibboleth.ShibbolethRequestHeaderAuthenticationFilter\"> <property name=\"principalRequestHeader\" value=\"<Shibboleth attribute name>\"/> <property name=\"authenticationManager\" ref=\"authenticationManager\" /> <property name=\"userDetailsService\" ref=\"userDetailsService\" /> <property name=\"userDirectoryService\" ref=\"userDirectoryService\" /> <property name=\"shibbolethLoginHandler\" ref=\"configurableLoginHandler\" /> <property name=\"exceptionIfHeaderMissing\" value=\"false\" /> </bean> <!-- AAI specific header extractor and user generator --> <bean id=\"configurableLoginHandler\" class=\"org.opencastproject.security.aai.ConfigurableLoginHandler\"> <property name=\"securityService\" ref=\"securityService\" /> <property name=\"userReferenceProvider\" ref=\"userReferenceProvider\" /> </bean> <bean id=\"preauthAuthProvider\" class=\"org.springframework.security.web.authentication.preauth.PreAuthenticatedAuthenticationProvider\"> <property name=\"preAuthenticatedUserDetailsService\"> <bean id=\"userDetailsServiceWrapper\" class=\"org.springframework.security.core.userdetails.UserDetailsByNameServiceWrapper\"> <property name=\"userDetailsService\" ref=\"userDetailsService\"/> </bean> </property> </bean> Finally be sure to enable the user reference provider to enable support for externally provided users: <osgi:reference id=\"userReferenceProvider\" cardinality=\"1..1\" interface=\"org.opencastproject.userdirectory.api.UserReferenceProvider\" /> Since the Opencast login page is not used when Shibboleth authentication is in place, there is no point in redirecting unauthenticated requests to the Opencast login form. You can redirect them directly to the administrative user interface which is supposed to be protected by Shibboleth. <!-- Redirects unauthenticated requests to the login form --> <bean id=\"userEntryPoint\" class=\"org.springframework.security.web.authentication.LoginUrlAuthenticationEntryPoint\"> <property name=\"loginFormUrl\" value=\"/admin-ng/index.html\" /> </bean> Last but not least, you need to add the preauthAuthProvider authentication provider to the authentication-manager : <sec:authentication-manager alias=\"authenticationManager\"> <sec:authentication-provider ref=\"preauthAuthProvider\"> <sec:authentication-provider user-service-ref=\"userDetailsService\"> <sec:password-encoder hash=\"md5\"><sec:salt-source user-property=\"username\" /></sec:password-encoder> </sec:authentication-provider> </sec:authentication-manager>","title":"Step 2: Spring Security Configuration"},{"location":"configuration/security.aai/#step-3-protecting-html-pages-by-shibboleth","text":"It is important to understand that Shibboleth is only used to protect content that is accessed by human users. Access to APIs is protected by other means of authentication as, for example, digest authentication. To protect HTML pages, you will need to adapt the configuration of your web server: <LocationMatch \\.(htm|html)$> AuthType shibboleth ShibRequireSession On ShibUseHeaders On require valid-user </LocationMatch>","title":"Step 3: Protecting HTML pages by Shibboleth"},{"location":"configuration/security.cas/","text":"Configure Central Authentication Service (CAS) Authentication Many campuses use some kind of single sign on, such as JASIG's Central Authentication Service, or CAS. This guide describes how to integrate Opencast into such a system. Step 1 First, you need to edit the file etc/org.apache.karaf.features.cfg and add the opencast-security-cas to the featuresBoot variable. featuresBoot = ..., opencast-security-cas Step 2 In a single-tenant deployment, your security.xml file is under OPENCAST_HOME/etc/security/mh_default_org.xml . In an RPM/DEB based installation, it is located in /etc/opencast/security/mh_default_org.xml . You should make a backup copy of the file and substitute it by the sample file named security_sample_cas.xml-example . In other words: $> cd etc/security $> mv mh_default_org.xml mh_default_org.xml.old $> cp security_sample_cas.xml-example mh_default_org.xml The sample file should be exactly the same as the default security file, except for the parts only relevant to the CAS. If you have done custom modifications to your security file, make sure to incorporate them to the new file, too. Step 3 Add the necessary configuration values to the CAS section of the new security file. The comments should be self-explanatory. You must modify several settings in the sample to point to your CAS server: <bean id=\"casEntryPoint\" class=\"org.springframework.security.cas.web.CasAuthenticationEntryPoint\"> <property name=\"loginUrl\" value=\"https://auth-test.berkeley.edu/cas/login\"/> <property name=\"serviceProperties\" ref=\"serviceProperties\"/> </bean> <bean id=\"casAuthenticationProvider\" class=\"org.springframework.security.cas.authentication.CasAuthenticationProvider\"> <property name=\"userDetailsService\" ref=\"userDetailsService\"/> <property name=\"serviceProperties\" ref=\"serviceProperties\" /> <property name=\"ticketValidator\"> <bean class=\"org.jasig.cas.client.validation.Cas20ServiceTicketValidator\"> <constructor-arg index=\"0\" value=\"https://auth-test.berkeley.edu/cas\" /> </bean> </property> <property name=\"key\" value=\"cas\"/> </bean> You will also need to set the public URL for your Opencast server: <bean id=\"serviceProperties\" class=\"org.springframework.security.cas.ServiceProperties\"> <property name=\"service\" value=\"http://localhost:8080/j_spring_cas_security_check\"/> <property name=\"sendRenew\" value=\"false\"/> </bean> Authorization Now the system knows all the information necessary to authenticate users against CAS, but also need some authorization information, to tell which services the user is allowed to use and which resources is allowed to see and/or modify. You will need to configure a UserProvider to look up users as identified by CAS. Sakai User Provider LDAP User Provider (Section Authorization/Step 2 ) Original documentation from University of Saskatchewan University of Saskatchewan CAS and LDAP integration","title":"Central Authentication Service (CAS)"},{"location":"configuration/security.cas/#configure-central-authentication-service-cas","text":"","title":"Configure Central Authentication Service (CAS)"},{"location":"configuration/security.cas/#authentication","text":"Many campuses use some kind of single sign on, such as JASIG's Central Authentication Service, or CAS. This guide describes how to integrate Opencast into such a system.","title":"Authentication"},{"location":"configuration/security.cas/#step-1","text":"First, you need to edit the file etc/org.apache.karaf.features.cfg and add the opencast-security-cas to the featuresBoot variable. featuresBoot = ..., opencast-security-cas","title":"Step 1"},{"location":"configuration/security.cas/#step-2","text":"In a single-tenant deployment, your security.xml file is under OPENCAST_HOME/etc/security/mh_default_org.xml . In an RPM/DEB based installation, it is located in /etc/opencast/security/mh_default_org.xml . You should make a backup copy of the file and substitute it by the sample file named security_sample_cas.xml-example . In other words: $> cd etc/security $> mv mh_default_org.xml mh_default_org.xml.old $> cp security_sample_cas.xml-example mh_default_org.xml The sample file should be exactly the same as the default security file, except for the parts only relevant to the CAS. If you have done custom modifications to your security file, make sure to incorporate them to the new file, too.","title":"Step 2"},{"location":"configuration/security.cas/#step-3","text":"Add the necessary configuration values to the CAS section of the new security file. The comments should be self-explanatory. You must modify several settings in the sample to point to your CAS server: <bean id=\"casEntryPoint\" class=\"org.springframework.security.cas.web.CasAuthenticationEntryPoint\"> <property name=\"loginUrl\" value=\"https://auth-test.berkeley.edu/cas/login\"/> <property name=\"serviceProperties\" ref=\"serviceProperties\"/> </bean> <bean id=\"casAuthenticationProvider\" class=\"org.springframework.security.cas.authentication.CasAuthenticationProvider\"> <property name=\"userDetailsService\" ref=\"userDetailsService\"/> <property name=\"serviceProperties\" ref=\"serviceProperties\" /> <property name=\"ticketValidator\"> <bean class=\"org.jasig.cas.client.validation.Cas20ServiceTicketValidator\"> <constructor-arg index=\"0\" value=\"https://auth-test.berkeley.edu/cas\" /> </bean> </property> <property name=\"key\" value=\"cas\"/> </bean> You will also need to set the public URL for your Opencast server: <bean id=\"serviceProperties\" class=\"org.springframework.security.cas.ServiceProperties\"> <property name=\"service\" value=\"http://localhost:8080/j_spring_cas_security_check\"/> <property name=\"sendRenew\" value=\"false\"/> </bean>","title":"Step 3"},{"location":"configuration/security.cas/#authorization","text":"Now the system knows all the information necessary to authenticate users against CAS, but also need some authorization information, to tell which services the user is allowed to use and which resources is allowed to see and/or modify. You will need to configure a UserProvider to look up users as identified by CAS. Sakai User Provider LDAP User Provider (Section Authorization/Step 2 )","title":"Authorization"},{"location":"configuration/security.cas/#original-documentation-from-university-of-saskatchewan","text":"University of Saskatchewan CAS and LDAP integration","title":"Original documentation from University of Saskatchewan"},{"location":"configuration/security.ldap/","text":"LDAP Authentication and Authorization (without CAS) This page describes how to use only an LDAP server to authenticate users in Opencast. If you just want to use LDAP as an identity provider for another authentication mechanism, such as a CAS server, this guide does not apply to you. You may find the instructions to configure an LDAP-backed CAS server here . The variable $OPENCAST_ETC used below stands for the location of Opencast's configuration folder within your system. Its location varies depending on whether Opencast was installed from source or a packaged version (e.g. RPM) was used: Source installation: The etc folder within the directory containing the Opencast code. Packaged installation: A subdirectory of your system's usual configuration directory, most likely /etc/opencast .* Set up an LDAP provider Step 1 Opencast's security.xml files are located in the folder $OPENCAST_ETC/security . In a single-tenant deployment, the file is named $OPENCAST_ETC/security/mh_default_org.xml for the default organization. In a multi-tenant installation, or when a non-default organization is used, the file(s) are $OPENCAST_ETC/security/<organization_id>.xml . You should make a backup copy of the file and substitute it with the sample file named security_sample_ldap.xml-example . In other words: $> cd $OPENCAST_ETC/security $> mv mh_default_org.xml mh_default_org.xml.old $> cp security_sample_ldap.xml-example mh_default_org.xml The sample file should be exactly the same as the replaced security file, except for the parts only relevant to the LDAP which will be discussed below. If you have done custom modifications to your security file, please make sure to incorporate them to the new file, too. Step 2 Add the necessary configuration values to the LDAP section of the new security file. The first relevant section defines a context source. This contains the basic login information that enables Opencast to request information about users from the LDAP server in order to authenticate them. <bean id=\"contextSource\" class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\"> <!-- URL of the LDAP server --> <constructor-arg value=\"ldap://myldapserver:myport\" /> <!-- \"Distinguished name\" for the unprivileged user --> <!-- This user is merely to perform searches in the LDAP to find the users to login --> <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" /> <!-- Password of the user above --> <property name=\"password\" value=\"mypassword\" /> </bean> The next part tells the system how to search for users in the LDAP server: <constructor-arg> <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\"> <constructor-arg ref=\"contextSource\" /> <property name=\"userDnPatterns\"> <list> <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed --> <value>uid={0},ou=Group,dc=my-institution,dc=country</value> </list> </property> <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them --> <!-- This property can be used together with the \"userDnPatterns\" above --> <!-- <property name=\"userSearch\"> <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\"> < ! - - Base Dn from where the users will be searched for - - > <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" /> < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - > <constructor-arg index=\"1\" value=\"(uid={0})\" /> <constructor-arg ref=\"contextSource\" /> </bean> </property> --> </bean> </constructor-arg> As the previous snippet shows, there are two alternative ways to find users in your LDAP: Using the property userDnPatterns: This property accepts a list of search patterns to match against the user's DN. The patterns will be tried in order until a match is found. The placeholder {0} can be used to represent the username in such patterns. Using a userSearch filter: With the previous approach, it is not possible to find users whose login name is not part of their DN. In such cases, you can use the userSearch property, that allows you to search the users based on a filter. The filter requires three parameters: The first parameter specifies the \"root node\" where the searches will start from. The second one specifies the filter, where, again, the placeholder {0} will be substituted by the username during the searches. The third parameter should be the contextSource defined above. Both methods are not mutually exclusive --i.e. both can be activated at the same time, even though only the first one is uncommented in the sample file because it is the most usual. The last constructor argument is defined as follows: <!-- Defines how the user attributes are converted to authorities (roles) --> <constructor-arg ref=\"authoritiesPopulator\" /> , which refers to the following definition: <osgi:reference id=\"authoritiesPopulator\" cardinality=\"1..1\" interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\" filter=\"(instanceId=theId)\"/> You may edit theId to any value, ideally one that is descriptive of the LDAP connection being configured. The same value used here must be set as the org.opencastproject.userdirectory.ldap.id in the LDAP configuration file described below. Step 3 Make a copy of the file $OPENCAST_ETC/org.opencastproject.userdirectory.ldap.cfg.template in the same directory and rename it as: org.opencastproject.userdirectory.ldap-<ID>.cfg , where <ID> is a unique identifier for each LDAP connection. This identifier is only use to distinguish between the files and is not used internally. It might have any value, but for the sake of clarity, it is recommended to use the same value as in the org.opencastproject.userdirectory.ldap.id parameter in the file. Step 4 Edit the parameters in the file with your particular configuration. Unfortunately, some of those are duplicated in the security.xml file, but this situation cannot currently be avoided. The parameters that are exclusive to this .cfg file control the user authorization, i.e. how the roles obtained from the LDAP are handled and assigned to the users. Please refer to the documentation in the file itself to know the meaning of these parameters and how to use them. IMPORTANT : The org.opencastproject.userdirectory.ldap.id parameter in the file must be configured to the same value as the ID of the OSGI reference in the security.xml file above (at the end of the step #2). Combination with Existing authorization Mechanisms In the default configuration included in the security_sample_ldap.xml-example file, the LDAP is tried after the normal authorization mechanisms (i.e. the database). This means that if a user is present in both the database and the LDAP, the database will take precedence. The order is determined by the order in which the authentication providers appear on the security file. The relevant snippet is this: <sec:authentication-manager alias=\"authenticationManager\"> <sec:authentication-provider user-service-ref=\"userDetailsService\"> # \\ <sec:password-encoder hash=\"md5\"> # | <sec:salt-source user-property=\"username\" /> # -> These lines must be moved as a block </sec:password-encoder> # | </sec:authentication-provider> # / <sec:authentication-provider ref=\"ldapAuthProvider\" /> # The LDAP provider appears in the second position, therefore it is the second provider to consider </sec:authentication-manager> By switching the position of the authentication providers, you will give them more or less priority. Adding more LDAP servers More LDAP servers can be added to the configuration by including the LDAP-related sections as many times as necessary with their corresponding configurations. The new authentication providers must also be added to the providers list at the bottom of the file. Please see the example below: <bean id=\"contextSource\" class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\"> <!-- URL of the LDAP server --> <constructor-arg value=\"ldap://myldapserver:myport\" /> <!-- \"Distinguished name\" for the unprivileged user --> <!-- This user is merely to perform searches in the LDAP to find the users to login --> <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" /> <!-- Password of the user above --> <property name=\"password\" value=\"mypassword\" /> </bean> <bean id=\"ldapAuthProvider\" class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\"> <constructor-arg> <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\"> <constructor-arg ref=\"contextSource\" /> <property name=\"userDnPatterns\"> <list> <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed --> <value>uid={0},ou=Group,dc=my-institution,dc=country</value> </list> </property> <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them --> <!-- This property can be used together with the \"userDnPatterns\" above --> <!-- <property name=\"userSearch\"> <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\"> < ! - - Base Dn from where the users will be searched for - - > <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" /> < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - > <constructor-arg index=\"1\" value=\"(uid={0})\" /> <constructor-arg ref=\"contextSource\" /> </bean> </property> --> </bean> </constructor-arg> <!-- Defines how the user attributes are converted to authorities (roles) --> <constructor-arg ref=\"authoritiesPopulator\" /> </bean> <!-- PLEASE NOTE: The ID below must be changed for each context source instance --> <bean id=\"contextSource2\" class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\"> <constructor-arg value=\"ldap://myldapserver:myport\" /> <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" /> <property name=\"password\" value=\"mypassword\" /> </bean> <!-- PLEASE NOTE: The ID below must be changed for each LDAP authentication provider instance --> <bean id=\"ldapAuthProvider2\" class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\"> <constructor-arg> <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\"> <!-- PLEASE NOTE: the ref below must match the corresponding context source ID --> <constructor-arg ref=\"contextSource2\" /> <property name=\"userDnPatterns\"> <list> <value>uid={0},ou=OtherGroup,dc=my-other-institution,dc=other-country</value> </list> </property> <property name=\"userSearch\"> <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\"> <constructor-arg index=\"0\" value=\"ou=OtherGroup,dc=my-other-institution,dc=other-country\" /> <constructor-arg index=\"1\" value=\"(uid={0})\" /> <!-- PLEASE NOTE: the ref below must match the corresponding context source ID --> <constructor-arg ref=\"contextSource2\" /> </bean> </property> </bean> </constructor-arg> <!-- Defines how the user attributes are converted to authorities (roles) --> <!-- PLEASE NOTE: the ref below must match the corresponding authoritiesPopulator --> <constructor-arg ref=\"authoritiesPopulator2\" /> </bean> <!-- [ ... SKIPPED LINES ... ] --> <osgi:reference id=\"authoritiesPopulator\" cardinality=\"1..1\" interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\" filter=\"(instanceId=theId)\"/> <osgi:reference id=\"authoritiesPopulator2\" cardinality=\"1..1\" interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\" filter=\"(instanceId=theId2)\"/> <!-- [ ... SKIPPED LINES ... ] --> <sec:authentication-manager alias=\"authenticationManager\"> <sec:authentication-provider user-service-ref=\"userDetailsService\"> <sec:password-encoder hash=\"md5\"> <sec:salt-source user-property=\"username\" /> </sec:password-encoder> </sec:authentication-provider> <!-- PLEASE NOTE: In this example, the 2nd LDAP provider defined in the file has more priority that the first one --> <sec:authentication-provider ref=\"ldapAuthProvider2\" /> <sec:authentication-provider ref=\"ldapAuthProvider\" /> </sec:authentication-manager> Then, a separate .cfg must be generated for each of the configured providers, as explained here . Please make sure to configure the org.opencastproject.userdirectory.ldap.id parameter correctly. In this case, the values should be theId and theId2 , respectively.","title":"LDAP Authentication and Authorization (without CAS)"},{"location":"configuration/security.ldap/#ldap-authentication-and-authorization-without-cas","text":"This page describes how to use only an LDAP server to authenticate users in Opencast. If you just want to use LDAP as an identity provider for another authentication mechanism, such as a CAS server, this guide does not apply to you. You may find the instructions to configure an LDAP-backed CAS server here . The variable $OPENCAST_ETC used below stands for the location of Opencast's configuration folder within your system. Its location varies depending on whether Opencast was installed from source or a packaged version (e.g. RPM) was used: Source installation: The etc folder within the directory containing the Opencast code. Packaged installation: A subdirectory of your system's usual configuration directory, most likely /etc/opencast .*","title":"LDAP Authentication and Authorization (without CAS)"},{"location":"configuration/security.ldap/#set-up-an-ldap-provider","text":"","title":"Set up an LDAP provider"},{"location":"configuration/security.ldap/#step-1","text":"Opencast's security.xml files are located in the folder $OPENCAST_ETC/security . In a single-tenant deployment, the file is named $OPENCAST_ETC/security/mh_default_org.xml for the default organization. In a multi-tenant installation, or when a non-default organization is used, the file(s) are $OPENCAST_ETC/security/<organization_id>.xml . You should make a backup copy of the file and substitute it with the sample file named security_sample_ldap.xml-example . In other words: $> cd $OPENCAST_ETC/security $> mv mh_default_org.xml mh_default_org.xml.old $> cp security_sample_ldap.xml-example mh_default_org.xml The sample file should be exactly the same as the replaced security file, except for the parts only relevant to the LDAP which will be discussed below. If you have done custom modifications to your security file, please make sure to incorporate them to the new file, too.","title":"Step 1"},{"location":"configuration/security.ldap/#step-2","text":"Add the necessary configuration values to the LDAP section of the new security file. The first relevant section defines a context source. This contains the basic login information that enables Opencast to request information about users from the LDAP server in order to authenticate them. <bean id=\"contextSource\" class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\"> <!-- URL of the LDAP server --> <constructor-arg value=\"ldap://myldapserver:myport\" /> <!-- \"Distinguished name\" for the unprivileged user --> <!-- This user is merely to perform searches in the LDAP to find the users to login --> <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" /> <!-- Password of the user above --> <property name=\"password\" value=\"mypassword\" /> </bean> The next part tells the system how to search for users in the LDAP server: <constructor-arg> <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\"> <constructor-arg ref=\"contextSource\" /> <property name=\"userDnPatterns\"> <list> <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed --> <value>uid={0},ou=Group,dc=my-institution,dc=country</value> </list> </property> <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them --> <!-- This property can be used together with the \"userDnPatterns\" above --> <!-- <property name=\"userSearch\"> <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\"> < ! - - Base Dn from where the users will be searched for - - > <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" /> < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - > <constructor-arg index=\"1\" value=\"(uid={0})\" /> <constructor-arg ref=\"contextSource\" /> </bean> </property> --> </bean> </constructor-arg> As the previous snippet shows, there are two alternative ways to find users in your LDAP: Using the property userDnPatterns: This property accepts a list of search patterns to match against the user's DN. The patterns will be tried in order until a match is found. The placeholder {0} can be used to represent the username in such patterns. Using a userSearch filter: With the previous approach, it is not possible to find users whose login name is not part of their DN. In such cases, you can use the userSearch property, that allows you to search the users based on a filter. The filter requires three parameters: The first parameter specifies the \"root node\" where the searches will start from. The second one specifies the filter, where, again, the placeholder {0} will be substituted by the username during the searches. The third parameter should be the contextSource defined above. Both methods are not mutually exclusive --i.e. both can be activated at the same time, even though only the first one is uncommented in the sample file because it is the most usual. The last constructor argument is defined as follows: <!-- Defines how the user attributes are converted to authorities (roles) --> <constructor-arg ref=\"authoritiesPopulator\" /> , which refers to the following definition: <osgi:reference id=\"authoritiesPopulator\" cardinality=\"1..1\" interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\" filter=\"(instanceId=theId)\"/> You may edit theId to any value, ideally one that is descriptive of the LDAP connection being configured. The same value used here must be set as the org.opencastproject.userdirectory.ldap.id in the LDAP configuration file described below.","title":"Step 2"},{"location":"configuration/security.ldap/#step-3","text":"Make a copy of the file $OPENCAST_ETC/org.opencastproject.userdirectory.ldap.cfg.template in the same directory and rename it as: org.opencastproject.userdirectory.ldap-<ID>.cfg , where <ID> is a unique identifier for each LDAP connection. This identifier is only use to distinguish between the files and is not used internally. It might have any value, but for the sake of clarity, it is recommended to use the same value as in the org.opencastproject.userdirectory.ldap.id parameter in the file.","title":" Step 3"},{"location":"configuration/security.ldap/#step-4","text":"Edit the parameters in the file with your particular configuration. Unfortunately, some of those are duplicated in the security.xml file, but this situation cannot currently be avoided. The parameters that are exclusive to this .cfg file control the user authorization, i.e. how the roles obtained from the LDAP are handled and assigned to the users. Please refer to the documentation in the file itself to know the meaning of these parameters and how to use them. IMPORTANT : The org.opencastproject.userdirectory.ldap.id parameter in the file must be configured to the same value as the ID of the OSGI reference in the security.xml file above (at the end of the step #2).","title":"Step 4"},{"location":"configuration/security.ldap/#combination-with-existing-authorization-mechanisms","text":"In the default configuration included in the security_sample_ldap.xml-example file, the LDAP is tried after the normal authorization mechanisms (i.e. the database). This means that if a user is present in both the database and the LDAP, the database will take precedence. The order is determined by the order in which the authentication providers appear on the security file. The relevant snippet is this: <sec:authentication-manager alias=\"authenticationManager\"> <sec:authentication-provider user-service-ref=\"userDetailsService\"> # \\ <sec:password-encoder hash=\"md5\"> # | <sec:salt-source user-property=\"username\" /> # -> These lines must be moved as a block </sec:password-encoder> # | </sec:authentication-provider> # / <sec:authentication-provider ref=\"ldapAuthProvider\" /> # The LDAP provider appears in the second position, therefore it is the second provider to consider </sec:authentication-manager> By switching the position of the authentication providers, you will give them more or less priority.","title":"Combination with Existing authorization Mechanisms"},{"location":"configuration/security.ldap/#adding-more-ldap-servers","text":"More LDAP servers can be added to the configuration by including the LDAP-related sections as many times as necessary with their corresponding configurations. The new authentication providers must also be added to the providers list at the bottom of the file. Please see the example below: <bean id=\"contextSource\" class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\"> <!-- URL of the LDAP server --> <constructor-arg value=\"ldap://myldapserver:myport\" /> <!-- \"Distinguished name\" for the unprivileged user --> <!-- This user is merely to perform searches in the LDAP to find the users to login --> <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" /> <!-- Password of the user above --> <property name=\"password\" value=\"mypassword\" /> </bean> <bean id=\"ldapAuthProvider\" class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\"> <constructor-arg> <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\"> <constructor-arg ref=\"contextSource\" /> <property name=\"userDnPatterns\"> <list> <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed --> <value>uid={0},ou=Group,dc=my-institution,dc=country</value> </list> </property> <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them --> <!-- This property can be used together with the \"userDnPatterns\" above --> <!-- <property name=\"userSearch\"> <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\"> < ! - - Base Dn from where the users will be searched for - - > <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" /> < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - > <constructor-arg index=\"1\" value=\"(uid={0})\" /> <constructor-arg ref=\"contextSource\" /> </bean> </property> --> </bean> </constructor-arg> <!-- Defines how the user attributes are converted to authorities (roles) --> <constructor-arg ref=\"authoritiesPopulator\" /> </bean> <!-- PLEASE NOTE: The ID below must be changed for each context source instance --> <bean id=\"contextSource2\" class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\"> <constructor-arg value=\"ldap://myldapserver:myport\" /> <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" /> <property name=\"password\" value=\"mypassword\" /> </bean> <!-- PLEASE NOTE: The ID below must be changed for each LDAP authentication provider instance --> <bean id=\"ldapAuthProvider2\" class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\"> <constructor-arg> <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\"> <!-- PLEASE NOTE: the ref below must match the corresponding context source ID --> <constructor-arg ref=\"contextSource2\" /> <property name=\"userDnPatterns\"> <list> <value>uid={0},ou=OtherGroup,dc=my-other-institution,dc=other-country</value> </list> </property> <property name=\"userSearch\"> <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\"> <constructor-arg index=\"0\" value=\"ou=OtherGroup,dc=my-other-institution,dc=other-country\" /> <constructor-arg index=\"1\" value=\"(uid={0})\" /> <!-- PLEASE NOTE: the ref below must match the corresponding context source ID --> <constructor-arg ref=\"contextSource2\" /> </bean> </property> </bean> </constructor-arg> <!-- Defines how the user attributes are converted to authorities (roles) --> <!-- PLEASE NOTE: the ref below must match the corresponding authoritiesPopulator --> <constructor-arg ref=\"authoritiesPopulator2\" /> </bean> <!-- [ ... SKIPPED LINES ... ] --> <osgi:reference id=\"authoritiesPopulator\" cardinality=\"1..1\" interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\" filter=\"(instanceId=theId)\"/> <osgi:reference id=\"authoritiesPopulator2\" cardinality=\"1..1\" interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\" filter=\"(instanceId=theId2)\"/> <!-- [ ... SKIPPED LINES ... ] --> <sec:authentication-manager alias=\"authenticationManager\"> <sec:authentication-provider user-service-ref=\"userDetailsService\"> <sec:password-encoder hash=\"md5\"> <sec:salt-source user-property=\"username\" /> </sec:password-encoder> </sec:authentication-provider> <!-- PLEASE NOTE: In this example, the 2nd LDAP provider defined in the file has more priority that the first one --> <sec:authentication-provider ref=\"ldapAuthProvider2\" /> <sec:authentication-provider ref=\"ldapAuthProvider\" /> </sec:authentication-manager> Then, a separate .cfg must be generated for each of the configured providers, as explained here . Please make sure to configure the org.opencastproject.userdirectory.ldap.id parameter correctly. In this case, the values should be theId and theId2 , respectively.","title":"Adding more LDAP servers"},{"location":"configuration/security/","text":"Security Configuration This document will help you configure the Opencast security policy. Introduction Opencast service endpoints and user interfaces are secured by default using a set of servlet filters. The following diagram illustrates the flow of an HTTP request and response through these filters. The Spring Security filters used here are very powerful, but are also somewhat complicated. Please familiarize yourself with the basic concepts and vocabulary described in the Spring Security documentation, then edit the xml files in etc/security , as described below. Configure Access To configure access roles and URL patterns for a tenant, modify /etc/security/{{tenant_identifier.xml}} . If you are not hosting multiple tenants on your Opencast server or cluster, all configuration should be done in mh_default_org.xml . Some examples: <!-- Allow anonymous access to the welcome.html URLs --> <sec:intercept-url pattern='/welcome.html' access='ROLE_ANONYMOUS,ROLE_USER'/> <!-- Allow anonymous GET to the search service, but not POST or PUT --> <sec:intercept-url pattern='/search/**' method=\"GET\" access='ROLE_ANONYMOUS,ROLE_USER' /> <!-- Allow users with the admin role to do anything --> <sec:intercept-url pattern='/**' access='ROLE_ADMIN'/> Authentication Provider Opencast specifies an AuthenticationProvider by default, using a UserDetailService that is obtained from the OSGI service registry. You can use this simple provider as is, loading users into the oc_user and oc_role database tables, and specifying an administrative username and password in custom.properties : org.opencastproject.security.digest.user=opencast_system_account org.opencastproject.security.digest.pass=CHANGE_ME User and Role Providers Opencast allows user and role information to be supplied from external systems through user and role providers. Four user providers are available by default: LDAP User Provider, described in LDAP Security and Authorization Sakai User Provider Moodle User Provider Brightspace D2L User Provider The set of user and role providers can be configured. If you do not want to keep users and passwords in Opencast's database, you can replace the JpaUserAndRoleProvider with the LdapUserProvider by replacing the userdirectory-jpa jar with the userdirectory-ldap jar. Further Authentication Configuration Configure Central Authentication Service (CAS) Configure LDAP Authentication and Authorization Configure Authentication and Authorization Infrastructure (AAI)","title":"General Security"},{"location":"configuration/security/#security-configuration","text":"This document will help you configure the Opencast security policy.","title":"Security Configuration"},{"location":"configuration/security/#introduction","text":"Opencast service endpoints and user interfaces are secured by default using a set of servlet filters. The following diagram illustrates the flow of an HTTP request and response through these filters. The Spring Security filters used here are very powerful, but are also somewhat complicated. Please familiarize yourself with the basic concepts and vocabulary described in the Spring Security documentation, then edit the xml files in etc/security , as described below.","title":"Introduction"},{"location":"configuration/security/#configure-access","text":"To configure access roles and URL patterns for a tenant, modify /etc/security/{{tenant_identifier.xml}} . If you are not hosting multiple tenants on your Opencast server or cluster, all configuration should be done in mh_default_org.xml . Some examples: <!-- Allow anonymous access to the welcome.html URLs --> <sec:intercept-url pattern='/welcome.html' access='ROLE_ANONYMOUS,ROLE_USER'/> <!-- Allow anonymous GET to the search service, but not POST or PUT --> <sec:intercept-url pattern='/search/**' method=\"GET\" access='ROLE_ANONYMOUS,ROLE_USER' /> <!-- Allow users with the admin role to do anything --> <sec:intercept-url pattern='/**' access='ROLE_ADMIN'/>","title":"Configure Access"},{"location":"configuration/security/#authentication-provider","text":"Opencast specifies an AuthenticationProvider by default, using a UserDetailService that is obtained from the OSGI service registry. You can use this simple provider as is, loading users into the oc_user and oc_role database tables, and specifying an administrative username and password in custom.properties : org.opencastproject.security.digest.user=opencast_system_account org.opencastproject.security.digest.pass=CHANGE_ME","title":"Authentication Provider"},{"location":"configuration/security/#user-and-role-providers","text":"Opencast allows user and role information to be supplied from external systems through user and role providers. Four user providers are available by default: LDAP User Provider, described in LDAP Security and Authorization Sakai User Provider Moodle User Provider Brightspace D2L User Provider The set of user and role providers can be configured. If you do not want to keep users and passwords in Opencast's database, you can replace the JpaUserAndRoleProvider with the LdapUserProvider by replacing the userdirectory-jpa jar with the userdirectory-ldap jar.","title":"User and Role Providers"},{"location":"configuration/security/#further-authentication-configuration","text":"Configure Central Authentication Service (CAS) Configure LDAP Authentication and Authorization Configure Authentication and Authorization Infrastructure (AAI)","title":"Further Authentication Configuration"},{"location":"configuration/security.user.brightspace/","text":"What it does The Brightspace User Provider enriches Opencast users with a set of roles made up of the user's membership in Brightspace courses, of the form ROLE_courseID. For example, an Opencast user who is also a Brightspace user and a member of the Brightspace course myCourseID will be granted the Opencast role ROLE_myCourseID . Requirements Step 1 To enable the Brightspace User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.brightspace-default.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.brightspace-default.cfg Edit the configuration file to set your Brightspace URL and the credentials needed for making authenticated API calls. # The organization for this provider org.opencastproject.userdirectory.brightspace.org=mh_default_org # The URL for the Brightspace REST webservice org.opencastproject.userdirectory.brightspace.url=https://brightspace-api # properties for authentication in brightspace api org.opencastproject.userdirectory.brightspace.systemuser.id=system-user-id org.opencastproject.userdirectory.brightspace.systemuser.key=system-user-key org.opencastproject.userdirectory.brightspace.application.id=application-id org.opencastproject.userdirectory.brightspace.application.key=application-key # The maximum number of users to cache #org.opencastproject.userdirectory.brightspace.cache.size=1000 # The maximum number of minutes to cache a user #org.opencastproject.userdirectory.brightspace.cache.expiration=60 Step 2 Verify that the Brightspace User Provider starts up with the correct Brightspace URL by looking for a log entry like this: (BrightspaceUserProviderInstance:143) - Creating new BrightspaceUserProviderInstance(pid=org.opencastproject.userdirectory.brightspace.378cdff4-825f-4b60-b1ed-33f75aa7f265, url= ... , cacheSize=1000, cacheExpiration=60) Then login to Opencast using a username which also exists in your Brightspace system. Verify the roles granted to the user by opening the url OPENCAST-URL/info/me.json in a new browser tab, or navigate to the user details and open the tab \"Effective Roles\". If necessary, you can increase the logging detail from the Brightspace user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j.logger.org.opencastproject.userdirectory.brightspace=DEBUG","title":"Brightspace User Provider"},{"location":"configuration/security.user.brightspace/#what-it-does","text":"The Brightspace User Provider enriches Opencast users with a set of roles made up of the user's membership in Brightspace courses, of the form ROLE_courseID. For example, an Opencast user who is also a Brightspace user and a member of the Brightspace course myCourseID will be granted the Opencast role ROLE_myCourseID .","title":"What it does"},{"location":"configuration/security.user.brightspace/#requirements","text":"","title":"Requirements"},{"location":"configuration/security.user.brightspace/#step-1","text":"To enable the Brightspace User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.brightspace-default.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.brightspace-default.cfg Edit the configuration file to set your Brightspace URL and the credentials needed for making authenticated API calls. # The organization for this provider org.opencastproject.userdirectory.brightspace.org=mh_default_org # The URL for the Brightspace REST webservice org.opencastproject.userdirectory.brightspace.url=https://brightspace-api # properties for authentication in brightspace api org.opencastproject.userdirectory.brightspace.systemuser.id=system-user-id org.opencastproject.userdirectory.brightspace.systemuser.key=system-user-key org.opencastproject.userdirectory.brightspace.application.id=application-id org.opencastproject.userdirectory.brightspace.application.key=application-key # The maximum number of users to cache #org.opencastproject.userdirectory.brightspace.cache.size=1000 # The maximum number of minutes to cache a user #org.opencastproject.userdirectory.brightspace.cache.expiration=60","title":"Step 1"},{"location":"configuration/security.user.brightspace/#step-2","text":"Verify that the Brightspace User Provider starts up with the correct Brightspace URL by looking for a log entry like this: (BrightspaceUserProviderInstance:143) - Creating new BrightspaceUserProviderInstance(pid=org.opencastproject.userdirectory.brightspace.378cdff4-825f-4b60-b1ed-33f75aa7f265, url= ... , cacheSize=1000, cacheExpiration=60) Then login to Opencast using a username which also exists in your Brightspace system. Verify the roles granted to the user by opening the url OPENCAST-URL/info/me.json in a new browser tab, or navigate to the user details and open the tab \"Effective Roles\". If necessary, you can increase the logging detail from the Brightspace user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j.logger.org.opencastproject.userdirectory.brightspace=DEBUG","title":"Step 2"},{"location":"configuration/security.user.moodle/","text":"What it does The Moodle User Provider enriches Opencast users with a set of roles made up of the user's membership in Moodle courses, of the form COURSEID_Role. For example, an Opencast user who is also a Moodle user and a member of the Moodle course myCourseID with the Moodle capability tool/opencast:learner will be granted the Opencast role myCourseID_Learner . Analogously, users with the capability tool/opencast:instructor will recieve the Opencast role myCourseID_Instructor . Note that by default, Moodle course IDs are opaque ID values such as 10765 . The ROLE_GROUP_MOODLE Opencast group role is granted to all users that also exist in Moodle. The mapping of Moodle courses and capabilities to Opencast roles is consistent with the course and role mapping used by the LTI endpoint. The Moodle User Provider can therefore be used with LTI or another method of authenticating users. The Moodle Role Provider allows Moodle course and capability combinations to be used in Event and Series ACLs. For example, the role myCourseID_Learner can be added to a Series ACL to grant access to the Series to members of the myCourseID course in Moodle. Requirements The Moodle User Provider requires the moodle-tool_opencast plug-in that extends Moodle with the necessary API functions and capabilities. As this plug-in also provides base settings for additional Moodle plug-ins, the user is asked to provide Opencast API login information during the installation. The values can be arbitrary, if only the Moodle User Provider should be configured. After the installation, a new user with the capabilities webservice/rest:use , tool/opencast:externalapi , moodle/user:viewalldetails , moodle/user:viewdetails and moodle/site:accessallgroups has to be created. Then generate a new web service token and add that user to the \"Opencast web service\" service. Step 1 Edit etc/org.apache.karaf.features.cfg and make sure the opencast-moodle feature is listed in the featuresBoot option. Step 2 To enable the Moodle User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.moodle-default.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.moodle-default.cfg Edit the configuration file to set your Moodle URL and the web service token of the Moodle user that should be used for API calls. # The URL and token for the Moodle REST webservice org.opencastproject.userdirectory.moodle.url=http://localhost/webservice/rest/server.php org.opencastproject.userdirectory.moodle.token=mytoken1234abcdef Step 3 Verify that the Moodle User Provider starts up with the correct Moodle URL by looking for a log entry like this: (MoodleUserProviderInstance:143) - Creating new MoodleUserProviderInstance(pid=org.opencastproject.userdirectory.moodle.378cdff4-825f-4b60-b1ed-33f75aa7f265, url=http://localhost/webservice/rest/server.php, cacheSize=1000, cacheExpiration=60) Then login to Opencast using a username which also exists in your Moodle system. Verify the roles granted to the user by opening the url OPENCAST-URL/info/me.json in a new browser tab, or navigate to the user details and open the tab \"Effective Roles\". If necessary, you can increase the logging detail from the Moodle user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j.logger.org.opencastproject.userdirectory.moodle=DEBUG Step 4 You can grant additional roles to all Moodle users in Opencast by creating a group with the name 'Moodle'. You can then add additional roles to this group, which will be inherited by all Moodle users. You can also use the group role name ROLE_GROUP_MOODLE in Event or Series ACLs.","title":"Moodle User Provider"},{"location":"configuration/security.user.moodle/#what-it-does","text":"The Moodle User Provider enriches Opencast users with a set of roles made up of the user's membership in Moodle courses, of the form COURSEID_Role. For example, an Opencast user who is also a Moodle user and a member of the Moodle course myCourseID with the Moodle capability tool/opencast:learner will be granted the Opencast role myCourseID_Learner . Analogously, users with the capability tool/opencast:instructor will recieve the Opencast role myCourseID_Instructor . Note that by default, Moodle course IDs are opaque ID values such as 10765 . The ROLE_GROUP_MOODLE Opencast group role is granted to all users that also exist in Moodle. The mapping of Moodle courses and capabilities to Opencast roles is consistent with the course and role mapping used by the LTI endpoint. The Moodle User Provider can therefore be used with LTI or another method of authenticating users. The Moodle Role Provider allows Moodle course and capability combinations to be used in Event and Series ACLs. For example, the role myCourseID_Learner can be added to a Series ACL to grant access to the Series to members of the myCourseID course in Moodle.","title":"What it does"},{"location":"configuration/security.user.moodle/#requirements","text":"The Moodle User Provider requires the moodle-tool_opencast plug-in that extends Moodle with the necessary API functions and capabilities. As this plug-in also provides base settings for additional Moodle plug-ins, the user is asked to provide Opencast API login information during the installation. The values can be arbitrary, if only the Moodle User Provider should be configured. After the installation, a new user with the capabilities webservice/rest:use , tool/opencast:externalapi , moodle/user:viewalldetails , moodle/user:viewdetails and moodle/site:accessallgroups has to be created. Then generate a new web service token and add that user to the \"Opencast web service\" service.","title":"Requirements"},{"location":"configuration/security.user.moodle/#step-1","text":"Edit etc/org.apache.karaf.features.cfg and make sure the opencast-moodle feature is listed in the featuresBoot option.","title":"Step 1"},{"location":"configuration/security.user.moodle/#step-2","text":"To enable the Moodle User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.moodle-default.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.moodle-default.cfg Edit the configuration file to set your Moodle URL and the web service token of the Moodle user that should be used for API calls. # The URL and token for the Moodle REST webservice org.opencastproject.userdirectory.moodle.url=http://localhost/webservice/rest/server.php org.opencastproject.userdirectory.moodle.token=mytoken1234abcdef","title":"Step 2"},{"location":"configuration/security.user.moodle/#step-3","text":"Verify that the Moodle User Provider starts up with the correct Moodle URL by looking for a log entry like this: (MoodleUserProviderInstance:143) - Creating new MoodleUserProviderInstance(pid=org.opencastproject.userdirectory.moodle.378cdff4-825f-4b60-b1ed-33f75aa7f265, url=http://localhost/webservice/rest/server.php, cacheSize=1000, cacheExpiration=60) Then login to Opencast using a username which also exists in your Moodle system. Verify the roles granted to the user by opening the url OPENCAST-URL/info/me.json in a new browser tab, or navigate to the user details and open the tab \"Effective Roles\". If necessary, you can increase the logging detail from the Moodle user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j.logger.org.opencastproject.userdirectory.moodle=DEBUG","title":"Step 3"},{"location":"configuration/security.user.moodle/#step-4","text":"You can grant additional roles to all Moodle users in Opencast by creating a group with the name 'Moodle'. You can then add additional roles to this group, which will be inherited by all Moodle users. You can also use the group role name ROLE_GROUP_MOODLE in Event or Series ACLs.","title":"Step 4"},{"location":"configuration/security.user.sakai/","text":"What it does The Sakai User Provider enriches Opencast users with a set of roles made up of the user's membership in Sakai sites, of the form SITEID_Role. For example, an Opencast user who is also a Sakai user and a member of the Sakai site mysiteid with the Sakai role Student will be granted the Opencast role mysiteid_Learner . Note that by default, Sakai site IDs are opaque GUID values such as d02f250e-be2d-4b72-009a-161d66ed6df9 . The mapping of Sakai sites and roles to Opencast roles is consistent with the site and role mapping used by the LTI endpoint. The Sakai User Provider can therefore be used with LTI or another method of authenticating users. The Sakai Role Provider allows Sakai site and role combinations to be used in Event and Series ACLs. For example, the role mysiteid_Learner can be added to a Series ACL to grant access to the Series to members of the mysiteid site in Sakai. Requirements The Sakai User Provider requires Sakai 11.0 or later, and an admin-equivalent account on the Sakai instance. Step 1 Edit etc/org.apache.karaf.features.cfg and make sure the opencast-sakai feature is listed in the featuresBoot option. Step 2 To enable the Sakai User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.sakai-default.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.sakai-default.cfg Edit the configuration file to set your Sakai URL, and the username and password of the admin user on the Sakai system: sakai.url=https://mysakai.my.domain sakai.user=opencast sakai.password=CHANGE_ME Step 3 Verify that the Sakai User Provider starts up with the correct Sakai URL by looking for a log entry like this: (SakaiUserProviderInstance:154) - Creating new SakaiUserProviderInstance(pid=org.opencastproject.userdirectory.sakai.f1fad141-8cc8-41ee-b514-8dad00984af6, url=https://mysakai.my.domain, cacheSize=1000, cacheExpiration=60) Then login to Opencast using a username which also exists in your Sakai system. Verify the roles granted to the user by opening the url OPENCAST-URL/info/me.json in a new browser tab. If necessary, you can increase the logging detail from the Sakai user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j.logger.org.opencastproject.userdirectory.sakai=DEBUG Step 4 You can grant additional roles to all Sakai users in Opencast by creating a group with the title 'Sakai'. You can then add additional roles to this group, which will be inherited by all Sakai users. You can also use the group role name ROLE_GROUP_SAKAI in Event or Series ACLs.","title":"Sakai User Provider"},{"location":"configuration/security.user.sakai/#what-it-does","text":"The Sakai User Provider enriches Opencast users with a set of roles made up of the user's membership in Sakai sites, of the form SITEID_Role. For example, an Opencast user who is also a Sakai user and a member of the Sakai site mysiteid with the Sakai role Student will be granted the Opencast role mysiteid_Learner . Note that by default, Sakai site IDs are opaque GUID values such as d02f250e-be2d-4b72-009a-161d66ed6df9 . The mapping of Sakai sites and roles to Opencast roles is consistent with the site and role mapping used by the LTI endpoint. The Sakai User Provider can therefore be used with LTI or another method of authenticating users. The Sakai Role Provider allows Sakai site and role combinations to be used in Event and Series ACLs. For example, the role mysiteid_Learner can be added to a Series ACL to grant access to the Series to members of the mysiteid site in Sakai.","title":"What it does"},{"location":"configuration/security.user.sakai/#requirements","text":"The Sakai User Provider requires Sakai 11.0 or later, and an admin-equivalent account on the Sakai instance.","title":"Requirements"},{"location":"configuration/security.user.sakai/#step-1","text":"Edit etc/org.apache.karaf.features.cfg and make sure the opencast-sakai feature is listed in the featuresBoot option.","title":"Step 1"},{"location":"configuration/security.user.sakai/#step-2","text":"To enable the Sakai User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.sakai-default.cfg.template to OPENCAST/etc/org.opencastproject.userdirectory.sakai-default.cfg Edit the configuration file to set your Sakai URL, and the username and password of the admin user on the Sakai system: sakai.url=https://mysakai.my.domain sakai.user=opencast sakai.password=CHANGE_ME","title":"Step 2"},{"location":"configuration/security.user.sakai/#step-3","text":"Verify that the Sakai User Provider starts up with the correct Sakai URL by looking for a log entry like this: (SakaiUserProviderInstance:154) - Creating new SakaiUserProviderInstance(pid=org.opencastproject.userdirectory.sakai.f1fad141-8cc8-41ee-b514-8dad00984af6, url=https://mysakai.my.domain, cacheSize=1000, cacheExpiration=60) Then login to Opencast using a username which also exists in your Sakai system. Verify the roles granted to the user by opening the url OPENCAST-URL/info/me.json in a new browser tab. If necessary, you can increase the logging detail from the Sakai user provider by adding an entry to OPENCAST/etc/org.ops4j.pax.logging.cfg : log4j.logger.org.opencastproject.userdirectory.sakai=DEBUG","title":"Step 3"},{"location":"configuration/security.user.sakai/#step-4","text":"You can grant additional roles to all Sakai users in Opencast by creating a group with the title 'Sakai'. You can then add additional roles to this group, which will be inherited by all Sakai users. You can also use the group role name ROLE_GROUP_SAKAI in Event or Series ACLs.","title":"Step 4"},{"location":"configuration/stream-security/","text":"Configuration of Stream Security To get an introduction to stream security before deploying, please read the overview at: Stream Security Overview It is important to note that if stream security is enabled, all resources will be signed and protected, even ones that do not have any access restrictions defined in their access control lists. Accessing resources with unsigned URLs will not be possible. On a high level, to use Stream security, these steps are required: Install and configure the URL signing service and signing providers Configure Opencast services (and, optionally, 3rd party services) that use the signing infrastructure to sign requests Install and configure verification components URL Signing Service Installation There are three modules that are built by default and need to be present on each Opencast node in order to initiate URL signing: urlsigning-common urlsigning-service-api urlsigning-service-impl If these modules are present, the URL signing service will be available, to which the URL signing providers can then register themselves. Minimal Configuration Example This is a minimal configuration example which requires valid tokens for all static file downloads: etc/org.opencastproject.security.urlsigning.filter.UrlSigningFilter.cfg : enabled=true url.regex.files=.*localhost:8080/static/.* etc/org.opencastproject.security.urlsigning.provider.impl.GenericUrlSigningProvider.cfg key.default.secret=THISISNOSECUREKEY key.default.url=http://localhost:8080/static/ etc/org.opencastproject.security.urlsigning.verifier.impl.UrlSigningVerifierImpl.cfg : key.default=THISISNOSECUREKEY Configuration of Signing Providers The GenericUrlSigningProvider that comes with Opencast has its own configuration file: etc/org.opencastproject.security.urlsigning.provider.impl.GenericUrlSigningProvider.cfg All signing providers follow the same configuration structure and support multiple configuration blocks, providing the settings for separate distributions (i.e. download or streaming servers, services or paths). Each signing key configuration consists of the following attributes: Key ID: Key identifier, e.g. demoKeyOne Key secret: Key value, e.g. 25DA2BA549CB62EF297977845259A . The key-length is not predefined, but a key length of at least 128 bit is recommended. Any larger value will not increase security of the underlying algorithm URL prefix: The URL signing provider will only sign URLs that start with this value. This allows to support multiple distributions and different key pairs Organization: Keys can be restricted to organizations so that different organizations use different keys. This attribute is optional. If not specified, the key can be used by all organizations A typical configuration looks like this: key.demoKeyOne.secret=6EDB5EDDCF994B7432C371D7C274F key.demoKeyOne.url=http://download.opencast.org/engage key.demoKeyTwo.secret=6EDB5EDDCF994B7432C371D7C274F key.demoKeyTwo.url=http://download.opencast.org/custom key.demoKeyTwo.organization=mh_default_org It is also possible to use one key for multiple URL prefixes: key.demoKeyThree.secret=6EDB5EDDCF994B7432C371D7C274F key.demoKeyThree.url.http=http://download.opencast.org/custom key.demoKeyThree.url.https=https://download.opencast.org/custom key.demoKeyThree.url.streaming=http://streaming.opencast.org/custom key.demoKeyThree.organization=mh_default_org A Java regular expression can be defined to identify URLs to be excluded from URL signing. Any URL that matches this anchored regex will not be signed. exclude.url.pattern=.*/.*/unprotected/.*/.* Configuration of URL Signing Timeout Values Once stream security is turned on by configuring the signing providers, multiple different services within Opencast will be signing URLs, and while some services are signing on behalf of administrative users working in the Opencast administrative user interface, others are signing URLs in order to grant access to learners playing back video content i.e. the functionality we have been talking about up to now. This section explains how to best configure URLs to ensure that they expire at the right time. This might be required if the default valid times do not seem secure enough or is more secure than needed. Signing for external access The lifetime of the signed URLs can be configured by setting a custom value for the property url.signing.expires.seconds that defines the validity in seconds. The default valid time is 7200 seconds (2 hours). The signed URLs can also be configured to restrict access to the user\u2019s IP address by setting the property url.signing.use.client.ip to true. By default this is disabled. Overview of configuration files for services that are able to automatically sign URLs on behalf of users: URLs That Are Signed Configuration File Name Video player content org.opencastproject.security.urlsigning.SigningMediaPackageSerializer.cfg Admin UI links org.opencastproject.adminui.endpoint.OsgiEventEndpoint.cfg Preview and editor files org.opencastproject.adminui.endpoint.ToolsEndpoint.cfg The URLs will be signed by the first signing provider that will accept the URL\u2019s path based upon the signing provider\u2019s configuration. This makes it flexible to support many different scenarios. For example, we could configure the signing provider to have one key for any URL that begins with one scheme, such as http, which would cover all of the URLs to be signed with a single key. Or it could be configured so that each different scheme and hostname pair would have a different keys protecting each host\u2019s URLs separately etc. Having the timing configurations separate from the key configuration allows the different types of URLs to be signed differently depending on the needs of the users without needing to configure this timing for all of the different keys. Signing for Opencast-internal access Signing of requests for internal use is performed by a core component called TrustedHttpClientImpl , which is used to establish all internal HTTP connections. More specifically, the HTTP client needs access to internal storage areas such as the working file repository as well as to distributed artifacts on the downloads and streaming servers, all of which are protected by verification components. The default expiration time for signed internal requests is 60 seconds. This can be changed by setting a value in seconds for the org.opencastproject.security.internal.url.signing.duration property in the custom.properties configuration file. Since those URLs are signed right before the request is made, the valid time of 60 seconds should be sufficiently long. Configuration of Verification Components The verification components ensure that only valid and correctly signed URLs are accessible at any given time. URLs which are not properly signed or have expired will be rejected. Out of the box, Opencast provides an internal verification component: Opencast internal UrlSigningFilter The following section is dedicated to the installation and configuration of the Opencast internal UrlSigningFilter. The stream security architecture allows the implementation for URL verification for third-party applications which are not covered in this documentation. Configuration of Opencast verification filter The Servlet filter providing the verification of requests to Opencast internal resources is implemented in the bundles: urlsigning-verifier-service-api urlsigning-verifier-service-impl The filter uses a set of regular expressions to determine which requests to an Opencast instance need to be verified. Installation The bundles are built by default and as soon as they are running in Opencast, the filter is active, and ready to be enabled. Configuration Two things need to be configured for the Opencast verification filter: key pairs used to verify the signatures paths and endpoints that need to be protected The configuration is located at: etc/org.opencastproject.security.urlsigning.verifier.impl.UrlSigningVerifierImpl.cfg Example: key.demoKeyOne=6EDB5EDDCF994B7432C371D7C274F key.demoKeyTwo=C843C21ECF59F2B38872A1BCAA774 The entries in this file need to have the same values for the signing providers configuration. The second step is to configure the filter defining the endpoints to be protected. The configuration file is located at: etc/org.opencastproject.security.urlsigning.filter.UrlSigningFilter.cfg The configuration defaults to a set of regular expressions which match all of the endpoints that serve files, and avoid protecting endpoints that only serve data. Therefore, the remaining step is enabling the filter by setting the property enabled to true and determining whether strict or non-strict verification of the resource is required. Note that strict verification of resources means the entire URL will be considered when comparing the incoming request for a resource against the policy, including the scheme (http, https, etc.), hostname and port. If turned off, only the path to the resource will be considered. So if the resource http://httpdserver:8080/the/full/path/video.mp4 is requested, only the /the/full/path/video.mp4 part of the URL will be checked against the policy\u2019s path. As mentioned before, this is useful when using a load balancer so that the requested host name does not have to match the actual hostname or if a video player is rewriting requests, e.g. by inserting the port number. Example: enabled=true strict=true url.regex.collection=.*files\\/collection\\/.* url.regex.mediapackage=.*files\\/mediapackage\\/.* url.regex.staticfiles=(?\\=(.*staticfiles.*))(?=^(?!.*staticfiles.*url|.*docs.*).*$)(.*) url.regex.archive=.*archive\\/archive\\/mediapackage\\/.*\\/.*\\/.* url.regex.static=.*static.* Testing Once all components of Stream Security are installed and properly configured, it is important to verify that the system is working as expected. It is especially important to try to access resources that should not be accessible. There are ways to test in a structured way which will be explained below. Creating Signed URLs with Signing Endpoint The signing service provides a REST endpoint, which allows for the signing of arbitrary URLs. For manual use it is recommended to visit the endpoint\u2019s documentation page at http://localhost:8080/signing/docs . Is the URL accepted? Check if the URL to be signed is accepted by the signing service (or by one of its signing providers respectively) by using the /signing/accepts endpoint. If that is not the case, the configuration of the signing providers should be checked again to ensure that at least one signing provider is responsible for the URL in question. If the service is fully operational, the response code will be 200 OK and the response body either true (accepted) or false (refused). Signing the URL On the same documentation page URLs can be signed using the /signing/sign endpoint, and the access policy may be specified in that form as well. With this, several scenarios can be tested. Examples are: URLs that have already expired or will expire at a known date URLs that are not yet valid (if you provided a validFrom data in the access policy) URLs that are missing some or all of the signing parameters (policy, keyId or signature) URLs that are attempting to use signing parameters (policy and signature) from a different signed URL Verifying the URL The signed URLs can then be passed to the appropriate testing tool (web browser, cURL, player, \u2026) to test the functionality of the verification component(s). The following table is the return codes associated with different rejection conditions: Case Return Code If any of the query string parameters are missing or are the wrong case / spelt incorrectly Bad Request (400) If any of the required policy variables are missing Bad Request (400) No encryption key that matches the KeyID known by the plugin Bad Request (400) The Policy and Signature don\u2019t match in any way Forbidden (403) If client IP is specified and doesn\u2019t match Forbidden (403) The current time has passed the DateGreaterThan, the time the URL expires Gone (410) The current time is before the DateLessThan, the time the URL becomes available Gone (410) The components that verify a URL is signed will run before a request is checked to be valid, so if a non-existent URL is signed for example, the above conditions will need to be fixed before a missing (404) response code will be returned. Inspect policy The generated policy which is added to the signed URLs can be inspected. It needs to be decoded from Base64 and the result must be a JSON document that contains exactly the values which have been passed during signing. Decoding this Base64 encoded policy eyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRh dGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0 \u2026would result in this JSON document (policy): { \"Statement\":{ \"Resource\":\"http:\\/\\/opencast.org\\/engage\\/resource.mp4\", \"Condition\":{ \"DateLessThan\":1425170777000, \"DateGreaterThan\":1425084379000, \"IpAddress\":\"10.0.0.1\" } } } Inspecting and modifying the policy is useful for advanced testing, such as: URLs where the policy was modified after signing URLs where the policy was modified and resigned with a different key Further information For an overview of Stream Security: Stream Security Overview For further developer information, please have a look at the stream security section in the developer guide.","title":"Stream Security"},{"location":"configuration/stream-security/#configuration-of-stream-security","text":"To get an introduction to stream security before deploying, please read the overview at: Stream Security Overview It is important to note that if stream security is enabled, all resources will be signed and protected, even ones that do not have any access restrictions defined in their access control lists. Accessing resources with unsigned URLs will not be possible. On a high level, to use Stream security, these steps are required: Install and configure the URL signing service and signing providers Configure Opencast services (and, optionally, 3rd party services) that use the signing infrastructure to sign requests Install and configure verification components","title":"Configuration of Stream Security"},{"location":"configuration/stream-security/#url-signing-service-installation","text":"There are three modules that are built by default and need to be present on each Opencast node in order to initiate URL signing: urlsigning-common urlsigning-service-api urlsigning-service-impl If these modules are present, the URL signing service will be available, to which the URL signing providers can then register themselves.","title":"URL Signing Service Installation"},{"location":"configuration/stream-security/#minimal-configuration-example","text":"This is a minimal configuration example which requires valid tokens for all static file downloads: etc/org.opencastproject.security.urlsigning.filter.UrlSigningFilter.cfg : enabled=true url.regex.files=.*localhost:8080/static/.* etc/org.opencastproject.security.urlsigning.provider.impl.GenericUrlSigningProvider.cfg key.default.secret=THISISNOSECUREKEY key.default.url=http://localhost:8080/static/ etc/org.opencastproject.security.urlsigning.verifier.impl.UrlSigningVerifierImpl.cfg : key.default=THISISNOSECUREKEY","title":"Minimal Configuration Example"},{"location":"configuration/stream-security/#configuration-of-signing-providers","text":"The GenericUrlSigningProvider that comes with Opencast has its own configuration file: etc/org.opencastproject.security.urlsigning.provider.impl.GenericUrlSigningProvider.cfg All signing providers follow the same configuration structure and support multiple configuration blocks, providing the settings for separate distributions (i.e. download or streaming servers, services or paths). Each signing key configuration consists of the following attributes: Key ID: Key identifier, e.g. demoKeyOne Key secret: Key value, e.g. 25DA2BA549CB62EF297977845259A . The key-length is not predefined, but a key length of at least 128 bit is recommended. Any larger value will not increase security of the underlying algorithm URL prefix: The URL signing provider will only sign URLs that start with this value. This allows to support multiple distributions and different key pairs Organization: Keys can be restricted to organizations so that different organizations use different keys. This attribute is optional. If not specified, the key can be used by all organizations A typical configuration looks like this: key.demoKeyOne.secret=6EDB5EDDCF994B7432C371D7C274F key.demoKeyOne.url=http://download.opencast.org/engage key.demoKeyTwo.secret=6EDB5EDDCF994B7432C371D7C274F key.demoKeyTwo.url=http://download.opencast.org/custom key.demoKeyTwo.organization=mh_default_org It is also possible to use one key for multiple URL prefixes: key.demoKeyThree.secret=6EDB5EDDCF994B7432C371D7C274F key.demoKeyThree.url.http=http://download.opencast.org/custom key.demoKeyThree.url.https=https://download.opencast.org/custom key.demoKeyThree.url.streaming=http://streaming.opencast.org/custom key.demoKeyThree.organization=mh_default_org A Java regular expression can be defined to identify URLs to be excluded from URL signing. Any URL that matches this anchored regex will not be signed. exclude.url.pattern=.*/.*/unprotected/.*/.*","title":"Configuration of Signing Providers"},{"location":"configuration/stream-security/#configuration-of-url-signing-timeout-values","text":"Once stream security is turned on by configuring the signing providers, multiple different services within Opencast will be signing URLs, and while some services are signing on behalf of administrative users working in the Opencast administrative user interface, others are signing URLs in order to grant access to learners playing back video content i.e. the functionality we have been talking about up to now. This section explains how to best configure URLs to ensure that they expire at the right time. This might be required if the default valid times do not seem secure enough or is more secure than needed.","title":"Configuration of URL Signing Timeout Values"},{"location":"configuration/stream-security/#signing-for-external-access","text":"The lifetime of the signed URLs can be configured by setting a custom value for the property url.signing.expires.seconds that defines the validity in seconds. The default valid time is 7200 seconds (2 hours). The signed URLs can also be configured to restrict access to the user\u2019s IP address by setting the property url.signing.use.client.ip to true. By default this is disabled. Overview of configuration files for services that are able to automatically sign URLs on behalf of users: URLs That Are Signed Configuration File Name Video player content org.opencastproject.security.urlsigning.SigningMediaPackageSerializer.cfg Admin UI links org.opencastproject.adminui.endpoint.OsgiEventEndpoint.cfg Preview and editor files org.opencastproject.adminui.endpoint.ToolsEndpoint.cfg The URLs will be signed by the first signing provider that will accept the URL\u2019s path based upon the signing provider\u2019s configuration. This makes it flexible to support many different scenarios. For example, we could configure the signing provider to have one key for any URL that begins with one scheme, such as http, which would cover all of the URLs to be signed with a single key. Or it could be configured so that each different scheme and hostname pair would have a different keys protecting each host\u2019s URLs separately etc. Having the timing configurations separate from the key configuration allows the different types of URLs to be signed differently depending on the needs of the users without needing to configure this timing for all of the different keys.","title":"Signing for external access"},{"location":"configuration/stream-security/#signing-for-opencast-internal-access","text":"Signing of requests for internal use is performed by a core component called TrustedHttpClientImpl , which is used to establish all internal HTTP connections. More specifically, the HTTP client needs access to internal storage areas such as the working file repository as well as to distributed artifacts on the downloads and streaming servers, all of which are protected by verification components. The default expiration time for signed internal requests is 60 seconds. This can be changed by setting a value in seconds for the org.opencastproject.security.internal.url.signing.duration property in the custom.properties configuration file. Since those URLs are signed right before the request is made, the valid time of 60 seconds should be sufficiently long.","title":"Signing for Opencast-internal access"},{"location":"configuration/stream-security/#configuration-of-verification-components","text":"The verification components ensure that only valid and correctly signed URLs are accessible at any given time. URLs which are not properly signed or have expired will be rejected. Out of the box, Opencast provides an internal verification component: Opencast internal UrlSigningFilter The following section is dedicated to the installation and configuration of the Opencast internal UrlSigningFilter. The stream security architecture allows the implementation for URL verification for third-party applications which are not covered in this documentation.","title":"Configuration of Verification Components"},{"location":"configuration/stream-security/#configuration-of-opencast-verification-filter","text":"The Servlet filter providing the verification of requests to Opencast internal resources is implemented in the bundles: urlsigning-verifier-service-api urlsigning-verifier-service-impl The filter uses a set of regular expressions to determine which requests to an Opencast instance need to be verified.","title":"Configuration of Opencast verification filter"},{"location":"configuration/stream-security/#installation","text":"The bundles are built by default and as soon as they are running in Opencast, the filter is active, and ready to be enabled.","title":"Installation"},{"location":"configuration/stream-security/#configuration","text":"Two things need to be configured for the Opencast verification filter: key pairs used to verify the signatures paths and endpoints that need to be protected The configuration is located at: etc/org.opencastproject.security.urlsigning.verifier.impl.UrlSigningVerifierImpl.cfg Example: key.demoKeyOne=6EDB5EDDCF994B7432C371D7C274F key.demoKeyTwo=C843C21ECF59F2B38872A1BCAA774 The entries in this file need to have the same values for the signing providers configuration. The second step is to configure the filter defining the endpoints to be protected. The configuration file is located at: etc/org.opencastproject.security.urlsigning.filter.UrlSigningFilter.cfg The configuration defaults to a set of regular expressions which match all of the endpoints that serve files, and avoid protecting endpoints that only serve data. Therefore, the remaining step is enabling the filter by setting the property enabled to true and determining whether strict or non-strict verification of the resource is required. Note that strict verification of resources means the entire URL will be considered when comparing the incoming request for a resource against the policy, including the scheme (http, https, etc.), hostname and port. If turned off, only the path to the resource will be considered. So if the resource http://httpdserver:8080/the/full/path/video.mp4 is requested, only the /the/full/path/video.mp4 part of the URL will be checked against the policy\u2019s path. As mentioned before, this is useful when using a load balancer so that the requested host name does not have to match the actual hostname or if a video player is rewriting requests, e.g. by inserting the port number. Example: enabled=true strict=true url.regex.collection=.*files\\/collection\\/.* url.regex.mediapackage=.*files\\/mediapackage\\/.* url.regex.staticfiles=(?\\=(.*staticfiles.*))(?=^(?!.*staticfiles.*url|.*docs.*).*$)(.*) url.regex.archive=.*archive\\/archive\\/mediapackage\\/.*\\/.*\\/.* url.regex.static=.*static.*","title":"Configuration"},{"location":"configuration/stream-security/#testing","text":"Once all components of Stream Security are installed and properly configured, it is important to verify that the system is working as expected. It is especially important to try to access resources that should not be accessible. There are ways to test in a structured way which will be explained below.","title":"Testing"},{"location":"configuration/stream-security/#creating-signed-urls-with-signing-endpoint","text":"The signing service provides a REST endpoint, which allows for the signing of arbitrary URLs. For manual use it is recommended to visit the endpoint\u2019s documentation page at http://localhost:8080/signing/docs .","title":"Creating Signed URLs with Signing Endpoint"},{"location":"configuration/stream-security/#is-the-url-accepted","text":"Check if the URL to be signed is accepted by the signing service (or by one of its signing providers respectively) by using the /signing/accepts endpoint. If that is not the case, the configuration of the signing providers should be checked again to ensure that at least one signing provider is responsible for the URL in question. If the service is fully operational, the response code will be 200 OK and the response body either true (accepted) or false (refused).","title":"Is the URL accepted?"},{"location":"configuration/stream-security/#signing-the-url","text":"On the same documentation page URLs can be signed using the /signing/sign endpoint, and the access policy may be specified in that form as well. With this, several scenarios can be tested. Examples are: URLs that have already expired or will expire at a known date URLs that are not yet valid (if you provided a validFrom data in the access policy) URLs that are missing some or all of the signing parameters (policy, keyId or signature) URLs that are attempting to use signing parameters (policy and signature) from a different signed URL","title":"Signing the URL"},{"location":"configuration/stream-security/#verifying-the-url","text":"The signed URLs can then be passed to the appropriate testing tool (web browser, cURL, player, \u2026) to test the functionality of the verification component(s). The following table is the return codes associated with different rejection conditions: Case Return Code If any of the query string parameters are missing or are the wrong case / spelt incorrectly Bad Request (400) If any of the required policy variables are missing Bad Request (400) No encryption key that matches the KeyID known by the plugin Bad Request (400) The Policy and Signature don\u2019t match in any way Forbidden (403) If client IP is specified and doesn\u2019t match Forbidden (403) The current time has passed the DateGreaterThan, the time the URL expires Gone (410) The current time is before the DateLessThan, the time the URL becomes available Gone (410) The components that verify a URL is signed will run before a request is checked to be valid, so if a non-existent URL is signed for example, the above conditions will need to be fixed before a missing (404) response code will be returned.","title":"Verifying the URL"},{"location":"configuration/stream-security/#inspect-policy","text":"The generated policy which is added to the signed URLs can be inspected. It needs to be decoded from Base64 and the result must be a JSON document that contains exactly the values which have been passed during signing. Decoding this Base64 encoded policy eyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRh dGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0 \u2026would result in this JSON document (policy): { \"Statement\":{ \"Resource\":\"http:\\/\\/opencast.org\\/engage\\/resource.mp4\", \"Condition\":{ \"DateLessThan\":1425170777000, \"DateGreaterThan\":1425084379000, \"IpAddress\":\"10.0.0.1\" } } } Inspecting and modifying the policy is useful for advanced testing, such as: URLs where the policy was modified after signing URLs where the policy was modified and resigned with a different key","title":"Inspect policy"},{"location":"configuration/stream-security/#further-information","text":"For an overview of Stream Security: Stream Security Overview For further developer information, please have a look at the stream security section in the developer guide.","title":"Further information"},{"location":"configuration/user-statistics.and.privacy/","text":"User Statistics and Privacy There exists a newer and more complete tracking service using Matomo included as a module . The Opencast User-Tracking service stores user actions of the Opencast players in the database. This data is used for the footprint feature of the player and for the optional analytics component. Note that enabling all of the tracking options may result in legal problems depending on your country's privacy laws and the type of service you are running. The settings for tracking user data can be found in: .../etc/org.opencastproject.usertracking.impl.UserTrackingServiceImpl.cfg Tracking of user data can be controlled on two levels. First, tracking can be generally activated or deactivated. Second, if it is activated, the data being tracked can be defined. org.opencastproject.usertracking.detailedtrack defines if the user tracking JavaScript code is loaded and data about user actions are being sent to and stored by Opencast. Deactivating this will effectively stop all tracking. This may effect features like the footprints in the Opencast player. Default: true . If tracking is still activated, the following keys may be used to define the kind of data that is being tracked. The keys have no effect if tracking is turned off. Key Data to be tracked Default value org.opencastproject.usertracking.log.ip IP addresses false org.opencastproject.usertracking.log.user login names of users false org.opencastproject.usertracking.log.session Browser session-IDs false If you want to use the footprint feature but do not want to store any user specific data you can turn the tracking of IP addresses, usernames and session-IDs off.","title":"User Statistics and Privacy Configuration"},{"location":"configuration/user-statistics.and.privacy/#user-statistics-and-privacy","text":"There exists a newer and more complete tracking service using Matomo included as a module . The Opencast User-Tracking service stores user actions of the Opencast players in the database. This data is used for the footprint feature of the player and for the optional analytics component. Note that enabling all of the tracking options may result in legal problems depending on your country's privacy laws and the type of service you are running. The settings for tracking user data can be found in: .../etc/org.opencastproject.usertracking.impl.UserTrackingServiceImpl.cfg Tracking of user data can be controlled on two levels. First, tracking can be generally activated or deactivated. Second, if it is activated, the data being tracked can be defined. org.opencastproject.usertracking.detailedtrack defines if the user tracking JavaScript code is loaded and data about user actions are being sent to and stored by Opencast. Deactivating this will effectively stop all tracking. This may effect features like the footprints in the Opencast player. Default: true . If tracking is still activated, the following keys may be used to define the kind of data that is being tracked. The keys have no effect if tracking is turned off. Key Data to be tracked Default value org.opencastproject.usertracking.log.ip IP addresses false org.opencastproject.usertracking.log.user login names of users false org.opencastproject.usertracking.log.session Browser session-IDs false If you want to use the footprint feature but do not want to store any user specific data you can turn the tracking of IP addresses, usernames and session-IDs off.","title":"User Statistics and Privacy"},{"location":"configuration/workflow/","text":"Create a Custom Workflow Creating custom workflows can be complex. Some members of the community have contributed their production workflows to a public repo. Community Workflow Repository Please feel free to contribute your workflows when you have Opencast in production! This document will help you get started with creating your own Opencast workflows. For a list of available workflow operations, see: List of Workflow Operation Handler Overview A Opencast workflow is an ordered list of operations. There is no limit to the number of operations or their repetition in a given workflow. Workflow operations can be configured using configuration elements. The use of string replacement in configuration values allows workflows to dynamically adapt to a given input or user decision. Document Opencast workflows are defined in XML. The structure of a Opencast workflow looks like this: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> <id></id> <title></title> <tags></tags> <description></description> <displayOrder></displayOrder> <!-- Operations --> <operations> <operation></operation> ... </operations> </definition> Create a Workflow This sections will walk you through creating a custom workflow, which will encode ingested tracks to defined output format. Encoding Profiles First create or select the encoding profiles you want to use. For more details on this, have a look at the Encoding Profile Configuration Guide . For this guide we assume that we have an encoding profile mov-low.http which creates a distribution format definition for mp4 video and a feed-cover.http encoding profile to create thumbnail images for the videos. Describe the Workflow Start by naming the workflow and giving it a meaningful description: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> <id>example</id> <!-- Optionally specify an organization --> <organization>mh_default_org</organization> <!-- optionally specify roles for this workflow --> <roles> <role>ROLE_ADMIN</role> </roles> <title>Encode Mp4, Distribute and Publish</title> <tags> <!-- Tell the UI where to show this workflow --> <tag>upload</tag> <tag>schedule</tag> <tag>archive</tag> </tags> <description> 1. Encode to Mp4 and thumbnail. 2. Distribute to local repository. 3. Publish to search index. </description> <displayOrder>10</displayOrder> <!-- Operations --> <operations></operations> </definition> The id is used in several Opencast endpoints to identify and select this workflow. Make sure that this identifier is unique among all endpoints in the system (except in multitenant workflows, see organization below). The organization specifies the organization this workflow is valid for (thus, it only makes sense in multitenant installations). If there are two workflows with the same id, the one corresponding to the user\u2019s organization is always chosen. This pertains workflow dropdowns (for example, the \u201cAdd new event\u201d dropdown) as well as workflows included in other workflows via the include workflow operation handler. The roles define which user roles are allowed to see and start this workflow (a user needs one of the roles provided in the definition). If this is omitted or no roles are specified, everyone can see and start the workflow (provided the organization constraints are satisfied). Also, users with ROLE_ADMIN can see and start every workflow. Note that the workflows included in Opencast do not set roles. The tags define where the user interfaces may use these workflows. Useful tags are: upload : Usable for uploaded media schedule : Usable for scheduled events archive : Usable for archived media delete : Usable for deletion of events with publications editor : Usable from the video editor The displayOrder is an integer that indicates in what order workflow definitions shall be displayed by clients. If ommitted, the displayOrder defaults to 0 . Clients are expected to list workflow definitions in descending order. The description allows you to describe the workflow in detail. Blank lines are formatted as newlines, while single line breaks are ignored so that the XML remains compact and readable even with long paragraphs. Inspect the Media The first operation will be to inspect the media for technical metadata, such as format and length: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> ... <!-- Operations --> <operations> <!-- inspect media --> <operation id=\"inspect\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspect media package\"> </operation> </operations> </definition> The fail-on-error attribute is a boolean determining whether the workflow will throw an error to the exception-handler-workflow or simply proceed with the remaining operations. Encoding The next operations will encode the media to the Mp4 format: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> ... <!-- Operations --> <operations> <!-- inspect media --> ... <!-- encode: mp4 --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode camera to mp4\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"target-flavor\">presenter/delivery</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">mov-low.http</configuration> </configurations> </operation> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode screen to mp4\"> <configurations> <configuration key=\"source-flavor\">presentation/source</configuration> <configuration key=\"target-flavor\">presentation/delivery</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">mov-low.http</configuration> </configurations> </operation> </operations> </definition> The target-tags attribute causes the resulting media to be tagged. For example, this could be used to define these media as input for other operations, using their source-tags attribute. The encoding-profile attribute refers to an encoding profile defined in etc/encoding . Encode to Thumbnail The next operations will create thumbnails from the media: <definition xmlns=\"http://workflow.opencastproject.org\"> ... <operations> ... <!-- encode: images --> <operation id=\"image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode camera to thumbnail\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">cover/source</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">feed-cover.http</configuration> <configuration key=\"time\">1</configuration> </configurations> </operation> <operation id=\"image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode screen to thumbnail\"> <configurations> <configuration key=\"source-flavor\">presentation/source</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">cover/source</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">feed-cover.http</configuration> <configuration key=\"time\">1</configuration> </configurations> </operation> </operations> </definition> The time attribute determines the approximate frame of the source media is used. The time unit is in seconds. Distribute the Media The next operation copies the encoded media to the Opencast distribution channel: <definition xmlns=\"http://workflow.opencastproject.org\"> ... <operations> <!-- distribute: local --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Distribute media to the local distribution channel\"> <configurations> <configuration key=\"download-source-tags\">publish,rss,atom</configuration> <configuration key=\"streaming-source-tags\"></configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation> </operations> </definition> The publish-engage operation uses all media tagged as rss or atom as input. Accept User Input Workflow definitions may optionally include variables to be replaced by user input. For instance, this may be used to select optional parts of a workflow. To enable user control of individual workflow instances, the workflow definition must: use the ${variable} notation in the workflow definition contain a custom configuration panel. Here is an example of a configurable operation: <operation id=\"...\" if=\"${somevar}\"> ... </operation> The attribute if specifies the execution condition in means of the operation only being executed if that condition evaluates to true. You can find more details on conditional execution in the next section. Once the operation is configured to accept a variable, we need to describe how to gather the value from the administrative user. The <configuration_panel> element of a workflow definitions describes this user interface snippet. A simple configuration panel could look like this: <configuration_panel> <![CDATA[ <input id=\"someaction\" name=\"someaction\" type=\"checkbox\" value=\"true\" /> <label for=\"someaction\">Execute some operation?</label> ]]> </configuration_panel> The checkbox in this <configuration_panel> will now be displayed in the administrative tools, and the user's selection will be used to replace the ${someaction} variable in the workflow. This input can also be sent by capture agents, using the ingest endpoints. Please note that capture agents usually do not load the configuration panel. Hence defaults set in the user interface will not apply to ingests. To circumvent this, the defaults operation can be used. Conditional Execution The attribute if of the operation element can be used to specify a condition to control whether the workflow operation should be executed. This so-called execution condition is a boolean expression of the following form: <expression> ::= <term> [\"OR\" <expression>] <term> ::= <value> [\"AND\" <term>] <value> ::= [\"NOT\"]* ( \"(\" <expression> \")\" | <relation> | <bool-literal> ) <relation> ::= <relation-factor> <rel-literal> <relation-factor> <relation-factor> ::= <operation> | <atom> <operation> ::= <atom> <op-literal> <atom> <rel-literal> ::= \">=\" | \">\" | \"<=\" | \"<\" | \"==\" | \"!=\" <op-literal> ::= \"+\" | \"-\" | \"*\" | \"/\" <bool-literal> ::= \"true\" | \"false\" <atom> ::= <number> | <string> As the formal description above explains, such boolean expressions may contain\u2026 \u2026the boolean constants true and false . \u2026numbers, which may contain a decimal point. \u2026strings, which must be surrounded by single-quotes. Escaping of single quotes is supported, just use two single quotes next to each other: 'foo''bar' \u2026as well as references to the variables of the workflow instance that contain these data types. Variables are enclosed in in ${} , as shown below. A default value may be specified for a variable, after the name, separated by a colon, as such: ${foo:1} . The default value will be used in case the variable doesn\u2019t exist. If no default value is specified, false will be used. This, of course, only makes sense in boolean contexts. Be aware to specify a default value in relations such as ${foo} < ${bar} . Example for simple boolean expressions: <operation id=\"...\" if=\"${variableName1} AND NOT (${variableName2} OR ${variableName3})\"> \u2026 </operation> Example for string comparisons: <operation id=\"...\" if=\"${captureAgentVendor} == 'ACME Corporation'\"> \u2026 </operation> Note that operations containing strings and numbers are somewhat well-behaved, for example, the following operation gets executed because 3 is converted to a string and then added to the string '4' : <operation id=\"...\" if=\"3+'4' == '34'\"> \u2026 </operation> Note that XML requires certain characters like the < and > operators to be written as XML entities. Even if they are used quoted in attributes. The following table shows all those characters: \" \u2192 &quot; ' \u2192 &apos; < \u2192 &lt; > \u2192 &gt; & \u2192 &amp; Example: <operation id=\"...\" if=\"${yresolution} &gt; 720\"> \u2026 </operation> Thumbnail Support The Admin UI comes with explicit support for thumbnails that are supposed to represent events visually, e.g. in lists of events as commonly used in video portals and other similar systems. To make it possible to implement the required processing and retain flexibility, the Admin UI will store the following information in variables of workflow instances: Variable Description thumbnailType The type of the thumbnail as number (see table below) thumbnailPosition The time position in case of snapshot thumbnails thumbnailTrack The source track in case of snapshot thumbnails Thumbnail Type Description 0 The default thumbnail shall be extracted at a configured time position 1 The thumbnail has been uploaded and is stored in the asset manager as media package attachment 2 The thumbnail shall be extracted at a given time position from a given track To fully support the thumbnail feature, your workflows should take care of creating the different types of thumbnails and be consistent to the Admin UI thumbnail configuration (see Thumbnail Configuration ) Test the Workflow The easiest way to test a workflow is to just put it into the workflow folder where it will be picked up by Opencast automatically and will be available in Opencast a few seconds later.","title":"Workflow"},{"location":"configuration/workflow/#create-a-custom-workflow","text":"Creating custom workflows can be complex. Some members of the community have contributed their production workflows to a public repo. Community Workflow Repository Please feel free to contribute your workflows when you have Opencast in production! This document will help you get started with creating your own Opencast workflows. For a list of available workflow operations, see: List of Workflow Operation Handler","title":"Create a Custom Workflow"},{"location":"configuration/workflow/#overview","text":"A Opencast workflow is an ordered list of operations. There is no limit to the number of operations or their repetition in a given workflow. Workflow operations can be configured using configuration elements. The use of string replacement in configuration values allows workflows to dynamically adapt to a given input or user decision.","title":"Overview"},{"location":"configuration/workflow/#document","text":"Opencast workflows are defined in XML. The structure of a Opencast workflow looks like this: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> <id></id> <title></title> <tags></tags> <description></description> <displayOrder></displayOrder> <!-- Operations --> <operations> <operation></operation> ... </operations> </definition>","title":"Document"},{"location":"configuration/workflow/#create-a-workflow","text":"This sections will walk you through creating a custom workflow, which will encode ingested tracks to defined output format.","title":"Create a Workflow"},{"location":"configuration/workflow/#encoding-profiles","text":"First create or select the encoding profiles you want to use. For more details on this, have a look at the Encoding Profile Configuration Guide . For this guide we assume that we have an encoding profile mov-low.http which creates a distribution format definition for mp4 video and a feed-cover.http encoding profile to create thumbnail images for the videos.","title":"Encoding Profiles"},{"location":"configuration/workflow/#describe-the-workflow","text":"Start by naming the workflow and giving it a meaningful description: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> <id>example</id> <!-- Optionally specify an organization --> <organization>mh_default_org</organization> <!-- optionally specify roles for this workflow --> <roles> <role>ROLE_ADMIN</role> </roles> <title>Encode Mp4, Distribute and Publish</title> <tags> <!-- Tell the UI where to show this workflow --> <tag>upload</tag> <tag>schedule</tag> <tag>archive</tag> </tags> <description> 1. Encode to Mp4 and thumbnail. 2. Distribute to local repository. 3. Publish to search index. </description> <displayOrder>10</displayOrder> <!-- Operations --> <operations></operations> </definition> The id is used in several Opencast endpoints to identify and select this workflow. Make sure that this identifier is unique among all endpoints in the system (except in multitenant workflows, see organization below). The organization specifies the organization this workflow is valid for (thus, it only makes sense in multitenant installations). If there are two workflows with the same id, the one corresponding to the user\u2019s organization is always chosen. This pertains workflow dropdowns (for example, the \u201cAdd new event\u201d dropdown) as well as workflows included in other workflows via the include workflow operation handler. The roles define which user roles are allowed to see and start this workflow (a user needs one of the roles provided in the definition). If this is omitted or no roles are specified, everyone can see and start the workflow (provided the organization constraints are satisfied). Also, users with ROLE_ADMIN can see and start every workflow. Note that the workflows included in Opencast do not set roles. The tags define where the user interfaces may use these workflows. Useful tags are: upload : Usable for uploaded media schedule : Usable for scheduled events archive : Usable for archived media delete : Usable for deletion of events with publications editor : Usable from the video editor The displayOrder is an integer that indicates in what order workflow definitions shall be displayed by clients. If ommitted, the displayOrder defaults to 0 . Clients are expected to list workflow definitions in descending order. The description allows you to describe the workflow in detail. Blank lines are formatted as newlines, while single line breaks are ignored so that the XML remains compact and readable even with long paragraphs.","title":"Describe the Workflow"},{"location":"configuration/workflow/#inspect-the-media","text":"The first operation will be to inspect the media for technical metadata, such as format and length: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> ... <!-- Operations --> <operations> <!-- inspect media --> <operation id=\"inspect\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspect media package\"> </operation> </operations> </definition> The fail-on-error attribute is a boolean determining whether the workflow will throw an error to the exception-handler-workflow or simply proceed with the remaining operations.","title":"Inspect the Media"},{"location":"configuration/workflow/#encoding","text":"The next operations will encode the media to the Mp4 format: <definition xmlns=\"http://workflow.opencastproject.org\"> <!-- Description --> ... <!-- Operations --> <operations> <!-- inspect media --> ... <!-- encode: mp4 --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode camera to mp4\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"target-flavor\">presenter/delivery</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">mov-low.http</configuration> </configurations> </operation> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode screen to mp4\"> <configurations> <configuration key=\"source-flavor\">presentation/source</configuration> <configuration key=\"target-flavor\">presentation/delivery</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">mov-low.http</configuration> </configurations> </operation> </operations> </definition> The target-tags attribute causes the resulting media to be tagged. For example, this could be used to define these media as input for other operations, using their source-tags attribute. The encoding-profile attribute refers to an encoding profile defined in etc/encoding .","title":"Encoding"},{"location":"configuration/workflow/#encode-to-thumbnail","text":"The next operations will create thumbnails from the media: <definition xmlns=\"http://workflow.opencastproject.org\"> ... <operations> ... <!-- encode: images --> <operation id=\"image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode camera to thumbnail\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">cover/source</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">feed-cover.http</configuration> <configuration key=\"time\">1</configuration> </configurations> </operation> <operation id=\"image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encode screen to thumbnail\"> <configurations> <configuration key=\"source-flavor\">presentation/source</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">cover/source</configuration> <configuration key=\"target-tags\">rss, atom</configuration> <configuration key=\"encoding-profile\">feed-cover.http</configuration> <configuration key=\"time\">1</configuration> </configurations> </operation> </operations> </definition> The time attribute determines the approximate frame of the source media is used. The time unit is in seconds.","title":"Encode to Thumbnail"},{"location":"configuration/workflow/#distribute-the-media","text":"The next operation copies the encoded media to the Opencast distribution channel: <definition xmlns=\"http://workflow.opencastproject.org\"> ... <operations> <!-- distribute: local --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Distribute media to the local distribution channel\"> <configurations> <configuration key=\"download-source-tags\">publish,rss,atom</configuration> <configuration key=\"streaming-source-tags\"></configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation> </operations> </definition> The publish-engage operation uses all media tagged as rss or atom as input.","title":"Distribute the Media"},{"location":"configuration/workflow/#accept-user-input","text":"Workflow definitions may optionally include variables to be replaced by user input. For instance, this may be used to select optional parts of a workflow. To enable user control of individual workflow instances, the workflow definition must: use the ${variable} notation in the workflow definition contain a custom configuration panel. Here is an example of a configurable operation: <operation id=\"...\" if=\"${somevar}\"> ... </operation> The attribute if specifies the execution condition in means of the operation only being executed if that condition evaluates to true. You can find more details on conditional execution in the next section. Once the operation is configured to accept a variable, we need to describe how to gather the value from the administrative user. The <configuration_panel> element of a workflow definitions describes this user interface snippet. A simple configuration panel could look like this: <configuration_panel> <![CDATA[ <input id=\"someaction\" name=\"someaction\" type=\"checkbox\" value=\"true\" /> <label for=\"someaction\">Execute some operation?</label> ]]> </configuration_panel> The checkbox in this <configuration_panel> will now be displayed in the administrative tools, and the user's selection will be used to replace the ${someaction} variable in the workflow. This input can also be sent by capture agents, using the ingest endpoints. Please note that capture agents usually do not load the configuration panel. Hence defaults set in the user interface will not apply to ingests. To circumvent this, the defaults operation can be used.","title":"Accept User Input"},{"location":"configuration/workflow/#conditional-execution","text":"The attribute if of the operation element can be used to specify a condition to control whether the workflow operation should be executed. This so-called execution condition is a boolean expression of the following form: <expression> ::= <term> [\"OR\" <expression>] <term> ::= <value> [\"AND\" <term>] <value> ::= [\"NOT\"]* ( \"(\" <expression> \")\" | <relation> | <bool-literal> ) <relation> ::= <relation-factor> <rel-literal> <relation-factor> <relation-factor> ::= <operation> | <atom> <operation> ::= <atom> <op-literal> <atom> <rel-literal> ::= \">=\" | \">\" | \"<=\" | \"<\" | \"==\" | \"!=\" <op-literal> ::= \"+\" | \"-\" | \"*\" | \"/\" <bool-literal> ::= \"true\" | \"false\" <atom> ::= <number> | <string> As the formal description above explains, such boolean expressions may contain\u2026 \u2026the boolean constants true and false . \u2026numbers, which may contain a decimal point. \u2026strings, which must be surrounded by single-quotes. Escaping of single quotes is supported, just use two single quotes next to each other: 'foo''bar' \u2026as well as references to the variables of the workflow instance that contain these data types. Variables are enclosed in in ${} , as shown below. A default value may be specified for a variable, after the name, separated by a colon, as such: ${foo:1} . The default value will be used in case the variable doesn\u2019t exist. If no default value is specified, false will be used. This, of course, only makes sense in boolean contexts. Be aware to specify a default value in relations such as ${foo} < ${bar} . Example for simple boolean expressions: <operation id=\"...\" if=\"${variableName1} AND NOT (${variableName2} OR ${variableName3})\"> \u2026 </operation> Example for string comparisons: <operation id=\"...\" if=\"${captureAgentVendor} == 'ACME Corporation'\"> \u2026 </operation> Note that operations containing strings and numbers are somewhat well-behaved, for example, the following operation gets executed because 3 is converted to a string and then added to the string '4' : <operation id=\"...\" if=\"3+'4' == '34'\"> \u2026 </operation> Note that XML requires certain characters like the < and > operators to be written as XML entities. Even if they are used quoted in attributes. The following table shows all those characters: \" \u2192 &quot; ' \u2192 &apos; < \u2192 &lt; > \u2192 &gt; & \u2192 &amp; Example: <operation id=\"...\" if=\"${yresolution} &gt; 720\"> \u2026 </operation>","title":"Conditional Execution"},{"location":"configuration/workflow/#thumbnail-support","text":"The Admin UI comes with explicit support for thumbnails that are supposed to represent events visually, e.g. in lists of events as commonly used in video portals and other similar systems. To make it possible to implement the required processing and retain flexibility, the Admin UI will store the following information in variables of workflow instances: Variable Description thumbnailType The type of the thumbnail as number (see table below) thumbnailPosition The time position in case of snapshot thumbnails thumbnailTrack The source track in case of snapshot thumbnails Thumbnail Type Description 0 The default thumbnail shall be extracted at a configured time position 1 The thumbnail has been uploaded and is stored in the asset manager as media package attachment 2 The thumbnail shall be extracted at a given time position from a given track To fully support the thumbnail feature, your workflows should take care of creating the different types of thumbnails and be consistent to the Admin UI thumbnail configuration (see Thumbnail Configuration )","title":"Thumbnail Support"},{"location":"configuration/workflow/#test-the-workflow","text":"The easiest way to test a workflow is to just put it into the workflow folder where it will be picked up by Opencast automatically and will be available in Opencast a few seconds later.","title":"Test the Workflow"},{"location":"configuration/admin-ui/asset-upload/","text":"Asset Upload Options Description This guide will help you customize manual upload asset options for the Admin UI. Opencast event media packages reference several different types of assets. These may include video file tracks, metadata catalogs, image files and class handout notes. Some assets are automatically created through workflow events. Others need to be manually attached to the mediapackage. An example of automatically created assets are navigation slides. An example of a manually attached assets are handout notes. This guide describes how to customize the Admin UI to support new asset upload options. Default Setup Out of the box, Opencast provides preconfigured asset and source upload configuration. The configuration is a listprovider properties file: etc/listproviders/event.upload.asset.options.properties Two source types are enabled by default for use in the Admin UI. EVENTS.EVENTS.NEW.SOURCE.UPLOAD.NON_SEGMENTABLE={\\ \"id\":\"track_presenter\",\\ \"type\":\"track\",\\ \"flavorType\":\"presenter\",\\ \"flavorSubType\":\"source\",\\ \"multiple\":false,\\ \"displayOrder\": 1} EVENTS.EVENTS.NEW.SOURCE.UPLOAD.SEGMENTABLE={\\ \"id\":\"track_presentation\",\\ \"type\":\"track\",\\ \"flavorType\":\"presentation\",\\ \"flavorSubType\":\"source\",\\ \"multiple\":false,\\ \"displayOrder\": 2} Source upload options as displayed in the Admin UI Create event: Asset flavor and sub-flavor are used by default Opencast workflows. When you add new asset types, you may need to adjust workflows to process the new asset flavor. These workflow variables are avaiable to workflows started by the create event or add asset action: Variable Name Type Description uploadedSearchPreview boolean true if manually uploaded preview image, false otherwise. Used to prevent image extraction overwrite in compose operation downloadSourceflavorsExist boolean true if download-source-flavors variable exists, false otherwise. Identifies existence of download-source-flavors var for tagging download-source-flavors comma separated list A convenience variable that lists manually uploaded asset flavors. Example of variables in a workflow: <!-- Tag any optionally uploaded assets --> <operation id=\"tag\" if=\"${downloadSourceflavorsExist}\" exception-handler-workflow=\"partial-error\" description=\"Tagging uploaded assets for distribution\"> <configurations> <configuration key=\"source-flavors\">${download-source-flavors}</configuration> <configuration key=\"target-tags\">+engage-download</configuration> </configurations> </operation> How to Enable Preconfigured Asset Options Catalogs and attachments can be added to new and existing events. Source tracks are uploaded as new events. Some predefined catalog and attachment examples are commented out in the properties file. You can uncomment any of these to make them upload options in the Admin UI. The workflow publish-uploaded-assets will automatically distribute, publish, and archive uploaded assets on existing events. # Attachments and catalogs upload options are for new and existing events. # Only one file can be uploaded for each of these options, the uploaded file replaces existing elements of the same # type and flavor in the mediapackage. # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_DFXP={\"id\":\"catalog_captions_dfxp\", \"type\": \"catalog\", # \"flavorType\": \"captions\", \"flavorSubType\": \"timedtext\", \"displayOrder\": 2} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_WEBVTT={\"id\":\"attachment_captions_webvtt\", # \"type\": \"attachment\", \"flavorType\": \"text\", \"flavorSubType\": \"webvtt\", \"displayOrder\": 3} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CLASS_HANDOUT_NOTES={\"id\": \"attachment_class_handout_notes\", # \"type\": \"attachment\", \"flavorType\": \"attachment\", \"flavorSubType\": \"notes\", \"displayOrder\": 4} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.SMIL={\"id\":\"catalog_smil\", \"type\":\"catalog\", \"flavorType\": \"smil\", # \"flavorSubType\": \"smil\", \"displayOrder\": 5} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.PREVIEW_IMAGE={\"id\":\"attachment_preview_image\", # \"type\":\"attachment\", \"flavorType\": \"presenter\",\"flavorSubType\": \"search+preview\", \"displayOrder\": 6} EVENTS.EVENTS.NEW.UPLOAD_ASSET.WORKFLOWDEFID=publish-uploaded-assets # The video source track upload options are only for new events. # Unlike the other assets, multiple source tracks can be uploaded for a single flavor. # The MULTIPLE_PARTS example shows how to enable choosing multiple source files for a single flavor. In this case, # a fictional \"multipart/part+source\". # EVENTS.EVENTS.NEW.SOURCE.UPLOAD.MULTIPLE_PARTS={\"id\": \"track_parts\",\"type\":\"track\", # \"flavorType\": \"multipart\", \"flavorSubType\": \"part+source\", \"multiple\":true, \"displayOrder\": 10} # EVENTS.EVENTS.NEW.SOURCE.UPLOAD.AUDIO_ONLY={\"id\": \"track_audio\",\"type\":\"track\", # \"flavorType\": \"presenter-audio\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 11} EVENTS.EVENTS.NEW.SOURCE.UPLOAD.NON_SEGMENTABLE={\"id\": \"track_presenter\",\"type\":\"track\", \"flavorType\":\"presenter\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 12} EVENTS.EVENTS.NEW.SOURCE.UPLOAD.SEGMENTABLE={\"id\": \"track_presentation\",\"type\":\"track\", \"flavorType\":\"presentation\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 13} How to Upload Assets in the Admin UI After enabling an upload option, a new navigation area becomes visible in the \"Create event\", called \"Asset Upload\". Assets can be uploaded to new events. The \"Asset Upload\" navigation disapears for scheduled events. Assets cannot be uploaded for scheduled events until after the scheduled event is processed. The manually uploaded assets appear in the Create event summary To Upload an asset to an existing event, go into the existing event details Assets tab, and click \"Add Asset >\" link The option selection is the same as for Create event, execpt the \"Add Asset\" button automatically executes the workflow defined by EVENTS.EVENTS.NEW.UPLOAD_ASSET.WORKFLOWDEFID How to Create a New Asset Option The following steps will assist you in creating a new asset upload option. As mentioned before, only catalog and attachments can be added to existing events. New source types can be added to new events. Tasks: Modify etc/listproviders/event.upload.asset.options.properties For the title of the options displayed in the admin interface, either: add a translation for the new asset name to modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/... or add a title field to the upload specification Modify your workflow from etc/workflows/... Test your changes The following steps describe how to change the properties configuration. Step 1. Determine your new option type and processing needs There are 3 asset upload types: track is a media source such as video file catalog is an XML formatted metadata file attachment can be any type of file. For example jpeg, pdf, text, etc. Tracks are usually associated with workflow processing. If you need special processing with your custom track flavors, update or create workflows to work with your new track flavor. Attachments and Catalogs, such as smil files, can also be used for processing. If you only need to publish manually uploaded assets with a unique flavor, this is already built into the default workflows. Step 2. Add your new option to the list configuration You add your new asset upload configuration as a row to this file: etc/listproviders/event.upload.asset.options.properties Copy an existing row as a template for your new asset. Retain the property key prefix EVENTS.EVENTS.NEW.SOURCE. or EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION. Your unique asset identifier will follow the last dot after the prefix, in all capital alphabetical characters. Underbars are allowed. CONFIGURATION values are in JSON object format. Attribute Example Description id track_presenter One of \"attachment\" or \"catalog\" or \"track\", underbar (_), unique text (no spaces) type track One of \"attachment\" or \"catalog\" or \"track\" to designate asset type (must match id prefix) flavorType presentation The primary flavor type. Used to reference asset in workflows, player, and media module flavorSubType source The sub flavor type. Used to identify the sub flavor of this flavor type multiple false true or false, used by the admin UI to enable single or multiple file input selection displayOrder 32 Integer number, used by the admin UI to sort the display of upload options in the UI displayOverride 'My New Catalog' A short asset title which overrides all translations displayFallback 'My New Catalog' A short asset title which displays when no translation is found displayOverride.SHORT 'Video of a Presenter' A short source title which overrides all translations displayFallback.SHORT 'Video of a Presenter' A short source title which displays when no translation is found displayOverride.DETAIL 'A recording that showing the lecturer speaking' A longer source description which overrides all translation displayFallback.DETAIL 'A recording that showing the lecturer speaking' A longer source description which displays when no translation is found accept 'video/*,.png' A list of accepted file formats as taken by the HTML \\<input>'s accept field. This field is optional. This has to be a list of comma separated values. Each value of the list can either be a IANA MediaType or a file ending. The parameter key is internationalized as the display text in the admin UI ref: modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/ Step 3. Add translation for the new option The option property key is internationalized for display in the Admin UI. Add a translation for the option property when adding new option, otherwise the Admin UI will display the raw key. The translation language files are located: modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/... Example of US English translation for EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_WEBVTT : modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/lang-en_US.json { ... \"EVENTS\": { ... \"EVENTS\": { ... \"NEW\": { ... \"UPLOAD_ASSET\": { ... \"CAPTIONS_WEBVTT\" : \"Captions WebVTT\", ... Now you are ready to test and deploy.","title":"Manual Asset Upload"},{"location":"configuration/admin-ui/asset-upload/#asset-upload-options","text":"","title":"Asset Upload Options"},{"location":"configuration/admin-ui/asset-upload/#description","text":"This guide will help you customize manual upload asset options for the Admin UI. Opencast event media packages reference several different types of assets. These may include video file tracks, metadata catalogs, image files and class handout notes. Some assets are automatically created through workflow events. Others need to be manually attached to the mediapackage. An example of automatically created assets are navigation slides. An example of a manually attached assets are handout notes. This guide describes how to customize the Admin UI to support new asset upload options.","title":"Description"},{"location":"configuration/admin-ui/asset-upload/#default-setup","text":"Out of the box, Opencast provides preconfigured asset and source upload configuration. The configuration is a listprovider properties file: etc/listproviders/event.upload.asset.options.properties Two source types are enabled by default for use in the Admin UI. EVENTS.EVENTS.NEW.SOURCE.UPLOAD.NON_SEGMENTABLE={\\ \"id\":\"track_presenter\",\\ \"type\":\"track\",\\ \"flavorType\":\"presenter\",\\ \"flavorSubType\":\"source\",\\ \"multiple\":false,\\ \"displayOrder\": 1} EVENTS.EVENTS.NEW.SOURCE.UPLOAD.SEGMENTABLE={\\ \"id\":\"track_presentation\",\\ \"type\":\"track\",\\ \"flavorType\":\"presentation\",\\ \"flavorSubType\":\"source\",\\ \"multiple\":false,\\ \"displayOrder\": 2} Source upload options as displayed in the Admin UI Create event: Asset flavor and sub-flavor are used by default Opencast workflows. When you add new asset types, you may need to adjust workflows to process the new asset flavor. These workflow variables are avaiable to workflows started by the create event or add asset action: Variable Name Type Description uploadedSearchPreview boolean true if manually uploaded preview image, false otherwise. Used to prevent image extraction overwrite in compose operation downloadSourceflavorsExist boolean true if download-source-flavors variable exists, false otherwise. Identifies existence of download-source-flavors var for tagging download-source-flavors comma separated list A convenience variable that lists manually uploaded asset flavors. Example of variables in a workflow: <!-- Tag any optionally uploaded assets --> <operation id=\"tag\" if=\"${downloadSourceflavorsExist}\" exception-handler-workflow=\"partial-error\" description=\"Tagging uploaded assets for distribution\"> <configurations> <configuration key=\"source-flavors\">${download-source-flavors}</configuration> <configuration key=\"target-tags\">+engage-download</configuration> </configurations> </operation>","title":"Default Setup"},{"location":"configuration/admin-ui/asset-upload/#how-to-enable-preconfigured-asset-options","text":"Catalogs and attachments can be added to new and existing events. Source tracks are uploaded as new events. Some predefined catalog and attachment examples are commented out in the properties file. You can uncomment any of these to make them upload options in the Admin UI. The workflow publish-uploaded-assets will automatically distribute, publish, and archive uploaded assets on existing events. # Attachments and catalogs upload options are for new and existing events. # Only one file can be uploaded for each of these options, the uploaded file replaces existing elements of the same # type and flavor in the mediapackage. # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_DFXP={\"id\":\"catalog_captions_dfxp\", \"type\": \"catalog\", # \"flavorType\": \"captions\", \"flavorSubType\": \"timedtext\", \"displayOrder\": 2} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_WEBVTT={\"id\":\"attachment_captions_webvtt\", # \"type\": \"attachment\", \"flavorType\": \"text\", \"flavorSubType\": \"webvtt\", \"displayOrder\": 3} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CLASS_HANDOUT_NOTES={\"id\": \"attachment_class_handout_notes\", # \"type\": \"attachment\", \"flavorType\": \"attachment\", \"flavorSubType\": \"notes\", \"displayOrder\": 4} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.SMIL={\"id\":\"catalog_smil\", \"type\":\"catalog\", \"flavorType\": \"smil\", # \"flavorSubType\": \"smil\", \"displayOrder\": 5} # EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.PREVIEW_IMAGE={\"id\":\"attachment_preview_image\", # \"type\":\"attachment\", \"flavorType\": \"presenter\",\"flavorSubType\": \"search+preview\", \"displayOrder\": 6} EVENTS.EVENTS.NEW.UPLOAD_ASSET.WORKFLOWDEFID=publish-uploaded-assets # The video source track upload options are only for new events. # Unlike the other assets, multiple source tracks can be uploaded for a single flavor. # The MULTIPLE_PARTS example shows how to enable choosing multiple source files for a single flavor. In this case, # a fictional \"multipart/part+source\". # EVENTS.EVENTS.NEW.SOURCE.UPLOAD.MULTIPLE_PARTS={\"id\": \"track_parts\",\"type\":\"track\", # \"flavorType\": \"multipart\", \"flavorSubType\": \"part+source\", \"multiple\":true, \"displayOrder\": 10} # EVENTS.EVENTS.NEW.SOURCE.UPLOAD.AUDIO_ONLY={\"id\": \"track_audio\",\"type\":\"track\", # \"flavorType\": \"presenter-audio\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 11} EVENTS.EVENTS.NEW.SOURCE.UPLOAD.NON_SEGMENTABLE={\"id\": \"track_presenter\",\"type\":\"track\", \"flavorType\":\"presenter\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 12} EVENTS.EVENTS.NEW.SOURCE.UPLOAD.SEGMENTABLE={\"id\": \"track_presentation\",\"type\":\"track\", \"flavorType\":\"presentation\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 13}","title":"How to Enable Preconfigured Asset Options"},{"location":"configuration/admin-ui/asset-upload/#how-to-upload-assets-in-the-admin-ui","text":"After enabling an upload option, a new navigation area becomes visible in the \"Create event\", called \"Asset Upload\". Assets can be uploaded to new events. The \"Asset Upload\" navigation disapears for scheduled events. Assets cannot be uploaded for scheduled events until after the scheduled event is processed. The manually uploaded assets appear in the Create event summary To Upload an asset to an existing event, go into the existing event details Assets tab, and click \"Add Asset >\" link The option selection is the same as for Create event, execpt the \"Add Asset\" button automatically executes the workflow defined by EVENTS.EVENTS.NEW.UPLOAD_ASSET.WORKFLOWDEFID","title":"How to Upload Assets in the Admin UI"},{"location":"configuration/admin-ui/asset-upload/#how-to-create-a-new-asset-option","text":"The following steps will assist you in creating a new asset upload option. As mentioned before, only catalog and attachments can be added to existing events. New source types can be added to new events. Tasks: Modify etc/listproviders/event.upload.asset.options.properties For the title of the options displayed in the admin interface, either: add a translation for the new asset name to modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/... or add a title field to the upload specification Modify your workflow from etc/workflows/... Test your changes The following steps describe how to change the properties configuration.","title":"How to Create a New Asset Option"},{"location":"configuration/admin-ui/asset-upload/#step-1-determine-your-new-option-type-and-processing-needs","text":"There are 3 asset upload types: track is a media source such as video file catalog is an XML formatted metadata file attachment can be any type of file. For example jpeg, pdf, text, etc. Tracks are usually associated with workflow processing. If you need special processing with your custom track flavors, update or create workflows to work with your new track flavor. Attachments and Catalogs, such as smil files, can also be used for processing. If you only need to publish manually uploaded assets with a unique flavor, this is already built into the default workflows.","title":"Step 1. Determine your new option type and processing needs"},{"location":"configuration/admin-ui/asset-upload/#step-2-add-your-new-option-to-the-list-configuration","text":"You add your new asset upload configuration as a row to this file: etc/listproviders/event.upload.asset.options.properties Copy an existing row as a template for your new asset. Retain the property key prefix EVENTS.EVENTS.NEW.SOURCE. or EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION. Your unique asset identifier will follow the last dot after the prefix, in all capital alphabetical characters. Underbars are allowed. CONFIGURATION values are in JSON object format. Attribute Example Description id track_presenter One of \"attachment\" or \"catalog\" or \"track\", underbar (_), unique text (no spaces) type track One of \"attachment\" or \"catalog\" or \"track\" to designate asset type (must match id prefix) flavorType presentation The primary flavor type. Used to reference asset in workflows, player, and media module flavorSubType source The sub flavor type. Used to identify the sub flavor of this flavor type multiple false true or false, used by the admin UI to enable single or multiple file input selection displayOrder 32 Integer number, used by the admin UI to sort the display of upload options in the UI displayOverride 'My New Catalog' A short asset title which overrides all translations displayFallback 'My New Catalog' A short asset title which displays when no translation is found displayOverride.SHORT 'Video of a Presenter' A short source title which overrides all translations displayFallback.SHORT 'Video of a Presenter' A short source title which displays when no translation is found displayOverride.DETAIL 'A recording that showing the lecturer speaking' A longer source description which overrides all translation displayFallback.DETAIL 'A recording that showing the lecturer speaking' A longer source description which displays when no translation is found accept 'video/*,.png' A list of accepted file formats as taken by the HTML \\<input>'s accept field. This field is optional. This has to be a list of comma separated values. Each value of the list can either be a IANA MediaType or a file ending. The parameter key is internationalized as the display text in the admin UI ref: modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/","title":"Step 2. Add your new option to the list configuration"},{"location":"configuration/admin-ui/asset-upload/#step-3-add-translation-for-the-new-option","text":"The option property key is internationalized for display in the Admin UI. Add a translation for the option property when adding new option, otherwise the Admin UI will display the raw key. The translation language files are located: modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/... Example of US English translation for EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_WEBVTT : modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/lang-en_US.json { ... \"EVENTS\": { ... \"EVENTS\": { ... \"NEW\": { ... \"UPLOAD_ASSET\": { ... \"CAPTIONS_WEBVTT\" : \"Captions WebVTT\", ... Now you are ready to test and deploy.","title":"Step 3. Add translation for the new option"},{"location":"configuration/admin-ui/event-filters/","text":"Events Filters Configuration At the top right of the admin UI a set of predefined filters for events are available, displayed with a description and the amount of events currently matching that filter. By default, the following filters are visible: Statistic Description Yesterday All events with a start date sometime yesterday. Today All events with a start date sometime today. Tomorrow All events with a start date sometime tomorrow. Scheduled All events with status Scheduled . Recording All events with status Recording . Running All events with status Running . Paused All events with status Paused . Failed All events with status Failed . Todo All events with status Finished and open comments. Finished All events with status Finished . Filters can be added or removed by editing the file etc/listproviders/adminui.stats.properties . For example, the Finished filter is defined as follows: FINISHED=\\ {\"filters\": [{\"name\": \"status\", \"filter\": \"FILTERS.EVENTS.STATUS.LABEL\", \\ \"value\": \"EVENTS.EVENTS.STATUS.PROCESSED\"}],\\ \"description\": \"DASHBOARD.FINISHED\",\\ \"order\":12} filters defines a list containing at least one filter. Each filter is defined with a name that defines the event property to filter on for the backend a filter that defines the event property to filter on for the frontend and the value that property is supposed to have description contains the (possibly translated) description displayed in the UI order controls the order the filters are shown in the UI Filters with relative time spans For defining filters that contain a relative time span like yesterday or this week value can contain an object instead of a string. This object has to contain a relativeDateSpan property which itself contains the fields from , to and unit . The unit defines the unit of time that is being considered, e.g. hour , day , week , month or year , while from and to specify the beginning and end of the time span by defining an integer offset relative to the current hour, day, ... depending on the unit. So if the unit is defined as day , 0 is the current day while -1 is yesterday and 1 is tomorrow. If the unit is week instead, 0 is the current week while -1 is the last and 1 the next week, and so on. Every date/time unit below the one defined by unit depends on whether the offset is defined by to or from . So if the unit is day , from: -1 would be the beginning of yesterday (so the time is 00:00:00 in the user's timezone) while to: -1 would be the end of yesterday (23:59:59). If the unit is week , from: -1 is the beginning of last week (which day is the first day of the week is defined by the user's locale) and to: 0 would be the end of this week, so a filter defined as LAST_TWO_WEEKS=\\ {\"filters\": [{\"name\": \"startDate\", \"filter\":\"FILTERS.EVENTS.START_DATE\", \"value\": {\"relativeDateSpan\": {\"from\": \"-2\", \"to\": \"0\", \"unit\": \"week\"}}}],\\ \"description\": \"DATES.LAST_TWO_WEEKS\",\\ \"order\":15} would cover all events whose start dates occur sometime during the last or current week. This functionality is implemented with the library Moment.js by adding the values of to or from to the current date and time while considering the defined unit. A list of valid unit strings can be found in the documentation . To be considered Since only one unit can be defined per filter, time spans like the beginning of this month until tomorrow are currently not possible. Be advised that a too big amount of filters can lead to filters disappearing from view depending on the width of the user's screen.","title":"Event Filters"},{"location":"configuration/admin-ui/event-filters/#events-filters-configuration","text":"At the top right of the admin UI a set of predefined filters for events are available, displayed with a description and the amount of events currently matching that filter. By default, the following filters are visible: Statistic Description Yesterday All events with a start date sometime yesterday. Today All events with a start date sometime today. Tomorrow All events with a start date sometime tomorrow. Scheduled All events with status Scheduled . Recording All events with status Recording . Running All events with status Running . Paused All events with status Paused . Failed All events with status Failed . Todo All events with status Finished and open comments. Finished All events with status Finished . Filters can be added or removed by editing the file etc/listproviders/adminui.stats.properties . For example, the Finished filter is defined as follows: FINISHED=\\ {\"filters\": [{\"name\": \"status\", \"filter\": \"FILTERS.EVENTS.STATUS.LABEL\", \\ \"value\": \"EVENTS.EVENTS.STATUS.PROCESSED\"}],\\ \"description\": \"DASHBOARD.FINISHED\",\\ \"order\":12} filters defines a list containing at least one filter. Each filter is defined with a name that defines the event property to filter on for the backend a filter that defines the event property to filter on for the frontend and the value that property is supposed to have description contains the (possibly translated) description displayed in the UI order controls the order the filters are shown in the UI","title":"Events Filters Configuration"},{"location":"configuration/admin-ui/event-filters/#filters-with-relative-time-spans","text":"For defining filters that contain a relative time span like yesterday or this week value can contain an object instead of a string. This object has to contain a relativeDateSpan property which itself contains the fields from , to and unit . The unit defines the unit of time that is being considered, e.g. hour , day , week , month or year , while from and to specify the beginning and end of the time span by defining an integer offset relative to the current hour, day, ... depending on the unit. So if the unit is defined as day , 0 is the current day while -1 is yesterday and 1 is tomorrow. If the unit is week instead, 0 is the current week while -1 is the last and 1 the next week, and so on. Every date/time unit below the one defined by unit depends on whether the offset is defined by to or from . So if the unit is day , from: -1 would be the beginning of yesterday (so the time is 00:00:00 in the user's timezone) while to: -1 would be the end of yesterday (23:59:59). If the unit is week , from: -1 is the beginning of last week (which day is the first day of the week is defined by the user's locale) and to: 0 would be the end of this week, so a filter defined as LAST_TWO_WEEKS=\\ {\"filters\": [{\"name\": \"startDate\", \"filter\":\"FILTERS.EVENTS.START_DATE\", \"value\": {\"relativeDateSpan\": {\"from\": \"-2\", \"to\": \"0\", \"unit\": \"week\"}}}],\\ \"description\": \"DATES.LAST_TWO_WEEKS\",\\ \"order\":15} would cover all events whose start dates occur sometime during the last or current week. This functionality is implemented with the library Moment.js by adding the values of to or from to the current date and time while considering the defined unit. A list of valid unit strings can be found in the documentation .","title":"Filters with relative time spans"},{"location":"configuration/admin-ui/event-filters/#to-be-considered","text":"Since only one unit can be defined per filter, time spans like the beginning of this month until tomorrow are currently not possible. Be advised that a too big amount of filters can lead to filters disappearing from view depending on the width of the user's screen.","title":"To be considered"},{"location":"configuration/admin-ui/languages/","text":"Language Configuration The admin UI is translated into a number of languages by default. If you wish to restrict the languages available to your users, add the relevant locale code to etc/org.opencastproject.adminui.endpoint.LanguageServiceEndpoint.cfg .","title":"Languages"},{"location":"configuration/admin-ui/languages/#language-configuration","text":"The admin UI is translated into a number of languages by default. If you wish to restrict the languages available to your users, add the relevant locale code to etc/org.opencastproject.adminui.endpoint.LanguageServiceEndpoint.cfg .","title":"Language Configuration"},{"location":"configuration/admin-ui/statistics/","text":"Overview In Opencast, the \"Statistics\" feature can be seen as a set of charts which can be displayed in the Admin UI. Currently, statistics for three so-called \"resource types\" are available: Statistics for the resource type EPISODE are displayed in a tab in the event details dialog. Statistics for the resource type SERIES are displayed in a tab in the series details dialog. Statistics for the resource type ORGANIZATION are displayed in the \"Statistics\" menu of Opencast. These tabs/menus are only visible if the statistics feature is configured. For the statistics to work, you need a data source from which Opencast can retrieve the data to display. Currently, InfluxDB is the only supported data source. Architecture A complete setup consists of the following components: InfluxDB A source which actually generates your data A tool which ingests your data into InfluxDB Opencast For example, using Opencast's opencast-influxdb-adapter , your architecture would look like this: G webserver Webserver Logs adapter influxdb-adapter webserver->adapter influxdb InfluxDB adapter->influxdb opencast Opencast influxdb->opencast Precisely, the Opencast bundle opencast-statistics-provider-influx is the one that needs to be able to connect to InfluxDB using http(s). So the node hosting this bundle needs network access to InfluxDB. Configuration Before configuring Opencast, you should have a running InfluxDB instance and should think about how you want your data to be written to InfluxDB and what your InfluxDB database schema should look like. Specifically, you should think about retention policies, measurement names, field/tag names and how much you want to downsample your data . If you don't have any data in your InfluxDB, but want to verify your setup is working, there is some test data provided in the section Verifying Your Setup . InfluxDB Access Opencast needs to know how to talk to your InfluxDB instance. Therefore, you should edit the configuration file etc/org.opencastproject.statistics.provider.influx.StatisticsProviderInfluxService.cfg and fill in your influx URI, username, password, and database name. Statistics Providers To support the detailed configuration of the charts to be shown in the Admin UI, Opencast has a concept called Statistics Providers . Each statistics provider can be configured separately and for each provider, there is one chart displayed in the Admin UI. The configuration files of the providers have to be stored at etc/statistics and they have to follow a certain naming convention. Configuration files of providers using InfluxDB have to be named starting with influx. . All provider configurations have to be in json format. So e.g. influx.views.episode.sum.json would be a valid name. For each provider, the following properties have to be configured: id has to be a unique identifier and can be chosen freely. title is the title to be displayed with the chart. This can be a translation key. description is the description to be displayed with the chart. This can be a translation key. resourceType tells Opencast to which type of entity the chart refers to. Valid values are EPISODE , SERIES , and ORGANIZATION . This is used by Opencast to decide where to display the chart. sources is list of JSON objects, each containing the following fields: measurement , e.g. infinite.impressions_daily tells Opencast that your InfluxDB data retention policy is named infinite and your InfluxDB measurement name is impressions_daily . aggregation , e.g. SUM tells Opencast that InfluxDB's SUM() function should be used to calculate the values to display in the chart. aggregationVariable , e.g. value tells Opencast that the InfluxDB field which should be summed is named value . resourceIdName , e.g. episodeId tells Opencast that the InfluxDB tag identifying the resource type this provider refers to is named episodeId . resolutions is a list of resolutions supported by this provider. Opencast allows the user to select a resolution with which the data is displayed. Valid values are HOURLY , DAILY , WEEKLY , MONTHLY and YEARLY . E.g. when a chart shows data of two years, a DAILY resolution will lead to 2x365=730 values to be plotted while a MONTHLY resolution would leave us with 24 values being plotted in the chart. type defines the structure of the data provided by this provider. Currently, timeseries and runningtotal are supported. Here is an example json configuration for a provider which generates charts for episodes showing the number of views: etc/statistics/influx.views.episode.sum.json { \"id\": \"episode.views.sum.influx\", \"title\": \"STATISTICS.TITLE.VIEWS_SUM\", \"description\": \"STATISTICS.DESCRIPTION.VIEWS_SUM\", \"resourceType\": \"EPISODE\", \"sources\": [{ \"measurement\": \"infinite.impressions_daily\", \"aggregation\": \"SUM\", \"aggregationVariable\": \"value\", \"resourceIdName\": \"episodeId\", \"resolutions\": [ \"DAILY\", \"WEEKLY\", \"MONTHLY\", \"YEARLY\" ] }], \"type\": \"timeseries\" } CSV Exports Statistics can be exported to CSV files by clicking the \"download\" button in the top right corner of a graph. Per default, the export will contain the data which the graph currently displays. For series statistics, it is possible to change this behavior in the way that exported series statistics contain the data of all events of a series instead of just the top level series data. To enable this, it is necessary to specify which Statistics Provider should be used to get the episode data. See the configuration file org.opencastproject.statistics.export.impl.StatisticsExportServiceImpl.cfg for details. Using the runningtotal provider The runningtotal statistics provider is a special type of time series statistics provider. To illustrate what it can be used for, let\u2019s assume we want to track the number of hours of videos per organization (this is actually what the provider was initially designed for). We create a JSON file for the provider as such: { \"id\": \"organization.publishedhours.influx\", \"title\": \"STATISTICS.TITLE.PUBLISHEDHOURS\", \"description\": \"STATISTICS.DESCRIPTION.PUBLISHEDHOURS\", \"resourceType\": \"ORGANIZATION\", \"sources\": [{ \"measurement\": \"infinite.publishedhours\", \"aggregation\": \"SUM\", \"aggregationVariable\": \"hours\", \"resourceIdName\": \"organizationId\", \"resolutions\": [ \"DAILY\", \"WEEKLY\", \"MONTHLY\", \"YEARLY\" ] }], \"type\": \"runningtotal\" } Note that the published hours entries can be negative, in case we retract a video. When the runningtotal provider is asked to report on, for example, the monthly hours of video for a specific year, it will first take the sum of all video lengths up until that year. Then, for each month, it will take the sum of all the entries in that month, and add it to the previous value. And so on for the next months. To actually write these hours to the statistics data base, you have to add the statistics-writer workflow operation handler to your workflows. Specifically, somewhere in your publishing workflow, you have to add an entry such as this: <operation id=\"statistics-writer\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Collect video statistics\"> <configurations> <configuration key=\"flavor\">presenter/video</configuration> <configuration key=\"retract\">false</configuration> <configuration key=\"measurement-name\">publishedhours</configuration> <configuration key=\"organization-resource-id-name\">organizationId</configuration> <configuration key=\"length-field-name\">hours</configuration> <configuration key=\"temporal-resolution\">hours</configuration> </configurations> </operation> To decrement the running total of hours in the case of retractions, set the retract property to true . In the default case, or when the retract property is false the running total is not decremented when a retraction occurs. Verifying Your Setup If you want to test your setup, you can put the following test data into InfluxDB and check if Opencast displays all charts correctly. First, create a series and an event as part of that series using the Opencast Admin UI. Second, copy the test data to a file called testdata.txt and edit it to match your InfluxDB database schema. Make sure you replace the episodeId , seriesId , and organizazionId tag value with the correct identifiers of the test event/series you just created. Also make sure, that the tag names (e.g.) episodeId and the field name ( value ) match the ones you have specified in the source strings of your providers. Also, the database name, retention policy name and measurement name have to match your configuration. The InfluxDB test data could look like this: # DDL CREATE DATABASE opencast # DML # CONTEXT-DATABASE: opencast impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554468810 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554555210 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554641610 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554728010 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554814410 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554900810 The file format of the InfluxDB test data is described here . You can import the test data into InfluxDB using the following command: influx -import -path=testdata.txt -precision=s -database=opencast Once you have imported your test data, you should be able to view the charts you have configured when accessing the event/series details of your test event or Opencast's statistics section.","title":"Statistics"},{"location":"configuration/admin-ui/statistics/#overview","text":"In Opencast, the \"Statistics\" feature can be seen as a set of charts which can be displayed in the Admin UI. Currently, statistics for three so-called \"resource types\" are available: Statistics for the resource type EPISODE are displayed in a tab in the event details dialog. Statistics for the resource type SERIES are displayed in a tab in the series details dialog. Statistics for the resource type ORGANIZATION are displayed in the \"Statistics\" menu of Opencast. These tabs/menus are only visible if the statistics feature is configured. For the statistics to work, you need a data source from which Opencast can retrieve the data to display. Currently, InfluxDB is the only supported data source.","title":"Overview"},{"location":"configuration/admin-ui/statistics/#architecture","text":"A complete setup consists of the following components: InfluxDB A source which actually generates your data A tool which ingests your data into InfluxDB Opencast For example, using Opencast's opencast-influxdb-adapter , your architecture would look like this: G webserver Webserver Logs adapter influxdb-adapter webserver->adapter influxdb InfluxDB adapter->influxdb opencast Opencast influxdb->opencast Precisely, the Opencast bundle opencast-statistics-provider-influx is the one that needs to be able to connect to InfluxDB using http(s). So the node hosting this bundle needs network access to InfluxDB.","title":"Architecture"},{"location":"configuration/admin-ui/statistics/#configuration","text":"Before configuring Opencast, you should have a running InfluxDB instance and should think about how you want your data to be written to InfluxDB and what your InfluxDB database schema should look like. Specifically, you should think about retention policies, measurement names, field/tag names and how much you want to downsample your data . If you don't have any data in your InfluxDB, but want to verify your setup is working, there is some test data provided in the section Verifying Your Setup .","title":"Configuration"},{"location":"configuration/admin-ui/statistics/#influxdb-access","text":"Opencast needs to know how to talk to your InfluxDB instance. Therefore, you should edit the configuration file etc/org.opencastproject.statistics.provider.influx.StatisticsProviderInfluxService.cfg and fill in your influx URI, username, password, and database name.","title":"InfluxDB Access"},{"location":"configuration/admin-ui/statistics/#statistics-providers","text":"To support the detailed configuration of the charts to be shown in the Admin UI, Opencast has a concept called Statistics Providers . Each statistics provider can be configured separately and for each provider, there is one chart displayed in the Admin UI. The configuration files of the providers have to be stored at etc/statistics and they have to follow a certain naming convention. Configuration files of providers using InfluxDB have to be named starting with influx. . All provider configurations have to be in json format. So e.g. influx.views.episode.sum.json would be a valid name. For each provider, the following properties have to be configured: id has to be a unique identifier and can be chosen freely. title is the title to be displayed with the chart. This can be a translation key. description is the description to be displayed with the chart. This can be a translation key. resourceType tells Opencast to which type of entity the chart refers to. Valid values are EPISODE , SERIES , and ORGANIZATION . This is used by Opencast to decide where to display the chart. sources is list of JSON objects, each containing the following fields: measurement , e.g. infinite.impressions_daily tells Opencast that your InfluxDB data retention policy is named infinite and your InfluxDB measurement name is impressions_daily . aggregation , e.g. SUM tells Opencast that InfluxDB's SUM() function should be used to calculate the values to display in the chart. aggregationVariable , e.g. value tells Opencast that the InfluxDB field which should be summed is named value . resourceIdName , e.g. episodeId tells Opencast that the InfluxDB tag identifying the resource type this provider refers to is named episodeId . resolutions is a list of resolutions supported by this provider. Opencast allows the user to select a resolution with which the data is displayed. Valid values are HOURLY , DAILY , WEEKLY , MONTHLY and YEARLY . E.g. when a chart shows data of two years, a DAILY resolution will lead to 2x365=730 values to be plotted while a MONTHLY resolution would leave us with 24 values being plotted in the chart. type defines the structure of the data provided by this provider. Currently, timeseries and runningtotal are supported. Here is an example json configuration for a provider which generates charts for episodes showing the number of views: etc/statistics/influx.views.episode.sum.json { \"id\": \"episode.views.sum.influx\", \"title\": \"STATISTICS.TITLE.VIEWS_SUM\", \"description\": \"STATISTICS.DESCRIPTION.VIEWS_SUM\", \"resourceType\": \"EPISODE\", \"sources\": [{ \"measurement\": \"infinite.impressions_daily\", \"aggregation\": \"SUM\", \"aggregationVariable\": \"value\", \"resourceIdName\": \"episodeId\", \"resolutions\": [ \"DAILY\", \"WEEKLY\", \"MONTHLY\", \"YEARLY\" ] }], \"type\": \"timeseries\" }","title":"Statistics Providers"},{"location":"configuration/admin-ui/statistics/#csv-exports","text":"Statistics can be exported to CSV files by clicking the \"download\" button in the top right corner of a graph. Per default, the export will contain the data which the graph currently displays. For series statistics, it is possible to change this behavior in the way that exported series statistics contain the data of all events of a series instead of just the top level series data. To enable this, it is necessary to specify which Statistics Provider should be used to get the episode data. See the configuration file org.opencastproject.statistics.export.impl.StatisticsExportServiceImpl.cfg for details.","title":"CSV Exports"},{"location":"configuration/admin-ui/statistics/#using-the-runningtotal-provider","text":"The runningtotal statistics provider is a special type of time series statistics provider. To illustrate what it can be used for, let\u2019s assume we want to track the number of hours of videos per organization (this is actually what the provider was initially designed for). We create a JSON file for the provider as such: { \"id\": \"organization.publishedhours.influx\", \"title\": \"STATISTICS.TITLE.PUBLISHEDHOURS\", \"description\": \"STATISTICS.DESCRIPTION.PUBLISHEDHOURS\", \"resourceType\": \"ORGANIZATION\", \"sources\": [{ \"measurement\": \"infinite.publishedhours\", \"aggregation\": \"SUM\", \"aggregationVariable\": \"hours\", \"resourceIdName\": \"organizationId\", \"resolutions\": [ \"DAILY\", \"WEEKLY\", \"MONTHLY\", \"YEARLY\" ] }], \"type\": \"runningtotal\" } Note that the published hours entries can be negative, in case we retract a video. When the runningtotal provider is asked to report on, for example, the monthly hours of video for a specific year, it will first take the sum of all video lengths up until that year. Then, for each month, it will take the sum of all the entries in that month, and add it to the previous value. And so on for the next months. To actually write these hours to the statistics data base, you have to add the statistics-writer workflow operation handler to your workflows. Specifically, somewhere in your publishing workflow, you have to add an entry such as this: <operation id=\"statistics-writer\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Collect video statistics\"> <configurations> <configuration key=\"flavor\">presenter/video</configuration> <configuration key=\"retract\">false</configuration> <configuration key=\"measurement-name\">publishedhours</configuration> <configuration key=\"organization-resource-id-name\">organizationId</configuration> <configuration key=\"length-field-name\">hours</configuration> <configuration key=\"temporal-resolution\">hours</configuration> </configurations> </operation> To decrement the running total of hours in the case of retractions, set the retract property to true . In the default case, or when the retract property is false the running total is not decremented when a retraction occurs.","title":"Using the runningtotal provider"},{"location":"configuration/admin-ui/statistics/#verifying-your-setup","text":"If you want to test your setup, you can put the following test data into InfluxDB and check if Opencast displays all charts correctly. First, create a series and an event as part of that series using the Opencast Admin UI. Second, copy the test data to a file called testdata.txt and edit it to match your InfluxDB database schema. Make sure you replace the episodeId , seriesId , and organizazionId tag value with the correct identifiers of the test event/series you just created. Also make sure, that the tag names (e.g.) episodeId and the field name ( value ) match the ones you have specified in the source strings of your providers. Also, the database name, retention policy name and measurement name have to match your configuration. The InfluxDB test data could look like this: # DDL CREATE DATABASE opencast # DML # CONTEXT-DATABASE: opencast impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554468810 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554555210 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554641610 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554728010 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554814410 impressions_daily,episodeId=6d3004a3-a581-4fdd-9dab-d4ed02f125f8,seriesId=5b421e3c-56a5-4c9e-86cd-bedcfa739cfa,organizationId=mh_default_org value=1 1554900810 The file format of the InfluxDB test data is described here . You can import the test data into InfluxDB using the following command: influx -import -path=testdata.txt -precision=s -database=opencast Once you have imported your test data, you should be able to view the charts you have configured when accessing the event/series details of your test event or Opencast's statistics section.","title":"Verifying Your Setup"},{"location":"configuration/admin-ui/thumbnails/","text":"Overview Video content is often represented visually by using thumbnail images and metadata. Think of, for example, of list of videos displayed as a thumbnail image together with the title and description for each video. On this page, this is the image that we refer to as thumbnail. Since having high quality thumbnails is important, the Opencast video editor comes with built-in support for thumbnails. We distinguish between three kinds of thumbnails: The Thumbnail Preview is a preview of the thumbnail shown in the video editor only The Default Thumbnail is automatically generated A Snapshot Thumbnail can be extracted from the video by the user An Uploaded Thumbnail is uploaded by the user As both the video editor and your workflows need to work together to enable full support of this feature, the Admin UI comes with a number of configuration options that allows this feature to be integrated into your workflow configuration. This page describes the configuration options of the Admin UI relevant for the thumbnail support of the video editor. These options can be adjusted in the configuration file etc/org.opencastproject.adminui.cfg . Thumbnail Preview The video editor displays a preview of the actual thumbnail at any time. This preview image is expected to be published in the publication channel internal as attachment with the flavor as specified in the Admin UI configuration: # Default: thumbnail/preview #thumbnail.preview.flavor=thumbnail/preview The initial thumbnail preview image is generated by the workflow that creates and publishes the distribution artefacts required by the video editor (e.g. etc/workflows/partial-preview.xml ). If the user uploads a thumbnail in the video editor, the thumbnail preview is created by converting the uploaded thumbnail using the following encoding profile: # Default: editor.thumbnail.preview.downscale #thumbnail.preview.profile.downscale=editor.thumbnail.preview.downscale If the user selects the default thumbnail or a snapshot thumbnail in the video editor, the update of the thumbnail preview is done differently depending on whether automatic distribution is enabled or not. In case that automatic distribution is disabled, the thumbnail preview is extracted from the source track using the following encoding profile: # Default: editor.thumbnail.preview #thumbnail.preview.profile=editor.thumbnail.preview In case that automatic distribution is enabled, a master thumbnail image is extracted. The thumbnail preview image is then created by downscaling this master thumbnail image using the following encoding profile: # Default: editor.thumbnail.preview.downscale #thumbnail.preview.profile.downscale=editor.thumbnail.preview.downscale Note that the thumbnail preview image is supposed to be used by the Admin UI only. Default Thumbnail This thumbnail is supposed to be automatically generated without user interaction. When the user chooses the default thumbnail in the video editor, Opencast will automatically generate and publish an updated thumbnail preview image. The default thumbnail image is extracted from a track identified by the following configuration: # Default: presenter #thumbnail.source.flavor.type.primary=presenter # Default: presentation #thumbnail.source.flavor.type.secondary=presentation # Default: source #thumbnail.source.flavor.subtype=source In this example, the default thumbnail would be extracted from the track with the flavor presenter/source or, if no such track is available, a track with the flavor presentation/source . The relative position within the edited video where the default thumbnail is extracted can be configured: # Default: 1.0 #thumbnail.default.position=1.0 Opencast will set the following processing settings for the event being edited: - `thumbnailType` is set to `0` to indicate that the default thumbnail is used - `thumbnailPosition` is set to the absolute position of the video where the default thumbnail should be extracted Snapshot Thumbnail In case the user is not happy with the automatically generated default thumbnail, the user can extract a thumbnail at an arbitrary position within the video. The snapshot thumbnail will be extracted from tracks identified by the following configuration properties: # Default: presenter/source #sourcetrack.left.flavor=presenter/source # Default: presentation/source #sourcetrack.right.flavor=presentation/source Note that the user can choose between \"Extract from video\", \"Extract from left video\" and \"Extract from right video\". In any case, the video editor ensures that the correct source track flavor is used. Opencast will set the following processing settings for the event being edited: - `thumbnailType` is set to `1` to indicate that a snapshot thumbnail is used - `thumbnailPosition` is set to the absolute position of the video where the snapshot thumbnail should be extracted - `thumbnailTrack` is set to the type of the flavor of the source track which is `presenter` or `presentation` Uploaded Thumbnail The most flexible option is to upload an image to be used as thumbnail. When the user uploads an image in the video editor, Opencast will automatically generate and publish the thumbnail preview and creates a new media package snapshot after adding the uploaded image as attachment to the media package. This attachment will have the following flavor: # Default: thumbnail/source #thumbnail.uploaded.flavor=thumbnail/source Additionally, the following tags are added to the attachment: # Default: archive #thumbnail.uploaded.tags=archive IMPORTANT: Please ensure that all workflows in your setup will always include this attachment when taking snapshots using the workflow operation snapshot by setting its configuration key source-tags and/or source-flavor appropriately. Opencast will set the following processing settings for the event being edited: - `thumbnailType` is set to `2` to indicate that an uploaded thumbnail is used Automatic Distribution To avoid the situation that a user needs to start a workflow just to update the thumbnail on the publication channels, Opencast supports automatic distribution of thumbnail images for publication channels that support incremental publication. This is currently supported by the following kinds of publication channels: Configurable publication channels (used by the External API) OAI-PMH publication channels Note that this mechanism is currently limited to at most one publication channel per kind. The automatic distribution of thumbnail images can be enabled in the configuration: # Default: false #thumbnail.distribution.auto=false If automatic distribution is enabled, Opencast will automatically create and publish the thumbnail. Note that the generation of multiple thumbnails is based on a master image that will be extracted using the following encoding profile: # Default: editor.thumbnail.master #thumbnail.master.profile=editor.thumbnail.master This master image will be converted into all the different formats required. For the automatic distribution to the OAI-PMH publication channel, the following settings are available: # The ID of the OAI-PMH publication channel # Default: oaipmh-default #thumbnail.distribution.oaipmh.channel=oaipmh-default # The flavor of the attachment # Default: */search+preview #thumbnail.distribution.oaipmh.flavor=*/search+preview # Comma-separated list of tags # Default:engage-download #thumbnail.distribution.oaipmh.tags=engage-download # Comma-separated list of encoding profiles # Default: search-cover.http.downscale #thumbnail.distribution.oaipmh.profiles=search-cover.http.downscale To enable automatic distribution to the OAI-PMH channel, thumbnail.distribution.auto must be set to true and thumbnail.distribution.oaipmh.channel must be set to a non-empty string. For the automatic distribution to the configurable publication channel, the following settings are available: # The ID of the configurable publication channel # Default: api #thumbnail.distribution.configurable.channel=api # The flavor of the attachment # Default: */search+preview #thumbnail.distribution.configurable.flavor=*/search+preview # Comma-separated list of tags # Default:engage-download #thumbnail.distribution.configurable.tags=engage-download # Comma-separated list of encoding profiles # Default: search-cover.http.downscale #thumbnail.distribution.configurable.profiles=search-cover.http.downscale To enable automatic distribution to the configurable publication channel, thumbnail.distribution.auto must be set to true and thumbnail.distribution.configurable.channel must be set to a non-empty string.","title":"Thumbnails"},{"location":"configuration/admin-ui/thumbnails/#overview","text":"Video content is often represented visually by using thumbnail images and metadata. Think of, for example, of list of videos displayed as a thumbnail image together with the title and description for each video. On this page, this is the image that we refer to as thumbnail. Since having high quality thumbnails is important, the Opencast video editor comes with built-in support for thumbnails. We distinguish between three kinds of thumbnails: The Thumbnail Preview is a preview of the thumbnail shown in the video editor only The Default Thumbnail is automatically generated A Snapshot Thumbnail can be extracted from the video by the user An Uploaded Thumbnail is uploaded by the user As both the video editor and your workflows need to work together to enable full support of this feature, the Admin UI comes with a number of configuration options that allows this feature to be integrated into your workflow configuration. This page describes the configuration options of the Admin UI relevant for the thumbnail support of the video editor. These options can be adjusted in the configuration file etc/org.opencastproject.adminui.cfg .","title":"Overview"},{"location":"configuration/admin-ui/thumbnails/#thumbnail-preview","text":"The video editor displays a preview of the actual thumbnail at any time. This preview image is expected to be published in the publication channel internal as attachment with the flavor as specified in the Admin UI configuration: # Default: thumbnail/preview #thumbnail.preview.flavor=thumbnail/preview The initial thumbnail preview image is generated by the workflow that creates and publishes the distribution artefacts required by the video editor (e.g. etc/workflows/partial-preview.xml ). If the user uploads a thumbnail in the video editor, the thumbnail preview is created by converting the uploaded thumbnail using the following encoding profile: # Default: editor.thumbnail.preview.downscale #thumbnail.preview.profile.downscale=editor.thumbnail.preview.downscale If the user selects the default thumbnail or a snapshot thumbnail in the video editor, the update of the thumbnail preview is done differently depending on whether automatic distribution is enabled or not. In case that automatic distribution is disabled, the thumbnail preview is extracted from the source track using the following encoding profile: # Default: editor.thumbnail.preview #thumbnail.preview.profile=editor.thumbnail.preview In case that automatic distribution is enabled, a master thumbnail image is extracted. The thumbnail preview image is then created by downscaling this master thumbnail image using the following encoding profile: # Default: editor.thumbnail.preview.downscale #thumbnail.preview.profile.downscale=editor.thumbnail.preview.downscale Note that the thumbnail preview image is supposed to be used by the Admin UI only.","title":"Thumbnail Preview"},{"location":"configuration/admin-ui/thumbnails/#default-thumbnail","text":"This thumbnail is supposed to be automatically generated without user interaction. When the user chooses the default thumbnail in the video editor, Opencast will automatically generate and publish an updated thumbnail preview image. The default thumbnail image is extracted from a track identified by the following configuration: # Default: presenter #thumbnail.source.flavor.type.primary=presenter # Default: presentation #thumbnail.source.flavor.type.secondary=presentation # Default: source #thumbnail.source.flavor.subtype=source In this example, the default thumbnail would be extracted from the track with the flavor presenter/source or, if no such track is available, a track with the flavor presentation/source . The relative position within the edited video where the default thumbnail is extracted can be configured: # Default: 1.0 #thumbnail.default.position=1.0 Opencast will set the following processing settings for the event being edited: - `thumbnailType` is set to `0` to indicate that the default thumbnail is used - `thumbnailPosition` is set to the absolute position of the video where the default thumbnail should be extracted","title":"Default Thumbnail"},{"location":"configuration/admin-ui/thumbnails/#snapshot-thumbnail","text":"In case the user is not happy with the automatically generated default thumbnail, the user can extract a thumbnail at an arbitrary position within the video. The snapshot thumbnail will be extracted from tracks identified by the following configuration properties: # Default: presenter/source #sourcetrack.left.flavor=presenter/source # Default: presentation/source #sourcetrack.right.flavor=presentation/source Note that the user can choose between \"Extract from video\", \"Extract from left video\" and \"Extract from right video\". In any case, the video editor ensures that the correct source track flavor is used. Opencast will set the following processing settings for the event being edited: - `thumbnailType` is set to `1` to indicate that a snapshot thumbnail is used - `thumbnailPosition` is set to the absolute position of the video where the snapshot thumbnail should be extracted - `thumbnailTrack` is set to the type of the flavor of the source track which is `presenter` or `presentation`","title":"Snapshot Thumbnail"},{"location":"configuration/admin-ui/thumbnails/#uploaded-thumbnail","text":"The most flexible option is to upload an image to be used as thumbnail. When the user uploads an image in the video editor, Opencast will automatically generate and publish the thumbnail preview and creates a new media package snapshot after adding the uploaded image as attachment to the media package. This attachment will have the following flavor: # Default: thumbnail/source #thumbnail.uploaded.flavor=thumbnail/source Additionally, the following tags are added to the attachment: # Default: archive #thumbnail.uploaded.tags=archive IMPORTANT: Please ensure that all workflows in your setup will always include this attachment when taking snapshots using the workflow operation snapshot by setting its configuration key source-tags and/or source-flavor appropriately. Opencast will set the following processing settings for the event being edited: - `thumbnailType` is set to `2` to indicate that an uploaded thumbnail is used","title":"Uploaded Thumbnail"},{"location":"configuration/admin-ui/thumbnails/#automatic-distribution","text":"To avoid the situation that a user needs to start a workflow just to update the thumbnail on the publication channels, Opencast supports automatic distribution of thumbnail images for publication channels that support incremental publication. This is currently supported by the following kinds of publication channels: Configurable publication channels (used by the External API) OAI-PMH publication channels Note that this mechanism is currently limited to at most one publication channel per kind. The automatic distribution of thumbnail images can be enabled in the configuration: # Default: false #thumbnail.distribution.auto=false If automatic distribution is enabled, Opencast will automatically create and publish the thumbnail. Note that the generation of multiple thumbnails is based on a master image that will be extracted using the following encoding profile: # Default: editor.thumbnail.master #thumbnail.master.profile=editor.thumbnail.master This master image will be converted into all the different formats required. For the automatic distribution to the OAI-PMH publication channel, the following settings are available: # The ID of the OAI-PMH publication channel # Default: oaipmh-default #thumbnail.distribution.oaipmh.channel=oaipmh-default # The flavor of the attachment # Default: */search+preview #thumbnail.distribution.oaipmh.flavor=*/search+preview # Comma-separated list of tags # Default:engage-download #thumbnail.distribution.oaipmh.tags=engage-download # Comma-separated list of encoding profiles # Default: search-cover.http.downscale #thumbnail.distribution.oaipmh.profiles=search-cover.http.downscale To enable automatic distribution to the OAI-PMH channel, thumbnail.distribution.auto must be set to true and thumbnail.distribution.oaipmh.channel must be set to a non-empty string. For the automatic distribution to the configurable publication channel, the following settings are available: # The ID of the configurable publication channel # Default: api #thumbnail.distribution.configurable.channel=api # The flavor of the attachment # Default: */search+preview #thumbnail.distribution.configurable.flavor=*/search+preview # Comma-separated list of tags # Default:engage-download #thumbnail.distribution.configurable.tags=engage-download # Comma-separated list of encoding profiles # Default: search-cover.http.downscale #thumbnail.distribution.configurable.profiles=search-cover.http.downscale To enable automatic distribution to the configurable publication channel, thumbnail.distribution.auto must be set to true and thumbnail.distribution.configurable.channel must be set to a non-empty string.","title":"Automatic Distribution"},{"location":"configuration/https/","text":"Serve Content Via HTTPS For all production systems you want to enable HTTPS. To archieve that, you can either use an HTTP(S) proxy like Apache httpd or Nginx (recommended) or enable HTTPS directly in Opencast. Using Nginx to enable HTTPS Enable HTTPS directly in Opencast Note that introducing HTTPS will not automatically migrate old content. It may still use the previously configured HTTP prorocol. For a semi-automatic migration, please take a look at the following guide: Migrating old content to HTTPS General Recommendations It's hard to keep up with security (e.g. proper TLS configuration). That is why we recommend using a proxy like Nginx or Apache as, due to their general popularity, it is usually much easier to find good configuration recommenations. There are also a couple of great sites to test your final setup: Observatory by Mozilla Qualys SSL Labs Additionally, if you have no easy way of obtaining proper TLS certificates for your organization, please consider using Let\u2019s Encrypt instead of self-signed certificates.","title":"Overview"},{"location":"configuration/https/#serve-content-via-https","text":"For all production systems you want to enable HTTPS. To archieve that, you can either use an HTTP(S) proxy like Apache httpd or Nginx (recommended) or enable HTTPS directly in Opencast. Using Nginx to enable HTTPS Enable HTTPS directly in Opencast Note that introducing HTTPS will not automatically migrate old content. It may still use the previously configured HTTP prorocol. For a semi-automatic migration, please take a look at the following guide: Migrating old content to HTTPS","title":"Serve Content Via HTTPS"},{"location":"configuration/https/#general-recommendations","text":"It's hard to keep up with security (e.g. proper TLS configuration). That is why we recommend using a proxy like Nginx or Apache as, due to their general popularity, it is usually much easier to find good configuration recommenations. There are also a couple of great sites to test your final setup: Observatory by Mozilla Qualys SSL Labs Additionally, if you have no easy way of obtaining proper TLS certificates for your organization, please consider using Let\u2019s Encrypt instead of self-signed certificates.","title":"General Recommendations"},{"location":"configuration/https/migration/","text":"Migrating old content to HTTPS Opencast will not modify already published events. This means that old publications might still use HTTP as protocol if it was used before. Re-processing or re-publishing will update the links but this may not be an option for larger migrations. For that, the following steps might help. Note that you modify stored data directly without any safety nets usually provided by Opencast. You should understand what you are doing! Backup your database, and the Solr and Elasticsearch indexes. Elasticsearch: {data}/index Solr: {data}/solr-indexes Configure Opencast to use HTTPS and test your set-up with a new publication. Put all your nodes into maintenance mode or, at least, do not process any videos. Update the media packages: find . -type f -name \"*.xml\" -exec \\ sed -i 's/http\\:\\/\\/oc-presentation\\.example\\.com\\:80/https:\\/\\/oc-presentation.example.com/g' {} + Update database tables. Note that Opencast 5 did change the database table name prefix from mh to oc : UPDATE opencast.oc_assets_snapshot SET mediapackage_xml = REPLACE( mediapackage_xml, 'http://oc-presentation.example.com:80', 'https://oc-presentation.example.com') WHERE INSTR( mediapackage_xml, 'http://oc-presentation.example.com:80') > 0; UPDATE opencast.oc_search SET mediapackage_xml = REPLACE( mediapackage_xml, 'http://oc-presentation.example.com:80', 'https://oc-presentation.example.com') WHERE INSTR( mediapackage_xml, 'http://oc-presentation.example.com:80') > 0; Remove the search service's Solr index. It usually is located at solr-indexes/search but its location really depends on org.opencastproject.solr.dir and org.opencastproject.search.solr.dir Rebuild the Solr indices by re-starting your Opencast node running the search service (usually presentation). Rebuild the Elasticsearch indices using the REST endpoint listed in the docs: https://admin.opencast.example.com/docs.html?path=/admin-ng/index Note: If the solr index does not repopulate by itself please check if your nodes are still in maintenance mode and reactiveate them.","title":"Migrating old content to HTTPS"},{"location":"configuration/https/migration/#migrating-old-content-to-https","text":"Opencast will not modify already published events. This means that old publications might still use HTTP as protocol if it was used before. Re-processing or re-publishing will update the links but this may not be an option for larger migrations. For that, the following steps might help. Note that you modify stored data directly without any safety nets usually provided by Opencast. You should understand what you are doing! Backup your database, and the Solr and Elasticsearch indexes. Elasticsearch: {data}/index Solr: {data}/solr-indexes Configure Opencast to use HTTPS and test your set-up with a new publication. Put all your nodes into maintenance mode or, at least, do not process any videos. Update the media packages: find . -type f -name \"*.xml\" -exec \\ sed -i 's/http\\:\\/\\/oc-presentation\\.example\\.com\\:80/https:\\/\\/oc-presentation.example.com/g' {} + Update database tables. Note that Opencast 5 did change the database table name prefix from mh to oc : UPDATE opencast.oc_assets_snapshot SET mediapackage_xml = REPLACE( mediapackage_xml, 'http://oc-presentation.example.com:80', 'https://oc-presentation.example.com') WHERE INSTR( mediapackage_xml, 'http://oc-presentation.example.com:80') > 0; UPDATE opencast.oc_search SET mediapackage_xml = REPLACE( mediapackage_xml, 'http://oc-presentation.example.com:80', 'https://oc-presentation.example.com') WHERE INSTR( mediapackage_xml, 'http://oc-presentation.example.com:80') > 0; Remove the search service's Solr index. It usually is located at solr-indexes/search but its location really depends on org.opencastproject.solr.dir and org.opencastproject.search.solr.dir Rebuild the Solr indices by re-starting your Opencast node running the search service (usually presentation). Rebuild the Elasticsearch indices using the REST endpoint listed in the docs: https://admin.opencast.example.com/docs.html?path=/admin-ng/index Note: If the solr index does not repopulate by itself please check if your nodes are still in maintenance mode and reactiveate them.","title":"Migrating old content to HTTPS"},{"location":"configuration/https/nginx/","text":"Enable HTTPS using Nginx This guide will help you to configure Nginx to act as HTTP(S) proxy for Opencast. Opencast Configuration Make sure to use https as protocol for org.opencastproject.server.url in etc/custom.properties . org.opencastproject.server.url=https://example.opencast.org No other configuration is required. Do not enable TLS in Opencast. Listen to local connections only. Both are the default settings. Minimal Set-up Note that this guide does not give any security advise but is meant to provide a minimal working example which works well with Opencast. The following configuration is an example for /etc/nginx/nginx.conf . Note that depending on your distributions packaging, often conf.d or sites-enabled directories are used. But since this is an Opencast only set-up (we do not use the web server for anything else), we are just using the main configuration file. Explanations for the configuration directives are provided inline. Please make sure to replace example.opencast.org with your nodes domain name. The main goals of this set-up are: Always redirect to HTTPS Proxy to Opencast and take care of TLS Avoid caching # Check your distributions default nginx.conf to make sure the first # configuration keys (up until the http section) make sense within your # distribution's set-up. # Defines user and group credentials used by worker processes. If group is # omitted, a group whose name equals that of user is used. user nginx; # Configures logging to `/var/log/\u2026`. Log level `error` is used by default. error_log /var/log/nginx/error.log; # Defines a file that will store the process ID of the main process. This needs # to match the Systemd unit file. pid /run/nginx.pid; events { # Sets the maximum number of simultaneous connections that can be opened by # a worker process. worker_connections 1024; } ### # What follows is the specific http(s) set-up for Opencast. ## http { # HTTP set-up server { listen 80; listen [::]:80; server_name example.opencast.org; # Enforce HTTPS by redirecting requests location / { return 301 https://example.opencast.org$request_uri; } } # HTTPS set-up server { listen 443 ssl http2; listen [::]:443 ssl http2; server_name example.opencast.org; # Path to the TLS certificate and private key. In almost all cases, you # need to provide intermediate certificates as well to ensure browsers # get the whole certificate chain. ssl_certificate_key /path/to/example.opencast.org.key; ssl_certificate /path/to/example.opencast.org.crt; # Accept large ingests. There should be no limit since Opencast may get # really large ingests. client_max_body_size 0; # Proxy configuration for Opencast location / { # Make sure to pass the real addresses as well as the fact that # outwards we are using HTTPS to Opencast. proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # Pass requests to this location. This expects Opencast to be # running locally on port 8080 which should be the default set-up. proxy_pass http://127.0.0.1:8080; # Make sure to redirect location headers to HTTPS. This is just a # precaution and shouldn't strictly be necessary but it did prevent # some issues in the past and it does not cost much performance. proxy_redirect http://$host https://$host; # Do not buffer responses proxy_buffering off; # Do not buffer requests proxy_request_buffering off; } } }","title":"Using Nginx"},{"location":"configuration/https/nginx/#enable-https-using-nginx","text":"This guide will help you to configure Nginx to act as HTTP(S) proxy for Opencast.","title":"Enable HTTPS using Nginx"},{"location":"configuration/https/nginx/#opencast-configuration","text":"Make sure to use https as protocol for org.opencastproject.server.url in etc/custom.properties . org.opencastproject.server.url=https://example.opencast.org No other configuration is required. Do not enable TLS in Opencast. Listen to local connections only. Both are the default settings.","title":"Opencast Configuration"},{"location":"configuration/https/nginx/#minimal-set-up","text":"Note that this guide does not give any security advise but is meant to provide a minimal working example which works well with Opencast. The following configuration is an example for /etc/nginx/nginx.conf . Note that depending on your distributions packaging, often conf.d or sites-enabled directories are used. But since this is an Opencast only set-up (we do not use the web server for anything else), we are just using the main configuration file. Explanations for the configuration directives are provided inline. Please make sure to replace example.opencast.org with your nodes domain name. The main goals of this set-up are: Always redirect to HTTPS Proxy to Opencast and take care of TLS Avoid caching # Check your distributions default nginx.conf to make sure the first # configuration keys (up until the http section) make sense within your # distribution's set-up. # Defines user and group credentials used by worker processes. If group is # omitted, a group whose name equals that of user is used. user nginx; # Configures logging to `/var/log/\u2026`. Log level `error` is used by default. error_log /var/log/nginx/error.log; # Defines a file that will store the process ID of the main process. This needs # to match the Systemd unit file. pid /run/nginx.pid; events { # Sets the maximum number of simultaneous connections that can be opened by # a worker process. worker_connections 1024; } ### # What follows is the specific http(s) set-up for Opencast. ## http { # HTTP set-up server { listen 80; listen [::]:80; server_name example.opencast.org; # Enforce HTTPS by redirecting requests location / { return 301 https://example.opencast.org$request_uri; } } # HTTPS set-up server { listen 443 ssl http2; listen [::]:443 ssl http2; server_name example.opencast.org; # Path to the TLS certificate and private key. In almost all cases, you # need to provide intermediate certificates as well to ensure browsers # get the whole certificate chain. ssl_certificate_key /path/to/example.opencast.org.key; ssl_certificate /path/to/example.opencast.org.crt; # Accept large ingests. There should be no limit since Opencast may get # really large ingests. client_max_body_size 0; # Proxy configuration for Opencast location / { # Make sure to pass the real addresses as well as the fact that # outwards we are using HTTPS to Opencast. proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # Pass requests to this location. This expects Opencast to be # running locally on port 8080 which should be the default set-up. proxy_pass http://127.0.0.1:8080; # Make sure to redirect location headers to HTTPS. This is just a # precaution and shouldn't strictly be necessary but it did prevent # some issues in the past and it does not cost much performance. proxy_redirect http://$host https://$host; # Do not buffer responses proxy_buffering off; # Do not buffer requests proxy_request_buffering off; } } }","title":"Minimal Set-up"},{"location":"configuration/https/opencast.only/","text":"Enable HTTPS directly in Opencast In opencast/etc/ , use the org.ops4j.pax.web.cfg file for configuration: # ... # Whether Opencast itself should handle HTTPS traffic. # Even if you set this to 'false',you can still use an HTTP proxy to handle SSL. org.osgi.service.http.secure.enabled=true # The secure server port to use if running Opencast with HTTPS (as opposed to # a proxy handling HTTPS). # Note that we use the docker proxy for the port-mapping from 8843 from within # the container to 443 at the host # Don't run Opencast with root privileges, which is a security issue org.osgi.service.http.port.secure=8443 # Path to the keystore file. # Use the Java `keytool` to generate this file. # Example: # keytool -genkey -keyalg RSA -validity 365 -alias serverkey \\ # -keypass password -storepass password -keystore keystore.jks org.ops4j.pax.web.ssl.keystore=<path_to_keystore> # Password used for keystore integrity check. org.ops4j.pax.web.ssl.password=<the_keystore_password> # Password used for keystore. org.ops4j.pax.web.ssl.keypassword=<the_key_password> Port-Forwarding required Note that Opencast most likely can't bind to port 443. That's why you still need to reverse-proxy or port-forward if you want to avoid URLs with port specified like https://host:8443/ which is technically perfectly okay but may confuse users or may be perceived as \"ugly\". Here is a non-comprehensive lists of tools and methods which can be used for port forwarding: Port-Forwarding with iptables A rule like iptables -A PREROUTING -t nat -i eth0 -p tcp --dport 443 -j REDIRECT --to-port 8443 # Allow also localhost traffic to use :443 # iptables -A OUTPUT -t nat -o lo -p tcp --dport 443 -j REDIRECT --to-port 8443 should do the job after replacing eth0 with the network interface your Opencast consumers will connect on. Note that you usually want to persist the rule. Port-Forwarding with docker(-proxy) When starting a container from an Opencast image, either insert a command line argument to docker run: -p 443:8443 or add a ports: in docker-compose.yaml . Port-Forwarding with sniproxy Sniproxy can be used as well, especially if you have multiple servers running on the same machine that handle HTTPS individually (no termination proxy). user, pidfile, error_log ... listen 443 { proto tls table https_hosts fallback 127.0.0.1:8443 access_log { filename /var/log/sniproxy/https_access.log priority notice } } table https_hosts { .*\\.opencast\\.example\\.org 127.0.0.1:8443 } Creating the keystore What you need, is the TLS private key and the certificate including the whole chain between the root certificate, all intermediates and the certificate itself. Obtaining the certificate chain If you only have the key and the certificate, I recommend certificatechain.io or cert-chain-resolver . The latter can be used as follows: # Obtain the chain for cert.pem and save it at opencast.chain.pem.tmp # The -s command switch includes the root certificate; this is not # mandatory and might add some overhead cert-chain-resolver -s -o \"opencast.chain.pem.tmp\" \"cert.pem\" # Verify the certificate using the chain openssl verify -crl_download -crl_check -untrusted \"opencast.chain.pem.tmp\" \"cert.pem\" Create the p12 keystore If the private key (assumed to be key.pem ) is encrypted (password protected), issue the following command. Note that there are safer ways supplying the key's password to OpenSSL. openssl pkcs12 \\ -export \\ -inkey \"key.pem\" \\ -passin \"pass:<the_keys_password>\" \\ -in \"opencast.chain.pem.tmp\" \\ -name \"serverkey\" \\ -out \"opencast.p12\" \\ -passout \"pass:<the_keystore_password>\" In case the private key is not protected by password: openssl pkcs12 \\ -export \\ -inkey \"key.pem\" \\ -in \"opencast.chain.pem.tmp\" \\ -name \"serverkey\" \\ -out \"opencast.p12\" \\ -passout \"pass:<the_keystore_password>\" Import the p12 keystore into a Java keystore: keytool \\ -importkeystore \\ -srckeystore \"opencast.p12\" \\ -srcstoretype \"pkcs12\" \\ -srcstorepass \"<the_keystore_password>\" \\ -destkeystore \"keystore.jks\" \\ -storepass \"<the_keystore_password>\" # print out details about the JKS built keytool \\ -keystore \"keystore.jks\" \\ -list \\ -destalias serverkey \\ -storepass \"<the_keystore_password>\" There exists a shell script automating that task . Default to HTTPS When finished, restarted and verified that HTTPS works as expected, you can change Opencast's default URL to the HTTPS one. Set org.opencastproject.server.url to the HTTPS-URL in etc/custom.properties . org.opencastproject.server.url=https://opencast.example.com","title":"Internal HTTPS"},{"location":"configuration/https/opencast.only/#enable-https-directly-in-opencast","text":"In opencast/etc/ , use the org.ops4j.pax.web.cfg file for configuration: # ... # Whether Opencast itself should handle HTTPS traffic. # Even if you set this to 'false',you can still use an HTTP proxy to handle SSL. org.osgi.service.http.secure.enabled=true # The secure server port to use if running Opencast with HTTPS (as opposed to # a proxy handling HTTPS). # Note that we use the docker proxy for the port-mapping from 8843 from within # the container to 443 at the host # Don't run Opencast with root privileges, which is a security issue org.osgi.service.http.port.secure=8443 # Path to the keystore file. # Use the Java `keytool` to generate this file. # Example: # keytool -genkey -keyalg RSA -validity 365 -alias serverkey \\ # -keypass password -storepass password -keystore keystore.jks org.ops4j.pax.web.ssl.keystore=<path_to_keystore> # Password used for keystore integrity check. org.ops4j.pax.web.ssl.password=<the_keystore_password> # Password used for keystore. org.ops4j.pax.web.ssl.keypassword=<the_key_password>","title":"Enable HTTPS directly in Opencast"},{"location":"configuration/https/opencast.only/#port-forwarding-required","text":"Note that Opencast most likely can't bind to port 443. That's why you still need to reverse-proxy or port-forward if you want to avoid URLs with port specified like https://host:8443/ which is technically perfectly okay but may confuse users or may be perceived as \"ugly\". Here is a non-comprehensive lists of tools and methods which can be used for port forwarding:","title":"Port-Forwarding required"},{"location":"configuration/https/opencast.only/#port-forwarding-with-iptables","text":"A rule like iptables -A PREROUTING -t nat -i eth0 -p tcp --dport 443 -j REDIRECT --to-port 8443 # Allow also localhost traffic to use :443 # iptables -A OUTPUT -t nat -o lo -p tcp --dport 443 -j REDIRECT --to-port 8443 should do the job after replacing eth0 with the network interface your Opencast consumers will connect on. Note that you usually want to persist the rule.","title":"Port-Forwarding with iptables"},{"location":"configuration/https/opencast.only/#port-forwarding-with-docker-proxy","text":"When starting a container from an Opencast image, either insert a command line argument to docker run: -p 443:8443 or add a ports: in docker-compose.yaml .","title":"Port-Forwarding with docker(-proxy)"},{"location":"configuration/https/opencast.only/#port-forwarding-with-sniproxy","text":"Sniproxy can be used as well, especially if you have multiple servers running on the same machine that handle HTTPS individually (no termination proxy). user, pidfile, error_log ... listen 443 { proto tls table https_hosts fallback 127.0.0.1:8443 access_log { filename /var/log/sniproxy/https_access.log priority notice } } table https_hosts { .*\\.opencast\\.example\\.org 127.0.0.1:8443 }","title":"Port-Forwarding with sniproxy"},{"location":"configuration/https/opencast.only/#creating-the-keystore","text":"What you need, is the TLS private key and the certificate including the whole chain between the root certificate, all intermediates and the certificate itself.","title":"Creating the keystore"},{"location":"configuration/https/opencast.only/#obtaining-the-certificate-chain","text":"If you only have the key and the certificate, I recommend certificatechain.io or cert-chain-resolver . The latter can be used as follows: # Obtain the chain for cert.pem and save it at opencast.chain.pem.tmp # The -s command switch includes the root certificate; this is not # mandatory and might add some overhead cert-chain-resolver -s -o \"opencast.chain.pem.tmp\" \"cert.pem\" # Verify the certificate using the chain openssl verify -crl_download -crl_check -untrusted \"opencast.chain.pem.tmp\" \"cert.pem\"","title":"Obtaining the certificate chain"},{"location":"configuration/https/opencast.only/#create-the-p12-keystore","text":"If the private key (assumed to be key.pem ) is encrypted (password protected), issue the following command. Note that there are safer ways supplying the key's password to OpenSSL. openssl pkcs12 \\ -export \\ -inkey \"key.pem\" \\ -passin \"pass:<the_keys_password>\" \\ -in \"opencast.chain.pem.tmp\" \\ -name \"serverkey\" \\ -out \"opencast.p12\" \\ -passout \"pass:<the_keystore_password>\" In case the private key is not protected by password: openssl pkcs12 \\ -export \\ -inkey \"key.pem\" \\ -in \"opencast.chain.pem.tmp\" \\ -name \"serverkey\" \\ -out \"opencast.p12\" \\ -passout \"pass:<the_keystore_password>\"","title":"Create the p12 keystore"},{"location":"configuration/https/opencast.only/#import-the-p12-keystore-into-a-java-keystore","text":"keytool \\ -importkeystore \\ -srckeystore \"opencast.p12\" \\ -srcstoretype \"pkcs12\" \\ -srcstorepass \"<the_keystore_password>\" \\ -destkeystore \"keystore.jks\" \\ -storepass \"<the_keystore_password>\" # print out details about the JKS built keytool \\ -keystore \"keystore.jks\" \\ -list \\ -destalias serverkey \\ -storepass \"<the_keystore_password>\" There exists a shell script automating that task .","title":"Import the p12 keystore into a Java keystore:"},{"location":"configuration/https/opencast.only/#default-to-https","text":"When finished, restarted and verified that HTTPS works as expected, you can change Opencast's default URL to the HTTPS one. Set org.opencastproject.server.url to the HTTPS-URL in etc/custom.properties . org.opencastproject.server.url=https://opencast.example.com","title":"Default to HTTPS"},{"location":"installation/","text":"Install Opencast Installation from Source These guides will help you to build Opencast, including all necessary third party tools. This method will most likely work on all Unix-like systems. RedHat Enterprise Linux CentOS Scientific Linux Fedora Debian Ubuntu Mac OS X Building on most other Unix-like operating systems should be very much alike. Installation from Repository There are package repositories available for multiple operating systems. It provides packages containing pre-configured and pre-built Opencast installations. RedHat Enterprise Linux 7 CentOS 7 Scientific Linux 7 Fedora Debian Ubuntu Experimental RedHat Enterprise Linux 8 CentOS 8 Installation via Script We provide configuration scripts to install and configure Opencast automatically. These scripts rely on the packages from the repository above. Ansible Installation with Docker You can also use Docker to quickly install or test Opencast. There are multiple Docker images available for installing Opencast on either a single or multiple server. Testing Locally with Docker Installation Across Multiple Servers For production systems, it is recommended to install Opencast across multiple servers to separate the processing, management and presentation layer, so that, for example, even if the processing layer is under full load, users can still watch recordings unaffected since the presentation layer is running on a separate machine. Installation Across Multiple Servers","title":"Overview"},{"location":"installation/#install-opencast","text":"","title":"Install Opencast"},{"location":"installation/#installation-from-source","text":"These guides will help you to build Opencast, including all necessary third party tools. This method will most likely work on all Unix-like systems. RedHat Enterprise Linux CentOS Scientific Linux Fedora Debian Ubuntu Mac OS X Building on most other Unix-like operating systems should be very much alike.","title":"Installation from Source"},{"location":"installation/#installation-from-repository","text":"There are package repositories available for multiple operating systems. It provides packages containing pre-configured and pre-built Opencast installations. RedHat Enterprise Linux 7 CentOS 7 Scientific Linux 7 Fedora Debian Ubuntu Experimental RedHat Enterprise Linux 8 CentOS 8","title":"Installation from Repository"},{"location":"installation/#installation-via-script","text":"We provide configuration scripts to install and configure Opencast automatically. These scripts rely on the packages from the repository above. Ansible","title":"Installation via Script"},{"location":"installation/#installation-with-docker","text":"You can also use Docker to quickly install or test Opencast. There are multiple Docker images available for installing Opencast on either a single or multiple server. Testing Locally with Docker","title":"Installation with Docker"},{"location":"installation/#installation-across-multiple-servers","text":"For production systems, it is recommended to install Opencast across multiple servers to separate the processing, management and presentation layer, so that, for example, even if the processing layer is under full load, users can still watch recordings unaffected since the presentation layer is running on a separate machine. Installation Across Multiple Servers","title":"Installation Across Multiple Servers"},{"location":"installation/ansible/","text":"Install from Repository via Ansible (Debian, and RedHat based distros) We provide Ansible installation and configuration scripts which drastically reduce the time required to set up an Opencast installation, and help you manage the configuration across your entire cluster. Whether you are installing a single machine, or dozens, these scripts should do the basic setup of your Opencast install. These scripts use the package repository, so the first step is to register. Note that these scripts are meant as a basis to get you started and you will likely need to adjust and extend them to fit your local environment for which you need to have some basic knowledge of Ansible. Please review the scripts before using them to make sure they fit your needs. Examples in this document refer to 7.x and r/7.x . You should replace those with the version you want to install! Registration Before you can start you need to get an account for the repository. You will need the credentials that you get by mail after the registration to successfully complete this manual. The placeholders [your_username] and [your_password] are used in this manual wherever the credentials are needed. Please visit pkg.opencast.org Install Ansible Ansible may be available from your distribution's packaging manager, or you may need to install it manually. See the Ansible installation documentation for more details. Script Setup The next step is getting the scripts themselves. Go to the list of branches and then click on the branch version you want. This must match the desired Opencast version, so if you want the latest Opencast 7 release click on r/7.x . Then click on Clone or download , then Download Zip . You will need to decompress this file someplace handy, and then run terminal commands from inside that directory. Alternatively, if you familiar with git you can just clone the repository like this git clone -b r/7.x https://github.com/opencast/oc-config-management Install Opencast To complete your install, please follow the instructions in the README.md documentation included in the scripts.","title":"Ansible"},{"location":"installation/ansible/#install-from-repository-via-ansible-debian-and-redhat-based-distros","text":"We provide Ansible installation and configuration scripts which drastically reduce the time required to set up an Opencast installation, and help you manage the configuration across your entire cluster. Whether you are installing a single machine, or dozens, these scripts should do the basic setup of your Opencast install. These scripts use the package repository, so the first step is to register. Note that these scripts are meant as a basis to get you started and you will likely need to adjust and extend them to fit your local environment for which you need to have some basic knowledge of Ansible. Please review the scripts before using them to make sure they fit your needs. Examples in this document refer to 7.x and r/7.x . You should replace those with the version you want to install!","title":"Install from Repository via Ansible (Debian, and RedHat based distros)"},{"location":"installation/ansible/#registration","text":"Before you can start you need to get an account for the repository. You will need the credentials that you get by mail after the registration to successfully complete this manual. The placeholders [your_username] and [your_password] are used in this manual wherever the credentials are needed. Please visit pkg.opencast.org","title":"Registration"},{"location":"installation/ansible/#install-ansible","text":"Ansible may be available from your distribution's packaging manager, or you may need to install it manually. See the Ansible installation documentation for more details.","title":"Install Ansible"},{"location":"installation/ansible/#script-setup","text":"The next step is getting the scripts themselves. Go to the list of branches and then click on the branch version you want. This must match the desired Opencast version, so if you want the latest Opencast 7 release click on r/7.x . Then click on Clone or download , then Download Zip . You will need to decompress this file someplace handy, and then run terminal commands from inside that directory. Alternatively, if you familiar with git you can just clone the repository like this git clone -b r/7.x https://github.com/opencast/oc-config-management","title":"Script Setup"},{"location":"installation/ansible/#install-opencast","text":"To complete your install, please follow the instructions in the README.md documentation included in the scripts.","title":"Install Opencast"},{"location":"installation/debs/","text":"Install from Repository (Debian, Ubuntu) There is a Debian software repository (DEB) available for Debian-based Linux distributions provided by Greg Logan, and hosted at University of Osnabr\u00fcck. This repository provides prebuilt Opencast installations, including all 3rd-Party-Tools. Using this method, you do not have to compile the software by yourself, but you still need to configure it. It may also be interesting for developers as all dependencies for Opencast usage, testing and development are provided by the Debian repository. Availability Note that it may take some time (usually about two weeks after a new release is out) before the DEBs are available. Watch for announcements on list or just check which versions are available in the repository. Currently Supported Debian 8/9 amd64 Ubuntu 16.04 amd64 Debian 8 requires a manual OpenJDK install Add jessie-backports to your sources, replacing the mirror URL with your local mirror: echo \"deb http://[YOUR_MIRROR]/debian jessie-backports main\" | sudo tee /etc/apt/sources.list.d/jessie-backports.list Update your package listing apt-get update Install OpenJDK 8 from the backports apt-get install -t jessie-backports openjdk-8-jre Other architectures like i386, i686, arm, \u2026 are not supported! Registration Before you can start you need to get an account for the repository. You will need the credentials that you get by mail after the registration to successfully complete this manual. The placeholders [your_username] and [your_password] are used in this manual wherever the credentials are needed. Please visit pkg.opencast.org Activate Repository First you have to install the necessary repositories so that your package manager can access them: Ensure https repositories are supported: apt-get install apt-transport-https ca-certificates sudo Add Opencast repository: cd /etc/apt/sources.list.d/ echo \"deb https://[YOUR_USERNAME]:[YOUR_PASSWORD]@pkg.opencast.org/debian stable/\" | sudo tee opencast.list It might take some time after the release of a new Opencast version before the Debs are moved to the stable repository. If you need the new release prior to its promotion to stable you can use the testing repository. Note that the testing repository is an additional repository and still requires the stable repository to be active. cd /etc/apt/sources.list.d/ echo \"deb https://[YOUR_USERNAME]:[YOUR_PASSWORD]@pkg.opencast.org/debian testing/\" | sudo tee opencast.list Add the repository key to your apt keyring: wget -qO - https://pkg.opencast.org/gpgkeys/opencast-deb.key | sudo apt-key add - Update your package listing apt-get update Install Apache ActiveMQ The Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be installed on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the the normal software repositories for your distribution: apt-get install activemq-dist A prepared configuration file for ActiveMQ can be found at /usr/share/opencast/docs/scripts/activemq/activemq.xml after Opencast itself has been installed and should replace /etc/activemq/activemq.xml . For an all-in-one installation the following command should suffice: cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml ActiveMQ must be started prior to Opencast startup. More information about how to properly set up ActiveMQ for Opencast can be found in the message broker configuration documentation . Note that most Debian based distributions also have activemq packaged by upstream package maintainers. These packages will work, however the ActiveMQ configuration file will require modification to function correctly. Install Opencast For this guide we will be installing the latest released version of Opencast 3.x, however if you wish to install another version please change the name accordingly. Basic Installation For a basic installation (All-In-One) just run: apt-get install opencast-3-allinone This will install the default distribution of Opencast and all its dependencies, including the 3rd-Party-Tools. Note that while the repository provides a packaged version of ffmpeg, your distribution may have a version which is pre-installed or otherwise takes precedence. This version may work, however Opencast only formally supports the version(s) in the repository. At this point Opencast is installed and will work locally, but it is not completely configured. Please follow the Basic Configuration guide from here. Once you are ready, start Opencast: On a SysV-init based system service opencast start On a Systemd based system systemctl start opencast.service Advanced Installation While the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might want to have more control over your system and deploy it over several machines by choosing which parts of Opencast you want to install. You can list all Opencast packages with: apt-cache search opencast This will list all available Opencast distributions in the form opencast-<version>-<dist-type> Some available distributions are: opencast-X-allinone opencast-X-admin opencast-X-presentation opencast-X-worker \u2026where X stands for a specific Opencast version. These packages will install the latest release for a given version, so opencast-3-admin will install the admin profile for Opencast 3.x (currently 3.3). Once Opencast 3.4 has been packaged and made available your system will automatically update to Opencast 3.4 using the standard apt-get tools. Point Revisions (Experts only) If for some reason you wish to install a specific point revision of Opencast, and the repository still hosts that point revision, you can select it by adding it, and the packaging build, to your apt-get install line. For example: apt-get install opencast-3-admin=3.2-2 Installs an Opencast 3.2 admin node, using the second build of that series. Not all series have more than a single build, and older point revisions may be removed once superceded, so please explore the repository prior to attempting this. Install 3rd-party-tools This step is optional and only recommended for those who want to build Opencast from source. If you install Opencast from the repository, all necessary dependencies will be installed automatically. You can install all necessary 3rd-Party-Tools for Opencast like this: apt-get install ffmpeg-dist tesseract-ocr sox hunspell synfig netcat Upgrading Major Versions While these packages will automatically upgrade you to the latest point version in a release series, they do not automatically upgrade you to the latest major version. In other words, if you install opencast3-admin you get the latest 3.x release, not the latest 4.x release. To upgrade from one version to another you first stop Opencast: On a SysV-init based system service opencast stop On a Systemd based system systemctl stop opencast.service As a reminder, these instructions will change your Opencast installation, and files to a new version which is likely incompatible with older versions. If you are performing this on a production system, please ensure you have valid backups prior to taking the next steps. Uninstall your current Opencast packaging (using Opencast 3 as an example): apt-get remove opencast-3-* Then install the new version (using Opencast 4 as an example): apt-get install opencast-4-allinone At this point you must follow the relevant upgrade instructions, prior to starting Opencast again. Uninstall Opencast To uninstall Opencast, you can run: apt-get remove 'opencast*' This will not touch your created media files or modified configuration files. If you want to remove them as well, you have to do that by yourself. # Remove media files sudo rm -rf /srv/opencast # Remove local db, search indexes and working files sudo rm -rf /var/lib/opencast # Remove configuration files sudo rm -rf /etc/opencast # Remove logs sudo rm -rf /var/log/opencast Troubleshooting Missing Dependencies This repository expects that the stable section is always available, regardless of which version of Opencast you have installed. The 3rd party tools (ActiveMQ, FFmpeg) may or may not be in the other sections, but if they are there it is only during a testing period for a new version. For day-to-day use, please install them from stable !","title":"Debian/Ubuntu"},{"location":"installation/debs/#install-from-repository-debian-ubuntu","text":"There is a Debian software repository (DEB) available for Debian-based Linux distributions provided by Greg Logan, and hosted at University of Osnabr\u00fcck. This repository provides prebuilt Opencast installations, including all 3rd-Party-Tools. Using this method, you do not have to compile the software by yourself, but you still need to configure it. It may also be interesting for developers as all dependencies for Opencast usage, testing and development are provided by the Debian repository.","title":"Install from Repository (Debian, Ubuntu)"},{"location":"installation/debs/#availability","text":"Note that it may take some time (usually about two weeks after a new release is out) before the DEBs are available. Watch for announcements on list or just check which versions are available in the repository.","title":"Availability"},{"location":"installation/debs/#currently-supported","text":"Debian 8/9 amd64 Ubuntu 16.04 amd64 Debian 8 requires a manual OpenJDK install Add jessie-backports to your sources, replacing the mirror URL with your local mirror: echo \"deb http://[YOUR_MIRROR]/debian jessie-backports main\" | sudo tee /etc/apt/sources.list.d/jessie-backports.list Update your package listing apt-get update Install OpenJDK 8 from the backports apt-get install -t jessie-backports openjdk-8-jre Other architectures like i386, i686, arm, \u2026 are not supported!","title":"Currently Supported"},{"location":"installation/debs/#registration","text":"Before you can start you need to get an account for the repository. You will need the credentials that you get by mail after the registration to successfully complete this manual. The placeholders [your_username] and [your_password] are used in this manual wherever the credentials are needed. Please visit pkg.opencast.org","title":"Registration"},{"location":"installation/debs/#activate-repository","text":"First you have to install the necessary repositories so that your package manager can access them: Ensure https repositories are supported: apt-get install apt-transport-https ca-certificates sudo Add Opencast repository: cd /etc/apt/sources.list.d/ echo \"deb https://[YOUR_USERNAME]:[YOUR_PASSWORD]@pkg.opencast.org/debian stable/\" | sudo tee opencast.list It might take some time after the release of a new Opencast version before the Debs are moved to the stable repository. If you need the new release prior to its promotion to stable you can use the testing repository. Note that the testing repository is an additional repository and still requires the stable repository to be active. cd /etc/apt/sources.list.d/ echo \"deb https://[YOUR_USERNAME]:[YOUR_PASSWORD]@pkg.opencast.org/debian testing/\" | sudo tee opencast.list Add the repository key to your apt keyring: wget -qO - https://pkg.opencast.org/gpgkeys/opencast-deb.key | sudo apt-key add - Update your package listing apt-get update","title":"Activate Repository"},{"location":"installation/debs/#install-apache-activemq","text":"The Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be installed on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the the normal software repositories for your distribution: apt-get install activemq-dist A prepared configuration file for ActiveMQ can be found at /usr/share/opencast/docs/scripts/activemq/activemq.xml after Opencast itself has been installed and should replace /etc/activemq/activemq.xml . For an all-in-one installation the following command should suffice: cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml ActiveMQ must be started prior to Opencast startup. More information about how to properly set up ActiveMQ for Opencast can be found in the message broker configuration documentation . Note that most Debian based distributions also have activemq packaged by upstream package maintainers. These packages will work, however the ActiveMQ configuration file will require modification to function correctly.","title":"Install Apache ActiveMQ"},{"location":"installation/debs/#install-opencast","text":"For this guide we will be installing the latest released version of Opencast 3.x, however if you wish to install another version please change the name accordingly.","title":"Install Opencast"},{"location":"installation/debs/#basic-installation","text":"For a basic installation (All-In-One) just run: apt-get install opencast-3-allinone This will install the default distribution of Opencast and all its dependencies, including the 3rd-Party-Tools. Note that while the repository provides a packaged version of ffmpeg, your distribution may have a version which is pre-installed or otherwise takes precedence. This version may work, however Opencast only formally supports the version(s) in the repository. At this point Opencast is installed and will work locally, but it is not completely configured. Please follow the Basic Configuration guide from here. Once you are ready, start Opencast: On a SysV-init based system service opencast start On a Systemd based system systemctl start opencast.service","title":"Basic Installation"},{"location":"installation/debs/#advanced-installation","text":"While the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might want to have more control over your system and deploy it over several machines by choosing which parts of Opencast you want to install. You can list all Opencast packages with: apt-cache search opencast This will list all available Opencast distributions in the form opencast-<version>-<dist-type> Some available distributions are: opencast-X-allinone opencast-X-admin opencast-X-presentation opencast-X-worker \u2026where X stands for a specific Opencast version. These packages will install the latest release for a given version, so opencast-3-admin will install the admin profile for Opencast 3.x (currently 3.3). Once Opencast 3.4 has been packaged and made available your system will automatically update to Opencast 3.4 using the standard apt-get tools.","title":"Advanced Installation"},{"location":"installation/debs/#point-revisions-experts-only","text":"If for some reason you wish to install a specific point revision of Opencast, and the repository still hosts that point revision, you can select it by adding it, and the packaging build, to your apt-get install line. For example: apt-get install opencast-3-admin=3.2-2 Installs an Opencast 3.2 admin node, using the second build of that series. Not all series have more than a single build, and older point revisions may be removed once superceded, so please explore the repository prior to attempting this.","title":"Point Revisions (Experts only)"},{"location":"installation/debs/#install-3rd-party-tools","text":"This step is optional and only recommended for those who want to build Opencast from source. If you install Opencast from the repository, all necessary dependencies will be installed automatically. You can install all necessary 3rd-Party-Tools for Opencast like this: apt-get install ffmpeg-dist tesseract-ocr sox hunspell synfig netcat","title":"Install 3rd-party-tools"},{"location":"installation/debs/#upgrading-major-versions","text":"While these packages will automatically upgrade you to the latest point version in a release series, they do not automatically upgrade you to the latest major version. In other words, if you install opencast3-admin you get the latest 3.x release, not the latest 4.x release. To upgrade from one version to another you first stop Opencast: On a SysV-init based system service opencast stop On a Systemd based system systemctl stop opencast.service As a reminder, these instructions will change your Opencast installation, and files to a new version which is likely incompatible with older versions. If you are performing this on a production system, please ensure you have valid backups prior to taking the next steps. Uninstall your current Opencast packaging (using Opencast 3 as an example): apt-get remove opencast-3-* Then install the new version (using Opencast 4 as an example): apt-get install opencast-4-allinone At this point you must follow the relevant upgrade instructions, prior to starting Opencast again.","title":"Upgrading Major Versions"},{"location":"installation/debs/#uninstall-opencast","text":"To uninstall Opencast, you can run: apt-get remove 'opencast*' This will not touch your created media files or modified configuration files. If you want to remove them as well, you have to do that by yourself. # Remove media files sudo rm -rf /srv/opencast # Remove local db, search indexes and working files sudo rm -rf /var/lib/opencast # Remove configuration files sudo rm -rf /etc/opencast # Remove logs sudo rm -rf /var/log/opencast","title":"Uninstall Opencast"},{"location":"installation/debs/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"installation/debs/#missing-dependencies","text":"This repository expects that the stable section is always available, regardless of which version of Opencast you have installed. The 3rd party tools (ActiveMQ, FFmpeg) may or may not be in the other sections, but if they are there it is only during a testing period for a new version. For day-to-day use, please install them from stable !","title":"Missing Dependencies"},{"location":"installation/docker-local/","text":"Testing Locally with Docker Opencast is a complex system that requires multiple steps to install and configure properly, which may be too complicated for quick, local testing. Therefore, the University of M\u00fcnster provides various Docker images for Opencast that can simplify this process. The only requirement is an x86_64 Linux system with a running Docker Engine. This method is ideal for new adopters who just want to try out Opencast. It can also be used to test workflows. Because of the isolation that Docker provides, multiple instances of Opencast can run in parallel on a single system. This might be helpful for developers. Install Docker Docker is available for multiple Linux distributions. Please have a look at the official documentation for the latest installation instructions. Note that it might be necessary to install docker-compose separately. Start with docker-compose Opencast is packaged into multiple distributions. There is a separate Docker image for each distribution. Simple installations can use the all-in-one distribution. Opencast requires a database and a message broker (Apache ActiveMQ). We currently support H2 or MySQL/MariaDB databases. The Docker Hub repository has official Docker images for MySQL and MariaDB. H2 is already integrated into Opencast so that no database container is needed. There are multiple 3rd-party Docker images for ActiveMQ; this guide uses webcenter/activemq . docker-compose can be used to configure, start and connect all services automatically. The opencast-docker repository contains multiple configuration examples: Configuration Compose file all-in-one + H2 https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.h2.yml all-in-one + MariaDB https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.mariadb.yml admin, presentation, worker + MariaDB https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.multiserver.mariadb.yml Choose and download a configuration: $ curl -o docker-compose.yml <URL> You might want to edit the compose file and add extra volumes to include custom configurations or workflows (see compose file reference ). The compose files assume that the ActiveMQ configuration is located at ./assets/activemq.xml . Additionally, if you use MariaDB, the SQL DDL commands for the Opencast database must be available at ./assets/opencast-ddl.sql . You can download both files from the repository: $ mkdir assets $ curl -o assets/activemq.xml https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/assets/activemq.xml $ curl -o assets/opencast-ddl.sql https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/assets/opencast-ddl.sql Alternatively, you can use the Docker images to generate these files. This has the advantage that the correct version is always used: $ mkdir assets $ docker run -it --rm \\ quay.io/opencast/allinone:<version> \\ app:print:activemq.xml > assets/activemq.xml $ docker run -it --rm \\ -e ORG_OPENCASTPROJECT_DB_VENDOR=MySQL \\ quay.io/opencast/allinone:<version> \\ app:print:ddl > assets/opencast-ddl.sql At this point you are ready to start Opencast with the up command: $ docker-compose up After downloading the necessary Docker images, docker-compose should start all relevant services and you should see the logging output. Alternatively, adding the -d flag will start Opencast in the background and hide the log messages. The admin UI is available at http://localhost:8080 . The down command will stop Opencast and remove the created Docker containers. All relevant Opencast files are still preserved in Docker volumes. To remove them as well, run down -v instead.","title":"Testing Locally"},{"location":"installation/docker-local/#testing-locally-with-docker","text":"Opencast is a complex system that requires multiple steps to install and configure properly, which may be too complicated for quick, local testing. Therefore, the University of M\u00fcnster provides various Docker images for Opencast that can simplify this process. The only requirement is an x86_64 Linux system with a running Docker Engine. This method is ideal for new adopters who just want to try out Opencast. It can also be used to test workflows. Because of the isolation that Docker provides, multiple instances of Opencast can run in parallel on a single system. This might be helpful for developers.","title":"Testing Locally with Docker"},{"location":"installation/docker-local/#install-docker","text":"Docker is available for multiple Linux distributions. Please have a look at the official documentation for the latest installation instructions. Note that it might be necessary to install docker-compose separately.","title":"Install Docker"},{"location":"installation/docker-local/#start-with-docker-compose","text":"Opencast is packaged into multiple distributions. There is a separate Docker image for each distribution. Simple installations can use the all-in-one distribution. Opencast requires a database and a message broker (Apache ActiveMQ). We currently support H2 or MySQL/MariaDB databases. The Docker Hub repository has official Docker images for MySQL and MariaDB. H2 is already integrated into Opencast so that no database container is needed. There are multiple 3rd-party Docker images for ActiveMQ; this guide uses webcenter/activemq . docker-compose can be used to configure, start and connect all services automatically. The opencast-docker repository contains multiple configuration examples: Configuration Compose file all-in-one + H2 https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.h2.yml all-in-one + MariaDB https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.mariadb.yml admin, presentation, worker + MariaDB https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.multiserver.mariadb.yml Choose and download a configuration: $ curl -o docker-compose.yml <URL> You might want to edit the compose file and add extra volumes to include custom configurations or workflows (see compose file reference ). The compose files assume that the ActiveMQ configuration is located at ./assets/activemq.xml . Additionally, if you use MariaDB, the SQL DDL commands for the Opencast database must be available at ./assets/opencast-ddl.sql . You can download both files from the repository: $ mkdir assets $ curl -o assets/activemq.xml https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/assets/activemq.xml $ curl -o assets/opencast-ddl.sql https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/assets/opencast-ddl.sql Alternatively, you can use the Docker images to generate these files. This has the advantage that the correct version is always used: $ mkdir assets $ docker run -it --rm \\ quay.io/opencast/allinone:<version> \\ app:print:activemq.xml > assets/activemq.xml $ docker run -it --rm \\ -e ORG_OPENCASTPROJECT_DB_VENDOR=MySQL \\ quay.io/opencast/allinone:<version> \\ app:print:ddl > assets/opencast-ddl.sql At this point you are ready to start Opencast with the up command: $ docker-compose up After downloading the necessary Docker images, docker-compose should start all relevant services and you should see the logging output. Alternatively, adding the -d flag will start Opencast in the background and hide the log messages. The admin UI is available at http://localhost:8080 . The down command will stop Opencast and remove the created Docker containers. All relevant Opencast files are still preserved in Docker volumes. To remove them as well, run down -v instead.","title":"Start with docker-compose"},{"location":"installation/multiple-servers/","text":"Install Across Multiple Servers Note that this is not a comprehensive guide of all possible ways to install Opencast. It is more like a guide to good practices and presents what a lot of people are running. Step 1: Install Opencast Opencast consists of a large set of modules which together build the whole system. In a distributed set-up, different kinds of nodes are basically only defined by the existence or absence of specific modules. While it is possible to stick together a system module by module, opencast comes with a set of pre-defined distribution which can directly be built and installed. To build these distributions, you would compile Opencast just like it is outlined in the basic installation guides and will then find a set of different distributions, both as archive and in a separate directory. To list all distributions, run the following command after Opencast is built: % ls -1 build/*.tar.gz build/opencast-dist-admin-${version}.tar.gz build/opencast-dist-allinone-${version}.tar.gz build/opencast-dist-presentation-${version}.tar.gz build/opencast-dist-worker-${version}.tar.g ... The same distributions can be found in the packages provided in the Opencast RPM repository. These packages will automatically install all dependencies for a given node type. For example, to install an Opencast worker node, you would install the package opencast21-distribution-worker . The following list describes possible set-ups: All-In-One This is the default set-up described in the basic installation guides. It works fine for testing purposes. It should usually not be used in production. It is not distributed but is listed here to have a comprehensive list of predefined distributions. Two-Server Set-up This set-up is the minimum set-up recommended for productive use. It will separate the presentation layer from the administrative and working layer. This means that even if one server is under heavy load while videos are processed, it will not effect the distribution and users should still be able to watch videos smoothly. However, it might happen that under heavy load the handling of the administrative user interface gets a bit rough. Three (or more) Server Set-up While in the last example we have created one combined node for both the administrative tools and the workers, in this example we will split it into dedicated worker and admin nodes. Using this set-up it is easy to increase the systems performance simply by adding further worker nodes to the system. Step 2: Set-Up NFS Server Though it is possible to have Opencast run without shared storage, it is still a good idea to do so, as hard links can be used to link files instead of copying them and not everything has to be tunneled over HTTP. Thus you should first set-up your NFS server. The best solution is certainly to have a dedicated storage server. For smaller set-ups, however, it can also be put on one of the Opencast nodes, i.e. on the admin node. To do this, you first have to install and enable the NFS server: yum install nfs-utils nfs-utils-lib chkconfig --level 345 nfs on service nfs start You want to have one common user on all your systems, so that file permissions do not become an issue.. As preparation for this it makes sense to manually create an opencast user and group with a common UID and GID: groupadd -g 1234 opencast useradd -g 1234 -u 1234 opencast If the user and group id 1234 is already used, just pick another one but make sure to pick the same one on all your Opencast nodes. Then create the directory to be shared and set its ownership to the newly created users: mkdir -p /srv/opencast chown opencast:opencast /srv/opencast Next we actually share the storage dir. For this we need to edit the file /etc/exports and set: /srv/opencast 131.173.172.190(rw,sync,no_subtree_check) with 131.173.172.190 being the IP address of the other machine that should get access. Finally we enable the share with: exportfs -a Of cause you have to open the necessary ports in your firewall configuration. For iptables, appropriate rules could be for example: -A INPUT -m state --state NEW -p tcp -m multiport --dport 111,892,2049,32803 -j ACCEPT -A INPUT -m state --state NEW -p udp -m multiport --dport 111,892,2049,32803 -j ACCEPT You can set them by editing /etc/sysconfig/iptables and restarting the service afterwards. Now you have set-up your storage server. What is still left to do is to mount the network storage on all other servers of the Opencast clusters except the capture agents. To do that you need to edit the /etc/fstab on each server and add the command to mount the network storage on startup: storageserver.example.com:/srv/opencast /srv/opencast nfs rw,hard,intr,rsize=32768,wsize=32768 0 0 Important: Do not use multiple NFS shares for different parts of the Opencast storage dir. Opencast will check if hard links are possible across in a distributed set-up, but the detection may fail if hard links are only possible between certain parts of the storage. This may lead to failures. Important: Do not share the Karaf data directory. Doing so will cause Opencast to fail. Please share the storage directory only. Step 3: Set-Up the Database First make sure to follow the regular database set-up . Do not forget to set the user also for the remote servers and grant them the necessary rights. Additionally, you need to configure your firewall: -A INPUT -p tcp -s 131.173.172.190 --dport 3306 -m state --state NEW,ESTABLISHED -j ACCEPT Step 4: Set-Up ActiveMQ Since version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user interface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the admin node). ActiveMQ 5.10 or above should work. ActiveMQ 5.6 will not work. Versions in between are untested. Installation If you use the Opencast RPM repository, simply install the activemq-dist package. If you are running RHEL, CentOS or Fedora you can use the ActiveMQ-dist Copr RPM repository You can download binary distributions from the Apache ActiveMQ website Configuration What you basically need to do is to point all your Opencast nodes to your message broker. For more information about the configuration, have a look at the Message Broker Set-Up Guide . Do not forget that ActiveMQ uses TCP port 61616 (default configuration) for communication which you might have to allow in your firewall. Step 5: Configure Opencast You did already set-up and configured your database and message broker in the last steps, but there is some more configuration you have to do. First of all you should follow the Basic Configuration guide which will tell you how to set the login credentials etc. After that continue with the following steps: custom.properties Set the server URL to the public URL of each server (admin URL on admin, worker URL on worker, presentation URL on presentation, \u2026). This may either be this nodes IP address or preferable its domain name: org.opencastproject.server.url=http://<URL>:8080 Set the location of the shared storage directory: org.opencastproject.storage.dir=/srv/opencast Define that the file repository shall access all files locally: org.opencastproject.file.repo.url=${org.opencastproject.admin.ui.url} org.opencastproject.organization-mh_default_org.cfg Set the base URL of the server hosting the administrative tools. Again use a domain name instead of an IP address if possible: prop.org.opencastproject.admin.ui.url=http://<ADMIN-URL>:8080 Set the base URL of the server hosting the engage tools (usually the presentation node): prop.org.opencastproject.engage.ui.url=http://<ENGAGE-URL>:8080 Set the base URL of the file server. When using a shared filesystem between servers, set all servers to use the same URL (e.g. URL of the admin node). prop.org.opencastproject.file.repo.url=http://<ADMIN-URL>:8080 org.opencastproject.serviceregistry.impl.ServiceRegistryJpaImpl.cfg To ensure that jobs are not dispatched by non-admin nodes, on these you should also set: dispatchinterval=0","title":"Multiple Servers"},{"location":"installation/multiple-servers/#install-across-multiple-servers","text":"Note that this is not a comprehensive guide of all possible ways to install Opencast. It is more like a guide to good practices and presents what a lot of people are running.","title":"Install Across Multiple Servers"},{"location":"installation/multiple-servers/#step-1-install-opencast","text":"Opencast consists of a large set of modules which together build the whole system. In a distributed set-up, different kinds of nodes are basically only defined by the existence or absence of specific modules. While it is possible to stick together a system module by module, opencast comes with a set of pre-defined distribution which can directly be built and installed. To build these distributions, you would compile Opencast just like it is outlined in the basic installation guides and will then find a set of different distributions, both as archive and in a separate directory. To list all distributions, run the following command after Opencast is built: % ls -1 build/*.tar.gz build/opencast-dist-admin-${version}.tar.gz build/opencast-dist-allinone-${version}.tar.gz build/opencast-dist-presentation-${version}.tar.gz build/opencast-dist-worker-${version}.tar.g ... The same distributions can be found in the packages provided in the Opencast RPM repository. These packages will automatically install all dependencies for a given node type. For example, to install an Opencast worker node, you would install the package opencast21-distribution-worker . The following list describes possible set-ups:","title":"Step 1: Install Opencast"},{"location":"installation/multiple-servers/#all-in-one","text":"This is the default set-up described in the basic installation guides. It works fine for testing purposes. It should usually not be used in production. It is not distributed but is listed here to have a comprehensive list of predefined distributions.","title":"All-In-One"},{"location":"installation/multiple-servers/#two-server-set-up","text":"This set-up is the minimum set-up recommended for productive use. It will separate the presentation layer from the administrative and working layer. This means that even if one server is under heavy load while videos are processed, it will not effect the distribution and users should still be able to watch videos smoothly. However, it might happen that under heavy load the handling of the administrative user interface gets a bit rough.","title":"Two-Server Set-up"},{"location":"installation/multiple-servers/#three-or-more-server-set-up","text":"While in the last example we have created one combined node for both the administrative tools and the workers, in this example we will split it into dedicated worker and admin nodes. Using this set-up it is easy to increase the systems performance simply by adding further worker nodes to the system.","title":"Three (or more) Server Set-up"},{"location":"installation/multiple-servers/#step-2-set-up-nfs-server","text":"Though it is possible to have Opencast run without shared storage, it is still a good idea to do so, as hard links can be used to link files instead of copying them and not everything has to be tunneled over HTTP. Thus you should first set-up your NFS server. The best solution is certainly to have a dedicated storage server. For smaller set-ups, however, it can also be put on one of the Opencast nodes, i.e. on the admin node. To do this, you first have to install and enable the NFS server: yum install nfs-utils nfs-utils-lib chkconfig --level 345 nfs on service nfs start You want to have one common user on all your systems, so that file permissions do not become an issue.. As preparation for this it makes sense to manually create an opencast user and group with a common UID and GID: groupadd -g 1234 opencast useradd -g 1234 -u 1234 opencast If the user and group id 1234 is already used, just pick another one but make sure to pick the same one on all your Opencast nodes. Then create the directory to be shared and set its ownership to the newly created users: mkdir -p /srv/opencast chown opencast:opencast /srv/opencast Next we actually share the storage dir. For this we need to edit the file /etc/exports and set: /srv/opencast 131.173.172.190(rw,sync,no_subtree_check) with 131.173.172.190 being the IP address of the other machine that should get access. Finally we enable the share with: exportfs -a Of cause you have to open the necessary ports in your firewall configuration. For iptables, appropriate rules could be for example: -A INPUT -m state --state NEW -p tcp -m multiport --dport 111,892,2049,32803 -j ACCEPT -A INPUT -m state --state NEW -p udp -m multiport --dport 111,892,2049,32803 -j ACCEPT You can set them by editing /etc/sysconfig/iptables and restarting the service afterwards. Now you have set-up your storage server. What is still left to do is to mount the network storage on all other servers of the Opencast clusters except the capture agents. To do that you need to edit the /etc/fstab on each server and add the command to mount the network storage on startup: storageserver.example.com:/srv/opencast /srv/opencast nfs rw,hard,intr,rsize=32768,wsize=32768 0 0 Important: Do not use multiple NFS shares for different parts of the Opencast storage dir. Opencast will check if hard links are possible across in a distributed set-up, but the detection may fail if hard links are only possible between certain parts of the storage. This may lead to failures. Important: Do not share the Karaf data directory. Doing so will cause Opencast to fail. Please share the storage directory only.","title":"Step 2: Set-Up NFS Server"},{"location":"installation/multiple-servers/#step-3-set-up-the-database","text":"First make sure to follow the regular database set-up . Do not forget to set the user also for the remote servers and grant them the necessary rights. Additionally, you need to configure your firewall: -A INPUT -p tcp -s 131.173.172.190 --dport 3306 -m state --state NEW,ESTABLISHED -j ACCEPT","title":"Step 3: Set-Up the Database"},{"location":"installation/multiple-servers/#step-4-set-up-activemq","text":"Since version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user interface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the admin node). ActiveMQ 5.10 or above should work. ActiveMQ 5.6 will not work. Versions in between are untested.","title":"Step 4: Set-Up ActiveMQ"},{"location":"installation/multiple-servers/#installation","text":"If you use the Opencast RPM repository, simply install the activemq-dist package. If you are running RHEL, CentOS or Fedora you can use the ActiveMQ-dist Copr RPM repository You can download binary distributions from the Apache ActiveMQ website","title":"Installation"},{"location":"installation/multiple-servers/#configuration","text":"What you basically need to do is to point all your Opencast nodes to your message broker. For more information about the configuration, have a look at the Message Broker Set-Up Guide . Do not forget that ActiveMQ uses TCP port 61616 (default configuration) for communication which you might have to allow in your firewall.","title":"Configuration"},{"location":"installation/multiple-servers/#step-5-configure-opencast","text":"You did already set-up and configured your database and message broker in the last steps, but there is some more configuration you have to do. First of all you should follow the Basic Configuration guide which will tell you how to set the login credentials etc. After that continue with the following steps:","title":"Step 5: Configure Opencast"},{"location":"installation/multiple-servers/#customproperties","text":"Set the server URL to the public URL of each server (admin URL on admin, worker URL on worker, presentation URL on presentation, \u2026). This may either be this nodes IP address or preferable its domain name: org.opencastproject.server.url=http://<URL>:8080 Set the location of the shared storage directory: org.opencastproject.storage.dir=/srv/opencast Define that the file repository shall access all files locally: org.opencastproject.file.repo.url=${org.opencastproject.admin.ui.url}","title":"custom.properties"},{"location":"installation/multiple-servers/#orgopencastprojectorganization-mh_default_orgcfg","text":"Set the base URL of the server hosting the administrative tools. Again use a domain name instead of an IP address if possible: prop.org.opencastproject.admin.ui.url=http://<ADMIN-URL>:8080 Set the base URL of the server hosting the engage tools (usually the presentation node): prop.org.opencastproject.engage.ui.url=http://<ENGAGE-URL>:8080 Set the base URL of the file server. When using a shared filesystem between servers, set all servers to use the same URL (e.g. URL of the admin node). prop.org.opencastproject.file.repo.url=http://<ADMIN-URL>:8080","title":"org.opencastproject.organization-mh_default_org.cfg"},{"location":"installation/multiple-servers/#orgopencastprojectserviceregistryimplserviceregistryjpaimplcfg","text":"To ensure that jobs are not dispatched by non-admin nodes, on these you should also set: dispatchinterval=0","title":"org.opencastproject.serviceregistry.impl.ServiceRegistryJpaImpl.cfg"},{"location":"installation/rpm-el7/","text":"Install from Repository (Red Hat Enterprise Linux 7.x, CentOS 7.x, Scientific Linux 7.x) This guide is for EL7 only. There is a separate CentOS 8 and Red Hat Enterprise Linux 8 guide . This guide is based on a RPM software repository available for Red Hat-based Linux distributions provided by Osnabr\u00fcck University. This repository provides preconfigured Opencast installations and all necessary 3rd-Party-Tools. Using this method, you do not have to compile the software by yourself. Availability Note that it may take some time (usually about two weeks after a new release is out) before the RPMs are available. Watch for announcements on the users list or just check which versions are available in the repository. Currently Supported CentOS 7.x (x86_64) Red Hat Enterprise Linux 7.x (x86_64) Scientific Linux 7.x (x86_64) Other architectures like i386, i686, arm, \u2026 are not supported! Registration Before you can start you need to get an account for the repository. You will need the credentials that you got via e-mail after the registration to successfully complete this guide. Get your account on pkg.opencast.org . Activate Repository First you have to install the necessary repositories so that your package manager can access them: Add Opencast repository: cd /etc/yum.repos.d curl -O https://pkg.opencast.org/opencast.repo \\ -d os=el -d version=7 -u [YOUR_USERNAME] You will be asked for your password. It might take some time after the release of a new Opencast version before the RPMs are moved to the stable repository. Until then, you can use \u2026/opencast-testing.repo instead to get the latest version. Note that the testing repository is an additional repository and still requires the stable repository to be active. Add the Extra Packages for Enterprise Linux (EPEL) repository: yum install epel-release If this package is not available, please enable this repository manually. For that, follow the instructions in the EPEL documentation . You can check if the repository was sucessfully enabled using: yum repolist enabled Install Apache ActiveMQ The Apache ActiveMQ message broker is required by Opencast. It can be installed on the same machine as Opencast. ActiveMQ can be installed by running: yum install activemq-dist A prepared configuration file for ActiveMQ can be found at /usr/share/opencast/docs/scripts/activemq/activemq.xml after Opencast itself has been installed and should replace /etc/activemq/activemq.xml . For an all-in-one installation the following command should suffice: cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml ActiveMQ should be started prior to Opencast. More information about how to properly set up ActiveMQ for Opencast can be found in the message broker configuration documentation . Install Opencast Basic Installation For a basic installation (All-In-One) just run: yum install opencast<version>-allinone \u2026where <version> is the major version number of the Opencast release you want to install, e.g. opencast8-allinone . This will install the default distribution of Opencast and all its dependencies. Don't forget to start configure and start ActiveMQ first as described in the ActiveMQ installation section . Then start Opencast by running: systemctl start opencast.service While Opencast is preconfigured, it is strongly recommended to follow at least the Basic Configuration guide . It will help you to set your hostname, login information, \u2026 Advanced Installation The basic installation will give you an all-in-one Opencast distribution on a single server. For productions, most users prefer deploying Opencast over several machines, which allows for a better workload distribution. You can list all available Opencast packages with: yum search opencast This will list all available Opencast distributions in the form opencast<version>-<dist-type> . Some commonly used distributions are: opencast<version>-allinone opencast<version>-admin opencast<version>-presentation opencast<version>-worker Upgrading Major Versions Packages will automatically upgrade to the latest minor version in a release series. They do not automatically upgrade the latest major version. This is intentional since additional migration steps might be necessary for that. For example, if you install opencast7-admin you get the latest 7.x release, not the latest 8.x release. To upgrade from one major version to another, please consult the upgrade guide for each major version. Still, here is a short overview of the required steps: First, stop Opencast: systemctl stop opencast.service As a reminder, these instructions will upgrade your Opencast installation to a new version which is likely incompatible with older versions, and cannot be rolled back. If you are performing this on a production system, please ensure you have valid backups prior to taking the next steps. Uninstall your current Opencast package: yum remove opencast Then install the new version: yum install opencast<version>-<distribution> At this point you must follow the relevant upgrade instructions , prior to starting Opencast again. Uninstall Opencast To uninstall Opencast, you can run: yum remove opencast This will not touch your created media files or modified configuration files. If you want to remove them as well, you have to do that by yourself. # Remove media files (default location) sudo rm -rf /srv/opencast # Remove local db, search indexes and working files sudo rm -rf /var/lib/opencast # Remove configuration files sudo rm -rf /etc/opencast # Remove logs sudo rm -rf /var/log/opencast Troubleshooting Missing Dependencies If you try to install Opencast but yum is complaining about missing dependencies, please check if the epel repository is really activated on your system. Some distributions come with epel preinstalled but disabled. The installation of the epel-release package will not fix this. You can check what repositories are installed and enabled by executing yum repolist enabled which should give you a list with epel, opencast and opencast-noarch in it. To enable a repository, edit the configuration file in /etc/yum.repos.d/ .","title":"RHEL/CentOS 7"},{"location":"installation/rpm-el7/#install-from-repository-red-hat-enterprise-linux-7x-centos-7x-scientific-linux-7x","text":"This guide is for EL7 only. There is a separate CentOS 8 and Red Hat Enterprise Linux 8 guide . This guide is based on a RPM software repository available for Red Hat-based Linux distributions provided by Osnabr\u00fcck University. This repository provides preconfigured Opencast installations and all necessary 3rd-Party-Tools. Using this method, you do not have to compile the software by yourself.","title":"Install from Repository (Red Hat Enterprise Linux 7.x, CentOS 7.x, Scientific Linux 7.x)"},{"location":"installation/rpm-el7/#availability","text":"Note that it may take some time (usually about two weeks after a new release is out) before the RPMs are available. Watch for announcements on the users list or just check which versions are available in the repository.","title":"Availability"},{"location":"installation/rpm-el7/#currently-supported","text":"CentOS 7.x (x86_64) Red Hat Enterprise Linux 7.x (x86_64) Scientific Linux 7.x (x86_64) Other architectures like i386, i686, arm, \u2026 are not supported!","title":"Currently Supported"},{"location":"installation/rpm-el7/#registration","text":"Before you can start you need to get an account for the repository. You will need the credentials that you got via e-mail after the registration to successfully complete this guide. Get your account on pkg.opencast.org .","title":"Registration"},{"location":"installation/rpm-el7/#activate-repository","text":"First you have to install the necessary repositories so that your package manager can access them: Add Opencast repository: cd /etc/yum.repos.d curl -O https://pkg.opencast.org/opencast.repo \\ -d os=el -d version=7 -u [YOUR_USERNAME] You will be asked for your password. It might take some time after the release of a new Opencast version before the RPMs are moved to the stable repository. Until then, you can use \u2026/opencast-testing.repo instead to get the latest version. Note that the testing repository is an additional repository and still requires the stable repository to be active. Add the Extra Packages for Enterprise Linux (EPEL) repository: yum install epel-release If this package is not available, please enable this repository manually. For that, follow the instructions in the EPEL documentation . You can check if the repository was sucessfully enabled using: yum repolist enabled","title":"Activate Repository"},{"location":"installation/rpm-el7/#install-apache-activemq","text":"The Apache ActiveMQ message broker is required by Opencast. It can be installed on the same machine as Opencast. ActiveMQ can be installed by running: yum install activemq-dist A prepared configuration file for ActiveMQ can be found at /usr/share/opencast/docs/scripts/activemq/activemq.xml after Opencast itself has been installed and should replace /etc/activemq/activemq.xml . For an all-in-one installation the following command should suffice: cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml ActiveMQ should be started prior to Opencast. More information about how to properly set up ActiveMQ for Opencast can be found in the message broker configuration documentation .","title":"Install Apache ActiveMQ"},{"location":"installation/rpm-el7/#install-opencast","text":"","title":"Install Opencast"},{"location":"installation/rpm-el7/#basic-installation","text":"For a basic installation (All-In-One) just run: yum install opencast<version>-allinone \u2026where <version> is the major version number of the Opencast release you want to install, e.g. opencast8-allinone . This will install the default distribution of Opencast and all its dependencies. Don't forget to start configure and start ActiveMQ first as described in the ActiveMQ installation section . Then start Opencast by running: systemctl start opencast.service While Opencast is preconfigured, it is strongly recommended to follow at least the Basic Configuration guide . It will help you to set your hostname, login information, \u2026","title":"Basic Installation"},{"location":"installation/rpm-el7/#advanced-installation","text":"The basic installation will give you an all-in-one Opencast distribution on a single server. For productions, most users prefer deploying Opencast over several machines, which allows for a better workload distribution. You can list all available Opencast packages with: yum search opencast This will list all available Opencast distributions in the form opencast<version>-<dist-type> . Some commonly used distributions are: opencast<version>-allinone opencast<version>-admin opencast<version>-presentation opencast<version>-worker","title":"Advanced Installation"},{"location":"installation/rpm-el7/#upgrading-major-versions","text":"Packages will automatically upgrade to the latest minor version in a release series. They do not automatically upgrade the latest major version. This is intentional since additional migration steps might be necessary for that. For example, if you install opencast7-admin you get the latest 7.x release, not the latest 8.x release. To upgrade from one major version to another, please consult the upgrade guide for each major version. Still, here is a short overview of the required steps: First, stop Opencast: systemctl stop opencast.service As a reminder, these instructions will upgrade your Opencast installation to a new version which is likely incompatible with older versions, and cannot be rolled back. If you are performing this on a production system, please ensure you have valid backups prior to taking the next steps. Uninstall your current Opencast package: yum remove opencast Then install the new version: yum install opencast<version>-<distribution> At this point you must follow the relevant upgrade instructions , prior to starting Opencast again.","title":"Upgrading Major Versions"},{"location":"installation/rpm-el7/#uninstall-opencast","text":"To uninstall Opencast, you can run: yum remove opencast This will not touch your created media files or modified configuration files. If you want to remove them as well, you have to do that by yourself. # Remove media files (default location) sudo rm -rf /srv/opencast # Remove local db, search indexes and working files sudo rm -rf /var/lib/opencast # Remove configuration files sudo rm -rf /etc/opencast # Remove logs sudo rm -rf /var/log/opencast","title":"Uninstall Opencast"},{"location":"installation/rpm-el7/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"installation/rpm-el7/#missing-dependencies","text":"If you try to install Opencast but yum is complaining about missing dependencies, please check if the epel repository is really activated on your system. Some distributions come with epel preinstalled but disabled. The installation of the epel-release package will not fix this. You can check what repositories are installed and enabled by executing yum repolist enabled which should give you a list with epel, opencast and opencast-noarch in it. To enable a repository, edit the configuration file in /etc/yum.repos.d/ .","title":"Missing Dependencies"},{"location":"installation/rpm-el8/","text":"Install from Repository (Red Hat Enterprise Linux 8.x, CentOS 8.x) This guide is for EL8 only. There is a separate CentOS 7 and Red Hat Enterprise Linux 7 guide . This installation is still experimental . This guide is based on a RPM software repository available for Red Hat-based Linux distributions provided by Osnabr\u00fcck University. This repository provides preconfigured Opencast installations and all necessary 3rd-Party-Tools. Using this method, you do not have to compile the software by yourself. Availability Note that it may take some time (usually about two weeks after a new release is out) before the RPMs are available. Watch for announcements on the users list or just check which versions are available in the repository. Currently Supported CentOS 8.x (x86_64) Red Hat Enterprise Linux 8.x (x86_64) Other architectures like i386, i686, arm, \u2026 are not supported! Registration Before you can start you need to get an account for the repository. You will need the credentials that you got via e-mail after the registration to successfully complete this guide. Get your account on pkg.opencast.org . Activate Repository First you have to install the Opencast repository: cd /etc/yum.repos.d curl -O https://pkg.opencast.org/opencast-testing.repo \\ -d os=el -d version=8 -u [YOUR_USERNAME] You will be asked for your password. While this installation is experimental, only the testing repository is available for EL8. A stable repository will be made available once the installation has been proven to work properly in different environments. Install Apache ActiveMQ The Apache ActiveMQ message broker is required by Opencast. It can be installed on the same machine as Opencast. ActiveMQ can be installed by running: dnf install activemq-dist A prepared configuration file for ActiveMQ can be found at /usr/share/opencast/docs/scripts/activemq/activemq.xml after Opencast itself has been installed and should replace /etc/activemq/activemq.xml . For an all-in-one installation the following command should suffice: cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml ActiveMQ should be started prior to Opencast. More information about how to properly set up ActiveMQ for Opencast can be found in the message broker configuration documentation . Install Opencast Basic Installation For a basic installation (All-In-One) just run: dnf install opencast<version>-allinone \u2026where <version> is the major version number of the Opencast release you want to install, e.g. opencast8-allinone . This will install the default distribution of Opencast and all its dependencies. Don't forget to start configure and start ActiveMQ first as described in the ActiveMQ installation section . Then start Opencast by running: systemctl start opencast.service While Opencast is preconfigured, it is strongly recommended to follow at least the Basic Configuration guide . It will help you to set your hostname, login information, \u2026 Advanced Installation The basic installation will give you an all-in-one Opencast distribution on a single server. For productions, most users prefer deploying Opencast over several machines, which allows for a better workload distribution. You can list all available Opencast packages with: dnf search opencast This will list all available Opencast distributions in the form opencast<version>-<dist-type> . Some commonly used distributions are: opencast<version>-allinone opencast<version>-admin opencast<version>-presentation opencast<version>-worker Upgrading Major Versions Packages will automatically upgrade to the latest minor version in a release series. They do not automatically upgrade the latest major version. This is intentional since additional migration steps might be necessary for that. For example, if you install opencast7-admin you get the latest 7.x release, not the latest 8.x release. To upgrade from one major version to another, please consult the upgrade guide for each major version. Still, here is a short overview of the required steps: First, stop Opencast: systemctl stop opencast.service As a reminder, these instructions will upgrade your Opencast installation to a new version which is likely incompatible with older versions, and cannot be rolled back. If you are performing this on a production system, please ensure you have valid backups prior to taking the next steps. Uninstall your current Opencast package: dnf remove opencast Then install the new version: dnf install opencast<version>-<distribution> At this point you must follow the relevant upgrade instructions , prior to starting Opencast again. Uninstall Opencast To uninstall Opencast, you can run: dnf remove opencast This will not touch your created media files or modified configuration files. If you want to remove them as well, you have to do that by yourself. # Remove media files (default location) sudo rm -rf /srv/opencast # Remove local db, search indexes and working files sudo rm -rf /var/lib/opencast # Remove configuration files sudo rm -rf /etc/opencast # Remove logs sudo rm -rf /var/log/opencast","title":"RHEL/CentOS 8"},{"location":"installation/rpm-el8/#install-from-repository-red-hat-enterprise-linux-8x-centos-8x","text":"This guide is for EL8 only. There is a separate CentOS 7 and Red Hat Enterprise Linux 7 guide . This installation is still experimental . This guide is based on a RPM software repository available for Red Hat-based Linux distributions provided by Osnabr\u00fcck University. This repository provides preconfigured Opencast installations and all necessary 3rd-Party-Tools. Using this method, you do not have to compile the software by yourself.","title":"Install from Repository (Red Hat Enterprise Linux 8.x, CentOS 8.x)"},{"location":"installation/rpm-el8/#availability","text":"Note that it may take some time (usually about two weeks after a new release is out) before the RPMs are available. Watch for announcements on the users list or just check which versions are available in the repository.","title":"Availability"},{"location":"installation/rpm-el8/#currently-supported","text":"CentOS 8.x (x86_64) Red Hat Enterprise Linux 8.x (x86_64) Other architectures like i386, i686, arm, \u2026 are not supported!","title":"Currently Supported"},{"location":"installation/rpm-el8/#registration","text":"Before you can start you need to get an account for the repository. You will need the credentials that you got via e-mail after the registration to successfully complete this guide. Get your account on pkg.opencast.org .","title":"Registration"},{"location":"installation/rpm-el8/#activate-repository","text":"First you have to install the Opencast repository: cd /etc/yum.repos.d curl -O https://pkg.opencast.org/opencast-testing.repo \\ -d os=el -d version=8 -u [YOUR_USERNAME] You will be asked for your password. While this installation is experimental, only the testing repository is available for EL8. A stable repository will be made available once the installation has been proven to work properly in different environments.","title":"Activate Repository"},{"location":"installation/rpm-el8/#install-apache-activemq","text":"The Apache ActiveMQ message broker is required by Opencast. It can be installed on the same machine as Opencast. ActiveMQ can be installed by running: dnf install activemq-dist A prepared configuration file for ActiveMQ can be found at /usr/share/opencast/docs/scripts/activemq/activemq.xml after Opencast itself has been installed and should replace /etc/activemq/activemq.xml . For an all-in-one installation the following command should suffice: cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml ActiveMQ should be started prior to Opencast. More information about how to properly set up ActiveMQ for Opencast can be found in the message broker configuration documentation .","title":"Install Apache ActiveMQ"},{"location":"installation/rpm-el8/#install-opencast","text":"","title":"Install Opencast"},{"location":"installation/rpm-el8/#basic-installation","text":"For a basic installation (All-In-One) just run: dnf install opencast<version>-allinone \u2026where <version> is the major version number of the Opencast release you want to install, e.g. opencast8-allinone . This will install the default distribution of Opencast and all its dependencies. Don't forget to start configure and start ActiveMQ first as described in the ActiveMQ installation section . Then start Opencast by running: systemctl start opencast.service While Opencast is preconfigured, it is strongly recommended to follow at least the Basic Configuration guide . It will help you to set your hostname, login information, \u2026","title":"Basic Installation"},{"location":"installation/rpm-el8/#advanced-installation","text":"The basic installation will give you an all-in-one Opencast distribution on a single server. For productions, most users prefer deploying Opencast over several machines, which allows for a better workload distribution. You can list all available Opencast packages with: dnf search opencast This will list all available Opencast distributions in the form opencast<version>-<dist-type> . Some commonly used distributions are: opencast<version>-allinone opencast<version>-admin opencast<version>-presentation opencast<version>-worker","title":"Advanced Installation"},{"location":"installation/rpm-el8/#upgrading-major-versions","text":"Packages will automatically upgrade to the latest minor version in a release series. They do not automatically upgrade the latest major version. This is intentional since additional migration steps might be necessary for that. For example, if you install opencast7-admin you get the latest 7.x release, not the latest 8.x release. To upgrade from one major version to another, please consult the upgrade guide for each major version. Still, here is a short overview of the required steps: First, stop Opencast: systemctl stop opencast.service As a reminder, these instructions will upgrade your Opencast installation to a new version which is likely incompatible with older versions, and cannot be rolled back. If you are performing this on a production system, please ensure you have valid backups prior to taking the next steps. Uninstall your current Opencast package: dnf remove opencast Then install the new version: dnf install opencast<version>-<distribution> At this point you must follow the relevant upgrade instructions , prior to starting Opencast again.","title":"Upgrading Major Versions"},{"location":"installation/rpm-el8/#uninstall-opencast","text":"To uninstall Opencast, you can run: dnf remove opencast This will not touch your created media files or modified configuration files. If you want to remove them as well, you have to do that by yourself. # Remove media files (default location) sudo rm -rf /srv/opencast # Remove local db, search indexes and working files sudo rm -rf /var/lib/opencast # Remove configuration files sudo rm -rf /etc/opencast # Remove logs sudo rm -rf /var/log/opencast","title":"Uninstall Opencast"},{"location":"installation/rpm-fedora/","text":"Install from Repository (Fedora) The Opencast RPM repository for Fedora has been discontinued since Fedora with RPMfusion now provides nearly all necessary dependencies for Opencast. Use the following steps to install them, then continue with the installation from source . This guide is to be merged into the guide for the installation from source. Add RPMfusion repository RPMFusion is a community-driven RPM repository for Fedora. It provides tools like FFmpeg. You can activate it using: dnf install --nogpgcheck \\ http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm \\ http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm Install 3rd-party-tools You can install all necessary 3rd-Party-Tools for Opencast like this: dnf install maven ffmpeg tesseract hunspell sox synfig nmap-ncat For additional Unicode tests run during the build process, you can also install: dnf install hunspell-de tesseract-langpack-deu Install Apache ActiveMQ The Apache ActiveMQ message broker is commonly installed on the same machine as Opencast for an all-in-one system. The version of ActiveMQ shipped with Fedora is too old but you can use the ActiveMQ-dist Copr RPM repository Make sure it is properly configured for Opencast. For more information about the setup, have a look at the message broker configuration documentation . Install Opencast For the installation of Opencast, please have a look at the installation from source documentation .","title":"Fedora"},{"location":"installation/rpm-fedora/#install-from-repository-fedora","text":"The Opencast RPM repository for Fedora has been discontinued since Fedora with RPMfusion now provides nearly all necessary dependencies for Opencast. Use the following steps to install them, then continue with the installation from source . This guide is to be merged into the guide for the installation from source.","title":"Install from Repository (Fedora)"},{"location":"installation/rpm-fedora/#add-rpmfusion-repository","text":"RPMFusion is a community-driven RPM repository for Fedora. It provides tools like FFmpeg. You can activate it using: dnf install --nogpgcheck \\ http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm \\ http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm","title":"Add RPMfusion repository"},{"location":"installation/rpm-fedora/#install-3rd-party-tools","text":"You can install all necessary 3rd-Party-Tools for Opencast like this: dnf install maven ffmpeg tesseract hunspell sox synfig nmap-ncat For additional Unicode tests run during the build process, you can also install: dnf install hunspell-de tesseract-langpack-deu","title":"Install 3rd-party-tools"},{"location":"installation/rpm-fedora/#install-apache-activemq","text":"The Apache ActiveMQ message broker is commonly installed on the same machine as Opencast for an all-in-one system. The version of ActiveMQ shipped with Fedora is too old but you can use the ActiveMQ-dist Copr RPM repository Make sure it is properly configured for Opencast. For more information about the setup, have a look at the message broker configuration documentation .","title":"Install Apache ActiveMQ"},{"location":"installation/rpm-fedora/#install-opencast","text":"For the installation of Opencast, please have a look at the installation from source documentation .","title":"Install Opencast"},{"location":"installation/source-linux/","text":"Install from Source (Linux) These instructions outline how to install an all in one Opencast system on Linux. Preparation Create a dedicated Opencast system user: useradd -r -d /opt/opencast opencast Get Opencast source: You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git repository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The prior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git. Using the tarball: Select the tarball for the version you want to install from the GitHub releases section . # Download desired tarball curl -OL https://github.com/opencast/opencast/archive/[...].tar.gz tar xf [...].tar.gz cd opencast--[...] Cloning the Git repository: git clone https://github.com/opencast/opencast.git cd opencast git tag <- List all available versions git checkout TAG <- Switch to desired version Install Dependencies Please make sure to install the following dependencies. Required: java-1.8.0-openjdk-devel.x86_64 / openjdk-8-jdk ffmpeg >= 3.2.4 maven >= 3.1 python >= 2.6, < 3.0 unzip gcc-c++ tar bzip2 nc Required (not necessarily on the same machine): ActiveMQ >= 5.10 (older versions untested) Required for text extraction (recommended): tesseract >= 3 Required for hunspell based text filtering (optional): hunspell >= 1.2.8 Required for audio normalization (optional): sox >= 14.4 Required for animate service (optional): synfig Dependency Download Pre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project website: Get FFmpeg Get Apache Maven Get Apache ActiveMQ Building Opencast Automatically build all Opencast modules and assemble distributions for different server types: cd opencast-dir mvn clean install Deploy all-in-one distribution: cd build/ mv opencast-dist-allinone-*/ /opt/opencast Make sure everything belongs to the user opencast : sudo chown -R opencast:opencast /opt/opencast Configure Please follow the steps of the Basic Configuration guide . It will help you to set your hostname, login information, \u2026 Running Opencast To start Opencast, run .../bin/start-opencast as user opencast : sudo -u opencast /opt/opencast/bin/start-opencast As soon as Opencast is completely started, browse to http://localhost:8080 to get to the administration interface. Run Opencast as a service Usually, you do not want to run Opencast in interactive mode but as system service to make sure it is only running once on a system and is started automatically. You will find service files for Opencast in docs/scripts/service/{opt,system}/ . Using Systemd Make sure the path to Opencast is set correctly: vim docs/scripts/service/opencast.service Install the unit file: cp docs/scripts/service/opencast.service /etc/systemd/system/ systemctl daemon-reload Start Opencast and make it run automatically: systemctl start opencast.service systemctl enable opencast.service Using SysV-Init Note that this option is for compatibility to older systems. If you have the choice of either using the Systemd unit file or the Init script, it is recommended to use the Systemd unit file. Make sure the path to Opencast is set correctly: vim docs/scripts/service/etc-init.d-opencast Install init script: cp docs/scripts/service/etc-init.d-opencast /etc/init.d/opencast Enable service using chkconfig or update-rc.d Start Opencast using service opencast start","title":"Linux"},{"location":"installation/source-linux/#install-from-source-linux","text":"These instructions outline how to install an all in one Opencast system on Linux.","title":"Install from Source (Linux)"},{"location":"installation/source-linux/#preparation","text":"Create a dedicated Opencast system user: useradd -r -d /opt/opencast opencast Get Opencast source: You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git repository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The prior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git. Using the tarball: Select the tarball for the version you want to install from the GitHub releases section . # Download desired tarball curl -OL https://github.com/opencast/opencast/archive/[...].tar.gz tar xf [...].tar.gz cd opencast--[...] Cloning the Git repository: git clone https://github.com/opencast/opencast.git cd opencast git tag <- List all available versions git checkout TAG <- Switch to desired version","title":"Preparation"},{"location":"installation/source-linux/#install-dependencies","text":"Please make sure to install the following dependencies. Required: java-1.8.0-openjdk-devel.x86_64 / openjdk-8-jdk ffmpeg >= 3.2.4 maven >= 3.1 python >= 2.6, < 3.0 unzip gcc-c++ tar bzip2 nc Required (not necessarily on the same machine): ActiveMQ >= 5.10 (older versions untested) Required for text extraction (recommended): tesseract >= 3 Required for hunspell based text filtering (optional): hunspell >= 1.2.8 Required for audio normalization (optional): sox >= 14.4 Required for animate service (optional): synfig","title":"Install Dependencies"},{"location":"installation/source-linux/#dependency-download","text":"Pre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project website: Get FFmpeg Get Apache Maven Get Apache ActiveMQ","title":"Dependency Download"},{"location":"installation/source-linux/#building-opencast","text":"Automatically build all Opencast modules and assemble distributions for different server types: cd opencast-dir mvn clean install Deploy all-in-one distribution: cd build/ mv opencast-dist-allinone-*/ /opt/opencast Make sure everything belongs to the user opencast : sudo chown -R opencast:opencast /opt/opencast","title":"Building Opencast"},{"location":"installation/source-linux/#configure","text":"Please follow the steps of the Basic Configuration guide . It will help you to set your hostname, login information, \u2026","title":"Configure"},{"location":"installation/source-linux/#running-opencast","text":"To start Opencast, run .../bin/start-opencast as user opencast : sudo -u opencast /opt/opencast/bin/start-opencast As soon as Opencast is completely started, browse to http://localhost:8080 to get to the administration interface.","title":"Running Opencast"},{"location":"installation/source-linux/#run-opencast-as-a-service","text":"Usually, you do not want to run Opencast in interactive mode but as system service to make sure it is only running once on a system and is started automatically. You will find service files for Opencast in docs/scripts/service/{opt,system}/ .","title":"Run Opencast as a service"},{"location":"installation/source-linux/#using-systemd","text":"Make sure the path to Opencast is set correctly: vim docs/scripts/service/opencast.service Install the unit file: cp docs/scripts/service/opencast.service /etc/systemd/system/ systemctl daemon-reload Start Opencast and make it run automatically: systemctl start opencast.service systemctl enable opencast.service","title":"Using Systemd"},{"location":"installation/source-linux/#using-sysv-init","text":"Note that this option is for compatibility to older systems. If you have the choice of either using the Systemd unit file or the Init script, it is recommended to use the Systemd unit file. Make sure the path to Opencast is set correctly: vim docs/scripts/service/etc-init.d-opencast Install init script: cp docs/scripts/service/etc-init.d-opencast /etc/init.d/opencast Enable service using chkconfig or update-rc.d Start Opencast using service opencast start","title":"Using SysV-Init"},{"location":"installation/source-macosx/","text":"Install from Source (Mac OS X) These instructions outline how to install an all in one Opencast system on the Mac OS X operating system. Tested on OS X 10.14.1 Mojave. The installation on Mac OS X is not officially supported. Use this at your own risk. Preparation Open a Terminal and switch to the directory, in which the Opencast installation should be placed, e.g. /opt/ , ~/develop/ or whatever you prefer. Get Opencast source You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git repository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The prior option, the tarball download, needs less tools and you don't have to download nearly as much as with Git. Cloning the Git repository: git clone https://github.com/opencast/opencast.git cd opencast git tag <- List all available versions git checkout TAG <- Switch to desired version Using the tarball: Select the tarball for the version you want to install from the GitHub releases section under the \"Tags\" tab and download it directly from there or with the curl command specified below. # Download desired tarball, replace [...] with the desired version curl -OL https://github.com/opencast/opencast/archive/[...].tar.gz tar xf [...].tar.gz Install Dependencies Please make sure to install the following dependencies. Required: Xcode jdk 8 ffmpeg >= 3.2.4 maven >= 3.1 python >= 2.6, < 3.0 (If you are using jEnv to set up your environment, make sure to enable the maven plugin .) Required (not necessarily on the same machine): ActiveMQ >= 5.10 (older versions untested) Required for text extraction: tesseract >= 3 Required for hunspell based text filtering: hunspell >= 1.2.8 Required for audio normalization: sox >= 14.4 (with MP3, FLAC and OGG support) Required for animate service: synfig Dependency Download You can download Xcode in the Mac App Store. JDK 8 for OS X is available from Oracle . Using Homebrew Homebrew is a package manager for OS X. For installation instruction see their website . brew install maven brew install ffmpeg brew install apache-activemq brew install tesseract brew install hunspell brew install sox brew install synfig Using pre-built binaries Pre-built versions of most dependencies can be downloaded from the respective project website: Get Apache Maven Get FFmpeg Get Apache ActiveMQ Building Opencast Switch to the opencast folder. If you downloaded the tarball, this is the folder you just unpacked (called something like opencast-community-opencast-[\u2026] ). If you chose to download via git, use cd opencast . You can proceed by building opencast (depending on the folder permissions, you might need to start the command with sudo ): mvn clean install -Pdev Please be patient, as building Opencast for the first time will take quite long. Configure Please follow the steps of the Basic Configuration guide . It will help you to set your host name, login information, etc. Be aware that the config files now reside in the build folders for the desired distribution. For the allinone distribution, this would be /your/path/to/opencast/build/opencast-dist-allinone-[\u2026]/etc/ , again with [\u2026] representing the selected version. As specified in the guide, make sure you replace the default ActiveMQ configuration with the one provided in docs/scripts/activemq/activemq.xml . If you installed ActiveMQ using homebrew, you can find the installation path with brew info activemq . The configuration is probably located in /usr/local/Cellar/activemq/<version>/libexec/conf/ . ffprobe is used to analyse new videos. It is installed with ffmpeg but usually not on the path to be automatically executed. You have to link the ffprobe to /usr/local/bin/ . You can find the ffmpeg install directory with brew info ffmpeg . Usually you would link the file with ln -s /usr/local/Cellar/ffmpeg/<version>/bin/ffprobe /usr/local/bin/ffprobe . Running Opencast Make sure you have ActiveMQ running (unless you're running it on a different machine). Then you can start Opencast using the start-opencast script: activemq start cd /your/path/to/opencast/ cd build/opencast-dist-allinone-[\u2026] ./bin/start-opencast As soon as Opencast is completely started, browse to http://localhost:8080 to get to the administration interface.","title":"MacOS X"},{"location":"installation/source-macosx/#install-from-source-mac-os-x","text":"These instructions outline how to install an all in one Opencast system on the Mac OS X operating system. Tested on OS X 10.14.1 Mojave. The installation on Mac OS X is not officially supported. Use this at your own risk.","title":"Install from Source (Mac OS X)"},{"location":"installation/source-macosx/#preparation","text":"Open a Terminal and switch to the directory, in which the Opencast installation should be placed, e.g. /opt/ , ~/develop/ or whatever you prefer.","title":"Preparation"},{"location":"installation/source-macosx/#get-opencast-source","text":"You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git repository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The prior option, the tarball download, needs less tools and you don't have to download nearly as much as with Git. Cloning the Git repository: git clone https://github.com/opencast/opencast.git cd opencast git tag <- List all available versions git checkout TAG <- Switch to desired version Using the tarball: Select the tarball for the version you want to install from the GitHub releases section under the \"Tags\" tab and download it directly from there or with the curl command specified below. # Download desired tarball, replace [...] with the desired version curl -OL https://github.com/opencast/opencast/archive/[...].tar.gz tar xf [...].tar.gz","title":"Get Opencast source"},{"location":"installation/source-macosx/#install-dependencies","text":"Please make sure to install the following dependencies. Required: Xcode jdk 8 ffmpeg >= 3.2.4 maven >= 3.1 python >= 2.6, < 3.0 (If you are using jEnv to set up your environment, make sure to enable the maven plugin .) Required (not necessarily on the same machine): ActiveMQ >= 5.10 (older versions untested) Required for text extraction: tesseract >= 3 Required for hunspell based text filtering: hunspell >= 1.2.8 Required for audio normalization: sox >= 14.4 (with MP3, FLAC and OGG support) Required for animate service: synfig","title":"Install Dependencies"},{"location":"installation/source-macosx/#dependency-download","text":"You can download Xcode in the Mac App Store. JDK 8 for OS X is available from Oracle .","title":"Dependency Download"},{"location":"installation/source-macosx/#using-homebrew","text":"Homebrew is a package manager for OS X. For installation instruction see their website . brew install maven brew install ffmpeg brew install apache-activemq brew install tesseract brew install hunspell brew install sox brew install synfig","title":"Using Homebrew"},{"location":"installation/source-macosx/#using-pre-built-binaries","text":"Pre-built versions of most dependencies can be downloaded from the respective project website: Get Apache Maven Get FFmpeg Get Apache ActiveMQ","title":"Using pre-built binaries"},{"location":"installation/source-macosx/#building-opencast","text":"Switch to the opencast folder. If you downloaded the tarball, this is the folder you just unpacked (called something like opencast-community-opencast-[\u2026] ). If you chose to download via git, use cd opencast . You can proceed by building opencast (depending on the folder permissions, you might need to start the command with sudo ): mvn clean install -Pdev Please be patient, as building Opencast for the first time will take quite long.","title":"Building Opencast"},{"location":"installation/source-macosx/#configure","text":"Please follow the steps of the Basic Configuration guide . It will help you to set your host name, login information, etc. Be aware that the config files now reside in the build folders for the desired distribution. For the allinone distribution, this would be /your/path/to/opencast/build/opencast-dist-allinone-[\u2026]/etc/ , again with [\u2026] representing the selected version. As specified in the guide, make sure you replace the default ActiveMQ configuration with the one provided in docs/scripts/activemq/activemq.xml . If you installed ActiveMQ using homebrew, you can find the installation path with brew info activemq . The configuration is probably located in /usr/local/Cellar/activemq/<version>/libexec/conf/ . ffprobe is used to analyse new videos. It is installed with ffmpeg but usually not on the path to be automatically executed. You have to link the ffprobe to /usr/local/bin/ . You can find the ffmpeg install directory with brew info ffmpeg . Usually you would link the file with ln -s /usr/local/Cellar/ffmpeg/<version>/bin/ffprobe /usr/local/bin/ffprobe .","title":"Configure"},{"location":"installation/source-macosx/#running-opencast","text":"Make sure you have ActiveMQ running (unless you're running it on a different machine). Then you can start Opencast using the start-opencast script: activemq start cd /your/path/to/opencast/ cd build/opencast-dist-allinone-[\u2026] ./bin/start-opencast As soon as Opencast is completely started, browse to http://localhost:8080 to get to the administration interface.","title":"Running Opencast"},{"location":"modules/","text":"Module Documentation Documentation for modules included in Opencast. Atom and RSS Feed Amazon Services Amazon S3 Archive Storage Amazon S3 Distribution Execute Service Live Schedule LTI Module Media Module Player Configuration URL Parameter Search Indexes Solr Elasticsearch Stream Security Text Extraction Videoeditor Setup Architecture Video Segmentation Termination State Basic AWS AutoScaling Transcripts (Google Speech) Transcripts (IBM Watson) YouTube Publication","title":"Overview"},{"location":"modules/#module-documentation","text":"Documentation for modules included in Opencast. Atom and RSS Feed Amazon Services Amazon S3 Archive Storage Amazon S3 Distribution Execute Service Live Schedule LTI Module Media Module Player Configuration URL Parameter Search Indexes Solr Elasticsearch Stream Security Text Extraction Videoeditor Setup Architecture Video Segmentation Termination State Basic AWS AutoScaling Transcripts (Google Speech) Transcripts (IBM Watson) YouTube Publication","title":"Module Documentation"},{"location":"modules/adaptivestreaming-wowza/","text":"Wowza Adaptive Streaming Distribution Service The distribution-service-streaming-wowza module copies the media files to the Wowza application directory and generates a SMIL file containing the paths to those files, grouping those with the same flavor but different qualities. Then, for each configured streaming protocol, it generates the adequate entries in the MediaPackage and sets the necessary URLs and MIME-Types automatically. The protocols supported and the transport format they use are summarized below: RTMP(S)-based protocols (also supported by the default distribution-service-streaming module) RTMP(S): Adobe Flash Streaming protocol. Requires the Adobe Flash Player to be installed in the client's browser. HTTP(S)-based protocols, corresponding to the modern (Adaptive) Streaming Formats HLS: (Live) Streaming from Apple HDS: Dynamic Streaming from Adobe DASH: MPEG-DASH Dynamic Adaptive Streaming SMOOTH: Microsoft's Smooth Streaming Please note : Only the protocols RTMP, HLS and DASH (with and without SSL) have been thoroughly tested. Requirements A Wowza Streaming Engine version >= 4.0 is required. Please pay special attention to the instructions re. crossdomain access. Directory Structure The structure how this module stores the SMIL and media files is important to understand how the Wowza server must be configured to properly work with Opencast. This structure always follows the same pattern: ${org.opencastproject.streaming.directory}/<organization-id>/<channel-id>/<mediapackage-id>/<element-id>/<filename> , where: ${org.opencastproject.streaming.directory} is this module's root directory, as configured in Opencast's configuration (see below) <organization-id> is the identifier for the current organization (by default mh-default-org ) <channel-id> is the channel identifier. Normally, the Workflow Operation determines the value of this parameter; for instance, the operation publish-engage calls the Streaming Service with a hardcoded value for this property of engage-player <mediapackage-id> , <element-id> and <filename> are different for each MediaPackageElement that this module distributes. The organization ID is automatically assigned based on the server's DNS name ( more info ). Each organization (or tenant ) is independent from the others defined in the system. For the media distribution, that means that each organization's media content is stored in separate directories, so the streaming applications should also be different, as we will see below. Configuration Edit the file etc/org.opencastproject.distribution.streaming.wowza.WowzaAdaptiveStreamingDistributionService.cfg with your preferred configuration. The contents should be self-explanatory. Edit $KARAF/etc/custom.properties and adjust these values to match those of your scenario: org.opencastproject.streaming.url=rtmp(s)://<wowza-server>/<wowza-application> org.opencastproject.streaming.port=<port_number> org.opencastproject.adaptive-streaming.url=http(s)://<wowza-server>/<wowza-application> org.opencastproject.adaptive-streaming.port=<port_number> org.opencastproject.streaming.directory=/mnt/opencast-drive/content/streams The port numbers are only necessary when non-standard ports are used for streaming and/or adaptive-streaming. In most cases, it is safe to comment them out or simply not include those properties in the file. Restart your Opencast server. Installation on the Wowza side Pre-requirements Download/Purchase the Wowza Streaming Engine from the Wowza Homepage and install it according to their manuals. The shared drive indicated in the org.opencastproject.streaming.directory in the custom.properties file in Opencast must also be mounted in the Wowza server. Please note that mount points do not necessarily match! (e.g. the path /mnt/opencast-drive-content-streams in the Opencast server might be mounted as /media/opencast-streams in the Wowza server). Do not forget to open your firewall on ports 1935 (RTMP), 80 (HTTP, adaptive streaming) and, if you want to use SSL, 443. You will have set your login credentials during the setup of Wowza. You will need these for the web UI. Open http://<wowza-server>:8088/enginemanager and log in Select \"Application -> Add Application\" in the top menu Select \"VOD Single Server\" Enter a name for the new application. You must use the same application name you have configured in $KARAF/etc/custom.properties (for instance: opencast-engage ) Application Description : Feel free to add a description. Playback Types : Enable your desired streaming protocols Options : Disable the global CORS Content Directory : Mark the checkbox Use the following directory . The directory you should input is a subdirectory of the path indicated in the property org.opencastproject.streaming.directory defined in the file $KARAF/etc/custom.properties . That subdirectory's name is the organization's ID ( mh_default_org by default). For instance, if the org.opencastproject.streaming.directory is mounted in the Wowza Server as: /mnt/opencast-streams then the Content Directory for the default organization would be: /mnt/opencast-streams/mh_default_org In a multitenant Opencast setup, an organization with ID my_organization should have the Content Directory set to: /mnt/opencast-streams/my_organization Optional Settings Opencast HTML5 Player is able to play videos from Wowza using adaptive streaming protocols. However, some browsers may experiment problems due to crossdomain issues, which means that we need to instruct Wowza to include the right Allow-Origin headers in its HTTP requests. On the other hand, you may experiment problems with the MPEG-DASH protocol, depending on the encoding of the video sources. All this can be configured in the \"Options\" section of the Wowza application: Click on the tab \"Properties\" in your application If you can't see the \"Properties\" tab, go to \"Users\" > \"Edit\" > \"Preferences\" and select \"Allow access to advanced properties and features\" Scroll down the page to \"Custom\" Click the \"Edit\" button Add the following Properties Path Name Type Value /Root/Application/HTTPStreamer cupertinoUserHTTPHeaders String ** /Root/Application/HTTPStreamer mpegdashUserHTTPHeaders String ** /Root/Application/HTTPStreamer mpegdashAdjustCTTSForFirstKeyFrameToZero Boolean true Due to some limitations in Bitbucket's Markdown parser, we can write this value within a table because it contains a \"pipe\" symbol (\"|\"). The correct value for this property is: Access-Control-Allow-Origin: *|Access-Control-Allow-Methods:GET, HEAD, OPTIONS Do not forget to restart the application! Players and Formats Theodul : RTMP, HLS, DASH (over HTTP and HTTPS) Paella : RTMP, RTMPS, HLS, DASH (over HTTP and HTTPS) Encoding Profiles Keep in mind that you have to adapt your encoding profiles when you want generate the videos to distribute via HLS or DASH. Specifically, if the videos with different qualities are not keyframe-aligned, they may not play smoothly or not play at all. You can find more information here . Limitations This module is able to correctly distribute new elements incrementally. That means that if some elements in a mediapackage are already distributed when another Distribute operation runs, the operation should run without errors. However, partial Retract operations are discouraged and cause the remaining elements to be no longer playable. The recommended procedure to retract only some elements in a mediapackage is therefore: Completely retract the mediapackage Distribute again only the desired elements The effects of this limitation are small, because the retract-engage workflow operation always retracts the whole Mediapackage and because partial retractions seem to have little to no practical application. These can however be performed by calling the corresponding REST endpoints. In such cases, users are encouraged to use the recommended method above.","title":"Wowza Adaptive Streaming Distribution Service"},{"location":"modules/adaptivestreaming-wowza/#wowza-adaptive-streaming-distribution-service","text":"The distribution-service-streaming-wowza module copies the media files to the Wowza application directory and generates a SMIL file containing the paths to those files, grouping those with the same flavor but different qualities. Then, for each configured streaming protocol, it generates the adequate entries in the MediaPackage and sets the necessary URLs and MIME-Types automatically. The protocols supported and the transport format they use are summarized below: RTMP(S)-based protocols (also supported by the default distribution-service-streaming module) RTMP(S): Adobe Flash Streaming protocol. Requires the Adobe Flash Player to be installed in the client's browser. HTTP(S)-based protocols, corresponding to the modern (Adaptive) Streaming Formats HLS: (Live) Streaming from Apple HDS: Dynamic Streaming from Adobe DASH: MPEG-DASH Dynamic Adaptive Streaming SMOOTH: Microsoft's Smooth Streaming Please note : Only the protocols RTMP, HLS and DASH (with and without SSL) have been thoroughly tested.","title":"Wowza Adaptive Streaming Distribution Service"},{"location":"modules/adaptivestreaming-wowza/#requirements","text":"A Wowza Streaming Engine version >= 4.0 is required. Please pay special attention to the instructions re. crossdomain access.","title":"Requirements"},{"location":"modules/adaptivestreaming-wowza/#directory-structure","text":"The structure how this module stores the SMIL and media files is important to understand how the Wowza server must be configured to properly work with Opencast. This structure always follows the same pattern: ${org.opencastproject.streaming.directory}/<organization-id>/<channel-id>/<mediapackage-id>/<element-id>/<filename> , where: ${org.opencastproject.streaming.directory} is this module's root directory, as configured in Opencast's configuration (see below) <organization-id> is the identifier for the current organization (by default mh-default-org ) <channel-id> is the channel identifier. Normally, the Workflow Operation determines the value of this parameter; for instance, the operation publish-engage calls the Streaming Service with a hardcoded value for this property of engage-player <mediapackage-id> , <element-id> and <filename> are different for each MediaPackageElement that this module distributes. The organization ID is automatically assigned based on the server's DNS name ( more info ). Each organization (or tenant ) is independent from the others defined in the system. For the media distribution, that means that each organization's media content is stored in separate directories, so the streaming applications should also be different, as we will see below.","title":"Directory Structure"},{"location":"modules/adaptivestreaming-wowza/#configuration","text":"Edit the file etc/org.opencastproject.distribution.streaming.wowza.WowzaAdaptiveStreamingDistributionService.cfg with your preferred configuration. The contents should be self-explanatory. Edit $KARAF/etc/custom.properties and adjust these values to match those of your scenario: org.opencastproject.streaming.url=rtmp(s)://<wowza-server>/<wowza-application> org.opencastproject.streaming.port=<port_number> org.opencastproject.adaptive-streaming.url=http(s)://<wowza-server>/<wowza-application> org.opencastproject.adaptive-streaming.port=<port_number> org.opencastproject.streaming.directory=/mnt/opencast-drive/content/streams The port numbers are only necessary when non-standard ports are used for streaming and/or adaptive-streaming. In most cases, it is safe to comment them out or simply not include those properties in the file. Restart your Opencast server.","title":"Configuration"},{"location":"modules/adaptivestreaming-wowza/#installation-on-the-wowza-side","text":"","title":"Installation on the Wowza side"},{"location":"modules/adaptivestreaming-wowza/#pre-requirements","text":"Download/Purchase the Wowza Streaming Engine from the Wowza Homepage and install it according to their manuals. The shared drive indicated in the org.opencastproject.streaming.directory in the custom.properties file in Opencast must also be mounted in the Wowza server. Please note that mount points do not necessarily match! (e.g. the path /mnt/opencast-drive-content-streams in the Opencast server might be mounted as /media/opencast-streams in the Wowza server). Do not forget to open your firewall on ports 1935 (RTMP), 80 (HTTP, adaptive streaming) and, if you want to use SSL, 443. You will have set your login credentials during the setup of Wowza. You will need these for the web UI. Open http://<wowza-server>:8088/enginemanager and log in Select \"Application -> Add Application\" in the top menu Select \"VOD Single Server\" Enter a name for the new application. You must use the same application name you have configured in $KARAF/etc/custom.properties (for instance: opencast-engage ) Application Description : Feel free to add a description. Playback Types : Enable your desired streaming protocols Options : Disable the global CORS Content Directory : Mark the checkbox Use the following directory . The directory you should input is a subdirectory of the path indicated in the property org.opencastproject.streaming.directory defined in the file $KARAF/etc/custom.properties . That subdirectory's name is the organization's ID ( mh_default_org by default). For instance, if the org.opencastproject.streaming.directory is mounted in the Wowza Server as: /mnt/opencast-streams then the Content Directory for the default organization would be: /mnt/opencast-streams/mh_default_org In a multitenant Opencast setup, an organization with ID my_organization should have the Content Directory set to: /mnt/opencast-streams/my_organization","title":"Pre-requirements"},{"location":"modules/adaptivestreaming-wowza/#optional-settings","text":"Opencast HTML5 Player is able to play videos from Wowza using adaptive streaming protocols. However, some browsers may experiment problems due to crossdomain issues, which means that we need to instruct Wowza to include the right Allow-Origin headers in its HTTP requests. On the other hand, you may experiment problems with the MPEG-DASH protocol, depending on the encoding of the video sources. All this can be configured in the \"Options\" section of the Wowza application: Click on the tab \"Properties\" in your application If you can't see the \"Properties\" tab, go to \"Users\" > \"Edit\" > \"Preferences\" and select \"Allow access to advanced properties and features\" Scroll down the page to \"Custom\" Click the \"Edit\" button Add the following Properties Path Name Type Value /Root/Application/HTTPStreamer cupertinoUserHTTPHeaders String ** /Root/Application/HTTPStreamer mpegdashUserHTTPHeaders String ** /Root/Application/HTTPStreamer mpegdashAdjustCTTSForFirstKeyFrameToZero Boolean true Due to some limitations in Bitbucket's Markdown parser, we can write this value within a table because it contains a \"pipe\" symbol (\"|\"). The correct value for this property is: Access-Control-Allow-Origin: *|Access-Control-Allow-Methods:GET, HEAD, OPTIONS Do not forget to restart the application!","title":"Optional Settings"},{"location":"modules/adaptivestreaming-wowza/#players-and-formats","text":"Theodul : RTMP, HLS, DASH (over HTTP and HTTPS) Paella : RTMP, RTMPS, HLS, DASH (over HTTP and HTTPS)","title":"Players and Formats"},{"location":"modules/adaptivestreaming-wowza/#encoding-profiles","text":"Keep in mind that you have to adapt your encoding profiles when you want generate the videos to distribute via HLS or DASH. Specifically, if the videos with different qualities are not keyframe-aligned, they may not play smoothly or not play at all. You can find more information here .","title":"Encoding Profiles"},{"location":"modules/adaptivestreaming-wowza/#limitations","text":"This module is able to correctly distribute new elements incrementally. That means that if some elements in a mediapackage are already distributed when another Distribute operation runs, the operation should run without errors. However, partial Retract operations are discouraged and cause the remaining elements to be no longer playable. The recommended procedure to retract only some elements in a mediapackage is therefore: Completely retract the mediapackage Distribute again only the desired elements The effects of this limitation are small, because the retract-engage workflow operation always retracts the whole Mediapackage and because partial retractions seem to have little to no practical application. These can however be performed by calling the corresponding REST endpoints. In such cases, users are encouraged to use the recommended method above.","title":"Limitations"},{"location":"modules/atomrss/","text":"Configure Atom and RSS Feeds This document will help you understand and configure the Opencast RSS and Atom feed catalog. The catalog supports multiple versions of each syndication format. Feed Catalog The catalog is located at: http://opencast.example.edu:8080/feeds Individual feeds are located at: http://opencast.example.edu:8080/feeds/<feed_selector> Defaults The catalog contains the following default feeds: Latest http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/latest Need an example? Visit http://demo.opencastproject.org/feeds/atom/1.0/latest Series http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/series/<series_id> Aggregation (of a set of series) http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/aggregated/<name_of_configured_aggregation> Custom http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/custom/<query> Aggregation The feed allows administrators to pre-configure feeds for specific sets of series. Given the following configuration, http://opencast.example.edu:8080/feeds/aggregated/myseries would return the latest episodes from series series_1 and series_2 . The Opencast feed specifications are located in: .../etc/feeds Update aggregation.properties, the specification for an example feed aggregation: feed.selector=myseries feed.series=series_1,series_2 Custom The Opencast feed specifications are located in: .../etc/feeds Below is custom.properties, the default specification for an example custom feed of published episodes: feed.class=org.opencastproject.feed.impl.CustomFeedService feed.uri=custom feed.size=20 feed.query=dc_title-sum:{0} feed.name=Special episodes feed.description=Special collection of episodes feed.copyright=All rights reserved by The Opencast Project feed.home=/engage/ui feed.entry=/engage/ui/embed.html?id={0} feed.cover=/engage/feed-cover.png feed.rssflavors=presentation/delivery,presenter/delivery,presenter/feed+preview,presenter/search+preview feed.rsstags=rss feed.rssmediatype=video,audio feed.atomflavors=presentation/delivery,presenter/delivery,presenter/feed+preview,presenter/search+preview feed.atomtags=atom Properties The following properties are common to all feed specifications: Name Description feed.class Java implementation, e.g. LatestFeedService. feed.uri Feed location/identifier feed.size Maximum number of entries in the feed (defaul: 100). Set to 0 to include all available entries. feed.selector Feed route pattern, e.g. latest. feed.name Feed title feed.description Feed description feed.copyright Feed copyright notice feed.home Feed catalog homepage, e.g. http://www.opencastproject.org. feed.entry The route pattern used to generate links to individual enclosures, e.g. /engage/ui/embed.html?id={0}. feed.cover Feed image feed.rssflavors The RSS enclosure route pattern, e.g. presenter/delivery, selected according to their appearance. feed.rsstags A comma, semi-colon or space-separated list of tags used to filter available enclosures feed.rssmediatype A comma, semi-colon or space-separated list of tags used to decide whether to prefer video or audio enclosures feed.atomflavors The Atom enclosures route pattern, e.g. presenter/delivery. feed.atomtags A comma, semi-colon or space-separated list of tags used to filter available enclosures The following properties are specific to custom feeds: Name Description feed.query A custom lucene query, matched again Java's MessageFormat using solr. The query http://opencast.example.edu:8080/feeds/alphabetical/a would return all episodes starting with the letter a. feed.selector=alphabetical feed.query=dc_title:{0}*","title":"Atom/RSS Feed"},{"location":"modules/atomrss/#configure-atom-and-rss-feeds","text":"This document will help you understand and configure the Opencast RSS and Atom feed catalog. The catalog supports multiple versions of each syndication format.","title":"Configure Atom and RSS Feeds"},{"location":"modules/atomrss/#feed-catalog","text":"The catalog is located at: http://opencast.example.edu:8080/feeds Individual feeds are located at: http://opencast.example.edu:8080/feeds/<feed_selector>","title":"Feed Catalog"},{"location":"modules/atomrss/#defaults","text":"The catalog contains the following default feeds:","title":"Defaults"},{"location":"modules/atomrss/#latest","text":"http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/latest Need an example? Visit http://demo.opencastproject.org/feeds/atom/1.0/latest","title":"Latest"},{"location":"modules/atomrss/#series","text":"http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/series/<series_id>","title":"Series"},{"location":"modules/atomrss/#aggregation-of-a-set-of-series","text":"http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/aggregated/<name_of_configured_aggregation>","title":"Aggregation (of a set of series)"},{"location":"modules/atomrss/#custom","text":"http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/custom/<query>","title":"Custom"},{"location":"modules/atomrss/#aggregation","text":"The feed allows administrators to pre-configure feeds for specific sets of series. Given the following configuration, http://opencast.example.edu:8080/feeds/aggregated/myseries would return the latest episodes from series series_1 and series_2 . The Opencast feed specifications are located in: .../etc/feeds Update aggregation.properties, the specification for an example feed aggregation: feed.selector=myseries feed.series=series_1,series_2","title":"Aggregation"},{"location":"modules/atomrss/#custom_1","text":"The Opencast feed specifications are located in: .../etc/feeds Below is custom.properties, the default specification for an example custom feed of published episodes: feed.class=org.opencastproject.feed.impl.CustomFeedService feed.uri=custom feed.size=20 feed.query=dc_title-sum:{0} feed.name=Special episodes feed.description=Special collection of episodes feed.copyright=All rights reserved by The Opencast Project feed.home=/engage/ui feed.entry=/engage/ui/embed.html?id={0} feed.cover=/engage/feed-cover.png feed.rssflavors=presentation/delivery,presenter/delivery,presenter/feed+preview,presenter/search+preview feed.rsstags=rss feed.rssmediatype=video,audio feed.atomflavors=presentation/delivery,presenter/delivery,presenter/feed+preview,presenter/search+preview feed.atomtags=atom","title":"Custom"},{"location":"modules/atomrss/#properties","text":"The following properties are common to all feed specifications: Name Description feed.class Java implementation, e.g. LatestFeedService. feed.uri Feed location/identifier feed.size Maximum number of entries in the feed (defaul: 100). Set to 0 to include all available entries. feed.selector Feed route pattern, e.g. latest. feed.name Feed title feed.description Feed description feed.copyright Feed copyright notice feed.home Feed catalog homepage, e.g. http://www.opencastproject.org. feed.entry The route pattern used to generate links to individual enclosures, e.g. /engage/ui/embed.html?id={0}. feed.cover Feed image feed.rssflavors The RSS enclosure route pattern, e.g. presenter/delivery, selected according to their appearance. feed.rsstags A comma, semi-colon or space-separated list of tags used to filter available enclosures feed.rssmediatype A comma, semi-colon or space-separated list of tags used to decide whether to prefer video or audio enclosures feed.atomflavors The Atom enclosures route pattern, e.g. presenter/delivery. feed.atomtags A comma, semi-colon or space-separated list of tags used to filter available enclosures The following properties are specific to custom feeds: Name Description feed.query A custom lucene query, matched again Java's MessageFormat using solr. The query http://opencast.example.edu:8080/feeds/alphabetical/a would return all episodes starting with the letter a. feed.selector=alphabetical feed.query=dc_title:{0}*","title":"Properties"},{"location":"modules/awss3archive/","text":"AWS S3 Archive Configuration This page documents the configuration for the AWS S3 components in the Opencast module asset-manager-storage-aws . This configuration is only required on the admin node, and only if you are using Amazon S3 as an archive repository. Amazon User Configuration Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation . You will, however, require an Access Key ID and Secret Access Key . The user to which this key belongs requires the AmazonS3FullAccess permission, which can be granted using these instructions . A free Amazon account will work for small scale testing, but be aware that S3 archiving can cost you a lot of money very quickly. Be aware of how much data and how many requests you are making, and be sure to set alarms to notify you of cost overruns. Amazon Service Configuration The development and testing it is generally safe to allow the Opencast AWS S3 Archive service to create the S3 bucket for you. It will create the bucket per its configuration, with private-only access to the files, and no versioning. Opencast Service Configuration The Opencast AWS S3 Archive service has four configuration keys which can be found in the org.opencastproject.assetmanager.aws.s3.AwsS3ArchiveElementStore.cfg configuration file. Key name Value Example org.opencastproject.assetmanager.aws.s3.enabled Whether to enable this service true org.opencastproject.archive.aws.s3.region The AWS region to set us-west-2 org.opencastproject.archive.aws.s3.bucket The S3 bucket name example-org-archive org.opencastproject.archive.aws.s3.access.id Your access ID 20 alphanumeric characters org.opencastproject.archive.aws.s3.secret.key Your secret key 40 characters Using S3 Archiving There are two major methods to access S3 archiving features: manually, and via a workflow. Amazon S3 archiving is not part of the default workflows and manual S3 offload is disabled by default. To enable manual S3 offload you must edit the offload.xml workflow configuration file and change var s3Enabled = false; to var s3Enabled = true; . To manually offload a mediapackage follow the directions in the user documentation. To automatically offload a mediapackage to S3 you must add the move-storage workflow operation to your workflow. The operation documentation can be found here . Migrating to S3 Archiving with Pre-Existing Data Archiving to S3 is a non-destructive operation in that it is safe to move archive files back and forth between local storage and S3. To offload your local archive, select the workflow(s) and follow the manual offload steps described in the user documentation.","title":"Amazon S3 Archive Storage"},{"location":"modules/awss3archive/#aws-s3-archive-configuration","text":"This page documents the configuration for the AWS S3 components in the Opencast module asset-manager-storage-aws . This configuration is only required on the admin node, and only if you are using Amazon S3 as an archive repository.","title":"AWS S3 Archive Configuration"},{"location":"modules/awss3archive/#amazon-user-configuration","text":"Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation . You will, however, require an Access Key ID and Secret Access Key . The user to which this key belongs requires the AmazonS3FullAccess permission, which can be granted using these instructions . A free Amazon account will work for small scale testing, but be aware that S3 archiving can cost you a lot of money very quickly. Be aware of how much data and how many requests you are making, and be sure to set alarms to notify you of cost overruns.","title":"Amazon User Configuration"},{"location":"modules/awss3archive/#amazon-service-configuration","text":"The development and testing it is generally safe to allow the Opencast AWS S3 Archive service to create the S3 bucket for you. It will create the bucket per its configuration, with private-only access to the files, and no versioning.","title":"Amazon Service Configuration"},{"location":"modules/awss3archive/#opencast-service-configuration","text":"The Opencast AWS S3 Archive service has four configuration keys which can be found in the org.opencastproject.assetmanager.aws.s3.AwsS3ArchiveElementStore.cfg configuration file. Key name Value Example org.opencastproject.assetmanager.aws.s3.enabled Whether to enable this service true org.opencastproject.archive.aws.s3.region The AWS region to set us-west-2 org.opencastproject.archive.aws.s3.bucket The S3 bucket name example-org-archive org.opencastproject.archive.aws.s3.access.id Your access ID 20 alphanumeric characters org.opencastproject.archive.aws.s3.secret.key Your secret key 40 characters","title":"Opencast Service Configuration"},{"location":"modules/awss3archive/#using-s3-archiving","text":"There are two major methods to access S3 archiving features: manually, and via a workflow. Amazon S3 archiving is not part of the default workflows and manual S3 offload is disabled by default. To enable manual S3 offload you must edit the offload.xml workflow configuration file and change var s3Enabled = false; to var s3Enabled = true; . To manually offload a mediapackage follow the directions in the user documentation. To automatically offload a mediapackage to S3 you must add the move-storage workflow operation to your workflow. The operation documentation can be found here .","title":"Using S3 Archiving"},{"location":"modules/awss3archive/#migrating-to-s3-archiving-with-pre-existing-data","text":"Archiving to S3 is a non-destructive operation in that it is safe to move archive files back and forth between local storage and S3. To offload your local archive, select the workflow(s) and follow the manual offload steps described in the user documentation.","title":"Migrating to S3 Archiving with Pre-Existing Data"},{"location":"modules/awss3distribution/","text":"AWS S3 Distribution Configuration This page documents the configuration for Opencast module distribution-service-aws-s3 . This configuration is only required on the presentation node, and only if you are using Amazon S3 and/or Cloudfront for distributing media to end users. Amazon User Configuration Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation . You will, however, require to set up proper credentials by either: Creating an Access Key ID and a Secret Access Key or Using Instance Profile Credentials (recommended when running Opencast on EC2 instances) AmazonS3FullAccess permission is required , which can be granted using these instructions . A free Amazon account will work for small scale testing, but be aware that S3 distribution can cost you a lot of money very quickly. Be aware of how much data and how many requests you are making, and be sure to set alarms to notify you of cost overruns. Amazon Service Configuration The development and testing it is generally safe to allow the Opencast AWS S3 Distribution service to create the S3 bucket for you. It will create the bucket per its configuration, with public read-only access to the files, and no versioning. For production use we suggest using Amazon CloudFront, which requires additional configuration. Amazon CloudFront Amazon CloudFront provides an optional way to better handle distributing your media to end users. While fully configuring CloudFront is outside the scope of this documentation, we wish to note that this does affect one of the keys described below. Please ensure you use the correct distribution base format depending on which service you are using! Opencast Service Configuration The Opencast AWS S3 Distribution service has five configuration keys, which can be found in the org.opencastproject.distribution.aws.s3.AwsS3DistributionServiceImpl.cfg configuration file. Key name Value Example org.opencastproject.distribution.aws.s3.distribution.enable True to enable S3 distribution, false otherwise true org.opencastproject.distribution.aws.s3.region The AWS region to set us-west-2 org.opencastproject.distribution.aws.s3.bucket The S3 bucket name example-org-dist org.opencastproject.distribution.aws.s3.distribution.base Where the S3 files are available from. This value can be derived from the bucket and region values, or is set by CloudFront. http://s3-us-west-2.amazonaws.com/example-org-dist, or DOMAIN_NAME.cloudfront.net org.opencastproject.distribution.aws.s3.access.id Your access ID 20 alphanumeric characters org.opencastproject.distribution.aws.s3.secret.key Your secret key 40 characters If org.opencastproject.distribution.aws.s3.access.id and org.opencastproject.distribution.aws.s3.secret.key are not explicitly provided, search for credentials will be performed in the order specified by the Default Credentials Provider Chain . Using S3 Distribution Amazon S3 distribution is already included in the default Opencast workflows, however it must first be enabled. The schedule-and-upload.xml and publish.xml workflow configuration files both contain lines containing the string \"Remove this line if you wish to publish to AWS S3\". Both of these lines must be removed before publishing to AWS S3 will function correctly. If you wish to use AWS S3 publishing with your own custom workflow, you must add the publish-aws workflow operation to your workflow. The operation documentation can be found here . Publishing to multiple distribution services Currently we do not support publication to multiple distribution services simultaneously. This means that whichever workflow operation is last in the workflow will be the final publication. Using this handler in custom workflows If your workflow contains both publish-engage and publish-aws , in that order, and without a conditional you would have publication files stored both locally and in AWS. This is likely not what you want, so protect your workflow operations appropriately. If you really do need these files stored in both places (for example, in cases where you need to make the files available immediately, and only push to AWS in some cases) then remember to add a retract-engage in between the publication operations. Note that if this step is omitted the files will remain available locally, but will not be used. Of further note, if you retract after publication to AWS then your workflow will not be available to users. To summarize, this table presents a subset of the various situations that are possible Workflow Operations Files present in the Media Module Files present in AWS Files served from publish-engage Yes No Opencast Media Module publish-aws No Yes AWS publish-engage, publish-aws Yes Yes AWS publish-aws, publish-engage Yes Yes Opencast Media Module publish-engage, retract-engage, publish-aws Temporary Yes AWS publish-engage, publish-aws, retract-engage No Yes Not available Migrating to S3 Distribution with Pre-Existing Data If you already have data published to your local Opencast install, you should be able to republish the media selecting AWS S3 as the distribution service to use.","title":"Amazon S3 Distribution"},{"location":"modules/awss3distribution/#aws-s3-distribution-configuration","text":"This page documents the configuration for Opencast module distribution-service-aws-s3 . This configuration is only required on the presentation node, and only if you are using Amazon S3 and/or Cloudfront for distributing media to end users.","title":"AWS S3 Distribution Configuration"},{"location":"modules/awss3distribution/#amazon-user-configuration","text":"Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation . You will, however, require to set up proper credentials by either: Creating an Access Key ID and a Secret Access Key or Using Instance Profile Credentials (recommended when running Opencast on EC2 instances) AmazonS3FullAccess permission is required , which can be granted using these instructions . A free Amazon account will work for small scale testing, but be aware that S3 distribution can cost you a lot of money very quickly. Be aware of how much data and how many requests you are making, and be sure to set alarms to notify you of cost overruns.","title":"Amazon User Configuration"},{"location":"modules/awss3distribution/#amazon-service-configuration","text":"The development and testing it is generally safe to allow the Opencast AWS S3 Distribution service to create the S3 bucket for you. It will create the bucket per its configuration, with public read-only access to the files, and no versioning. For production use we suggest using Amazon CloudFront, which requires additional configuration.","title":"Amazon Service Configuration"},{"location":"modules/awss3distribution/#amazon-cloudfront","text":"Amazon CloudFront provides an optional way to better handle distributing your media to end users. While fully configuring CloudFront is outside the scope of this documentation, we wish to note that this does affect one of the keys described below. Please ensure you use the correct distribution base format depending on which service you are using!","title":"Amazon CloudFront"},{"location":"modules/awss3distribution/#opencast-service-configuration","text":"The Opencast AWS S3 Distribution service has five configuration keys, which can be found in the org.opencastproject.distribution.aws.s3.AwsS3DistributionServiceImpl.cfg configuration file. Key name Value Example org.opencastproject.distribution.aws.s3.distribution.enable True to enable S3 distribution, false otherwise true org.opencastproject.distribution.aws.s3.region The AWS region to set us-west-2 org.opencastproject.distribution.aws.s3.bucket The S3 bucket name example-org-dist org.opencastproject.distribution.aws.s3.distribution.base Where the S3 files are available from. This value can be derived from the bucket and region values, or is set by CloudFront. http://s3-us-west-2.amazonaws.com/example-org-dist, or DOMAIN_NAME.cloudfront.net org.opencastproject.distribution.aws.s3.access.id Your access ID 20 alphanumeric characters org.opencastproject.distribution.aws.s3.secret.key Your secret key 40 characters If org.opencastproject.distribution.aws.s3.access.id and org.opencastproject.distribution.aws.s3.secret.key are not explicitly provided, search for credentials will be performed in the order specified by the Default Credentials Provider Chain .","title":"Opencast Service Configuration"},{"location":"modules/awss3distribution/#using-s3-distribution","text":"Amazon S3 distribution is already included in the default Opencast workflows, however it must first be enabled. The schedule-and-upload.xml and publish.xml workflow configuration files both contain lines containing the string \"Remove this line if you wish to publish to AWS S3\". Both of these lines must be removed before publishing to AWS S3 will function correctly. If you wish to use AWS S3 publishing with your own custom workflow, you must add the publish-aws workflow operation to your workflow. The operation documentation can be found here .","title":"Using S3 Distribution"},{"location":"modules/awss3distribution/#publishing-to-multiple-distribution-services","text":"Currently we do not support publication to multiple distribution services simultaneously. This means that whichever workflow operation is last in the workflow will be the final publication.","title":"Publishing to multiple distribution services"},{"location":"modules/awss3distribution/#using-this-handler-in-custom-workflows","text":"If your workflow contains both publish-engage and publish-aws , in that order, and without a conditional you would have publication files stored both locally and in AWS. This is likely not what you want, so protect your workflow operations appropriately. If you really do need these files stored in both places (for example, in cases where you need to make the files available immediately, and only push to AWS in some cases) then remember to add a retract-engage in between the publication operations. Note that if this step is omitted the files will remain available locally, but will not be used. Of further note, if you retract after publication to AWS then your workflow will not be available to users. To summarize, this table presents a subset of the various situations that are possible Workflow Operations Files present in the Media Module Files present in AWS Files served from publish-engage Yes No Opencast Media Module publish-aws No Yes AWS publish-engage, publish-aws Yes Yes AWS publish-aws, publish-engage Yes Yes Opencast Media Module publish-engage, retract-engage, publish-aws Temporary Yes AWS publish-engage, publish-aws, retract-engage No Yes Not available","title":"Using this handler in custom workflows"},{"location":"modules/awss3distribution/#migrating-to-s3-distribution-with-pre-existing-data","text":"If you already have data published to your local Opencast install, you should be able to republish the media selecting AWS S3 as the distribution service to use.","title":"Migrating to S3 Distribution with Pre-Existing Data"},{"location":"modules/execute/","text":"Execute Service The Execute Service allows a workflow to run external scripts or applications with any MediaPackage element as arguments. This provides a flexible way to operate with MediaPackage resources without the need to write Java code or build Opencast from source. Commands are executed on worker nodes. There are two execute workflow operations: Execute Once : for running a single command that may operate on multiple elements of a mediapackage Execute Many : for running a command for each element in a mediapackage that matches the given criteria Service Configuration The Execute Service configuration in org.opencastproject.execute.impl.ExecuteServiceImpl.cfg must be updated to define which commands may be run: # Load factor job.load.execute = 1.0 # The list of commands, separated by spaces, which may be run by the Execute Service. # A value of * means any command is allowed. # Default: empty (no commands allowed) #commands.allowed = If commands.allowed is empty or undefined (the default), the service won't be able to run any commands. Use the special key * to permit any command to be executed (not recommended for production systems). To adjust the job load factor for a command, use the load parameter in the workflow operation rather than adjusting the job.load.execute parameter above. Parameter substitution The command arguments may contain placeholders, which are substituted by their corresponding values before the command runs. The complete list of available placeholders is detailed in the table below. Placeholder Used in Meaning #{id} Execute Once The Mediapackage ID #{flavor(some/flavor)} Execute Once The absolute path of the element matching the specified flavor. If several elements have the same flavor, the first element returned by MediaPackage#getElementsByFlavor is used. #{in} Execute Many The absolute path of the input element #{out} Execute Once, Execute Many The absolute path of the output element, formed from the output-filename parameter Using custom properties in the argument list Custom properties can be included in the command line by using the syntax #{name} , where name is the variable name, as defined in the Execute Service's configuration file or in the global configuration file custom.properties . The substitution will be done in the following order of precedence: Placeholders defined in the table above. Configuration keys defined in org.opencastproject.execute.impl.ExecuteServiceImpl.cfg . Configuration keys defined in custom.properties . For instance, suppose you use the Execute Service with the following arguments: \"John Doe\" xyz #{my.property} the command run will receive that argument list as-is, because my.property is not a valid placeholder, nor is it defined in the Execute Service's configuration file or custom.properties . However, if you define my.property in custom.properties : my.property = foo then the command will get the following argument list: \"John Doe\" xyz foo If you define the same variable in the Execute Service's configuration file (regardless of whether the variable is defined in custom.properties or not): my.property = bar then the actual argument list will be: \"John Doe\" xyz bar Executing commands in workflows For more information on how to execute a command in a workflow, see: Execute Once Workflow Operation Execute Many Workflow Operation","title":"Execute Service"},{"location":"modules/execute/#execute-service","text":"The Execute Service allows a workflow to run external scripts or applications with any MediaPackage element as arguments. This provides a flexible way to operate with MediaPackage resources without the need to write Java code or build Opencast from source. Commands are executed on worker nodes. There are two execute workflow operations: Execute Once : for running a single command that may operate on multiple elements of a mediapackage Execute Many : for running a command for each element in a mediapackage that matches the given criteria","title":"Execute Service"},{"location":"modules/execute/#service-configuration","text":"The Execute Service configuration in org.opencastproject.execute.impl.ExecuteServiceImpl.cfg must be updated to define which commands may be run: # Load factor job.load.execute = 1.0 # The list of commands, separated by spaces, which may be run by the Execute Service. # A value of * means any command is allowed. # Default: empty (no commands allowed) #commands.allowed = If commands.allowed is empty or undefined (the default), the service won't be able to run any commands. Use the special key * to permit any command to be executed (not recommended for production systems). To adjust the job load factor for a command, use the load parameter in the workflow operation rather than adjusting the job.load.execute parameter above.","title":"Service Configuration"},{"location":"modules/execute/#parameter-substitution","text":"The command arguments may contain placeholders, which are substituted by their corresponding values before the command runs. The complete list of available placeholders is detailed in the table below. Placeholder Used in Meaning #{id} Execute Once The Mediapackage ID #{flavor(some/flavor)} Execute Once The absolute path of the element matching the specified flavor. If several elements have the same flavor, the first element returned by MediaPackage#getElementsByFlavor is used. #{in} Execute Many The absolute path of the input element #{out} Execute Once, Execute Many The absolute path of the output element, formed from the output-filename parameter","title":"Parameter substitution"},{"location":"modules/execute/#using-custom-properties-in-the-argument-list","text":"Custom properties can be included in the command line by using the syntax #{name} , where name is the variable name, as defined in the Execute Service's configuration file or in the global configuration file custom.properties . The substitution will be done in the following order of precedence: Placeholders defined in the table above. Configuration keys defined in org.opencastproject.execute.impl.ExecuteServiceImpl.cfg . Configuration keys defined in custom.properties . For instance, suppose you use the Execute Service with the following arguments: \"John Doe\" xyz #{my.property} the command run will receive that argument list as-is, because my.property is not a valid placeholder, nor is it defined in the Execute Service's configuration file or custom.properties . However, if you define my.property in custom.properties : my.property = foo then the command will get the following argument list: \"John Doe\" xyz foo If you define the same variable in the Execute Service's configuration file (regardless of whether the variable is defined in custom.properties or not): my.property = bar then the actual argument list will be: \"John Doe\" xyz bar","title":"Using custom properties in the argument list"},{"location":"modules/execute/#executing-commands-in-workflows","text":"For more information on how to execute a command in a workflow, see: Execute Once Workflow Operation Execute Many Workflow Operation","title":"Executing commands in workflows"},{"location":"modules/googlespeechtranscripts/","text":"Transcripts (Automated by Google Speech) Overview The GoogleSpeechTranscriptionService invokes the Google Speech-to-Text service via REST API to transcribe audio to text. During the execution of an Opencast workflow, an audio file is extracted from one of the presenter videos and sent to the Google Speech-to-Text service. When the results are received, they are converted to the desired caption format and attached to the media package. Note that because Google's Speech-to-Text service can take a while to process a recording, we do not wait for it to finish before proceeding with the rest of Opencast's normal processing, the transcription process is asynchronous. Workflow 1 runs: Audio file is created Google Speech-to-Text job is started Workflow finishes Translation finishes, workflow 2 is started. Workflow 2 runs: File with results is converted and attached to media package Media package is republished with captions/transcripts Google Speech-to-Text service documentation, including which languages are currently supported, can be found here . Configuration Notes : Instructions and screenshots provided in this section are based on Google Speech-to-Text documentation at the time of writing this document. For up to date instructions please search for 'google speech to text configuration' or visit Google Cloud service page . Step 1: Activate Google Speech and Google Cloud Storage APIs Log in to your Google account and Activate a 12 months free trial Google Cloud Platform services Create a Project to store your credentials and billing information Click Select a project to create new project or use existing project Enable Google Speech API Expand the menu on the left Go to APIs & Service > Libraries Find the Cloud Speech API and click Enable to enable the Google Cloud Speech API Enable Google Cloud Storage and Google Cloud Storage JSON API Go to APIs & Service > Libraries Find Google Cloud Storage and Google Cloud Storage JSON API and enable them if there are not. Create a cloud storage bucket. This is where you will temporary host the files you want to transcribe Go to your Google Cloud Dashboard Expand the menu on the left Go to Storage > Browser Click CREATE BUCKET to create a bucket for the selected project Step 2: Get Google Cloud credentials Go to your Google Cloud Dashboard Expand the menu on the left Go to APIs & Service > Credentials Click on the tab OAuth Consent Screen Fill in a Project name and Save it. Don't worry about the other fields. Go back to Credentials Click the button that says Create Credentials select OAuth Client ID Choose Web Application and give it a name. Add https://developers.google.com/oauthplayground in Authorized redirect URIs . You will need to use this in the next step to get your refresh token Click Create and take note of your Client ID and Client Secret Getting your Refresh Token and Authorization enpdpoint Go to https://developers.google.com/oauthplayground (Make sure you added this URL to your Authorized redirect URIs in the previous step.) In the top right corner, click the settings icon Take note of your Token endpoint . It is the token endpoint url needed for the configuration. Make sure the Access token location is set to Authorization header w/ Bearer prefix Make sure Access type is set to Offline Make sure Force prompt is set to 'Consent Screen' Check Use your own OAuth credentials Paste your Client ID and Client Secret created previously. Close the settings. Select the scope of your APIs Click Step 1 Select & authorize APIs tab on the left Find Cloud Speech API v1 and click on https://www.googleapis.com/auth/cloud-platform to select it. Find Cloud Storage API v1 from the list, expand it and click on https://www.googleapis.com/auth/devstorage.full_control to select it Find Cloud Storage JSON API v1 expand it and select https://www.googleapis.com/auth/devstorage.full_control Click Authorize APIs , allow access to your account when prompted. There will be a few warning prompts, just proceed. (On some browser you may need to click the advanced option before you can proceed to next page) When you get to step 2 Exchange authorization code for tokens tab, click Exchange authorization code for tokens . You will need the OAuth Client ID, OAuth Client secret ,the Refresh token and Token endpoint for the configuration file Step 3: Configure GoogleSpeechTranscriptionService Edit etc/org.opencastproject.transcription.googlespeech.GoogleSpeechTranscriptionService.cfg : Set enabled =true Use OAuth Client ID , OAuth Client secret , Refresh token , Token endpoint and storage bucket created above to respectively set google.cloud.client.id , google.cloud.client.secret , google.cloud.refresh.token , google.cloud.token.endpoint.url and google.cloud.storage.bucket Enter the appropriate language in google.speech.language , default is ( en-US ). List of supported language: https://cloud.google.com/speech-to-text/docs/languages Remove profanity (bad language) from transcription by using google.speech.profanity.filter , default is ( false ), not removed by default In workflow , enter the workflow definition id of the workflow to be used to attach the generated transcripts/captions Enter a notification.email to get job failure notifications. If not entered, the email in etc/custom.properties (org.opencastproject.admin.email) will be used. If no email address specified in either notification.email or org.opencastproject.admin.email , email notifications will be disabled. Example of configuration file: # Change enabled to true to enable this service. enabled=false # Google Cloud Service details google.cloud.client.id=<OAUTH_CLIENT_ID> google.cloud.client.secret=<OAUTH_CLIENT_SECRET> google.cloud.refresh.token=1<REFRESH_TOKEN> google.cloud.token.endpoint.url=<TOKEN_ENDPOINT> # google cloud storage bucket google.cloud.storage.bucket=<BUCKET_NAME> # Language of the supplied audio. See the Google Speech-to-Text service documentation # for available languages. If empty, the default will be used (\"en-US\"). google.speech.language= # Filter out profanities from result. Default is false google.speech.profanity.filter=false # Workflow to be executed when results are ready to be attached to media package. workflow=google-speech-attach-transcripts # Interval the workflow dispatcher runs to start workflows to attach transcripts to the media package # after the transcription job is completed. # (in seconds) Default is 1 minute. workflow.dispatch.interval=60 # How long it should wait to check jobs after their start date + track duration has passed. # The default is 5 minutes. # (in seconds) completion.check.buffer=300 # How long to wait after a transcription is supposed to finish before marking the job as # cancelled in the database. Default is 5 hours. # (in seconds) max.processing.time=18000 # How long to keep result files in the working file repository in days. # The default is 7 days. cleanup.results.days=7 # Email to send notifications of errors. If not entered, the value from # org.opencastproject.admin.email in custom.properties will be used. notification.email=localadmin@domain Step 4: Add encoding profile for extracting audio The Google Speech-to-Text service has limitations on audio types. Supported audio type are here . By default Opencast will use the encoding settings in etc/encoding/googlespeech-audio.properties. Step 5: Add workflow operations and create new workflow Add the following operations to your workflow. We suggest adding them after the media package is published so that users can watch videos without having to wait for the transcription to finish, but it depends on your use case. The only requirement is to take a snapshot of the media package so that the second workflow can retrieve it from the archive to attach the caption/transcripts. <!-- Encode audio to flac --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-flavor\">audio/flac</configuration> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-flac</configuration> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start Google Speech transcription job --> <operation id=\"google-speech-start-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start Google Speech transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mediapackage already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/timedtext</configuration> <configuration key=\"language-code\">en-US</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation> Step 6: Create a workflow that will add the generated caption/transcript to the media package and republish it A sample one can be found in etc/workflows/google-speech-attach-transcripts.xml <!-- Attach caption/transcript --> <operation id=\"google-speech-attach-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Attach captions/transcription\"> <configurations> <!-- This is filled out by the transcription service when starting this workflow --> <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration> <configuration key=\"line-size\">80</configuration> <configuration key=\"target-flavor\">captions/timedtext</configuration> <configuration key=\"target-tag\">archive</configuration> <configuration key=\"target-caption-format\">vtt</configuration> </configurations> </operation> <!-- Publish to engage player --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Distribute and publish to engage server\"> <configurations> <configuration key=\"download-source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">false</configuration> </configurations> </operation> <!-- Publish to oaipmh --> <operation id=\"republish-oaipmh\" exception-handler-workflow=\"partial-error\" description=\"Update recording metadata in default OAI-PMH repository\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation> Workflow Operations google-speech-attach-transcription google-speech-start-transcription","title":"Transcripts (Google Speech)"},{"location":"modules/googlespeechtranscripts/#transcripts-automated-by-google-speech","text":"","title":"Transcripts (Automated by Google Speech)"},{"location":"modules/googlespeechtranscripts/#overview","text":"The GoogleSpeechTranscriptionService invokes the Google Speech-to-Text service via REST API to transcribe audio to text. During the execution of an Opencast workflow, an audio file is extracted from one of the presenter videos and sent to the Google Speech-to-Text service. When the results are received, they are converted to the desired caption format and attached to the media package. Note that because Google's Speech-to-Text service can take a while to process a recording, we do not wait for it to finish before proceeding with the rest of Opencast's normal processing, the transcription process is asynchronous. Workflow 1 runs: Audio file is created Google Speech-to-Text job is started Workflow finishes Translation finishes, workflow 2 is started. Workflow 2 runs: File with results is converted and attached to media package Media package is republished with captions/transcripts Google Speech-to-Text service documentation, including which languages are currently supported, can be found here .","title":"Overview"},{"location":"modules/googlespeechtranscripts/#configuration","text":"Notes : Instructions and screenshots provided in this section are based on Google Speech-to-Text documentation at the time of writing this document. For up to date instructions please search for 'google speech to text configuration' or visit Google Cloud service page .","title":"Configuration"},{"location":"modules/googlespeechtranscripts/#step-1-activate-google-speech-and-google-cloud-storage-apis","text":"Log in to your Google account and Activate a 12 months free trial Google Cloud Platform services Create a Project to store your credentials and billing information Click Select a project to create new project or use existing project Enable Google Speech API Expand the menu on the left Go to APIs & Service > Libraries Find the Cloud Speech API and click Enable to enable the Google Cloud Speech API Enable Google Cloud Storage and Google Cloud Storage JSON API Go to APIs & Service > Libraries Find Google Cloud Storage and Google Cloud Storage JSON API and enable them if there are not. Create a cloud storage bucket. This is where you will temporary host the files you want to transcribe Go to your Google Cloud Dashboard Expand the menu on the left Go to Storage > Browser Click CREATE BUCKET to create a bucket for the selected project","title":"Step 1: Activate Google Speech and Google Cloud Storage APIs"},{"location":"modules/googlespeechtranscripts/#step-2-get-google-cloud-credentials","text":"Go to your Google Cloud Dashboard Expand the menu on the left Go to APIs & Service > Credentials Click on the tab OAuth Consent Screen Fill in a Project name and Save it. Don't worry about the other fields. Go back to Credentials Click the button that says Create Credentials select OAuth Client ID Choose Web Application and give it a name. Add https://developers.google.com/oauthplayground in Authorized redirect URIs . You will need to use this in the next step to get your refresh token Click Create and take note of your Client ID and Client Secret","title":"Step 2: Get Google Cloud credentials"},{"location":"modules/googlespeechtranscripts/#getting-your-refresh-token-and-authorization-enpdpoint","text":"Go to https://developers.google.com/oauthplayground (Make sure you added this URL to your Authorized redirect URIs in the previous step.) In the top right corner, click the settings icon Take note of your Token endpoint . It is the token endpoint url needed for the configuration. Make sure the Access token location is set to Authorization header w/ Bearer prefix Make sure Access type is set to Offline Make sure Force prompt is set to 'Consent Screen' Check Use your own OAuth credentials Paste your Client ID and Client Secret created previously. Close the settings. Select the scope of your APIs Click Step 1 Select & authorize APIs tab on the left Find Cloud Speech API v1 and click on https://www.googleapis.com/auth/cloud-platform to select it. Find Cloud Storage API v1 from the list, expand it and click on https://www.googleapis.com/auth/devstorage.full_control to select it Find Cloud Storage JSON API v1 expand it and select https://www.googleapis.com/auth/devstorage.full_control Click Authorize APIs , allow access to your account when prompted. There will be a few warning prompts, just proceed. (On some browser you may need to click the advanced option before you can proceed to next page) When you get to step 2 Exchange authorization code for tokens tab, click Exchange authorization code for tokens . You will need the OAuth Client ID, OAuth Client secret ,the Refresh token and Token endpoint for the configuration file","title":"Getting your Refresh Token and Authorization enpdpoint"},{"location":"modules/googlespeechtranscripts/#step-3-configure-googlespeechtranscriptionservice","text":"Edit etc/org.opencastproject.transcription.googlespeech.GoogleSpeechTranscriptionService.cfg : Set enabled =true Use OAuth Client ID , OAuth Client secret , Refresh token , Token endpoint and storage bucket created above to respectively set google.cloud.client.id , google.cloud.client.secret , google.cloud.refresh.token , google.cloud.token.endpoint.url and google.cloud.storage.bucket Enter the appropriate language in google.speech.language , default is ( en-US ). List of supported language: https://cloud.google.com/speech-to-text/docs/languages Remove profanity (bad language) from transcription by using google.speech.profanity.filter , default is ( false ), not removed by default In workflow , enter the workflow definition id of the workflow to be used to attach the generated transcripts/captions Enter a notification.email to get job failure notifications. If not entered, the email in etc/custom.properties (org.opencastproject.admin.email) will be used. If no email address specified in either notification.email or org.opencastproject.admin.email , email notifications will be disabled. Example of configuration file: # Change enabled to true to enable this service. enabled=false # Google Cloud Service details google.cloud.client.id=<OAUTH_CLIENT_ID> google.cloud.client.secret=<OAUTH_CLIENT_SECRET> google.cloud.refresh.token=1<REFRESH_TOKEN> google.cloud.token.endpoint.url=<TOKEN_ENDPOINT> # google cloud storage bucket google.cloud.storage.bucket=<BUCKET_NAME> # Language of the supplied audio. See the Google Speech-to-Text service documentation # for available languages. If empty, the default will be used (\"en-US\"). google.speech.language= # Filter out profanities from result. Default is false google.speech.profanity.filter=false # Workflow to be executed when results are ready to be attached to media package. workflow=google-speech-attach-transcripts # Interval the workflow dispatcher runs to start workflows to attach transcripts to the media package # after the transcription job is completed. # (in seconds) Default is 1 minute. workflow.dispatch.interval=60 # How long it should wait to check jobs after their start date + track duration has passed. # The default is 5 minutes. # (in seconds) completion.check.buffer=300 # How long to wait after a transcription is supposed to finish before marking the job as # cancelled in the database. Default is 5 hours. # (in seconds) max.processing.time=18000 # How long to keep result files in the working file repository in days. # The default is 7 days. cleanup.results.days=7 # Email to send notifications of errors. If not entered, the value from # org.opencastproject.admin.email in custom.properties will be used. notification.email=localadmin@domain","title":"Step 3: Configure GoogleSpeechTranscriptionService"},{"location":"modules/googlespeechtranscripts/#step-4-add-encoding-profile-for-extracting-audio","text":"The Google Speech-to-Text service has limitations on audio types. Supported audio type are here . By default Opencast will use the encoding settings in etc/encoding/googlespeech-audio.properties.","title":"Step 4: Add encoding profile for extracting audio"},{"location":"modules/googlespeechtranscripts/#step-5-add-workflow-operations-and-create-new-workflow","text":"Add the following operations to your workflow. We suggest adding them after the media package is published so that users can watch videos without having to wait for the transcription to finish, but it depends on your use case. The only requirement is to take a snapshot of the media package so that the second workflow can retrieve it from the archive to attach the caption/transcripts. <!-- Encode audio to flac --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-flavor\">audio/flac</configuration> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-flac</configuration> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start Google Speech transcription job --> <operation id=\"google-speech-start-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start Google Speech transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mediapackage already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/timedtext</configuration> <configuration key=\"language-code\">en-US</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation>","title":"Step 5: Add workflow operations and create new workflow"},{"location":"modules/googlespeechtranscripts/#step-6-create-a-workflow-that-will-add-the-generated-captiontranscript-to-the-media-package-and-republish-it","text":"A sample one can be found in etc/workflows/google-speech-attach-transcripts.xml <!-- Attach caption/transcript --> <operation id=\"google-speech-attach-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Attach captions/transcription\"> <configurations> <!-- This is filled out by the transcription service when starting this workflow --> <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration> <configuration key=\"line-size\">80</configuration> <configuration key=\"target-flavor\">captions/timedtext</configuration> <configuration key=\"target-tag\">archive</configuration> <configuration key=\"target-caption-format\">vtt</configuration> </configurations> </operation> <!-- Publish to engage player --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Distribute and publish to engage server\"> <configurations> <configuration key=\"download-source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">false</configuration> </configurations> </operation> <!-- Publish to oaipmh --> <operation id=\"republish-oaipmh\" exception-handler-workflow=\"partial-error\" description=\"Update recording metadata in default OAI-PMH repository\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Step 6: Create a workflow that will add the generated caption/transcript to the media package and republish it"},{"location":"modules/googlespeechtranscripts/#workflow-operations","text":"google-speech-attach-transcription google-speech-start-transcription","title":"Workflow Operations"},{"location":"modules/liveschedule/","text":"Live Schedule Service Overview The Live Schedule Service manages a live event in the Search index on the engage server. When an event is scheduled and the publishLive configuration is set, a live media package is published to the Search index. The live media package contains track(s) with live streaming urls. The live media package is retracted from the Search index when the capture finishes or if it fails. If event metadata, such as title or duration, are updated, the live media package in the Search index is updated accordingly. Pre-requisites To use this service, you need to have: A streaming server (Wowza, Adobe Media Server) or CDN already set up to stream live content A capture agent capable of streaming to it A player capable of playing live streams. The Paella player using the Flash component supports the rtmp protocol. Other players/protocols have not been tested. Configuration Step 1: Configure the service Edit etc/org.opencastproject.liveschedule.impl.LiveScheduleServiceImpl.cfg . If your capture agent does not register a capture.device.live.resolution.WIDTHxHEIGHT property, it's mandatory to configure the live.streamingUrl . The live.streamingUrl should be set to your streaming server url (or the subscriber url specified by your CDN). This is the url that the player will use to play the live stream. For instance, if using rtmp, set it to something like: rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION/ # Configuration for the Live Schedule Service # # If the capture agent doesn't register the capture.device.live.resolution.WIDTHxHEIGHT property, # specify live.streamingUrl, live.resolution, and live.streamName below: # # ----------------------------- # The streaming base url e.g. rtmp://streaming.server/live/ #live.streamingUrl=rtmp://streaming.server/live # If a comma-separated list is provided, several resolutions will be generated for each flavor live.resolution=1920x540,960x270 # Possible variable substitutions: # #{id} = media package id # #{flavor} = type-subtype of flavor # #{caName} = capture agent name # #{resolution} = video resolution e.g. 1920x1080 #live.streamName=#{id}-#{flavor}.stream live.streamName=#{caName}-#{flavor}.stream-#{resolution} # ----------------------------- # The same mime-type applies to all flavors and resolutions live.mimeType=video/x-flv # If a comma-separated list is provided, several streams links will be generated, one for each # resolution-targetFlavor combination. # Default is presenter/delivery #live.targetFlavors=presenter/delivery # The distribution service to use: download or aws.s3 live.distributionService=download # A list of combinations with target flavor and resolution for which streaming URIs should be published. # For example: live.publishStreaming=presenter/delivery:1920x540 # Default is not to publish streaming URIs # live.publishStreaming= Step 2: Configure the capture agent Capture agent does not register the capture.device.live.resolution.WIDTHxHEIGHT property Configure the capture agent to stream to your streaming server (or the publisher url specified by your CDN), using the same stream name specified in live.streamName. Capture agent registers the capture.device.live.resolution.WIDTHxHEIGHT property If your capture agent supports configuring custom capture agent properties, instead of configuring the live.streamingUrl, live.resolution, live.streamName, you can update the capture agent firmware to pass the following when registering to Opencast: capture.device.names: add 'live' to the current list of devices capture.device.live.resolution.WIDTHxHEIGHT=STREAMING_URL_USED_BY_PLAYER: one for each desired stream Then, the LiveScheduleService will generate as many live tracks as the resolutions registered, with their streaming urls, using 'presenter/delivery' (or the flavor configured, but only one flavor can be used). If a property capture.device.live.resolution.WIDTHxHEIGHT was registered, it will take precedence over the LiveScheduleService configuration. Example 1: Capture agent does not register with capture.device.live.resolution.WIDTHxHEIGHT If: live.streamingUrl=rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION live.streamName=#{caName}-#{flavor}.stream live.targetFlavors=presenter/delivery capture agent name: ca01 Then, the capture agent should stream to ('/' is replaced by '-'): rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION/ca01-presenter-delivery.stream Note: Please refer to your streaming server or CDN documentation for the correct syntax of the streaming url. The live.streamingUrl may be very different from the url the capture agent streams to. For instance, with Akamai, the url used by the player will be something like live.streamingUrl=rtmp://xyz.live.edgefcs.net/live/ and the capture agent's publish url something like rtmp://a.bcd.e.akamaientrypoint.net/EntryPoint. The stream name should always match. Example 2: Capture agent registers with capture.device.live.resolution.WIDTHxHEIGHT If the capture agent registers itself with: property key value capture.device.names presentation,presenter,live capture.device.presentation.flavor presentation/source capture.device.presenter.flavor presenter/source capture.device.live.resolution.1920x540 rtmp://xyz.live.edgefcs.net/live/presenter.stream-1920x540@12345 capture.device.live.resolution.960x270 rtmp://xyz.live.edgefcs.net/live/presenter.stream-960x270@12345 The LiveScheduleService will generate a media package with two live tracks having the following urls: rtmp://xyz.live.edgefcs.net/live/presenter.stream-1920x540@12345 rtmp://xyz.live.edgefcs.net/live/presenter.stream-960x270@12345 Step 3: Configure the Workflow When scheduling a live event via the admin UI, the workflow needs to have the publishLive configuration set to true (this is already included in the sample workflows). If not using the sample Opencast workflows, add to the <configuration_panel> : <fieldset> <legend>Publish live stream:</legend> <ul> <li> <input id=\"publishLive\" name=\"publishLive\" type=\"checkbox\" class=\"configField\" value=\"false\" /> <label for=\"publishLive\">Add live event to Opencast Media Module</label> </li> </ul> </fieldset> And to the defaults operation: <operation id=\"defaults\" description=\"Applying default configuration values\"> <configurations> <configuration key=\"comment\">false</configuration> <configuration key=\"publishToMediaModule\">true</configuration> <configuration key=\"publishToOaiPmh\">true</configuration> <configuration key=\"uploadedSearchPreview\">false</configuration> <configuration key=\"publishLive\">false</configuration> </configurations> </operation>","title":"Live Schedule"},{"location":"modules/liveschedule/#live-schedule-service","text":"","title":"Live Schedule Service"},{"location":"modules/liveschedule/#overview","text":"The Live Schedule Service manages a live event in the Search index on the engage server. When an event is scheduled and the publishLive configuration is set, a live media package is published to the Search index. The live media package contains track(s) with live streaming urls. The live media package is retracted from the Search index when the capture finishes or if it fails. If event metadata, such as title or duration, are updated, the live media package in the Search index is updated accordingly.","title":"Overview"},{"location":"modules/liveschedule/#pre-requisites","text":"To use this service, you need to have: A streaming server (Wowza, Adobe Media Server) or CDN already set up to stream live content A capture agent capable of streaming to it A player capable of playing live streams. The Paella player using the Flash component supports the rtmp protocol. Other players/protocols have not been tested.","title":"Pre-requisites"},{"location":"modules/liveschedule/#configuration","text":"","title":"Configuration"},{"location":"modules/liveschedule/#step-1-configure-the-service","text":"Edit etc/org.opencastproject.liveschedule.impl.LiveScheduleServiceImpl.cfg . If your capture agent does not register a capture.device.live.resolution.WIDTHxHEIGHT property, it's mandatory to configure the live.streamingUrl . The live.streamingUrl should be set to your streaming server url (or the subscriber url specified by your CDN). This is the url that the player will use to play the live stream. For instance, if using rtmp, set it to something like: rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION/ # Configuration for the Live Schedule Service # # If the capture agent doesn't register the capture.device.live.resolution.WIDTHxHEIGHT property, # specify live.streamingUrl, live.resolution, and live.streamName below: # # ----------------------------- # The streaming base url e.g. rtmp://streaming.server/live/ #live.streamingUrl=rtmp://streaming.server/live # If a comma-separated list is provided, several resolutions will be generated for each flavor live.resolution=1920x540,960x270 # Possible variable substitutions: # #{id} = media package id # #{flavor} = type-subtype of flavor # #{caName} = capture agent name # #{resolution} = video resolution e.g. 1920x1080 #live.streamName=#{id}-#{flavor}.stream live.streamName=#{caName}-#{flavor}.stream-#{resolution} # ----------------------------- # The same mime-type applies to all flavors and resolutions live.mimeType=video/x-flv # If a comma-separated list is provided, several streams links will be generated, one for each # resolution-targetFlavor combination. # Default is presenter/delivery #live.targetFlavors=presenter/delivery # The distribution service to use: download or aws.s3 live.distributionService=download # A list of combinations with target flavor and resolution for which streaming URIs should be published. # For example: live.publishStreaming=presenter/delivery:1920x540 # Default is not to publish streaming URIs # live.publishStreaming=","title":"Step 1: Configure the service"},{"location":"modules/liveschedule/#step-2-configure-the-capture-agent","text":"","title":"Step 2: Configure the capture agent"},{"location":"modules/liveschedule/#capture-agent-does-not-register-the-capturedeviceliveresolutionwidthxheight-property","text":"Configure the capture agent to stream to your streaming server (or the publisher url specified by your CDN), using the same stream name specified in live.streamName.","title":"Capture agent does not register the capture.device.live.resolution.WIDTHxHEIGHT property"},{"location":"modules/liveschedule/#capture-agent-registers-the-capturedeviceliveresolutionwidthxheight-property","text":"If your capture agent supports configuring custom capture agent properties, instead of configuring the live.streamingUrl, live.resolution, live.streamName, you can update the capture agent firmware to pass the following when registering to Opencast: capture.device.names: add 'live' to the current list of devices capture.device.live.resolution.WIDTHxHEIGHT=STREAMING_URL_USED_BY_PLAYER: one for each desired stream Then, the LiveScheduleService will generate as many live tracks as the resolutions registered, with their streaming urls, using 'presenter/delivery' (or the flavor configured, but only one flavor can be used). If a property capture.device.live.resolution.WIDTHxHEIGHT was registered, it will take precedence over the LiveScheduleService configuration.","title":"Capture agent registers the capture.device.live.resolution.WIDTHxHEIGHT property"},{"location":"modules/liveschedule/#example-1","text":"","title":"Example 1:"},{"location":"modules/liveschedule/#capture-agent-does-not-register-with-capturedeviceliveresolutionwidthxheight","text":"If: live.streamingUrl=rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION live.streamName=#{caName}-#{flavor}.stream live.targetFlavors=presenter/delivery capture agent name: ca01 Then, the capture agent should stream to ('/' is replaced by '-'): rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION/ca01-presenter-delivery.stream Note: Please refer to your streaming server or CDN documentation for the correct syntax of the streaming url. The live.streamingUrl may be very different from the url the capture agent streams to. For instance, with Akamai, the url used by the player will be something like live.streamingUrl=rtmp://xyz.live.edgefcs.net/live/ and the capture agent's publish url something like rtmp://a.bcd.e.akamaientrypoint.net/EntryPoint. The stream name should always match.","title":"Capture agent does not register with capture.device.live.resolution.WIDTHxHEIGHT"},{"location":"modules/liveschedule/#example-2","text":"","title":"Example 2:"},{"location":"modules/liveschedule/#capture-agent-registers-with-capturedeviceliveresolutionwidthxheight","text":"If the capture agent registers itself with: property key value capture.device.names presentation,presenter,live capture.device.presentation.flavor presentation/source capture.device.presenter.flavor presenter/source capture.device.live.resolution.1920x540 rtmp://xyz.live.edgefcs.net/live/presenter.stream-1920x540@12345 capture.device.live.resolution.960x270 rtmp://xyz.live.edgefcs.net/live/presenter.stream-960x270@12345 The LiveScheduleService will generate a media package with two live tracks having the following urls: rtmp://xyz.live.edgefcs.net/live/presenter.stream-1920x540@12345 rtmp://xyz.live.edgefcs.net/live/presenter.stream-960x270@12345","title":"Capture agent registers with capture.device.live.resolution.WIDTHxHEIGHT"},{"location":"modules/liveschedule/#step-3-configure-the-workflow","text":"When scheduling a live event via the admin UI, the workflow needs to have the publishLive configuration set to true (this is already included in the sample workflows). If not using the sample Opencast workflows, add to the <configuration_panel> : <fieldset> <legend>Publish live stream:</legend> <ul> <li> <input id=\"publishLive\" name=\"publishLive\" type=\"checkbox\" class=\"configField\" value=\"false\" /> <label for=\"publishLive\">Add live event to Opencast Media Module</label> </li> </ul> </fieldset> And to the defaults operation: <operation id=\"defaults\" description=\"Applying default configuration values\"> <configurations> <configuration key=\"comment\">false</configuration> <configuration key=\"publishToMediaModule\">true</configuration> <configuration key=\"publishToOaiPmh\">true</configuration> <configuration key=\"uploadedSearchPreview\">false</configuration> <configuration key=\"publishLive\">false</configuration> </configurations> </operation>","title":"Step 3: Configure the Workflow"},{"location":"modules/ltimodule/","text":"Integrating Opencast using LTI About LTI LTI provides an easy way to integrate Opencast into any system which can act as an LTI tool consumer such as many learning management systems (LMS). Popular examples for LTI consumers include Sakai , Moodle or ILIAS . Using the LTI integration, students can access Opencast through an LTI tool in the LMS course site, and can play back Opencast videos without ever leaving their course. More information about the LTI specification is available at IMS Learning Tools Interoperability . Configuration Configure OAuth LTI uses OAuth to authenticate users. To enable OAuth in Opencast, edit etc/security/mh_default_org.xml and uncomment the oauthProtectedResourceFilter in the authentication filters section: <ref bean=\"oauthProtectedResourceFilter\" /> Next, configure the OAuth consumer by setting custom credentials in etc/org.opencastproject.kernel.security.OAuthConsumerDetailsService.cfg : oauth.consumer.name.1=CONSUMERNAME oauth.consumer.key.1=CONSUMERKEY oauth.consumer.secret.1=CONSUMERSECRET Configure LTI Opencast's LTI module allows additional configuration like making a OAuth consumer key a highly trusted key, preventing Opencast from generating a temporary username, or to block some specific usernames like the system administrator. For more details, take a look at the options in etc/org.opencastproject.kernel.security.LtiLaunchAuthenticationHandler.cfg . Configure and test an LTI tool in the LMS Configure an LTI tool in the LMS with these values: LTI launch URL: <presentation-node-url>/lti LTI key: the value of oauth.consumer.key LTI secret: the value of oauth.consumer.secret Access the LTI tool configured for Opencast in the LMS. The Opencast LTI welcome page should appear. Use the links provided there to verify the LTI connection. LTI Roles LTI users will only see Opencast series and videos which are public, or those to which they have access because of the Opencast roles which they have. The Opencast LTI module grants an LTI user the role(s) formed from the LTI parameters context_id and roles . The LTI context is typically the LMS course ID, and the default LTI role for a student in a course is Learner . The Opencast role granted would therefore be SITEID_Learner . To make a series or video visible to students who access Opencast through LTI in an LMS course, add the role SITEID_Learner to the Series or Event Access Control List (ACL). LTI users may also have additional roles if the LTI user is created as an Opencast user in the Admin UI and given additional roles, or if one or more Opencast User Providers or Role Providers are configured. Specifying LTI Tools Opencast will redirect an LTI user to the URL specified by the LTI custom tool parameter. Some LMS systems allow custom parameters to be defined separately in each place where an LTI tool is used, whereas other systems only allow custom parameters to be defined globally. To show the media module, use tool=engage/ui/ To show all videos for a single series, use tool=ltitools/series/index.html?series=SERIESID To show a single video, use tool=/play/MEDIAPACKAGEID To show a debug page before proceeding to the tool, append the parameter test=true For more information about how to set custom LTI parameters, please check the documentation of your LMS. Series LTI Tool Opencast's series LTI tool provides the option to provide custom style sheets for configuring the look and feel of the tool which may be important to match the design of the LTI consumer in which it is included. The CSS file can be found in the user interface configuration directory usually located at: etc/ui-config/mh_default_org/ltitools/series.css","title":"LTI Module"},{"location":"modules/ltimodule/#integrating-opencast-using-lti","text":"","title":"Integrating Opencast using LTI"},{"location":"modules/ltimodule/#about-lti","text":"LTI provides an easy way to integrate Opencast into any system which can act as an LTI tool consumer such as many learning management systems (LMS). Popular examples for LTI consumers include Sakai , Moodle or ILIAS . Using the LTI integration, students can access Opencast through an LTI tool in the LMS course site, and can play back Opencast videos without ever leaving their course. More information about the LTI specification is available at IMS Learning Tools Interoperability .","title":"About LTI"},{"location":"modules/ltimodule/#configuration","text":"","title":"Configuration"},{"location":"modules/ltimodule/#configure-oauth","text":"LTI uses OAuth to authenticate users. To enable OAuth in Opencast, edit etc/security/mh_default_org.xml and uncomment the oauthProtectedResourceFilter in the authentication filters section: <ref bean=\"oauthProtectedResourceFilter\" /> Next, configure the OAuth consumer by setting custom credentials in etc/org.opencastproject.kernel.security.OAuthConsumerDetailsService.cfg : oauth.consumer.name.1=CONSUMERNAME oauth.consumer.key.1=CONSUMERKEY oauth.consumer.secret.1=CONSUMERSECRET","title":"Configure OAuth"},{"location":"modules/ltimodule/#configure-lti","text":"Opencast's LTI module allows additional configuration like making a OAuth consumer key a highly trusted key, preventing Opencast from generating a temporary username, or to block some specific usernames like the system administrator. For more details, take a look at the options in etc/org.opencastproject.kernel.security.LtiLaunchAuthenticationHandler.cfg .","title":"Configure LTI"},{"location":"modules/ltimodule/#configure-and-test-an-lti-tool-in-the-lms","text":"Configure an LTI tool in the LMS with these values: LTI launch URL: <presentation-node-url>/lti LTI key: the value of oauth.consumer.key LTI secret: the value of oauth.consumer.secret Access the LTI tool configured for Opencast in the LMS. The Opencast LTI welcome page should appear. Use the links provided there to verify the LTI connection.","title":"Configure and test an LTI tool in the LMS"},{"location":"modules/ltimodule/#lti-roles","text":"LTI users will only see Opencast series and videos which are public, or those to which they have access because of the Opencast roles which they have. The Opencast LTI module grants an LTI user the role(s) formed from the LTI parameters context_id and roles . The LTI context is typically the LMS course ID, and the default LTI role for a student in a course is Learner . The Opencast role granted would therefore be SITEID_Learner . To make a series or video visible to students who access Opencast through LTI in an LMS course, add the role SITEID_Learner to the Series or Event Access Control List (ACL). LTI users may also have additional roles if the LTI user is created as an Opencast user in the Admin UI and given additional roles, or if one or more Opencast User Providers or Role Providers are configured.","title":"LTI Roles"},{"location":"modules/ltimodule/#specifying-lti-tools","text":"Opencast will redirect an LTI user to the URL specified by the LTI custom tool parameter. Some LMS systems allow custom parameters to be defined separately in each place where an LTI tool is used, whereas other systems only allow custom parameters to be defined globally. To show the media module, use tool=engage/ui/ To show all videos for a single series, use tool=ltitools/series/index.html?series=SERIESID To show a single video, use tool=/play/MEDIAPACKAGEID To show a debug page before proceeding to the tool, append the parameter test=true For more information about how to set custom LTI parameters, please check the documentation of your LMS.","title":"Specifying LTI Tools"},{"location":"modules/ltimodule/#series-lti-tool","text":"Opencast's series LTI tool provides the option to provide custom style sheets for configuring the look and feel of the tool which may be important to match the design of the LTI consumer in which it is included. The CSS file can be found in the user interface configuration directory usually located at: etc/ui-config/mh_default_org/ltitools/series.css","title":"Series LTI Tool"},{"location":"modules/mediamodule.configuration/","text":"Media Module Configuration The media module is the default overview of the distributed media files. The configurations for the media module are done for each tenant. So the configuration keys are located in etc/org.opencastproject.organization-mh_default_org.cfg : prop.logo_mediamodule This logo file will be displayed in the upper left of the media module page Default: Opencast logo prop.player The player that should be use to play the videos. Default: Theodul player","title":"Media Module"},{"location":"modules/mediamodule.configuration/#media-module-configuration","text":"The media module is the default overview of the distributed media files. The configurations for the media module are done for each tenant. So the configuration keys are located in etc/org.opencastproject.organization-mh_default_org.cfg : prop.logo_mediamodule This logo file will be displayed in the upper left of the media module page Default: Opencast logo prop.player The player that should be use to play the videos. Default: Theodul player","title":"Media Module Configuration"},{"location":"modules/player.configuration/","text":"Opencast Player - Configuration The configurations for the player are done for each tenant. So the configuration keys are located in .../etc/ui-config/<tenant>/theodul/config.yml The default tenant for opencast is mh_default_org Select the Opencast Player To activate the player set in each tenant this line in the file .../etc/org.opencastproject.organization-<tenant>.cfg . prop.player=/engage/theodul/ui/core.html?id=#{id}","title":"Configuration"},{"location":"modules/player.configuration/#opencast-player-configuration","text":"The configurations for the player are done for each tenant. So the configuration keys are located in .../etc/ui-config/<tenant>/theodul/config.yml The default tenant for opencast is mh_default_org","title":"Opencast Player - Configuration"},{"location":"modules/player.configuration/#select-the-opencast-player","text":"To activate the player set in each tenant this line in the file .../etc/org.opencastproject.organization-<tenant>.cfg . prop.player=/engage/theodul/ui/core.html?id=#{id}","title":"Select the Opencast Player"},{"location":"modules/player.matomo.tracking/","text":"Opencast Player - Matomo Tracking Plugin This plugin allows to use Matomo (https://matomo.org/), formerly known as Piwik, to track usage data. To setup Matomo please follow the instructions on the Matomo website: https://matomo.org/docs/installation/#the-5-minute-matomo-installation The plugin respects the Do-Not-Track settings of a browser. You might also need to consider the legal requirements of your country when you setup Matomo. This plugin uses a Matomo javascript library that is loaded from the remote Matomo server! Tested Matomo version: 3.0.2+ The configurations for the Matomo player plugin are done for each tenant. So the configuration keys are located in .../etc/org.opencastproject.organization-mh_default_org.cfg . To activate the plugin set: prop.player.matomo.server=http://localhost/matomo Where localhost should be replaced with your Piwik server URL. Configuration prop.player.matomo.server The plugin shows a notification about the tracking to the user. This can be disabled with this option. (Default: true) Before you disable the notification, make sure that you do not violate any local regulations. prop.player.matomo.server The Matomo server from which the Piwik JS library will be loaded and where the data will be reported. prop.player.matomo.site_id=1 The Matomo site ID has to be numeric value. If not set this will be 1. It is recommended to use different site IDs for each tenant that is configured in Opencast. prop.player.matomo.heartbeat=30 The heartbeat setting to track how long a user stayed on the player page. Set to 0 or comment this line to disable the heartbeat. prop.player.matomo.track_events This setting lets you track several player events. Add the events that you want to track to the list. Comment this property to prevent event tracking. Events that can be tracked: play: play has been pressed (will also be called if after seeking). pause: pause has been pressend (will also be called if before seeking). seek: user jumps to a different time. Time in seconds will be stored ended: video has reached the end playbackrate: user changes the playback speed (values 0.75 to 3.00) volume: Volume change by the user value 0.0 to 1.0 quality: manual change of video quality (quality tag is stored) fullscreen: user presses fullscreen button focus: user selects one video to be enlarged (flavor of selected video is stored) layout_reset: user switches back to default layout zoom: user changes the zoom of the video Tracked Data Additional to the event data that can be turned on for each event (see above), this Opencast specific data is tracked if tracking is allowed: Page name as \" - \" Custom Matomo variables: \"event\" as \" ( )\" \"series\" as \" ( )\" \"presenter\" \"view_mode\" which can be \"desktop\", \"mobile\" or \"embed\" Heartbeat data does not show how long a video has been played but how long a viewer remained on the page, while the page was in the foreground.","title":"Matomo Tracking"},{"location":"modules/player.matomo.tracking/#opencast-player-matomo-tracking-plugin","text":"This plugin allows to use Matomo (https://matomo.org/), formerly known as Piwik, to track usage data. To setup Matomo please follow the instructions on the Matomo website: https://matomo.org/docs/installation/#the-5-minute-matomo-installation The plugin respects the Do-Not-Track settings of a browser. You might also need to consider the legal requirements of your country when you setup Matomo. This plugin uses a Matomo javascript library that is loaded from the remote Matomo server! Tested Matomo version: 3.0.2+ The configurations for the Matomo player plugin are done for each tenant. So the configuration keys are located in .../etc/org.opencastproject.organization-mh_default_org.cfg . To activate the plugin set: prop.player.matomo.server=http://localhost/matomo Where localhost should be replaced with your Piwik server URL.","title":"Opencast Player - Matomo Tracking Plugin"},{"location":"modules/player.matomo.tracking/#configuration","text":"","title":"Configuration"},{"location":"modules/player.matomo.tracking/#propplayermatomoserver","text":"The plugin shows a notification about the tracking to the user. This can be disabled with this option. (Default: true) Before you disable the notification, make sure that you do not violate any local regulations.","title":"prop.player.matomo.server"},{"location":"modules/player.matomo.tracking/#propplayermatomoserver_1","text":"The Matomo server from which the Piwik JS library will be loaded and where the data will be reported.","title":"prop.player.matomo.server"},{"location":"modules/player.matomo.tracking/#propplayermatomosite_id1","text":"The Matomo site ID has to be numeric value. If not set this will be 1. It is recommended to use different site IDs for each tenant that is configured in Opencast.","title":"prop.player.matomo.site_id=1"},{"location":"modules/player.matomo.tracking/#propplayermatomoheartbeat30","text":"The heartbeat setting to track how long a user stayed on the player page. Set to 0 or comment this line to disable the heartbeat.","title":"prop.player.matomo.heartbeat=30"},{"location":"modules/player.matomo.tracking/#propplayermatomotrack_events","text":"This setting lets you track several player events. Add the events that you want to track to the list. Comment this property to prevent event tracking. Events that can be tracked: play: play has been pressed (will also be called if after seeking). pause: pause has been pressend (will also be called if before seeking). seek: user jumps to a different time. Time in seconds will be stored ended: video has reached the end playbackrate: user changes the playback speed (values 0.75 to 3.00) volume: Volume change by the user value 0.0 to 1.0 quality: manual change of video quality (quality tag is stored) fullscreen: user presses fullscreen button focus: user selects one video to be enlarged (flavor of selected video is stored) layout_reset: user switches back to default layout zoom: user changes the zoom of the video","title":"prop.player.matomo.track_events"},{"location":"modules/player.matomo.tracking/#tracked-data","text":"Additional to the event data that can be turned on for each event (see above), this Opencast specific data is tracked if tracking is allowed: Page name as \" - \" Custom Matomo variables: \"event\" as \" ( )\" \"series\" as \" ( )\" \"presenter\" \"view_mode\" which can be \"desktop\", \"mobile\" or \"embed\" Heartbeat data does not show how long a video has been played but how long a viewer remained on the page, while the page was in the foreground.","title":"Tracked Data"},{"location":"modules/player.url.parameter/","text":"Opencast Player * URL Parameters URL Parameters time Possible values Minutes (with value X ) and seconds (with value Y ) XmYs YsXm XmY Minutes (with value X ) only Xm Seconds (with value Y ) only Ys Y Default value - Description Seeks intially automatically to a specified time automatically plays the video from the specified time on autoplay Possible values true false Default value false Description Automatically starts playing the video after a short delay quality Possible values low medium high Default value medium Description Sets a video quality if the video has been encoded in multiple qualities mode Possible values desktop embed mobile Default value desktop Description Sets the player mode manually browser Possible values all default Default value default Description If your browser is not supported, try the new player with this flag activated overwrites filtering for supported browsers with parameter set to all Example http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&time=3m30s Developer URL Parameters debug Possible values true false Default value false Description prints debug output to the developer console debugEvents Possible values true false Default value false Description Prints debug output to the developer console when an event occurs format Possible Values hls : Apple HTTP Live Streaming dash : MPEG DASH rtmp : Adobe RTMP (Flash) mp4 : MP4 videos (no streaming) webm : WebM videos (no streaming) audio : audio only (no streaming) default : reset to defaults Default value default Description sets the preferred (streaming) format if not available, the defaults will be selected the value is permanently stored for the browser in the local storage Example http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&debug=true&debugEvents=true","title":"URL Parameters"},{"location":"modules/player.url.parameter/#opencast-player-url-parameters","text":"","title":"Opencast Player * URL Parameters"},{"location":"modules/player.url.parameter/#url-parameters","text":"time Possible values Minutes (with value X ) and seconds (with value Y ) XmYs YsXm XmY Minutes (with value X ) only Xm Seconds (with value Y ) only Ys Y Default value - Description Seeks intially automatically to a specified time automatically plays the video from the specified time on autoplay Possible values true false Default value false Description Automatically starts playing the video after a short delay quality Possible values low medium high Default value medium Description Sets a video quality if the video has been encoded in multiple qualities mode Possible values desktop embed mobile Default value desktop Description Sets the player mode manually browser Possible values all default Default value default Description If your browser is not supported, try the new player with this flag activated overwrites filtering for supported browsers with parameter set to all","title":"URL Parameters"},{"location":"modules/player.url.parameter/#example","text":"http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&time=3m30s","title":"Example"},{"location":"modules/player.url.parameter/#developer-url-parameters","text":"debug Possible values true false Default value false Description prints debug output to the developer console debugEvents Possible values true false Default value false Description Prints debug output to the developer console when an event occurs format Possible Values hls : Apple HTTP Live Streaming dash : MPEG DASH rtmp : Adobe RTMP (Flash) mp4 : MP4 videos (no streaming) webm : WebM videos (no streaming) audio : audio only (no streaming) default : reset to defaults Default value default Description sets the preferred (streaming) format if not available, the defaults will be selected the value is permanently stored for the browser in the local storage","title":"Developer URL Parameters"},{"location":"modules/player.url.parameter/#example_1","text":"http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&debug=true&debugEvents=true","title":"Example"},{"location":"modules/stream-security/","text":"Stream Security Introduction Security usually is a challenging, technically aspects of any software system. However, diving into technical details before understanding the principles of the solution can lead to false assumptions about the level of security in place. Therefore, this section provides a high-level overview of Opencast's stream security functionality. Content Security in Opencast In many settings, some or even all content published by an Opencast installation must not be accessible by everyone. Instead, access should be restricted to those users with corresponding permissions. So, if access control already ensures that each user only has access to the recordings he or she is allowed to see, what does stream security add to the mix? Looking more closely at what it means to serve recordings to a viewer reveals that a distinction needs to be made between: the presentation of the video player, the recording metadata the serving of the video streams, preview images etc. to that player. The former is protected by the engage part of Opencast. The latter may be served by download and streaming servers. Those distribution servers are independent of Opencast and have no knowledge about the current user and its permissions with regard to the requested video asset . To summarize: Opencast is capable of assessing a recording\u2019s access control list and the current user\u2019s permissions to decide if a user is allowed to access the recording\u2019s metadata and the player. External download and streaming servers, serving the actual video files are not aware of these permissions. As a result, nothing prevents an authorized user from passing on the actual video and image URLs to the public, thereby circumventing the restrictions implied on the presentation layer earlier on. Securing the Streams Since the download and streaming servers do not (and should not) have access to security related information about the user, its roles nor its permissions with regard to the media files, there is no way to perform authorization checks the same way Opencast is performing them while serving up recording metadata. The only way to decide if a given request should be served or not is to leave authorization to Opencast and agree on a secure protocol that defines whether a request is meant to be granted by Opencast or not. Stream security solves the problem exactly as described: Each request that is sent to any of the download or streaming servers must contain a validation policy, indicating for how long access should be granted and optionally even from which IP address. Signing of the policy ensures that potential changes to the policy will be detected. On the other end, the server must be enabled to verify the signature and extract the policy to verify whether it should comply with the request or not. What is secured and what is not? Even with Stream security enabled, some loopholes exist where unauthorized viewers might be able to get access to protected resources, even though for a limited time only. The following section describes in detail what is and what is not secured. URL hacking Executive summary: Accessing a resource with an unsigned or incorrectly signed URL is impossible. Resources distributed by Opencast are organized in a file structure that is built upon a resource\u2019s series identifier as well as the identifier of the recording itself. Since those identifiers usually are based on UUIDs , guessing the URL is hard but not impossible. In addition, a malicious user might be getting hold of a valid identifier through network sniffing, social hacking or by other means. With Stream Security enabled, a user cannot access that resource, since the URL for accessing the resource would either be lacking the policy and signature completely or would contain a broken signature due to an identifier mismatch in the policy. It is important to note that, if stream security is enabled, all resources will be signed and protected, even ones that do not have any access restrictions defined in their access control lists. Accessing resources with unsigned URLs will not be possible. Revoking access rights Executive summary: Access is revoked once the digital signature expires. If a user has the rights to access a resource, it does not automatically mean that permission has been granted for a lifetime. After a signed URL\u2019s policy has expired, the URL must receive an updated policy and be signed again in order to provide continuous access to the corresponding resource, so in the case of revoked access rights, the user in question will be able to keep access to the resource as long as the initially signed url is valid. After that, Opencast will not provide a signed URL anymore due to the change in permissions. On the other hand, there is no way to revoke access to that resource for that particular user unless the URL expires. The only way would be to completely remove the resource from the distribution server. It is therefore important to choose reasonable expiration times for signed URLs. Unauthorized sharing of URLs Executive summary: Leaked signed URLs are only accessible for the duration of the validity of the signature. A signed URL shared by an authorized user with a non-authorized third party will expire (as explained above). The expiration time can be set as low as some seconds but will then require even authorized users to obtain newly signed URLs as they continue to access protected content (e.g. the user takes a quick break watching a recording by hitting \u201cpause\u201d, then hits \u201cplay\u201d again to resume). This risk can be lowered further by restricting a resource to a client\u2019s IP address so that it can only be played by someone with the same IP. Downloading or ripping content Executive summary: Content protected by stream security is not protected against unauthorized publication through authorized users. Since stream security does not implement digital rights management (DRM), authorized users may download content while in possession of correctly signed URLs. When that content is republished on systems that are not under the control of the original owner (i.e. are not protected by stream security or any other means), it is publicly available. Most institutions will have a policy in place that legally prevents circumventing protection and sharing of protected media, and as a result, the above scenario will be taxed as piracy. Technical Overview Stream security consists of several components, and each of these components must be installed and configured properly, otherwise the system may not behave as expected. This part of the documentation describes how each of the components need to be installed and holds information on which configuration options are available. Terms For the understanding of this document it is important to have the following terms clearly defined. Policy A policy defines the timeframe and (optionally) from which addresses a specified resource may be accessed. In order to exchange the policy between system components, the involved components must agree on a serialization specification. Signature The signature expresses the validity of a policy. As with the policy, the system\u2019s signature components, must follow a predefined signing algorithm. Only then is it possible to verify if the signature was issued for a specific policy, or if either the signature or the policy was modified. Key Using keys is a common way to protect information that is being shared between two or more systems. In stream security, keys are used to prevent signature forgery. A key consists of an identifier (ID) and a secret value. The keys need to be kept private, otherwise everyone can create signatures and thereby gain unlimited access to all resource protected by that key. Signing Protocol The combination of a policy specification and a signature algorithm forms the signing protocol, where the policy contains the rules to be applied and the signature ensures that the rules remain unaltered. Components that implement the same signing protocol are compatible and can be used in combination. Components A typical signing infrastructure consists of two main components: a signing service and a verification component. While the signing service is used to sign arbitrary URLs, the verification component is located on the distribution servers to protect the resources and only serve requests that have been properly signed. All signing providers and verification components developed by the Opencast community implement the Opencast signing protocol as documented in the developer guide and are therefore compatible. URL Signing Service The URL signing service is designed to support one or more signing implementations called signing providers. With this concept, different signing protocols, and by virtue, different verification components are supported. The resource is presented to each signing provider in turn, where it is either signed or passed on. This process continues until a signature is obtained. Out of the box, Opencast provides the following implementation: Generic Signing Provider : This provider may be used in combination with HTTP servers. It appends the necessary information (policy, signature and key id) to the URL. The URL signing service makes it straightforward to provide additional implementations to handle third party distribution servers URL signatures. This becomes important in situations where files are served by a server that is currently not supported or if files are served by a CDN that implements its own proprietary signing protocol. Verification components In order to take advantage of the signed URLs, a verification component needs to reside on the distribution servers to verify the validity of the signature (i.e. check that the URL has not been altered after it was signed) and then grant or deny access to the resource, based on the policy associated with the URL. In addition to these external verification components there is also an Opencast verification component called the UrlSigningFilter that is used to protect files that Opencast itself provides. Verification components have the option of strict or non-strict checking. Strict verification of resources means the entire URL will be considered when comparing the incoming request for a resource against the policy, including the scheme (http, https, etc.), hostname and port. If using non-strict checking, only the path to the resource will be considered. So if the request is for a resource at http://httpdserver:8080/the/full/path/video.mp4 , only the /the/full/path/video.mp4 part of the URL will be checked against the policy\u2019s path. This is useful when using a load balancer so that the requested hostname does not have to match the actual hostname or if a video player is rewriting requests, e.g. by inserting the port number. Further Information For further technical information like installation instructions, configuration guides, server plugins and the signing specification, please have a look at these documents: Stream Security Configuration & Testing The Opencast Signing Protocol is defined in the subsection Stream Security in the modules section of the developer guide.","title":"Stream Security"},{"location":"modules/stream-security/#stream-security","text":"","title":"Stream Security"},{"location":"modules/stream-security/#introduction","text":"Security usually is a challenging, technically aspects of any software system. However, diving into technical details before understanding the principles of the solution can lead to false assumptions about the level of security in place. Therefore, this section provides a high-level overview of Opencast's stream security functionality.","title":"Introduction"},{"location":"modules/stream-security/#content-security-in-opencast","text":"In many settings, some or even all content published by an Opencast installation must not be accessible by everyone. Instead, access should be restricted to those users with corresponding permissions. So, if access control already ensures that each user only has access to the recordings he or she is allowed to see, what does stream security add to the mix? Looking more closely at what it means to serve recordings to a viewer reveals that a distinction needs to be made between: the presentation of the video player, the recording metadata the serving of the video streams, preview images etc. to that player. The former is protected by the engage part of Opencast. The latter may be served by download and streaming servers. Those distribution servers are independent of Opencast and have no knowledge about the current user and its permissions with regard to the requested video asset . To summarize: Opencast is capable of assessing a recording\u2019s access control list and the current user\u2019s permissions to decide if a user is allowed to access the recording\u2019s metadata and the player. External download and streaming servers, serving the actual video files are not aware of these permissions. As a result, nothing prevents an authorized user from passing on the actual video and image URLs to the public, thereby circumventing the restrictions implied on the presentation layer earlier on.","title":"Content Security in Opencast"},{"location":"modules/stream-security/#securing-the-streams","text":"Since the download and streaming servers do not (and should not) have access to security related information about the user, its roles nor its permissions with regard to the media files, there is no way to perform authorization checks the same way Opencast is performing them while serving up recording metadata. The only way to decide if a given request should be served or not is to leave authorization to Opencast and agree on a secure protocol that defines whether a request is meant to be granted by Opencast or not. Stream security solves the problem exactly as described: Each request that is sent to any of the download or streaming servers must contain a validation policy, indicating for how long access should be granted and optionally even from which IP address. Signing of the policy ensures that potential changes to the policy will be detected. On the other end, the server must be enabled to verify the signature and extract the policy to verify whether it should comply with the request or not.","title":"Securing the Streams"},{"location":"modules/stream-security/#what-is-secured-and-what-is-not","text":"Even with Stream security enabled, some loopholes exist where unauthorized viewers might be able to get access to protected resources, even though for a limited time only. The following section describes in detail what is and what is not secured.","title":"What is secured and what is not?"},{"location":"modules/stream-security/#url-hacking","text":"Executive summary: Accessing a resource with an unsigned or incorrectly signed URL is impossible. Resources distributed by Opencast are organized in a file structure that is built upon a resource\u2019s series identifier as well as the identifier of the recording itself. Since those identifiers usually are based on UUIDs , guessing the URL is hard but not impossible. In addition, a malicious user might be getting hold of a valid identifier through network sniffing, social hacking or by other means. With Stream Security enabled, a user cannot access that resource, since the URL for accessing the resource would either be lacking the policy and signature completely or would contain a broken signature due to an identifier mismatch in the policy. It is important to note that, if stream security is enabled, all resources will be signed and protected, even ones that do not have any access restrictions defined in their access control lists. Accessing resources with unsigned URLs will not be possible.","title":"URL hacking"},{"location":"modules/stream-security/#revoking-access-rights","text":"Executive summary: Access is revoked once the digital signature expires. If a user has the rights to access a resource, it does not automatically mean that permission has been granted for a lifetime. After a signed URL\u2019s policy has expired, the URL must receive an updated policy and be signed again in order to provide continuous access to the corresponding resource, so in the case of revoked access rights, the user in question will be able to keep access to the resource as long as the initially signed url is valid. After that, Opencast will not provide a signed URL anymore due to the change in permissions. On the other hand, there is no way to revoke access to that resource for that particular user unless the URL expires. The only way would be to completely remove the resource from the distribution server. It is therefore important to choose reasonable expiration times for signed URLs.","title":"Revoking access rights"},{"location":"modules/stream-security/#unauthorized-sharing-of-urls","text":"Executive summary: Leaked signed URLs are only accessible for the duration of the validity of the signature. A signed URL shared by an authorized user with a non-authorized third party will expire (as explained above). The expiration time can be set as low as some seconds but will then require even authorized users to obtain newly signed URLs as they continue to access protected content (e.g. the user takes a quick break watching a recording by hitting \u201cpause\u201d, then hits \u201cplay\u201d again to resume). This risk can be lowered further by restricting a resource to a client\u2019s IP address so that it can only be played by someone with the same IP.","title":"Unauthorized sharing of URLs"},{"location":"modules/stream-security/#downloading-or-ripping-content","text":"Executive summary: Content protected by stream security is not protected against unauthorized publication through authorized users. Since stream security does not implement digital rights management (DRM), authorized users may download content while in possession of correctly signed URLs. When that content is republished on systems that are not under the control of the original owner (i.e. are not protected by stream security or any other means), it is publicly available. Most institutions will have a policy in place that legally prevents circumventing protection and sharing of protected media, and as a result, the above scenario will be taxed as piracy.","title":"Downloading or ripping content"},{"location":"modules/stream-security/#technical-overview","text":"Stream security consists of several components, and each of these components must be installed and configured properly, otherwise the system may not behave as expected. This part of the documentation describes how each of the components need to be installed and holds information on which configuration options are available.","title":"Technical Overview"},{"location":"modules/stream-security/#terms","text":"For the understanding of this document it is important to have the following terms clearly defined.","title":"Terms"},{"location":"modules/stream-security/#policy","text":"A policy defines the timeframe and (optionally) from which addresses a specified resource may be accessed. In order to exchange the policy between system components, the involved components must agree on a serialization specification.","title":"Policy"},{"location":"modules/stream-security/#signature","text":"The signature expresses the validity of a policy. As with the policy, the system\u2019s signature components, must follow a predefined signing algorithm. Only then is it possible to verify if the signature was issued for a specific policy, or if either the signature or the policy was modified.","title":"Signature"},{"location":"modules/stream-security/#key","text":"Using keys is a common way to protect information that is being shared between two or more systems. In stream security, keys are used to prevent signature forgery. A key consists of an identifier (ID) and a secret value. The keys need to be kept private, otherwise everyone can create signatures and thereby gain unlimited access to all resource protected by that key.","title":"Key"},{"location":"modules/stream-security/#signing-protocol","text":"The combination of a policy specification and a signature algorithm forms the signing protocol, where the policy contains the rules to be applied and the signature ensures that the rules remain unaltered. Components that implement the same signing protocol are compatible and can be used in combination.","title":"Signing Protocol"},{"location":"modules/stream-security/#components","text":"A typical signing infrastructure consists of two main components: a signing service and a verification component. While the signing service is used to sign arbitrary URLs, the verification component is located on the distribution servers to protect the resources and only serve requests that have been properly signed. All signing providers and verification components developed by the Opencast community implement the Opencast signing protocol as documented in the developer guide and are therefore compatible.","title":"Components"},{"location":"modules/stream-security/#url-signing-service","text":"The URL signing service is designed to support one or more signing implementations called signing providers. With this concept, different signing protocols, and by virtue, different verification components are supported. The resource is presented to each signing provider in turn, where it is either signed or passed on. This process continues until a signature is obtained. Out of the box, Opencast provides the following implementation: Generic Signing Provider : This provider may be used in combination with HTTP servers. It appends the necessary information (policy, signature and key id) to the URL. The URL signing service makes it straightforward to provide additional implementations to handle third party distribution servers URL signatures. This becomes important in situations where files are served by a server that is currently not supported or if files are served by a CDN that implements its own proprietary signing protocol.","title":"URL Signing Service"},{"location":"modules/stream-security/#verification-components","text":"In order to take advantage of the signed URLs, a verification component needs to reside on the distribution servers to verify the validity of the signature (i.e. check that the URL has not been altered after it was signed) and then grant or deny access to the resource, based on the policy associated with the URL. In addition to these external verification components there is also an Opencast verification component called the UrlSigningFilter that is used to protect files that Opencast itself provides. Verification components have the option of strict or non-strict checking. Strict verification of resources means the entire URL will be considered when comparing the incoming request for a resource against the policy, including the scheme (http, https, etc.), hostname and port. If using non-strict checking, only the path to the resource will be considered. So if the request is for a resource at http://httpdserver:8080/the/full/path/video.mp4 , only the /the/full/path/video.mp4 part of the URL will be checked against the policy\u2019s path. This is useful when using a load balancer so that the requested hostname does not have to match the actual hostname or if a video player is rewriting requests, e.g. by inserting the port number.","title":"Verification components"},{"location":"modules/stream-security/#further-information","text":"For further technical information like installation instructions, configuration guides, server plugins and the signing specification, please have a look at these documents: Stream Security Configuration & Testing The Opencast Signing Protocol is defined in the subsection Stream Security in the modules section of the developer guide.","title":"Further Information"},{"location":"modules/terminationstate.aws.autoscaling/","text":"AWS Auto-Scaling Termination State Service This page documents the configuration for Opencast module terminationstate-aws . This configuration is only required on nodes that are part of an AWS Auto Scaling group. The purpose of this module to manage the termination of an AWS EC2 instance, triggered when an Auto Scaling Group \"scales in\", as the Opencast process may still be processing jobs which we want to complete. This is special implementation of the basic Termination State Service It does not terminate the Opencast process or the instance itself . Auto Scaling Groups can trigger a Lifecycle Hook when an instance is created or terminated which allow events to occur before the creation or termination is completed. The service can poll if the termination hook has been triggered, at which point it will: put the node in maintenance mode, to stop accepting new jobs periodically check for running jobs and if so emit a heartbeat when no jobs are running it will tell the Auto Scaling group to complete the Terminate life-cycle action Alternatively you can disable the Lifecycle state polling and call the REST endpoint (termination/aws/autoscaling) to signal that the instance is now terminating. The details of how to achieve this are beyond the scope of this document, but using a CloudWatch Alarm to trigger a Lambda function is a suggested route. Amazon User Configuration Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation . You will, however, require to set up proper credentials by either: Creating an Access Key ID and a Secret Access Key or Using Instance Profile Credentials (recommended when running Opencast on EC2 instances) The termination state service requires a number of permissions to query and respond to changes in the instance's lifecycle. You should follow these instructions to create a new policy that is assigned to the IAM profile or user account. The following policy contains all the necessary permissions. You will need to change the region and account number in the Resource ARN with your own. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"ReadInstanceLifcycle\", \"Effect\": \"Allow\", \"Action\": [ \"autoscaling:DescribeAutoScalingInstances\", \"autoscaling:DescribeAutoScalingGroups\", \"autoscaling:DescribeLifecycleHooks\" ], \"Resource\": \"*\" }, { \"Sid\": \"UpdateLifcycle\", \"Effect\": \"Allow\", \"Action\": [ \"autoscaling:CompleteLifecycleAction\", \"autoscaling:RecordLifecycleActionHeartbeat\" ], \"Resource\": \"arn:aws:autoscaling:<region>:<account>:autoScalingGroup:*:autoScalingGroupName/*\" } ] } A free Amazon account will work for small scale testing, but be aware that AutoScaling can incur costs if not correctly setup. Amazon AutoScaling Configuration Please consult the AWS documentation to create an AutoScaling Group . You will need to explicitly add a Lifecycle Hook for the \"autoscaling:EC2_INSTANCE_TERMINATING\" Lifecycle transition. The 'Heartbeat Timeout' should be set to something appropriate. The default 3600 seconds is fine for production but quite long when developing your deployment. NOTE: the service will tell the AutoScaling Group to complete termination even if the timeout hasn't expired once there are no jobs running. Opencast Service Configuration The Opencast AWS Autoscaling Termination State Service configuration can be found in the file org.opencastproject.terminationstate.aws.AutoScalingTerminationStateService.cfg . Key name Value Example enable true to enable the service, false (default) otherwise true lifecycle.polling.enabled true to poll the Lifecycle for the termination state true lifecycle.polling.period frequency which to poll the Lifecycle in seconds 300 lifecycle.heartbeat.period frequency which to check if if jobs are running and emit Lifecycle heartbeat 300 access.id AWS user's access ID 20 alphanumeric characters access.secret AWS user's secret key 40 characters If access.id and access.secret are not explicitly provided, search for credentials will be performed in the order specified by the Default Credentials Provider Chain . NOTE : both the lifecycle.polling.period and lifecycle.heartbeat.period should be less than the 'Heartbeat Timeout' of the Lifecycle Hook or else the instance could be terminated before the service can respond.","title":"AWS AutoScaling"},{"location":"modules/terminationstate.aws.autoscaling/#aws-auto-scaling-termination-state-service","text":"This page documents the configuration for Opencast module terminationstate-aws . This configuration is only required on nodes that are part of an AWS Auto Scaling group. The purpose of this module to manage the termination of an AWS EC2 instance, triggered when an Auto Scaling Group \"scales in\", as the Opencast process may still be processing jobs which we want to complete. This is special implementation of the basic Termination State Service It does not terminate the Opencast process or the instance itself . Auto Scaling Groups can trigger a Lifecycle Hook when an instance is created or terminated which allow events to occur before the creation or termination is completed. The service can poll if the termination hook has been triggered, at which point it will: put the node in maintenance mode, to stop accepting new jobs periodically check for running jobs and if so emit a heartbeat when no jobs are running it will tell the Auto Scaling group to complete the Terminate life-cycle action Alternatively you can disable the Lifecycle state polling and call the REST endpoint (termination/aws/autoscaling) to signal that the instance is now terminating. The details of how to achieve this are beyond the scope of this document, but using a CloudWatch Alarm to trigger a Lambda function is a suggested route.","title":"AWS Auto-Scaling Termination State Service"},{"location":"modules/terminationstate.aws.autoscaling/#amazon-user-configuration","text":"Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation . You will, however, require to set up proper credentials by either: Creating an Access Key ID and a Secret Access Key or Using Instance Profile Credentials (recommended when running Opencast on EC2 instances) The termination state service requires a number of permissions to query and respond to changes in the instance's lifecycle. You should follow these instructions to create a new policy that is assigned to the IAM profile or user account. The following policy contains all the necessary permissions. You will need to change the region and account number in the Resource ARN with your own. { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Sid\": \"ReadInstanceLifcycle\", \"Effect\": \"Allow\", \"Action\": [ \"autoscaling:DescribeAutoScalingInstances\", \"autoscaling:DescribeAutoScalingGroups\", \"autoscaling:DescribeLifecycleHooks\" ], \"Resource\": \"*\" }, { \"Sid\": \"UpdateLifcycle\", \"Effect\": \"Allow\", \"Action\": [ \"autoscaling:CompleteLifecycleAction\", \"autoscaling:RecordLifecycleActionHeartbeat\" ], \"Resource\": \"arn:aws:autoscaling:<region>:<account>:autoScalingGroup:*:autoScalingGroupName/*\" } ] } A free Amazon account will work for small scale testing, but be aware that AutoScaling can incur costs if not correctly setup.","title":"Amazon User Configuration"},{"location":"modules/terminationstate.aws.autoscaling/#amazon-autoscaling-configuration","text":"Please consult the AWS documentation to create an AutoScaling Group . You will need to explicitly add a Lifecycle Hook for the \"autoscaling:EC2_INSTANCE_TERMINATING\" Lifecycle transition. The 'Heartbeat Timeout' should be set to something appropriate. The default 3600 seconds is fine for production but quite long when developing your deployment. NOTE: the service will tell the AutoScaling Group to complete termination even if the timeout hasn't expired once there are no jobs running.","title":"Amazon AutoScaling Configuration"},{"location":"modules/terminationstate.aws.autoscaling/#opencast-service-configuration","text":"The Opencast AWS Autoscaling Termination State Service configuration can be found in the file org.opencastproject.terminationstate.aws.AutoScalingTerminationStateService.cfg . Key name Value Example enable true to enable the service, false (default) otherwise true lifecycle.polling.enabled true to poll the Lifecycle for the termination state true lifecycle.polling.period frequency which to poll the Lifecycle in seconds 300 lifecycle.heartbeat.period frequency which to check if if jobs are running and emit Lifecycle heartbeat 300 access.id AWS user's access ID 20 alphanumeric characters access.secret AWS user's secret key 40 characters If access.id and access.secret are not explicitly provided, search for credentials will be performed in the order specified by the Default Credentials Provider Chain . NOTE : both the lifecycle.polling.period and lifecycle.heartbeat.period should be less than the 'Heartbeat Timeout' of the Lifecycle Hook or else the instance could be terminated before the service can respond.","title":"Opencast Service Configuration"},{"location":"modules/terminationstate/","text":"Termination State Service This page documents the configuration for Opencast module terminationstate-impl . This module is provided as a convenience when you wish to terminate the Opencast process or the machine it is running on, when Opencast may still be processing jobs you want to complete. It also forms the basis for more sophisticated services that assist the dynamic scaling of nodes in cloud environments, see AWS AutoScaling: Termination State Service It does not terminate the Opencast process or the instance itself . The default termination state is \"none\". If the termination state is set to \"wait\" it will: put the node in maintenance mode, to stop accepting new jobs periodically check for running jobs when no jobs are running it will set the termination state to \"ready\" The termination state can then be monitored and the action completed when the state is changes from \"wait\" to \"ready\". Opencast Service Configuration The Opencast Termination State Service configuration can be found in the file org.opencastproject.terminationstate.impl.TerminationStateServiceImpl.cfg . Key name Value Example job.polling.period frequency which to check if jobs are running in seconds 300","title":"Basic"},{"location":"modules/terminationstate/#termination-state-service","text":"This page documents the configuration for Opencast module terminationstate-impl . This module is provided as a convenience when you wish to terminate the Opencast process or the machine it is running on, when Opencast may still be processing jobs you want to complete. It also forms the basis for more sophisticated services that assist the dynamic scaling of nodes in cloud environments, see AWS AutoScaling: Termination State Service It does not terminate the Opencast process or the instance itself . The default termination state is \"none\". If the termination state is set to \"wait\" it will: put the node in maintenance mode, to stop accepting new jobs periodically check for running jobs when no jobs are running it will set the termination state to \"ready\" The termination state can then be monitored and the action completed when the state is changes from \"wait\" to \"ready\".","title":"Termination State Service"},{"location":"modules/terminationstate/#opencast-service-configuration","text":"The Opencast Termination State Service configuration can be found in the file org.opencastproject.terminationstate.impl.TerminationStateServiceImpl.cfg . Key name Value Example job.polling.period frequency which to check if jobs are running in seconds 300","title":"Opencast Service Configuration"},{"location":"modules/textextraction/","text":"Text Extraction Configuration How the text extraction process works The sequence of the Opencast services used during slide detection and text extraction is the following: -----> Segmentation -----> TextAnalyzerService -----------------> / \\ / \\ TextExtractor DictionaryService (OCR with Tesseract) (Filter extracted texts) The segmentation will define the frames which are passed to the text analyzer. For extraction, a frame from the end of a segment is used to make sure that most of a slides text is visible. The frame is then exported as image and passed to the text extraction service which calls an OCR engine to get the text output. For this, the Tesseract OCR engine is used by default. After the text extraction is done, the analysis service will pass the recognized text to the dictionary service which may filter it to remove messed up words, unknown words, single characters or other things depending on the actual implementation and configuration. Finally, the extracted text is attached to the media package as MPEG 7 XML and the Opencast workflow continues. Configuration This section describes the configuration of all involved tools and services. In this guide, German is used as target language but the configuration for other languages should be similar. If necessary, important differences will be pointed out. OCR Engine: Tesseract Tesseract is the default OCR engine used by Opencast. It will accept an image file and write the extracted text to an output file. The command line arguments for this will be handled by Opencast. But apart from these mandatory ones, it is possible to pass additional arguments to Tesseract, defining the internally used dictionary, box files and the layout analysis. For example, if you want OCR for German content, you want to run something like this: tesseract in.tif out.txt -l deu --psm 3 The arguments in.tif and out.txt are automatically set by Opencast. The argument -l specifies the language files used by Tesseract. deu specifies the German language. Multiple languages may be specified, separated by plus characters. Please make sure that you have installed the language packs you want to use on every worker (E.g. yum install tesseract-langpack-deu ). Finally --psm 3 specifies the layout analysis for Tesseract. The value 3 means Fully automatic page segmentation, but no orientation and script detection which is actually the default. Hence in this case, the argument could simply be omitted. If you know more about your input videos, you might want to use different options here (not likely). In Opencast, you can modify this options in the custom.properties file by setting the following option: org.opencastproject.textanalyzer.tesseract.options=-l deu --psm 3 It is highly recommended to configure Tesseract to use your local language. It will improve the recognition a lot and only this will enable the recognition of special characters specific to your local language. Encoding (Image Preprocessing) The text extraction works best if there is a high contrast between text and background and additionally, the text is not too thin. Ideally, this means that you have black and white images with a clear, bold font. At this point, it is probably worth noting that despite what is often said and could also be found in the old documentation for Opencast, it does not matter for Tesseract if it is black text on a white background or if the colors are inverted (white on black). Because of the way Tesseract works, that does not matter. A lot of lecture slides are unfortunately not designed this way. Lecturers use colors, background images, etc. That is why, to get a better result, it is a good idea to do some image preprocessing steps. Some easy ones can be included directly into the image extraction step using FFmpeg. For this, edit the /etc/opencast/encoding/opencast-images.properties and modify the command for the image extraction: profile.text-analysis.http.ffmpeg.command = -ss #{time} -i #{in.video.path} \\ -filter:v boxblur=1:1,curves=all=0.4/0#{space}0.6/1 \\ -frames:v 1 -pix_fmt:v gray -r 1 #{out.dir}/#{out.name}#{out.suffix} This profile will create a gray, high contrast image. The additional light blur will reduce or remove noise and thicken the normal letters. The kind of preprocessing you should use highly depends on the input material. Interesting filters to try out for your material are among others the blur filters, the denoise filters, the curves filter and in some cases the color-channel mixer. DictionaryService (Filtering) The filtering you want to do on the recognized texts highly depends on what you want to use the recognized texts for. For searching, you might want a higher degree of filtering, for users you might also want to present text with slight errors, for testing and debugging, you want no filtering at all. Starting with version 1.6, Opencast provides three different kinds of implementation for filtering which can be just swapped out at any time: dictionary-none dictionary-regexp (default) dictionary-hunspell No Filtering (dictionary-none) The dictionary-none module is the simplest one. It will just let the recognized texts pass through unmodified. There is no additional configuration needed or even possible. Of course, this is also the fastest one. Using a Regular Expression (dictionary-regexp) Starting with 1.6, this is the default implementation for the DictionaryService. It is limited in terms of filtering capabilities as it will not check if a recognized word actually makes sense. Here is how this service works: If configured with a valid pattern that compiles to a regular expression, then this pattern is used, otherwise a fall- back to the default expression \\w+ . The pattern is repeatedly applied to the extracted text, until the end is reached. Each match is returned, separated by a space character. The default expression for this module is \\w+ which will let upper- and lowercase characters as well as digits pass through, but will block all other characters. For the German language, for example, this would mean that all special characters would be blocked as well. So you want to configure Opencast to let them pass as well. Example: * pattern: \\w+ * text input: \"a\u00e4a bbb\" * text output: \"a a bbb\" If this is undesired, modify the pattern in etc/org.opencastproject.dictionary.regexp.DictionaryServiceImpl.cfg : For German, a suitable pattern could be: pattern=[\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df][\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df]+[-.,:;!?]* This expression will let all words pass which contain upper- and lowercase [a-z], digits and German special characters as well as punctuation at the end of a word. Additionally, it requires that the words are at least two characters long which will filter out most of the common noise. Note the double-escaping of \\w . A similar pattern that could be used for Spanish would be: pattern=[\u00bf\u00a1(]*[\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1][\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1]+[)-.,:;!?]* Using a Spell Checker (dictionary-hunspell) Last, the dictionary-hunspell will check words based on a spell checker and a dictionary. As spell checker, the tool hunspell is used which is one of the most common spell checkers on Linux and should be available from the system repositories for most common operating systems. For the Hunspell based DictionaryService, there are two configuration options: One specifies the location of the binary and one is for the arguments to use for filtering. By default, Opencast will just call hunspell without an absolute path. This will work as long as hunspell is in the systems path which should be the case unless you have built and installed it manually. In that case, the binary can be configured using the following option in the custom.properties file: org.opencastproject.dictionary.hunspell.binary=/usr/bin/hunspell While most people will not need the binary path configuration, most people will need the filtering option which can be used for setting the languages. Configuration for this can be done using the following key in the custom.properties file: org.opencastproject.dictionary.hunspell.command=-d de_DE,en_GB,en_US -G Note that equivalent to the Tesseract configuration, again the necessary languages have to be installed in the system. On RedHat based systems, for German, you would install the hunspell-de package from the system repositories. For Hunspell, you can also create custom dictionaries or add custom words to the existing ones. This might be interesting for technical terms.","title":"Text Extraction"},{"location":"modules/textextraction/#text-extraction-configuration","text":"","title":"Text Extraction Configuration"},{"location":"modules/textextraction/#how-the-text-extraction-process-works","text":"The sequence of the Opencast services used during slide detection and text extraction is the following: -----> Segmentation -----> TextAnalyzerService -----------------> / \\ / \\ TextExtractor DictionaryService (OCR with Tesseract) (Filter extracted texts) The segmentation will define the frames which are passed to the text analyzer. For extraction, a frame from the end of a segment is used to make sure that most of a slides text is visible. The frame is then exported as image and passed to the text extraction service which calls an OCR engine to get the text output. For this, the Tesseract OCR engine is used by default. After the text extraction is done, the analysis service will pass the recognized text to the dictionary service which may filter it to remove messed up words, unknown words, single characters or other things depending on the actual implementation and configuration. Finally, the extracted text is attached to the media package as MPEG 7 XML and the Opencast workflow continues.","title":"How the text extraction process works"},{"location":"modules/textextraction/#configuration","text":"This section describes the configuration of all involved tools and services. In this guide, German is used as target language but the configuration for other languages should be similar. If necessary, important differences will be pointed out.","title":"Configuration"},{"location":"modules/textextraction/#ocr-engine-tesseract","text":"Tesseract is the default OCR engine used by Opencast. It will accept an image file and write the extracted text to an output file. The command line arguments for this will be handled by Opencast. But apart from these mandatory ones, it is possible to pass additional arguments to Tesseract, defining the internally used dictionary, box files and the layout analysis. For example, if you want OCR for German content, you want to run something like this: tesseract in.tif out.txt -l deu --psm 3 The arguments in.tif and out.txt are automatically set by Opencast. The argument -l specifies the language files used by Tesseract. deu specifies the German language. Multiple languages may be specified, separated by plus characters. Please make sure that you have installed the language packs you want to use on every worker (E.g. yum install tesseract-langpack-deu ). Finally --psm 3 specifies the layout analysis for Tesseract. The value 3 means Fully automatic page segmentation, but no orientation and script detection which is actually the default. Hence in this case, the argument could simply be omitted. If you know more about your input videos, you might want to use different options here (not likely). In Opencast, you can modify this options in the custom.properties file by setting the following option: org.opencastproject.textanalyzer.tesseract.options=-l deu --psm 3 It is highly recommended to configure Tesseract to use your local language. It will improve the recognition a lot and only this will enable the recognition of special characters specific to your local language.","title":"OCR Engine: Tesseract"},{"location":"modules/textextraction/#encoding-image-preprocessing","text":"The text extraction works best if there is a high contrast between text and background and additionally, the text is not too thin. Ideally, this means that you have black and white images with a clear, bold font. At this point, it is probably worth noting that despite what is often said and could also be found in the old documentation for Opencast, it does not matter for Tesseract if it is black text on a white background or if the colors are inverted (white on black). Because of the way Tesseract works, that does not matter. A lot of lecture slides are unfortunately not designed this way. Lecturers use colors, background images, etc. That is why, to get a better result, it is a good idea to do some image preprocessing steps. Some easy ones can be included directly into the image extraction step using FFmpeg. For this, edit the /etc/opencast/encoding/opencast-images.properties and modify the command for the image extraction: profile.text-analysis.http.ffmpeg.command = -ss #{time} -i #{in.video.path} \\ -filter:v boxblur=1:1,curves=all=0.4/0#{space}0.6/1 \\ -frames:v 1 -pix_fmt:v gray -r 1 #{out.dir}/#{out.name}#{out.suffix} This profile will create a gray, high contrast image. The additional light blur will reduce or remove noise and thicken the normal letters. The kind of preprocessing you should use highly depends on the input material. Interesting filters to try out for your material are among others the blur filters, the denoise filters, the curves filter and in some cases the color-channel mixer.","title":"Encoding (Image Preprocessing)"},{"location":"modules/textextraction/#dictionaryservice-filtering","text":"The filtering you want to do on the recognized texts highly depends on what you want to use the recognized texts for. For searching, you might want a higher degree of filtering, for users you might also want to present text with slight errors, for testing and debugging, you want no filtering at all. Starting with version 1.6, Opencast provides three different kinds of implementation for filtering which can be just swapped out at any time: dictionary-none dictionary-regexp (default) dictionary-hunspell","title":"DictionaryService (Filtering)"},{"location":"modules/textextraction/#no-filtering-dictionary-none","text":"The dictionary-none module is the simplest one. It will just let the recognized texts pass through unmodified. There is no additional configuration needed or even possible. Of course, this is also the fastest one.","title":"No Filtering (dictionary-none)"},{"location":"modules/textextraction/#using-a-regular-expression-dictionary-regexp","text":"Starting with 1.6, this is the default implementation for the DictionaryService. It is limited in terms of filtering capabilities as it will not check if a recognized word actually makes sense. Here is how this service works: If configured with a valid pattern that compiles to a regular expression, then this pattern is used, otherwise a fall- back to the default expression \\w+ . The pattern is repeatedly applied to the extracted text, until the end is reached. Each match is returned, separated by a space character. The default expression for this module is \\w+ which will let upper- and lowercase characters as well as digits pass through, but will block all other characters. For the German language, for example, this would mean that all special characters would be blocked as well. So you want to configure Opencast to let them pass as well. Example: * pattern: \\w+ * text input: \"a\u00e4a bbb\" * text output: \"a a bbb\" If this is undesired, modify the pattern in etc/org.opencastproject.dictionary.regexp.DictionaryServiceImpl.cfg : For German, a suitable pattern could be: pattern=[\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df][\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df]+[-.,:;!?]* This expression will let all words pass which contain upper- and lowercase [a-z], digits and German special characters as well as punctuation at the end of a word. Additionally, it requires that the words are at least two characters long which will filter out most of the common noise. Note the double-escaping of \\w . A similar pattern that could be used for Spanish would be: pattern=[\u00bf\u00a1(]*[\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1][\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1]+[)-.,:;!?]*","title":"Using a Regular Expression (dictionary-regexp)"},{"location":"modules/textextraction/#using-a-spell-checker-dictionary-hunspell","text":"Last, the dictionary-hunspell will check words based on a spell checker and a dictionary. As spell checker, the tool hunspell is used which is one of the most common spell checkers on Linux and should be available from the system repositories for most common operating systems. For the Hunspell based DictionaryService, there are two configuration options: One specifies the location of the binary and one is for the arguments to use for filtering. By default, Opencast will just call hunspell without an absolute path. This will work as long as hunspell is in the systems path which should be the case unless you have built and installed it manually. In that case, the binary can be configured using the following option in the custom.properties file: org.opencastproject.dictionary.hunspell.binary=/usr/bin/hunspell While most people will not need the binary path configuration, most people will need the filtering option which can be used for setting the languages. Configuration for this can be done using the following key in the custom.properties file: org.opencastproject.dictionary.hunspell.command=-d de_DE,en_GB,en_US -G Note that equivalent to the Tesseract configuration, again the necessary languages have to be installed in the system. On RedHat based systems, for German, you would install the hunspell-de package from the system repositories. For Hunspell, you can also create custom dictionaries or add custom words to the existing ones. This might be interesting for technical terms.","title":"Using a Spell Checker (dictionary-hunspell)"},{"location":"modules/timelinepreviews/","text":"Timeline Previews Configuration The Timeline previews service generates timeline preview images from a given video. These are shown above the timeline of the video in the engage player. The generation of these images is done using FFmpeg and all preview images are stored in one image file. To achieve this, several FFmpeg video filters are combined: - fps : to specify how many preview images should be generated. As the length of track is known and the desired number of preview images is configured in the workflow operation handler, it can be calculated how many seconds each preview image should represent. If 1 divided by that duration in seconds is set as fps value, FFmpeg will generate the desired amount of preview images. - scale : to achieve the desired output image resolution. This filter will scale the input video, so that the generated images will have that resolution. If one of the values is set to -1, the filter will use a value that maintains the aspect ratio of the input image. - tile : to tile all remaining frames together. This filter will put the preview images into one image file. The grid size can be set and is currently always quadratic, which means the number of lines and the number of columns are both the rounded up square root of the desired number of images. Configuration The resolution, the output format and the mimetype can be configured in etc/org.opencastproject.timelinepreviews.ffmpeg.TimelinePreviewsServiceImpl.cfg . Width of the resolution of a single preview image in pixels (defaults to 160). resolutionX = 160 Height of the resolution of a single preview image in pixels (defaults to -1). If not set or set to -1, it will be set automatically to preserve the original aspect ratio. resolutionY = -1 Output file format for the timeline previews image file (defaults to \".png\"). outputFormat = \".png\" Mimetype for the output image (defaults to \"image/png\"). mimetype = \"image/png\"","title":"Timeline Previews"},{"location":"modules/timelinepreviews/#timeline-previews-configuration","text":"The Timeline previews service generates timeline preview images from a given video. These are shown above the timeline of the video in the engage player. The generation of these images is done using FFmpeg and all preview images are stored in one image file. To achieve this, several FFmpeg video filters are combined: - fps : to specify how many preview images should be generated. As the length of track is known and the desired number of preview images is configured in the workflow operation handler, it can be calculated how many seconds each preview image should represent. If 1 divided by that duration in seconds is set as fps value, FFmpeg will generate the desired amount of preview images. - scale : to achieve the desired output image resolution. This filter will scale the input video, so that the generated images will have that resolution. If one of the values is set to -1, the filter will use a value that maintains the aspect ratio of the input image. - tile : to tile all remaining frames together. This filter will put the preview images into one image file. The grid size can be set and is currently always quadratic, which means the number of lines and the number of columns are both the rounded up square root of the desired number of images.","title":"Timeline Previews Configuration"},{"location":"modules/timelinepreviews/#configuration","text":"The resolution, the output format and the mimetype can be configured in etc/org.opencastproject.timelinepreviews.ffmpeg.TimelinePreviewsServiceImpl.cfg . Width of the resolution of a single preview image in pixels (defaults to 160). resolutionX = 160 Height of the resolution of a single preview image in pixels (defaults to -1). If not set or set to -1, it will be set automatically to preserve the original aspect ratio. resolutionY = -1 Output file format for the timeline previews image file (defaults to \".png\"). outputFormat = \".png\" Mimetype for the output image (defaults to \"image/png\"). mimetype = \"image/png\"","title":"Configuration"},{"location":"modules/videoeditor.architecture/","text":"Video Editor: Architecture Modules Of The Videoeditor The Videoeditor consists of the following moduls. Additional to this there is a Workflow Operation Handler within the Conductor module that provides the UI elements for the Video Editor. silencedetection-api API for the silence detection silencedetection-impl Implementation of the silence detection service Provides a SMIL file that can be used by the Video Editor UI or the Video Editor service to create a new cutted file. silencedetection-remote Remote implementation of the silence detection service to enable load balancing in a distributed setup. smil-api API for the SMIL service smil-impl The SMIL service allows creation and manipulation of SMIL files. This is more or less a helper class to create consistent SMIL files. videoeditor-api The API for the Video Editor which takes a SMIL file as an input to create a cutted version of the media files. videoeditor-ffmpeg-impl The Video Editor service creates new media files that will be cutted based on the information provided in a SMIL file. In the current implementation GStreamer with the gnonlin module is used to process the files. videoeditor-remote Remote implementation of the video editor service to enable load balancing in a distributed setup. Several other changes have been made on other Opencast modules to provide a better user experience for the video editor (i.e. byte-range request on the working-file-repository). Edit List Format The video editor uses SMIL 3.0 as a standardized Data format for the edit lists (cutting information). Some conventions and namespace extensions have been made to make sure that Opencast is able to find the files. As we usually have two (or more) parallel media files, these files are grouped in a <par> -element which forms a segment that should be included in the resulting video. This means the included <video> -files will be played in parallel. The clipBegin and clipEnd attributes a provided as milliseconds. Usually these should be identical for all <videos> within a <par> . For each segment a <par> is created. In the result of the silence detection segments with silence are omitted within the SMIL files, so only segments within the SMIL doc will be in the resulting video. The segments within the SMIL file will be in the order they are written down. If the sequence of the segments is changed, the sequence within the resulting video is changed too. Example SMIL file <smil xmlns=\"http://www.w3.org/ns/SMIL\" baseProfile=\"Language\" version=\"3.0\" xml:id=\"s-524c7815-4520-48e4-bb5e-94dcfdb3229f\"> <head xml:id=\"h-03b31c8d-68cf-49ea-8bae-d94abddf8f09\"> <meta name=\"track-duration\" content=\"6000841ms\" xml:id=\"meta-32069ddb-351d-4dca-a742-b9be490080f8\"/> <paramGroup xml:id=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\"> <param value=\"9f373445-5f46-4bdd-8d93-dca5e1094c38\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-d509b427-b239-4c4b-985a-f8b4ea31bbfb\"/> <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-411e0015-af0e-463c-898d-9a2bc594df46\"/> <param value=\"presenter/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-5ea022cd-189d-420f-9cea-4f6775af285e\"/> </paramGroup> <paramGroup xml:id=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\"> <param value=\"9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-c3c427ad-ef8a-4a71-9b0c-9208dd8a6bed\"/> <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-c15e1ed7-f773-456d-a007-fc237d9e0665\"/> <param value=\"presentation/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-97d5b5ac-1258-4267-a013-dc3882d7e242\"/> </paramGroup> </head> <body xml:id=\"b-c233c9ef-42d9-4f50-a1d2-29e3bbff003d\"> <par xml:id=\"par-7955133a-bcbe-40f8-87fd-47e78b3357c0\"> <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" paramGroup=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-61f5d0ee-dd36-4b1d-af3d-3f09f8807179\"/> <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" paramGroup=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-c68260e7-fd0d-4df6-8696-cc475ab3b3f8\"/> </par> </body> </smil> Workflow Operations Waveform Operation The waveform operation creates an image showing the temporal audio activity within the recording. This is be done with a probably well known waveform (see example image). The operation does not need an additional module, as it is not very work intensive to create such an image. The operation needs and audio-only file to create the image and it provides an PNG image. Input parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be used if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example). The output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too. Waveform Operation Template <operation id=\"waveform\" if=\"${trimHold}\" fail-on-error=\"false\" description=\"Generating waveform\"> <configurations> <configuration key=\"source-flavor\">*/audio</configuration> <configuration key=\"target-flavor\">*/waveform</configuration> </configurations> </operation> Silence Operation The silence operation performs a silence detection on an audio-only input file. The operation needs the silence detection API and impl (or remote in a distributed system) modules to be installed to process the request. The input parameters are source-flavors that takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type, and reference-tracks-flavor where the subtype of the media files that should be included in the provided SMIL file will be set. The * should not be modified here. In most cases it is not important which reference-tracks-flavor is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality. The output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced. The output of this operation is a SMIL file (see the example above). Silence Operation Template <operation id=\"silence\" if=\"${trimHold}\" fail-on-error=\"false\" description=\"Executing silence detection\"> <configurations> <configuration key=\"source-flavors\">*/audio</configuration> <configuration key=\"smil-flavor-subtype\">smil</configuration> <configuration key=\"reference-tracks-flavor\">*/preview</configuration> </configurations> </operation> Editor Operation The editor operation provides the UI for editing trim hold state and processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed. The input parameters are: source-flavors: the subtype of all media files in the best available quality and in a codec that can be processed by the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only the subtype is important. All needed videos should be available within this flavor. preview-flavors: the subtype of the media files that should be used for the preview player. This is an HTML5 player so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors. smil-flavors: the smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil will be favored, if this is not available the first in the list will be used. skipped-flavors: the flavor of the files that should be used if this workflow-operation is skipped. The output parameters are: target-smil-flavor: only a unique flavor is allowed here, as this is the file that the editor UI writes and that will be taken for processing the edited files afterwards. target-flavor-subtype: the flavor-subtype that will be used for all media files created in this operation. Editor Operation Template <operation id=\"editor\" if=\"${trimHold}\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Waiting for user to review / video edit recording\"> <configurations> <configuration key=\"source-flavors\">*/work</configuration> <configuration key=\"preview-flavors\">*/preview</configuration> <configuration key=\"skipped-flavors\">*/preview</configuration> <configuration key=\"smil-flavors\">*/smil</configuration> <configuration key=\"target-smil-flavor\">episode/smil</configuration> <configuration key=\"target-flavor-subtype\">trimmed</configuration> </configurations> </operation> Including The Video Editor To The Workflow Definition File Including the Video Editor with the silence detection into the needs some changes in the default workflow. Several of the steps here are inherited from the trim-operations and the workflow it was included too. We assume that you set ${trimHold} variable like in the current workflow definitions with trimming. The prepare-av operations has to be adopted. Gstreamer/gnonlin is kind of picky on the codec that it supports. So the media file has to be re-encoded in the beginning of the workflow. The prepare-av encoding profiles (av.work and mux-av.work) have been updated in the Video Editor branch for this. Within the prepare-av operation in the workflow-definition XML-file rewriting the file should be forced: Changes in the workflow definition <configuration key=\"rewrite\">true</configuration> <configuration key=\"audio-muxing-source-flavors\">*/?,*/*</configuration> The preview videos have to be created. These can be in H.264 (for Safari, IE, Chrome) or WebM (for Firefox, Opera or Chrome) codec. Encoding profiles for WebM are provided in the video editor branch and are used in the examples. This operation should be after the prepare-av operation. Workflow operation to create WebM preview videos <operation id=\"compose\" if=\"${trimHold}\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encoding presenter (camera) video for videoeditor preview\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/preview</configuration> <configuration key=\"encoding-profile\">webm-preview.http</configuration> </configurations> </operation> An audio-only file has to be composed for the waveform and silence operation. This operation should be after the prepare-av operation. Workflow operation to compose the audio-only file(s) <operation id=\"compose\" if=\"${trimHold}\" fail-on-error=\"false\" description=\"Extracting audio for waveform generation\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/audio</configuration> <configuration key=\"encoding-profile\">audio.wav</configuration> </configurations> </operation> The waveform operation should be included. See above for the XML-code for this operation. The audio-only file should already be available. The silence detection should be done. See above for the XML-code for this operation. The audio-only file should already be available. After all previous operations have been done the editor can be included. See above for the XML-code for this operation. You may consider to tag the trimmed files for archiving. Then you should include this operation after the editor: Tagging trimmed files for the archive <operation id=\"tag\" description=\"Tagging media for archival\"> <configurations> <configuration key=\"source-flavors\">*/trimmed</configuration> <configuration key=\"target-tags\">+archive</configuration> </configurations> </operation> You could check, if you want to archive the source media too, or remove the source-flavors from the previous tagging operations. The rest of the workflow definition can be kept as it is, the input flavor subtype for the trimmed files in other operations is \"/trimmed\" if you follow the naming in this example. The default compose-distribute-publish.xml workflow definition within the Video Editor branch has already been updated to include the editor instead of the trim-hold state. The trim operation is not overwritten with the video editor but could still be used.","title":"Architecture"},{"location":"modules/videoeditor.architecture/#video-editor-architecture","text":"","title":"Video Editor: Architecture"},{"location":"modules/videoeditor.architecture/#modules-of-the-videoeditor","text":"The Videoeditor consists of the following moduls. Additional to this there is a Workflow Operation Handler within the Conductor module that provides the UI elements for the Video Editor. silencedetection-api API for the silence detection silencedetection-impl Implementation of the silence detection service Provides a SMIL file that can be used by the Video Editor UI or the Video Editor service to create a new cutted file. silencedetection-remote Remote implementation of the silence detection service to enable load balancing in a distributed setup. smil-api API for the SMIL service smil-impl The SMIL service allows creation and manipulation of SMIL files. This is more or less a helper class to create consistent SMIL files. videoeditor-api The API for the Video Editor which takes a SMIL file as an input to create a cutted version of the media files. videoeditor-ffmpeg-impl The Video Editor service creates new media files that will be cutted based on the information provided in a SMIL file. In the current implementation GStreamer with the gnonlin module is used to process the files. videoeditor-remote Remote implementation of the video editor service to enable load balancing in a distributed setup. Several other changes have been made on other Opencast modules to provide a better user experience for the video editor (i.e. byte-range request on the working-file-repository).","title":"Modules Of The Videoeditor"},{"location":"modules/videoeditor.architecture/#edit-list-format","text":"The video editor uses SMIL 3.0 as a standardized Data format for the edit lists (cutting information). Some conventions and namespace extensions have been made to make sure that Opencast is able to find the files. As we usually have two (or more) parallel media files, these files are grouped in a <par> -element which forms a segment that should be included in the resulting video. This means the included <video> -files will be played in parallel. The clipBegin and clipEnd attributes a provided as milliseconds. Usually these should be identical for all <videos> within a <par> . For each segment a <par> is created. In the result of the silence detection segments with silence are omitted within the SMIL files, so only segments within the SMIL doc will be in the resulting video. The segments within the SMIL file will be in the order they are written down. If the sequence of the segments is changed, the sequence within the resulting video is changed too. Example SMIL file <smil xmlns=\"http://www.w3.org/ns/SMIL\" baseProfile=\"Language\" version=\"3.0\" xml:id=\"s-524c7815-4520-48e4-bb5e-94dcfdb3229f\"> <head xml:id=\"h-03b31c8d-68cf-49ea-8bae-d94abddf8f09\"> <meta name=\"track-duration\" content=\"6000841ms\" xml:id=\"meta-32069ddb-351d-4dca-a742-b9be490080f8\"/> <paramGroup xml:id=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\"> <param value=\"9f373445-5f46-4bdd-8d93-dca5e1094c38\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-d509b427-b239-4c4b-985a-f8b4ea31bbfb\"/> <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-411e0015-af0e-463c-898d-9a2bc594df46\"/> <param value=\"presenter/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-5ea022cd-189d-420f-9cea-4f6775af285e\"/> </paramGroup> <paramGroup xml:id=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\"> <param value=\"9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-c3c427ad-ef8a-4a71-9b0c-9208dd8a6bed\"/> <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-c15e1ed7-f773-456d-a007-fc237d9e0665\"/> <param value=\"presentation/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-97d5b5ac-1258-4267-a013-dc3882d7e242\"/> </paramGroup> </head> <body xml:id=\"b-c233c9ef-42d9-4f50-a1d2-29e3bbff003d\"> <par xml:id=\"par-7955133a-bcbe-40f8-87fd-47e78b3357c0\"> <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" paramGroup=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-61f5d0ee-dd36-4b1d-af3d-3f09f8807179\"/> <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" paramGroup=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-c68260e7-fd0d-4df6-8696-cc475ab3b3f8\"/> </par> </body> </smil>","title":"Edit List Format"},{"location":"modules/videoeditor.architecture/#workflow-operations","text":"","title":"Workflow Operations"},{"location":"modules/videoeditor.architecture/#waveform-operation","text":"The waveform operation creates an image showing the temporal audio activity within the recording. This is be done with a probably well known waveform (see example image). The operation does not need an additional module, as it is not very work intensive to create such an image. The operation needs and audio-only file to create the image and it provides an PNG image. Input parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be used if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example). The output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too. Waveform Operation Template <operation id=\"waveform\" if=\"${trimHold}\" fail-on-error=\"false\" description=\"Generating waveform\"> <configurations> <configuration key=\"source-flavor\">*/audio</configuration> <configuration key=\"target-flavor\">*/waveform</configuration> </configurations> </operation>","title":"Waveform Operation"},{"location":"modules/videoeditor.architecture/#silence-operation","text":"The silence operation performs a silence detection on an audio-only input file. The operation needs the silence detection API and impl (or remote in a distributed system) modules to be installed to process the request. The input parameters are source-flavors that takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type, and reference-tracks-flavor where the subtype of the media files that should be included in the provided SMIL file will be set. The * should not be modified here. In most cases it is not important which reference-tracks-flavor is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality. The output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced. The output of this operation is a SMIL file (see the example above). Silence Operation Template <operation id=\"silence\" if=\"${trimHold}\" fail-on-error=\"false\" description=\"Executing silence detection\"> <configurations> <configuration key=\"source-flavors\">*/audio</configuration> <configuration key=\"smil-flavor-subtype\">smil</configuration> <configuration key=\"reference-tracks-flavor\">*/preview</configuration> </configurations> </operation>","title":"Silence Operation"},{"location":"modules/videoeditor.architecture/#editor-operation","text":"The editor operation provides the UI for editing trim hold state and processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed. The input parameters are: source-flavors: the subtype of all media files in the best available quality and in a codec that can be processed by the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only the subtype is important. All needed videos should be available within this flavor. preview-flavors: the subtype of the media files that should be used for the preview player. This is an HTML5 player so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors. smil-flavors: the smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil will be favored, if this is not available the first in the list will be used. skipped-flavors: the flavor of the files that should be used if this workflow-operation is skipped. The output parameters are: target-smil-flavor: only a unique flavor is allowed here, as this is the file that the editor UI writes and that will be taken for processing the edited files afterwards. target-flavor-subtype: the flavor-subtype that will be used for all media files created in this operation. Editor Operation Template <operation id=\"editor\" if=\"${trimHold}\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Waiting for user to review / video edit recording\"> <configurations> <configuration key=\"source-flavors\">*/work</configuration> <configuration key=\"preview-flavors\">*/preview</configuration> <configuration key=\"skipped-flavors\">*/preview</configuration> <configuration key=\"smil-flavors\">*/smil</configuration> <configuration key=\"target-smil-flavor\">episode/smil</configuration> <configuration key=\"target-flavor-subtype\">trimmed</configuration> </configurations> </operation>","title":"Editor Operation"},{"location":"modules/videoeditor.architecture/#including-the-video-editor-to-the-workflow-definition-file","text":"Including the Video Editor with the silence detection into the needs some changes in the default workflow. Several of the steps here are inherited from the trim-operations and the workflow it was included too. We assume that you set ${trimHold} variable like in the current workflow definitions with trimming. The prepare-av operations has to be adopted. Gstreamer/gnonlin is kind of picky on the codec that it supports. So the media file has to be re-encoded in the beginning of the workflow. The prepare-av encoding profiles (av.work and mux-av.work) have been updated in the Video Editor branch for this. Within the prepare-av operation in the workflow-definition XML-file rewriting the file should be forced: Changes in the workflow definition <configuration key=\"rewrite\">true</configuration> <configuration key=\"audio-muxing-source-flavors\">*/?,*/*</configuration> The preview videos have to be created. These can be in H.264 (for Safari, IE, Chrome) or WebM (for Firefox, Opera or Chrome) codec. Encoding profiles for WebM are provided in the video editor branch and are used in the examples. This operation should be after the prepare-av operation. Workflow operation to create WebM preview videos <operation id=\"compose\" if=\"${trimHold}\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encoding presenter (camera) video for videoeditor preview\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/preview</configuration> <configuration key=\"encoding-profile\">webm-preview.http</configuration> </configurations> </operation> An audio-only file has to be composed for the waveform and silence operation. This operation should be after the prepare-av operation. Workflow operation to compose the audio-only file(s) <operation id=\"compose\" if=\"${trimHold}\" fail-on-error=\"false\" description=\"Extracting audio for waveform generation\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/audio</configuration> <configuration key=\"encoding-profile\">audio.wav</configuration> </configurations> </operation> The waveform operation should be included. See above for the XML-code for this operation. The audio-only file should already be available. The silence detection should be done. See above for the XML-code for this operation. The audio-only file should already be available. After all previous operations have been done the editor can be included. See above for the XML-code for this operation. You may consider to tag the trimmed files for archiving. Then you should include this operation after the editor: Tagging trimmed files for the archive <operation id=\"tag\" description=\"Tagging media for archival\"> <configurations> <configuration key=\"source-flavors\">*/trimmed</configuration> <configuration key=\"target-tags\">+archive</configuration> </configurations> </operation> You could check, if you want to archive the source media too, or remove the source-flavors from the previous tagging operations. The rest of the workflow definition can be kept as it is, the input flavor subtype for the trimmed files in other operations is \"/trimmed\" if you follow the naming in this example. The default compose-distribute-publish.xml workflow definition within the Video Editor branch has already been updated to include the editor instead of the trim-hold state. The trim operation is not overwritten with the video editor but could still be used.","title":"Including The Video Editor To The Workflow Definition File"},{"location":"modules/videoeditor.setup/","text":"Video Editor: Setup Silence Detection Configuration The settings regarding the sensitivity of the silence detection can be changed in etc/org.opencastproject.silencedetection.impl.SilenceDetectionServiceImpl.cfg . silence.pre.length Duration of silence that should be included at the beginning of a new voice segment. This is to avoid that a cut seems to sudden. Default: 2000 (2s) silence.threshold.db Silence threshold (e.g. -50dB for loud classrooms, -35dB for silent indoor location). Default: -40dB silence.min.length Minimum duration in milliseconds to detect a sequence as silence. Default: 10000 (10s) voice.min.length Minimum segment duration in milliseconds to start a new voice containing sequence after a silent sequence. Default: 60000 (1min) Video Editor Configuration The FFmpeg properties for the Video Editor can be modified in etc/org.opencastproject.videoeditor.impl.VideoEditorServiceImpl.cfg . Usually there should be no reason to touch this file.","title":"Setup"},{"location":"modules/videoeditor.setup/#video-editor-setup","text":"","title":"Video Editor: Setup"},{"location":"modules/videoeditor.setup/#silence-detection-configuration","text":"The settings regarding the sensitivity of the silence detection can be changed in etc/org.opencastproject.silencedetection.impl.SilenceDetectionServiceImpl.cfg . silence.pre.length Duration of silence that should be included at the beginning of a new voice segment. This is to avoid that a cut seems to sudden. Default: 2000 (2s) silence.threshold.db Silence threshold (e.g. -50dB for loud classrooms, -35dB for silent indoor location). Default: -40dB silence.min.length Minimum duration in milliseconds to detect a sequence as silence. Default: 10000 (10s) voice.min.length Minimum segment duration in milliseconds to start a new voice containing sequence after a silent sequence. Default: 60000 (1min)","title":"Silence Detection Configuration"},{"location":"modules/videoeditor.setup/#video-editor-configuration","text":"The FFmpeg properties for the Video Editor can be modified in etc/org.opencastproject.videoeditor.impl.VideoEditorServiceImpl.cfg . Usually there should be no reason to touch this file.","title":"Video Editor Configuration"},{"location":"modules/videosegmentation/","text":"Video Segmentation Configuration What is Video Segmentation Video segmentation is a way of dividing a movie into meaningful segments. In the context of lecture capture, segmentation is best applied to captured screen presentation, that the presenter goes through slide after slide. As a result, the video segmentation returns the exact times of slide changes on the timeline, which allows for sophisticated ways for the learner to browse the lecture content, as shown in the slides section of the Opencast Player. How the video segmentation process works For detecting new scenes, Opencast uses the scene detection build into the FFmpeg select filter. The basic idea behind this filter is to compare to consecutive frames and decide if the second frame belongs to a new scene based on the difference. What can be optimized The segmentation does not yield perfect results for all scenarios if always the same parameters for the FFmpeg filter are used. Especially for presentations that include live handwriting or small videos often way too many segments are created. In these special cases the difference between two consecutive frames is much higher than for normal presentation slides and these big differences happen very often, whereby many segments would be found. To improve the resulting number of segments, different FFmpeg parameters are tried out and to prevent having segments that are too short to be reasonably clickable, too short segments are filtered out. How the Optimization works In general the optimization repeats a cycle of calling the ffmpeg filter, merging too small segments and calculating a new changes threshold until the segmentation is good enough. Additional to calling the ffmpeg function there is a filter function that merges small segments to a bigger segment or splits it to the surrounding segments if the resulting segment would be too small. This can be beneficial for example if a video is shown in a lecture, so that the video will be only one segment and not many short segments. The stability threshold is used in the filter method to determine which segments are long enough and which should be merged. First the segmentation is run with a stability threshold of 1 second and the initial changes threshold, that can be changed in the options. If the segmentation or the filtered segmentation doesn't deviate more from the preferred number of segments than the maximum error allows, the optimization is done. If not, a new changes threshold, that should yield better results, is calculated and the segmentation is run again until the segmentation is good enough or until the maximum number of cycles is reached. Configuration The value for the frame difference as well as the minimum length for a segment, the preferred number of segments, the maximum error and the maximum number of cycles can be configured in etc/org.opencastproject.videosegmenter.ffmpeg.VideoSegmenterServiceImpl.cfg . The options that can be set are the minimum length of a segment (defaults to 60 sec). stabilitythreshold = 60 The percentage of pixels that may change between two frames without considering them different (defaults to 0.025). changesthreshold = 0.025 The number of segments that the segmentation optimally should yield (defaults to 30). prefNumber = 30 The maximum error for the number of segments in percent. As soon as a segmentation with a lower error is achieved the optimization will be ended (defaults to 0.25). maxError = 0.25 The maximum number of times the optimization will call the FFmpeg select filter (defaults to 3). maxCycles = 3 The absolute maximum number of segments. If at the end of the optimization more segments than this are found, instead a uniform segmentation will be generated (defaults to 150). absoluteMax = 150 The absolute minimum number of segments. If at the end of the optimization less segments than this are found, instead a uniform segmentation will be generated (defaults to 3). absoluteMin = 3 This parameter controls whether the options prefNumber, absoluteMax and absoluteMin are interpreted as absolute segment numbers or relative to track duration. If this is set to true, prefNumber, absoluteMax and absoluteMin will be interpreted as number of segments per hour. (defaults to false) durationDependent = false","title":"Video Segmentation"},{"location":"modules/videosegmentation/#video-segmentation-configuration","text":"","title":"Video Segmentation Configuration"},{"location":"modules/videosegmentation/#what-is-video-segmentation","text":"Video segmentation is a way of dividing a movie into meaningful segments. In the context of lecture capture, segmentation is best applied to captured screen presentation, that the presenter goes through slide after slide. As a result, the video segmentation returns the exact times of slide changes on the timeline, which allows for sophisticated ways for the learner to browse the lecture content, as shown in the slides section of the Opencast Player.","title":"What is Video Segmentation"},{"location":"modules/videosegmentation/#how-the-video-segmentation-process-works","text":"For detecting new scenes, Opencast uses the scene detection build into the FFmpeg select filter. The basic idea behind this filter is to compare to consecutive frames and decide if the second frame belongs to a new scene based on the difference.","title":"How the video segmentation process works"},{"location":"modules/videosegmentation/#what-can-be-optimized","text":"The segmentation does not yield perfect results for all scenarios if always the same parameters for the FFmpeg filter are used. Especially for presentations that include live handwriting or small videos often way too many segments are created. In these special cases the difference between two consecutive frames is much higher than for normal presentation slides and these big differences happen very often, whereby many segments would be found. To improve the resulting number of segments, different FFmpeg parameters are tried out and to prevent having segments that are too short to be reasonably clickable, too short segments are filtered out.","title":"What can be optimized"},{"location":"modules/videosegmentation/#how-the-optimization-works","text":"In general the optimization repeats a cycle of calling the ffmpeg filter, merging too small segments and calculating a new changes threshold until the segmentation is good enough. Additional to calling the ffmpeg function there is a filter function that merges small segments to a bigger segment or splits it to the surrounding segments if the resulting segment would be too small. This can be beneficial for example if a video is shown in a lecture, so that the video will be only one segment and not many short segments. The stability threshold is used in the filter method to determine which segments are long enough and which should be merged. First the segmentation is run with a stability threshold of 1 second and the initial changes threshold, that can be changed in the options. If the segmentation or the filtered segmentation doesn't deviate more from the preferred number of segments than the maximum error allows, the optimization is done. If not, a new changes threshold, that should yield better results, is calculated and the segmentation is run again until the segmentation is good enough or until the maximum number of cycles is reached.","title":"How the Optimization works"},{"location":"modules/videosegmentation/#configuration","text":"The value for the frame difference as well as the minimum length for a segment, the preferred number of segments, the maximum error and the maximum number of cycles can be configured in etc/org.opencastproject.videosegmenter.ffmpeg.VideoSegmenterServiceImpl.cfg . The options that can be set are the minimum length of a segment (defaults to 60 sec). stabilitythreshold = 60 The percentage of pixels that may change between two frames without considering them different (defaults to 0.025). changesthreshold = 0.025 The number of segments that the segmentation optimally should yield (defaults to 30). prefNumber = 30 The maximum error for the number of segments in percent. As soon as a segmentation with a lower error is achieved the optimization will be ended (defaults to 0.25). maxError = 0.25 The maximum number of times the optimization will call the FFmpeg select filter (defaults to 3). maxCycles = 3 The absolute maximum number of segments. If at the end of the optimization more segments than this are found, instead a uniform segmentation will be generated (defaults to 150). absoluteMax = 150 The absolute minimum number of segments. If at the end of the optimization less segments than this are found, instead a uniform segmentation will be generated (defaults to 3). absoluteMin = 3 This parameter controls whether the options prefNumber, absoluteMax and absoluteMin are interpreted as absolute segment numbers or relative to track duration. If this is set to true, prefNumber, absoluteMax and absoluteMin will be interpreted as number of segments per hour. (defaults to false) durationDependent = false","title":"Configuration"},{"location":"modules/watsontranscripts/","text":"Transcripts (Automated by IBM Watson) Overview The IBMWatsonTranscriptionService invokes the IBM Watson Speech-to-Text service via REST API to translate audio to text. During the execution of an Opencast workflow, an audio file is extracted from one of the presenter videos and sent to the IBM Watson Speech-to-Text service. When the results are received, they are converted to the desired caption format and attached to the media package. Workflow 1 runs: Audio file created Watson Speech-to-Text job started Workflow finishes Translation finishes, callback with results is received, and workflow 2 is started. Workflow 2 runs: File with results is converted and attached to media package Media package is republished with captions/transcripts IBM Watson Speech-to-Text service documentation, including which languages are currently supported, can be found here . Configuration Step 1: Get IBM Watson credentials Create a 30-day trial acoount in IBM Cloud Get service credentials As of 10/30/2018, the service has migrated to token-based Identity and Access Management (IAM) authentication so user and password are not generated anymore. Previously created instances can still use user name and password. Details can be found here . Step 2: Configure IBMWatsonTranscriptionService Edit etc/org.opencastproject.transcription.ibmwatson.IBMWatsonTranscriptionService.cfg : Set enabled =true Use service credentials obtained above to set ibm_watson_api_key ( ibm.watson.user and ibm.watson.psw are still supported to be used with instances created previously) Enter the IBM Watson Speech-to-Text url in ibm.watson.service.url , if not using the default (https://stream.watsonplatform.net/speech-to-text/api) Enter the appropriate language model in ibm.watson.model , if not using the default ( en-US_BroadbandModel ) In workflow , enter the workflow definition id of the workflow to be used to attach the generated transcripts/captions Enter a notification.email to get job failure notifications. If not entered, the email in etc/custom.properties (org.opencastproject.admin.email) will be used. Configure the SmtpService. If no email address specified in either notification.email or org.opencastproject.admin.email , email notifications will be disabled. If re-submitting requests is desired in case of failures, configure max-attempts and retry.workflow . If max.attempts > 1 and the service receives an error callback, it will start the workflow specified in retry_workflow to create a new job. When max.attempts is reached for a track, the service will stop retrying. # Change enabled to true to enable this service. enabled=false # IBM Watson Speech-to-Text service url # Default: https://stream.watsonplatform.net/speech-to-text/api # ibm.watson.service.url=https://stream.watsonplatform.net/speech-to-text/api # APi key obtained when registering with the IBM Watson Speech-to_text service. # If empty, user and password below will be used. ibm.watson.api.key=<API_KEY> # User obtained when registering with the IBM Watson Speech-to_text service. # Mandatory if ibm.watson.api.key not entered. #ibm.watson.user=<SERVICE_USER> # Password obtained when registering with the IBM Watson Speech-to_text service # Mandatory if ibm.watson.api.key not entered. #ibm.watson.password=<SERVICE_PSW> # Language model to be used. See the IBM Watson Speech-to-Text service documentation # for available models. # Default: en-US_BroadbandModel #ibm.watson.model=en-US_BroadbandModel # Workflow to be executed when results are ready to be attached to media package. # Default: attach-watson-transcripts #workflow=attach-watson-transcripts # Interval the workflow dispatcher runs to start workflows to attach transcripts to the media package # after the transcription job is completed. In seconds. # Default: 60 #workflow.dispatch.interval=60 # How long it should wait to check jobs after their start date + track duration has passed. # This is only used if we didn't get a callback from the ibm watson speech-to-text service. # In seconds. # Default: 600 #completion.check.buffer=600 # How long to wait after a transcription is supposed to finish before marking the job as # canceled in the database. In seconds. Default is 2 hours. # Default: 7200 #max.processing.time=7200 # How long to keep result files in the working file repository in days. # Default: 7 #cleanup.results.days=7 # Email to send notifications of errors. If not entered, the value from # org.opencastproject.admin.email in custom.properties will be used. #notification.email= # Start transcription job load # Default: 0.1 #job.load.start.transcription=0.1 # Number of max attempts. If max attempts > 1 and the service returned an error after the recognitions job was # accepted or the job did not return any results, the transcription is re-submitted. Default is to not retry. # Default: 1 #max.attempts= # If max.attempts > 1, name of workflow to use for retries. #retry.workflow= Step 3: Add encoding profile for extracting audio The IBM Watson Speech-to-Text service has limitations on audio file size. Try using the encoding profile suggested in etc/encoding/watson-audio.properties. Step 4: Add workflow operations and create new workflow Add the following operations to your workflow. We suggest adding them after the media package is published so that users can watch videos without having to wait for the transcription to finish, but it depends on your use case. The only requirement is to take a snapshot of the media package so that the second workflow can retrieve it from the Asset Manager to attach the caption/transcripts. <!-- Extract audio from one of the presenter videos --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-tags\">engage-download</configuration> <configuration key=\"target-flavor\">audio/ogg</configuration> <!-- The target tag 'transcript' will be used in the next 'start-watson-transcription' operation --> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-opus</configuration> <!-- If there is more than one file that match the source-tags, use only the first one --> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start IBM Watson recognitions job --> <operation id=\"start-watson-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start IBM Watson transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mp already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/vtt+en</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation> Create a workflow that will add the generated caption/transcript to the media package and republish it. A sample one can be found in etc/workflows/attach-watson-transcripts.xml If re-submitting requests is desired in case of failures, create a workflow that will start a transcription job. A sample one can be found in etc/workflows/retry-watson-transcripts.xml Workflow Operations start-watson-transcription attach-watson-transcription","title":"Transcripts (IBM Watson)"},{"location":"modules/watsontranscripts/#transcripts-automated-by-ibm-watson","text":"","title":"Transcripts (Automated by IBM Watson)"},{"location":"modules/watsontranscripts/#overview","text":"The IBMWatsonTranscriptionService invokes the IBM Watson Speech-to-Text service via REST API to translate audio to text. During the execution of an Opencast workflow, an audio file is extracted from one of the presenter videos and sent to the IBM Watson Speech-to-Text service. When the results are received, they are converted to the desired caption format and attached to the media package. Workflow 1 runs: Audio file created Watson Speech-to-Text job started Workflow finishes Translation finishes, callback with results is received, and workflow 2 is started. Workflow 2 runs: File with results is converted and attached to media package Media package is republished with captions/transcripts IBM Watson Speech-to-Text service documentation, including which languages are currently supported, can be found here .","title":"Overview"},{"location":"modules/watsontranscripts/#configuration","text":"","title":"Configuration"},{"location":"modules/watsontranscripts/#step-1-get-ibm-watson-credentials","text":"Create a 30-day trial acoount in IBM Cloud Get service credentials As of 10/30/2018, the service has migrated to token-based Identity and Access Management (IAM) authentication so user and password are not generated anymore. Previously created instances can still use user name and password. Details can be found here .","title":"Step 1: Get IBM Watson credentials"},{"location":"modules/watsontranscripts/#step-2-configure-ibmwatsontranscriptionservice","text":"Edit etc/org.opencastproject.transcription.ibmwatson.IBMWatsonTranscriptionService.cfg : Set enabled =true Use service credentials obtained above to set ibm_watson_api_key ( ibm.watson.user and ibm.watson.psw are still supported to be used with instances created previously) Enter the IBM Watson Speech-to-Text url in ibm.watson.service.url , if not using the default (https://stream.watsonplatform.net/speech-to-text/api) Enter the appropriate language model in ibm.watson.model , if not using the default ( en-US_BroadbandModel ) In workflow , enter the workflow definition id of the workflow to be used to attach the generated transcripts/captions Enter a notification.email to get job failure notifications. If not entered, the email in etc/custom.properties (org.opencastproject.admin.email) will be used. Configure the SmtpService. If no email address specified in either notification.email or org.opencastproject.admin.email , email notifications will be disabled. If re-submitting requests is desired in case of failures, configure max-attempts and retry.workflow . If max.attempts > 1 and the service receives an error callback, it will start the workflow specified in retry_workflow to create a new job. When max.attempts is reached for a track, the service will stop retrying. # Change enabled to true to enable this service. enabled=false # IBM Watson Speech-to-Text service url # Default: https://stream.watsonplatform.net/speech-to-text/api # ibm.watson.service.url=https://stream.watsonplatform.net/speech-to-text/api # APi key obtained when registering with the IBM Watson Speech-to_text service. # If empty, user and password below will be used. ibm.watson.api.key=<API_KEY> # User obtained when registering with the IBM Watson Speech-to_text service. # Mandatory if ibm.watson.api.key not entered. #ibm.watson.user=<SERVICE_USER> # Password obtained when registering with the IBM Watson Speech-to_text service # Mandatory if ibm.watson.api.key not entered. #ibm.watson.password=<SERVICE_PSW> # Language model to be used. See the IBM Watson Speech-to-Text service documentation # for available models. # Default: en-US_BroadbandModel #ibm.watson.model=en-US_BroadbandModel # Workflow to be executed when results are ready to be attached to media package. # Default: attach-watson-transcripts #workflow=attach-watson-transcripts # Interval the workflow dispatcher runs to start workflows to attach transcripts to the media package # after the transcription job is completed. In seconds. # Default: 60 #workflow.dispatch.interval=60 # How long it should wait to check jobs after their start date + track duration has passed. # This is only used if we didn't get a callback from the ibm watson speech-to-text service. # In seconds. # Default: 600 #completion.check.buffer=600 # How long to wait after a transcription is supposed to finish before marking the job as # canceled in the database. In seconds. Default is 2 hours. # Default: 7200 #max.processing.time=7200 # How long to keep result files in the working file repository in days. # Default: 7 #cleanup.results.days=7 # Email to send notifications of errors. If not entered, the value from # org.opencastproject.admin.email in custom.properties will be used. #notification.email= # Start transcription job load # Default: 0.1 #job.load.start.transcription=0.1 # Number of max attempts. If max attempts > 1 and the service returned an error after the recognitions job was # accepted or the job did not return any results, the transcription is re-submitted. Default is to not retry. # Default: 1 #max.attempts= # If max.attempts > 1, name of workflow to use for retries. #retry.workflow=","title":"Step 2: Configure IBMWatsonTranscriptionService"},{"location":"modules/watsontranscripts/#step-3-add-encoding-profile-for-extracting-audio","text":"The IBM Watson Speech-to-Text service has limitations on audio file size. Try using the encoding profile suggested in etc/encoding/watson-audio.properties.","title":"Step 3: Add encoding profile for extracting audio"},{"location":"modules/watsontranscripts/#step-4-add-workflow-operations-and-create-new-workflow","text":"Add the following operations to your workflow. We suggest adding them after the media package is published so that users can watch videos without having to wait for the transcription to finish, but it depends on your use case. The only requirement is to take a snapshot of the media package so that the second workflow can retrieve it from the Asset Manager to attach the caption/transcripts. <!-- Extract audio from one of the presenter videos --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-tags\">engage-download</configuration> <configuration key=\"target-flavor\">audio/ogg</configuration> <!-- The target tag 'transcript' will be used in the next 'start-watson-transcription' operation --> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-opus</configuration> <!-- If there is more than one file that match the source-tags, use only the first one --> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start IBM Watson recognitions job --> <operation id=\"start-watson-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start IBM Watson transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mp already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/vtt+en</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation> Create a workflow that will add the generated caption/transcript to the media package and republish it. A sample one can be found in etc/workflows/attach-watson-transcripts.xml If re-submitting requests is desired in case of failures, create a workflow that will start a transcription job. A sample one can be found in etc/workflows/retry-watson-transcripts.xml","title":"Step 4: Add workflow operations and create new workflow"},{"location":"modules/watsontranscripts/#workflow-operations","text":"start-watson-transcription attach-watson-transcription","title":"Workflow Operations"},{"location":"modules/waveform/","text":"Waveform Service Configuration The Waveform service generates waveform images from a audio/video file. These waveform images are then shown in the Admin-UI video editor. Service Configuration The Waveform service configuration file etc/org.opencastproject.waveform.ffmpeg.WaveformServiceImpl.cfg provides the following options: job.load.waveform = 0.5 With this value you can define the load of waveform jobs, see job load waveform.image.width.min = 5000 This will define the minimum width of the waveform image in pixels. waveform.image.width.max = 20000 This will define the maximum width of the waveform image in pixels. waveform.image.width.ppm = 200 This value defines the width of the waveform image in relation to the length of the audio/video file (in pixels per minute). waveform.image.height = 500 This will define the height of the waveform image in pixels. waveform.color = black This value defines the color of the waveform. The value must be a RGB(A) hex code or one of the predefined values, see FFMPEG Colors . You can define one color per audio channel separated by a whitespace. waveform.split.channels = false This boolean value defines whether multiple audio channels should be mixed in one waveform (if false ) or separated one next to each other (if true ). waveform.scale = lin This value defines the scale of the waveform. You can chose between lin for linear or log for logarithmic scale.","title":"Waveform Service"},{"location":"modules/waveform/#waveform-service-configuration","text":"The Waveform service generates waveform images from a audio/video file. These waveform images are then shown in the Admin-UI video editor.","title":"Waveform Service Configuration"},{"location":"modules/waveform/#service-configuration","text":"The Waveform service configuration file etc/org.opencastproject.waveform.ffmpeg.WaveformServiceImpl.cfg provides the following options: job.load.waveform = 0.5 With this value you can define the load of waveform jobs, see job load waveform.image.width.min = 5000 This will define the minimum width of the waveform image in pixels. waveform.image.width.max = 20000 This will define the maximum width of the waveform image in pixels. waveform.image.width.ppm = 200 This value defines the width of the waveform image in relation to the length of the audio/video file (in pixels per minute). waveform.image.height = 500 This will define the height of the waveform image in pixels. waveform.color = black This value defines the color of the waveform. The value must be a RGB(A) hex code or one of the predefined values, see FFMPEG Colors . You can define one color per audio channel separated by a whitespace. waveform.split.channels = false This boolean value defines whether multiple audio channels should be mixed in one waveform (if false ) or separated one next to each other (if true ). waveform.scale = lin This value defines the scale of the waveform. You can chose between lin for linear or log for logarithmic scale.","title":"Service Configuration"},{"location":"modules/youtubepublication/","text":"YouTube Publication Configuration This page documents the configuration for Opencast module publication-service-youtube-v3 . Before you start You need to meet these requirements to make a YouTube Publication: Google Account YouTube Channel to make the publication Google Developers Configuration Below is a summarized version of Google's quickstart page . If these instructions do not work for you, or are unclear please let us know - Google has a habit of changing its configuration pages and we don't always notice! Create new Google Project Login to Google account Navigate to the Google Developers Console Click Create Project and follow the instructions Navigate to the Google Credentials Console Select OAuth constent screen Configure the API Consent Screen, you will need to set the Product name Select Credentials Select Create Credentials , specifically OAuth Client ID Select Other application type Save Client ID in JSON Format Download the client information in JSON format by clicking Download JSON This currently looks like an arrow pointing downwards on the rightmost portion of the client id row Save the JSON file to ${karaf.etc}/youtube-v3/client-secrets-youtube-v3.json (Usually this is etc/youtube-v3/client-secrets-youtube-v3.json ) Enable API Naviate to the Google API Dashboard Click Enable APIs and Services in the navigation pane Use the filter to find and enable YouTube Data API v3 Enable the publication service In etc/org.opencastproject.publication.youtube.YouTubeV3PublicationServiceImpl.cfg set org.opencastproject.publication.youtube.enabled=true Update the category, keywords, default privacy, and default playlist variables as required YouTube configuration in Opencast With the JSON file created and saved previously, you have to proceed as described: Start Opencast server (Restart Opencast in case was running) Note: Until this service is fully configured, Opencast will not start completely. In case you want to abort the configuration, you only need to delete the JSON file and restart Opencast. In the command line, enter the command to view the extended status of the Opencast service: # systemctl status opencast -l This command will show parts of the Opencast logs in which you should see an URL that you have to copy to a browser. The web page will ask for your Google account (you have to use the account with which you created the developer project earlier) followed by access settings and settings for the channel you want to publish to. Once you have accepted the access, you will receive an answer like: Received verification code. Closing\u2026 Now verify that Opencast has received the access key and that it has been saved in data/opencast/youtube-v3/data-store/store. Restart Opencast Activate YouTube publication in Opencast Opencast can now publish to YouTube. The last step is to activate this feature. For this you have to create a new workflow or modify an existing one. Open the workflows etc/opencast/workflows/ng-schedule-and-upload.xml and etc/opencast/workflows/ng-publish.xml In the file, modify the <configuration_panel> and enable the YouTube option, like this: <input id=\"publishToYouTube\" name=\"publishToYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\" disabled=\"disabled\" /> becomes <input id=\"publishToYouTube\" name=\"publishToYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\"/> Open the workflows etc/opencast/workflows/ng-retract.xml In the file, modify the <configuration_panel> and enable the YouTube option, like this: <input id=\"retractFromYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\" disabled=\"disabled\" /> becomes <input id=\"retractFromYouTube\" type=\"checkbox\" checked=\"checked\" class=\"configField\" value=\"true\" /> Opencast will detect the new workflow without restart, with that you can select the new workflow with the YouTube option enabled.","title":"YouTube Publication"},{"location":"modules/youtubepublication/#youtube-publication-configuration","text":"This page documents the configuration for Opencast module publication-service-youtube-v3 .","title":"YouTube Publication Configuration"},{"location":"modules/youtubepublication/#before-you-start","text":"You need to meet these requirements to make a YouTube Publication: Google Account YouTube Channel to make the publication","title":"Before you start"},{"location":"modules/youtubepublication/#google-developers-configuration","text":"Below is a summarized version of Google's quickstart page . If these instructions do not work for you, or are unclear please let us know - Google has a habit of changing its configuration pages and we don't always notice!","title":"Google Developers Configuration"},{"location":"modules/youtubepublication/#create-new-google-project","text":"Login to Google account Navigate to the Google Developers Console Click Create Project and follow the instructions Navigate to the Google Credentials Console Select OAuth constent screen Configure the API Consent Screen, you will need to set the Product name Select Credentials Select Create Credentials , specifically OAuth Client ID Select Other application type","title":"Create new Google Project"},{"location":"modules/youtubepublication/#save-client-id-in-json-format","text":"Download the client information in JSON format by clicking Download JSON This currently looks like an arrow pointing downwards on the rightmost portion of the client id row Save the JSON file to ${karaf.etc}/youtube-v3/client-secrets-youtube-v3.json (Usually this is etc/youtube-v3/client-secrets-youtube-v3.json )","title":"Save Client ID in JSON Format"},{"location":"modules/youtubepublication/#enable-api","text":"Naviate to the Google API Dashboard Click Enable APIs and Services in the navigation pane Use the filter to find and enable YouTube Data API v3","title":"Enable API"},{"location":"modules/youtubepublication/#enable-the-publication-service","text":"In etc/org.opencastproject.publication.youtube.YouTubeV3PublicationServiceImpl.cfg set org.opencastproject.publication.youtube.enabled=true Update the category, keywords, default privacy, and default playlist variables as required","title":"Enable the publication service"},{"location":"modules/youtubepublication/#youtube-configuration-in-opencast","text":"With the JSON file created and saved previously, you have to proceed as described: Start Opencast server (Restart Opencast in case was running) Note: Until this service is fully configured, Opencast will not start completely. In case you want to abort the configuration, you only need to delete the JSON file and restart Opencast. In the command line, enter the command to view the extended status of the Opencast service: # systemctl status opencast -l This command will show parts of the Opencast logs in which you should see an URL that you have to copy to a browser. The web page will ask for your Google account (you have to use the account with which you created the developer project earlier) followed by access settings and settings for the channel you want to publish to. Once you have accepted the access, you will receive an answer like: Received verification code. Closing\u2026 Now verify that Opencast has received the access key and that it has been saved in data/opencast/youtube-v3/data-store/store. Restart Opencast","title":"YouTube configuration in Opencast"},{"location":"modules/youtubepublication/#activate-youtube-publication-in-opencast","text":"Opencast can now publish to YouTube. The last step is to activate this feature. For this you have to create a new workflow or modify an existing one. Open the workflows etc/opencast/workflows/ng-schedule-and-upload.xml and etc/opencast/workflows/ng-publish.xml In the file, modify the <configuration_panel> and enable the YouTube option, like this: <input id=\"publishToYouTube\" name=\"publishToYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\" disabled=\"disabled\" /> becomes <input id=\"publishToYouTube\" name=\"publishToYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\"/> Open the workflows etc/opencast/workflows/ng-retract.xml In the file, modify the <configuration_panel> and enable the YouTube option, like this: <input id=\"retractFromYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\" disabled=\"disabled\" /> becomes <input id=\"retractFromYouTube\" type=\"checkbox\" checked=\"checked\" class=\"configField\" value=\"true\" /> Opencast will detect the new workflow without restart, with that you can select the new workflow with the YouTube option enabled.","title":"Activate YouTube publication in Opencast"},{"location":"modules/paella.player/configuration/","text":"Paella Player The Paella (pronounced 'paeja') Player is an Open Source Javascript video player capable of playing an unlimited number of audio & video streams synchronously, Live Streaming, Zoom, Captions, contributed user plugins and a lot more. It is easy to install and customize for your own needs. Paella has been specially designed for lecture recordings, and currently is the default video player of the Opencast Community . It works with all HTML5 browsers (Chrome, Firefox, Safari and Edge) and within iOS and Android. Have a look to the paella features list or see them live on paella demos page Enable paella player To enable paella player you need to edit the prop.player variable. This can be enabled for each tenant. So the configuration keys are located in etc/org.opencastproject.organization-mh_default_org.cfg . To activate the paella player set: prop.player=/paella/ui/watch.html?id=#{id} Configuration The configurations for the paella player are done for each tenant. The paella configuration files are located in etc/ui-config/<tenant_id>/paella/config.json . For the default mh_default_org tenant file is located at etc/ui-config/mh_default_org/paella/config.json . For more information about the configuration format options, see the paella documentation Tracks to be played An event can have many tracks, but an institution can configure which of these tracks are played and which are not. To do it, you need to configure es.upv.paella.opencast.loader plugin. Multiple audio tracks An event can have multiple audio tracks. Paella only plays one at a time, but you can configure paella to allow the user to decide which one to play. Read the es.upv.paella.opencast.loader documentation plugin for more information. This feature is usefull when you have multiple audio languages, so the users can switch to the audio language they want.","title":"Configuration"},{"location":"modules/paella.player/configuration/#paella-player","text":"The Paella (pronounced 'paeja') Player is an Open Source Javascript video player capable of playing an unlimited number of audio & video streams synchronously, Live Streaming, Zoom, Captions, contributed user plugins and a lot more. It is easy to install and customize for your own needs. Paella has been specially designed for lecture recordings, and currently is the default video player of the Opencast Community . It works with all HTML5 browsers (Chrome, Firefox, Safari and Edge) and within iOS and Android. Have a look to the paella features list or see them live on paella demos page","title":"Paella Player"},{"location":"modules/paella.player/configuration/#enable-paella-player","text":"To enable paella player you need to edit the prop.player variable. This can be enabled for each tenant. So the configuration keys are located in etc/org.opencastproject.organization-mh_default_org.cfg . To activate the paella player set: prop.player=/paella/ui/watch.html?id=#{id}","title":"Enable paella player"},{"location":"modules/paella.player/configuration/#configuration","text":"The configurations for the paella player are done for each tenant. The paella configuration files are located in etc/ui-config/<tenant_id>/paella/config.json . For the default mh_default_org tenant file is located at etc/ui-config/mh_default_org/paella/config.json . For more information about the configuration format options, see the paella documentation","title":"Configuration"},{"location":"modules/paella.player/configuration/#tracks-to-be-played","text":"An event can have many tracks, but an institution can configure which of these tracks are played and which are not. To do it, you need to configure es.upv.paella.opencast.loader plugin.","title":"Tracks to be played"},{"location":"modules/paella.player/configuration/#multiple-audio-tracks","text":"An event can have multiple audio tracks. Paella only plays one at a time, but you can configure paella to allow the user to decide which one to play. Read the es.upv.paella.opencast.loader documentation plugin for more information. This feature is usefull when you have multiple audio languages, so the users can switch to the audio language they want.","title":"Multiple audio tracks"},{"location":"modules/paella.player/plugins/","text":"Paella player plugins Almost every paella feature is a plugin that can be enabled/disabled by each organization. You need to modify the plugins section of the paella config file . To enable/disable a plugin you need to set the plugin enable property to false . Example: { ... \"plugins\": { \"list\": { \"es.upv.paella.opencast.downloadsPlugin\": { \"enabled\": true }, ... } } } Plugins provided by Paella player To view a full list of plugins, see the the paella documentation page Plugins provided by Opencast The paella bundle for Opencast comes with a list of plugins to integrate with Opencast Plugin Description es.upv.paella.opencast.descriptionPlugin Adds a panel with the video description information. es.upv.paella.opencast.downloadsPlugin Adds a panel to download the videos. es.upv.paella.opencast.episodesFromSeries Show a list of videos in the same series. es.upv.paella.opencast.loader Configures how events are loaded into paella player. es.upv.paella.opencast.logIn Adds a button to be able to login. es.upv.paella.opencast.searchPlugin Enable searches using the OCR trascription. es.upv.paella.opencast.transcriptionTabBarPlugin Adds a panel to show the OCR transcriptios. es.upv.paella.opencast.userTrackingSaverPlugIn Allows to use Opencast Usertracking Service to track usage data.","title":"Overview"},{"location":"modules/paella.player/plugins/#paella-player-plugins","text":"Almost every paella feature is a plugin that can be enabled/disabled by each organization. You need to modify the plugins section of the paella config file . To enable/disable a plugin you need to set the plugin enable property to false . Example: { ... \"plugins\": { \"list\": { \"es.upv.paella.opencast.downloadsPlugin\": { \"enabled\": true }, ... } } }","title":"Paella player plugins"},{"location":"modules/paella.player/plugins/#plugins-provided-by-paella-player","text":"To view a full list of plugins, see the the paella documentation page","title":"Plugins provided by Paella player"},{"location":"modules/paella.player/plugins/#plugins-provided-by-opencast","text":"The paella bundle for Opencast comes with a list of plugins to integrate with Opencast Plugin Description es.upv.paella.opencast.descriptionPlugin Adds a panel with the video description information. es.upv.paella.opencast.downloadsPlugin Adds a panel to download the videos. es.upv.paella.opencast.episodesFromSeries Show a list of videos in the same series. es.upv.paella.opencast.loader Configures how events are loaded into paella player. es.upv.paella.opencast.logIn Adds a button to be able to login. es.upv.paella.opencast.searchPlugin Enable searches using the OCR trascription. es.upv.paella.opencast.transcriptionTabBarPlugin Adds a panel to show the OCR transcriptios. es.upv.paella.opencast.userTrackingSaverPlugIn Allows to use Opencast Usertracking Service to track usage data.","title":"Plugins provided by Opencast"},{"location":"modules/paella.player/url.parameter/","text":"Paella Player - URL Parameters Parameter Example Description id SOME-ID Video Id to play time 10m20s Seeks intially automatically to a specified time autoplay true Automatically starts playing the video id Video Id to play time Seeks intially automatically to a specified time. automatically plays the video from the specified time on Possible values * Hours (with value X ), minutes (with value Y ) and seconds (with value Z ) * XhYmZs * Minutes (with value Y ) and seconds (with value Z ) * YmZs * Minutes (with value Y ) only * Ym * Seconds (with value Z ) only * Zs Default value: - autoplay Automatically starts playing the video after a short delay Possible values * true * false Default value: false Example http://YOUR.SERVER/paella/ui/watch.html?id=SOME-ID&time=3m30s","title":"URL Parameters"},{"location":"modules/paella.player/url.parameter/#paella-player-url-parameters","text":"Parameter Example Description id SOME-ID Video Id to play time 10m20s Seeks intially automatically to a specified time autoplay true Automatically starts playing the video","title":"Paella Player - URL Parameters"},{"location":"modules/paella.player/url.parameter/#id","text":"Video Id to play","title":"id"},{"location":"modules/paella.player/url.parameter/#time","text":"Seeks intially automatically to a specified time. automatically plays the video from the specified time on Possible values * Hours (with value X ), minutes (with value Y ) and seconds (with value Z ) * XhYmZs * Minutes (with value Y ) and seconds (with value Z ) * YmZs * Minutes (with value Y ) only * Ym * Seconds (with value Z ) only * Zs Default value: -","title":"time"},{"location":"modules/paella.player/url.parameter/#autoplay","text":"Automatically starts playing the video after a short delay Possible values * true * false Default value: false","title":"autoplay"},{"location":"modules/paella.player/url.parameter/#example","text":"http://YOUR.SERVER/paella/ui/watch.html?id=SOME-ID&time=3m30s","title":"Example"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.descriptionPlugin/","text":"Paella plugin: es.upv.paella.opencast.descriptionPlugin This plugin adds a panel with the video description information. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.descriptionPlugin plugin. { \"es.upv.paella.opencast.descriptionPlugin\": { \"enabled\": true } }","title":"es.upv.paella.opencast.descriptionPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.descriptionPlugin/#paella-plugin-esupvpaellaopencastdescriptionplugin","text":"This plugin adds a panel with the video description information. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.descriptionPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.descriptionPlugin/#configuration","text":"You need to enabled the es.upv.paella.opencast.descriptionPlugin plugin. { \"es.upv.paella.opencast.descriptionPlugin\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.downloadsPlugin/","text":"Paella plugin: es.upv.paella.opencast.downloadsPlugin This plugin adds a panel to download the videos. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.downloadsPlugin plugin. { \"es.upv.paella.opencast.downloadsPlugin\": { \"enabled\": true } }","title":"es.upv.paella.opencast.downloadsPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.downloadsPlugin/#paella-plugin-esupvpaellaopencastdownloadsplugin","text":"This plugin adds a panel to download the videos. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.downloadsPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.downloadsPlugin/#configuration","text":"You need to enabled the es.upv.paella.opencast.downloadsPlugin plugin. { \"es.upv.paella.opencast.downloadsPlugin\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.episodesFromSeries/","text":"Paella plugin: es.upv.paella.opencast.episodesFromSeries This plugin show a list of videos in the same series. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.episodesFromSeries plugin. { \"es.upv.paella.opencast.episodesFromSeries\": { \"enabled\": true } }","title":"es.upv.paella.opencast.episodesFromSeries"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.episodesFromSeries/#paella-plugin-esupvpaellaopencastepisodesfromseries","text":"This plugin show a list of videos in the same series. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.episodesFromSeries"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.episodesFromSeries/#configuration","text":"You need to enabled the es.upv.paella.opencast.episodesFromSeries plugin. { \"es.upv.paella.opencast.episodesFromSeries\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.loader/","text":"Paella plugin: es.upv.paella.opencast.loader This plugin configures how events are loaded into paella player. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Control which flavors to play An event can have many tracks, but an institution can configure which of these tracks are played and which are not. To do it, you need to configure the streams property. The streams property is an array of rules. The first that matches is the one that will be applied. Each element in the array have two properties: filter : select which devices the rule applies to. Valid devices: Android, Linux, MacOS, Windows, iOS, iPad, iPhone, iPodTouch tracks : select which tracks to import into paella. tracks can be selected by flavors or tags Example: { \"streams\": [ { \"filter\": { \"system\": [\"*\"] }, \"tracks\": { \"flavors\": [\"*/*\"], \"tags\": [] } } ] } Multiple audio tracks An event can have multiple audio tracks. Paella only plays one at a time, but you can configure paella to allow the user to decide which one to play. You need to configure the audioTag property. It is an object where the key is the flavor to configure and the value is the label that will be shown in the player interface. Example: Your mediapackage has three audio tracks for english, spanish and german languages { \"audioTag\": { \"audio_en/delivery\" : \"en\", \"audio_es/delivery\" : \"es\", \"audio_de/delivery\" : \"de\" } } Examples An institution whant to play only */delivery media tracks and has two audio tracks for english and spanish languages { \"es.upv.paella.opencast.loader\": { \"streams\": [ { \"filter\": { \"system\": [\"*\"] }, \"tracks\": { \"flavors\": [\"*/delivery\"], \"tags\": [] } } ], \"audioTag\": { \"audio_en/delivery\" : \"en\", \"audio_es/delivery\" : \"es\" } } } An institution whants to play sidebyside/delivery track on Android and iOS devices and presenter/delivery and presentation/delivery on the other devices { \"es.upv.paella.opencast.loader\": { \"streams\": [ { \"filter\": { \"system\": [\"Android\", \"iOS\"] }, \"tracks\": { \"flavors\": [\"sidebyside/delivery\"], \"tags\": [] } }, { \"filter\": { \"system\": [\"*\"] }, \"tracks\": { \"flavors\": [\"presenter/delivery\", \"presentation/delivery\"], \"tags\": [] } } ], \"audioTag\": { } } }","title":"es.upv.paella.opencast.loader"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.loader/#paella-plugin-esupvpaellaopencastloader","text":"This plugin configures how events are loaded into paella player. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.loader"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.loader/#control-which-flavors-to-play","text":"An event can have many tracks, but an institution can configure which of these tracks are played and which are not. To do it, you need to configure the streams property. The streams property is an array of rules. The first that matches is the one that will be applied. Each element in the array have two properties: filter : select which devices the rule applies to. Valid devices: Android, Linux, MacOS, Windows, iOS, iPad, iPhone, iPodTouch tracks : select which tracks to import into paella. tracks can be selected by flavors or tags Example: { \"streams\": [ { \"filter\": { \"system\": [\"*\"] }, \"tracks\": { \"flavors\": [\"*/*\"], \"tags\": [] } } ] }","title":"Control which flavors to play"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.loader/#multiple-audio-tracks","text":"An event can have multiple audio tracks. Paella only plays one at a time, but you can configure paella to allow the user to decide which one to play. You need to configure the audioTag property. It is an object where the key is the flavor to configure and the value is the label that will be shown in the player interface. Example: Your mediapackage has three audio tracks for english, spanish and german languages { \"audioTag\": { \"audio_en/delivery\" : \"en\", \"audio_es/delivery\" : \"es\", \"audio_de/delivery\" : \"de\" } }","title":"Multiple audio tracks"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.loader/#examples","text":"An institution whant to play only */delivery media tracks and has two audio tracks for english and spanish languages { \"es.upv.paella.opencast.loader\": { \"streams\": [ { \"filter\": { \"system\": [\"*\"] }, \"tracks\": { \"flavors\": [\"*/delivery\"], \"tags\": [] } } ], \"audioTag\": { \"audio_en/delivery\" : \"en\", \"audio_es/delivery\" : \"es\" } } } An institution whants to play sidebyside/delivery track on Android and iOS devices and presenter/delivery and presentation/delivery on the other devices { \"es.upv.paella.opencast.loader\": { \"streams\": [ { \"filter\": { \"system\": [\"Android\", \"iOS\"] }, \"tracks\": { \"flavors\": [\"sidebyside/delivery\"], \"tags\": [] } }, { \"filter\": { \"system\": [\"*\"] }, \"tracks\": { \"flavors\": [\"presenter/delivery\", \"presentation/delivery\"], \"tags\": [] } } ], \"audioTag\": { } } }","title":"Examples"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.logIn/","text":"Paella plugin: es.upv.paella.opencast.logIn This plugin adds a button to be able to login. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.logIn plugin. { \"es.upv.paella.opencast.logIn\": { \"enabled\": true } }","title":"es.upv.paella.opencast.logIn"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.logIn/#paella-plugin-esupvpaellaopencastlogin","text":"This plugin adds a button to be able to login. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.logIn"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.logIn/#configuration","text":"You need to enabled the es.upv.paella.opencast.logIn plugin. { \"es.upv.paella.opencast.logIn\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.searchPlugin/","text":"Paella plugin: es.upv.paella.opencast.searchPlugin This plugin enable searches using the OCR trascription. See the Text Extraction Configuration page to configure the service. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.searchPlugin plugin. { \"es.upv.paella.opencast.searchPlugin\": { \"enabled\": true } }","title":"es.upv.paella.opencast.searchPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.searchPlugin/#paella-plugin-esupvpaellaopencastsearchplugin","text":"This plugin enable searches using the OCR trascription. See the Text Extraction Configuration page to configure the service. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.searchPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.searchPlugin/#configuration","text":"You need to enabled the es.upv.paella.opencast.searchPlugin plugin. { \"es.upv.paella.opencast.searchPlugin\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.transcriptionTabBarPlugin/","text":"Paella plugin: es.upv.paella.opencast.transcriptionTabBarPlugin This plugin adds a panel to show the OCR transcriptios. See the Text Extraction Configuration page to configure the service. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.transcriptionTabBarPlugin plugin. { \"es.upv.paella.opencast.transcriptionTabBarPlugin\": { \"enabled\": true } }","title":"es.upv.paella.opencast.transcriptionTabBarPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.transcriptionTabBarPlugin/#paella-plugin-esupvpaellaopencasttranscriptiontabbarplugin","text":"This plugin adds a panel to show the OCR transcriptios. See the Text Extraction Configuration page to configure the service. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.transcriptionTabBarPlugin"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.transcriptionTabBarPlugin/#configuration","text":"You need to enabled the es.upv.paella.opencast.transcriptionTabBarPlugin plugin. { \"es.upv.paella.opencast.transcriptionTabBarPlugin\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.userTrackingSaverPlugIn/","text":"Paella plugin: es.upv.paella.opencast.userTrackingSaverPlugIn This plugin allows to use Opencast Usertracking Service to track usage data. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file . Configuration You need to enabled the es.upv.paella.opencast.userTrackingSaverPlugIn plugin. { \"es.upv.paella.opencast.userTrackingSaverPlugIn\": { \"enabled\": true } }","title":"es.upv.paella.opencast.userTrackingSaverPlugIn"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.userTrackingSaverPlugIn/#paella-plugin-esupvpaellaopencastusertrackingsaverplugin","text":"This plugin allows to use Opencast Usertracking Service to track usage data. The configurations for this plugin are done for each tenant. So you need to modify the plugins section of the paella config file .","title":"Paella plugin: es.upv.paella.opencast.userTrackingSaverPlugIn"},{"location":"modules/paella.player/plugins/es.upv.paella.opencast.userTrackingSaverPlugIn/#configuration","text":"You need to enabled the es.upv.paella.opencast.userTrackingSaverPlugIn plugin. { \"es.upv.paella.opencast.userTrackingSaverPlugIn\": { \"enabled\": true } }","title":"Configuration"},{"location":"modules/searchindex/","text":"Search Indexes Opencast comes with multiple search indexes which act both as a cache and as a fast way to perform full text searches on metadata. By default, all search indexes are created automatically and no additional external software is required. While this works well, all indexes can be deployed separately. This comes with the obvious drawback of a harder deployment but has also a few advantages like a smaller core system or being able to have some service redundancies which would not be possible otherwise. Opencast currently uses two search index types: Solr and Elasticsearch. Solr is mostly powering older services and replacing this index type is planned for the future. But for now it is still the back-end for the search service (LTI and engage tools), the workflow service and the series service. Solr Configuration Guide Elasticsearch is the back-end for both the administrative user interface as well as the external API. Elasticsearch Configuration Guide","title":"Overview"},{"location":"modules/searchindex/#search-indexes","text":"Opencast comes with multiple search indexes which act both as a cache and as a fast way to perform full text searches on metadata. By default, all search indexes are created automatically and no additional external software is required. While this works well, all indexes can be deployed separately. This comes with the obvious drawback of a harder deployment but has also a few advantages like a smaller core system or being able to have some service redundancies which would not be possible otherwise. Opencast currently uses two search index types: Solr and Elasticsearch. Solr is mostly powering older services and replacing this index type is planned for the future. But for now it is still the back-end for the search service (LTI and engage tools), the workflow service and the series service. Solr Configuration Guide Elasticsearch is the back-end for both the administrative user interface as well as the external API. Elasticsearch Configuration Guide","title":"Search Indexes"},{"location":"modules/searchindex/elasticsearch/","text":"Elasticsearch Configuration Elasticsearch is powering the external API as well as the administrative user interface of Opencast. By default, Opencast will start its own, internal Elasticsearch node as part of the admin distribution and no special configuration or deployment is required. Nevertheless, it is possible to connect Opencast to an external Elasticsearch instead. Reasons for this may be: Ability for redundant services Lightweight admin distributions Cluster set-ups Running Elasticsearch When running Elasticsearch, it is recommended to deploy the same version Opencast includes as the client commands may otherwise not match the server. To check the version, take a look at the maven dependency declaration for the elasticsearch bundle in the search module . For example, to quickly spin up an external Elasticsearch matching the current version using Docker, create a simple Elasticsearch configuration file called elasticsearch.yml : cluster.name: opencast network.host: 0.0.0.0 discovery.type: single-node \u2026and run % docker run -p 9200:9200 -p 9300:9300 \\ -v \"$(pwd)/elasticsearch.yml\":/usr/share/elasticsearch/config/elasticsearch.yml \\ elasticsearch:5.6.15 This will already give you a running cluster with the cluster name opencast . Note that the cluster name is important and you will need this to match Opencast's configuration. Configuring External Nodes To configure an external node, set the server's address in etc/custom.properties : org.opencastproject.elasticsearch.server.address=127.0.0.1 Once this is set, Opencast will not launch its own internal Elasticsearch anymore. If necessary, you can also specify a custom port in this configuration file. Next, configure the correct cluster name in etc/elasticsearch.yml . Make sure that the correct cluster name is set in the configuration file of each index: cluster.name: opencast Opencast will now use the external Elasticsearch.","title":"Elasticsearch"},{"location":"modules/searchindex/elasticsearch/#elasticsearch-configuration","text":"Elasticsearch is powering the external API as well as the administrative user interface of Opencast. By default, Opencast will start its own, internal Elasticsearch node as part of the admin distribution and no special configuration or deployment is required. Nevertheless, it is possible to connect Opencast to an external Elasticsearch instead. Reasons for this may be: Ability for redundant services Lightweight admin distributions Cluster set-ups","title":"Elasticsearch Configuration"},{"location":"modules/searchindex/elasticsearch/#running-elasticsearch","text":"When running Elasticsearch, it is recommended to deploy the same version Opencast includes as the client commands may otherwise not match the server. To check the version, take a look at the maven dependency declaration for the elasticsearch bundle in the search module . For example, to quickly spin up an external Elasticsearch matching the current version using Docker, create a simple Elasticsearch configuration file called elasticsearch.yml : cluster.name: opencast network.host: 0.0.0.0 discovery.type: single-node \u2026and run % docker run -p 9200:9200 -p 9300:9300 \\ -v \"$(pwd)/elasticsearch.yml\":/usr/share/elasticsearch/config/elasticsearch.yml \\ elasticsearch:5.6.15 This will already give you a running cluster with the cluster name opencast . Note that the cluster name is important and you will need this to match Opencast's configuration.","title":"Running Elasticsearch"},{"location":"modules/searchindex/elasticsearch/#configuring-external-nodes","text":"To configure an external node, set the server's address in etc/custom.properties : org.opencastproject.elasticsearch.server.address=127.0.0.1 Once this is set, Opencast will not launch its own internal Elasticsearch anymore. If necessary, you can also specify a custom port in this configuration file. Next, configure the correct cluster name in etc/elasticsearch.yml . Make sure that the correct cluster name is set in the configuration file of each index: cluster.name: opencast Opencast will now use the external Elasticsearch.","title":"Configuring External Nodes"},{"location":"modules/searchindex/solr/","text":"Solr Configuration Opencast has Solr included by default. This guide is only needed, if you want to run Solr on a separate server. The software versions in these instructions are not the only versions that will work, they are just the version tested when this document was written. Newer versions of both Tomcat and Solr are highly recommended. Introduction Opencast services use filesystem, relational database, and/or search indexes to store and retrieve information. In order to cluster services across multiple servers, we must provide shared storage solutions for each of these technologies. We do this with NFS or ZFS for filesystems, JDBC for relational databases, and solr for search indexes. If you plan on clustering either the workflow service or the search service, you must configure Opencast to use remote solr servers as described below, otherwise no further action is required. Obtaining the software Solr runs in any modern servlet environment such as Apache Tomcat 7. Download and unpack Tomcat. $ curl -O http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.5-beta/bin/apache-tomcat-7.0.5.zip $ unzip apache-tomcat-7.0.5.zip Download solr from the closest mirror and unpack the zip file. Make sure the permissions are set properly (the zip file doesn't retain proper unix permissions) $ curl -O http://archive.apache.org/dist/lucene/solr/1.4.1/apache-solr-1.4.1.zip $ unzip apache-solr-1.4.1.zip $ chmod 755 apache-tomcat-7.0.5/bin/* Deploy solr to tomcat Copy the solr example war file to tomcat's webapps directory and expand the war file. $ unzip apache-solr-1.4.1/example/webapps/solr.war -d apache-tomcat-7.0.5/webapps/solr/ Configure solr Add the solr config files to the solr webapp in tomcat. If you are setting up the search service, use the solr config from the search module. $ cd apache-tomcat-7.0.5 $ cp -R [opencast source]/modules/search-service-impl/src/main/resources/solr solr Alternatively, if this is the solr index supporting the workflow service, copy those files instead: $ cd apache-tomcat-7.0.5 $ cp -R [opencast source]/modules/workflow-service-impl/src/main/resources/solr solr Edit the dataDir setting in solr/conf/solrconfig.xml to specify the directory you want to use for the index files. Dependency of the workflow index The index has a dependency on a Opencast class. The easiest way of getting rid of this dependency is providing a .jar file with that class within a directory named lib in the solr folder (you may need to create it if it does not exist). The .jar file can be the compiled solr bundle. Placing the jar in the main Tomcat lib directory does not work. Start the server $ bin/startup.sh Using CATALINA_BASE: /Users/josh/Desktop/apache-tomcat-7.0.5 Using CATALINA_HOME: /Users/josh/Desktop/apache-tomcat-7.0.5 Using CATALINA_TMPDIR: /Users/josh/Desktop/apache-tomcat-7.0.5/temp Using JRE_HOME: /System/Library/Frameworks/JavaVM.framework/Versions/CurrentJDK/Home You should see that the solr server is running on http://localhost:8080/solr You can use the admin screen to monitor the server or make ad-hoc queries: Secure the solr server Just like with a relational database server, it is critical that you limit access to the solr server. Opencast's communication with solr servers is unauthenticated, so you must secure a firewall on the solr servers that accepts HTTP requests only from Opencast servers. If these servers were publicly accessible, anyone could make changes to Opencast data from outside Opencast itself. Configure Opencast Set the URL to this solr server in Opencast's custom.properties file: org.opencastproject.search.solr.url=http://your.solr.server.edu:8080/solr/ If this solr server is supporting clustered workflow services: org.opencastproject.workflow.solr.url==http://your.solr.server.edu:8080/solr/ It is important to understand that a solr server provides exactly one schema, and one schema only. If you want to cluster both the workflow service and the search service, you will need two separate solr servers. These solr servers can run on the same machine, but each will needs its own servlet container and port.","title":"Solr"},{"location":"modules/searchindex/solr/#solr-configuration","text":"Opencast has Solr included by default. This guide is only needed, if you want to run Solr on a separate server. The software versions in these instructions are not the only versions that will work, they are just the version tested when this document was written. Newer versions of both Tomcat and Solr are highly recommended.","title":"Solr Configuration"},{"location":"modules/searchindex/solr/#introduction","text":"Opencast services use filesystem, relational database, and/or search indexes to store and retrieve information. In order to cluster services across multiple servers, we must provide shared storage solutions for each of these technologies. We do this with NFS or ZFS for filesystems, JDBC for relational databases, and solr for search indexes. If you plan on clustering either the workflow service or the search service, you must configure Opencast to use remote solr servers as described below, otherwise no further action is required.","title":"Introduction"},{"location":"modules/searchindex/solr/#obtaining-the-software","text":"Solr runs in any modern servlet environment such as Apache Tomcat 7. Download and unpack Tomcat. $ curl -O http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.5-beta/bin/apache-tomcat-7.0.5.zip $ unzip apache-tomcat-7.0.5.zip Download solr from the closest mirror and unpack the zip file. Make sure the permissions are set properly (the zip file doesn't retain proper unix permissions) $ curl -O http://archive.apache.org/dist/lucene/solr/1.4.1/apache-solr-1.4.1.zip $ unzip apache-solr-1.4.1.zip $ chmod 755 apache-tomcat-7.0.5/bin/*","title":"Obtaining the software"},{"location":"modules/searchindex/solr/#deploy-solr-to-tomcat","text":"Copy the solr example war file to tomcat's webapps directory and expand the war file. $ unzip apache-solr-1.4.1/example/webapps/solr.war -d apache-tomcat-7.0.5/webapps/solr/","title":"Deploy solr to tomcat"},{"location":"modules/searchindex/solr/#configure-solr","text":"Add the solr config files to the solr webapp in tomcat. If you are setting up the search service, use the solr config from the search module. $ cd apache-tomcat-7.0.5 $ cp -R [opencast source]/modules/search-service-impl/src/main/resources/solr solr Alternatively, if this is the solr index supporting the workflow service, copy those files instead: $ cd apache-tomcat-7.0.5 $ cp -R [opencast source]/modules/workflow-service-impl/src/main/resources/solr solr Edit the dataDir setting in solr/conf/solrconfig.xml to specify the directory you want to use for the index files.","title":"Configure solr"},{"location":"modules/searchindex/solr/#dependency-of-the-workflow-index","text":"The index has a dependency on a Opencast class. The easiest way of getting rid of this dependency is providing a .jar file with that class within a directory named lib in the solr folder (you may need to create it if it does not exist). The .jar file can be the compiled solr bundle. Placing the jar in the main Tomcat lib directory does not work.","title":"Dependency of the workflow index"},{"location":"modules/searchindex/solr/#start-the-server","text":"$ bin/startup.sh Using CATALINA_BASE: /Users/josh/Desktop/apache-tomcat-7.0.5 Using CATALINA_HOME: /Users/josh/Desktop/apache-tomcat-7.0.5 Using CATALINA_TMPDIR: /Users/josh/Desktop/apache-tomcat-7.0.5/temp Using JRE_HOME: /System/Library/Frameworks/JavaVM.framework/Versions/CurrentJDK/Home You should see that the solr server is running on http://localhost:8080/solr You can use the admin screen to monitor the server or make ad-hoc queries:","title":"Start the server"},{"location":"modules/searchindex/solr/#secure-the-solr-server","text":"Just like with a relational database server, it is critical that you limit access to the solr server. Opencast's communication with solr servers is unauthenticated, so you must secure a firewall on the solr servers that accepts HTTP requests only from Opencast servers. If these servers were publicly accessible, anyone could make changes to Opencast data from outside Opencast itself.","title":"Secure the solr server"},{"location":"modules/searchindex/solr/#configure-opencast","text":"Set the URL to this solr server in Opencast's custom.properties file: org.opencastproject.search.solr.url=http://your.solr.server.edu:8080/solr/ If this solr server is supporting clustered workflow services: org.opencastproject.workflow.solr.url==http://your.solr.server.edu:8080/solr/ It is important to understand that a solr server provides exactly one schema, and one schema only. If you want to cluster both the workflow service and the search service, you will need two separate solr servers. These solr servers can run on the same machine, but each will needs its own servlet container and port.","title":"Configure Opencast"},{"location":"workflowoperationhandlers/","text":"Workflow Operation Handler Introduction Workflows are the central element to define how a media package is being processed by the Opencast services. Their definitions consist of a list of workflow operations, which basically map a piece of configuration to Opencast code: <definition xmlns=\"http://workflow.opencastproject.org\"> .... <operation id=\"tag\" <configurations> <configuration key=\"source-flavors\">presentation/trimmed</configuration> <configuration key=\"target-flavor\">presentation/tagged</configuration> </configurations> </operation> ... </definition> Default Workflow Operations The following table contains the workflow operations that are available in an out-of-the-box Opencast installation: Operation Handler Description Details add-catalog Add a catalog to the media package Documentation analyze-audio Analyze first audio stream Documentation analyze-tracks Analyze tracks in media package Documentation animate Create animated video sequence Documentation asset-delete Deletes the current mediapackage from the Archive Documentation attach-watson-transcription Attaches automated transcripts to mediapackage Documentation cleanup Cleanup the working file repository Documentation clone Clone media package elements to another flavor Documentation comment Add, resolve or delete a comment Documentation compose Encode media files using FFmpeg Documentation composite Compose two videos on one canvas. Documentation concat Concatenate multiple video tracks into one video track Documentation configure-by-dcterm Set workflow parameter if dublincore term matches value Documentation copy Copy media package elements to target directory Documentation cover-image Generate a cover-image containing metadata Documentation crop-video Checks for black bars on the sides of the video Documentation defaults Applies default workflow configuration values Documentation demux Demuxes streams to multiple output files Documentation duplicate-event Create an event by cloning an existing one Documentation editor Waiting for user to review, then cut video based on edit-list Documentation encode Encode media files to differents formats in parallel Documentation error-resolution Internal operation to pause a workflow in error Documentation execute-many Execute a command for each matching element in a MediaPackage Documentation execute-once Execute a command for a MediaPackage Documentation export-wf-properties Export workflow properties Documentation extract-text Extracting text from presentation segments Documentation failing Operations that always fails Documentation google-speech-attach-transcription Attaches automated transcripts to mediapackage Documentation google-speech-start-transcription Starts automated transcription provided by Google Speech Documentation http-notify Notifies an HTTP endpoint about the process of the workflow Documentation image Extract images from a video using FFmpeg Documentation image-convert Convert images using FFmpeg Documentation image-to-video Create a video track from a source image Documentation import-wf-properties Import workflow properties Documentation incident Testing incidents on a dummy job Documentation include Include workflow definition in current workflow Documentation ingest-download Download files from external URL for ingest Documentation inspect Inspect the media (check if it is valid) Documentation log Log workflow status Documentation multiencode Encode to multiple profiles in one operation Documentation normalize-audio Normalize first audio stream Documentation partial-import Import partial tracks and process according to a SMIL document Documentation post-mediapackage Send mediapackage to remote service Documentation prepare-av Preparing audio and video work versions Documentation probe-resolution Set workflow instance variables based on video resolution Documentation process-smil Edit and Encode media defined by a SMIL file Documentation publish-aws Distribute and publish media to Amazon S3 and Cloudfront Documentation publish-configure Distribute and publish media to the configured publication Documentation publish-engage Distribute and publish media to the engage player Documentation publish-oaipmh Distribute and publish media to a OAI-PMH repository Documentation publish-youtube Distribute and publish media to YouTube Documentation republish-oaipmh Update media in a OAI-PMH repository Documentation retract-aws Retracts media from AWS S3 and Cloudfront publication Documentation retract-configure Retracts media from configured publication Documentation retract-engage Retracts media from Opencast Media Module publication Documentation retract-oaipmh Retracts media from a OAI-PMH repository Documentation retract-youtube Retracts media from YouTube Documentation segment-video Extracting segments from presentation Documentation segmentpreviews Extract segment images from a video using FFmpeg Documentation select-streams Select streams for further processing Documentation send-email Sends email notifications at any part of a workflow Documentation series Apply series to the mediapackage Documentation silence Silence detection on audio of the mediapackage Documentation snapshot Archive the current state of the mediapackage Documentation start-watson-transcription Starts automated transcription provided by IBM Watson Documentation start-workflow Start a new workflow for given media package ID Documentation statistics-writer Log statistical data about the video Documentation tag Modify the tag sets of media package elements Documentation tag-by-dcterm Modify the tags if dublincore term matches value Documentation theme Make settings of themes available to processing Documentation timelinepreviews Create a preview image stream from a given video track Documentation transfer-metadata Transfer metadata fields between catalogs Documentation waveform Create a waveform image of the audio of the mediapackage Documentation zip Create zipped archive of the current state of the mediapackage Documentation State Mappings Technically, a workflow can be in one of the following states: Technical State Description What the Admin UI displays in the events table instantiated The workflow is queued and will be started as soon as possible \"Pending\" running The workflow is running, no problems so far \"Running\" stopped The workflow was aborted by the user \"Processing canceled\" paused The workflow was paused and can be continued \"Paused\" succeeded The workflow has completed successfully \"Finished\" failed The workflow failed due to an error \"Processing failure\" failing The workflow is still running, but there were errors. It will fail. \"Running\" Using state mappings, it is possible to refine the labels displayed in the Admin UI events table for a particular workflow. Here is an example which displays \"Retracting\" instead of \"Running\" for the retract workflow: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <definition xmlns=\"http://workflow.opencastproject.org\"> <id>retract</id> ... <state-mappings> <state-mapping state=\"running\">retracting</state-mapping> <state-mapping state=\"failing\">retracting</state-mapping> </state-mappings> When no state mappings are configured for a workflow, the generic default labels will be displayed. When a workflow includes other workflows, the event table only shows the state of the including workflow.","title":"Overview"},{"location":"workflowoperationhandlers/#workflow-operation-handler","text":"","title":"Workflow Operation Handler"},{"location":"workflowoperationhandlers/#introduction","text":"Workflows are the central element to define how a media package is being processed by the Opencast services. Their definitions consist of a list of workflow operations, which basically map a piece of configuration to Opencast code: <definition xmlns=\"http://workflow.opencastproject.org\"> .... <operation id=\"tag\" <configurations> <configuration key=\"source-flavors\">presentation/trimmed</configuration> <configuration key=\"target-flavor\">presentation/tagged</configuration> </configurations> </operation> ... </definition>","title":"Introduction"},{"location":"workflowoperationhandlers/#default-workflow-operations","text":"The following table contains the workflow operations that are available in an out-of-the-box Opencast installation: Operation Handler Description Details add-catalog Add a catalog to the media package Documentation analyze-audio Analyze first audio stream Documentation analyze-tracks Analyze tracks in media package Documentation animate Create animated video sequence Documentation asset-delete Deletes the current mediapackage from the Archive Documentation attach-watson-transcription Attaches automated transcripts to mediapackage Documentation cleanup Cleanup the working file repository Documentation clone Clone media package elements to another flavor Documentation comment Add, resolve or delete a comment Documentation compose Encode media files using FFmpeg Documentation composite Compose two videos on one canvas. Documentation concat Concatenate multiple video tracks into one video track Documentation configure-by-dcterm Set workflow parameter if dublincore term matches value Documentation copy Copy media package elements to target directory Documentation cover-image Generate a cover-image containing metadata Documentation crop-video Checks for black bars on the sides of the video Documentation defaults Applies default workflow configuration values Documentation demux Demuxes streams to multiple output files Documentation duplicate-event Create an event by cloning an existing one Documentation editor Waiting for user to review, then cut video based on edit-list Documentation encode Encode media files to differents formats in parallel Documentation error-resolution Internal operation to pause a workflow in error Documentation execute-many Execute a command for each matching element in a MediaPackage Documentation execute-once Execute a command for a MediaPackage Documentation export-wf-properties Export workflow properties Documentation extract-text Extracting text from presentation segments Documentation failing Operations that always fails Documentation google-speech-attach-transcription Attaches automated transcripts to mediapackage Documentation google-speech-start-transcription Starts automated transcription provided by Google Speech Documentation http-notify Notifies an HTTP endpoint about the process of the workflow Documentation image Extract images from a video using FFmpeg Documentation image-convert Convert images using FFmpeg Documentation image-to-video Create a video track from a source image Documentation import-wf-properties Import workflow properties Documentation incident Testing incidents on a dummy job Documentation include Include workflow definition in current workflow Documentation ingest-download Download files from external URL for ingest Documentation inspect Inspect the media (check if it is valid) Documentation log Log workflow status Documentation multiencode Encode to multiple profiles in one operation Documentation normalize-audio Normalize first audio stream Documentation partial-import Import partial tracks and process according to a SMIL document Documentation post-mediapackage Send mediapackage to remote service Documentation prepare-av Preparing audio and video work versions Documentation probe-resolution Set workflow instance variables based on video resolution Documentation process-smil Edit and Encode media defined by a SMIL file Documentation publish-aws Distribute and publish media to Amazon S3 and Cloudfront Documentation publish-configure Distribute and publish media to the configured publication Documentation publish-engage Distribute and publish media to the engage player Documentation publish-oaipmh Distribute and publish media to a OAI-PMH repository Documentation publish-youtube Distribute and publish media to YouTube Documentation republish-oaipmh Update media in a OAI-PMH repository Documentation retract-aws Retracts media from AWS S3 and Cloudfront publication Documentation retract-configure Retracts media from configured publication Documentation retract-engage Retracts media from Opencast Media Module publication Documentation retract-oaipmh Retracts media from a OAI-PMH repository Documentation retract-youtube Retracts media from YouTube Documentation segment-video Extracting segments from presentation Documentation segmentpreviews Extract segment images from a video using FFmpeg Documentation select-streams Select streams for further processing Documentation send-email Sends email notifications at any part of a workflow Documentation series Apply series to the mediapackage Documentation silence Silence detection on audio of the mediapackage Documentation snapshot Archive the current state of the mediapackage Documentation start-watson-transcription Starts automated transcription provided by IBM Watson Documentation start-workflow Start a new workflow for given media package ID Documentation statistics-writer Log statistical data about the video Documentation tag Modify the tag sets of media package elements Documentation tag-by-dcterm Modify the tags if dublincore term matches value Documentation theme Make settings of themes available to processing Documentation timelinepreviews Create a preview image stream from a given video track Documentation transfer-metadata Transfer metadata fields between catalogs Documentation waveform Create a waveform image of the audio of the mediapackage Documentation zip Create zipped archive of the current state of the mediapackage Documentation","title":"Default Workflow Operations"},{"location":"workflowoperationhandlers/#state-mappings","text":"Technically, a workflow can be in one of the following states: Technical State Description What the Admin UI displays in the events table instantiated The workflow is queued and will be started as soon as possible \"Pending\" running The workflow is running, no problems so far \"Running\" stopped The workflow was aborted by the user \"Processing canceled\" paused The workflow was paused and can be continued \"Paused\" succeeded The workflow has completed successfully \"Finished\" failed The workflow failed due to an error \"Processing failure\" failing The workflow is still running, but there were errors. It will fail. \"Running\" Using state mappings, it is possible to refine the labels displayed in the Admin UI events table for a particular workflow. Here is an example which displays \"Retracting\" instead of \"Running\" for the retract workflow: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <definition xmlns=\"http://workflow.opencastproject.org\"> <id>retract</id> ... <state-mappings> <state-mapping state=\"running\">retracting</state-mapping> <state-mapping state=\"failing\">retracting</state-mapping> </state-mappings> When no state mappings are configured for a workflow, the generic default labels will be displayed. When a workflow includes other workflows, the event table only shows the state of the including workflow.","title":"State Mappings"},{"location":"workflowoperationhandlers/add-catalog-woh/","text":"AddCatalogWorkflowOperationHandler Description This operation adds a catalog to the media package of the running workflow. The catalog to add is specified by path. Additionally the name, flavor and tags of the catalog can be configured. If a catalog of the same flavor already exits in the media package, the parameter catalog-type-collision-behavior specifies how this case is handled. Parameter Table Configuration Key Example Description catalog-path ${karaf.etc}/catalogs/default_dublincore.xml Path to the catalog catalog-flavor dublincore/episode Flavor of the catalog catalog-name dublincore.xml Name of the catalog catalog-tags archive,dublincore List of tags, separated by commas catalog-type-collision-behavior keep How a collision is handled (more information below) All parameters are mandatory except catalog-tags . catalog-type-collision-behavior If the flavor of the new catalog and the flavor of an already existing catalog match, the catalog-type-collision-behavior specifies how this situation is handled. There are multiple supported options: - keep : The new catalog is added despite the collision. This results in two catalogs of the same type coexisting. - skip : The addition of the new catalog is skipped, the new catalog is not added. - fail : The workflow operation fails with an error, depending on the your configurations the complete workflow is aborted. Operation Example <operation id=\"add-catalog\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Add catalog to media package\"> <configurations> <configuration key=\"catalog-path\">${karaf.etc}/catalogs/default_dublincore.xml</configuration> <configuration key=\"catalog-flavor\">dublincore/episode</configuration> <configuration key=\"catalog-name\">dublincore.xml</configuration> <configuration key=\"catalog-tags\">archive,dublincore</configuration> <configuration key=\"catalog-type-collision-behavior\">keep</configuration> </configurations> </operation>","title":"Add Catalog"},{"location":"workflowoperationhandlers/add-catalog-woh/#addcatalogworkflowoperationhandler","text":"","title":"AddCatalogWorkflowOperationHandler"},{"location":"workflowoperationhandlers/add-catalog-woh/#description","text":"This operation adds a catalog to the media package of the running workflow. The catalog to add is specified by path. Additionally the name, flavor and tags of the catalog can be configured. If a catalog of the same flavor already exits in the media package, the parameter catalog-type-collision-behavior specifies how this case is handled.","title":"Description"},{"location":"workflowoperationhandlers/add-catalog-woh/#parameter-table","text":"Configuration Key Example Description catalog-path ${karaf.etc}/catalogs/default_dublincore.xml Path to the catalog catalog-flavor dublincore/episode Flavor of the catalog catalog-name dublincore.xml Name of the catalog catalog-tags archive,dublincore List of tags, separated by commas catalog-type-collision-behavior keep How a collision is handled (more information below) All parameters are mandatory except catalog-tags .","title":"Parameter Table"},{"location":"workflowoperationhandlers/add-catalog-woh/#catalog-type-collision-behavior","text":"If the flavor of the new catalog and the flavor of an already existing catalog match, the catalog-type-collision-behavior specifies how this situation is handled. There are multiple supported options: - keep : The new catalog is added despite the collision. This results in two catalogs of the same type coexisting. - skip : The addition of the new catalog is skipped, the new catalog is not added. - fail : The workflow operation fails with an error, depending on the your configurations the complete workflow is aborted.","title":"catalog-type-collision-behavior"},{"location":"workflowoperationhandlers/add-catalog-woh/#operation-example","text":"<operation id=\"add-catalog\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Add catalog to media package\"> <configurations> <configuration key=\"catalog-path\">${karaf.etc}/catalogs/default_dublincore.xml</configuration> <configuration key=\"catalog-flavor\">dublincore/episode</configuration> <configuration key=\"catalog-name\">dublincore.xml</configuration> <configuration key=\"catalog-tags\">archive,dublincore</configuration> <configuration key=\"catalog-type-collision-behavior\">keep</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/analyze-tracks-woh/","text":"AnalyzeTracksWorkflowOperationHandler Description The AnalyzeTracksWorkflowOperationHandler analyzes specified tracks in the mediapackage and sets workflow instance variables based on the tracks audio and video properties. These variables can then be used to control if workflow operations should be executed. Note that this operation should be preceded by the inspect workflow operation handler. For all tracks matching the flavor specified by the mandatory configuration key source-flavor , the following workflow instance variables may be set: Name Example Description flavor _media presenter_source_media=true Track with specific favor exists flavor _audio presenter_source_audio=true Track contains at least one audio stream flavor _video presenter_source_video=true Track contains at least one video stream flavor _resolution_x presenter_source_resolution_x=1280 Horizontal resolution of the video stream flavor _resolution_y presenter_source_resolution_y=720 Vertical resolution of the video stream flavor _aspect presenter_source_aspect=4/3 Exact aspect ratio of the video stream flavor _aspect_snap presenter_source_aspect_snap=4/3 Nearest specified aspect ratio of the video flavor _framerate presenter_source_framerate=30.0 Framerate of the video stream Parameter Table Configuration Key Example Description source-flavor* presentation/work The \"flavor\" of the track to use as a source input aspect-ratio 4/3,16/9 Snap to these aspect ratios if specified fail-no-tracks false Fail if flavor matches no tracks (Default: false) * mandatory configuration key Note that if there are multiple video streams with one flavor, only the information from the last video stream are taken. Snap to Aspect Ratio Snap-to-aspect can be used to deal with slightly off resolutions. Given an SAR of 1, for example, a video with the resolution of 640x481 pixels has almost an aspect ration of 4/3, but is 1 pixel too wide. For special encoding options or cover generation, it would still be reasonable to use the 4/3 settings. If 4/3 is listed in the aspect-ratio option, \u2026_aspect_snap would be set to 4/3. Operation Example <operation id=\"analyze-tracks\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Analyze tracks in media package and set control variables\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"aspect-ratio\">4/3,16/9</configuration> </configurations> </operation> If a video track with a resolution of 1280x720 and an included audio stream is passed to this operation as presentiation/source , the resulting variables would be: presentation_source_aspect=16/9 presentation_source_aspect_snap=16/9 presentation_source_audio=true presentation_source_media=true presentation_source_resolution_x=1280 presentation_source_resolution_y=720 presentation_source_video=true presentation_source_framerate=30.0","title":"Analyze Tracks"},{"location":"workflowoperationhandlers/analyze-tracks-woh/#analyzetracksworkflowoperationhandler","text":"","title":"AnalyzeTracksWorkflowOperationHandler"},{"location":"workflowoperationhandlers/analyze-tracks-woh/#description","text":"The AnalyzeTracksWorkflowOperationHandler analyzes specified tracks in the mediapackage and sets workflow instance variables based on the tracks audio and video properties. These variables can then be used to control if workflow operations should be executed. Note that this operation should be preceded by the inspect workflow operation handler. For all tracks matching the flavor specified by the mandatory configuration key source-flavor , the following workflow instance variables may be set: Name Example Description flavor _media presenter_source_media=true Track with specific favor exists flavor _audio presenter_source_audio=true Track contains at least one audio stream flavor _video presenter_source_video=true Track contains at least one video stream flavor _resolution_x presenter_source_resolution_x=1280 Horizontal resolution of the video stream flavor _resolution_y presenter_source_resolution_y=720 Vertical resolution of the video stream flavor _aspect presenter_source_aspect=4/3 Exact aspect ratio of the video stream flavor _aspect_snap presenter_source_aspect_snap=4/3 Nearest specified aspect ratio of the video flavor _framerate presenter_source_framerate=30.0 Framerate of the video stream","title":"Description"},{"location":"workflowoperationhandlers/analyze-tracks-woh/#parameter-table","text":"Configuration Key Example Description source-flavor* presentation/work The \"flavor\" of the track to use as a source input aspect-ratio 4/3,16/9 Snap to these aspect ratios if specified fail-no-tracks false Fail if flavor matches no tracks (Default: false) * mandatory configuration key Note that if there are multiple video streams with one flavor, only the information from the last video stream are taken.","title":"Parameter Table"},{"location":"workflowoperationhandlers/analyze-tracks-woh/#snap-to-aspect-ratio","text":"Snap-to-aspect can be used to deal with slightly off resolutions. Given an SAR of 1, for example, a video with the resolution of 640x481 pixels has almost an aspect ration of 4/3, but is 1 pixel too wide. For special encoding options or cover generation, it would still be reasonable to use the 4/3 settings. If 4/3 is listed in the aspect-ratio option, \u2026_aspect_snap would be set to 4/3.","title":"Snap to Aspect Ratio"},{"location":"workflowoperationhandlers/analyze-tracks-woh/#operation-example","text":"<operation id=\"analyze-tracks\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Analyze tracks in media package and set control variables\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"aspect-ratio\">4/3,16/9</configuration> </configurations> </operation> If a video track with a resolution of 1280x720 and an included audio stream is passed to this operation as presentiation/source , the resulting variables would be: presentation_source_aspect=16/9 presentation_source_aspect_snap=16/9 presentation_source_audio=true presentation_source_media=true presentation_source_resolution_x=1280 presentation_source_resolution_y=720 presentation_source_video=true presentation_source_framerate=30.0","title":"Operation Example"},{"location":"workflowoperationhandlers/analyzeaudio-woh/","text":"AnalyzeAudioWorkflowOperationHandler Description The AnalyzeAudioiWorkflowOperationHandler analyzes the first audio stream of a video or audio track through SoX (http://sox.sourceforge.net/) and writes the result back to the given track. This workflow operation handler can be used with audio and/or video files. At least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs: Used with Audio only file (forceTranscode is deactivated): Analyze the given audio file with SoX Write analyzed audio metadata back to the given track's mediapackage. Used with Video file or with Audio only file with forceTranscode activated: Extract audio file encoded as FLAC audio and save it temporary in a collection Analyze the previous encoded audio file with SoX Write analyzed audio metadata back to the given track's mediapackage. Delete the temporary encoded FLAC audio file Example result track: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?> <track type=\"presentation/audio\" id=\"audio\"> <mimetype>video/x-flac</mimetype> <tags /> <url>fooVideo.flac</url> <checksum type=\"md5\">46cb2e9df2e73756b0d96c33b1aaf055</checksum> <duration>65680</duration> <audio id=\"audio-1\"> <device /> <encoder type=\"ADPCM\" /> <bitdepth>16</bitdepth> <channels>2</channels> <bitrate>62500.0</bitrate> <peakleveldb>-30</peakleveldb> <!-- NEW --> <rmsleveldb>-20</rmsleveldb> <!-- NEW --> <rmspeakdb>-10</rmspeakdb> <!-- NEW --> </audio> </track> Parameter Table configuration keys example description default value source-flavors \"presentation/work,presenter/work\" The \"flavors\" of the track to use as a source input EMPTY source-flavor \"presentation/work\" The \"flavor\" of the track to use as a source input EMPTY source-tags \"engage,atom,rss\" The \"tag\" of the track to use as a source input EMPTY force-transcode \"true\" or \"false\" Whether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format) FALSE Operation Example <operation id=\"analyze-audio\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Analyze audio stream\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"force-transcode\">true</configuration> </configurations> </operation>","title":"Analyze Audio"},{"location":"workflowoperationhandlers/analyzeaudio-woh/#analyzeaudioworkflowoperationhandler","text":"","title":"AnalyzeAudioWorkflowOperationHandler"},{"location":"workflowoperationhandlers/analyzeaudio-woh/#description","text":"The AnalyzeAudioiWorkflowOperationHandler analyzes the first audio stream of a video or audio track through SoX (http://sox.sourceforge.net/) and writes the result back to the given track. This workflow operation handler can be used with audio and/or video files. At least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs:","title":"Description"},{"location":"workflowoperationhandlers/analyzeaudio-woh/#used-with-audio-only-file-forcetranscode-is-deactivated","text":"Analyze the given audio file with SoX Write analyzed audio metadata back to the given track's mediapackage.","title":"Used with Audio only file (forceTranscode is deactivated):"},{"location":"workflowoperationhandlers/analyzeaudio-woh/#used-with-video-file-or-with-audio-only-file-with-forcetranscode-activated","text":"Extract audio file encoded as FLAC audio and save it temporary in a collection Analyze the previous encoded audio file with SoX Write analyzed audio metadata back to the given track's mediapackage. Delete the temporary encoded FLAC audio file Example result track: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?> <track type=\"presentation/audio\" id=\"audio\"> <mimetype>video/x-flac</mimetype> <tags /> <url>fooVideo.flac</url> <checksum type=\"md5\">46cb2e9df2e73756b0d96c33b1aaf055</checksum> <duration>65680</duration> <audio id=\"audio-1\"> <device /> <encoder type=\"ADPCM\" /> <bitdepth>16</bitdepth> <channels>2</channels> <bitrate>62500.0</bitrate> <peakleveldb>-30</peakleveldb> <!-- NEW --> <rmsleveldb>-20</rmsleveldb> <!-- NEW --> <rmspeakdb>-10</rmspeakdb> <!-- NEW --> </audio> </track>","title":"Used with Video file or with Audio only file with forceTranscode activated:"},{"location":"workflowoperationhandlers/analyzeaudio-woh/#parameter-table","text":"configuration keys example description default value source-flavors \"presentation/work,presenter/work\" The \"flavors\" of the track to use as a source input EMPTY source-flavor \"presentation/work\" The \"flavor\" of the track to use as a source input EMPTY source-tags \"engage,atom,rss\" The \"tag\" of the track to use as a source input EMPTY force-transcode \"true\" or \"false\" Whether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format) FALSE","title":"Parameter Table"},{"location":"workflowoperationhandlers/analyzeaudio-woh/#operation-example","text":"<operation id=\"analyze-audio\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Analyze audio stream\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"force-transcode\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/animate-woh/","text":"Animate Workflow Operation ID: animate Description The animate operation can be used to generate an animated video clip using Synfig . It can automatically including episode and series metadata (e.g. the title) into the animation. For example, this can be used to automatically generate custom intro videos. Parameter Table configuration keys required description animation-files yes The source animation file to use target-flavor yes Flavor of the generated video width no Width of the generated video height no Height of the generated video fps no FPS of the generated video cmd-args no Custom synfig arguments. Will override all arguments except input and output file target-tags no Tags for the generated video Synfig Files Synfig animation files used for input must be saved uncompressed or the metadata replacement will not work. Uncompressed files usually have the file extension .sif and not .sifz . Metadata Replacements You can use all metadata fields present in the episode and series DublinCore catalogs of an event. In SynfigStudio, just use placeholders of the following form: '{{' ['series' | 'episode'] '.' DC-FIELD '}}' Here are some common examples: {{episode.title}} {{episode.creator}} {{series.title}} Operation Examples <operation id=\"animate\" description=\"Create animated video clip\"> <configurations> <configuration key=\"animation-file\">/path/to/animation.sif</configuration> <configuration key=\"target-flavor\">presentation/intro</configuration> <configuration key=\"target-tags\">archive</configuration> </configurations> </operation>","title":"Animate"},{"location":"workflowoperationhandlers/animate-woh/#animate-workflow-operation","text":"ID: animate","title":"Animate Workflow Operation"},{"location":"workflowoperationhandlers/animate-woh/#description","text":"The animate operation can be used to generate an animated video clip using Synfig . It can automatically including episode and series metadata (e.g. the title) into the animation. For example, this can be used to automatically generate custom intro videos.","title":"Description"},{"location":"workflowoperationhandlers/animate-woh/#parameter-table","text":"configuration keys required description animation-files yes The source animation file to use target-flavor yes Flavor of the generated video width no Width of the generated video height no Height of the generated video fps no FPS of the generated video cmd-args no Custom synfig arguments. Will override all arguments except input and output file target-tags no Tags for the generated video","title":"Parameter Table"},{"location":"workflowoperationhandlers/animate-woh/#synfig-files","text":"Synfig animation files used for input must be saved uncompressed or the metadata replacement will not work. Uncompressed files usually have the file extension .sif and not .sifz .","title":"Synfig Files"},{"location":"workflowoperationhandlers/animate-woh/#metadata-replacements","text":"You can use all metadata fields present in the episode and series DublinCore catalogs of an event. In SynfigStudio, just use placeholders of the following form: '{{' ['series' | 'episode'] '.' DC-FIELD '}}' Here are some common examples: {{episode.title}} {{episode.creator}} {{series.title}}","title":"Metadata Replacements"},{"location":"workflowoperationhandlers/animate-woh/#operation-examples","text":"<operation id=\"animate\" description=\"Create animated video clip\"> <configurations> <configuration key=\"animation-file\">/path/to/animation.sif</configuration> <configuration key=\"target-flavor\">presentation/intro</configuration> <configuration key=\"target-tags\">archive</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/asset-delete-woh/","text":"AssetManagerDeleteWorkflowOperationHandler Description The delete handler is responsible for deleting an episode, identified by the workflow\u2019s current media package, from the asset manager. If no parameter is given, the whole episode and all of its snapshots are deleted. If the keep-last-snapshot parameter is used, it is advised to use the ingest-download workflow before asset-delete . Otherwise there will be logged a lot of errors for unreferenced snapshots. Parameter Table Configuration Key Example Description keep-last-snapshot true Deletes every snapshot except the last one. Operation Example <operation id=\"asset-delete\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Delete from AssetManager\"> <configurations> <configuration key=\"keep-last-snapshot\">true</configuration> </configurations> </operation>","title":"Asset Delete"},{"location":"workflowoperationhandlers/asset-delete-woh/#assetmanagerdeleteworkflowoperationhandler","text":"","title":"AssetManagerDeleteWorkflowOperationHandler"},{"location":"workflowoperationhandlers/asset-delete-woh/#description","text":"The delete handler is responsible for deleting an episode, identified by the workflow\u2019s current media package, from the asset manager. If no parameter is given, the whole episode and all of its snapshots are deleted. If the keep-last-snapshot parameter is used, it is advised to use the ingest-download workflow before asset-delete . Otherwise there will be logged a lot of errors for unreferenced snapshots.","title":"Description"},{"location":"workflowoperationhandlers/asset-delete-woh/#parameter-table","text":"Configuration Key Example Description keep-last-snapshot true Deletes every snapshot except the last one.","title":"Parameter Table"},{"location":"workflowoperationhandlers/asset-delete-woh/#operation-example","text":"<operation id=\"asset-delete\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Delete from AssetManager\"> <configurations> <configuration key=\"keep-last-snapshot\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/attach-watson-transcription-woh/","text":"Attach Watson Transcription Description The Attach Watson Transcription converts the results file received from the IBM Watson Speech-to-Text service in json format, converts it to the desired caption format, and adds it to the media package. Parameter Table configuration keys description default value example transcription-job-id This is filled out by the transcription service when starting the workflow. EMPTY Should always be \"${transcriptionJobId}\" target-flavor The flavor of the caption/transcription file generated. Mandatory only if target-caption-format not informed. captions/ target-caption-format + language captions/vtt+en target-tag The tag to apply to the caption/transcription file generated. Optional. EMPTY archive target-caption-format The caption format to be generated. Optional. If not entered, the raw resulting file will be attached to the media package with the flavor target-flavor . EMPTY vtt Example <!-- Attach caption/transcript --> <operation id=\"attach-watson-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Attach captions/transcription\"> <configurations> <!-- This is filled out by the transcription service when starting this workflow so just use this as is --> <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration> <configuration key=\"target-tag\">archive</configuration> <!-- Caption generated will have the default flavor based on the target-caption-format and language e.g. captions/vtt+en --> <configuration key=\"target-caption-format\">vtt</configuration> <configuration key=\"target-tag\">engage-download</configuration> </configurations> </operation> <!-- Merge caption/transcript to existing publication and republish --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Distribute and publish to engage server\"> <configurations> <configuration key=\"download-source-tags\">engage-download</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation>","title":"Attach Watson Transcription"},{"location":"workflowoperationhandlers/attach-watson-transcription-woh/#attach-watson-transcription","text":"","title":"Attach Watson Transcription"},{"location":"workflowoperationhandlers/attach-watson-transcription-woh/#description","text":"The Attach Watson Transcription converts the results file received from the IBM Watson Speech-to-Text service in json format, converts it to the desired caption format, and adds it to the media package.","title":"Description"},{"location":"workflowoperationhandlers/attach-watson-transcription-woh/#parameter-table","text":"configuration keys description default value example transcription-job-id This is filled out by the transcription service when starting the workflow. EMPTY Should always be \"${transcriptionJobId}\" target-flavor The flavor of the caption/transcription file generated. Mandatory only if target-caption-format not informed. captions/ target-caption-format + language captions/vtt+en target-tag The tag to apply to the caption/transcription file generated. Optional. EMPTY archive target-caption-format The caption format to be generated. Optional. If not entered, the raw resulting file will be attached to the media package with the flavor target-flavor . EMPTY vtt","title":"Parameter Table"},{"location":"workflowoperationhandlers/attach-watson-transcription-woh/#example","text":"<!-- Attach caption/transcript --> <operation id=\"attach-watson-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Attach captions/transcription\"> <configurations> <!-- This is filled out by the transcription service when starting this workflow so just use this as is --> <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration> <configuration key=\"target-tag\">archive</configuration> <!-- Caption generated will have the default flavor based on the target-caption-format and language e.g. captions/vtt+en --> <configuration key=\"target-caption-format\">vtt</configuration> <configuration key=\"target-tag\">engage-download</configuration> </configurations> </operation> <!-- Merge caption/transcript to existing publication and republish --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Distribute and publish to engage server\"> <configurations> <configuration key=\"download-source-tags\">engage-download</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation>","title":"Example"},{"location":"workflowoperationhandlers/cleanup-woh/","text":"CleanupWorkflowOperationHandler Description This operation removes all files from the workspace and the working file repository which belong to media package elements of the running workflow unless their flavor is matched by the value configured in preserve-flavors . It is usually used as last workflow operation in a workflow to ensure that temporary processing artefacts are removed. Parameter Table Configuration Key Example Description Default preserve-flavors security/* Comma-separated list of flavors to be preserved. delete-external true If files from external working file repositories should be deleted false delay 5 Seconds to wait before removing files 1 Notes If delete-external is set to true , the externally referenced media package elements will be removed from its source where the value of preserve-flavors does not match If you have an shared working file repository setting delete-external to false will speed up the cleanup process while still removing all files. Operation Example <operation id=\"cleanup\" fail-on-error=\"false\" description=\"Remove temporary processing artifacts\"> <configurations> <configuration key=\"preserve-flavors\">security/*</configuration> <configuration key=\"delete-external\">true</configuration> <configuration key=\"delay\">5</configuration> </configurations> </operation>","title":"Cleanup"},{"location":"workflowoperationhandlers/cleanup-woh/#cleanupworkflowoperationhandler","text":"","title":"CleanupWorkflowOperationHandler"},{"location":"workflowoperationhandlers/cleanup-woh/#description","text":"This operation removes all files from the workspace and the working file repository which belong to media package elements of the running workflow unless their flavor is matched by the value configured in preserve-flavors . It is usually used as last workflow operation in a workflow to ensure that temporary processing artefacts are removed.","title":"Description"},{"location":"workflowoperationhandlers/cleanup-woh/#parameter-table","text":"Configuration Key Example Description Default preserve-flavors security/* Comma-separated list of flavors to be preserved. delete-external true If files from external working file repositories should be deleted false delay 5 Seconds to wait before removing files 1","title":"Parameter Table"},{"location":"workflowoperationhandlers/cleanup-woh/#notes","text":"If delete-external is set to true , the externally referenced media package elements will be removed from its source where the value of preserve-flavors does not match If you have an shared working file repository setting delete-external to false will speed up the cleanup process while still removing all files.","title":"Notes"},{"location":"workflowoperationhandlers/cleanup-woh/#operation-example","text":"<operation id=\"cleanup\" fail-on-error=\"false\" description=\"Remove temporary processing artifacts\"> <configurations> <configuration key=\"preserve-flavors\">security/*</configuration> <configuration key=\"delete-external\">true</configuration> <configuration key=\"delay\">5</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/clone-woh/","text":"Clone Workflow Operation ID: clone Description The clone workflow operation can be used to clone media package elements. Parameter Table Configuration Key Example Description source-flavor presenter/source The source flavor(s) to clone source-tags archive Comma-separated list of source-tags target-flavor* presenter/target The target flavor * mandatory configuration key Notes: source-flavor and source-tags may be used both together to select media package elements based on both flavors and tags If source-flavor is not specified, all media package elements matching source-tags will be selected In case that neither source-flavor nor source-tags are specified, the operation will be skipped In case no media package elements match source-flavor and source-tags , the operation will be skipped Source Flavor If source-flavor is specified as e.g. */source , all matching media package elements will be cloned and have the new flavor <original-flavor>/target . Target Flavor If target-flavor is specified as e.g. */target , the target flavors will have the subtype target and the type from the source If target-flavor is specified as e.g. target/* , the target flavors will have the type target and the subtype from the source. Operation Example <operation id=\"clone\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"source-tags\">archive</configuration> <configuration key=\"target-flavor\">*/target</configuration> </configurations> </operation>","title":"Clone"},{"location":"workflowoperationhandlers/clone-woh/#clone-workflow-operation","text":"ID: clone","title":"Clone Workflow Operation"},{"location":"workflowoperationhandlers/clone-woh/#description","text":"The clone workflow operation can be used to clone media package elements.","title":"Description"},{"location":"workflowoperationhandlers/clone-woh/#parameter-table","text":"Configuration Key Example Description source-flavor presenter/source The source flavor(s) to clone source-tags archive Comma-separated list of source-tags target-flavor* presenter/target The target flavor * mandatory configuration key Notes: source-flavor and source-tags may be used both together to select media package elements based on both flavors and tags If source-flavor is not specified, all media package elements matching source-tags will be selected In case that neither source-flavor nor source-tags are specified, the operation will be skipped In case no media package elements match source-flavor and source-tags , the operation will be skipped","title":"Parameter Table"},{"location":"workflowoperationhandlers/clone-woh/#source-flavor","text":"If source-flavor is specified as e.g. */source , all matching media package elements will be cloned and have the new flavor <original-flavor>/target .","title":"Source Flavor"},{"location":"workflowoperationhandlers/clone-woh/#target-flavor","text":"If target-flavor is specified as e.g. */target , the target flavors will have the subtype target and the type from the source If target-flavor is specified as e.g. target/* , the target flavors will have the type target and the subtype from the source.","title":"Target Flavor"},{"location":"workflowoperationhandlers/clone-woh/#operation-example","text":"<operation id=\"clone\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"source-tags\">archive</configuration> <configuration key=\"target-flavor\">*/target</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/comment-woh/","text":"CommentWorkflowOperationHandler Description The CommentWorkflowOperationHandler can be used to create, resolve or delete comments for events within workflows. Parameter Table Configuration Key Example Description action create Action to be performed: create, resolve or delete. Default value is create. reason EVENTS.EVENTS.DETAILS. COMMENTS.REASONS.CUTTING The comment reason's i18n id. You can find the id in etc/listproviders/ event.comment.reasons.properties description Recording has not been cut yet. The description text to add to the comment. Notes: reason and description must be provided for the create action. create will not create duplicate comments: if there is already a comment with the same reason and description, a new comment will not be created. resolve and delete will perform no action if no comment matches the provided parameters (reason, description, or reason and description). If more than one comment matches the parameters, only the first matching comment will be resolved or deleted. Operation Examples Create a comment: <operation id=\"comment\" description=\"Mark the recording for cutting\"> <configurations> <configuration key=\"action\">create</configuration> <configuration key=\"reason\">EVENTS.EVENTS.DETAILS.COMMENTS.REASONS.CUTTING</configuration> <configuration key=\"description\">Recording has not been cut yet.</configuration> </configurations> </operation> Resolve a comment: <operation id=\"comment\" description=\"Resolve the cutting flag\"> <configurations> <configuration key=\"action\">resolve</configuration> <configuration key=\"reason\">EVENTS.EVENTS.DETAILS.COMMENTS.REASONS.CUTTING</configuration> </configurations> </operation>","title":"Comment"},{"location":"workflowoperationhandlers/comment-woh/#commentworkflowoperationhandler","text":"","title":"CommentWorkflowOperationHandler"},{"location":"workflowoperationhandlers/comment-woh/#description","text":"The CommentWorkflowOperationHandler can be used to create, resolve or delete comments for events within workflows.","title":"Description"},{"location":"workflowoperationhandlers/comment-woh/#parameter-table","text":"Configuration Key Example Description action create Action to be performed: create, resolve or delete. Default value is create. reason EVENTS.EVENTS.DETAILS. COMMENTS.REASONS.CUTTING The comment reason's i18n id. You can find the id in etc/listproviders/ event.comment.reasons.properties description Recording has not been cut yet. The description text to add to the comment. Notes: reason and description must be provided for the create action. create will not create duplicate comments: if there is already a comment with the same reason and description, a new comment will not be created. resolve and delete will perform no action if no comment matches the provided parameters (reason, description, or reason and description). If more than one comment matches the parameters, only the first matching comment will be resolved or deleted.","title":"Parameter Table"},{"location":"workflowoperationhandlers/comment-woh/#operation-examples","text":"Create a comment: <operation id=\"comment\" description=\"Mark the recording for cutting\"> <configurations> <configuration key=\"action\">create</configuration> <configuration key=\"reason\">EVENTS.EVENTS.DETAILS.COMMENTS.REASONS.CUTTING</configuration> <configuration key=\"description\">Recording has not been cut yet.</configuration> </configurations> </operation> Resolve a comment: <operation id=\"comment\" description=\"Resolve the cutting flag\"> <configurations> <configuration key=\"action\">resolve</configuration> <configuration key=\"reason\">EVENTS.EVENTS.DETAILS.COMMENTS.REASONS.CUTTING</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/compose-woh/","text":"ComposeWorkflowHandler Description The ComposeWorkflowHandler is used to encode media files to different formats using FFmpeg. Parameter Table configuration keys example description source-flavor presenter/work Which media should be encoded target-flavor presenter/delivery Specifies the flavor of the new media source-tags sometag Tags of media to encode target-tags sometag Specifies the tags of the new media encoding-profile mp4-hd.http Specifies the encoding profile to use encoding-profiles mp4-low.http,mp4-hd.http Specifies a comma-separated encoding profiles to use tags-and-flavors true When false (default), the operation selects input elements that have EITHER any of the source tags OR the source flavor. When true, the operation selects input elements that have BOTH the source-flavor AND any of the source tags Operation Examples Encoding presenter (camera) video to MP4 medium quality: <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Encoding presenter (camera) video to MP4 medium quality\"> <configurations> <configuration key=\"source-flavor\">presenter/trimmed</configuration> <configuration key=\"target-flavor\">presenter/delivery</configuration> <configuration key=\"target-tags\">engage-download</configuration> <configuration key=\"encoding-profile\">mp4-medium.http</configuration> </configurations> </operation> Encoding 480p, 720p and 1080p video to MP4 adaptive streaming: <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Encoding 480p, 720p and 1080p video to MP4 streaming\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/delivery</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <configuration key=\"encoding-profiles\">adaptive-480p.http,adaptive-720p.http,adaptive-1080p.http</configuration> </configurations> </operation>","title":"Compose"},{"location":"workflowoperationhandlers/compose-woh/#composeworkflowhandler","text":"","title":"ComposeWorkflowHandler"},{"location":"workflowoperationhandlers/compose-woh/#description","text":"The ComposeWorkflowHandler is used to encode media files to different formats using FFmpeg.","title":"Description"},{"location":"workflowoperationhandlers/compose-woh/#parameter-table","text":"configuration keys example description source-flavor presenter/work Which media should be encoded target-flavor presenter/delivery Specifies the flavor of the new media source-tags sometag Tags of media to encode target-tags sometag Specifies the tags of the new media encoding-profile mp4-hd.http Specifies the encoding profile to use encoding-profiles mp4-low.http,mp4-hd.http Specifies a comma-separated encoding profiles to use tags-and-flavors true When false (default), the operation selects input elements that have EITHER any of the source tags OR the source flavor. When true, the operation selects input elements that have BOTH the source-flavor AND any of the source tags","title":"Parameter Table"},{"location":"workflowoperationhandlers/compose-woh/#operation-examples","text":"Encoding presenter (camera) video to MP4 medium quality: <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Encoding presenter (camera) video to MP4 medium quality\"> <configurations> <configuration key=\"source-flavor\">presenter/trimmed</configuration> <configuration key=\"target-flavor\">presenter/delivery</configuration> <configuration key=\"target-tags\">engage-download</configuration> <configuration key=\"encoding-profile\">mp4-medium.http</configuration> </configurations> </operation> Encoding 480p, 720p and 1080p video to MP4 adaptive streaming: <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Encoding 480p, 720p and 1080p video to MP4 streaming\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/delivery</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <configuration key=\"encoding-profiles\">adaptive-480p.http,adaptive-720p.http,adaptive-1080p.http</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/composite-woh/","text":"Composite Workflow Operation Handler Description The CompositeWorkflowOperationHandler is used to composite two videos (upper and lower) and an optional watermark into one video, including encoding to different formats. The audio track is taken from both videos by default. Everything is done using FFmpeg. The composition can be done in various layout formats e.g. side by side or picture in picture. The layout has to be defined in JSON format and is described in section \"Layout Definition\". For some general information about layouts see Opencast Composer Layout Module. The internal ffmpeg command is using the following filters: scale for scaling the videos, pad for defining the output dimension including the background color, movie for adding additional videos and images and overlay for aligning the videos and images to the output dimension. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide If both upper and lower tracks have audio, \"source-audio-name\" can be set to \"upper\", \"lower\" or \"both\" to choose only the audio from one track or both tracks for the composite video. Sample complex composite filter command -filter:v \"[in]scale=640:480,pad=1920:1080:20:20:black[lower];movie=test.mp4,scale=640:480[upper];movie=watermark.jpg[watermark];[lower][upper]overlay=200:200[video];[video][watermark]overlay=main_w-overlay_w-20:20[out]\" sidebyside.mp4 Parameter Table Tags and flavors can be used in combination. configuration keys value type (EBNF) example description default value source-audio-name \"lower\", \"upper\" or \"both\" upper The \"name\" of track to use as a source audio. both source-tags-upper String , { \",\" , String } comp,rss The \"tag\" of the upper track to use as a source input. EMPTY source-flavor-upper MediaPackageElementFlavor presenter/trimmed The \"flavor\" of the upper track to use as a source input. EMPTY source-tags-lower String , { \",\" , String } comp,rss The \"tag\" of the lower track to use as a source input. EMPTY source-flavor-lower MediaPackageElementFlavor presenter/trimmed The \"flavor\" of the lower track to use as a source input. EMPTY source-tags-watermark String , { \",\" , String } branding The \"tag\" of the attachment image to use as a source input. EMPTY source-flavor-watermark MediaPackageElementFlavor image/work The \"flavor\" of the attachment image to use as a source input. EMPTY source-url-watermark URL file:///Users/me/logo.jpg The \"URL\" of the fallback image to use as a source input. EMPTY target-tags String , { \",\" , String } composite,rss,atom,archive The tags to apply to the compound video track. EMPTY * target-flavor MediaPackageElementFlavor composite/delivery The flavor to apply to the compound video track. EMPTY * encoding-profile String composite The encoding profile to use. EMPTY * output-resolution width , \"x\" , height | lower | higher 1920x1080 The resulting resolution of the compound video e.g. 1920x1080. EMPTY output-background String red The resulting background color of the compound video http://www.ffmpeg.org/ffmpeg-utils.html#Color. black layout name Json , \";\" , Json , [ \";\" , Json ] The layout name to use or a semi-colon separated JSON layout definition (lower video, upper video, optional watermark). If a layout name is given than the corresponding layout-{name} key must be defined. EMPTY layout-single name Json , \";\" , Json , [ \";\" , Json ] Layout to be used in case of one input video track (see layout ) EMPTY layout-dual name Json , \";\" , Json , [ \";\" , Json ] Layout to be used in case of two input video tracks (see layout ). Defaults to value of layout if not set. EMPTY layout-{name} Json , \";\" , Json , [ \";\" , Json ] Define semi-colon separated JSON layouts (lower video, upper video, optional watermark) to provide by name. EMPTY * mandatory Notes: At least one of the configuration keys layout , layout-single , or layout-multiple must be set Output Resolution The output resolution must be specified using the configuration key output-resolution . The output resolution can be either explicitly specified (e.g. 1920x1080) or selected from the lower or upper input video (lower or higher). In case that only a single input track is available, both part-lower and part-higher will refer to that single input track. Layout Definition The layout definitions are provided as JSON. Each definition consist of the layout specifications for the lower and upper video and an optional specification for the watermark. The specifications have to be separated by comma. It is always ensured that the media does not exceed the canvas. Offset and scaling is adjusted appropriately. A single layout is specified as follows: { // How much of the canvas shall be covered. [0.0 - 1.0] // 1.0 means that the media is scaled to cover the complete width of the canvas keeping the aspect ratio. \"horizontalCoverage\": Double, // The offset between the anchor points of the media and the canvas \"anchorOffset\": { // The anchor point of the media. [0.0 - 1.0] // (0.0, 0.0) is the upper left corner, (1.0, 1.0) is the lower right corner. // (0.5, 0.5) is the center. \"referring\": { \"left\": Double, \"top\": Double }, // The anchor point of the canvas. \"reference\": { \"left\": Double, \"top\": Double }, // The offset between the two anchor points. \"offset\": { \"y\": Integer, \"x\": Integer } } } // Example. // The media is scaled to cover the whole width of the canvas and is placed in the upper left corner. { \"horizontalCoverage\": 1.0, \"anchorOffset\": { \"referring\": { \"left\": 0.0, \"top\": 0.0 }, \"offset\": { \"y\": 0, \"x\": 0 }, \"reference\": { \"left\": 0.0, \"top\": 0.0 } } } // Example. // The media is scaled to cover 20% of the width of the canvas and is placed in the lower right corner // with an offset of -10px on both x and y axis so that it does not touch the canvas' border. { \"horizontalCoverage\": 0.2, \"anchorOffset\": { \"referring\": { \"left\": 1.0, \"top\": 1.0 }, \"offset\": { \"y\": -10, \"x\": -10 }, \"reference\": { \"left\": 1.0, \"top\": 1.0 } } } Operation Example <operation id=\"composite\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Composite\"> <configurations> <configuration key=\"source-flavor-upper\">presentation/trimmed</configuration> <configuration key=\"source-flavor-lower\">presenter/trimmed</configuration> <configuration key=\"source-tags-upper\">comp,rss</configuration> <configuration key=\"source-tags-lower\">comp,rss</configuration> <configuration key=\"source-tags-watermark\">branding</configuration> <configuration key=\"source-flavor-watermark\">image/work</configuration> <configuration key=\"source-url-watermark\">file:///Users/me/logo.jpg</configuration> <configuration key=\"encoding-profile\">composite</configuration> <configuration key=\"target-tags\">composite,rss,atom,archive</configuration> <configuration key=\"target-flavor\">composite/delivery</configuration> <configuration key=\"output-resolution\">1920x1080</configuration> <configuration key=\"output-background\">red</configuration> <configuration key=\"layout\">topleft</configuration> <configuration key=\"layout-topleft\"> {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}}; {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":0.0,\"top\":0.0}}}; {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":1.0,\"top\":0.0}}} </configuration> <configuration key=\"layout-topright\"> {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}}; {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":0.0}}}; {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":0.0,\"top\":0.0}}} </configuration> </configurations> </operation>","title":"Composite"},{"location":"workflowoperationhandlers/composite-woh/#composite-workflow-operation-handler","text":"","title":"Composite Workflow Operation Handler"},{"location":"workflowoperationhandlers/composite-woh/#description","text":"The CompositeWorkflowOperationHandler is used to composite two videos (upper and lower) and an optional watermark into one video, including encoding to different formats. The audio track is taken from both videos by default. Everything is done using FFmpeg. The composition can be done in various layout formats e.g. side by side or picture in picture. The layout has to be defined in JSON format and is described in section \"Layout Definition\". For some general information about layouts see Opencast Composer Layout Module. The internal ffmpeg command is using the following filters: scale for scaling the videos, pad for defining the output dimension including the background color, movie for adding additional videos and images and overlay for aligning the videos and images to the output dimension. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide If both upper and lower tracks have audio, \"source-audio-name\" can be set to \"upper\", \"lower\" or \"both\" to choose only the audio from one track or both tracks for the composite video.","title":"Description"},{"location":"workflowoperationhandlers/composite-woh/#sample-complex-composite-filter-command","text":"-filter:v \"[in]scale=640:480,pad=1920:1080:20:20:black[lower];movie=test.mp4,scale=640:480[upper];movie=watermark.jpg[watermark];[lower][upper]overlay=200:200[video];[video][watermark]overlay=main_w-overlay_w-20:20[out]\" sidebyside.mp4","title":"Sample complex composite filter command"},{"location":"workflowoperationhandlers/composite-woh/#parameter-table","text":"Tags and flavors can be used in combination. configuration keys value type (EBNF) example description default value source-audio-name \"lower\", \"upper\" or \"both\" upper The \"name\" of track to use as a source audio. both source-tags-upper String , { \",\" , String } comp,rss The \"tag\" of the upper track to use as a source input. EMPTY source-flavor-upper MediaPackageElementFlavor presenter/trimmed The \"flavor\" of the upper track to use as a source input. EMPTY source-tags-lower String , { \",\" , String } comp,rss The \"tag\" of the lower track to use as a source input. EMPTY source-flavor-lower MediaPackageElementFlavor presenter/trimmed The \"flavor\" of the lower track to use as a source input. EMPTY source-tags-watermark String , { \",\" , String } branding The \"tag\" of the attachment image to use as a source input. EMPTY source-flavor-watermark MediaPackageElementFlavor image/work The \"flavor\" of the attachment image to use as a source input. EMPTY source-url-watermark URL file:///Users/me/logo.jpg The \"URL\" of the fallback image to use as a source input. EMPTY target-tags String , { \",\" , String } composite,rss,atom,archive The tags to apply to the compound video track. EMPTY * target-flavor MediaPackageElementFlavor composite/delivery The flavor to apply to the compound video track. EMPTY * encoding-profile String composite The encoding profile to use. EMPTY * output-resolution width , \"x\" , height | lower | higher 1920x1080 The resulting resolution of the compound video e.g. 1920x1080. EMPTY output-background String red The resulting background color of the compound video http://www.ffmpeg.org/ffmpeg-utils.html#Color. black layout name Json , \";\" , Json , [ \";\" , Json ] The layout name to use or a semi-colon separated JSON layout definition (lower video, upper video, optional watermark). If a layout name is given than the corresponding layout-{name} key must be defined. EMPTY layout-single name Json , \";\" , Json , [ \";\" , Json ] Layout to be used in case of one input video track (see layout ) EMPTY layout-dual name Json , \";\" , Json , [ \";\" , Json ] Layout to be used in case of two input video tracks (see layout ). Defaults to value of layout if not set. EMPTY layout-{name} Json , \";\" , Json , [ \";\" , Json ] Define semi-colon separated JSON layouts (lower video, upper video, optional watermark) to provide by name. EMPTY * mandatory Notes: At least one of the configuration keys layout , layout-single , or layout-multiple must be set","title":"Parameter Table"},{"location":"workflowoperationhandlers/composite-woh/#output-resolution","text":"The output resolution must be specified using the configuration key output-resolution . The output resolution can be either explicitly specified (e.g. 1920x1080) or selected from the lower or upper input video (lower or higher). In case that only a single input track is available, both part-lower and part-higher will refer to that single input track.","title":"Output Resolution"},{"location":"workflowoperationhandlers/composite-woh/#layout-definition","text":"The layout definitions are provided as JSON. Each definition consist of the layout specifications for the lower and upper video and an optional specification for the watermark. The specifications have to be separated by comma. It is always ensured that the media does not exceed the canvas. Offset and scaling is adjusted appropriately. A single layout is specified as follows: { // How much of the canvas shall be covered. [0.0 - 1.0] // 1.0 means that the media is scaled to cover the complete width of the canvas keeping the aspect ratio. \"horizontalCoverage\": Double, // The offset between the anchor points of the media and the canvas \"anchorOffset\": { // The anchor point of the media. [0.0 - 1.0] // (0.0, 0.0) is the upper left corner, (1.0, 1.0) is the lower right corner. // (0.5, 0.5) is the center. \"referring\": { \"left\": Double, \"top\": Double }, // The anchor point of the canvas. \"reference\": { \"left\": Double, \"top\": Double }, // The offset between the two anchor points. \"offset\": { \"y\": Integer, \"x\": Integer } } } // Example. // The media is scaled to cover the whole width of the canvas and is placed in the upper left corner. { \"horizontalCoverage\": 1.0, \"anchorOffset\": { \"referring\": { \"left\": 0.0, \"top\": 0.0 }, \"offset\": { \"y\": 0, \"x\": 0 }, \"reference\": { \"left\": 0.0, \"top\": 0.0 } } } // Example. // The media is scaled to cover 20% of the width of the canvas and is placed in the lower right corner // with an offset of -10px on both x and y axis so that it does not touch the canvas' border. { \"horizontalCoverage\": 0.2, \"anchorOffset\": { \"referring\": { \"left\": 1.0, \"top\": 1.0 }, \"offset\": { \"y\": -10, \"x\": -10 }, \"reference\": { \"left\": 1.0, \"top\": 1.0 } } }","title":"Layout Definition"},{"location":"workflowoperationhandlers/composite-woh/#operation-example","text":"<operation id=\"composite\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Composite\"> <configurations> <configuration key=\"source-flavor-upper\">presentation/trimmed</configuration> <configuration key=\"source-flavor-lower\">presenter/trimmed</configuration> <configuration key=\"source-tags-upper\">comp,rss</configuration> <configuration key=\"source-tags-lower\">comp,rss</configuration> <configuration key=\"source-tags-watermark\">branding</configuration> <configuration key=\"source-flavor-watermark\">image/work</configuration> <configuration key=\"source-url-watermark\">file:///Users/me/logo.jpg</configuration> <configuration key=\"encoding-profile\">composite</configuration> <configuration key=\"target-tags\">composite,rss,atom,archive</configuration> <configuration key=\"target-flavor\">composite/delivery</configuration> <configuration key=\"output-resolution\">1920x1080</configuration> <configuration key=\"output-background\">red</configuration> <configuration key=\"layout\">topleft</configuration> <configuration key=\"layout-topleft\"> {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}}; {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":0.0,\"top\":0.0}}}; {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":1.0,\"top\":0.0}}} </configuration> <configuration key=\"layout-topright\"> {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}}; {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":0.0}}}; {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":0.0,\"top\":0.0}}} </configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/concat-woh/","text":"Concat Workflow Operation Handler The concat operation handler has been created to concatenate multiple video tracks into one video track. For a concatenation of two video files to work, both files need to have the same format (timebase, resolution, codecs, frame rate, etc.). This workflow operation has two modes to deal with this restriction: A general mode which re-encodes all input files, hence ensuring that this restriction is always met. A same codec mode which assumes the restriction is already met and can hence concatenate the files much faster while also being a lossless process. But it will fail or produce a weird output if if the restrictions are not met. General Mode No restriction on source tracks codecs This will re-encode the videos first to the same format (framerate/timebase/codec, etc) before concatenation. G cluster_inputs Input cluster_output Output outro outro source-flavor-part-2 concat concat outro->concat intro intro source-flavor-part-0 intro->concat presenter presenter source-flavor-part-1 presenter->concat o_intro intro o_presenter presenter o_intro->o_presenter o_outro outro o_presenter->o_outro concat->o_intro The internal FFmpeg command for re-encoding is using the following filters: fps, scale, pad and setdar for scaling all videos to a similar size including letterboxing, aevalsrc for creating silent audio streams and of course the concat for the actual concatenation step. This requires an output-resolution and an optional output-framerate for the pre-concatenation encode. The automatically generated FFmpeg filter for this process does look like this: -filter_complex ' [0:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[b]; [1:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[c]; [2:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[d]; aevalsrc=0::d=1[silent]; [b][0:a][c][silent][d][2:a]concat=n=3:v=1:a=1[v][a]' -map '[v]' -map '[a]' Same Codec Mode Requires the source tracks having the same format (same timebase/resolution/encoding, etc.) If the same-codec option is specified to use this mode, the sources files can be arranged into one container losslessly without re-encoding first. This is often the case if the tracks came from the same camera/recorder for example. This mode uses FFmpeg's concat demuxer , which puts all the video content into a single container without any re-encoding. The encoding profile then operates on the source in this container. If -c copy is used in the encoding profile, the complete concatenation is lossless. The FFmpeg command for this is is: -f concat -i videolist.txt \u2026where videolist.txt contains a line in the form file <path to video> for each source track. Usage This operation is quite similar to the compose operation. The only difference is that the input properties are not only limited to one source-flavor and source-tag . The operation supports multiple flavor and tags as input. To add multiple sources, add different keys with the prefix source-flavor- / source-tag- and an incremental number starting with 0. For example: source-flavor-part-0 source-flavor-part-1 source-flavor-part-.. Alternatively, using the source-flavor-numbered-files option, the operation supports an undetermined number of ordered input files. This is useful when the number of input files cannot be known in advance, such as chunked output files from some camera/recorders, and the names are ordered by number or timestamps and to be sorted lexicographically. For example, the configuration could be source-flavor-numbered-files: multipart/part+source and the ordered input files: video-201711201020.mp4 video-201711201030.mp4 video-201711201040.mp4 Note that both methods of defining input files are mutually exclusive. Configuration Keys Key Required Description Default Example source-flavor-part-X false An iterative list of part/flavor to use as input track. NULL presenter/trimmed source-tag-part-X false An iterative list of part/tag to use as input track. NULL source-to-concate source-flavor-part-X-mandatory false Define the flavor part-X as optional for concatenation. false true source-tag-part-X-mandatory false Define the tag part-X as optional for concatenation. false true encoding-profile true Encoding profile to use for the concatenation. NULL concat target-flavor true Flavor(s) to add to the output track. NULL presenter/concat target-tags false Tag(s) to add to the output track NULL engage-download output-resolution true Output resolution in width, height or a source part NULL 1900x1080 , part-1 output-framerate false Output frame rate in frames per second or a source part -1.0 25 , 23.976 , part-1 source-flavor-numbered-files false Files of this flavor are ordered lexicographically to use as input track. NULL multipart/sections same-codec false All source files have identical formats. false true Example Example of a concat operation in a workflow definition. <!-- Add intro and outro part to the presenter track --> <operation id=\"concat\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Concatenate the presenter track and the intro/outro videos.\"> <configurations> <configuration key=\"source-flavor-part-0\">intro/source</configuration> <configuration key=\"source-flavor-part-1\">presenter/trimmed</configuration> <configuration key=\"source-flavor-part-1-mandatory\">true</configuration> <configuration key=\"source-flavor-part-2\">outro/source</configuration> <configuration key=\"target-flavor\">presenter/concat</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <configuration key=\"encoding-profile\">concat</configuration> <configuration key=\"output-resolution\">1920x1080</configuration> <configuration key=\"output-framerate\">part-1</configuration> </configurations> </operation> Example of a lossless concat operation for videos with identical formats in a workflow definition. <!-- Concatenate chunked video from camera --> <operation id=\"concat\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Concatenate the generated videos.\"> <configurations> <configuration key=\"source-flavor-numbered-files\">multipart/chunkedsource</configuration> <configuration key=\"target-flavor\">presenter/concat</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <!-- do not encode before concatenation --> <configuration key=\"same-codec\">true</configuration> <configuration key=\"encoding-profile\">concat-samecodec</configuration> </configurations> </operation> Encoding Profile The encoding profile command must contain the #{concatCommand} parameter which will set all input and possibly filter commands required for this operation: profile.concat.ffmpeg.command = #{concatCommand} \\ \u2026 #{out.dir}/#{out.name}#{out.suffix}","title":"Concat"},{"location":"workflowoperationhandlers/concat-woh/#concat-workflow-operation-handler","text":"The concat operation handler has been created to concatenate multiple video tracks into one video track. For a concatenation of two video files to work, both files need to have the same format (timebase, resolution, codecs, frame rate, etc.). This workflow operation has two modes to deal with this restriction: A general mode which re-encodes all input files, hence ensuring that this restriction is always met. A same codec mode which assumes the restriction is already met and can hence concatenate the files much faster while also being a lossless process. But it will fail or produce a weird output if if the restrictions are not met.","title":"Concat Workflow Operation Handler"},{"location":"workflowoperationhandlers/concat-woh/#general-mode","text":"No restriction on source tracks codecs This will re-encode the videos first to the same format (framerate/timebase/codec, etc) before concatenation. G cluster_inputs Input cluster_output Output outro outro source-flavor-part-2 concat concat outro->concat intro intro source-flavor-part-0 intro->concat presenter presenter source-flavor-part-1 presenter->concat o_intro intro o_presenter presenter o_intro->o_presenter o_outro outro o_presenter->o_outro concat->o_intro The internal FFmpeg command for re-encoding is using the following filters: fps, scale, pad and setdar for scaling all videos to a similar size including letterboxing, aevalsrc for creating silent audio streams and of course the concat for the actual concatenation step. This requires an output-resolution and an optional output-framerate for the pre-concatenation encode. The automatically generated FFmpeg filter for this process does look like this: -filter_complex ' [0:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[b]; [1:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[c]; [2:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[d]; aevalsrc=0::d=1[silent]; [b][0:a][c][silent][d][2:a]concat=n=3:v=1:a=1[v][a]' -map '[v]' -map '[a]'","title":"General Mode"},{"location":"workflowoperationhandlers/concat-woh/#same-codec-mode","text":"Requires the source tracks having the same format (same timebase/resolution/encoding, etc.) If the same-codec option is specified to use this mode, the sources files can be arranged into one container losslessly without re-encoding first. This is often the case if the tracks came from the same camera/recorder for example. This mode uses FFmpeg's concat demuxer , which puts all the video content into a single container without any re-encoding. The encoding profile then operates on the source in this container. If -c copy is used in the encoding profile, the complete concatenation is lossless. The FFmpeg command for this is is: -f concat -i videolist.txt \u2026where videolist.txt contains a line in the form file <path to video> for each source track.","title":"Same Codec Mode"},{"location":"workflowoperationhandlers/concat-woh/#usage","text":"This operation is quite similar to the compose operation. The only difference is that the input properties are not only limited to one source-flavor and source-tag . The operation supports multiple flavor and tags as input. To add multiple sources, add different keys with the prefix source-flavor- / source-tag- and an incremental number starting with 0. For example: source-flavor-part-0 source-flavor-part-1 source-flavor-part-.. Alternatively, using the source-flavor-numbered-files option, the operation supports an undetermined number of ordered input files. This is useful when the number of input files cannot be known in advance, such as chunked output files from some camera/recorders, and the names are ordered by number or timestamps and to be sorted lexicographically. For example, the configuration could be source-flavor-numbered-files: multipart/part+source and the ordered input files: video-201711201020.mp4 video-201711201030.mp4 video-201711201040.mp4 Note that both methods of defining input files are mutually exclusive.","title":"Usage"},{"location":"workflowoperationhandlers/concat-woh/#configuration-keys","text":"Key Required Description Default Example source-flavor-part-X false An iterative list of part/flavor to use as input track. NULL presenter/trimmed source-tag-part-X false An iterative list of part/tag to use as input track. NULL source-to-concate source-flavor-part-X-mandatory false Define the flavor part-X as optional for concatenation. false true source-tag-part-X-mandatory false Define the tag part-X as optional for concatenation. false true encoding-profile true Encoding profile to use for the concatenation. NULL concat target-flavor true Flavor(s) to add to the output track. NULL presenter/concat target-tags false Tag(s) to add to the output track NULL engage-download output-resolution true Output resolution in width, height or a source part NULL 1900x1080 , part-1 output-framerate false Output frame rate in frames per second or a source part -1.0 25 , 23.976 , part-1 source-flavor-numbered-files false Files of this flavor are ordered lexicographically to use as input track. NULL multipart/sections same-codec false All source files have identical formats. false true","title":"Configuration Keys"},{"location":"workflowoperationhandlers/concat-woh/#example","text":"Example of a concat operation in a workflow definition. <!-- Add intro and outro part to the presenter track --> <operation id=\"concat\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Concatenate the presenter track and the intro/outro videos.\"> <configurations> <configuration key=\"source-flavor-part-0\">intro/source</configuration> <configuration key=\"source-flavor-part-1\">presenter/trimmed</configuration> <configuration key=\"source-flavor-part-1-mandatory\">true</configuration> <configuration key=\"source-flavor-part-2\">outro/source</configuration> <configuration key=\"target-flavor\">presenter/concat</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <configuration key=\"encoding-profile\">concat</configuration> <configuration key=\"output-resolution\">1920x1080</configuration> <configuration key=\"output-framerate\">part-1</configuration> </configurations> </operation> Example of a lossless concat operation for videos with identical formats in a workflow definition. <!-- Concatenate chunked video from camera --> <operation id=\"concat\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Concatenate the generated videos.\"> <configurations> <configuration key=\"source-flavor-numbered-files\">multipart/chunkedsource</configuration> <configuration key=\"target-flavor\">presenter/concat</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <!-- do not encode before concatenation --> <configuration key=\"same-codec\">true</configuration> <configuration key=\"encoding-profile\">concat-samecodec</configuration> </configurations> </operation>","title":"Example"},{"location":"workflowoperationhandlers/concat-woh/#encoding-profile","text":"The encoding profile command must contain the #{concatCommand} parameter which will set all input and possibly filter commands required for this operation: profile.concat.ffmpeg.command = #{concatCommand} \\ \u2026 #{out.dir}/#{out.name}#{out.suffix}","title":"Encoding Profile"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/","text":"ConfigureByDCTermWorkflowOperationHandler Description With the ConfigureByDCTermWorkflowOperationHandler it's possible to create a workflow configuration property according to whether a Dublin Core term in a catalog has a specific value. So for example it's possible to control a workflow so that it will publish before editing if a certain Dublin Core term has the specified value. In combination with TagByDCTermWorkflowOperationHandler workflows can be controlled by the metadata contained within the Dublin Core catalogs. Parameter Table Tags and flavors can be used in combination. configuration keys example description default value dccatalog \"episode\" or \"series\" the type of catalog in which to search for dcterm EMPTY dcterm \"creator\" the name of the Dublin Core term which to check EMPTY match-value \"Joe Bloggs\" the Dublin Core term value to check for EMPTY default-value \"Anon\" the implied value if the dubincore term is not present in the catalog EMPTY configProperty true / false a configuration property and the value it will be given if a match is found EMPTY dccatalog The type of Dublin Core catalog in which to look for the dcterm . This will usually be episode or series . dcterm The name of the Dublin Core term to look for in the dccatalog . This could be one of the terms set by Opencast or an additional term adding to the catalog. match-value The value of the dcterm which to match against. The comparison is case sensitive. default-value If default-value is used when the dcterm is not found in the catalog. If not specified the operation will treat the match as false and not configure anything. If default-value is specified the operation will compare the match-value to the default-value and set the workflow property if they match. This allows an implied value to be explicitly and clearly defined. For example if you have mediapackages that were created before additional metadata was added to the episode catalog you may want to imply that the audience term has a value of all-enrolled . \"configProperty\" Specifies as the key the name of a new workflow configuration property and the boolean value to which it will be set if the Dublin Core term matches the specified value. Due to the way a workflow evaluates operation if conditions as configuration properties are created, only new configuration properties can be used to modify the execution of subsequent operations. Also since an undefined property will be evaluted as false in practice the only useful value which can set is true . However operation if conditions can be negated though so it is possible to skip subsequent operations on matched dcterm value. Operation Example <operation id=\"configure-by-dcterm\" fail-on-error=\"true\" description=\"Configure publication channel by dcterm\"> <configurations> <configuration key=\"dccatalog\">episode</configuration> <configuration key=\"dcterm\">audience</configuration> <configuration key=\"match-value\">private</configuration> <configuration key=\"publishPrivate\">true</configuration> </configurations> </operation> ... <operation id=\"publish-engage\" if=\"${publishPrivate}\" description=\"Publish to internal audience only\"> ... </operation> <operation id=\"publish-youtube\" if=\"NOT ${publishPrivate}\" description=\"Publish to global audience\"> ... </operation>","title":"Configure-By-DCTerm"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#configurebydctermworkflowoperationhandler","text":"","title":"ConfigureByDCTermWorkflowOperationHandler"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#description","text":"With the ConfigureByDCTermWorkflowOperationHandler it's possible to create a workflow configuration property according to whether a Dublin Core term in a catalog has a specific value. So for example it's possible to control a workflow so that it will publish before editing if a certain Dublin Core term has the specified value. In combination with TagByDCTermWorkflowOperationHandler workflows can be controlled by the metadata contained within the Dublin Core catalogs.","title":"Description"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#parameter-table","text":"Tags and flavors can be used in combination. configuration keys example description default value dccatalog \"episode\" or \"series\" the type of catalog in which to search for dcterm EMPTY dcterm \"creator\" the name of the Dublin Core term which to check EMPTY match-value \"Joe Bloggs\" the Dublin Core term value to check for EMPTY default-value \"Anon\" the implied value if the dubincore term is not present in the catalog EMPTY configProperty true / false a configuration property and the value it will be given if a match is found EMPTY","title":"Parameter Table"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#dccatalog","text":"The type of Dublin Core catalog in which to look for the dcterm . This will usually be episode or series .","title":"dccatalog"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#dcterm","text":"The name of the Dublin Core term to look for in the dccatalog . This could be one of the terms set by Opencast or an additional term adding to the catalog.","title":"dcterm"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#match-value","text":"The value of the dcterm which to match against. The comparison is case sensitive.","title":"match-value"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#default-value","text":"If default-value is used when the dcterm is not found in the catalog. If not specified the operation will treat the match as false and not configure anything. If default-value is specified the operation will compare the match-value to the default-value and set the workflow property if they match. This allows an implied value to be explicitly and clearly defined. For example if you have mediapackages that were created before additional metadata was added to the episode catalog you may want to imply that the audience term has a value of all-enrolled .","title":"default-value"},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#configproperty","text":"Specifies as the key the name of a new workflow configuration property and the boolean value to which it will be set if the Dublin Core term matches the specified value. Due to the way a workflow evaluates operation if conditions as configuration properties are created, only new configuration properties can be used to modify the execution of subsequent operations. Also since an undefined property will be evaluted as false in practice the only useful value which can set is true . However operation if conditions can be negated though so it is possible to skip subsequent operations on matched dcterm value.","title":"\"configProperty\""},{"location":"workflowoperationhandlers/configure-by-dcterm-woh/#operation-example","text":"<operation id=\"configure-by-dcterm\" fail-on-error=\"true\" description=\"Configure publication channel by dcterm\"> <configurations> <configuration key=\"dccatalog\">episode</configuration> <configuration key=\"dcterm\">audience</configuration> <configuration key=\"match-value\">private</configuration> <configuration key=\"publishPrivate\">true</configuration> </configurations> </operation> ... <operation id=\"publish-engage\" if=\"${publishPrivate}\" description=\"Publish to internal audience only\"> ... </operation> <operation id=\"publish-youtube\" if=\"NOT ${publishPrivate}\" description=\"Publish to global audience\"> ... </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/copy-woh/","text":"CopyWorkflowOperationHandler Description The CopyWorkflowOperationHandler can be used to copy media package elements to a given target directory. Parameter Table Configuration Key Example Description source-flavors presenter/source Comma-separated list of source-flavors source-tags archive Comma-separated list of source-tags target-directory* /mnt/mydisk The directory where the file is copied to target-filename test The optional target filename. The file extension extract from the media package element URI will be appended * mandatory configuration key Notes: source-flavors and source-tags may be used both together to select media package elements based on both flavors and tags In case that neither source-flavors nor source-tags are specified, the operation will be skipped In case no media package elements match source-flavors and source-tags , the operation will be skipped Target Filenames If target-filename is not specified, the filename for each media package element is extracted from the media package element URI. If target-filename is specified, the filename is the result of appending the file extension (extracted from the media package element URI) to target-filename . In case the source-flavors and source-tags match mutliple media package elements, a sequentially increasing integer number (starting at 1) can be used within target-filename in Java string formatting manner to ensure unique filenames. Operation Example <operation id=\"copy\" description=\"Copy sources to my disk\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-flavors\">presenter/source, presentation/source</configuration> <configuration key=\"target-directory\">/mnt/mydisk</configuration> </configurations>","title":"Copy"},{"location":"workflowoperationhandlers/copy-woh/#copyworkflowoperationhandler","text":"","title":"CopyWorkflowOperationHandler"},{"location":"workflowoperationhandlers/copy-woh/#description","text":"The CopyWorkflowOperationHandler can be used to copy media package elements to a given target directory.","title":"Description"},{"location":"workflowoperationhandlers/copy-woh/#parameter-table","text":"Configuration Key Example Description source-flavors presenter/source Comma-separated list of source-flavors source-tags archive Comma-separated list of source-tags target-directory* /mnt/mydisk The directory where the file is copied to target-filename test The optional target filename. The file extension extract from the media package element URI will be appended * mandatory configuration key Notes: source-flavors and source-tags may be used both together to select media package elements based on both flavors and tags In case that neither source-flavors nor source-tags are specified, the operation will be skipped In case no media package elements match source-flavors and source-tags , the operation will be skipped","title":"Parameter Table"},{"location":"workflowoperationhandlers/copy-woh/#target-filenames","text":"If target-filename is not specified, the filename for each media package element is extracted from the media package element URI. If target-filename is specified, the filename is the result of appending the file extension (extracted from the media package element URI) to target-filename . In case the source-flavors and source-tags match mutliple media package elements, a sequentially increasing integer number (starting at 1) can be used within target-filename in Java string formatting manner to ensure unique filenames.","title":"Target Filenames"},{"location":"workflowoperationhandlers/copy-woh/#operation-example","text":"<operation id=\"copy\" description=\"Copy sources to my disk\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-flavors\">presenter/source, presentation/source</configuration> <configuration key=\"target-directory\">/mnt/mydisk</configuration> </configurations>","title":"Operation Example"},{"location":"workflowoperationhandlers/coverimage-woh/","text":"CoverImageWorkflowOperationHandler Description The CoverImageWorkflowOperationHandler generates a cover image based on an XSLT transformation which results in an SVG image that is rasterized as PNG as a last step. Parameter Table Name Type Example Default Value Description stylesheet * URL file:///etc/opencast/branding/coverimage.xsl - File URI to the XSL stylesheet used to generate the SVG image metadata XML Hello! - XML string which is passed to the XSL transformation. If parameter is not given, a default XML is handed to the transformation width * int 1920 - Width of the resulting image height * int 1080 - Height of the resulting image posterimage-flavor Flavor image/poster - Flavor of a poster image which may be used as a part of the cover image (e.g. as a background) posterimage URL http://flickr.com/posterimage.jpg - URL to a custom poster image instead of using one out of the media package target-flavor * Flavor image/cover - Flavor of the resulting cover image target-tags String archive,download - Comma separated list of tags to be applied to the resulting attachment. Metadata If no metadata is passed by using the configuration key metadata , the default metadata is passed to the cover image service which looks like the following example: <?xml version=\"1.0\"?> <metadata> <title>Puppy Love</title> <date>2014-04-24T11:21:00</date> <license>All rights reserved</license> <description>Here is a description of the video</description> <series>Superbowl Commercials</series> <contributors>Budweiser</contributors> <creators>Budweiser</creators> <subjects>Commercial</subjects> </metadata> Note that the date is localized based on your servers Java Runtime language settings. Stylesheet The cover image service uses the Xalan XSLT 1.0 processor to transform an XML stylesheet to an SVG image. The general structure of the stylesheet is expected to look like this: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?> <xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"> <xsl:param name=\"width\" /> <xsl:param name=\"height\" /> <xsl:param name=\"posterimage\" /> <xsl:template match=\"/\"> <svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.1\"> <xsl:attribute name=\"width\"> <xsl:value-of select=\"$width\" /> </xsl:attribute> <xsl:attribute name=\"height\"> <xsl:value-of select=\"$height\" /> </xsl:attribute> <!-- Your SVG content --> </xsl:template> </xsl:stylesheet> The variables width , height and posterimage will be set to the values of the respective configuration keys. As a starting point for your own template you best take a look at file etc/branding/coverimage.xsl . Using XLST Extensions Xalan is a powerful XSLT 1.0 processor that comes with a rich feature set. For example, it is possible to execute JavaScript or Java code directly within the stylesheet. For commonly used tasks it is simpler, however, to make use of available XSLT Extensions. Opencast Extensions The package org.opencastproject.coverimage.impl.xsl provides classes supposed to be used within XSL stylesheets. To make use of those classes, you need to reference the package from your XSL stylesheet: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?> <xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:opencast=\"xalan://org.opencastproject.coverimage.impl.xsl\" exclude-result-prefixes=\"opencast\" extension-element-prefixes=\"opencast\"> </xsl:stylesheet> Later on, you can use methods of those classes as shown in the following example: <tspan class=\"title\" y=\"30%\" x=\"50%\"> <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 1, false())\" /> </tspan> Note: In XSLT, use true() and false() for boolean literals ( true and false won't work since those are not keywords in XSLT) The following classes are provided by the org.opencastproject.coverimage.impl.xsl package: class XsltHelper String split(String text, int maxChars, int line, boolean isLastLine) This method can be used to break strings over multiple lines and to abbreviate strings that are too using ellipsis. Parameter Description text Input string maxChars Maximum number of characters per line line Number of line isLastLine Whether line is the last line used to represent the text Example To use at most two lines (max. 30 characters per line) to represent a string metadata/title and abbreviate the string if two lines aren't enough: <tspan class=\"title\" y=\"30%\" x=\"50%\"> <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 1, false())\" /> </tspan> <tspan class=\"title\" dy=\"10%\" x=\"50%\"> <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 2, true())\" /> </tspan> EXSLT Extensions Xalan supports most of the XSLT extensions of the EXSLT community (see [1] ). In doubt consult [2] for more information about Xalan's implementation of the EXSLT extensions. Please find an example of how to use EXSLT extensions below: <xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:date=\"http://exslt.org/dates-and-times\" xmlns:opencast=\"xalan://org.opencastproject.coverimage.impl.xsl\" exclude-result-prefixes=\"date\" extension-element-prefixes=\"date\"> <!-- [...] --> <tspan class=\"presentationdate\" dy=\"12%\" x=\"50%\"> <xsl:value-of select=\"date:format-date(metadata/date, 'MMMMMMMMMM dd, YYYY, HH:mm:ss')\" /> </tspan> <!-- [...] --> </xsl:stylesheet> In this example, the function format-date of the EXSLT dates-and-times functions library is used to format a date. Operation Example Operation example with metadata derived from events metadata: <operation id=\"cover-image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Create a cover image\"> <configurations> <configuration key=\"stylesheet\">file://${karaf.etc}/branding/coverimage.xsl</configuration> <configuration key=\"width\">1920</configuration> <configuration key=\"height\">1080</configuration> <configuration key=\"posterimage-flavor\">presenter/coverbackground</configuration> <configuration key=\"target-flavor\">presenter/player+preview</configuration> <configuration key=\"target-tags\">archive, engage-download</configuration> </configurations> </operation> Operation example with metadata provided in the operations configuration: <operation id=\"cover-image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Create a cover image\"> <configurations> <configuration key=\"stylesheet\">file://${karaf.etc}/branding/coverimage.xsl</configuration> <configuration key=\"metadata\"> <![CDATA[<meta><title>my custom title</title><special>very special</special></meta>]]> </configuration> <configuration key=\"width\">1920</configuration> <configuration key=\"height\">1080</configuration> <configuration key=\"posterimage-flavor\">presenter/player+preview</configuration> <configuration key=\"target-flavor\">image/cover</configuration> </configurations> </operation>","title":"Cover Image"},{"location":"workflowoperationhandlers/coverimage-woh/#coverimageworkflowoperationhandler","text":"","title":"CoverImageWorkflowOperationHandler"},{"location":"workflowoperationhandlers/coverimage-woh/#description","text":"The CoverImageWorkflowOperationHandler generates a cover image based on an XSLT transformation which results in an SVG image that is rasterized as PNG as a last step.","title":"Description"},{"location":"workflowoperationhandlers/coverimage-woh/#parameter-table","text":"Name Type Example Default Value Description stylesheet * URL file:///etc/opencast/branding/coverimage.xsl - File URI to the XSL stylesheet used to generate the SVG image metadata XML Hello! - XML string which is passed to the XSL transformation. If parameter is not given, a default XML is handed to the transformation width * int 1920 - Width of the resulting image height * int 1080 - Height of the resulting image posterimage-flavor Flavor image/poster - Flavor of a poster image which may be used as a part of the cover image (e.g. as a background) posterimage URL http://flickr.com/posterimage.jpg - URL to a custom poster image instead of using one out of the media package target-flavor * Flavor image/cover - Flavor of the resulting cover image target-tags String archive,download - Comma separated list of tags to be applied to the resulting attachment.","title":"Parameter Table"},{"location":"workflowoperationhandlers/coverimage-woh/#metadata","text":"If no metadata is passed by using the configuration key metadata , the default metadata is passed to the cover image service which looks like the following example: <?xml version=\"1.0\"?> <metadata> <title>Puppy Love</title> <date>2014-04-24T11:21:00</date> <license>All rights reserved</license> <description>Here is a description of the video</description> <series>Superbowl Commercials</series> <contributors>Budweiser</contributors> <creators>Budweiser</creators> <subjects>Commercial</subjects> </metadata> Note that the date is localized based on your servers Java Runtime language settings.","title":"Metadata"},{"location":"workflowoperationhandlers/coverimage-woh/#stylesheet","text":"The cover image service uses the Xalan XSLT 1.0 processor to transform an XML stylesheet to an SVG image. The general structure of the stylesheet is expected to look like this: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?> <xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"> <xsl:param name=\"width\" /> <xsl:param name=\"height\" /> <xsl:param name=\"posterimage\" /> <xsl:template match=\"/\"> <svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.1\"> <xsl:attribute name=\"width\"> <xsl:value-of select=\"$width\" /> </xsl:attribute> <xsl:attribute name=\"height\"> <xsl:value-of select=\"$height\" /> </xsl:attribute> <!-- Your SVG content --> </xsl:template> </xsl:stylesheet> The variables width , height and posterimage will be set to the values of the respective configuration keys. As a starting point for your own template you best take a look at file etc/branding/coverimage.xsl .","title":"Stylesheet"},{"location":"workflowoperationhandlers/coverimage-woh/#using-xlst-extensions","text":"Xalan is a powerful XSLT 1.0 processor that comes with a rich feature set. For example, it is possible to execute JavaScript or Java code directly within the stylesheet. For commonly used tasks it is simpler, however, to make use of available XSLT Extensions.","title":"Using XLST Extensions"},{"location":"workflowoperationhandlers/coverimage-woh/#opencast-extensions","text":"The package org.opencastproject.coverimage.impl.xsl provides classes supposed to be used within XSL stylesheets. To make use of those classes, you need to reference the package from your XSL stylesheet: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?> <xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:opencast=\"xalan://org.opencastproject.coverimage.impl.xsl\" exclude-result-prefixes=\"opencast\" extension-element-prefixes=\"opencast\"> </xsl:stylesheet> Later on, you can use methods of those classes as shown in the following example: <tspan class=\"title\" y=\"30%\" x=\"50%\"> <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 1, false())\" /> </tspan> Note: In XSLT, use true() and false() for boolean literals ( true and false won't work since those are not keywords in XSLT) The following classes are provided by the org.opencastproject.coverimage.impl.xsl package: class XsltHelper String split(String text, int maxChars, int line, boolean isLastLine) This method can be used to break strings over multiple lines and to abbreviate strings that are too using ellipsis. Parameter Description text Input string maxChars Maximum number of characters per line line Number of line isLastLine Whether line is the last line used to represent the text Example To use at most two lines (max. 30 characters per line) to represent a string metadata/title and abbreviate the string if two lines aren't enough: <tspan class=\"title\" y=\"30%\" x=\"50%\"> <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 1, false())\" /> </tspan> <tspan class=\"title\" dy=\"10%\" x=\"50%\"> <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 2, true())\" /> </tspan>","title":"Opencast Extensions"},{"location":"workflowoperationhandlers/coverimage-woh/#exslt-extensions","text":"Xalan supports most of the XSLT extensions of the EXSLT community (see [1] ). In doubt consult [2] for more information about Xalan's implementation of the EXSLT extensions. Please find an example of how to use EXSLT extensions below: <xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:date=\"http://exslt.org/dates-and-times\" xmlns:opencast=\"xalan://org.opencastproject.coverimage.impl.xsl\" exclude-result-prefixes=\"date\" extension-element-prefixes=\"date\"> <!-- [...] --> <tspan class=\"presentationdate\" dy=\"12%\" x=\"50%\"> <xsl:value-of select=\"date:format-date(metadata/date, 'MMMMMMMMMM dd, YYYY, HH:mm:ss')\" /> </tspan> <!-- [...] --> </xsl:stylesheet> In this example, the function format-date of the EXSLT dates-and-times functions library is used to format a date.","title":"EXSLT Extensions"},{"location":"workflowoperationhandlers/coverimage-woh/#operation-example","text":"Operation example with metadata derived from events metadata: <operation id=\"cover-image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Create a cover image\"> <configurations> <configuration key=\"stylesheet\">file://${karaf.etc}/branding/coverimage.xsl</configuration> <configuration key=\"width\">1920</configuration> <configuration key=\"height\">1080</configuration> <configuration key=\"posterimage-flavor\">presenter/coverbackground</configuration> <configuration key=\"target-flavor\">presenter/player+preview</configuration> <configuration key=\"target-tags\">archive, engage-download</configuration> </configurations> </operation> Operation example with metadata provided in the operations configuration: <operation id=\"cover-image\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Create a cover image\"> <configurations> <configuration key=\"stylesheet\">file://${karaf.etc}/branding/coverimage.xsl</configuration> <configuration key=\"metadata\"> <![CDATA[<meta><title>my custom title</title><special>very special</special></meta>]]> </configuration> <configuration key=\"width\">1920</configuration> <configuration key=\"height\">1080</configuration> <configuration key=\"posterimage-flavor\">presenter/player+preview</configuration> <configuration key=\"target-flavor\">image/cover</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/cropvideo-woh/","text":"Crop Workflow operation The plugin provides the workflow operation crop-video . This workflow operation excutes ffmpeg command cropdetect . cropdetect checks for black bars on the sides of the track of the workflow instance. If cropdetect is successful, then ffmpeg command crop is executed. crop removes these black bars. Parameter Table configuration keys example description source-flavor */source which media should be encoded target-tags sometag Specifies the tags of the new media target-flavor presenter/cropped Flavor of the cropped media track Example for crop-video in a workflow <operation id=\"crop-video\" fail-on-error=\"false\" description=\"Detecting black bars in presentation track\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-tags\">engage-download</configuration> </configurations> </operation>","title":"Crop Video"},{"location":"workflowoperationhandlers/cropvideo-woh/#crop-workflow-operation","text":"The plugin provides the workflow operation crop-video . This workflow operation excutes ffmpeg command cropdetect . cropdetect checks for black bars on the sides of the track of the workflow instance. If cropdetect is successful, then ffmpeg command crop is executed. crop removes these black bars.","title":"Crop Workflow operation"},{"location":"workflowoperationhandlers/cropvideo-woh/#parameter-table","text":"configuration keys example description source-flavor */source which media should be encoded target-tags sometag Specifies the tags of the new media target-flavor presenter/cropped Flavor of the cropped media track","title":"Parameter Table"},{"location":"workflowoperationhandlers/cropvideo-woh/#example-for-crop-video-in-a-workflow","text":"<operation id=\"crop-video\" fail-on-error=\"false\" description=\"Detecting black bars in presentation track\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-tags\">engage-download</configuration> </configurations> </operation>","title":"Example for crop-video in a workflow"},{"location":"workflowoperationhandlers/defaults-woh/","text":"DefaultsWorkflowOperation Description The DefaultsWorkflowOperationHandler is used to define default workflow configuration values that are in effect in cases where a workflow instance is started without the user interface being invoked, with the result that no configuration of the workflow instance has taken place. The defaults specified by this handler will be applied for configuration keys that have not been specified but won't overwrite existing values. Parameter Table Tags and flavors can be used in combination. configuration keys example description default value key hello world This would set the workflow configuration \"key\" to the value \"hello world\" if - and only if - the key is undefined. - Operation Example <operation id=\"defaults\" description=\"Applying default values\"> <configurations> <configuration key=\"key\">hello world</configuration> </configurations> </operation>","title":"Defaults"},{"location":"workflowoperationhandlers/defaults-woh/#defaultsworkflowoperation","text":"","title":"DefaultsWorkflowOperation"},{"location":"workflowoperationhandlers/defaults-woh/#description","text":"The DefaultsWorkflowOperationHandler is used to define default workflow configuration values that are in effect in cases where a workflow instance is started without the user interface being invoked, with the result that no configuration of the workflow instance has taken place. The defaults specified by this handler will be applied for configuration keys that have not been specified but won't overwrite existing values.","title":"Description"},{"location":"workflowoperationhandlers/defaults-woh/#parameter-table","text":"Tags and flavors can be used in combination. configuration keys example description default value key hello world This would set the workflow configuration \"key\" to the value \"hello world\" if - and only if - the key is undefined. -","title":"Parameter Table"},{"location":"workflowoperationhandlers/defaults-woh/#operation-example","text":"<operation id=\"defaults\" description=\"Applying default values\"> <configurations> <configuration key=\"key\">hello world</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/demux-woh/","text":"Demux Workflow Operation Description The demux operation can be used to demux multiple streams (e.g. presenter and presentation) from one container and put them into separate tracks. It uses a special encoding profile that has two outputs. It flavors the target media in the order listed in the encoding profile output. Parameter Table Configuration Key Example Description source-flavors multitrack/source Which media should be encoded target-tags archive,rss;rss Specifies the tags of the new media target-flavors presenter/*,presentation/* Specifies the flavors of the new media encoding-profile demux Specifies the encoding profile Note that target-tags can hold multiple sets of tags separated by ; . Each set is applied to the matching set of output files (same order). Target flavors are separated by , as usual. They are applied in order as well. Operation Example <operation id=\"demux\" exception-handler-workflow=\"partial-error\" description=\"Extract presenter and presentation video from multitrack source\"> <configurations> <configuration key=\"source-flavors\">multitrack/source</configuration> <configuration key=\"target-flavors\">presenter/source,presentation/source</configuration> <configuration key=\"target-tags\">archive</configuration> <configuration key=\"encoding-profile\">demux</configuration> </configurations> </operation> Example Profile profile.demux.name = demux profile.demux.input = visual profile.demux.output = visual profile.demux.suffix = .mp4 profile.demux.ffmpeg.command = -i #{in.video.path} -c copy \\ -map 0:a:0 -map 0:v:0 #{out.dir}/#{out.name}_presenter#{out.suffix} \\ -map 0:a:1 -map 0:v:1 #{out.dir}/#{out.name}_presentation#{out.suffix}","title":"Demux"},{"location":"workflowoperationhandlers/demux-woh/#demux-workflow-operation","text":"","title":"Demux Workflow Operation"},{"location":"workflowoperationhandlers/demux-woh/#description","text":"The demux operation can be used to demux multiple streams (e.g. presenter and presentation) from one container and put them into separate tracks. It uses a special encoding profile that has two outputs. It flavors the target media in the order listed in the encoding profile output.","title":"Description"},{"location":"workflowoperationhandlers/demux-woh/#parameter-table","text":"Configuration Key Example Description source-flavors multitrack/source Which media should be encoded target-tags archive,rss;rss Specifies the tags of the new media target-flavors presenter/*,presentation/* Specifies the flavors of the new media encoding-profile demux Specifies the encoding profile Note that target-tags can hold multiple sets of tags separated by ; . Each set is applied to the matching set of output files (same order). Target flavors are separated by , as usual. They are applied in order as well.","title":"Parameter Table"},{"location":"workflowoperationhandlers/demux-woh/#operation-example","text":"<operation id=\"demux\" exception-handler-workflow=\"partial-error\" description=\"Extract presenter and presentation video from multitrack source\"> <configurations> <configuration key=\"source-flavors\">multitrack/source</configuration> <configuration key=\"target-flavors\">presenter/source,presentation/source</configuration> <configuration key=\"target-tags\">archive</configuration> <configuration key=\"encoding-profile\">demux</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/demux-woh/#example-profile","text":"profile.demux.name = demux profile.demux.input = visual profile.demux.output = visual profile.demux.suffix = .mp4 profile.demux.ffmpeg.command = -i #{in.video.path} -c copy \\ -map 0:a:0 -map 0:v:0 #{out.dir}/#{out.name}_presenter#{out.suffix} \\ -map 0:a:1 -map 0:v:1 #{out.dir}/#{out.name}_presentation#{out.suffix}","title":"Example Profile"},{"location":"workflowoperationhandlers/duplicate-event-woh/","text":"Duplicate Event Workflow Operation Id: duplicate-event Description The duplicate event operation can be used to duplicate an event by copying an existing one. The main use case are events, which contain a series of different presentations which were all recorded with just one recording. In order to create seperate events for each presentation, the original recording can be copied and each copy can be cut to only contain one presentation. If the original event was already published, the duplicate won't be published right away. The user will have to publish it manually when he is done editing it. For each duplicated event the new media package ID is stored as a workflow property: Name Example Description duplicate_media_package_ number _id duplicate_media_package_1_id=e72f2265-472a-49ae-bc04-8301d94b4b1a Media package ID of the duplicated event Parameter Table Configuration Key Example Description source-flavors archive Copy any mediapackage elements with one of these (comma separated) flavors. source-tags */* Copy any mediapackage elements with one of these (comma separated) tags. target-tags +copied Apply these (comma separated) tags to any copied media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. property-namespaces org.opencastproject.assetmanager.security Copy all asset manager properties of these (comma separated) namespaces. copy-number-prefix copy The prefix used for the number of the copy which is appended to the title of the new event. number-of-events 2 How many events to create. max-number-of-events 1000 How many events are allowed to be created at maximum. Operation Example <operation id=\"duplicate-event\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Duplicate event\"> <configurations> <configuration key=\"source-flavors\">*/*</configuration> <configuration key=\"number-of-events\">${numberOfEvents}</configuration> <configuration key=\"max-number-of-events\">1000</configuration> <configuration key=\"target-tags\"></configuration> <configuration key=\"property-namespaces\"> org.opencastproject.assetmanager.security </configuration> <configuration key=\"copy-number-prefix\">copy</configuration> </configurations> </operation>","title":"Duplicate Event"},{"location":"workflowoperationhandlers/duplicate-event-woh/#duplicate-event-workflow-operation","text":"Id: duplicate-event","title":"Duplicate Event Workflow Operation"},{"location":"workflowoperationhandlers/duplicate-event-woh/#description","text":"The duplicate event operation can be used to duplicate an event by copying an existing one. The main use case are events, which contain a series of different presentations which were all recorded with just one recording. In order to create seperate events for each presentation, the original recording can be copied and each copy can be cut to only contain one presentation. If the original event was already published, the duplicate won't be published right away. The user will have to publish it manually when he is done editing it. For each duplicated event the new media package ID is stored as a workflow property: Name Example Description duplicate_media_package_ number _id duplicate_media_package_1_id=e72f2265-472a-49ae-bc04-8301d94b4b1a Media package ID of the duplicated event","title":"Description"},{"location":"workflowoperationhandlers/duplicate-event-woh/#parameter-table","text":"Configuration Key Example Description source-flavors archive Copy any mediapackage elements with one of these (comma separated) flavors. source-tags */* Copy any mediapackage elements with one of these (comma separated) tags. target-tags +copied Apply these (comma separated) tags to any copied media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. property-namespaces org.opencastproject.assetmanager.security Copy all asset manager properties of these (comma separated) namespaces. copy-number-prefix copy The prefix used for the number of the copy which is appended to the title of the new event. number-of-events 2 How many events to create. max-number-of-events 1000 How many events are allowed to be created at maximum.","title":"Parameter Table"},{"location":"workflowoperationhandlers/duplicate-event-woh/#operation-example","text":"<operation id=\"duplicate-event\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Duplicate event\"> <configurations> <configuration key=\"source-flavors\">*/*</configuration> <configuration key=\"number-of-events\">${numberOfEvents}</configuration> <configuration key=\"max-number-of-events\">1000</configuration> <configuration key=\"target-tags\"></configuration> <configuration key=\"property-namespaces\"> org.opencastproject.assetmanager.security </configuration> <configuration key=\"copy-number-prefix\">copy</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/editor-woh/","text":"VideoEditorWorkflowOperationHandler Description The editor operation processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed. Parameter Table configuration keys example description source-flavors */work The flavor(s) of all media files to process smil-flavors */smil The flavor(s) of the SMIL file(s) to be used skipped-flavors */work The flavor(s) of all media files to be \"processed\" (cloned) if the editor operation is skipped target-flavor-subtype trimmed The flavor subtype to be applied to all resulting videos, e.g. for a value of baz , a track with flavor foo/bar will generate another track with flavor foo/baz target-smil-flavor smil/cutting the flavor of the SMIL file containing the final video segments. Should be the same as the smil.catalog.flavor property in etc/org.opencastproject.adminui.cfg skip-if-not-trimmed false (Optional) if set to true , the track encoding will be skipped if no trimming points were defined (i.e. there is only one segment from the very beginning to the very end of the video). Defaults to false skip-processing true Do not do the actual encoding, just create the smil file and exit. This option is used with process-smil workflow operation, which will use the smil to run the encodings then. Default is false. preview_flavors */preview (Legacy) Flavors used to preview the video in the editor. Currently has no effect. Preview flavors are now configured in the file etc/org.opencastproject.adminui.cfg interactive false (Legacy) If true make the operation interactive, i.e. pause and wait for user input. Do not use. Interactive operations are deprecated in the current API. Operation Example <operation id=\"editor\" if=\"${trimHold}\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Waiting for user to review / video edit recording\"> <configurations> <configuration key=\"source-flavors\">*/work</configuration> <configuration key=\"skipped-flavors\">*/work</configuration> <configuration key=\"smil-flavors\">*/smil</configuration> <configuration key=\"target-smil-flavor\">smil/cutting</configuration> <configuration key=\"target-flavor-subtype\">trimmed</configuration> </configurations> </operation>","title":"Editor"},{"location":"workflowoperationhandlers/editor-woh/#videoeditorworkflowoperationhandler","text":"","title":"VideoEditorWorkflowOperationHandler"},{"location":"workflowoperationhandlers/editor-woh/#description","text":"The editor operation processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed.","title":"Description"},{"location":"workflowoperationhandlers/editor-woh/#parameter-table","text":"configuration keys example description source-flavors */work The flavor(s) of all media files to process smil-flavors */smil The flavor(s) of the SMIL file(s) to be used skipped-flavors */work The flavor(s) of all media files to be \"processed\" (cloned) if the editor operation is skipped target-flavor-subtype trimmed The flavor subtype to be applied to all resulting videos, e.g. for a value of baz , a track with flavor foo/bar will generate another track with flavor foo/baz target-smil-flavor smil/cutting the flavor of the SMIL file containing the final video segments. Should be the same as the smil.catalog.flavor property in etc/org.opencastproject.adminui.cfg skip-if-not-trimmed false (Optional) if set to true , the track encoding will be skipped if no trimming points were defined (i.e. there is only one segment from the very beginning to the very end of the video). Defaults to false skip-processing true Do not do the actual encoding, just create the smil file and exit. This option is used with process-smil workflow operation, which will use the smil to run the encodings then. Default is false. preview_flavors */preview (Legacy) Flavors used to preview the video in the editor. Currently has no effect. Preview flavors are now configured in the file etc/org.opencastproject.adminui.cfg interactive false (Legacy) If true make the operation interactive, i.e. pause and wait for user input. Do not use. Interactive operations are deprecated in the current API.","title":"Parameter Table"},{"location":"workflowoperationhandlers/editor-woh/#operation-example","text":"<operation id=\"editor\" if=\"${trimHold}\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Waiting for user to review / video edit recording\"> <configurations> <configuration key=\"source-flavors\">*/work</configuration> <configuration key=\"skipped-flavors\">*/work</configuration> <configuration key=\"smil-flavors\">*/smil</configuration> <configuration key=\"target-smil-flavor\">smil/cutting</configuration> <configuration key=\"target-flavor-subtype\">trimmed</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/encode-woh/","text":"Encode Workflow Operation Handler Parallel FFmpeg encoding Description The encode workflow operation can be used to encode media files to different formats using FFmpeg . Its functionality is similar to the compose workflow operation but can utilize the parallel encoding capabilities of FFmpeg. This has the advantage that the source file needs to be read only once for several encodings, reducing the encoding time quite a lot. Additionally, this will let FFmpeg make better use of multiple CPU cores. Parameter Table configuration keys example description source-flavor presenter/work Which media should be encoded target-flavor presenter/delivery Specifies the flavor of the new media source-tags sometag Tags of media to encode target-tags sometag Specifies the tags of the new media encoding-profile webm-hd Specifies the encoding profile to use As explained in the \"Encoding Profile\" section, every media file created by an encode operation has its own named suffix. The suffix name is defined in the encode profile definition. It will be added as a tag to the corresponding track in the media package. This is different from the target-tags workflow operation parameter, which will cause the specified tag list to be added to every media file created by the operation. For instance, let us take the example operation and encoding profile defined in this documentation. After a successful run of the operation, the media package will contain four new tracks: the first one containing the new tags engage-download , engage-streaming and low-quality ; the second one containing the new tags engage-download , engage-streaming and medium-quality ; etc. Operation Example <operation id=\"encode\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"encoding media files\"> <configurations> <configuration key=\"source-flavor\">*/trimmed</configuration> <configuration key=\"target-flavor\">*/delivery</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <configuration key=\"encoding-profile\">parallel.http</configuration> </configurations> </operation> Encoding Profile Example Unlike a regular compose operation, this operation can generate more than one output file and, therefore, more than one media package track elements. In order to distinguish these tracks, the encoding profile syntax for this operation allows different named suffix parameters in the form of <profile_name>.suffix.<suffix_name> = <suffix_value> . Because file names are irrelevant for the workflow operations, each suffix name is added as a tag to the corresponding media package element. For instance, if a media file with a filename of myfile.ext is processed with the encoding profile in the example below, the first output file will be myfile-low.mp4 and the resulting media package element will contain a tag with the value low-quality ; the second output file will be myfile-medium.mp4 and the resulting media package element will contain a tag with the value medium-quality ; and so on. # Distribution format definition for low quality presenter download profile.parallel.http.name = parallel video encoding profile.parallel.http.input = visual profile.parallel.http.output = visual profile.parallel.http.suffix.low-quality = -low.mp4 profile.parallel.http.suffix.medium-quality = -medium.mp4 profile.parallel.http.suffix.high-quality = -high.mp4 profile.parallel.http.suffix.hd-quality = -hd.mp4 profile.parallel.http.ffmpeg.command = -i #{in.video.path} \\ -c:v libx264 -filter:v yadif,scale=-2:288 -preset slower -crf 28 -r 25 -profile:v baseline -tune film -movflags faststart \\ -c:a aac -ar 22050 -ac 1 -ab 32k #{out.dir}/#{out.name}#{out.suffix.low-quality} \\ -c:v libx264 -filter:v yadif,scale=-2:360 -preset slower -crf 25 -r 25 -profile:v baseline -tune film -movflags faststart \\ -c:a aac -ar 22050 -ac 1 -ab 48k #{out.dir}/#{out.name}#{out.suffix.medium-quality} \\ -c:v libx264 -filter:v yadif,scale=-2:576 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.high-quality} \\ -c:v libx264 -filter:v yadif,scale=-2:720 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.hd-quality} Resolution Based Encoding The encode operation supports encoding based on the input video's resolution. For example, you can encode a certain output resolution only for high resolution inputs. For this you can define variables like if-height-geq-720 which retain their value only if the video resolution meets the defined criteria. This modification to the encoding profile from above will encode the 720p output only if the input height is at least 720 pixels: \u2026 profile.parallel.http.ffmpeg.command.if-height-geq-720 = -c:v libx264 -filter:v yadif,scale=-2:720 \\ -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.hd-quality} profile.parallel.http.ffmpeg.command = -i #{in.video.path} \\ \u2026 -c:v libx264 -filter:v yadif,scale=-2:576 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.high-quality} \\ #{if-height-geq-720}","title":"Encode"},{"location":"workflowoperationhandlers/encode-woh/#encode-workflow-operation-handler","text":"Parallel FFmpeg encoding","title":"Encode Workflow Operation Handler"},{"location":"workflowoperationhandlers/encode-woh/#description","text":"The encode workflow operation can be used to encode media files to different formats using FFmpeg . Its functionality is similar to the compose workflow operation but can utilize the parallel encoding capabilities of FFmpeg. This has the advantage that the source file needs to be read only once for several encodings, reducing the encoding time quite a lot. Additionally, this will let FFmpeg make better use of multiple CPU cores.","title":"Description"},{"location":"workflowoperationhandlers/encode-woh/#parameter-table","text":"configuration keys example description source-flavor presenter/work Which media should be encoded target-flavor presenter/delivery Specifies the flavor of the new media source-tags sometag Tags of media to encode target-tags sometag Specifies the tags of the new media encoding-profile webm-hd Specifies the encoding profile to use As explained in the \"Encoding Profile\" section, every media file created by an encode operation has its own named suffix. The suffix name is defined in the encode profile definition. It will be added as a tag to the corresponding track in the media package. This is different from the target-tags workflow operation parameter, which will cause the specified tag list to be added to every media file created by the operation. For instance, let us take the example operation and encoding profile defined in this documentation. After a successful run of the operation, the media package will contain four new tracks: the first one containing the new tags engage-download , engage-streaming and low-quality ; the second one containing the new tags engage-download , engage-streaming and medium-quality ; etc.","title":"Parameter Table"},{"location":"workflowoperationhandlers/encode-woh/#operation-example","text":"<operation id=\"encode\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"encoding media files\"> <configurations> <configuration key=\"source-flavor\">*/trimmed</configuration> <configuration key=\"target-flavor\">*/delivery</configuration> <configuration key=\"target-tags\">engage-download,engage-streaming</configuration> <configuration key=\"encoding-profile\">parallel.http</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/encode-woh/#encoding-profile-example","text":"Unlike a regular compose operation, this operation can generate more than one output file and, therefore, more than one media package track elements. In order to distinguish these tracks, the encoding profile syntax for this operation allows different named suffix parameters in the form of <profile_name>.suffix.<suffix_name> = <suffix_value> . Because file names are irrelevant for the workflow operations, each suffix name is added as a tag to the corresponding media package element. For instance, if a media file with a filename of myfile.ext is processed with the encoding profile in the example below, the first output file will be myfile-low.mp4 and the resulting media package element will contain a tag with the value low-quality ; the second output file will be myfile-medium.mp4 and the resulting media package element will contain a tag with the value medium-quality ; and so on. # Distribution format definition for low quality presenter download profile.parallel.http.name = parallel video encoding profile.parallel.http.input = visual profile.parallel.http.output = visual profile.parallel.http.suffix.low-quality = -low.mp4 profile.parallel.http.suffix.medium-quality = -medium.mp4 profile.parallel.http.suffix.high-quality = -high.mp4 profile.parallel.http.suffix.hd-quality = -hd.mp4 profile.parallel.http.ffmpeg.command = -i #{in.video.path} \\ -c:v libx264 -filter:v yadif,scale=-2:288 -preset slower -crf 28 -r 25 -profile:v baseline -tune film -movflags faststart \\ -c:a aac -ar 22050 -ac 1 -ab 32k #{out.dir}/#{out.name}#{out.suffix.low-quality} \\ -c:v libx264 -filter:v yadif,scale=-2:360 -preset slower -crf 25 -r 25 -profile:v baseline -tune film -movflags faststart \\ -c:a aac -ar 22050 -ac 1 -ab 48k #{out.dir}/#{out.name}#{out.suffix.medium-quality} \\ -c:v libx264 -filter:v yadif,scale=-2:576 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.high-quality} \\ -c:v libx264 -filter:v yadif,scale=-2:720 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.hd-quality}","title":"Encoding Profile Example"},{"location":"workflowoperationhandlers/encode-woh/#resolution-based-encoding","text":"The encode operation supports encoding based on the input video's resolution. For example, you can encode a certain output resolution only for high resolution inputs. For this you can define variables like if-height-geq-720 which retain their value only if the video resolution meets the defined criteria. This modification to the encoding profile from above will encode the 720p output only if the input height is at least 720 pixels: \u2026 profile.parallel.http.ffmpeg.command.if-height-geq-720 = -c:v libx264 -filter:v yadif,scale=-2:720 \\ -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.hd-quality} profile.parallel.http.ffmpeg.command = -i #{in.video.path} \\ \u2026 -c:v libx264 -filter:v yadif,scale=-2:576 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film -movflags faststart \\ -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.high-quality} \\ #{if-height-geq-720}","title":"Resolution Based Encoding"},{"location":"workflowoperationhandlers/error-resolution-woh/","text":"Error Resolution Workflow Operation Id: error-resolution Description The Error Resolution operation is an internal operation inserted in the workflow by the Workflow Service when an operation that has retry-strategy=\"hold\" fails. This operations pauses the workflow so that the user can retry or abort processing using the Admin UI. See Retry Strategies for more details.","title":"Error Resolution"},{"location":"workflowoperationhandlers/error-resolution-woh/#error-resolution-workflow-operation","text":"Id: error-resolution","title":"Error Resolution Workflow Operation"},{"location":"workflowoperationhandlers/error-resolution-woh/#description","text":"The Error Resolution operation is an internal operation inserted in the workflow by the Workflow Service when an operation that has retry-strategy=\"hold\" fails. This operations pauses the workflow so that the user can retry or abort processing using the Admin UI. See Retry Strategies for more details.","title":"Description"},{"location":"workflowoperationhandlers/execute-many-woh/","text":"Execute Many Workflow Operation This operation handler filters a set of MediaPackageElements that match certain input conditions and runs a command on each of them. To run a command only once for the whole mediapackage, use the Execute Once operation. Commands run by this operation handler must first be included in the commands.allowed list in the Execute Service configuration. Parameter table All parameters are empty by default if not specified. The special parameters #in and #out are described in Execute Service: Parameter Substitution Configuration keys Example Description Required? exec qtfaststart The command to run Yes params -f -t 15 #{in} #{out} The arguments to the command. This string allows some placeholders for input and output MediaPackage elements (see Parameter Substitution) Yes load 1.5 A floating point estimate of the load imposed on the node by this job No source-flavor presentation/source Run the command for any MediaPackage elements with this flavor. Elements must also match the source-tags condition, if present No source-tag rss, trim, -engage Run the command for any MediaPackage elements with one of these (comma- separated) tags. If any of them starts with '-', MediaPackage elements containing this tag will be excluded. Elements must also match the source-flavor condition, if present No output-filename outfile.mp4 Specifies the name of the file created by the command (if any), without path information. Used as the last part of the #{out} parameter No expected-type Track Specifies the type of MediaPackage element produced by the command: Manifest, Timeline, Track, Catalog, Attachment, Publication, Other Required if output- filename is present target-flavor presentation/processed Specifies the flavor of the resulting Mediapackage element created by the command Required if output- filename is present target-tags execservice, -trim List of tags that will be applied to the resulting Mediapackage element. Tags starting with \"-\" will be deleted from the element instead, if present. The resulting element may be the same as the input element No Operation Example <operation id=\"execute-many\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Run command\"> <configurations> <configuration key=\"exec\">qt-faststart</configuration> <configuration key=\"params\">-f #{in} #{out}</configuration> <configuration key=\"source-flavor\">*/toprocess</configuration> <configuration key=\"source-tags\">copy, -rss</configuration> <configuration key=\"output-filename\">result.avi</configuration> <configuration key=\"target-flavor\">output/processed</configuration> <configuration key=\"target-tags\">copied, -copy</configuration> <configuration key=\"expected-type\">Track</configuration> </configurations> </operation>","title":"Execute Many"},{"location":"workflowoperationhandlers/execute-many-woh/#execute-many-workflow-operation","text":"This operation handler filters a set of MediaPackageElements that match certain input conditions and runs a command on each of them. To run a command only once for the whole mediapackage, use the Execute Once operation. Commands run by this operation handler must first be included in the commands.allowed list in the Execute Service configuration.","title":"Execute Many Workflow Operation"},{"location":"workflowoperationhandlers/execute-many-woh/#parameter-table","text":"All parameters are empty by default if not specified. The special parameters #in and #out are described in Execute Service: Parameter Substitution Configuration keys Example Description Required? exec qtfaststart The command to run Yes params -f -t 15 #{in} #{out} The arguments to the command. This string allows some placeholders for input and output MediaPackage elements (see Parameter Substitution) Yes load 1.5 A floating point estimate of the load imposed on the node by this job No source-flavor presentation/source Run the command for any MediaPackage elements with this flavor. Elements must also match the source-tags condition, if present No source-tag rss, trim, -engage Run the command for any MediaPackage elements with one of these (comma- separated) tags. If any of them starts with '-', MediaPackage elements containing this tag will be excluded. Elements must also match the source-flavor condition, if present No output-filename outfile.mp4 Specifies the name of the file created by the command (if any), without path information. Used as the last part of the #{out} parameter No expected-type Track Specifies the type of MediaPackage element produced by the command: Manifest, Timeline, Track, Catalog, Attachment, Publication, Other Required if output- filename is present target-flavor presentation/processed Specifies the flavor of the resulting Mediapackage element created by the command Required if output- filename is present target-tags execservice, -trim List of tags that will be applied to the resulting Mediapackage element. Tags starting with \"-\" will be deleted from the element instead, if present. The resulting element may be the same as the input element No","title":"Parameter table"},{"location":"workflowoperationhandlers/execute-many-woh/#operation-example","text":"<operation id=\"execute-many\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Run command\"> <configurations> <configuration key=\"exec\">qt-faststart</configuration> <configuration key=\"params\">-f #{in} #{out}</configuration> <configuration key=\"source-flavor\">*/toprocess</configuration> <configuration key=\"source-tags\">copy, -rss</configuration> <configuration key=\"output-filename\">result.avi</configuration> <configuration key=\"target-flavor\">output/processed</configuration> <configuration key=\"target-tags\">copied, -copy</configuration> <configuration key=\"expected-type\">Track</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/execute-once-woh/","text":"Execute Once Workflow Operation This operation handler runs a single command with multiple MediaPackage elements as arguments. The command may be used to create a new mediapackage element, or to add configuration properties to the running workflow. To run a command for each element in a MediaPackage, use the Execute Many operation. Commands run by this operation handler must first be included in the commands.allowed list in the Execute Service configuration. Parameter table All parameters are empty by default if not specified. The special parameters #id , #flavor and #out are described in Execute Service: Parameter Substitution Configuration keys Example Description Required? exec qtfaststart The command to run Yes params -f -t 15 #{flavor(presentation/distribute)} #{out} The arguments to the command. This string allows some placeholders for input and output MediaPackage elements (see Parameter Substitution) Yes load 1.5 A floating point estimate of the load imposed on the node by this job No set-workflow-properties true / false Import workflow properties from the output file No output-filename outfile.mp4 Specifies the name of the file created by the command (if any), without path information. Used as the last part of the #{out} parameter No expected-type Track Specifies the type of MediaPackage element produced by the command: Manifest, Timeline, Track, Catalog, Attachment, Publication, Other Required if output- filename is present target-flavor presentation/processed Specifies the flavor of the resulting Mediapackage element created by the command. If no new element is created, this parameter is ignored. Required if output- filename is present target-tags execservice, -trim List of tags that will be applied to the resulting Mediapackage element. Tags starting with \"-\" will be deleted from the element instead, if present. The resulting element may be the same as the input element. No If set-workflow-properties is true, the command should write a plain-text properties file to the location specified by #{out} in the key-value format supported by the Java Properties class, for example: key1=value1 key2=value2 Operation Examples Run a command which combines two tracks into a new track: <operation id=\"execute-once\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Run command\"> <configurations> <configuration key=\"exec\">ges-launch</configuration> <configuration key=\"params\">-e #{flavor(presenter/source)} 0 5m14s #{flavor(presentation/source)} 0 14s</configuration> <configuration key=\"output-filename\">result.avi</configuration> <configuration key=\"target-flavor\">output/joined</configuration> <configuration key=\"target-tags\">joined, -tojoin</configuration> <configuration key=\"expected-type\">Track</configuration> </configurations> </operation> Run a command which inspects a mediapackage and adds new configuration properties to the running workflow, leaving the mediapackage unchanged: <operation id=\"execute-once\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspect media and update workflow properties\"> <configurations> <configuration key=\"exec\">/usr/local/bin/oc-inspect.sh</configuration> <configuration key=\"params\">#{out} #{id}</configuration> <configuration key=\"set-workflow-properties\">true</configuration> <configuration key=\"output-filename\">wf.properties</configuration> <configuration key=\"expected-type\">Attachment</configuration> </configurations> </operation>","title":"Execute Once"},{"location":"workflowoperationhandlers/execute-once-woh/#execute-once-workflow-operation","text":"This operation handler runs a single command with multiple MediaPackage elements as arguments. The command may be used to create a new mediapackage element, or to add configuration properties to the running workflow. To run a command for each element in a MediaPackage, use the Execute Many operation. Commands run by this operation handler must first be included in the commands.allowed list in the Execute Service configuration.","title":"Execute Once Workflow Operation"},{"location":"workflowoperationhandlers/execute-once-woh/#parameter-table","text":"All parameters are empty by default if not specified. The special parameters #id , #flavor and #out are described in Execute Service: Parameter Substitution Configuration keys Example Description Required? exec qtfaststart The command to run Yes params -f -t 15 #{flavor(presentation/distribute)} #{out} The arguments to the command. This string allows some placeholders for input and output MediaPackage elements (see Parameter Substitution) Yes load 1.5 A floating point estimate of the load imposed on the node by this job No set-workflow-properties true / false Import workflow properties from the output file No output-filename outfile.mp4 Specifies the name of the file created by the command (if any), without path information. Used as the last part of the #{out} parameter No expected-type Track Specifies the type of MediaPackage element produced by the command: Manifest, Timeline, Track, Catalog, Attachment, Publication, Other Required if output- filename is present target-flavor presentation/processed Specifies the flavor of the resulting Mediapackage element created by the command. If no new element is created, this parameter is ignored. Required if output- filename is present target-tags execservice, -trim List of tags that will be applied to the resulting Mediapackage element. Tags starting with \"-\" will be deleted from the element instead, if present. The resulting element may be the same as the input element. No If set-workflow-properties is true, the command should write a plain-text properties file to the location specified by #{out} in the key-value format supported by the Java Properties class, for example: key1=value1 key2=value2","title":"Parameter table"},{"location":"workflowoperationhandlers/execute-once-woh/#operation-examples","text":"Run a command which combines two tracks into a new track: <operation id=\"execute-once\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Run command\"> <configurations> <configuration key=\"exec\">ges-launch</configuration> <configuration key=\"params\">-e #{flavor(presenter/source)} 0 5m14s #{flavor(presentation/source)} 0 14s</configuration> <configuration key=\"output-filename\">result.avi</configuration> <configuration key=\"target-flavor\">output/joined</configuration> <configuration key=\"target-tags\">joined, -tojoin</configuration> <configuration key=\"expected-type\">Track</configuration> </configurations> </operation> Run a command which inspects a mediapackage and adds new configuration properties to the running workflow, leaving the mediapackage unchanged: <operation id=\"execute-once\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspect media and update workflow properties\"> <configurations> <configuration key=\"exec\">/usr/local/bin/oc-inspect.sh</configuration> <configuration key=\"params\">#{out} #{id}</configuration> <configuration key=\"set-workflow-properties\">true</configuration> <configuration key=\"output-filename\">wf.properties</configuration> <configuration key=\"expected-type\">Attachment</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/export-wf-properties-woh/","text":"ExportWfPropertiesWorkflowOperationHandler Description The ExportWfPropertiesWorkflowOperation can be used to export workflow properties to a Java properties file. Those properties can later be imported using the ImportWfPropertiesWorkflowOperation . Parameter Table Configuration Key Example Description target-flavor* processing/defaults The flavor to apply to the exported workflow properties target-tags archive The tags to apply to the exported workflow properties keys variableName1, variableName2 The workflow property keys that need to be persisted. If the option is not specified, all defined properties should be persisted. * mandatory configuration key Operation Example <operation id=\"export-wf-properties\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Export workflow settings to Java properties file\"> <configurations> <configuration key=\"target-flavor\">processing/defaults</configuration> <configuration key=\"target-tags\">archive</configuration> </configurations> </operation>","title":"Export Workflow Properties"},{"location":"workflowoperationhandlers/export-wf-properties-woh/#exportwfpropertiesworkflowoperationhandler","text":"","title":"ExportWfPropertiesWorkflowOperationHandler"},{"location":"workflowoperationhandlers/export-wf-properties-woh/#description","text":"The ExportWfPropertiesWorkflowOperation can be used to export workflow properties to a Java properties file. Those properties can later be imported using the ImportWfPropertiesWorkflowOperation .","title":"Description"},{"location":"workflowoperationhandlers/export-wf-properties-woh/#parameter-table","text":"Configuration Key Example Description target-flavor* processing/defaults The flavor to apply to the exported workflow properties target-tags archive The tags to apply to the exported workflow properties keys variableName1, variableName2 The workflow property keys that need to be persisted. If the option is not specified, all defined properties should be persisted. * mandatory configuration key","title":"Parameter Table"},{"location":"workflowoperationhandlers/export-wf-properties-woh/#operation-example","text":"<operation id=\"export-wf-properties\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Export workflow settings to Java properties file\"> <configurations> <configuration key=\"target-flavor\">processing/defaults</configuration> <configuration key=\"target-tags\">archive</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/extracttext-woh/","text":"ExtractTextWorkflowOperation Description The ExtractTextWorkflowOperation will try to extract test from a video using Tesseract OCR. Parameter Table configuration keys example description source-flavor presentation/work Specifies which media should be processed source-tags text Specifies which media should be processed target-tags engage Specifies the tags for the produces media Operation Example <operation id=\"extract-text\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Extracting text from presentation segments\"> <configurations> <configuration key=\"source-flavor\">presentation/trimmed</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-tags\">engage,archive</configuration> </configurations> </operation>","title":"Extract Text"},{"location":"workflowoperationhandlers/extracttext-woh/#extracttextworkflowoperation","text":"","title":"ExtractTextWorkflowOperation"},{"location":"workflowoperationhandlers/extracttext-woh/#description","text":"The ExtractTextWorkflowOperation will try to extract test from a video using Tesseract OCR.","title":"Description"},{"location":"workflowoperationhandlers/extracttext-woh/#parameter-table","text":"configuration keys example description source-flavor presentation/work Specifies which media should be processed source-tags text Specifies which media should be processed target-tags engage Specifies the tags for the produces media","title":"Parameter Table"},{"location":"workflowoperationhandlers/extracttext-woh/#operation-example","text":"<operation id=\"extract-text\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Extracting text from presentation segments\"> <configurations> <configuration key=\"source-flavor\">presentation/trimmed</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-tags\">engage,archive</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/failing-woh/","text":"Failing Workflow Operation Id: failing Description The Failing operation will always fail and is supposed to be used for testing purposes only.","title":"Failing"},{"location":"workflowoperationhandlers/failing-woh/#failing-workflow-operation","text":"Id: failing","title":"Failing Workflow Operation"},{"location":"workflowoperationhandlers/failing-woh/#description","text":"The Failing operation will always fail and is supposed to be used for testing purposes only.","title":"Description"},{"location":"workflowoperationhandlers/google-speech-attach-transcription-woh/","text":"Google Speech Attach Transcription Description Google Speech Attach Transcription converts the json format file received from the Google Speech-to-Text service into the desired caption format and adds it to the media package. Parameter Table configuration keys description default value example transcription-job-id This is filled out by the transcription service when starting the workflow. EMPTY Should always be \"${transcriptionJobId}\" line-size The line size (number of characters) of the transcripts to display at a time. Optional. EMPTY 100 target-flavor The flavor of the caption/transcription file generated. Mandatory. EMPTY captions/timedtext target-tag The tag to apply to the caption/transcription file generated. Optional. EMPTY archive target-caption-format The caption format to be generated. Optional. If not entered, the raw resulting file will be attached to the media package. EMPTY vtt Example <!-- Attach caption/transcript --> <operation id=\"google-speech-attach-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Attach captions/transcription\"> <configurations> <!-- This is filled out by the transcription service when starting this workflow --> <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration> <configuration key=\"line-size\">100</configuration> <configuration key=\"target-flavor\">captions/timedtext</configuration> <configuration key=\"target-tag\">archive</configuration> <configuration key=\"target-caption-format\">vtt</configuration> </configurations> </operation> <!-- Publish to engage player --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Distribute and publish to engage server\"> <configurations> <configuration key=\"download-source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">false</configuration> </configurations> </operation> <!-- Publish to oaipmh --> <operation id=\"republish-oaipmh\" exception-handler-workflow=\"partial-error\" description=\"Update recording metadata in default OAI-PMH repository\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Google Speech Attach Transcription"},{"location":"workflowoperationhandlers/google-speech-attach-transcription-woh/#google-speech-attach-transcription","text":"","title":"Google Speech Attach Transcription"},{"location":"workflowoperationhandlers/google-speech-attach-transcription-woh/#description","text":"Google Speech Attach Transcription converts the json format file received from the Google Speech-to-Text service into the desired caption format and adds it to the media package.","title":"Description"},{"location":"workflowoperationhandlers/google-speech-attach-transcription-woh/#parameter-table","text":"configuration keys description default value example transcription-job-id This is filled out by the transcription service when starting the workflow. EMPTY Should always be \"${transcriptionJobId}\" line-size The line size (number of characters) of the transcripts to display at a time. Optional. EMPTY 100 target-flavor The flavor of the caption/transcription file generated. Mandatory. EMPTY captions/timedtext target-tag The tag to apply to the caption/transcription file generated. Optional. EMPTY archive target-caption-format The caption format to be generated. Optional. If not entered, the raw resulting file will be attached to the media package. EMPTY vtt","title":"Parameter Table"},{"location":"workflowoperationhandlers/google-speech-attach-transcription-woh/#example","text":"<!-- Attach caption/transcript --> <operation id=\"google-speech-attach-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Attach captions/transcription\"> <configurations> <!-- This is filled out by the transcription service when starting this workflow --> <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration> <configuration key=\"line-size\">100</configuration> <configuration key=\"target-flavor\">captions/timedtext</configuration> <configuration key=\"target-tag\">archive</configuration> <configuration key=\"target-caption-format\">vtt</configuration> </configurations> </operation> <!-- Publish to engage player --> <operation id=\"publish-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Distribute and publish to engage server\"> <configurations> <configuration key=\"download-source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">false</configuration> </configurations> </operation> <!-- Publish to oaipmh --> <operation id=\"republish-oaipmh\" exception-handler-workflow=\"partial-error\" description=\"Update recording metadata in default OAI-PMH repository\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*,captions/*</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Example"},{"location":"workflowoperationhandlers/google-speech-start-transcription-woh/","text":"Google Speech Start Transcription Description Google speech Start Transcription invokes the Google Speech-to-Text service by passing an audio file to be translated to text. Parameter Table configuration keys description default value example source-flavor The flavor of the audio file to be sent for translation. EMPTY presenter/delivery source-tag The flavor of the audio file to be sent for translation. EMPTY transcript skip-if-flavor-exists If this flavor already exists in the media package, skip this operation. To be used when the media package already has a transcript file. Optional false captions/timedtext language-code The language code to use for the transcription. Optional. If set, it will override the configuration language code EMPTY en-US, supported language: https://cloud.google.com/speech-to-text/docs/languages One of source-flavor or source-tag must be specified. Example <!-- Encode audio to flac --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-flavor\">audio/flac</configuration> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-flac</configuration> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start Google Speech transcription job --> <operation id=\"google-speech-start-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start Google Speech transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mp already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/timedtext</configuration> <configuration key=\"language-code\">en-US</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation> Encoding profile used in example above profile.audio-flac.name = audio-flac profile.audio-flac.input = stream profile.audio-flac.output = audio profile.audio-flac.suffix = -audio.flac profile.audio-flac.mimetype = audio/flac profile.audio-flac.ffmpeg.command = -i /#{in.video.path} -ac 1 #{out.dir}/#{out.name}#{out.suffix}","title":"Google Speech Start Transcription"},{"location":"workflowoperationhandlers/google-speech-start-transcription-woh/#google-speech-start-transcription","text":"","title":"Google Speech Start Transcription"},{"location":"workflowoperationhandlers/google-speech-start-transcription-woh/#description","text":"Google speech Start Transcription invokes the Google Speech-to-Text service by passing an audio file to be translated to text.","title":"Description"},{"location":"workflowoperationhandlers/google-speech-start-transcription-woh/#parameter-table","text":"configuration keys description default value example source-flavor The flavor of the audio file to be sent for translation. EMPTY presenter/delivery source-tag The flavor of the audio file to be sent for translation. EMPTY transcript skip-if-flavor-exists If this flavor already exists in the media package, skip this operation. To be used when the media package already has a transcript file. Optional false captions/timedtext language-code The language code to use for the transcription. Optional. If set, it will override the configuration language code EMPTY en-US, supported language: https://cloud.google.com/speech-to-text/docs/languages One of source-flavor or source-tag must be specified.","title":"Parameter Table"},{"location":"workflowoperationhandlers/google-speech-start-transcription-woh/#example","text":"<!-- Encode audio to flac --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-flavor\">audio/flac</configuration> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-flac</configuration> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start Google Speech transcription job --> <operation id=\"google-speech-start-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start Google Speech transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mp already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/timedtext</configuration> <configuration key=\"language-code\">en-US</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation>","title":"Example"},{"location":"workflowoperationhandlers/google-speech-start-transcription-woh/#encoding-profile-used-in-example-above","text":"profile.audio-flac.name = audio-flac profile.audio-flac.input = stream profile.audio-flac.output = audio profile.audio-flac.suffix = -audio.flac profile.audio-flac.mimetype = audio/flac profile.audio-flac.ffmpeg.command = -i /#{in.video.path} -ac 1 #{out.dir}/#{out.name}#{out.suffix}","title":"Encoding profile used in example above"},{"location":"workflowoperationhandlers/httpnotify-woh/","text":"HttpNotificationWorkflowOperation Description Opencast can through this operation notify any HTTP endpoint about the process of the workflow. Parameter Table A parameter that is always posted is the workflow instance identifier in the parameter named workflowInstanceId containing the current workflow\u2019s identifier. Key Required Description Example url true The target url to notify http://test.ch subject false The name of the event to notify from. The following events are planned: importing_started, imported, prepared, processing_started, published importing_started message false Data supporting the notification. Think of this as the body of an e-mail internal::25 method false Supported methods are \"put\", \"post\". If no method is specified, \"post\" is used by default post max-retry false The maximal number of notification attempts. The default value is 5 5 timeout false The timeout in seconds for the notification request: The default value is 10 10 Operation Example <operation id=\"http-notify\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Notify test\"> <configurations> <configuration key=\"url\">http://www.test.ch</configuration> <configuration key=\"subject\">importing-started</configuration> <configuration key=\"message\">internal::25</configuration> <configuration key=\"method\">put</configuration> <configuration key=\"max-retry\">3</configuration> <configuration key=\"timeout\">5</configuration> </configurations> </operation>","title":"HTTP Notify"},{"location":"workflowoperationhandlers/httpnotify-woh/#httpnotificationworkflowoperation","text":"","title":"HttpNotificationWorkflowOperation"},{"location":"workflowoperationhandlers/httpnotify-woh/#description","text":"Opencast can through this operation notify any HTTP endpoint about the process of the workflow.","title":"Description"},{"location":"workflowoperationhandlers/httpnotify-woh/#parameter-table","text":"A parameter that is always posted is the workflow instance identifier in the parameter named workflowInstanceId containing the current workflow\u2019s identifier. Key Required Description Example url true The target url to notify http://test.ch subject false The name of the event to notify from. The following events are planned: importing_started, imported, prepared, processing_started, published importing_started message false Data supporting the notification. Think of this as the body of an e-mail internal::25 method false Supported methods are \"put\", \"post\". If no method is specified, \"post\" is used by default post max-retry false The maximal number of notification attempts. The default value is 5 5 timeout false The timeout in seconds for the notification request: The default value is 10 10","title":"Parameter Table"},{"location":"workflowoperationhandlers/httpnotify-woh/#operation-example","text":"<operation id=\"http-notify\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Notify test\"> <configurations> <configuration key=\"url\">http://www.test.ch</configuration> <configuration key=\"subject\">importing-started</configuration> <configuration key=\"message\">internal::25</configuration> <configuration key=\"method\">put</configuration> <configuration key=\"max-retry\">3</configuration> <configuration key=\"timeout\">5</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/image-convert-woh/","text":"Image-Convert Workflow Operation Description The Image-Convert workflow operation allows source images to be converted into target images with different encoding settings. One example is the conversion of preview images into different formats. This operation expects an attachment as input and creates one attachment as output. Parameter Table configuration keys example description default value source-tags* preview+player,preview+search A comma separated lsit of source image(s) tags. EMPTY source-flavors* */image A comma separated list of source image(s) flavors. EMPTY tags-and-flavors false An boolean value wether to select elements with tags and flavors (then set this option to true) or either tags or flavors (then set this option to false). false target-tags +preview-converted,-preview+player Apply these (comma separated) tags to the output attachments. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. EMPTY target-flavor* */image+converted Apply these flavor to the output attachments. EMPTY encoding-profiles* jpeg-player,jpeg-search A comma separated list of encoding profiles to be applied to each input image. EMPTY * mandatory configuration key Note: At least source-tags or source-flavors parameter must be set. Operation Example This operation would convert all image attachments with flavor matches */preview and tag player into two different formats described by the encoding profiles preview-regular.image and preview-small.image . The produced image attachments will have an flavor with the subtype preview+player . <operation id=\"image-convert\" exception-handler-workflow=\"error\" description=\"Resize images to fixed size\"> <configurations> <configuration key=\"source-tags\">player</configuration> <configuration key=\"source-flavors\">*/preview</configuration> <configuration key=\"tags-and-flavors\">true</configuration> <configuration key=\"target-tags\"></configuration> <configuration key=\"target-flavor\">*/preview+player</configuration> <configuration key=\"encoding-profiles\">preview-regular.image,preview-small.image</configuration> </configurations> </operation> Encoding Profile Example # Player preview image regular size profile.preview-regular.image.name = player preview image regular size profile.preview-regular.image.input = image profile.preview-regular.image.output = image profile.preview-regular.image.suffix = -preview-regular.jpg profile.preview-regular.image.mimetype = image/jpeg profile.preview-regular.image.ffmpeg.command = -i #{in.video.path} -vf scale=480:-2 #{out.dir}/#{out.name}#{out.suffix}","title":"Image convert"},{"location":"workflowoperationhandlers/image-convert-woh/#image-convert-workflow-operation","text":"","title":"Image-Convert Workflow Operation"},{"location":"workflowoperationhandlers/image-convert-woh/#description","text":"The Image-Convert workflow operation allows source images to be converted into target images with different encoding settings. One example is the conversion of preview images into different formats. This operation expects an attachment as input and creates one attachment as output.","title":"Description"},{"location":"workflowoperationhandlers/image-convert-woh/#parameter-table","text":"configuration keys example description default value source-tags* preview+player,preview+search A comma separated lsit of source image(s) tags. EMPTY source-flavors* */image A comma separated list of source image(s) flavors. EMPTY tags-and-flavors false An boolean value wether to select elements with tags and flavors (then set this option to true) or either tags or flavors (then set this option to false). false target-tags +preview-converted,-preview+player Apply these (comma separated) tags to the output attachments. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. EMPTY target-flavor* */image+converted Apply these flavor to the output attachments. EMPTY encoding-profiles* jpeg-player,jpeg-search A comma separated list of encoding profiles to be applied to each input image. EMPTY * mandatory configuration key Note: At least source-tags or source-flavors parameter must be set.","title":"Parameter Table"},{"location":"workflowoperationhandlers/image-convert-woh/#operation-example","text":"This operation would convert all image attachments with flavor matches */preview and tag player into two different formats described by the encoding profiles preview-regular.image and preview-small.image . The produced image attachments will have an flavor with the subtype preview+player . <operation id=\"image-convert\" exception-handler-workflow=\"error\" description=\"Resize images to fixed size\"> <configurations> <configuration key=\"source-tags\">player</configuration> <configuration key=\"source-flavors\">*/preview</configuration> <configuration key=\"tags-and-flavors\">true</configuration> <configuration key=\"target-tags\"></configuration> <configuration key=\"target-flavor\">*/preview+player</configuration> <configuration key=\"encoding-profiles\">preview-regular.image,preview-small.image</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/image-convert-woh/#encoding-profile-example","text":"# Player preview image regular size profile.preview-regular.image.name = player preview image regular size profile.preview-regular.image.input = image profile.preview-regular.image.output = image profile.preview-regular.image.suffix = -preview-regular.jpg profile.preview-regular.image.mimetype = image/jpeg profile.preview-regular.image.ffmpeg.command = -i #{in.video.path} -vf scale=480:-2 #{out.dir}/#{out.name}#{out.suffix}","title":"Encoding Profile Example"},{"location":"workflowoperationhandlers/image-woh/","text":"Image Workflow Operation ID: image Description The image operation will extract still images from a video using FFmpeg and a list of given encoding profiles. Both absolute and relative positions can be used. Parameter Table configuration keys example description source-flavor presenter/source Specifies which media should be processed. source-flavors presenter/source, presentation/source Specifies a list of media which should be processed. In case a flavor has been specified in source-flavor , it will be added to this list. source-tags engage Specifies which media should be processed. target-flavor presenter/work Specifies the flavor the new files will get. target-tags engage Specifies the tags the new files will get. encoding-profile search-cover.http Comma-separated list of encoding profiles to use. time 1 or 5% Comma-separated list of times in seconds or as percentage of the source track duration where the images should be extracted target-base-name-format-second thumbnail_%.0f%s Used to control the target filenames for images extracted at absolute times. Mainly helpful when integrating third-party applications that prefer to use filename to distinguish individual images target-base-name-format-percent thumbnail_%.3f%s Used to control the target filenames for images extracted at relative times. Mainly helpful when integrating third-party applications that prefer to use filename to distinguish individual images end-margin 500 Safety margin at the end of the track. Sometimes, image extraction is critical at the end of the file. Using end-margin ensures, that no images are being extracted near the end of the video file to avoid problems with defective inputs. (Default: 100) Notes: Absolute and relative position may be mixed up in the configuration key time Operation Example Extract one image at position 1 second using the encoding profile search-cover.http . <operation id=\"image\" description=\"Encoding presenter preview image\"> <configurations> <configuration key=\"source-flavor\">presenter/trimmed</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">presenter/search+preview</configuration> <configuration key=\"target-tags\">engage</configuration> <configuration key=\"encoding-profile\">search-cover.http</configuration> <configuration key=\"time\">1</configuration> </configurations> </operation> Extract images at three relative positions ( 1%, 50%, 100% ) from the presenter/trimmed track. For each position, we use three different encoding profiles ( example.encoding.profile.* ). This operation therefore generates nine images in total. The target filenames will be formed based on the target-base-name-format-* configuration keys (prefix) and the configuration of the encoding profiles (file extension and possibly suffix). <operation id=\"image\" description=\"Extract set of thumbnails\"> <configurations> <configuration key=\"source-flavor\">presenter/trimmed</configuration> <configuration key=\"target-flavor\">presenter/thumbnails</configuration> <configuration key=\"target-base-name-format-second\">thumbnail_%.3f%s</configuration> <configuration key=\"target-base-name-format-percent\">thumbnail_%.0f%s</configuration> <configuration key=\"encoding-profile\"> example.encoding.profile.small, example.encoding.profile.medium, example.encoding.profile.large</configuration> <configuration key=\"time\">1%, 50%, 100%</configuration> <configuration key=\"end-margin\">1000</configuration> </configurations> </operation>","title":"Image"},{"location":"workflowoperationhandlers/image-woh/#image-workflow-operation","text":"ID: image","title":"Image Workflow Operation"},{"location":"workflowoperationhandlers/image-woh/#description","text":"The image operation will extract still images from a video using FFmpeg and a list of given encoding profiles. Both absolute and relative positions can be used.","title":"Description"},{"location":"workflowoperationhandlers/image-woh/#parameter-table","text":"configuration keys example description source-flavor presenter/source Specifies which media should be processed. source-flavors presenter/source, presentation/source Specifies a list of media which should be processed. In case a flavor has been specified in source-flavor , it will be added to this list. source-tags engage Specifies which media should be processed. target-flavor presenter/work Specifies the flavor the new files will get. target-tags engage Specifies the tags the new files will get. encoding-profile search-cover.http Comma-separated list of encoding profiles to use. time 1 or 5% Comma-separated list of times in seconds or as percentage of the source track duration where the images should be extracted target-base-name-format-second thumbnail_%.0f%s Used to control the target filenames for images extracted at absolute times. Mainly helpful when integrating third-party applications that prefer to use filename to distinguish individual images target-base-name-format-percent thumbnail_%.3f%s Used to control the target filenames for images extracted at relative times. Mainly helpful when integrating third-party applications that prefer to use filename to distinguish individual images end-margin 500 Safety margin at the end of the track. Sometimes, image extraction is critical at the end of the file. Using end-margin ensures, that no images are being extracted near the end of the video file to avoid problems with defective inputs. (Default: 100) Notes: Absolute and relative position may be mixed up in the configuration key time","title":"Parameter Table"},{"location":"workflowoperationhandlers/image-woh/#operation-example","text":"Extract one image at position 1 second using the encoding profile search-cover.http . <operation id=\"image\" description=\"Encoding presenter preview image\"> <configurations> <configuration key=\"source-flavor\">presenter/trimmed</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">presenter/search+preview</configuration> <configuration key=\"target-tags\">engage</configuration> <configuration key=\"encoding-profile\">search-cover.http</configuration> <configuration key=\"time\">1</configuration> </configurations> </operation> Extract images at three relative positions ( 1%, 50%, 100% ) from the presenter/trimmed track. For each position, we use three different encoding profiles ( example.encoding.profile.* ). This operation therefore generates nine images in total. The target filenames will be formed based on the target-base-name-format-* configuration keys (prefix) and the configuration of the encoding profiles (file extension and possibly suffix). <operation id=\"image\" description=\"Extract set of thumbnails\"> <configurations> <configuration key=\"source-flavor\">presenter/trimmed</configuration> <configuration key=\"target-flavor\">presenter/thumbnails</configuration> <configuration key=\"target-base-name-format-second\">thumbnail_%.3f%s</configuration> <configuration key=\"target-base-name-format-percent\">thumbnail_%.0f%s</configuration> <configuration key=\"encoding-profile\"> example.encoding.profile.small, example.encoding.profile.medium, example.encoding.profile.large</configuration> <configuration key=\"time\">1%, 50%, 100%</configuration> <configuration key=\"end-margin\">1000</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/imagetovideo-woh/","text":"ImageToVideo Workflow Operation Handler Description The ImageToVideo Workflow Operation Handler allows to create a video track from a source image. Parameters table Tags and flavors can be used in combination. But combined they should match one image. configuration keys example description default value source-tags * intro A comma separated list of tags of the input image EMPTY source-flavor * intro/source The \"flavor\" of the image to use as a source input EMPTY target-tags composite,rss,atom,archive The tags to apply to the output video track EMPTY target-flavor intro/work The flavor to apply to the output video track EMPTY duration * 5 The length of the output video in seconds. EMPTY profile * image-movie Define the encoding-profile to use to create the output video. See example of profile below. EMPTY * mandatory Operation example <operation id=\"image-to-video\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Composite\"> <configurations> <configuration key=\"source-tags\">intro</configuration> <configuration key=\"source-flavor\">intro/source</configuration> <configuration key=\"target-tags\">intro-video</configuration> <configuration key=\"target-flavor\">intro/video</configuration> <configuration key=\"duration\">10</configuration> <configuration key=\"profile\">image-movie</configuration> </configurations> </operation> Encoding profile example # Image to video profile.image-movie.name = image to video profile.image-movie.input = image profile.image-movie.output = visual profile.image-movie.suffix = -image-video.mp4 profile.image-movie.ffmpeg.command = -loop 1 -i #{in.video.path} -c:v libx264 -r 25 -t #{time} -pix_fmt yuv420p #{out.dir}/#{out.name}#{out.suffix}","title":"Image to Video"},{"location":"workflowoperationhandlers/imagetovideo-woh/#imagetovideo-workflow-operation-handler","text":"","title":"ImageToVideo Workflow Operation Handler"},{"location":"workflowoperationhandlers/imagetovideo-woh/#description","text":"The ImageToVideo Workflow Operation Handler allows to create a video track from a source image.","title":"Description"},{"location":"workflowoperationhandlers/imagetovideo-woh/#parameters-table","text":"Tags and flavors can be used in combination. But combined they should match one image. configuration keys example description default value source-tags * intro A comma separated list of tags of the input image EMPTY source-flavor * intro/source The \"flavor\" of the image to use as a source input EMPTY target-tags composite,rss,atom,archive The tags to apply to the output video track EMPTY target-flavor intro/work The flavor to apply to the output video track EMPTY duration * 5 The length of the output video in seconds. EMPTY profile * image-movie Define the encoding-profile to use to create the output video. See example of profile below. EMPTY * mandatory","title":"Parameters table"},{"location":"workflowoperationhandlers/imagetovideo-woh/#operation-example","text":"<operation id=\"image-to-video\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Composite\"> <configurations> <configuration key=\"source-tags\">intro</configuration> <configuration key=\"source-flavor\">intro/source</configuration> <configuration key=\"target-tags\">intro-video</configuration> <configuration key=\"target-flavor\">intro/video</configuration> <configuration key=\"duration\">10</configuration> <configuration key=\"profile\">image-movie</configuration> </configurations> </operation>","title":"Operation example"},{"location":"workflowoperationhandlers/imagetovideo-woh/#encoding-profile-example","text":"# Image to video profile.image-movie.name = image to video profile.image-movie.input = image profile.image-movie.output = visual profile.image-movie.suffix = -image-video.mp4 profile.image-movie.ffmpeg.command = -loop 1 -i #{in.video.path} -c:v libx264 -r 25 -t #{time} -pix_fmt yuv420p #{out.dir}/#{out.name}#{out.suffix}","title":"Encoding profile example"},{"location":"workflowoperationhandlers/import-wf-properties-woh/","text":"ImportWfPropertiesWorkflowOperationHandler Description The ImportWfPropertiesWorkflowOperationHandler loads workflow properties from a Java properties file and sets the corresponding workflow instance variables so that the properties can be use to control workflow execution. In case that no properties are found in source-flavor , the workflow operation will just skip. Note that the ExportWfPropertiesWorkflowOperationHandler can be used to export workflow properties to a Java properties file. Parameter Table Configuration Key Example Description source-flavor* processing/defaults Flavor of the attachment that contains the serialized workflow instance properties keys variableName1, variableName2 The workflow property keys to retrieve (comma separated list). If the option has not been specified, all keys will be retrieved * mandatory configuration key Operation Example <operation id=\"import-wf-properties\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Load processing settings\"> <configurations> <configuration key=\"source-flavor\">processing/defaults</configuration> </configurations> </operation>","title":"Import Workflow Properties"},{"location":"workflowoperationhandlers/import-wf-properties-woh/#importwfpropertiesworkflowoperationhandler","text":"","title":"ImportWfPropertiesWorkflowOperationHandler"},{"location":"workflowoperationhandlers/import-wf-properties-woh/#description","text":"The ImportWfPropertiesWorkflowOperationHandler loads workflow properties from a Java properties file and sets the corresponding workflow instance variables so that the properties can be use to control workflow execution. In case that no properties are found in source-flavor , the workflow operation will just skip. Note that the ExportWfPropertiesWorkflowOperationHandler can be used to export workflow properties to a Java properties file.","title":"Description"},{"location":"workflowoperationhandlers/import-wf-properties-woh/#parameter-table","text":"Configuration Key Example Description source-flavor* processing/defaults Flavor of the attachment that contains the serialized workflow instance properties keys variableName1, variableName2 The workflow property keys to retrieve (comma separated list). If the option has not been specified, all keys will be retrieved * mandatory configuration key","title":"Parameter Table"},{"location":"workflowoperationhandlers/import-wf-properties-woh/#operation-example","text":"<operation id=\"import-wf-properties\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Load processing settings\"> <configurations> <configuration key=\"source-flavor\">processing/defaults</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/incident-woh/","text":"IncidentCreatorWorkflowOperationHandler Description The IncidentCreatorWorkflowOperationHandler creates an incident on a dummy job used for integration testing. Parameter Table configuration keys example description default value code 2 The code number of the incident to produce. 1 severity WARNING The severity. See Incident.Severity enum. INFO details \"tagged,+rss\" / \"-rss,+tagged\" Some details: title=content;title=content;... EMPTY params \"presentation/tagged\" Some params: key=value;key=value;... EMPTY Operation Example <operation id=\"incident\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Provoke a job incident\"> <configurations> <configuration key=\"code\">3</configuration> <configuration key=\"severity\">INFO</configuration> <configuration key=\"details\">exception=content;id=325</configuration> <configuration key=\"params\">track=track-1;profile=full</configuration> </configurations> </operation>","title":"Incident"},{"location":"workflowoperationhandlers/incident-woh/#incidentcreatorworkflowoperationhandler","text":"","title":"IncidentCreatorWorkflowOperationHandler"},{"location":"workflowoperationhandlers/incident-woh/#description","text":"The IncidentCreatorWorkflowOperationHandler creates an incident on a dummy job used for integration testing.","title":"Description"},{"location":"workflowoperationhandlers/incident-woh/#parameter-table","text":"configuration keys example description default value code 2 The code number of the incident to produce. 1 severity WARNING The severity. See Incident.Severity enum. INFO details \"tagged,+rss\" / \"-rss,+tagged\" Some details: title=content;title=content;... EMPTY params \"presentation/tagged\" Some params: key=value;key=value;... EMPTY","title":"Parameter Table"},{"location":"workflowoperationhandlers/incident-woh/#operation-example","text":"<operation id=\"incident\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Provoke a job incident\"> <configurations> <configuration key=\"code\">3</configuration> <configuration key=\"severity\">INFO</configuration> <configuration key=\"details\">exception=content;id=325</configuration> <configuration key=\"params\">track=track-1;profile=full</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/include-woh/","text":"Include Workflow Operation Id: include Description The Include operation can be used to add a workflow definition to the current workflow. This enables re-usable sequences of operations to be factored out and allows better structuring of complex workflows. Parameter Table Configuration Key Example Description workflow-id partial-cleanup The workflow definition id of the workflow to be included Operation Example <operation id=\"include\" description=\"Remove temporary processing artifacts\"> <configurations> <configuration key=\"workflow-id\">partial-cleanup</configuration> </configurations> </operation>","title":"Include"},{"location":"workflowoperationhandlers/include-woh/#include-workflow-operation","text":"Id: include","title":"Include Workflow Operation"},{"location":"workflowoperationhandlers/include-woh/#description","text":"The Include operation can be used to add a workflow definition to the current workflow. This enables re-usable sequences of operations to be factored out and allows better structuring of complex workflows.","title":"Description"},{"location":"workflowoperationhandlers/include-woh/#parameter-table","text":"Configuration Key Example Description workflow-id partial-cleanup The workflow definition id of the workflow to be included","title":"Parameter Table"},{"location":"workflowoperationhandlers/include-woh/#operation-example","text":"<operation id=\"include\" description=\"Remove temporary processing artifacts\"> <configurations> <configuration key=\"workflow-id\">partial-cleanup</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/ingestdownload-woh/","text":"IngestDownloadWorkflowOperationHandler Description With the IngestDownloadWorkflowOperationHandler it's possible to initially download external URI's from mediapackage elements and store them to the working file repository. The external element URI's are then rewritten to the stored working file repository URI. In case of having external element URI's showing to a different Opencast working file repository, it's also possible to delete them after downloading it by activating the \"delete-external\" option. Additionally the \"source-flavors\" and \"source-tags\" option can be used to specifiy exactly, which external URI's should be downloaded. This operation is originally implemented to get rid of remaining files on ingest working file repositories. Parameter Table configuration keys example description default value delete-external \"true\" Whether to try to delete external working file repository URIs. FALSE source-flavors \"dublincore/episode\" List of flavors (seperated by comma), elements matching a flavor will be downloaded \"*/*\" source-tags \"archive\" List of tags (seperated by comma), elements matching a tag will be downloaded \"\" (empty list) tags-and-flavors \"true\" Whether both, a tag and a flavor, must match or if one is sufficient FALSE Operation Example <operation id=\"ingest-download\" fail-on-error=\"false\" description=\"Downloads external artifacts to the working file repository\"> <configurations> <configuration key=\"delete-external\">true</configuration> <configuration key=\"source-flavors\">dublincore/episode</configuration> <configuration key=\"source-tags\">archive</configuration> <configuration key=\"tags-and-flavors\">true</configuration> </configurations> </operation>","title":"Ingest-Download"},{"location":"workflowoperationhandlers/ingestdownload-woh/#ingestdownloadworkflowoperationhandler","text":"","title":"IngestDownloadWorkflowOperationHandler"},{"location":"workflowoperationhandlers/ingestdownload-woh/#description","text":"With the IngestDownloadWorkflowOperationHandler it's possible to initially download external URI's from mediapackage elements and store them to the working file repository. The external element URI's are then rewritten to the stored working file repository URI. In case of having external element URI's showing to a different Opencast working file repository, it's also possible to delete them after downloading it by activating the \"delete-external\" option. Additionally the \"source-flavors\" and \"source-tags\" option can be used to specifiy exactly, which external URI's should be downloaded. This operation is originally implemented to get rid of remaining files on ingest working file repositories.","title":"Description"},{"location":"workflowoperationhandlers/ingestdownload-woh/#parameter-table","text":"configuration keys example description default value delete-external \"true\" Whether to try to delete external working file repository URIs. FALSE source-flavors \"dublincore/episode\" List of flavors (seperated by comma), elements matching a flavor will be downloaded \"*/*\" source-tags \"archive\" List of tags (seperated by comma), elements matching a tag will be downloaded \"\" (empty list) tags-and-flavors \"true\" Whether both, a tag and a flavor, must match or if one is sufficient FALSE","title":"Parameter Table"},{"location":"workflowoperationhandlers/ingestdownload-woh/#operation-example","text":"<operation id=\"ingest-download\" fail-on-error=\"false\" description=\"Downloads external artifacts to the working file repository\"> <configurations> <configuration key=\"delete-external\">true</configuration> <configuration key=\"source-flavors\">dublincore/episode</configuration> <configuration key=\"source-tags\">archive</configuration> <configuration key=\"tags-and-flavors\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/inspect-woh/","text":"InspectWorkflowOperation Description The InspectWorkflowOperation is used to inspect all tracks of a media package. It tries to verify if they are valid media tracks. The InspectWorkflowOperation will also set the duration and creation date of the dublincore/episode catalog (if available) to the media package duration and media package creation date. Parameter Table Configuration Key Type Description Default accept-no-media Boolean Whether mediapackages with no media tracks should be accepted false accurate-frame-count Booelan Whether the media inspection service should determine the exact frame count false overwrite Boolean Whether to rewrite existing metadata false Accept No Media If the configuration key accept-no-media is set to false , the operation will fail if the media package does not contain any media tracks. If this behaviour is not appropriate, set accept-no-media to true . Accurate Frame Count The media inspection service will provide the number of frames in case of video streams. Normally, this information is extracted from the media file header. In case of incorrect media file headers, this information might not be accurate. Using the configuration key accurate-frame-count , the media inspection service can be forced to perform a full decoding of the video stream. While this does result in an exact count of frames, this is expensive in terms of computation power. Overwrite The inspection service will try to fill empty metadata fields. It will not overwrite any existing values except when you specify the option overwrite as true . Operation Example <operation id=\"inspect\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspecting mediapackage track elements\"> <configurations> <configuration key=\"overwrite\">false</configuration> <configuration key=\"accept-no-media\">false</configuration> <configuration key=\"accurate-frame-count\">false</configuration> </configurations> </operation>","title":"Inspect"},{"location":"workflowoperationhandlers/inspect-woh/#inspectworkflowoperation","text":"","title":"InspectWorkflowOperation"},{"location":"workflowoperationhandlers/inspect-woh/#description","text":"The InspectWorkflowOperation is used to inspect all tracks of a media package. It tries to verify if they are valid media tracks. The InspectWorkflowOperation will also set the duration and creation date of the dublincore/episode catalog (if available) to the media package duration and media package creation date.","title":"Description"},{"location":"workflowoperationhandlers/inspect-woh/#parameter-table","text":"Configuration Key Type Description Default accept-no-media Boolean Whether mediapackages with no media tracks should be accepted false accurate-frame-count Booelan Whether the media inspection service should determine the exact frame count false overwrite Boolean Whether to rewrite existing metadata false","title":"Parameter Table"},{"location":"workflowoperationhandlers/inspect-woh/#accept-no-media","text":"If the configuration key accept-no-media is set to false , the operation will fail if the media package does not contain any media tracks. If this behaviour is not appropriate, set accept-no-media to true .","title":"Accept No Media"},{"location":"workflowoperationhandlers/inspect-woh/#accurate-frame-count","text":"The media inspection service will provide the number of frames in case of video streams. Normally, this information is extracted from the media file header. In case of incorrect media file headers, this information might not be accurate. Using the configuration key accurate-frame-count , the media inspection service can be forced to perform a full decoding of the video stream. While this does result in an exact count of frames, this is expensive in terms of computation power.","title":"Accurate Frame Count"},{"location":"workflowoperationhandlers/inspect-woh/#overwrite","text":"The inspection service will try to fill empty metadata fields. It will not overwrite any existing values except when you specify the option overwrite as true .","title":"Overwrite"},{"location":"workflowoperationhandlers/inspect-woh/#operation-example","text":"<operation id=\"inspect\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Inspecting mediapackage track elements\"> <configurations> <configuration key=\"overwrite\">false</configuration> <configuration key=\"accept-no-media\">false</configuration> <configuration key=\"accurate-frame-count\">false</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/log-woh/","text":"LoggingWorkflowOperationHandler Description The LoggingWorkflowOperationHandler is primarily meant for testing and debugging purposes. It allows to log the current state of of a workflow and/or its media package. Name Default Description directory If set, write the logs to this directory workflowinstance-xml false Log the current state of the workflow as XML mediapackage-xml false Log the state of the current workflow's media package as XML mediapackage-json true Log the state of the current workflow's media package as JSON Setting any output configuration ( *-xml and *-json options) will overwrite all defaults and only the formats explicitly enabled will be logged. Operation Example <operation id=\"log\" description=\"Log to system logger\"> </operation> <operation id=\"log\" description=\"Log to file\"> <configurations> <configuration key=\"directory\">/tmp/logtest</configuration> </configurations> </operation>","title":"Log"},{"location":"workflowoperationhandlers/log-woh/#loggingworkflowoperationhandler","text":"","title":"LoggingWorkflowOperationHandler"},{"location":"workflowoperationhandlers/log-woh/#description","text":"The LoggingWorkflowOperationHandler is primarily meant for testing and debugging purposes. It allows to log the current state of of a workflow and/or its media package. Name Default Description directory If set, write the logs to this directory workflowinstance-xml false Log the current state of the workflow as XML mediapackage-xml false Log the state of the current workflow's media package as XML mediapackage-json true Log the state of the current workflow's media package as JSON Setting any output configuration ( *-xml and *-json options) will overwrite all defaults and only the formats explicitly enabled will be logged.","title":"Description"},{"location":"workflowoperationhandlers/log-woh/#operation-example","text":"<operation id=\"log\" description=\"Log to system logger\"> </operation> <operation id=\"log\" description=\"Log to file\"> <configurations> <configuration key=\"directory\">/tmp/logtest</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/move-storage-woh/","text":"MoveStorageOperationHandler Description The MoveStorageOperationHandler can be used to move files in the Asset Manager from one storage system to another. Parameter Table Configuration Key Example Description target-storage* local-storage The ID of the storage to move the files to target-version 0 The (optional) snapshot version to move * mandatory configuration key Notes: Omitting target-version will move all current versions of the mediapackage to target-storage . An example usecase would be moving the raw input media to a cold(er) storage system after initial processing. Operation Example <operation id=\"move-storage\" description=\"Offloading to AWS S3\"> <configurations> <configuration key=\"target-storage\">aws-s3</configuration> </configurations> </operation>","title":"Move Storage"},{"location":"workflowoperationhandlers/move-storage-woh/#movestorageoperationhandler","text":"","title":"MoveStorageOperationHandler"},{"location":"workflowoperationhandlers/move-storage-woh/#description","text":"The MoveStorageOperationHandler can be used to move files in the Asset Manager from one storage system to another.","title":"Description"},{"location":"workflowoperationhandlers/move-storage-woh/#parameter-table","text":"Configuration Key Example Description target-storage* local-storage The ID of the storage to move the files to target-version 0 The (optional) snapshot version to move * mandatory configuration key Notes: Omitting target-version will move all current versions of the mediapackage to target-storage . An example usecase would be moving the raw input media to a cold(er) storage system after initial processing.","title":"Parameter Table"},{"location":"workflowoperationhandlers/move-storage-woh/#operation-example","text":"<operation id=\"move-storage\" description=\"Offloading to AWS S3\"> <configurations> <configuration key=\"target-storage\">aws-s3</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/multiencode-woh/","text":"MultiencodeWorkflowHandler Description The MultiencodeWorkflowHandler is used to encode source media into multiple formats concurrently. The source recording are selected by source-flavors AND source-tags. Each source media selector (eg presenter or presentation) can have an independent set of encoding profile ids (one for each target medium) and target tags. Encoding of each source medium runs as one ffmpeg command. This operation will generate one multiencode operation per source medium, all of them running concurrently on the same or on different workers. In addition, the target media can be optionally tagged with the encoding profile ids. Configuration details This workflow handles each source selector independently as a section. The parameters for each configuration, such as flavors are separated positionally into sections by \" ; \". The use of the semi-colon is optional. If it is absent, there is only one section. <configuration key=\"source-flavors\">*/source</configuration> One source selector means that all the matching recording will be processed the same way. <configuration key=\"source-flavors\">presenter/source;presentation/source</configuration> Two different source selectors means that all the matching recordings in the first selector will be processed according to the parameters in the first section and the all the matching recordings in the second selector will be processed according to the parameters in next section. Each source selector can have only one corresponding section. If there is only one section in one parameter, eg: target-flavors, but multiple sections in another, eg: source-flavors, then the sections are collapsed into one. For example: <configuration key=\"target-flavors\">*/preview</configuration> All targets are flavored the same way, using the example above, becomes \"presenter/preview\" and \"presentation/preview\" Each source selector can have its own set of target tags and flavors, defined as a comma delimited list. For example: <configuration key=\"target-tags\">engage-streaming,rss,atom;engage-download,rss,atom</configuration> Using the example above. \"presenter/preview\" is tagged with \"engage-streaming,rss,atom\". \"presentation/preview\" is tagged with \"engage-download,rss,atom\". When a configuration has the same number of sections as the source, then the configurations for the operation are taken from the corresponding sections. Each section runs independently as a parallel encoding job. For example, if presenter/source is to encoded with \"mp4-low.http,mp4-medium.http\" and presentation/source is to be encoded with \"mp4-hd.http,mp4-hd.http\" The target flavors are presenter/delivery and presentation/delivery and all are tagged \"rss, archive\". The target flavors are additionally tagged with encoding profiles, so that they can selected individually. Parameter Table configuration keys example description source-flavors presenter/source ; presentation/source Which media should be encoded target-flavors */preview Specifies the flavor of the new media target-tags rss,archive Specifies the tags of the new media encoding-profiles mp4-low.http,mp4-medium.http ; mp4-hd.http,mp4-hd.http Encoding profiles for each source flavor tag-with-profile true target media are tagged with coresponding encoding profile Id (false if omitted) Operation Example <operation id=\"multiencode\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encoding media to delivery formats\"> <configurations> <configuration key=\"source-flavors\">presenter/work;presentation/work</configuration> <configuration key=\"target-flavors\">*/delivery</configuration> <configuration key=\"target-tags\">rss,archive</configuration> <configuration key=\"encoding-profiles\">mp4-low.http;mp4-hd.http</configuration> <configuration key=\"tag-with-profile\">true</configuration> </configurations> </operation> Note: (Important) Each source flavor generates all the target formats in one ffmpeg call by incorporating relevant parts of the encoding profile commands. Care must be taken that no ffmpeg complex filters are used in the encoding profiles used for this workflow, as it can cause a conflict. Encoded target media are distinguished by the suffix, it is important that all the encoding profiles used have distinct suffixes to use \"tag-with-profile\" configuration, for example: profile.mp4-vga-medium.http.suffix = -vga-medium.mp4 profile.mp4-medium.http.suffix = -medium.mp4","title":"Multiencode"},{"location":"workflowoperationhandlers/multiencode-woh/#multiencodeworkflowhandler","text":"","title":"MultiencodeWorkflowHandler"},{"location":"workflowoperationhandlers/multiencode-woh/#description","text":"The MultiencodeWorkflowHandler is used to encode source media into multiple formats concurrently. The source recording are selected by source-flavors AND source-tags. Each source media selector (eg presenter or presentation) can have an independent set of encoding profile ids (one for each target medium) and target tags. Encoding of each source medium runs as one ffmpeg command. This operation will generate one multiencode operation per source medium, all of them running concurrently on the same or on different workers. In addition, the target media can be optionally tagged with the encoding profile ids.","title":"Description"},{"location":"workflowoperationhandlers/multiencode-woh/#configuration-details","text":"This workflow handles each source selector independently as a section. The parameters for each configuration, such as flavors are separated positionally into sections by \" ; \". The use of the semi-colon is optional. If it is absent, there is only one section. <configuration key=\"source-flavors\">*/source</configuration> One source selector means that all the matching recording will be processed the same way. <configuration key=\"source-flavors\">presenter/source;presentation/source</configuration> Two different source selectors means that all the matching recordings in the first selector will be processed according to the parameters in the first section and the all the matching recordings in the second selector will be processed according to the parameters in next section. Each source selector can have only one corresponding section. If there is only one section in one parameter, eg: target-flavors, but multiple sections in another, eg: source-flavors, then the sections are collapsed into one. For example: <configuration key=\"target-flavors\">*/preview</configuration> All targets are flavored the same way, using the example above, becomes \"presenter/preview\" and \"presentation/preview\" Each source selector can have its own set of target tags and flavors, defined as a comma delimited list. For example: <configuration key=\"target-tags\">engage-streaming,rss,atom;engage-download,rss,atom</configuration> Using the example above. \"presenter/preview\" is tagged with \"engage-streaming,rss,atom\". \"presentation/preview\" is tagged with \"engage-download,rss,atom\". When a configuration has the same number of sections as the source, then the configurations for the operation are taken from the corresponding sections. Each section runs independently as a parallel encoding job. For example, if presenter/source is to encoded with \"mp4-low.http,mp4-medium.http\" and presentation/source is to be encoded with \"mp4-hd.http,mp4-hd.http\" The target flavors are presenter/delivery and presentation/delivery and all are tagged \"rss, archive\". The target flavors are additionally tagged with encoding profiles, so that they can selected individually.","title":"Configuration details"},{"location":"workflowoperationhandlers/multiencode-woh/#parameter-table","text":"configuration keys example description source-flavors presenter/source ; presentation/source Which media should be encoded target-flavors */preview Specifies the flavor of the new media target-tags rss,archive Specifies the tags of the new media encoding-profiles mp4-low.http,mp4-medium.http ; mp4-hd.http,mp4-hd.http Encoding profiles for each source flavor tag-with-profile true target media are tagged with coresponding encoding profile Id (false if omitted)","title":"Parameter Table"},{"location":"workflowoperationhandlers/multiencode-woh/#operation-example","text":"<operation id=\"multiencode\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encoding media to delivery formats\"> <configurations> <configuration key=\"source-flavors\">presenter/work;presentation/work</configuration> <configuration key=\"target-flavors\">*/delivery</configuration> <configuration key=\"target-tags\">rss,archive</configuration> <configuration key=\"encoding-profiles\">mp4-low.http;mp4-hd.http</configuration> <configuration key=\"tag-with-profile\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/multiencode-woh/#note-important","text":"Each source flavor generates all the target formats in one ffmpeg call by incorporating relevant parts of the encoding profile commands. Care must be taken that no ffmpeg complex filters are used in the encoding profiles used for this workflow, as it can cause a conflict. Encoded target media are distinguished by the suffix, it is important that all the encoding profiles used have distinct suffixes to use \"tag-with-profile\" configuration, for example: profile.mp4-vga-medium.http.suffix = -vga-medium.mp4 profile.mp4-medium.http.suffix = -medium.mp4","title":"Note: (Important)"},{"location":"workflowoperationhandlers/normalizeaudio-woh/","text":"Audio Normalization Operation Description This operation normalizes the first audio stream of a video or audio track through SoX , it creates a new track with a reference to the original track which can be flavored and tagged. It can be used with audio and/or video files, at least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs: Used with Audio only file (forceTranscode is deactivated): Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation. Run audio normalization with original audio file. Replace the normalized audio file with the original. Write analyzed audio metadata to the track's mediapackage. Delete all used temporary files. Used with Audio only file and forceTranscode activated: Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation. (forceTranscode step) Encode audio to FLAC. (Must be used when given audio file format is not supported by SoX) Run audio normalization with original audio file or encoded FLAC audio file. (forceTranscode step) Mux normalized audio file back to the original audio container by replacing it with the original audio stream. Write analyzed audio metadata to the track's mediapackage. Delete all used temporary files Used with Video file: Extract audio file encoded as FLAC audio and save it temporary in a collection Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation. Run audio normalization with extracted audio file. Mux normalized audio file back to the original video container by replacing it with original audio stream. Write analyzed audio metadata to the track's mediapackage. Delete all used temporary files Example result track: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?> <track ref=\"track:track-2\" type=\"presenter/normalized\" id=\"70626874-17d2-480d-9d30-c10f0824961c\"> <mimetype>audio/x-flv</mimetype> <tags> <tag>norm</tag> </tags> <url>http://localhost:8080/files/mediapackage/8a510168-9102-425f-81e9-0943774dd229/70626874-17d2-480d-9d30-c10f0824961c/demo_slide_video_6min_buss.flv</url> <checksum type=\"md5\">4e30d7d4305b0793f301816e796471db</checksum> <duration>414407</duration> <audio id=\"audio-1\"> <device/> <encoder type=\"MPEG Audio\"/> <bitdepth>16</bitdepth> <channels>2</channels> <bitrate>64000.0</bitrate> <peakleveldb>-4.03</peakleveldb> <!-- NEW --> <rmsleveldb>-30.54</rmsleveldb> <!-- NEW --> <rmspeakdb>-10.85</rmspeakdb> <!-- NEW --> </audio> </track> Parameter Table configuration keys example description default value source-flavors \"presentation/work,presenter/work\" The \"flavors\" of the track to use as a source input EMPTY source-flavor \"presentation/work\" The \"flavor\" of the track to use as a source input EMPTY source-tags \"engage,atom,rss\" The \"tag\" of the track to use as a source input EMPTY target-flavor \"presentation/normalized\" The flavor to apply to the normalized file EMPTY target-tags \"norm\" The tags to apply to the normalized file EMPTY target-decibel * -30.4 The target RMS Level Decibel EMPTY force-transcode \"true\" or \"false\" Whether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format) FALSE * required keys Operation Example <operation id=\"normalize-audio\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Normalize audio stream\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/normalized</configuration> <configuration key=\"target-tags\">norm</configuration> <configuration key=\"target-decibel\">-30</configuration> <configuration key=\"force-transcode\">true</configuration> </configurations> </operation>","title":"Normalize Audio"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#audio-normalization-operation","text":"","title":"Audio Normalization Operation"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#description","text":"This operation normalizes the first audio stream of a video or audio track through SoX , it creates a new track with a reference to the original track which can be flavored and tagged. It can be used with audio and/or video files, at least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs:","title":"Description"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#used-with-audio-only-file-forcetranscode-is-deactivated","text":"Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation. Run audio normalization with original audio file. Replace the normalized audio file with the original. Write analyzed audio metadata to the track's mediapackage. Delete all used temporary files.","title":"Used with Audio only file (forceTranscode is deactivated):"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#used-with-audio-only-file-and-forcetranscode-activated","text":"Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation. (forceTranscode step) Encode audio to FLAC. (Must be used when given audio file format is not supported by SoX) Run audio normalization with original audio file or encoded FLAC audio file. (forceTranscode step) Mux normalized audio file back to the original audio container by replacing it with the original audio stream. Write analyzed audio metadata to the track's mediapackage. Delete all used temporary files","title":"Used with Audio only file and forceTranscode activated:"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#used-with-video-file","text":"Extract audio file encoded as FLAC audio and save it temporary in a collection Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation. Run audio normalization with extracted audio file. Mux normalized audio file back to the original video container by replacing it with original audio stream. Write analyzed audio metadata to the track's mediapackage. Delete all used temporary files Example result track: <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?> <track ref=\"track:track-2\" type=\"presenter/normalized\" id=\"70626874-17d2-480d-9d30-c10f0824961c\"> <mimetype>audio/x-flv</mimetype> <tags> <tag>norm</tag> </tags> <url>http://localhost:8080/files/mediapackage/8a510168-9102-425f-81e9-0943774dd229/70626874-17d2-480d-9d30-c10f0824961c/demo_slide_video_6min_buss.flv</url> <checksum type=\"md5\">4e30d7d4305b0793f301816e796471db</checksum> <duration>414407</duration> <audio id=\"audio-1\"> <device/> <encoder type=\"MPEG Audio\"/> <bitdepth>16</bitdepth> <channels>2</channels> <bitrate>64000.0</bitrate> <peakleveldb>-4.03</peakleveldb> <!-- NEW --> <rmsleveldb>-30.54</rmsleveldb> <!-- NEW --> <rmspeakdb>-10.85</rmspeakdb> <!-- NEW --> </audio> </track>","title":"Used with Video file:"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#parameter-table","text":"configuration keys example description default value source-flavors \"presentation/work,presenter/work\" The \"flavors\" of the track to use as a source input EMPTY source-flavor \"presentation/work\" The \"flavor\" of the track to use as a source input EMPTY source-tags \"engage,atom,rss\" The \"tag\" of the track to use as a source input EMPTY target-flavor \"presentation/normalized\" The flavor to apply to the normalized file EMPTY target-tags \"norm\" The tags to apply to the normalized file EMPTY target-decibel * -30.4 The target RMS Level Decibel EMPTY force-transcode \"true\" or \"false\" Whether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format) FALSE * required keys","title":"Parameter Table"},{"location":"workflowoperationhandlers/normalizeaudio-woh/#operation-example","text":"<operation id=\"normalize-audio\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Normalize audio stream\"> <configurations> <configuration key=\"source-flavor\">*/work</configuration> <configuration key=\"target-flavor\">*/normalized</configuration> <configuration key=\"target-tags\">norm</configuration> <configuration key=\"target-decibel\">-30</configuration> <configuration key=\"force-transcode\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/notification/","text":"Mattermost Notification Description The MattermostNotificationOperationHander sends a notification to a channel of Mattermost or similar applications, like Slack, with the chosen parameters provided. It is useful to send such notifications when some operation(s) have been completed or some error has occurred in a workflow. The notification message can be freely chosen. You can use different parameters which will be replaced with the corresponding metadata of the current workflow instance (see List of parameters). List of configuration options configuration keys description default url URL of the mattermost webhook EMPTY message Message that will be send EMPTY method HTTP method that will be used post max-retry Value for the number of attempts for a request 5 timeout Maximum time to wait for client to excecute a request 10 * 1000 Example for mattermost-notify operation <operation id=\"mattermost-notify\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Notify Mattermost about error\"> <configurations> <configuration key=\"url\">insert-url-of-mattermost-webhook</configuration> <configuration key=\"message\">Error at Workflow %i (%t) State: %s</configuration> <configuration key=\"method\">post</configuration> <configuration key=\"max-retry\">3</configuration> <configuration key=\"timeout\">5</configuration> </configurations> </operation> List of parameters All parameters (% ) will be substituted with corresponding metadata of the current workflow instance. Parameter Metadata %t Title of workflow %i ID of workflow %s State of workflow %o ID of current workflow operation %I ID of Mediapackage %T Title of Mediapackage %C Creators of Mediapackage %c Contributors of Mediapackage %D Date of Mediapackage %d Duration of Mediapackage %L License of Mediapackage %l Language of Mediapackage %S Series-Title of Mediapackage","title":"Mattermost Notification Module"},{"location":"workflowoperationhandlers/notification/#mattermost-notification","text":"","title":"Mattermost Notification"},{"location":"workflowoperationhandlers/notification/#description","text":"The MattermostNotificationOperationHander sends a notification to a channel of Mattermost or similar applications, like Slack, with the chosen parameters provided. It is useful to send such notifications when some operation(s) have been completed or some error has occurred in a workflow. The notification message can be freely chosen. You can use different parameters which will be replaced with the corresponding metadata of the current workflow instance (see List of parameters).","title":"Description"},{"location":"workflowoperationhandlers/notification/#list-of-configuration-options","text":"configuration keys description default url URL of the mattermost webhook EMPTY message Message that will be send EMPTY method HTTP method that will be used post max-retry Value for the number of attempts for a request 5 timeout Maximum time to wait for client to excecute a request 10 * 1000","title":"List of configuration options"},{"location":"workflowoperationhandlers/notification/#example-for-mattermost-notify-operation","text":"<operation id=\"mattermost-notify\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Notify Mattermost about error\"> <configurations> <configuration key=\"url\">insert-url-of-mattermost-webhook</configuration> <configuration key=\"message\">Error at Workflow %i (%t) State: %s</configuration> <configuration key=\"method\">post</configuration> <configuration key=\"max-retry\">3</configuration> <configuration key=\"timeout\">5</configuration> </configurations> </operation>","title":"Example for mattermost-notify operation"},{"location":"workflowoperationhandlers/notification/#list-of-parameters","text":"All parameters (% ) will be substituted with corresponding metadata of the current workflow instance. Parameter Metadata %t Title of workflow %i ID of workflow %s State of workflow %o ID of current workflow operation %I ID of Mediapackage %T Title of Mediapackage %C Creators of Mediapackage %c Contributors of Mediapackage %D Date of Mediapackage %d Duration of Mediapackage %L License of Mediapackage %l Language of Mediapackage %S Series-Title of Mediapackage","title":"List of parameters"},{"location":"workflowoperationhandlers/partial-import-woh/","text":"PartialImportWorkflowOperation Description The PartialImportWorkflowOperation processes a set of audio and video files according to a SMIL document describing their relations. Its primary use is to post-process audio and video files ingested by capture agents using /ingest/addPartialTrack of the ingest endpoint. Prerequisite When using the PartialImportWorkflowOperation, it is recommended to perform a media inspection beforehand using the InspectWorkflowOperation with the option accurate-frame-count set to true . This ensures that the PartialImportWorkflowOperation works correctly in case of media files with incorrect framecount in their header. Note that the use of accurate-frame-count will force the InspectWorkflowOperation to decode the complete video stream which makes the operation more expensive in terms of load. Parameter Table configuration keys type description default value source-presenter-flavor MediaPackageElementFlavor The flavor of tracks for the presenter video source-presentation-flavor MediaPackageElementFlavor The flavor of tracks for the presentation video source-smil-flavor * MediaPackageElementFlavor The flavor of the SMIL file describing how to build the targets. When using /ingest/addPartialTrack, the ingest service will create the SMIL file and add it to the media package as flavor smil/source+partial target-presenter-flavor * MediaPackageElementFlavor The flavor to be used for the target presentation track. Both the type and subtype must not be * target-presentation-flavor * MediaPackageElementFlavor The flavor to be used for the target presentation track. Both the type nor subtype must not be * concat-encoding-profile * String Encoding profile used for concatenating audio or video files concat-output-framerate Float The optional output framerate for concatenated video files trim-encoding-profile * String Encoding profile using for trimming tracks force-encoding Boolean If set to true , all generated target files will be encoded using the encoding profile force-encoding-profile false force-encoding-profile * String Encoding profile to be used when force-encoding is set to true or a given target track has a file extension not included in required-extensions required-extensions String , { \",\" , String } Comma-separated list of file extension names (case insensitive). All generated target files whose file extensions are not in this list will be encoded using the encoding profile force-encoding-profile \"mp4\" enforce-divisible-by-two Boolean If set, all video targets will have widths and heights divisible by two. This might be necessary depending since some encoder fail when encountering uneven widths or heights. false * required keys Note that it is allowed to set the configuration keys 'target-presenter-flavor' and 'target-presentation-flavor' to the same value. Operation Example What exactly the PartialImportWorkflowOperation does is best described by example. In our example, a capture agent records three sources: Presenter camera (video only) Presenter microphone (audio only) Presentation (video only) While the capture agent internally triggers the recording for all sources at the same time, the actual recording of the individual sources might not necessarily start at the exact same time, e.g. due to latency of the recording devices. Also, while recording, a watch dog in our example capture agent recognizes that for whatever reason, the recording of the sources had stopped and restarted again several times - resulting in multiple audio and/or video files per source. Here is a graphics showing how this example could look like: So we have three tracks, but seven files: Presenter camera: 2 video-only files Presenter microphone: 2 audio-only files Presentation: 3 video-only files We call that individual fragments of a track partial tracks . Our example capture agent can now use the addPartialTrack ingest facility to specify for each of the ingested files, at which time the content fits into the overall recording. The ingest service will automatically create the SMIL file describing how the files relate to each other and add it to the media package as flavor smil/source+partial . In our example, this SMIL file would like something like: <?xml version=\"1.1\" encoding=\"UTF-8\"?> <smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\"> <head/> <body> <par dur=\"93861ms\"> <seq> <video begin=\"412ms\" dur=\"13440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <video begin=\"15324ms\" dur=\"73440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <audio begin=\"0ms\" dur=\"40861ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> <audio begin=\"43400ms\" dur=\"13861ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> </seq> <seq> <video begin=\"948ms\" dur=\"33440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> <video begin=\"35643ms\" dur=\"15430ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> <video begin=\"45448ms\" dur=\"25440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> </seq> </par> </body> </smil> What we finally want, however, is a single presenter and a single presentation track that can be processed by Opencast workflow operations. To achieve this, the PartialImportWorkflowOperation is used to post-process the files as described in the SMIL file: <operation id=\"partial-import\" description=\"Post-processing raw audio and video files from capture agent\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-presenter-flavor\">presenter/source</configuration> <configuration key=\"source-presentation-flavor\">presentation/source</configuration> <configuration key=\"source-smil-flavor\">smil/source+partial</configuration> <configuration key=\"target-presenter-flavor\">presenter/standard</configuration> <configuration key=\"target-presentation-flavor\">presentation/standard</configuration> <configuration key=\"concat-encoding-profile\">concat.work</configuration> <configuration key=\"trim-encoding-profile\">trim.work</configuration> <configuration key=\"force-encoding-profile\">editor.work</configuration> </configurations> </operation> In our example, the PartialImportWorkflowOperation will create the target flavors presenter/standard and presentation/standard as depicted below: The green parts have been filled in by the PartialImportWorkflowOperation by either silence (audio) or pictures (video). To achieve this, the PartialImportWorkflowOperation performs the following steps: Extend content at the beginning: If the first partial track of a given source and type (audio/video) does not begin at position zero, content is added in front of it so that the corresponding target track will start at position zero. For audio, silence is added. In case of video, the first frame of the first partial track is added. Filling the gaps: As you can see in our example, it is possible that content is missing within the actual tracks. Those gaps are filled by adding silence (in case of audio) or adding the last frame of the previous partial track (in case of video). In this step, content is also added at the end of the track in case its duration is less than the overall duration of the recording. Trim the tracks: It is possible that processing the ingested files according to the SMIL file would result in tracks that have a longer duration than the overall recording should. Therefore, all tracks are trimmed individually to the target duration. Mux audio tracks: To avoid the necessity to call further workflow operations just for audio muxing, the PartialImportWorkflowOperation can perform audio muxing itself. In our example, it would mux the audio and video track of the presenter into a single audio/video track. Ensure specific output formats: There may be situations where you want to ensure that the output of this operations comes with a specific file format, e.g. MP4 . The configuration keys force-encoding and required_extensions can be used to control the behavior of the PartialImportWorkflowOperation: In case the force-encoding is set to true , the target tracks will be re-encoded using the force-encoding-profile . The target tracks will also be re-encoded using that encoding profile in case its file extensions don't match the required_extensions . SMIL File Structure The PartialImportWorkflowOperation expects a specific subset of SMIL that is described in this section. The overall structure of the SMIL file is shown by example below: <?xml version=\"1.1\" encoding=\"UTF-8\"?> <smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\"> <head/> <body> <par dur=\"15000ms\"> <seq> <video begin=\"400ms\" dur=\"13000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <video begin=\"15000ms\" dur=\"70000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <audio begin=\"0ms\" dur=\"400ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> <audio begin=\"900ms\" dur=\"13000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> </seq> <seq> <video begin=\"900ms\" dur=\"30000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> </seq> </par> </body> </smil> The PartialImportWorkflowOperation can handle at most one par element that is used to describe to overall media duration using the attribute dur . The resulting tracks will be trimmed to this duration if necessary. In the example above, the overall media duration is set to 15 seconds. The par element has one or two sequence sub elements seq , each describing a track that is to be built from its sub elements - the partial tracks. Each sequence ( seq ) has at least one sub element. Sub elements can be either video elements, audio elements or both video and audio elements. Each of those sub elements requires the attributes begin (position of partial track in milliseconds relative to start of overall media) and dur (duration of partial track in milliseconds) The audio elements are used to indicate that the media file referred to is an audio-only media file, whereas video elements can refer to either video-only or audio-video media files. The following combinations result in a defined behavior: Supported Combinations of Video and Audio Elements video audio resulting track audio/video track n/a audio/video track video-only track n/a video-only track video-only track audio-only track audio/video track n/a audio-only track audio-only track All other combinations of video and audio elements result in unspecified behavior of the PartialImportWorkflowOperation. Order of Video and Audio Elements Within a sequence ( seq ), the video elements most occur in ascending order considering the values of their attributes begin . The same holds for audio elements. Note the video and audio elements are processed individually, so the order of occurrences of video and audio elements are independent from each other. Important: The PartialImportWorkflowOperation will not process video or audio elements correctly if the order of appearance in the SMIL file is not correct. Overlapping Partial Tracks The behavior of overlapping partial tracks is unspecified, i.e. for a given element e ( video or audio ), the value of begin for the subsequent element (e+1) of the same type ( video or audio ) within the same sequence must be equal or greater than e.begin + e.dur , i.e. make sure that the following invariant holds: (e+1).begin >= e.begin + e.dur Encoding Profiles The PartialImportWorkflowOperation uses a number of encoding profiles to perform its processing. Some of the encoding profiles can be explicitly configured by the user, others are used implicitly in means of being hard-coded and are not supposed to be changed by the user. Hard-coded Encoding Profiles encoding profile description import.preview Extract the first frame of a given partial track import.image-frame Extract the last frame of a given partial track. Note that this profile is used to extract the exactly last frame of a partial track - not just a frame close to the last one. To make this work for video files with headers that don't contain the exact frame count, set accurate_frame_count to true in etc/org.opencastproject.inspection.ffmpeg.MediaInspectionServiceImpl.cfg image-movie.work Generate video partial tracks based on extracted images used to fill video gaps import.silent Generate silent audio tracks used to fill audio gaps Configurable Encoding Profiles configuration key description concat-encoding-profile Used to concatenate partial tracks into tracks trim-encoding-profile Used to trim the resulting concatenated single tracks if necessary force-encoding-profile Used to re-encode target tracks in case the file extension of a given target track is not included in required-extensions or the configuration key force-encoding is set to true","title":"Partial Import"},{"location":"workflowoperationhandlers/partial-import-woh/#partialimportworkflowoperation","text":"","title":"PartialImportWorkflowOperation"},{"location":"workflowoperationhandlers/partial-import-woh/#description","text":"The PartialImportWorkflowOperation processes a set of audio and video files according to a SMIL document describing their relations. Its primary use is to post-process audio and video files ingested by capture agents using /ingest/addPartialTrack of the ingest endpoint.","title":"Description"},{"location":"workflowoperationhandlers/partial-import-woh/#prerequisite","text":"When using the PartialImportWorkflowOperation, it is recommended to perform a media inspection beforehand using the InspectWorkflowOperation with the option accurate-frame-count set to true . This ensures that the PartialImportWorkflowOperation works correctly in case of media files with incorrect framecount in their header. Note that the use of accurate-frame-count will force the InspectWorkflowOperation to decode the complete video stream which makes the operation more expensive in terms of load.","title":"Prerequisite"},{"location":"workflowoperationhandlers/partial-import-woh/#parameter-table","text":"configuration keys type description default value source-presenter-flavor MediaPackageElementFlavor The flavor of tracks for the presenter video source-presentation-flavor MediaPackageElementFlavor The flavor of tracks for the presentation video source-smil-flavor * MediaPackageElementFlavor The flavor of the SMIL file describing how to build the targets. When using /ingest/addPartialTrack, the ingest service will create the SMIL file and add it to the media package as flavor smil/source+partial target-presenter-flavor * MediaPackageElementFlavor The flavor to be used for the target presentation track. Both the type and subtype must not be * target-presentation-flavor * MediaPackageElementFlavor The flavor to be used for the target presentation track. Both the type nor subtype must not be * concat-encoding-profile * String Encoding profile used for concatenating audio or video files concat-output-framerate Float The optional output framerate for concatenated video files trim-encoding-profile * String Encoding profile using for trimming tracks force-encoding Boolean If set to true , all generated target files will be encoded using the encoding profile force-encoding-profile false force-encoding-profile * String Encoding profile to be used when force-encoding is set to true or a given target track has a file extension not included in required-extensions required-extensions String , { \",\" , String } Comma-separated list of file extension names (case insensitive). All generated target files whose file extensions are not in this list will be encoded using the encoding profile force-encoding-profile \"mp4\" enforce-divisible-by-two Boolean If set, all video targets will have widths and heights divisible by two. This might be necessary depending since some encoder fail when encountering uneven widths or heights. false * required keys Note that it is allowed to set the configuration keys 'target-presenter-flavor' and 'target-presentation-flavor' to the same value.","title":"Parameter Table"},{"location":"workflowoperationhandlers/partial-import-woh/#operation-example","text":"What exactly the PartialImportWorkflowOperation does is best described by example. In our example, a capture agent records three sources: Presenter camera (video only) Presenter microphone (audio only) Presentation (video only) While the capture agent internally triggers the recording for all sources at the same time, the actual recording of the individual sources might not necessarily start at the exact same time, e.g. due to latency of the recording devices. Also, while recording, a watch dog in our example capture agent recognizes that for whatever reason, the recording of the sources had stopped and restarted again several times - resulting in multiple audio and/or video files per source. Here is a graphics showing how this example could look like: So we have three tracks, but seven files: Presenter camera: 2 video-only files Presenter microphone: 2 audio-only files Presentation: 3 video-only files We call that individual fragments of a track partial tracks . Our example capture agent can now use the addPartialTrack ingest facility to specify for each of the ingested files, at which time the content fits into the overall recording. The ingest service will automatically create the SMIL file describing how the files relate to each other and add it to the media package as flavor smil/source+partial . In our example, this SMIL file would like something like: <?xml version=\"1.1\" encoding=\"UTF-8\"?> <smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\"> <head/> <body> <par dur=\"93861ms\"> <seq> <video begin=\"412ms\" dur=\"13440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <video begin=\"15324ms\" dur=\"73440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <audio begin=\"0ms\" dur=\"40861ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> <audio begin=\"43400ms\" dur=\"13861ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> </seq> <seq> <video begin=\"948ms\" dur=\"33440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> <video begin=\"35643ms\" dur=\"15430ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> <video begin=\"45448ms\" dur=\"25440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> </seq> </par> </body> </smil> What we finally want, however, is a single presenter and a single presentation track that can be processed by Opencast workflow operations. To achieve this, the PartialImportWorkflowOperation is used to post-process the files as described in the SMIL file: <operation id=\"partial-import\" description=\"Post-processing raw audio and video files from capture agent\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\"> <configurations> <configuration key=\"source-presenter-flavor\">presenter/source</configuration> <configuration key=\"source-presentation-flavor\">presentation/source</configuration> <configuration key=\"source-smil-flavor\">smil/source+partial</configuration> <configuration key=\"target-presenter-flavor\">presenter/standard</configuration> <configuration key=\"target-presentation-flavor\">presentation/standard</configuration> <configuration key=\"concat-encoding-profile\">concat.work</configuration> <configuration key=\"trim-encoding-profile\">trim.work</configuration> <configuration key=\"force-encoding-profile\">editor.work</configuration> </configurations> </operation> In our example, the PartialImportWorkflowOperation will create the target flavors presenter/standard and presentation/standard as depicted below: The green parts have been filled in by the PartialImportWorkflowOperation by either silence (audio) or pictures (video). To achieve this, the PartialImportWorkflowOperation performs the following steps: Extend content at the beginning: If the first partial track of a given source and type (audio/video) does not begin at position zero, content is added in front of it so that the corresponding target track will start at position zero. For audio, silence is added. In case of video, the first frame of the first partial track is added. Filling the gaps: As you can see in our example, it is possible that content is missing within the actual tracks. Those gaps are filled by adding silence (in case of audio) or adding the last frame of the previous partial track (in case of video). In this step, content is also added at the end of the track in case its duration is less than the overall duration of the recording. Trim the tracks: It is possible that processing the ingested files according to the SMIL file would result in tracks that have a longer duration than the overall recording should. Therefore, all tracks are trimmed individually to the target duration. Mux audio tracks: To avoid the necessity to call further workflow operations just for audio muxing, the PartialImportWorkflowOperation can perform audio muxing itself. In our example, it would mux the audio and video track of the presenter into a single audio/video track. Ensure specific output formats: There may be situations where you want to ensure that the output of this operations comes with a specific file format, e.g. MP4 . The configuration keys force-encoding and required_extensions can be used to control the behavior of the PartialImportWorkflowOperation: In case the force-encoding is set to true , the target tracks will be re-encoded using the force-encoding-profile . The target tracks will also be re-encoded using that encoding profile in case its file extensions don't match the required_extensions .","title":"Operation Example"},{"location":"workflowoperationhandlers/partial-import-woh/#smil-file-structure","text":"The PartialImportWorkflowOperation expects a specific subset of SMIL that is described in this section. The overall structure of the SMIL file is shown by example below: <?xml version=\"1.1\" encoding=\"UTF-8\"?> <smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\"> <head/> <body> <par dur=\"15000ms\"> <seq> <video begin=\"400ms\" dur=\"13000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <video begin=\"15000ms\" dur=\"70000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/> <audio begin=\"0ms\" dur=\"400ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> <audio begin=\"900ms\" dur=\"13000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/> </seq> <seq> <video begin=\"900ms\" dur=\"30000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/> </seq> </par> </body> </smil> The PartialImportWorkflowOperation can handle at most one par element that is used to describe to overall media duration using the attribute dur . The resulting tracks will be trimmed to this duration if necessary. In the example above, the overall media duration is set to 15 seconds. The par element has one or two sequence sub elements seq , each describing a track that is to be built from its sub elements - the partial tracks. Each sequence ( seq ) has at least one sub element. Sub elements can be either video elements, audio elements or both video and audio elements. Each of those sub elements requires the attributes begin (position of partial track in milliseconds relative to start of overall media) and dur (duration of partial track in milliseconds) The audio elements are used to indicate that the media file referred to is an audio-only media file, whereas video elements can refer to either video-only or audio-video media files. The following combinations result in a defined behavior:","title":"SMIL File Structure"},{"location":"workflowoperationhandlers/partial-import-woh/#supported-combinations-of-video-and-audio-elements","text":"video audio resulting track audio/video track n/a audio/video track video-only track n/a video-only track video-only track audio-only track audio/video track n/a audio-only track audio-only track All other combinations of video and audio elements result in unspecified behavior of the PartialImportWorkflowOperation.","title":"Supported Combinations of Video and Audio Elements"},{"location":"workflowoperationhandlers/partial-import-woh/#order-of-video-and-audio-elements","text":"Within a sequence ( seq ), the video elements most occur in ascending order considering the values of their attributes begin . The same holds for audio elements. Note the video and audio elements are processed individually, so the order of occurrences of video and audio elements are independent from each other. Important: The PartialImportWorkflowOperation will not process video or audio elements correctly if the order of appearance in the SMIL file is not correct.","title":"Order of Video and Audio Elements"},{"location":"workflowoperationhandlers/partial-import-woh/#overlapping-partial-tracks","text":"The behavior of overlapping partial tracks is unspecified, i.e. for a given element e ( video or audio ), the value of begin for the subsequent element (e+1) of the same type ( video or audio ) within the same sequence must be equal or greater than e.begin + e.dur , i.e. make sure that the following invariant holds: (e+1).begin >= e.begin + e.dur","title":"Overlapping Partial Tracks"},{"location":"workflowoperationhandlers/partial-import-woh/#encoding-profiles-the-partialimportworkflowoperation-uses-a-number-of-encoding-profiles-to-perform-its-processing","text":"Some of the encoding profiles can be explicitly configured by the user, others are used implicitly in means of being hard-coded and are not supposed to be changed by the user.","title":"Encoding Profiles The PartialImportWorkflowOperation uses a number of encoding profiles to perform its processing."},{"location":"workflowoperationhandlers/partial-import-woh/#hard-coded-encoding-profiles","text":"encoding profile description import.preview Extract the first frame of a given partial track import.image-frame Extract the last frame of a given partial track. Note that this profile is used to extract the exactly last frame of a partial track - not just a frame close to the last one. To make this work for video files with headers that don't contain the exact frame count, set accurate_frame_count to true in etc/org.opencastproject.inspection.ffmpeg.MediaInspectionServiceImpl.cfg image-movie.work Generate video partial tracks based on extracted images used to fill video gaps import.silent Generate silent audio tracks used to fill audio gaps","title":"Hard-coded Encoding Profiles"},{"location":"workflowoperationhandlers/partial-import-woh/#configurable-encoding-profiles","text":"configuration key description concat-encoding-profile Used to concatenate partial tracks into tracks trim-encoding-profile Used to trim the resulting concatenated single tracks if necessary force-encoding-profile Used to re-encode target tracks in case the file extension of a given target track is not included in required-extensions or the configuration key force-encoding is set to true","title":"Configurable Encoding Profiles"},{"location":"workflowoperationhandlers/postmediapackage-woh/","text":"PostMediapackageWorkflowHandler Description This Workflow Operation Handler can be used to send a POST request containing an XML/JSON representation of the Mediapackage processed by the workflow to an external webservice. The service supports HTTP Basic and Digest Authentication. Parameter Table Configuration Keys Description url The target url format The desired export format: xml or json debug Disable this on a productive system. If enabled, request bodies etc. will be written to log. If disabled, only errors will be logged. mediapackage.type Type of Mediapackage to send (possible values: workflow , search ; default: search ) auth.enabled enable authentication (simple/digest will be detected automatically) auth.username username for authentication auth.password password for authentication +source_system fields with keys beginning with + will be added to the message body Operation Example <operation id=\"post-mediapackage\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Sending MediaPackage to Lernfunk3\"> <configurations> <configuration key=\"url\">http://example.com:5000/</configuration> <configuration key=\"format\">xml</configuration> <configuration key=\"debug\">no</configuration> <configuration key=\"mediapackage.type\">search</configuration> <configuration key=\"auth.enabled\">yes</configuration> <configuration key=\"auth.username\">exportuser</configuration> <configuration key=\"auth.password\">secret</configuration> <configuration key=\"+source_system\">video.example.com</configuration> </configurations> </operation>","title":"Post Media Package"},{"location":"workflowoperationhandlers/postmediapackage-woh/#postmediapackageworkflowhandler","text":"","title":"PostMediapackageWorkflowHandler"},{"location":"workflowoperationhandlers/postmediapackage-woh/#description","text":"This Workflow Operation Handler can be used to send a POST request containing an XML/JSON representation of the Mediapackage processed by the workflow to an external webservice. The service supports HTTP Basic and Digest Authentication.","title":"Description"},{"location":"workflowoperationhandlers/postmediapackage-woh/#parameter-table","text":"Configuration Keys Description url The target url format The desired export format: xml or json debug Disable this on a productive system. If enabled, request bodies etc. will be written to log. If disabled, only errors will be logged. mediapackage.type Type of Mediapackage to send (possible values: workflow , search ; default: search ) auth.enabled enable authentication (simple/digest will be detected automatically) auth.username username for authentication auth.password password for authentication +source_system fields with keys beginning with + will be added to the message body","title":"Parameter Table"},{"location":"workflowoperationhandlers/postmediapackage-woh/#operation-example","text":"<operation id=\"post-mediapackage\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Sending MediaPackage to Lernfunk3\"> <configurations> <configuration key=\"url\">http://example.com:5000/</configuration> <configuration key=\"format\">xml</configuration> <configuration key=\"debug\">no</configuration> <configuration key=\"mediapackage.type\">search</configuration> <configuration key=\"auth.enabled\">yes</configuration> <configuration key=\"auth.username\">exportuser</configuration> <configuration key=\"auth.password\">secret</configuration> <configuration key=\"+source_system\">video.example.com</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/prepareav-woh/","text":"PrepareAVWorkflowOperation Description The PrepareAVWorkflowOperation works is like this: If there are two tracks with the same flavor, and one of them contains a video stream only, while the other contains an audio stream only, the implementation will call the composer's \"mux\" method, with the result that the audio will be muxed with the video, using the video's movie container. If it there is one track with a certain flavor, the \"encode\" method is called which will rewrite (vs. encode) the file using the same container and codec (-vcodec copy, -a codec copy), while the container format is determined by ffmpeg via the file's extension. The reason for doing this is that many media files are in a poor state with regard to their compatibility (most often, the stream's codec contains differing information from the container), so we are basically asking ffmepg to rewrite the whole thing, which will in many cases eliminate problems that would otherwhise occur later in the pipeline (encoding to flash, mjpeg etc.). Parameter Table configuration keys example description source-flavor presenter/source Specifies which media should be processed. target-flavor presenter/work Specifies the flavor the new files will get. mux-encoding-profile mux-av.prepared The encoding profile to use for media that needs to be muxed (default is 'mux-av.work') audio-video-encoding-profile av.prepared The encoding profile to use for media that is audio-video already and needs to be re-encodend (default is av.work) video-encoding-profile video-only.prepared The encoding profile to use for media that is only video and needs to be re-encodend (default is video-only.work) audio-encoding-profile audio-only.prepared The encoding profile to use for media that is only audio and needs to be re-encodend (default is audio-only.work) rewrite true Should files be rewritten audio-muxing-source-flavors presentation/source,presentation/*,*/* If there is no matching flavor to mux, search for a track with audio that can be muxed by going from left to right through this comma-separated list of source flavors Operation Example <operation id=\"prepare-av\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Preparing presenter audio and video work versions\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"target-flavor\">presenter/work</configuration> <configuration key=\"rewrite\">false</configuration> <configuration key=\"audio-muxing-source-flavors\">*/?,*/*</configuration> </configurations> </operation> Audio Muxing The PrepareAVWorkflowOperation can be used for audio muxing in case a matching source video track has no audio. Audio muxing is performed as described below: In case the source-flavor matches to exactly two tracks whereas one track is a video-only track and the other is an audio-only track, those tracks will be merged into a single audio-video track. If there is no such matching flavor to mux, additional audio muxing facilities can be controlled by the use of the configuration key audio-muxing-source-flavors . That configuration key contains a comma-separated list of flavors that defines the search order of how to find an audio track. The following two wildcard characters can be used in flavors in that list: '*' will match to any type or subtype '?' will match to the type or subtype of the matching source-flavor Note: In case that a flavor used with audio-muxing-source-flavors matches to multiple tracks within the media package resulting in a list of matching tracks, the search order within that list is undefined, i.e. PrepareAVWorkflowOperation will just pick any of those tracks that has audio. Example [...] <configuration key=\"source-flavor\">presenter/*</configuration> <configuration key=\"audio-muxing-source-flavors\">presenter-audio/?, presentation/?,presentation/*,?/audio,*/*</configuration> [...] Let's assume that exactly one video-only track of flavor presenter/source in the media package and another track of flavor audio/track that has audio. In this example, the PrepareAVWorkflowOperation would perform the following steps: Search tracks of flavor presenter-audio/source (presenter-audio/?) Search tracks of flavor presentation/source (presentation/?) Search tracks of flavor presentation/* Search tracks of flavor presenter/audio (?/audio) Search tracks of flavor */*","title":"Prepare A/V"},{"location":"workflowoperationhandlers/prepareav-woh/#prepareavworkflowoperation","text":"","title":"PrepareAVWorkflowOperation"},{"location":"workflowoperationhandlers/prepareav-woh/#description","text":"The PrepareAVWorkflowOperation works is like this: If there are two tracks with the same flavor, and one of them contains a video stream only, while the other contains an audio stream only, the implementation will call the composer's \"mux\" method, with the result that the audio will be muxed with the video, using the video's movie container. If it there is one track with a certain flavor, the \"encode\" method is called which will rewrite (vs. encode) the file using the same container and codec (-vcodec copy, -a codec copy), while the container format is determined by ffmpeg via the file's extension. The reason for doing this is that many media files are in a poor state with regard to their compatibility (most often, the stream's codec contains differing information from the container), so we are basically asking ffmepg to rewrite the whole thing, which will in many cases eliminate problems that would otherwhise occur later in the pipeline (encoding to flash, mjpeg etc.).","title":"Description"},{"location":"workflowoperationhandlers/prepareav-woh/#parameter-table","text":"configuration keys example description source-flavor presenter/source Specifies which media should be processed. target-flavor presenter/work Specifies the flavor the new files will get. mux-encoding-profile mux-av.prepared The encoding profile to use for media that needs to be muxed (default is 'mux-av.work') audio-video-encoding-profile av.prepared The encoding profile to use for media that is audio-video already and needs to be re-encodend (default is av.work) video-encoding-profile video-only.prepared The encoding profile to use for media that is only video and needs to be re-encodend (default is video-only.work) audio-encoding-profile audio-only.prepared The encoding profile to use for media that is only audio and needs to be re-encodend (default is audio-only.work) rewrite true Should files be rewritten audio-muxing-source-flavors presentation/source,presentation/*,*/* If there is no matching flavor to mux, search for a track with audio that can be muxed by going from left to right through this comma-separated list of source flavors","title":"Parameter Table"},{"location":"workflowoperationhandlers/prepareav-woh/#operation-example","text":"<operation id=\"prepare-av\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Preparing presenter audio and video work versions\"> <configurations> <configuration key=\"source-flavor\">presenter/source</configuration> <configuration key=\"target-flavor\">presenter/work</configuration> <configuration key=\"rewrite\">false</configuration> <configuration key=\"audio-muxing-source-flavors\">*/?,*/*</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/prepareav-woh/#audio-muxing","text":"The PrepareAVWorkflowOperation can be used for audio muxing in case a matching source video track has no audio. Audio muxing is performed as described below: In case the source-flavor matches to exactly two tracks whereas one track is a video-only track and the other is an audio-only track, those tracks will be merged into a single audio-video track. If there is no such matching flavor to mux, additional audio muxing facilities can be controlled by the use of the configuration key audio-muxing-source-flavors . That configuration key contains a comma-separated list of flavors that defines the search order of how to find an audio track. The following two wildcard characters can be used in flavors in that list: '*' will match to any type or subtype '?' will match to the type or subtype of the matching source-flavor Note: In case that a flavor used with audio-muxing-source-flavors matches to multiple tracks within the media package resulting in a list of matching tracks, the search order within that list is undefined, i.e. PrepareAVWorkflowOperation will just pick any of those tracks that has audio.","title":"Audio Muxing"},{"location":"workflowoperationhandlers/prepareav-woh/#example","text":"[...] <configuration key=\"source-flavor\">presenter/*</configuration> <configuration key=\"audio-muxing-source-flavors\">presenter-audio/?, presentation/?,presentation/*,?/audio,*/*</configuration> [...] Let's assume that exactly one video-only track of flavor presenter/source in the media package and another track of flavor audio/track that has audio. In this example, the PrepareAVWorkflowOperation would perform the following steps: Search tracks of flavor presenter-audio/source (presenter-audio/?) Search tracks of flavor presentation/source (presentation/?) Search tracks of flavor presentation/* Search tracks of flavor presenter/audio (?/audio) Search tracks of flavor */*","title":"Example"},{"location":"workflowoperationhandlers/probe-resolution-woh/","text":"ProbeResolutionWorkflowOperationHandler Description The ProbeResolutionWorkflowOperationHandler analyzes specified tracks in the mediapackage and sets workflow instance variables based on the video resolution and the mapping set-up. Parameter Table Configuration Key Example Description source-flavor* presentation/work The \"flavor\" of the track to use as a source input var:VARNAME 1280x720,1920x1080 Resolutions to variable mapping val:VARNAME 16/9 Value to set if resolution matches * mandatory configuration key There can be an arbitrary number of variable parameters. They must be prefixed by var: , followed by the variable name to set to true if the video has a resolution listed. The var: prefix will not be part of the resulting variable name but will be replaced with a representation of the tracks flavor. By default, the variable will be set to true if the resolution matches. If a val:VARNAME configuration is present which matches a var:VARNAME , the value from that configuration key will be used instead. Note that if there are multiple video streams with one flavor, only the information from the last video stream are taken. Operation Example <operation id=\"probe-resolution\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Set control variables based on video resolution\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"var:aspect\">1280x720,1920x1080,2592x1080</configuration> <configuration key=\"val:aspect\">16/9</configuration> <configuration key=\"var:is_720\">1280x720</configuration> <configuration key=\"var:is_1080\">1920x1080,2592x1080</configuration> </configurations> </operation> If a video track with a resolution of 1280x720 is passed to this operation as presentation/source , the resulting variables would be: presentation_source_is_720=true presentation_source_aspect=16/9","title":"Probe Resolution"},{"location":"workflowoperationhandlers/probe-resolution-woh/#proberesolutionworkflowoperationhandler","text":"","title":"ProbeResolutionWorkflowOperationHandler"},{"location":"workflowoperationhandlers/probe-resolution-woh/#description","text":"The ProbeResolutionWorkflowOperationHandler analyzes specified tracks in the mediapackage and sets workflow instance variables based on the video resolution and the mapping set-up.","title":"Description"},{"location":"workflowoperationhandlers/probe-resolution-woh/#parameter-table","text":"Configuration Key Example Description source-flavor* presentation/work The \"flavor\" of the track to use as a source input var:VARNAME 1280x720,1920x1080 Resolutions to variable mapping val:VARNAME 16/9 Value to set if resolution matches * mandatory configuration key There can be an arbitrary number of variable parameters. They must be prefixed by var: , followed by the variable name to set to true if the video has a resolution listed. The var: prefix will not be part of the resulting variable name but will be replaced with a representation of the tracks flavor. By default, the variable will be set to true if the resolution matches. If a val:VARNAME configuration is present which matches a var:VARNAME , the value from that configuration key will be used instead. Note that if there are multiple video streams with one flavor, only the information from the last video stream are taken.","title":"Parameter Table"},{"location":"workflowoperationhandlers/probe-resolution-woh/#operation-example","text":"<operation id=\"probe-resolution\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Set control variables based on video resolution\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"var:aspect\">1280x720,1920x1080,2592x1080</configuration> <configuration key=\"val:aspect\">16/9</configuration> <configuration key=\"var:is_720\">1280x720</configuration> <configuration key=\"var:is_1080\">1920x1080,2592x1080</configuration> </configurations> </operation> If a video track with a resolution of 1280x720 is passed to this operation as presentation/source , the resulting variables would be: presentation_source_is_720=true presentation_source_aspect=16/9","title":"Operation Example"},{"location":"workflowoperationhandlers/process-smil-woh/","text":"ProcessSmilWorkflowHandler Description The ProcessSmilWorkflowHandler is used to edit media files using descriptions from a SMIL file. The SMIL file is typically generated by the editor or it can be constructed and uploaded. It contains names of one or more source tracks and a list of selected clips defined by in/out points in ms in the source tracks. It will concatenate all the clips from the source tracks according to the in/out points and encode the result into multiple target videos using a list of encoding profiles. In addition, the target videos are optionally tagged with the name of the encoding profiles. The Video editor produces a SMIL file and by default will also encode one set of edited videos targets as an intermediate format to be used to do segmentation and then used as source to generate multiple delivery formats. This workflow operation is used to bypass the generation of the temporary targets and generate the delivery formats directly. Subsequent workflow operations can select the highest quality source medium by tags and flavors. This operation saves the encoding time of one set of full length video and allows concurrent processing of multiple independent ffmpeg operations. To use this operation with the editor, the following must be added to the editor workflow operation to bypass the video editor encoding, <configuration key=\"skip-processing\">true</configuration> Configuration details Currently, there is only one transition type, which is \"fade to black\". The edited video will fade in from black with a fade-out/fade-in for each clip transition and a fade out at the end. The transition duration is a 2 second fade, configured in org.opencastproject.composer.impl.ComposerServiceImpl.cfg. In the future, each transition can be configurable as a SMIL element. The SMIL file can use more than one source video, but the caller has to take care that the dimension of all the source videos are the same. This workflow will generate one independent ffmpeg operation per SMIL paramgroup (based on source) regardless of the number of target outputs. This workflow can handle each source flavor selector independently. eg: Each source selector can have its own set of encoding profiles, target tags and flavors. The parameters for each configuration, such as flavor are separated into sections by \" ; \". E ach source media selector can have its own sets of encoding profile ids (one for each target recording) and target tags, as well as its own set of target tags and flavors, defined as a comma delimited list. As an example, using presenter/source and presentation/source as uploaded media. eg: <configuration key=\"source-flavors\">*/source</configuration> One source selector means that all the matching recording will be processed the same way. <configuration key=\"source-flavors\">presenter/source;presentation/source</configuration> Two different source selectors separated by semicolons means that all the matching recordings in the first selector will be processed according to the parameters in the first section and the all the matching recordings in the second selector will be processed according to the parameters in next section of the other configuration values such as encoding profiles. Each source selector can have only one corresponding section in each set of values. The use of the semi-colon is optional. If it is absent, there is only one section. If there is only one source selector, but multiple sections in the parameters, then the sections are collapsed into one and they will apply to all the source flavors in the source selector. \"N to N\" means that each section has its own processing configuration. \"1 to N\" or \"N to 1\" means that all the sections are processed the same way, but \"M to N\" where \"M <> N\" will result in an error. eg: <configuration key=\"target-flavors\">*/preview</configuration> <configuration key=\"encoding-profiles\">mp4-low.http;mp4-vga-medium</configuration> All targets are flavored the same way. Using the example above, all media are encoded with \"mp4-low.http\" and \"mp4-vga-medium\" and targets are flavored as \"presenter/preview\" and \"presentation/preview\" <configuration key=\"target-tags\">engage-streaming,rss,atom;engage-download,rss,atom</configuration> <configuration key=\"encoding-profiles\">mp4-medium.http;mp4-vga-medium</configuration> Each section is tagged individually. Using the example above, presenter/preview is encoded with \"mp4-medium.http\" and tagged with \"engage-streaming\" ,\"rss\" and \"atom\", presentation/preview is encoded with \"mp4-vga-medium\" and tagged with \"engage-download\",\"rss\" and \"atom\". If presenter/work is to be encoded with \"mp4-low.http,mp4-medium.http\" and presentation/work is to be encoded with \"mp4-vga-medium,mp4-medium.http\", and the target media are flavored as \"presenter/delivery\" and \"presentation/delivery\" respectively, and all targets are tagged with \"engage\" and \"archive\" in addition to the names of the encoding profiles used. It will look like the following. Parameter Table configuration keys example description smil-flavor smil/smil Specifies the flavor of the new media source-flavors presenter/work ; presentation/work Which media should be encoded target-flavors */delivery Specifies the flavor of the new media target-tags engage,archive Specifies the tags of the new media encoding-profiles mp4-low.http,mp4-medium.http ; mp4-vga-medium,mp4-medium.http Profiles for each source flavor tag-with-profile true (default to false) target medium are tagged with coresponding encoding profile Id Operation Example The parameters in the table above will look like this as a workflow operation. <operation id=\"process-smil\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encoding presenter (camera) video to Flash download\"> <configurations> <configuration key=\"smil-flavor\">smil/cutting</configuration> <configuration key=\"source-flavors\">presenter/work;presentation/work</configuration> <configuration key=\"target-flavors\">*/delivery</configuration> <configuration key=\"target-tags\">engage,archive</configuration> <configuration key=\"encoding-profiles\"> mp4-low.http,mp4-medium.http*;*mp4-vga-medium,mp4-medium.http</configuration> <configuration key=\"tag-with-profile\">true</configuration> </configurations> </operation> Note:(Very Important) Each encoding section generates all the target media in one ffmpeg call by incorporating relevant parts of each encoding profile command using complex filters. Care must be taken that no complex filters are used in the encoding profiles used for this workflow, as it can cause a conflict and ffmpeg will fail. Simple filters (i.e.: -vf, -af , -filter:v, -filter:a) can be used. Encoded target recording are distinguished by the suffix, it is important that all the encoding profiles used have distinct suffixes or the target video tagging can be wrong, for example: profile.mp4-vga-medium.http.suffix = -vga-medium.mp4 profile.mp4-medium.http.suffix = -medium.mp4 If using this to process SMIL files generated by the editor in the same workflow, be sure to set the \"skip-processing\" key in the editor to true.","title":"Process Smil"},{"location":"workflowoperationhandlers/process-smil-woh/#processsmilworkflowhandler","text":"","title":"ProcessSmilWorkflowHandler"},{"location":"workflowoperationhandlers/process-smil-woh/#description","text":"The ProcessSmilWorkflowHandler is used to edit media files using descriptions from a SMIL file. The SMIL file is typically generated by the editor or it can be constructed and uploaded. It contains names of one or more source tracks and a list of selected clips defined by in/out points in ms in the source tracks. It will concatenate all the clips from the source tracks according to the in/out points and encode the result into multiple target videos using a list of encoding profiles. In addition, the target videos are optionally tagged with the name of the encoding profiles. The Video editor produces a SMIL file and by default will also encode one set of edited videos targets as an intermediate format to be used to do segmentation and then used as source to generate multiple delivery formats. This workflow operation is used to bypass the generation of the temporary targets and generate the delivery formats directly. Subsequent workflow operations can select the highest quality source medium by tags and flavors. This operation saves the encoding time of one set of full length video and allows concurrent processing of multiple independent ffmpeg operations. To use this operation with the editor, the following must be added to the editor workflow operation to bypass the video editor encoding, <configuration key=\"skip-processing\">true</configuration>","title":"Description"},{"location":"workflowoperationhandlers/process-smil-woh/#configuration-details","text":"Currently, there is only one transition type, which is \"fade to black\". The edited video will fade in from black with a fade-out/fade-in for each clip transition and a fade out at the end. The transition duration is a 2 second fade, configured in org.opencastproject.composer.impl.ComposerServiceImpl.cfg. In the future, each transition can be configurable as a SMIL element. The SMIL file can use more than one source video, but the caller has to take care that the dimension of all the source videos are the same. This workflow will generate one independent ffmpeg operation per SMIL paramgroup (based on source) regardless of the number of target outputs. This workflow can handle each source flavor selector independently. eg: Each source selector can have its own set of encoding profiles, target tags and flavors. The parameters for each configuration, such as flavor are separated into sections by \" ; \". E ach source media selector can have its own sets of encoding profile ids (one for each target recording) and target tags, as well as its own set of target tags and flavors, defined as a comma delimited list. As an example, using presenter/source and presentation/source as uploaded media. eg: <configuration key=\"source-flavors\">*/source</configuration> One source selector means that all the matching recording will be processed the same way. <configuration key=\"source-flavors\">presenter/source;presentation/source</configuration> Two different source selectors separated by semicolons means that all the matching recordings in the first selector will be processed according to the parameters in the first section and the all the matching recordings in the second selector will be processed according to the parameters in next section of the other configuration values such as encoding profiles. Each source selector can have only one corresponding section in each set of values. The use of the semi-colon is optional. If it is absent, there is only one section. If there is only one source selector, but multiple sections in the parameters, then the sections are collapsed into one and they will apply to all the source flavors in the source selector. \"N to N\" means that each section has its own processing configuration. \"1 to N\" or \"N to 1\" means that all the sections are processed the same way, but \"M to N\" where \"M <> N\" will result in an error. eg: <configuration key=\"target-flavors\">*/preview</configuration> <configuration key=\"encoding-profiles\">mp4-low.http;mp4-vga-medium</configuration> All targets are flavored the same way. Using the example above, all media are encoded with \"mp4-low.http\" and \"mp4-vga-medium\" and targets are flavored as \"presenter/preview\" and \"presentation/preview\" <configuration key=\"target-tags\">engage-streaming,rss,atom;engage-download,rss,atom</configuration> <configuration key=\"encoding-profiles\">mp4-medium.http;mp4-vga-medium</configuration> Each section is tagged individually. Using the example above, presenter/preview is encoded with \"mp4-medium.http\" and tagged with \"engage-streaming\" ,\"rss\" and \"atom\", presentation/preview is encoded with \"mp4-vga-medium\" and tagged with \"engage-download\",\"rss\" and \"atom\". If presenter/work is to be encoded with \"mp4-low.http,mp4-medium.http\" and presentation/work is to be encoded with \"mp4-vga-medium,mp4-medium.http\", and the target media are flavored as \"presenter/delivery\" and \"presentation/delivery\" respectively, and all targets are tagged with \"engage\" and \"archive\" in addition to the names of the encoding profiles used. It will look like the following.","title":"Configuration details"},{"location":"workflowoperationhandlers/process-smil-woh/#parameter-table","text":"configuration keys example description smil-flavor smil/smil Specifies the flavor of the new media source-flavors presenter/work ; presentation/work Which media should be encoded target-flavors */delivery Specifies the flavor of the new media target-tags engage,archive Specifies the tags of the new media encoding-profiles mp4-low.http,mp4-medium.http ; mp4-vga-medium,mp4-medium.http Profiles for each source flavor tag-with-profile true (default to false) target medium are tagged with coresponding encoding profile Id","title":"Parameter Table"},{"location":"workflowoperationhandlers/process-smil-woh/#operation-example","text":"The parameters in the table above will look like this as a workflow operation. <operation id=\"process-smil\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Encoding presenter (camera) video to Flash download\"> <configurations> <configuration key=\"smil-flavor\">smil/cutting</configuration> <configuration key=\"source-flavors\">presenter/work;presentation/work</configuration> <configuration key=\"target-flavors\">*/delivery</configuration> <configuration key=\"target-tags\">engage,archive</configuration> <configuration key=\"encoding-profiles\"> mp4-low.http,mp4-medium.http*;*mp4-vga-medium,mp4-medium.http</configuration> <configuration key=\"tag-with-profile\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/process-smil-woh/#notevery-important","text":"Each encoding section generates all the target media in one ffmpeg call by incorporating relevant parts of each encoding profile command using complex filters. Care must be taken that no complex filters are used in the encoding profiles used for this workflow, as it can cause a conflict and ffmpeg will fail. Simple filters (i.e.: -vf, -af , -filter:v, -filter:a) can be used. Encoded target recording are distinguished by the suffix, it is important that all the encoding profiles used have distinct suffixes or the target video tagging can be wrong, for example: profile.mp4-vga-medium.http.suffix = -vga-medium.mp4 profile.mp4-medium.http.suffix = -medium.mp4 If using this to process SMIL files generated by the editor in the same workflow, be sure to set the \"skip-processing\" key in the editor to true.","title":"Note:(Very Important)"},{"location":"workflowoperationhandlers/publish-aws-woh/","text":"PublishAWSS3WorkflowOperation Description The PublishAWSS3WorkflowOperation will publish your recording to the normal publication channel (ie, engage), but the media files will be hosted via AWS S3/Cloudfront. Parameter Table configuration keys description check-availability Check if the media if rechable download-source-flavors Specifies which media should be published for download download-source-tags Specifies which media should be published for download download-target-subflavors Subflavor to use for distributed material download-target-tags Modify tags of published media strategy If there is no key, published media would be retracted before publishing merge merges new publication with existing publication streaming-source-flavors Specifies which media should be published to the streaming server streaming-source-tags Specifies which media should be published to the streaming server streaming-tagret-tags Modify tags of published media streaming-target-subflavors Subflavor to use for distributed material Operation Example <operation id=\"publish-aws\" max-attempts=\"2\" exception-handler-workflow=\"partial-error\" description=\"Publishing to Amazon Web Services\"> <configurations> <configuration key=\"download-source-flavors\">dublincore/*,security/*</configuration> <configuration key=\"download-source-tags\">engage-download,atom,rss,mobile</configuration> <configuration key=\"streaming-source-tags\">engage-streaming</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation>","title":"Publish AWS"},{"location":"workflowoperationhandlers/publish-aws-woh/#publishawss3workflowoperation","text":"","title":"PublishAWSS3WorkflowOperation"},{"location":"workflowoperationhandlers/publish-aws-woh/#description","text":"The PublishAWSS3WorkflowOperation will publish your recording to the normal publication channel (ie, engage), but the media files will be hosted via AWS S3/Cloudfront.","title":"Description"},{"location":"workflowoperationhandlers/publish-aws-woh/#parameter-table","text":"configuration keys description check-availability Check if the media if rechable download-source-flavors Specifies which media should be published for download download-source-tags Specifies which media should be published for download download-target-subflavors Subflavor to use for distributed material download-target-tags Modify tags of published media strategy If there is no key, published media would be retracted before publishing merge merges new publication with existing publication streaming-source-flavors Specifies which media should be published to the streaming server streaming-source-tags Specifies which media should be published to the streaming server streaming-tagret-tags Modify tags of published media streaming-target-subflavors Subflavor to use for distributed material","title":"Parameter Table"},{"location":"workflowoperationhandlers/publish-aws-woh/#operation-example","text":"<operation id=\"publish-aws\" max-attempts=\"2\" exception-handler-workflow=\"partial-error\" description=\"Publishing to Amazon Web Services\"> <configurations> <configuration key=\"download-source-flavors\">dublincore/*,security/*</configuration> <configuration key=\"download-source-tags\">engage-download,atom,rss,mobile</configuration> <configuration key=\"streaming-source-tags\">engage-streaming</configuration> <configuration key=\"strategy\">merge</configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/publish-configure-woh/","text":"ConfigurablePublishWorkflowOperationHandler Description The ConfigurablePublishWorkflowOperationHandler will distribute the given elements and create a publication element for it. By default it will retract all publications before publishing anew. Parameter Table These are the keys that are configured through the workflow definition. At least one media package element must match the supplied source-flavors or source-tags or else the operation will not know what to publish. The channel-id and url-pattern are also mandatory. Key Description Example Default channel-id Id of the channel to publish to internal mimetype Mime type of the published element text/html Type of last distributed element source-flavors Flavors of the media package elements to publish */trimmed source-tags Tags of the media package elements to publish engage url-pattern Pattern to create the URI for the published from ftp://\u2026/${event_id} with-published-elements Use the current contents of the media package instead of publishing elements to a channel true check-availability Check if the media is reachable after publication false false strategy Strategy for when there is already published material fail retract mode How elements are distributed mixed bulk Mode The configuration key mode can be used to control how media package elements are being distributed: Mode Description single For each media package element, a job is created mixed One job for all media package elements that are not tracks and one job per track bulk One job for all media package elements This allows you to choose a lot of jobs and parallelism ( single ), just one job and no parallelism ( bulk ) or something in between ( mixed ). The best choice depends on your setup. URL Pattern Variables These are the variables available in the url-pattern configuration. They will be replaced with the value during the execution of the workflow operation. Variable Description Example ${event_id} The event (media package) identifier 18633e04-1a3f-4bbb-a72a-99c15deba1b9 ${player_path} The player path for the event /engage/theodul/ui/core.html?id= ${publication_id} The id of this publication. 54f6c12d-8e68-4ec8-badf-cd045b33d01e ${series_id} The id of the series if available 36f3c5d8-ad4d-4dab-beb1-1400ffab4a69 The organization properties are also available and can be accessed with the org_ prefix followed by the property name, eg. ${org_player} will be replaced by the value of the organization property named player . Note some organization properties contain an . (period) in their name (e.g. org.opencastproject.external.api.url ). As this character have an special meaning in the FreeMarker library (used for substitution), all occurrences are replaced with _ (underscore). Additional to the organization properties you can use org_id , org_name , org_admin_role and org_anonymous_role as well. Publication Channel Labels and Icons Using this workflow operation, you can create arbitrary custom publication channels. Without further action, the administrative user interface will label these channels \"Custom\". You can specify both a label and an icon for each custom publication channels in the configuration files etc/listproviders/publication.channel.labels.properties and etc/listproviders/publication.channel.icons.properties . Operation Examples Internal Channel <operation id=\"publish-configure\" exception-handler-workflow=\"partial-error\" description=\"Publish to internal channel\"> <configurations> <configuration key=\"source-tags\">engage,atom,rss</configuration> <configuration key=\"channel-id\">internal</configuration> <configuration key=\"url-pattern\">http://localhost:8080/admin-ng/index.html#/events/events/${event_id}/tools/playback</configuration> </configurations> </operation> External API <operation id=\"publish-configure\" exception-handler-workflow=\"partial-error\" description=\"Publish to external api publication channel\"> <configurations> <configuration key=\"channel-id\">api</configuration> <configuration key=\"mimetype\">application/json</configuration> <configuration key=\"source-tags\">engage-download,engage-streaming</configuration> <configuration key=\"url-pattern\">http://api.oc.org/api/events/${event_id}</configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation>","title":"Publish Configure"},{"location":"workflowoperationhandlers/publish-configure-woh/#configurablepublishworkflowoperationhandler","text":"","title":"ConfigurablePublishWorkflowOperationHandler"},{"location":"workflowoperationhandlers/publish-configure-woh/#description","text":"The ConfigurablePublishWorkflowOperationHandler will distribute the given elements and create a publication element for it. By default it will retract all publications before publishing anew.","title":"Description"},{"location":"workflowoperationhandlers/publish-configure-woh/#parameter-table","text":"These are the keys that are configured through the workflow definition. At least one media package element must match the supplied source-flavors or source-tags or else the operation will not know what to publish. The channel-id and url-pattern are also mandatory. Key Description Example Default channel-id Id of the channel to publish to internal mimetype Mime type of the published element text/html Type of last distributed element source-flavors Flavors of the media package elements to publish */trimmed source-tags Tags of the media package elements to publish engage url-pattern Pattern to create the URI for the published from ftp://\u2026/${event_id} with-published-elements Use the current contents of the media package instead of publishing elements to a channel true check-availability Check if the media is reachable after publication false false strategy Strategy for when there is already published material fail retract mode How elements are distributed mixed bulk","title":"Parameter Table"},{"location":"workflowoperationhandlers/publish-configure-woh/#mode","text":"The configuration key mode can be used to control how media package elements are being distributed: Mode Description single For each media package element, a job is created mixed One job for all media package elements that are not tracks and one job per track bulk One job for all media package elements This allows you to choose a lot of jobs and parallelism ( single ), just one job and no parallelism ( bulk ) or something in between ( mixed ). The best choice depends on your setup.","title":"Mode"},{"location":"workflowoperationhandlers/publish-configure-woh/#url-pattern-variables","text":"These are the variables available in the url-pattern configuration. They will be replaced with the value during the execution of the workflow operation. Variable Description Example ${event_id} The event (media package) identifier 18633e04-1a3f-4bbb-a72a-99c15deba1b9 ${player_path} The player path for the event /engage/theodul/ui/core.html?id= ${publication_id} The id of this publication. 54f6c12d-8e68-4ec8-badf-cd045b33d01e ${series_id} The id of the series if available 36f3c5d8-ad4d-4dab-beb1-1400ffab4a69 The organization properties are also available and can be accessed with the org_ prefix followed by the property name, eg. ${org_player} will be replaced by the value of the organization property named player . Note some organization properties contain an . (period) in their name (e.g. org.opencastproject.external.api.url ). As this character have an special meaning in the FreeMarker library (used for substitution), all occurrences are replaced with _ (underscore). Additional to the organization properties you can use org_id , org_name , org_admin_role and org_anonymous_role as well.","title":"URL Pattern Variables"},{"location":"workflowoperationhandlers/publish-configure-woh/#publication-channel-labels-and-icons","text":"Using this workflow operation, you can create arbitrary custom publication channels. Without further action, the administrative user interface will label these channels \"Custom\". You can specify both a label and an icon for each custom publication channels in the configuration files etc/listproviders/publication.channel.labels.properties and etc/listproviders/publication.channel.icons.properties .","title":"Publication Channel Labels and Icons"},{"location":"workflowoperationhandlers/publish-configure-woh/#operation-examples","text":"","title":"Operation Examples"},{"location":"workflowoperationhandlers/publish-configure-woh/#internal-channel","text":"<operation id=\"publish-configure\" exception-handler-workflow=\"partial-error\" description=\"Publish to internal channel\"> <configurations> <configuration key=\"source-tags\">engage,atom,rss</configuration> <configuration key=\"channel-id\">internal</configuration> <configuration key=\"url-pattern\">http://localhost:8080/admin-ng/index.html#/events/events/${event_id}/tools/playback</configuration> </configurations> </operation>","title":"Internal Channel"},{"location":"workflowoperationhandlers/publish-configure-woh/#external-api","text":"<operation id=\"publish-configure\" exception-handler-workflow=\"partial-error\" description=\"Publish to external api publication channel\"> <configurations> <configuration key=\"channel-id\">api</configuration> <configuration key=\"mimetype\">application/json</configuration> <configuration key=\"source-tags\">engage-download,engage-streaming</configuration> <configuration key=\"url-pattern\">http://api.oc.org/api/events/${event_id}</configuration> <configuration key=\"check-availability\">true</configuration> </configurations> </operation>","title":"External API"},{"location":"workflowoperationhandlers/publish-engage-woh/","text":"Publish Engage Workflow Operation ID: publish-engage Description The publish-engage operation will bring your media to the engage distribution channels (streaming, progressive download, \u2026) Parameter Table configuration keys description check-availability Check if the media is reachable download-source-flavors Distribute any mediapackage elements with one of these (comma separated) flavors to download download-source-tags Distribute any mediapackage elements with one of these (comma separated) tags to download download-target-subflavors Subflavor to use for distributed material download-target-tags Add tags (comma separated) to published media strategy If there is no key, published media would be retracted before publishing <configuration key=\"strategy\">merge</configuration> merges new publication with existing publication streaming-source-flavors Specifies which media should be published to the streaming server streaming-source-tags Specifies which media should be published to the streaming server streaming-target-tags Add tags (comma separated) to published media streaming-target-subflavors Subflavor to use for distributed material merge-force-flavors Flavors of elements for which an update is enforced when mergeing catalogs. Defaults to dublincore/*,security/* . Operation Example <operation id=\"publish-engage\" max-attempts=\"2\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Distribute and publish to engage player\"> <configurations> <configuration key=\"download-source-tags\">engage,atom,rss</configuration> <configuration key=\"streaming-source-tags\">engage</configuration> <configuration key=\"check-availability\">true</configuration> <configuration key=\"strategy\">merge</configuration> </configurations> </operation>","title":"Publish Engage"},{"location":"workflowoperationhandlers/publish-engage-woh/#publish-engage-workflow-operation","text":"ID: publish-engage","title":"Publish Engage Workflow Operation"},{"location":"workflowoperationhandlers/publish-engage-woh/#description","text":"The publish-engage operation will bring your media to the engage distribution channels (streaming, progressive download, \u2026)","title":"Description"},{"location":"workflowoperationhandlers/publish-engage-woh/#parameter-table","text":"configuration keys description check-availability Check if the media is reachable download-source-flavors Distribute any mediapackage elements with one of these (comma separated) flavors to download download-source-tags Distribute any mediapackage elements with one of these (comma separated) tags to download download-target-subflavors Subflavor to use for distributed material download-target-tags Add tags (comma separated) to published media strategy If there is no key, published media would be retracted before publishing <configuration key=\"strategy\">merge</configuration> merges new publication with existing publication streaming-source-flavors Specifies which media should be published to the streaming server streaming-source-tags Specifies which media should be published to the streaming server streaming-target-tags Add tags (comma separated) to published media streaming-target-subflavors Subflavor to use for distributed material merge-force-flavors Flavors of elements for which an update is enforced when mergeing catalogs. Defaults to dublincore/*,security/* .","title":"Parameter Table"},{"location":"workflowoperationhandlers/publish-engage-woh/#operation-example","text":"<operation id=\"publish-engage\" max-attempts=\"2\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Distribute and publish to engage player\"> <configurations> <configuration key=\"download-source-tags\">engage,atom,rss</configuration> <configuration key=\"streaming-source-tags\">engage</configuration> <configuration key=\"check-availability\">true</configuration> <configuration key=\"strategy\">merge</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/publish-oaipmh-woh/","text":"PublishOaiPmhWorkflowOperation Description The Publish OAI-PMH workflow operation exposes your media's metadata in a OAI-PMH repository for harvesting by OAI-PMH aware applications. Parameter Table Configuration Keys Description download-flavors Distribute any mediapackage elements with one of these (comma separated) flavors to download download-tags Distribute any mediapackage elements with one of these (comma separated) tags to download streaming-flavors Distribute any mediapackage elements with one of these (comma separated) flavors to streaming streaming-tags Distribute any mediapackage elements with one of these (comma separated) tags to streaming check-availability Check if the distributed download artifact is available at its URL (default: true) repository The name of the OAI-PMH repository where the media should be published to external-template The optional URL template for URL the OAI-PMH publication element external-channel The optional channel name for the OAI-PMH publication element external-mime-type The optional mime type for the OAI-PMH publication element Note: The all or none of the configuration keys external-template , external-channel and external-mime-type must to be set. Customizing the OAI-PMH Publication Element If the configuration keys external-template , external-channel and external-mime-type are not set, the publication element will use the following default values: Field Default Value url prop.org.opencastproject.oaipmh.server.hosturl + org.opencastproject.oaipmh.mountpoint + repository mime type \"text/xml\" channel name \"oaipmh-\" + repository Note that org.opencastproject.oaipmh.server.hosturl is defined in etc/org.opencastproject.organization-mh_default_org.cfg and org.opencastproject.oaipmh.mountpoint is defined in custom.properties and defaults to /oaipmh . Example: http://localhost:8080/oaipmh/default The OAI-PMH publication element can be customized by setting the configuration keys external-template , external-channel and external-mime-type . The URL of the publication element can be set by using external-template . The following variables can be used in the template: Variable Name Description event ID of the event being published series ID of the series being published Example: https://www.externalURL.com/watch.html?series={series}&id={event} The configuration key external-mime-type is used to set the mime type of the content return when accessing the URL of the publication element. The configuration key 'external-channel' is used to set the name of the publication channel. Operation Example <operation id=\"publish-oaipmh\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Publish event to the OAI-PMH repository\"> <configurations> <configuration key=\"download-tags\">oaipmh-download</configuration> <configuration key=\"streaming-tags\">oaipmh-streaming</configuration> <configuration key=\"check-availability\">true</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Publish OAI-PMH"},{"location":"workflowoperationhandlers/publish-oaipmh-woh/#publishoaipmhworkflowoperation","text":"","title":"PublishOaiPmhWorkflowOperation"},{"location":"workflowoperationhandlers/publish-oaipmh-woh/#description","text":"The Publish OAI-PMH workflow operation exposes your media's metadata in a OAI-PMH repository for harvesting by OAI-PMH aware applications.","title":"Description"},{"location":"workflowoperationhandlers/publish-oaipmh-woh/#parameter-table","text":"Configuration Keys Description download-flavors Distribute any mediapackage elements with one of these (comma separated) flavors to download download-tags Distribute any mediapackage elements with one of these (comma separated) tags to download streaming-flavors Distribute any mediapackage elements with one of these (comma separated) flavors to streaming streaming-tags Distribute any mediapackage elements with one of these (comma separated) tags to streaming check-availability Check if the distributed download artifact is available at its URL (default: true) repository The name of the OAI-PMH repository where the media should be published to external-template The optional URL template for URL the OAI-PMH publication element external-channel The optional channel name for the OAI-PMH publication element external-mime-type The optional mime type for the OAI-PMH publication element Note: The all or none of the configuration keys external-template , external-channel and external-mime-type must to be set.","title":"Parameter Table"},{"location":"workflowoperationhandlers/publish-oaipmh-woh/#customizing-the-oai-pmh-publication-element","text":"If the configuration keys external-template , external-channel and external-mime-type are not set, the publication element will use the following default values: Field Default Value url prop.org.opencastproject.oaipmh.server.hosturl + org.opencastproject.oaipmh.mountpoint + repository mime type \"text/xml\" channel name \"oaipmh-\" + repository Note that org.opencastproject.oaipmh.server.hosturl is defined in etc/org.opencastproject.organization-mh_default_org.cfg and org.opencastproject.oaipmh.mountpoint is defined in custom.properties and defaults to /oaipmh . Example: http://localhost:8080/oaipmh/default The OAI-PMH publication element can be customized by setting the configuration keys external-template , external-channel and external-mime-type . The URL of the publication element can be set by using external-template . The following variables can be used in the template: Variable Name Description event ID of the event being published series ID of the series being published Example: https://www.externalURL.com/watch.html?series={series}&id={event} The configuration key external-mime-type is used to set the mime type of the content return when accessing the URL of the publication element. The configuration key 'external-channel' is used to set the name of the publication channel.","title":"Customizing the OAI-PMH Publication Element"},{"location":"workflowoperationhandlers/publish-oaipmh-woh/#operation-example","text":"<operation id=\"publish-oaipmh\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Publish event to the OAI-PMH repository\"> <configurations> <configuration key=\"download-tags\">oaipmh-download</configuration> <configuration key=\"streaming-tags\">oaipmh-streaming</configuration> <configuration key=\"check-availability\">true</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/publish-youtube-woh/","text":"PublishYoutubeWorkflowOperation Description The PublishYoutubeWorkflowOperation publishes a single stream to YouTube. This stream must meet YouTube's format requirements, and may consist of audio and/or video. If you want to publish both your presenter and presentation streams we suggest using the Composite workflow operation handler to prepare a composite file with both streams inside of it. The default Opencast workflow prepares a video using this method. Parameter Table configuration keys description source-flavors The flavors to publish to YouTube source-tags The tags to publish to YouTube Operation Example <operation id=\"publish-youtube\" max-attempts=\"2\" exception-handler-workflow=\"ng-partial-error\" description=\"Publishing to YouTube\"> <configurations> <configuration key=\"source-tags\">youtube</configuration> </configurations> </operation>","title":"Publish YouTube"},{"location":"workflowoperationhandlers/publish-youtube-woh/#publishyoutubeworkflowoperation","text":"","title":"PublishYoutubeWorkflowOperation"},{"location":"workflowoperationhandlers/publish-youtube-woh/#description","text":"The PublishYoutubeWorkflowOperation publishes a single stream to YouTube. This stream must meet YouTube's format requirements, and may consist of audio and/or video. If you want to publish both your presenter and presentation streams we suggest using the Composite workflow operation handler to prepare a composite file with both streams inside of it. The default Opencast workflow prepares a video using this method.","title":"Description"},{"location":"workflowoperationhandlers/publish-youtube-woh/#parameter-table","text":"configuration keys description source-flavors The flavors to publish to YouTube source-tags The tags to publish to YouTube","title":"Parameter Table"},{"location":"workflowoperationhandlers/publish-youtube-woh/#operation-example","text":"<operation id=\"publish-youtube\" max-attempts=\"2\" exception-handler-workflow=\"ng-partial-error\" description=\"Publishing to YouTube\"> <configurations> <configuration key=\"source-tags\">youtube</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/republish-oaipmh-woh/","text":"RepublishOaiPmhWorkflowOperation Description The Republish OAI-PMH workflow operation will update metadata in your OAI-PMH repositories. In case that the media has not been published before, this operation will skip. Otherwise all elements matching the flavors and tags will be replaced. In case of missing elements in the media package, the published elements will be also removed. Parameter Table Configuration Keys Description source-flavors Republish any media package elements with one of these (comma-separated) flavors source-tags Republish only media package elements that are tagged with one of these (comma-separated) tags repository The name of the OAI-PMH repository where the media should be updated Operation Example <operation id=\"republish-oaipmh\" description=\"Update recording metadata in default OAI-PMH repository\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Republish OAI-PMH"},{"location":"workflowoperationhandlers/republish-oaipmh-woh/#republishoaipmhworkflowoperation","text":"","title":"RepublishOaiPmhWorkflowOperation"},{"location":"workflowoperationhandlers/republish-oaipmh-woh/#description","text":"The Republish OAI-PMH workflow operation will update metadata in your OAI-PMH repositories. In case that the media has not been published before, this operation will skip. Otherwise all elements matching the flavors and tags will be replaced. In case of missing elements in the media package, the published elements will be also removed.","title":"Description"},{"location":"workflowoperationhandlers/republish-oaipmh-woh/#parameter-table","text":"Configuration Keys Description source-flavors Republish any media package elements with one of these (comma-separated) flavors source-tags Republish only media package elements that are tagged with one of these (comma-separated) tags repository The name of the OAI-PMH repository where the media should be updated","title":"Parameter Table"},{"location":"workflowoperationhandlers/republish-oaipmh-woh/#operation-example","text":"<operation id=\"republish-oaipmh\" description=\"Update recording metadata in default OAI-PMH repository\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*</configuration> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/retract-aws-woh/","text":"RetractAWSWorkflowOperationHandler Description The RetractAWSWorkflowOperationHandler retracts the published elements from Amazon S3. There are no configuration keys at this time. Operation Examples Retract <!-- Retract from AWS --> <operation id=\"retract-aws\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Retract recording from AWS\"> </operation>","title":"Retract AWS S3 and Cloudfront"},{"location":"workflowoperationhandlers/retract-aws-woh/#retractawsworkflowoperationhandler","text":"","title":"RetractAWSWorkflowOperationHandler"},{"location":"workflowoperationhandlers/retract-aws-woh/#description","text":"The RetractAWSWorkflowOperationHandler retracts the published elements from Amazon S3. There are no configuration keys at this time.","title":"Description"},{"location":"workflowoperationhandlers/retract-aws-woh/#operation-examples","text":"","title":"Operation Examples"},{"location":"workflowoperationhandlers/retract-aws-woh/#retract","text":"<!-- Retract from AWS --> <operation id=\"retract-aws\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Retract recording from AWS\"> </operation>","title":"Retract"},{"location":"workflowoperationhandlers/retract-configure-woh/","text":"ConfigurableRetractWorkflowOperationHandler Description The ConfigurableRetractWorkflowOperationHandler retracts the published elements from a configured publication. If the elements have been added to the Publication using \"with-published-elements\", as in the case with the external api, they haven't actually been published so it is unnecessary to have a retract-configuration. Adding a retraction won't cause any errors, it will just skip those elements. There is only one configuration key \"channel-id\". This is the channel to remove the published elements from. Operation Examples Retract from Internal Channel <!-- Remove the internal publication if the mediapackage is being deleted. --> <operation id=\"retract-configure\" exception-handler-workflow=\"partial-error\" description=\"Retract from internal publication channel\"> <configurations> <configuration key=\"channel-id\">internal</configuration> </configurations> </operation> Retract from External API <operation id=\"retract-configure\" exception-handler-workflow=\"partial-error\" description=\"Retract from external api publication channel\"> <configurations> <configuration key=\"channel-id\">api</configuration> </configurations> </operation>","title":"Retract Configure"},{"location":"workflowoperationhandlers/retract-configure-woh/#configurableretractworkflowoperationhandler","text":"","title":"ConfigurableRetractWorkflowOperationHandler"},{"location":"workflowoperationhandlers/retract-configure-woh/#description","text":"The ConfigurableRetractWorkflowOperationHandler retracts the published elements from a configured publication. If the elements have been added to the Publication using \"with-published-elements\", as in the case with the external api, they haven't actually been published so it is unnecessary to have a retract-configuration. Adding a retraction won't cause any errors, it will just skip those elements. There is only one configuration key \"channel-id\". This is the channel to remove the published elements from.","title":"Description"},{"location":"workflowoperationhandlers/retract-configure-woh/#operation-examples","text":"","title":"Operation Examples"},{"location":"workflowoperationhandlers/retract-configure-woh/#retract-from-internal-channel","text":"<!-- Remove the internal publication if the mediapackage is being deleted. --> <operation id=\"retract-configure\" exception-handler-workflow=\"partial-error\" description=\"Retract from internal publication channel\"> <configurations> <configuration key=\"channel-id\">internal</configuration> </configurations> </operation>","title":"Retract from Internal Channel"},{"location":"workflowoperationhandlers/retract-configure-woh/#retract-from-external-api","text":"<operation id=\"retract-configure\" exception-handler-workflow=\"partial-error\" description=\"Retract from external api publication channel\"> <configurations> <configuration key=\"channel-id\">api</configuration> </configurations> </operation>","title":"Retract from External API"},{"location":"workflowoperationhandlers/retract-engage-woh/","text":"RetractEngageWorkflowOperationHandler Description The RetractEngageWorkflowOperationHandler retracts the published elements from the local Opencast Media Module. There are no configuration keys at this time. Operation Examples Retract <!-- Retract from engage player --> <operation id=\"retract-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Retract recording from Engage\"> </operation>","title":"Retract Engage"},{"location":"workflowoperationhandlers/retract-engage-woh/#retractengageworkflowoperationhandler","text":"","title":"RetractEngageWorkflowOperationHandler"},{"location":"workflowoperationhandlers/retract-engage-woh/#description","text":"The RetractEngageWorkflowOperationHandler retracts the published elements from the local Opencast Media Module. There are no configuration keys at this time.","title":"Description"},{"location":"workflowoperationhandlers/retract-engage-woh/#operation-examples","text":"","title":"Operation Examples"},{"location":"workflowoperationhandlers/retract-engage-woh/#retract","text":"<!-- Retract from engage player --> <operation id=\"retract-engage\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Retract recording from Engage\"> </operation>","title":"Retract"},{"location":"workflowoperationhandlers/retract-oaipmh-woh/","text":"RetractOaiPmhWorkflowOperation Description The Retract OAI-PMH workflow operation retracts the published elements from a OAI-PMH repository. Parameter Table Configuration Keys Description repository The name of the OAI-PMH repository where the media should be retracted from Operation Examples <operation id=\"retract-oaipmh\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Retract event from the OAI-PMH repository\"> <configurations> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Retract OAI-PMH"},{"location":"workflowoperationhandlers/retract-oaipmh-woh/#retractoaipmhworkflowoperation","text":"","title":"RetractOaiPmhWorkflowOperation"},{"location":"workflowoperationhandlers/retract-oaipmh-woh/#description","text":"The Retract OAI-PMH workflow operation retracts the published elements from a OAI-PMH repository.","title":"Description"},{"location":"workflowoperationhandlers/retract-oaipmh-woh/#parameter-table","text":"Configuration Keys Description repository The name of the OAI-PMH repository where the media should be retracted from","title":"Parameter Table"},{"location":"workflowoperationhandlers/retract-oaipmh-woh/#operation-examples","text":"<operation id=\"retract-oaipmh\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Retract event from the OAI-PMH repository\"> <configurations> <configuration key=\"repository\">default</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/retract-youtube-woh/","text":"RetractYoutubeWorkflowOperation Description The RetractYoutubeWorkflowOperationHandler retracts the published elements from YouTube. There are no configuration keys at this time. Operation Example <operation id=\"retract-youtube\" fail-on-error=\"true\" exception-handler-workflow=\"ng-partial-error\" description=\"Retract recording from YouTube\"> </operation>","title":"Retract YouTube"},{"location":"workflowoperationhandlers/retract-youtube-woh/#retractyoutubeworkflowoperation","text":"","title":"RetractYoutubeWorkflowOperation"},{"location":"workflowoperationhandlers/retract-youtube-woh/#description","text":"The RetractYoutubeWorkflowOperationHandler retracts the published elements from YouTube. There are no configuration keys at this time.","title":"Description"},{"location":"workflowoperationhandlers/retract-youtube-woh/#operation-example","text":"<operation id=\"retract-youtube\" fail-on-error=\"true\" exception-handler-workflow=\"ng-partial-error\" description=\"Retract recording from YouTube\"> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/retry-strategies/","text":"Retry Strategies An operation can have a retry-strategy specified to define what will happen if the operation fails : Strategy Description none This is the default. No action taken. If the operation fails, the behavior will depend on the fail-on-error parameter. If fail-on-error=\"true\", the workflow will fail. If fail-on-error=\"false\", the next operation will be executed. retry If the operation fails, it will be re-tried until the number of attempts reaches max-attempts, which defaults to 2. hold If the operation fails, the workflow will be paused, until the user takes an action. The user can choose to Retry the operation or Abort it. The user can retry the operation many times, until the number of attempts reaches max-attempts. If the user aborts the operation, the behavior will depend on the fail-on-error parameter as described above. Example 1 : No retry If the operation1 fails, the workflow will fail because fail-on-error=\"true\". <operation id=\"operation1\" retry-strategy=\"none\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Operation One\"> </operation> Example 2 : Automatic retry If operation2 fails, it will be retried until it succeeds or until it has failed 5 times. <operation id=\"operation2\" retry-strategy=\"retry\" max-attempts=\"5\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Operation Two\"> </operation> Example 3 : Manual retry If operation3 fails, the user can choose between Retry or Abort. The user can manually retry the operation 4 times. <operation id=\"operation3\" retry-strategy=\"hold\" max-attempts=\"5\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Operation Three\"> </operation>","title":"Retry Strategies"},{"location":"workflowoperationhandlers/retry-strategies/#retry-strategies","text":"An operation can have a retry-strategy specified to define what will happen if the operation fails : Strategy Description none This is the default. No action taken. If the operation fails, the behavior will depend on the fail-on-error parameter. If fail-on-error=\"true\", the workflow will fail. If fail-on-error=\"false\", the next operation will be executed. retry If the operation fails, it will be re-tried until the number of attempts reaches max-attempts, which defaults to 2. hold If the operation fails, the workflow will be paused, until the user takes an action. The user can choose to Retry the operation or Abort it. The user can retry the operation many times, until the number of attempts reaches max-attempts. If the user aborts the operation, the behavior will depend on the fail-on-error parameter as described above. Example 1 : No retry If the operation1 fails, the workflow will fail because fail-on-error=\"true\". <operation id=\"operation1\" retry-strategy=\"none\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Operation One\"> </operation> Example 2 : Automatic retry If operation2 fails, it will be retried until it succeeds or until it has failed 5 times. <operation id=\"operation2\" retry-strategy=\"retry\" max-attempts=\"5\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Operation Two\"> </operation> Example 3 : Manual retry If operation3 fails, the user can choose between Retry or Abort. The user can manually retry the operation 4 times. <operation id=\"operation3\" retry-strategy=\"hold\" max-attempts=\"5\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Operation Three\"> </operation>","title":"Retry Strategies"},{"location":"workflowoperationhandlers/segmentpreviews-woh/","text":"SegmentpreviewsWorkflowOperation Description The SegmentpreviewsWorkflowOperation will extract still images from a video using FFmpeg, a given encoding profile and previous discovered segments. Parameter Table configuration keys example description source-flavor presenter/source Specifies which media should be processed. target-flavor presenter/work Specifies the flavor the new files will get. source-tags engage Specifies which media should be processed. target-tags engage Specifies the tags the new files will get. encoding-profile search-cover.http The encoding profile to use. reference-flavor presentation/work Flavor of the segments to use. reference-tags engage Tags of the segments to use. Operation Example <operation id=\"segmentpreviews\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Encoding presentation (screen) to segment preview image\"> <configurations> <configuration key=\"source-flavor\">presentation/trimmed</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">presentation/segment+preview</configuration> <configuration key=\"reference-flavor\">presentation/delivery</configuration> <configuration key=\"reference-tags\">engage</configuration> <configuration key=\"target-tags\">engage</configuration> <configuration key=\"encoding-profile\">player-slides.http</configuration> </configurations> </operation>","title":"Segment Previews"},{"location":"workflowoperationhandlers/segmentpreviews-woh/#segmentpreviewsworkflowoperation","text":"","title":"SegmentpreviewsWorkflowOperation"},{"location":"workflowoperationhandlers/segmentpreviews-woh/#description","text":"The SegmentpreviewsWorkflowOperation will extract still images from a video using FFmpeg, a given encoding profile and previous discovered segments.","title":"Description"},{"location":"workflowoperationhandlers/segmentpreviews-woh/#parameter-table","text":"configuration keys example description source-flavor presenter/source Specifies which media should be processed. target-flavor presenter/work Specifies the flavor the new files will get. source-tags engage Specifies which media should be processed. target-tags engage Specifies the tags the new files will get. encoding-profile search-cover.http The encoding profile to use. reference-flavor presentation/work Flavor of the segments to use. reference-tags engage Tags of the segments to use.","title":"Parameter Table"},{"location":"workflowoperationhandlers/segmentpreviews-woh/#operation-example","text":"<operation id=\"segmentpreviews\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Encoding presentation (screen) to segment preview image\"> <configurations> <configuration key=\"source-flavor\">presentation/trimmed</configuration> <configuration key=\"source-tags\"></configuration> <configuration key=\"target-flavor\">presentation/segment+preview</configuration> <configuration key=\"reference-flavor\">presentation/delivery</configuration> <configuration key=\"reference-tags\">engage</configuration> <configuration key=\"target-tags\">engage</configuration> <configuration key=\"encoding-profile\">player-slides.http</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/segmentvideo-woh/","text":"SegmentVideoWorkflowOperation Description The SegmentVideoWorkflowOperation will try to identify and mark different segments of a video. A new segment is created when a major change in the video occurs. This might be the case for example if the video is a screenrecording and the slides which were shown change. Parameter Table configuration keys example description source-flavor presentation/trimmed Specifies which media should be processed. Operation Example <operation id=\"segment-video\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Extracting segments from presentation\"> <configurations> <configuration key=\"source-flavor\">presentation/trimmed</configuration> </configurations> </operation>","title":"Segment Video"},{"location":"workflowoperationhandlers/segmentvideo-woh/#segmentvideoworkflowoperation","text":"","title":"SegmentVideoWorkflowOperation"},{"location":"workflowoperationhandlers/segmentvideo-woh/#description","text":"The SegmentVideoWorkflowOperation will try to identify and mark different segments of a video. A new segment is created when a major change in the video occurs. This might be the case for example if the video is a screenrecording and the slides which were shown change.","title":"Description"},{"location":"workflowoperationhandlers/segmentvideo-woh/#parameter-table","text":"configuration keys example description source-flavor presentation/trimmed Specifies which media should be processed.","title":"Parameter Table"},{"location":"workflowoperationhandlers/segmentvideo-woh/#operation-example","text":"<operation id=\"segment-video\" fail-on-error=\"false\" exception-handler-workflow=\"error\" description=\"Extracting segments from presentation\"> <configurations> <configuration key=\"source-flavor\">presentation/trimmed</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/select-streams-woh/","text":"SelectStreamsWorkflowOperationHandler Description The SelectStreamsWorkflowOperationHandler can be used in case not all source streams should be processed. For example, given a recording with a presenter and a presentation track, the final recording to be published should only include the video stream of the presenter track and the audio stream of the presentation track. The workflow operation will use workflow properties set by the Opencast video editor to determine which streams should be selected for further processing and add them to the media package based on target-flavor and target-tags . IMPORTANT: The input tracks need to be inspected using the workflow operation inspect before running this operation. Parameter Table Configuration Key Example Description source-flavor* */source The flavor of the track(s) to use as a source input target-flavor* */work The flavor of the target track(s) target-tags download The tags applied to all target tracks audio-muxing force Move single-audio media packages to a specific track (see below) force-target presenter Target track for the force setting for audio-muxing * mandatory configuration key Workflow Properties The names of the workflow properties that control which streams are included in the output tracks are \"hide_\" + source-flavor.type + \"_audio\" \"hide_\" + source-flavor.type + \"_video\" Example: For the source flavor presenter/work , use the boolean workflow properties hide_presenter_audio and hide_presenter_video to control which streams should be included in the output tracks. Those properties are set by the Opencast video editor and can also be set using a custom workflow configuration panel. Audio Muxing The optional audio-muxing parameter has three possible values: none (same as omitting the option), force and duplicate . none If none is specified or the option is omitted, the audio stream is taken from the specified source-flavor track and is edited according to the selections in video editor\u2019s \u201cTracks\u201d panel. The resulting tracks are stored in the corresponding target-flavor and target-tags are applied. Note: If your editing results in a single video and single audio (track/stream) they will be muxed together even if this option is set to none . force The parameter value force only applies to media packages that have exactly one non-hidden audio stream. For media packages without an audio stream or with more than one audio stream, the behavior is the same as if the parameter were omitted. The same applies to media packages for which there is only one audio stream, and it already belongs to the track with flavor type given by force-target (or presenter if that parameter is omitted). If, however, there is only one non-hidden audio stream and it does not belong to the track given by force-target , then the WOH will \u201cmove\u201d the audio stream to this target track. Specifically, it will mux the video stream of force-target with the audio stream it found. Then, it removes the audio stream from the original track. For example, consider a media package with two tracks, presenter and presentation . Both of these tracks have audio components, however the presenter audio stream is hidden. This WOH will mux presentations 's audio stream with presenter 's video, and remove the audio track from presentation 's video. duplicate The parameter value duplicate only applies to media packages that have exactly one non-hidden audio stream and no hidden video streams. For these media packages, the WOH will mux the audio stream it found to all video streams in the media package. For media packages without an audio stream or with more than one audio stream, the behavior is the same as if the parameter were omitted. Encoding Profiles This workflow operation handler depends on the presence of the following encoding profiles: Name Description video-only.work Removes all audio streams from a media track audio-only.work Removes all video streams from a media track mux-av.work Mux a video stream and an audio stream into a media track Note that those encoding profiles are included in the default configuration of Opencast. Operation Example <operation id=\"select-tracks\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Select tracks for further processing\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-flavor\">*/work</configuration> <configuration key=\"audio-muxing\">force</configuration> </configurations> </operation>","title":"Select Streams"},{"location":"workflowoperationhandlers/select-streams-woh/#selectstreamsworkflowoperationhandler","text":"","title":"SelectStreamsWorkflowOperationHandler"},{"location":"workflowoperationhandlers/select-streams-woh/#description","text":"The SelectStreamsWorkflowOperationHandler can be used in case not all source streams should be processed. For example, given a recording with a presenter and a presentation track, the final recording to be published should only include the video stream of the presenter track and the audio stream of the presentation track. The workflow operation will use workflow properties set by the Opencast video editor to determine which streams should be selected for further processing and add them to the media package based on target-flavor and target-tags . IMPORTANT: The input tracks need to be inspected using the workflow operation inspect before running this operation.","title":"Description"},{"location":"workflowoperationhandlers/select-streams-woh/#parameter-table","text":"Configuration Key Example Description source-flavor* */source The flavor of the track(s) to use as a source input target-flavor* */work The flavor of the target track(s) target-tags download The tags applied to all target tracks audio-muxing force Move single-audio media packages to a specific track (see below) force-target presenter Target track for the force setting for audio-muxing * mandatory configuration key","title":"Parameter Table"},{"location":"workflowoperationhandlers/select-streams-woh/#workflow-properties","text":"The names of the workflow properties that control which streams are included in the output tracks are \"hide_\" + source-flavor.type + \"_audio\" \"hide_\" + source-flavor.type + \"_video\" Example: For the source flavor presenter/work , use the boolean workflow properties hide_presenter_audio and hide_presenter_video to control which streams should be included in the output tracks. Those properties are set by the Opencast video editor and can also be set using a custom workflow configuration panel.","title":"Workflow Properties"},{"location":"workflowoperationhandlers/select-streams-woh/#audio-muxing","text":"The optional audio-muxing parameter has three possible values: none (same as omitting the option), force and duplicate .","title":"Audio Muxing"},{"location":"workflowoperationhandlers/select-streams-woh/#none","text":"If none is specified or the option is omitted, the audio stream is taken from the specified source-flavor track and is edited according to the selections in video editor\u2019s \u201cTracks\u201d panel. The resulting tracks are stored in the corresponding target-flavor and target-tags are applied. Note: If your editing results in a single video and single audio (track/stream) they will be muxed together even if this option is set to none .","title":"none"},{"location":"workflowoperationhandlers/select-streams-woh/#force","text":"The parameter value force only applies to media packages that have exactly one non-hidden audio stream. For media packages without an audio stream or with more than one audio stream, the behavior is the same as if the parameter were omitted. The same applies to media packages for which there is only one audio stream, and it already belongs to the track with flavor type given by force-target (or presenter if that parameter is omitted). If, however, there is only one non-hidden audio stream and it does not belong to the track given by force-target , then the WOH will \u201cmove\u201d the audio stream to this target track. Specifically, it will mux the video stream of force-target with the audio stream it found. Then, it removes the audio stream from the original track. For example, consider a media package with two tracks, presenter and presentation . Both of these tracks have audio components, however the presenter audio stream is hidden. This WOH will mux presentations 's audio stream with presenter 's video, and remove the audio track from presentation 's video.","title":"force"},{"location":"workflowoperationhandlers/select-streams-woh/#duplicate","text":"The parameter value duplicate only applies to media packages that have exactly one non-hidden audio stream and no hidden video streams. For these media packages, the WOH will mux the audio stream it found to all video streams in the media package. For media packages without an audio stream or with more than one audio stream, the behavior is the same as if the parameter were omitted.","title":"duplicate"},{"location":"workflowoperationhandlers/select-streams-woh/#encoding-profiles","text":"This workflow operation handler depends on the presence of the following encoding profiles: Name Description video-only.work Removes all audio streams from a media track audio-only.work Removes all video streams from a media track mux-av.work Mux a video stream and an audio stream into a media track Note that those encoding profiles are included in the default configuration of Opencast.","title":"Encoding Profiles"},{"location":"workflowoperationhandlers/select-streams-woh/#operation-example","text":"<operation id=\"select-tracks\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Select tracks for further processing\"> <configurations> <configuration key=\"source-flavor\">*/source</configuration> <configuration key=\"target-flavor\">*/work</configuration> <configuration key=\"audio-muxing\">force</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/send-email-woh/","text":"EmailWorkflowOperation Description The EmailWorkflowOperationHandler invokes the SMTP Service to send an email with the parameters provided. It is useful to send email notifications when some operation(s) have been completed or some error(s) have occurred in a workflow. The email body, if not specified by body or body-template-file, will consist of a single line of the form: <Recording Title> (<Mediapackage ID>) . Freemarker templates can be used in the following fields to allow replacement with values obtained from the workflow or media package: to, cc, bcc, subject, and body. If body-template-file is specified, the operation will use a Freemarker template file located in <config_dir>/etc/email to generate the email body. User names can be provided in to , cc , or bcc in lieu of email addresses so that the user directory is searched and that user's email address is used (see Example 5). Parameter Table configuration keys description default value example body Email body content. Takes precedence over body-template-file. <Recording Title> (<Mediapackage ID>) Lecture 1 (4bf316fc-ea78-4903-b00e-9976b0912e4d) body-template-file Name of file that will be used as a template for the content of the email body. EMPTY templateName subject Email subject. EMPTY Operation has been completed to The field to of the email i.e. the comma separated list of email accounts the email will be sent to. EMPTY email-account@email-domain.org,second-account@second-domain.org cc The field cc of the email i.e. the comma separated list of email accounts that will receive a carbon copy of the email. EMPTY email-account@email-domain.org,second-account@second-domain.org bcc The field bcc of the email i.e. the comma separated list of email accounts that will receive a blind carbon copy of the email. EMPTY email-account@email-domain.org,second-account@second-domain.org use-html Flag to indicate that the email content should be displayed as 'text/html' false true/false Some other email parameters can be customized in the SMTP Service configuration Variable Substitution The template will have access to the media package, workflow instance (including its configuration properties and last failed operation), catalogs, and any incidents. Fields should be tested for null/empty values before being used. Media Package Information Use ${mediaPackage.FIELD} Examples Field How To Get It media package id ${mediaPackage.identifier} recording title ${mediaPackage.title} recording date and time ${mediaPackage.date?datetime?iso_utc} - See Freemarker manual for date manipulation (extract date only, time only, format, etc) series title ${mediaPackage.seriesTitle} series id ${mediaPackage.series} Workflow Information Use ${workflow.FIELD} Examples Field How To Get It workflow id ${workflow.id} workflow name ${workflow.template} Workflow Configuration Properties Use ${workflowConfig['PROPERTY']} Last Failed Operation Operation that caused the workflow to fail. Should be tested before accessing any of its fields: <#if failedOperation?has_content>Workflow failed in operation: ${failedOperation.template}</#if> Incidents In your email template: <#if incident?has_content> <#list incident as inc> <#list inc.details as dets>${dets.b}</#list> </#list> </#if> Catalog fields Use ${catalogs['SUBTYPE']['FIELD']} Examples Field How To Get It episode creator ${catalogs['episode']['creator']} episode title ${catalogs['episode']['title']} series creator ${catalogs['series']['creator']} series title ${catalogs['series']['title']} Examples Example 1 Media package title in subject field, default email body. <operation id=\"send-email\" fail-on-error=\"false\" exception-handler-workflow=\"email-error\" description=\"Sending email to user after media package is published\"> <configurations> <configuration key=\"to\">email-account@email-domain.org</configuration> <!-- This is going to be replaced with the media package title --> <configuration key=\"subject\">${mediaPackage.title} has been published</configuration> <!-- Neither body or body-template-file specified so default body <Recording Title> (<Mediapackage ID>)<br>is sent --> </configurations> </operation> Example 2 To and subject are inline templates; the email body uses a template file named sample stored in \u2026/etc/email : <operation id=\"send-email\" fail-on-error=\"false\" exception-handler-workflow=\"email-error\" description=\"Sending email to user before holding for edit\"> <configurations> <!-- This is going to be replaced with the episode catalog publisher field, which in this example it is assumed it contains a notification email address --> <configuration key=\"to\">${catalogs['episode']['publisher']}</configuration> <!-- This is going to be replaced with the episode catalog title field --> <configuration key=\"subject\">${catalogs['episode']['title']} is ready for EDIT</configuration> <!-- Email body is going to be built using the sample template found in <config_dir>/etc/email --> <configuration key=\"body-template-file\">sample</configuration> </configurations> </operation> Template: sample The contents of the \u2026/etc/email/sample email template: Event Details <#if catalogs['series']?has_content> Series Title: ${catalogs['series']['title']} Instructor: ${catalogs['series']['contributor']} </#if> Media Package Id: ${mediaPackage.identifier} Title: ${mediaPackage.title} Workflow Id: ${workflow.id} Event Date: ${mediaPackage.date?datetime?iso_local} Example 3 Email address entered via admin UI as a workflow configuration parameter: <operation id=\"send-email\" fail-on-error=\"false\" exception-handler-workflow=\"email-error\" description=\"Sends email\"> <configurations> <configuration key=\"to\">${workflowConfig['emailAddress']}</configuration> <configuration key=\"subject\">Media package has been published</configuration> <configuration key=\"body-template-file\">sample</configuration> </configurations> </operation> Workflow Configuration Panel: <configuration_panel> <![CDATA[ <!-- Add after the other configuration fields (Holds, Archive, etc) --> <fieldset> <legend>Notification</legend> <ul class=\"oc-ui-form-list\"> <li class=\"ui-helper-clearfix\"> <label class=\"scheduler-label\"> <span class=\"color-red\">* </span><span id=\"i18n_email_label\">Email Address</span>: </label> <span id=\"emailconfig\"> <input id=\"emailAddress\" name=\"emailAddress\" type=\"text\" class=\"configField\" value=\"my-email-account@my-email-domain.org\"/> </span> </li> </ul> </fieldset> <script type=\"text/javascript\"> // Add email variable var emailAddress = $('input#emailAddress'); // Register email configuration property ocWorkflowPanel.registerComponents = function(components){ /* components with keys that begin with 'org.opencastproject.workflow.config' will be passed * into the workflow. The component's nodeKey must match the components array key. * * Example:'org.opencastproject.workflow.config.myProperty' will be availible at ${my.property} */ // After the other components (Hold, Archive, etc), add: components['org.opencastproject.workflow.config.emailAddress'] = new ocAdmin.Component( ['emailAddress'], {key: 'org.opencastproject.workflow.config.emailAddress'}, {getValue: function(){ return this.fields.emailAddress.value;} }); //etc... } ocWorkflowPanel.setComponentValues = function(values, components){ // After the other components (Hold, Archive, etc), add: components['org.opencastproject.workflow.config.emailAddress'].setValue( values['org.opencastproject.workflow.config.emailAddress']); } </script> ]]> </configuration_panel> Example 4 In error handling workflow (email-error): <operation id=\"send-email\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Sends email\"> <configurations> <!-- Note that you can use variable substitution in to, subject, body e.g. ${(catalogs['episode']['FIELD']!'root@localhost'} --> <configuration key=\"to\">root@localhost</configuration> <configuration key=\"subject\">Failure processing a mediapackage</configuration> <configuration key=\"body-template-file\">errorDetails</configuration> </configurations> </operation> Template: errorDetails The contents of the /etc/email/errorDetails email template: Error Details <#if catalogs['series']?has_content> Course: ${catalogs['series']['subject']!'series subject missing'}-${catalogs['series']['title']!'series title missing'} Instructor: ${catalogs['series']['contributor']!'instructor missing'} </#if> Title: ${catalogs['episode']['title']!'title missing'} Event Date: ${mediaPackage.date?datetime?iso_local} <#if failedOperation?has_content> Workflow failed in operation: ${failedOperation.position}-${failedOperation.template} Started: ${failedOperation.dateStarted?datetime?iso_local} Ended: ${failedOperation.dateCompleted?datetime?iso_local} Execution Host: ${failedOperation.executionHost} </#if> Logged incident of the error looks like this: <#if incident?has_content> <#list incident as inc> <#list inc.details as dets>${dets.b} </#list> </#list> </#if> Example 5 The user name is stored in the episode dublin core contributor field. There's a user jharvard with email jharvard@harvard.edu defined in the system. The message will be sent to jharvard@harvard.edu : <operation id=\"send-email\" fail-on-error=\"false\" description=\"Notify user associated to this recording that it is ready to be trimmed\"> <configurations> <configuration key=\"to\">${(catalogs['episode']['contributor'])}</configuration> <configuration key=\"subject\">Recording is ready for EDIT</configuration> <configuration key=\"body-template-file\">eventDetails</configuration> </configurations> </operation> Episode Dublin Core <?xml version=\"1.0\" encoding=\"UTF-8\"?> <dublincore xmlns=\"http://www.opencastproject.org/xsd/1.0/dublincore/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <dcterms:contributor>jharvard</dcterms:contributor> <dcterms:created>2018-05-01T16:14:00Z</dcterms:created> <dcterms:extent xsi:type=\"dcterms:ISO8601\">PT17M1.933S</dcterms:extent> <dcterms:isPartOf>20180229999</dcterms:isPartOf> <dcterms:spatial>classroom-20</dcterms:spatial> <dcterms:temporal>start=2018-05-01T16:14:00Z; end=2018-05-01T16:31:00Z; scheme=W3C-DTF;</dcterms:temporal> <dcterms:title>Test Lecture</dcterms:title> </dublincore>","title":"Send Email"},{"location":"workflowoperationhandlers/send-email-woh/#emailworkflowoperation","text":"","title":"EmailWorkflowOperation"},{"location":"workflowoperationhandlers/send-email-woh/#description","text":"The EmailWorkflowOperationHandler invokes the SMTP Service to send an email with the parameters provided. It is useful to send email notifications when some operation(s) have been completed or some error(s) have occurred in a workflow. The email body, if not specified by body or body-template-file, will consist of a single line of the form: <Recording Title> (<Mediapackage ID>) . Freemarker templates can be used in the following fields to allow replacement with values obtained from the workflow or media package: to, cc, bcc, subject, and body. If body-template-file is specified, the operation will use a Freemarker template file located in <config_dir>/etc/email to generate the email body. User names can be provided in to , cc , or bcc in lieu of email addresses so that the user directory is searched and that user's email address is used (see Example 5).","title":"Description"},{"location":"workflowoperationhandlers/send-email-woh/#parameter-table","text":"configuration keys description default value example body Email body content. Takes precedence over body-template-file. <Recording Title> (<Mediapackage ID>) Lecture 1 (4bf316fc-ea78-4903-b00e-9976b0912e4d) body-template-file Name of file that will be used as a template for the content of the email body. EMPTY templateName subject Email subject. EMPTY Operation has been completed to The field to of the email i.e. the comma separated list of email accounts the email will be sent to. EMPTY email-account@email-domain.org,second-account@second-domain.org cc The field cc of the email i.e. the comma separated list of email accounts that will receive a carbon copy of the email. EMPTY email-account@email-domain.org,second-account@second-domain.org bcc The field bcc of the email i.e. the comma separated list of email accounts that will receive a blind carbon copy of the email. EMPTY email-account@email-domain.org,second-account@second-domain.org use-html Flag to indicate that the email content should be displayed as 'text/html' false true/false Some other email parameters can be customized in the SMTP Service configuration","title":"Parameter Table"},{"location":"workflowoperationhandlers/send-email-woh/#variable-substitution","text":"The template will have access to the media package, workflow instance (including its configuration properties and last failed operation), catalogs, and any incidents. Fields should be tested for null/empty values before being used.","title":"Variable Substitution"},{"location":"workflowoperationhandlers/send-email-woh/#media-package-information","text":"Use ${mediaPackage.FIELD}","title":"Media Package Information"},{"location":"workflowoperationhandlers/send-email-woh/#examples","text":"Field How To Get It media package id ${mediaPackage.identifier} recording title ${mediaPackage.title} recording date and time ${mediaPackage.date?datetime?iso_utc} - See Freemarker manual for date manipulation (extract date only, time only, format, etc) series title ${mediaPackage.seriesTitle} series id ${mediaPackage.series}","title":"Examples"},{"location":"workflowoperationhandlers/send-email-woh/#workflow-information","text":"Use ${workflow.FIELD}","title":"Workflow Information"},{"location":"workflowoperationhandlers/send-email-woh/#examples_1","text":"Field How To Get It workflow id ${workflow.id} workflow name ${workflow.template}","title":"Examples"},{"location":"workflowoperationhandlers/send-email-woh/#workflow-configuration-properties","text":"Use ${workflowConfig['PROPERTY']}","title":"Workflow Configuration Properties"},{"location":"workflowoperationhandlers/send-email-woh/#last-failed-operation","text":"Operation that caused the workflow to fail. Should be tested before accessing any of its fields: <#if failedOperation?has_content>Workflow failed in operation: ${failedOperation.template}</#if>","title":"Last Failed Operation"},{"location":"workflowoperationhandlers/send-email-woh/#incidents","text":"In your email template: <#if incident?has_content> <#list incident as inc> <#list inc.details as dets>${dets.b}</#list> </#list> </#if>","title":"Incidents"},{"location":"workflowoperationhandlers/send-email-woh/#catalog-fields","text":"Use ${catalogs['SUBTYPE']['FIELD']}","title":"Catalog fields"},{"location":"workflowoperationhandlers/send-email-woh/#examples_2","text":"Field How To Get It episode creator ${catalogs['episode']['creator']} episode title ${catalogs['episode']['title']} series creator ${catalogs['series']['creator']} series title ${catalogs['series']['title']}","title":"Examples"},{"location":"workflowoperationhandlers/send-email-woh/#examples_3","text":"","title":"Examples"},{"location":"workflowoperationhandlers/send-email-woh/#example-1","text":"Media package title in subject field, default email body. <operation id=\"send-email\" fail-on-error=\"false\" exception-handler-workflow=\"email-error\" description=\"Sending email to user after media package is published\"> <configurations> <configuration key=\"to\">email-account@email-domain.org</configuration> <!-- This is going to be replaced with the media package title --> <configuration key=\"subject\">${mediaPackage.title} has been published</configuration> <!-- Neither body or body-template-file specified so default body <Recording Title> (<Mediapackage ID>)<br>is sent --> </configurations> </operation>","title":"Example 1"},{"location":"workflowoperationhandlers/send-email-woh/#example-2","text":"To and subject are inline templates; the email body uses a template file named sample stored in \u2026/etc/email : <operation id=\"send-email\" fail-on-error=\"false\" exception-handler-workflow=\"email-error\" description=\"Sending email to user before holding for edit\"> <configurations> <!-- This is going to be replaced with the episode catalog publisher field, which in this example it is assumed it contains a notification email address --> <configuration key=\"to\">${catalogs['episode']['publisher']}</configuration> <!-- This is going to be replaced with the episode catalog title field --> <configuration key=\"subject\">${catalogs['episode']['title']} is ready for EDIT</configuration> <!-- Email body is going to be built using the sample template found in <config_dir>/etc/email --> <configuration key=\"body-template-file\">sample</configuration> </configurations> </operation>","title":"Example 2"},{"location":"workflowoperationhandlers/send-email-woh/#template-sample","text":"The contents of the \u2026/etc/email/sample email template: Event Details <#if catalogs['series']?has_content> Series Title: ${catalogs['series']['title']} Instructor: ${catalogs['series']['contributor']} </#if> Media Package Id: ${mediaPackage.identifier} Title: ${mediaPackage.title} Workflow Id: ${workflow.id} Event Date: ${mediaPackage.date?datetime?iso_local}","title":"Template: sample"},{"location":"workflowoperationhandlers/send-email-woh/#example-3","text":"Email address entered via admin UI as a workflow configuration parameter: <operation id=\"send-email\" fail-on-error=\"false\" exception-handler-workflow=\"email-error\" description=\"Sends email\"> <configurations> <configuration key=\"to\">${workflowConfig['emailAddress']}</configuration> <configuration key=\"subject\">Media package has been published</configuration> <configuration key=\"body-template-file\">sample</configuration> </configurations> </operation> Workflow Configuration Panel: <configuration_panel> <![CDATA[ <!-- Add after the other configuration fields (Holds, Archive, etc) --> <fieldset> <legend>Notification</legend> <ul class=\"oc-ui-form-list\"> <li class=\"ui-helper-clearfix\"> <label class=\"scheduler-label\"> <span class=\"color-red\">* </span><span id=\"i18n_email_label\">Email Address</span>: </label> <span id=\"emailconfig\"> <input id=\"emailAddress\" name=\"emailAddress\" type=\"text\" class=\"configField\" value=\"my-email-account@my-email-domain.org\"/> </span> </li> </ul> </fieldset> <script type=\"text/javascript\"> // Add email variable var emailAddress = $('input#emailAddress'); // Register email configuration property ocWorkflowPanel.registerComponents = function(components){ /* components with keys that begin with 'org.opencastproject.workflow.config' will be passed * into the workflow. The component's nodeKey must match the components array key. * * Example:'org.opencastproject.workflow.config.myProperty' will be availible at ${my.property} */ // After the other components (Hold, Archive, etc), add: components['org.opencastproject.workflow.config.emailAddress'] = new ocAdmin.Component( ['emailAddress'], {key: 'org.opencastproject.workflow.config.emailAddress'}, {getValue: function(){ return this.fields.emailAddress.value;} }); //etc... } ocWorkflowPanel.setComponentValues = function(values, components){ // After the other components (Hold, Archive, etc), add: components['org.opencastproject.workflow.config.emailAddress'].setValue( values['org.opencastproject.workflow.config.emailAddress']); } </script> ]]> </configuration_panel>","title":"Example 3"},{"location":"workflowoperationhandlers/send-email-woh/#example-4","text":"In error handling workflow (email-error): <operation id=\"send-email\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Sends email\"> <configurations> <!-- Note that you can use variable substitution in to, subject, body e.g. ${(catalogs['episode']['FIELD']!'root@localhost'} --> <configuration key=\"to\">root@localhost</configuration> <configuration key=\"subject\">Failure processing a mediapackage</configuration> <configuration key=\"body-template-file\">errorDetails</configuration> </configurations> </operation>","title":"Example 4"},{"location":"workflowoperationhandlers/send-email-woh/#template-errordetails","text":"The contents of the /etc/email/errorDetails email template: Error Details <#if catalogs['series']?has_content> Course: ${catalogs['series']['subject']!'series subject missing'}-${catalogs['series']['title']!'series title missing'} Instructor: ${catalogs['series']['contributor']!'instructor missing'} </#if> Title: ${catalogs['episode']['title']!'title missing'} Event Date: ${mediaPackage.date?datetime?iso_local} <#if failedOperation?has_content> Workflow failed in operation: ${failedOperation.position}-${failedOperation.template} Started: ${failedOperation.dateStarted?datetime?iso_local} Ended: ${failedOperation.dateCompleted?datetime?iso_local} Execution Host: ${failedOperation.executionHost} </#if> Logged incident of the error looks like this: <#if incident?has_content> <#list incident as inc> <#list inc.details as dets>${dets.b} </#list> </#list> </#if>","title":"Template: errorDetails"},{"location":"workflowoperationhandlers/send-email-woh/#example-5","text":"The user name is stored in the episode dublin core contributor field. There's a user jharvard with email jharvard@harvard.edu defined in the system. The message will be sent to jharvard@harvard.edu : <operation id=\"send-email\" fail-on-error=\"false\" description=\"Notify user associated to this recording that it is ready to be trimmed\"> <configurations> <configuration key=\"to\">${(catalogs['episode']['contributor'])}</configuration> <configuration key=\"subject\">Recording is ready for EDIT</configuration> <configuration key=\"body-template-file\">eventDetails</configuration> </configurations> </operation>","title":"Example 5"},{"location":"workflowoperationhandlers/send-email-woh/#episode-dublin-core","text":"<?xml version=\"1.0\" encoding=\"UTF-8\"?> <dublincore xmlns=\"http://www.opencastproject.org/xsd/1.0/dublincore/\" xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"> <dcterms:contributor>jharvard</dcterms:contributor> <dcterms:created>2018-05-01T16:14:00Z</dcterms:created> <dcterms:extent xsi:type=\"dcterms:ISO8601\">PT17M1.933S</dcterms:extent> <dcterms:isPartOf>20180229999</dcterms:isPartOf> <dcterms:spatial>classroom-20</dcterms:spatial> <dcterms:temporal>start=2018-05-01T16:14:00Z; end=2018-05-01T16:31:00Z; scheme=W3C-DTF;</dcterms:temporal> <dcterms:title>Test Lecture</dcterms:title> </dublincore>","title":"Episode Dublin Core"},{"location":"workflowoperationhandlers/series-woh/","text":"SeriesWorkflowOperationHandler Description The SeriesWorkflowOperation will apply a series to the mediapackage. Parameter Table configuration keys example description default value series 0d06537e-09d3-420c-8314-a21e45c5d032 The optional series identifier. If empty the current series of the medipackage will be taken. attach creativecommons/*,dublincore/* The flavors of the series catalogs to attach to the mediapackage. apply-acl true Whether the ACL should be applied or not. false copy-metadata {http://purl.org/dc/terms/}title, isPartOf A comma-separated list of metadata fields (possibly \"expanded\") to be transferred from the series catalog to the episode catalog if they do not exist in the latter. default-namespace http://purl.org/dc/elements/1.1/ The default namespace to use when the metadata fields in the copy-metadata property are not fully \"expanded\". http://purl.org/dc/terms/ (DublinCore Term namespace) About Expanded Names Expanded names are qualified XML terms where the prefix has been expanded to the full namespace it represents. For convention, they are written as: {namespace}localname \u2026 where namespace is the full namespace (not a prefix like in XML documents) and localname is the term itself. Some examples of expanded names are: {http://purl.org/dc/terms/}title {http://mediapackage.opencastproject.org}mediapackage {}term-with-an-empty-namespace The value of the copy-metadata may contain expanded and non-expanded names. In the latter case, the names will be expanded using the provided namespace, if any, or the DublinCore namespace by default. Please note that: An empty namespace (such as in {}example ) is still a namespace. That means that the default namespace will not be substituted in this case and the term will be handled \"as-is\", i.e. with an empty namespace. Most of the terms used by Opencast belong to the DublinCore namespace, so using non-expanded names and the default namespace should be sufficient. However, custom metadata fields may be in a different namespace which must be explicitly specified. Allowed Namespaces For technical reasons, namespaces need to be pre-registered in Opencast to be used. That is why only a defined set of namespaces can be used in this operation. The allowed namespaces are: DublinCore Terms: http://purl.org/dc/terms/ DublinCore Elements 1.1: http://purl.org/dc/elements/1.1/ Opencast Properties: http://www.opencastproject.org/ Operation Examples <operation id=\"series\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Applying series to mediapackage\"> <configurations> <configuration key=\"series\">0d06537e-09d3-420c-8314-a21e45c5d032</configuration> <configuration key=\"attach\">*</configuration> <configuration key=\"apply-acl\">true</configuration> </configurations> </operation> <operation id=\"series\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Applying series to mediapackage\"> <configurations> <configuration key=\"attach\">*</configuration> <configuration key=\"apply-acl\">false</configuration> <configuration key=\"copy-metadata\">contributor, license</configuration> </configurations> </operation> <operation id=\"series\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Applying series to mediapackage\"> <configurations> <configuration key=\"attach\">dublincore/*</configuration> <configuration key=\"apply-acl\">false</configuration> <configuration key=\"copy-metadata\">{http://purl.org/dc/terms/}contributor custom1 custom2</configuration> <configuration key=\"default-namespace\">http://www.opencastproject.org/</configuration> </configurations> </operation>","title":"Series"},{"location":"workflowoperationhandlers/series-woh/#seriesworkflowoperationhandler","text":"","title":"SeriesWorkflowOperationHandler"},{"location":"workflowoperationhandlers/series-woh/#description","text":"The SeriesWorkflowOperation will apply a series to the mediapackage.","title":"Description"},{"location":"workflowoperationhandlers/series-woh/#parameter-table","text":"configuration keys example description default value series 0d06537e-09d3-420c-8314-a21e45c5d032 The optional series identifier. If empty the current series of the medipackage will be taken. attach creativecommons/*,dublincore/* The flavors of the series catalogs to attach to the mediapackage. apply-acl true Whether the ACL should be applied or not. false copy-metadata {http://purl.org/dc/terms/}title, isPartOf A comma-separated list of metadata fields (possibly \"expanded\") to be transferred from the series catalog to the episode catalog if they do not exist in the latter. default-namespace http://purl.org/dc/elements/1.1/ The default namespace to use when the metadata fields in the copy-metadata property are not fully \"expanded\". http://purl.org/dc/terms/ (DublinCore Term namespace)","title":"Parameter Table"},{"location":"workflowoperationhandlers/series-woh/#about-expanded-names","text":"Expanded names are qualified XML terms where the prefix has been expanded to the full namespace it represents. For convention, they are written as: {namespace}localname \u2026 where namespace is the full namespace (not a prefix like in XML documents) and localname is the term itself. Some examples of expanded names are: {http://purl.org/dc/terms/}title {http://mediapackage.opencastproject.org}mediapackage {}term-with-an-empty-namespace The value of the copy-metadata may contain expanded and non-expanded names. In the latter case, the names will be expanded using the provided namespace, if any, or the DublinCore namespace by default. Please note that: An empty namespace (such as in {}example ) is still a namespace. That means that the default namespace will not be substituted in this case and the term will be handled \"as-is\", i.e. with an empty namespace. Most of the terms used by Opencast belong to the DublinCore namespace, so using non-expanded names and the default namespace should be sufficient. However, custom metadata fields may be in a different namespace which must be explicitly specified.","title":"About Expanded Names"},{"location":"workflowoperationhandlers/series-woh/#allowed-namespaces","text":"For technical reasons, namespaces need to be pre-registered in Opencast to be used. That is why only a defined set of namespaces can be used in this operation. The allowed namespaces are: DublinCore Terms: http://purl.org/dc/terms/ DublinCore Elements 1.1: http://purl.org/dc/elements/1.1/ Opencast Properties: http://www.opencastproject.org/","title":"Allowed Namespaces"},{"location":"workflowoperationhandlers/series-woh/#operation-examples","text":"<operation id=\"series\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Applying series to mediapackage\"> <configurations> <configuration key=\"series\">0d06537e-09d3-420c-8314-a21e45c5d032</configuration> <configuration key=\"attach\">*</configuration> <configuration key=\"apply-acl\">true</configuration> </configurations> </operation> <operation id=\"series\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Applying series to mediapackage\"> <configurations> <configuration key=\"attach\">*</configuration> <configuration key=\"apply-acl\">false</configuration> <configuration key=\"copy-metadata\">contributor, license</configuration> </configurations> </operation> <operation id=\"series\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Applying series to mediapackage\"> <configurations> <configuration key=\"attach\">dublincore/*</configuration> <configuration key=\"apply-acl\">false</configuration> <configuration key=\"copy-metadata\">{http://purl.org/dc/terms/}contributor custom1 custom2</configuration> <configuration key=\"default-namespace\">http://www.opencastproject.org/</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/silence-woh/","text":"SilenceDetectionWorkflowOperationHandler Description The silence operation performs a silence detection on an audio-only input file. Parameter Table configuration keys example description default value source-flavors */audio The input parameter source-flavors takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type EMPTY reference-tracks-flavor */preview The input parameter reference-tracks-flavor is the subtype of the media files that should be included in the provided SMIL file. The * should not be modified here. In most cases it is not important which reference-tracks-flavor is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality. EMPTY smil-flavor-subtype smil The output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced. EMPTY Operation Example <operation id=\"silence\" description=\"Executing silence detection\"> <configurations> <configuration key=\"source-flavors\">*/audio</configuration> <configuration key=\"smil-flavor-subtype\">smil</configuration> <configuration key=\"reference-tracks-flavor\">*/preview</configuration> </configurations> </operation>","title":"Silence"},{"location":"workflowoperationhandlers/silence-woh/#silencedetectionworkflowoperationhandler","text":"","title":"SilenceDetectionWorkflowOperationHandler"},{"location":"workflowoperationhandlers/silence-woh/#description","text":"The silence operation performs a silence detection on an audio-only input file.","title":"Description"},{"location":"workflowoperationhandlers/silence-woh/#parameter-table","text":"configuration keys example description default value source-flavors */audio The input parameter source-flavors takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type EMPTY reference-tracks-flavor */preview The input parameter reference-tracks-flavor is the subtype of the media files that should be included in the provided SMIL file. The * should not be modified here. In most cases it is not important which reference-tracks-flavor is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality. EMPTY smil-flavor-subtype smil The output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced. EMPTY","title":"Parameter Table"},{"location":"workflowoperationhandlers/silence-woh/#operation-example","text":"<operation id=\"silence\" description=\"Executing silence detection\"> <configurations> <configuration key=\"source-flavors\">*/audio</configuration> <configuration key=\"smil-flavor-subtype\">smil</configuration> <configuration key=\"reference-tracks-flavor\">*/preview</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/snapshot-woh/","text":"AssetManagerSnapshotWorkflowOperationHandler Description The snapshot operation allows you to take a new, versioned snapshot of a media package which is put into the asset manager. Parameter Table configuration keys example description source-tags text Comma separated list of tags. Specifies which media should be the source of a snapshop. source-flavors presenter/source Comma separated list of flavors. Specifies which media should be the source of a snapshot. Operation Example <operation id=\"snapshot\" description=\"Archiving\"> <configurations> <configuration key=\"source-tags\">archive</configuration> </configurations> </operation>","title":"Asset Snapshot"},{"location":"workflowoperationhandlers/snapshot-woh/#assetmanagersnapshotworkflowoperationhandler","text":"","title":"AssetManagerSnapshotWorkflowOperationHandler"},{"location":"workflowoperationhandlers/snapshot-woh/#description","text":"The snapshot operation allows you to take a new, versioned snapshot of a media package which is put into the asset manager.","title":"Description"},{"location":"workflowoperationhandlers/snapshot-woh/#parameter-table","text":"configuration keys example description source-tags text Comma separated list of tags. Specifies which media should be the source of a snapshop. source-flavors presenter/source Comma separated list of flavors. Specifies which media should be the source of a snapshot.","title":"Parameter Table"},{"location":"workflowoperationhandlers/snapshot-woh/#operation-example","text":"<operation id=\"snapshot\" description=\"Archiving\"> <configurations> <configuration key=\"source-tags\">archive</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/start-watson-transcription-woh/","text":"Start Watson Transcription Description The Start Watson Transcription invokes the IBM Watson Speech-to-Text service, passing an audio file to be translated to text. Parameter Table configuration keys description default value example source-flavor The flavor of the audio file to be sent for translation. EMPTY presenter/delivery source-tag The flavor of the audio file to be sent for translation. EMPTY transcript-audio skip-if-flavor-exists If this flavor already exists in the media package, skip this operation. To be used when the media package already has a transcript file. false captions/vtt+en One of source-flavor or source-tag must be specified. Example <!-- Extract audio from video in ogg/opus format --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-tags\">engage-download</configuration> <configuration key=\"target-flavor\">audio/ogg</configuration> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-opus</configuration> <!-- If there is more than one file that match the source-tags, use only the first one --> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start IBM Watson recognitions job --> <operation id=\"start-watson-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start IBM Watson transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mp already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/vtt+en</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation> Encoding profile used in example above profile.audio-opus.name = audio-opus profile.audio-opus.input = stream profile.audio-opus.output = audio profile.audio-opus.suffix = -audio.opus profile.audio-opus.ffmpeg.command = -i /#{in.video.path} -c:a libvorbis -ac 1 -ar 16k -b:a 64k #{out.dir}/#{out.name}#{out.suffix}","title":"Start Watson Transcription"},{"location":"workflowoperationhandlers/start-watson-transcription-woh/#start-watson-transcription","text":"","title":"Start Watson Transcription"},{"location":"workflowoperationhandlers/start-watson-transcription-woh/#description","text":"The Start Watson Transcription invokes the IBM Watson Speech-to-Text service, passing an audio file to be translated to text.","title":"Description"},{"location":"workflowoperationhandlers/start-watson-transcription-woh/#parameter-table","text":"configuration keys description default value example source-flavor The flavor of the audio file to be sent for translation. EMPTY presenter/delivery source-tag The flavor of the audio file to be sent for translation. EMPTY transcript-audio skip-if-flavor-exists If this flavor already exists in the media package, skip this operation. To be used when the media package already has a transcript file. false captions/vtt+en One of source-flavor or source-tag must be specified.","title":"Parameter Table"},{"location":"workflowoperationhandlers/start-watson-transcription-woh/#example","text":"<!-- Extract audio from video in ogg/opus format --> <operation id=\"compose\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Extract audio for transcript generation\"> <configurations> <configuration key=\"source-tags\">engage-download</configuration> <configuration key=\"target-flavor\">audio/ogg</configuration> <configuration key=\"target-tags\">transcript</configuration> <configuration key=\"encoding-profile\">audio-opus</configuration> <!-- If there is more than one file that match the source-tags, use only the first one --> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation> <!-- Start IBM Watson recognitions job --> <operation id=\"start-watson-transcription\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Start IBM Watson transcription job\"> <configurations> <!-- Skip this operation if flavor already exists. Used for cases when mp already has captions. --> <configuration key=\"skip-if-flavor-exists\">captions/vtt+en</configuration> <!-- Audio to be translated, produced in the previous compose operation --> <configuration key=\"source-tag\">transcript</configuration> </configurations> </operation>","title":"Example"},{"location":"workflowoperationhandlers/start-watson-transcription-woh/#encoding-profile-used-in-example-above","text":"profile.audio-opus.name = audio-opus profile.audio-opus.input = stream profile.audio-opus.output = audio profile.audio-opus.suffix = -audio.opus profile.audio-opus.ffmpeg.command = -i /#{in.video.path} -c:a libvorbis -ac 1 -ar 16k -b:a 64k #{out.dir}/#{out.name}#{out.suffix}","title":"Encoding profile used in example above"},{"location":"workflowoperationhandlers/start-workflow-woh/","text":"StartWorkflowWorkflowOperationHandler Description The StartWorkflowWorkflowOperationHandler can be used to start a new workflow for given media package and workflow definition. Parameter Table Configuration Key Example Description media-package* e72f2265-472a-49ae-bc04-8301d94b4b1a The ID of the media package that should be used workflow-definition* fast The workflow definition that should be used configProperty abc / false Workflow configuration property * mandatory configuration key Operation Example <operation id=\"start-workflow\"> <configurations> <configuration key=\"workflow-definition\">fast</configuration> <configuration key=\"media-package\">e72f2265-472a-49ae-bc04-8301d94b4b1a</configuration> <configuration key=\"key\">value</configuration> <configuration key=\"publish\">true</configuration> </configurations> </operation>","title":"Start Workflow"},{"location":"workflowoperationhandlers/start-workflow-woh/#startworkflowworkflowoperationhandler","text":"","title":"StartWorkflowWorkflowOperationHandler"},{"location":"workflowoperationhandlers/start-workflow-woh/#description","text":"The StartWorkflowWorkflowOperationHandler can be used to start a new workflow for given media package and workflow definition.","title":"Description"},{"location":"workflowoperationhandlers/start-workflow-woh/#parameter-table","text":"Configuration Key Example Description media-package* e72f2265-472a-49ae-bc04-8301d94b4b1a The ID of the media package that should be used workflow-definition* fast The workflow definition that should be used configProperty abc / false Workflow configuration property * mandatory configuration key","title":"Parameter Table"},{"location":"workflowoperationhandlers/start-workflow-woh/#operation-example","text":"<operation id=\"start-workflow\"> <configurations> <configuration key=\"workflow-definition\">fast</configuration> <configuration key=\"media-package\">e72f2265-472a-49ae-bc04-8301d94b4b1a</configuration> <configuration key=\"key\">value</configuration> <configuration key=\"publish\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/statistics-writer/","text":"Statistics Writer Workflow Operation ID: statistics-writer Description The statistics writer operation can be used to publish statistics about a video to a statistics backend such as InfluxDB. Currently, it only writes the length of the video in seconds to the data base. It can be configured to write the negative length and can thus be used for retract workflows, too. Parameter Table configuration keys required description flavor yes The flavor of the track you want to publish statistics about measurement-name yes Measurement name in the statistics DB organization-resource-id-name yes Resource ID name for the organization length-field-name yes Field name for the length of the video temporal-resolution yes Temporal resolution to store the length in * retention-policy no Retention policy to use for the statistics DB retract no Whether to publish positive or negative numbers (default: false ) * Possible values are milliseconds , seconds , minutes , hours , days Operation Examples <operation id=\"statistics-writer\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Collect video statistics\"> <configurations> <configuration key=\"flavor\">presenter/video</configuration> <configuration key=\"retract\">false</configuration> <configuration key=\"retention-policy\">infinite</configuration> <configuration key=\"measurement-name\">publishedhours</configuration> <configuration key=\"organization-resource-id-name\">organizationId</configuration> <configuration key=\"length-field-name\">hours</configuration> <configuration key=\"temporal-resolution\">hours</configuration> </configurations> </operation>","title":"Statistics Writer"},{"location":"workflowoperationhandlers/statistics-writer/#statistics-writer-workflow-operation","text":"ID: statistics-writer","title":"Statistics Writer Workflow Operation"},{"location":"workflowoperationhandlers/statistics-writer/#description","text":"The statistics writer operation can be used to publish statistics about a video to a statistics backend such as InfluxDB. Currently, it only writes the length of the video in seconds to the data base. It can be configured to write the negative length and can thus be used for retract workflows, too.","title":"Description"},{"location":"workflowoperationhandlers/statistics-writer/#parameter-table","text":"configuration keys required description flavor yes The flavor of the track you want to publish statistics about measurement-name yes Measurement name in the statistics DB organization-resource-id-name yes Resource ID name for the organization length-field-name yes Field name for the length of the video temporal-resolution yes Temporal resolution to store the length in * retention-policy no Retention policy to use for the statistics DB retract no Whether to publish positive or negative numbers (default: false ) * Possible values are milliseconds , seconds , minutes , hours , days","title":"Parameter Table"},{"location":"workflowoperationhandlers/statistics-writer/#operation-examples","text":"<operation id=\"statistics-writer\" fail-on-error=\"true\" exception-handler-workflow=\"partial-error\" description=\"Collect video statistics\"> <configurations> <configuration key=\"flavor\">presenter/video</configuration> <configuration key=\"retract\">false</configuration> <configuration key=\"retention-policy\">infinite</configuration> <configuration key=\"measurement-name\">publishedhours</configuration> <configuration key=\"organization-resource-id-name\">organizationId</configuration> <configuration key=\"length-field-name\">hours</configuration> <configuration key=\"temporal-resolution\">hours</configuration> </configurations> </operation>","title":"Operation Examples"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/","text":"TagByDCTermWorkflowOperationHandler Description With the TagByDCTermWorkflowOperationHandler it's possible to select various media package elements and then modify their tag set and / or set their flavor according to whether a Dublin Core term in a catalog has a specific value. So for example it's possible to pick elements like the Dublin Core catalogs that have been added to the media package at the beginning of the workflow and tag them, so they can be picked up by operations later on or even an application that harvests the mediapackage from a publication channel. In combination with ConfigureByDCTermWorkflowOperationHandler workflows can be controlled by the metadata contained within the Dublin core catalogs. Parameter Table Tags and flavors can be used in combination. configuration keys example description default value source-tags \"engage,atom,rss,-publish\" Tag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded. EMPTY source-flavors \"presentation/trimmed\" Tag any media package elements with one of these (comma separated) flavors. EMPTY dccatalog \"episode\" or \"series\" the type of catalog in which to search for dcterm EMPTY dcterm \"creator\" the name of the Dublin Core term which to check EMPTY match-value \"Joe Bloggs\" the Dublin Core term value to check for EMPTY default-value\" \"Anon\" the implied value if the dubincore term is not present in the catalog EMPTY target-tags \"tagged,+rss\" / \"-rss,+tagged\" Apply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. EMPTY target-flavor \"presentation/tagged\" Apply these flavor to any media package elements EMPTY copy \"true\" or \"false\" Indicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise. FALSE Note: see TagWorkflowOperationHandler for further explanation of the source/target-flavor/tags dccatalog The type of Dublin Core catalog in which to look for the dcterm . This will usually be episode or series . dcterm The name of the Dublin Core term to look for in the dccatalog . This could be one of the terms set by Opencast or an additional term adding to the catalog. match-value The value of the dcterm which to match against. The comparison is case sensitive. default-value If default-value is used when the dcterm is not found in the catalog. If not specified the operation will treat the match as false and not tag anything. If default-value is specified the operation will compare the match-value to the default-value and apply the tags if they match. This allows an implied value to be explicitly and clearly defined. For example if you have mediapackages that were created before additional metadata was added to the episode catalog you may want to imply that the audience term has a value of all-enrolled . Operation Example <operation id=\"tag-by-dcterm\" max-attempts=\"2\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Tagging media package elements according to dcterm\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*</configuration> <configuration key=\"dccatalog\">episode</configuration> <configuration key=\"dcterm\">audience</configuration> <configuration key=\"match-value\">learning-difficulties</configuration> <configuration key=\"default-value\">all-enrolled</confiuration> <configuration key=\"target-tags\">+publishBeforeEditing</configuration> </configurations> </operation>","title":"Tag-By-DCTerm"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#tagbydctermworkflowoperationhandler","text":"","title":"TagByDCTermWorkflowOperationHandler"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#description","text":"With the TagByDCTermWorkflowOperationHandler it's possible to select various media package elements and then modify their tag set and / or set their flavor according to whether a Dublin Core term in a catalog has a specific value. So for example it's possible to pick elements like the Dublin Core catalogs that have been added to the media package at the beginning of the workflow and tag them, so they can be picked up by operations later on or even an application that harvests the mediapackage from a publication channel. In combination with ConfigureByDCTermWorkflowOperationHandler workflows can be controlled by the metadata contained within the Dublin core catalogs.","title":"Description"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#parameter-table","text":"Tags and flavors can be used in combination. configuration keys example description default value source-tags \"engage,atom,rss,-publish\" Tag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded. EMPTY source-flavors \"presentation/trimmed\" Tag any media package elements with one of these (comma separated) flavors. EMPTY dccatalog \"episode\" or \"series\" the type of catalog in which to search for dcterm EMPTY dcterm \"creator\" the name of the Dublin Core term which to check EMPTY match-value \"Joe Bloggs\" the Dublin Core term value to check for EMPTY default-value\" \"Anon\" the implied value if the dubincore term is not present in the catalog EMPTY target-tags \"tagged,+rss\" / \"-rss,+tagged\" Apply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. EMPTY target-flavor \"presentation/tagged\" Apply these flavor to any media package elements EMPTY copy \"true\" or \"false\" Indicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise. FALSE Note: see TagWorkflowOperationHandler for further explanation of the source/target-flavor/tags","title":"Parameter Table"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#dccatalog","text":"The type of Dublin Core catalog in which to look for the dcterm . This will usually be episode or series .","title":"dccatalog"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#dcterm","text":"The name of the Dublin Core term to look for in the dccatalog . This could be one of the terms set by Opencast or an additional term adding to the catalog.","title":"dcterm"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#match-value","text":"The value of the dcterm which to match against. The comparison is case sensitive.","title":"match-value"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#default-value","text":"If default-value is used when the dcterm is not found in the catalog. If not specified the operation will treat the match as false and not tag anything. If default-value is specified the operation will compare the match-value to the default-value and apply the tags if they match. This allows an implied value to be explicitly and clearly defined. For example if you have mediapackages that were created before additional metadata was added to the episode catalog you may want to imply that the audience term has a value of all-enrolled .","title":"default-value"},{"location":"workflowoperationhandlers/tag-by-dcterm-woh/#operation-example","text":"<operation id=\"tag-by-dcterm\" max-attempts=\"2\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Tagging media package elements according to dcterm\"> <configurations> <configuration key=\"source-flavors\">dublincore/*,security/*</configuration> <configuration key=\"dccatalog\">episode</configuration> <configuration key=\"dcterm\">audience</configuration> <configuration key=\"match-value\">learning-difficulties</configuration> <configuration key=\"default-value\">all-enrolled</confiuration> <configuration key=\"target-tags\">+publishBeforeEditing</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/tag-woh/","text":"TagWorkflowOperation Description With the TagWorkflowOperationHandler it's possible to select various media package elements and then modify their tag set and / or set their flavor. So for example it's possible to pick up elements like the dublin core catalogs that have been added to the media package at the beginning of the workflow and tag them, so they can be picked up by operations later on. Parameter Table Tags and flavors can be used in combination. configuration keys example description default value source-tags \"engage,atom,rss,-publish\" Tag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded. EMPTY source-flavors \"presentation/trimmed\" Tag any media package elements with one of these (comma separated) flavors. EMPTY target-tags \"tagged,+rss\" / \"-rss,+tagged\" Apply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. EMPTY target-flavor \"presentation/tagged\" Apply these flavor to any media package elements EMPTY copy \"true\" or \"false\" Indicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise. FALSE Target Tags Example Target-Tags Preexisting Tags Resulting Tags rss engage rss +rss engage engage,rss -rss engage,rss engage tagged,+rss engage tagged -rss,+tagged engage,rss engage,tagged Operation Example <operation id=\"tag\" max-attempts=\"2\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Tagging media package elements\"> <configurations> <configuration key=\"source-tags\">engage,atom,publish</configuration> <configuration key=\"source-flavors\">presentation/trimmed</configuration> <configuration key=\"target-tags\">-atom,+rss</configuration> <configuration key=\"target-flavor\">presentation/tagged</configuration> <configuration key=\"copy\">true</configuration> </configurations> </operation>","title":"Tag"},{"location":"workflowoperationhandlers/tag-woh/#tagworkflowoperation","text":"","title":"TagWorkflowOperation"},{"location":"workflowoperationhandlers/tag-woh/#description","text":"With the TagWorkflowOperationHandler it's possible to select various media package elements and then modify their tag set and / or set their flavor. So for example it's possible to pick up elements like the dublin core catalogs that have been added to the media package at the beginning of the workflow and tag them, so they can be picked up by operations later on.","title":"Description"},{"location":"workflowoperationhandlers/tag-woh/#parameter-table","text":"Tags and flavors can be used in combination. configuration keys example description default value source-tags \"engage,atom,rss,-publish\" Tag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded. EMPTY source-flavors \"presentation/trimmed\" Tag any media package elements with one of these (comma separated) flavors. EMPTY target-tags \"tagged,+rss\" / \"-rss,+tagged\" Apply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags. EMPTY target-flavor \"presentation/tagged\" Apply these flavor to any media package elements EMPTY copy \"true\" or \"false\" Indicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise. FALSE","title":"Parameter Table"},{"location":"workflowoperationhandlers/tag-woh/#target-tags-example","text":"Target-Tags Preexisting Tags Resulting Tags rss engage rss +rss engage engage,rss -rss engage,rss engage tagged,+rss engage tagged -rss,+tagged engage,rss engage,tagged","title":"Target Tags Example"},{"location":"workflowoperationhandlers/tag-woh/#operation-example","text":"<operation id=\"tag\" max-attempts=\"2\" fail-on-error=\"true\" exception-handler-workflow=\"error\" description=\"Tagging media package elements\"> <configurations> <configuration key=\"source-tags\">engage,atom,publish</configuration> <configuration key=\"source-flavors\">presentation/trimmed</configuration> <configuration key=\"target-tags\">-atom,+rss</configuration> <configuration key=\"target-flavor\">presentation/tagged</configuration> <configuration key=\"copy\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/theme-woh/","text":"ThemeWorkflowOperationHandler Description The ThemeWorkflowOperation loads workflow properties and adds elements to the media package if available. This information can be used within workflow definitions to actually implement themes. Bumpers The property theme_bumper_active indicates whether the theme defines a bumper video. If true, the bumper video is added to the media package with the flavor bumper-flavor and/or tags bumper-tags . Trailers The property theme_trailer_active indicates whether the theme defines a trailer video. If true, the trailer video is added to the media package with the flavor trailer-flavor and/or tags trailer-tags . Title Slide The property theme_title_slide_active indicates whether the theme defines a title slide. Additionally, the property theme_title_slide_uploaded indicates whether the image needed as background for the generation of the title slide should be extracted from a video track or has been uploaded. In the later case, the background image is added to the media package with the flavor title-slide-flavor and/or tags title-slide-tags . Watermark The property theme_watermark_active indicates whether the theme defines a watermark. If true, the watermark image is added to the media package with the flavor watermark-flavor and/or tags watermark-tags . Additionally, a watermark layout compatible to the CompositeWorkflowOperation is added as property watermark_layout_variable*. Workflow Properties The ThemeWorkflowOperation will set the following workflow properties: Property Name Description theme_active true if the theme has active settings, false or undefined otherwise theme_bumper_active true if the theme has an active bumper video, false otherwise theme_trailer_active true if the theme has an active trailer video, false otherwise theme_title_slide_active true if the theme has an active title slide, false otherwise theme_title_slide_uploaded true if the theme come with an uploaded title slide, false otherwise theme_watermark_active true if the theme has an active watermark, false otherwise Note: The property theme_active can be used to test whether a theme has any active settings, i.e. at least one of the properties theme_*_active is true. Parameter Table Configuration Keys Example Description *bumper-flavor branding/bumper Flavor of the bumper video *bumper-tags bumper Tags of of the bumper video *trailer-flavor branding/trailer Flavor of the trailer video *trailer-tags trailer Tags of the trailer video *title-slide-flavor branding/titleslide Flavor of the title slide image *title-slide-tags titleslide Tags of the title slide image *watermark-flavor branding/watermark Flavor of the watermark image *watermark-tags watermark Tags of the watermark image *watermark-layout-variable theme_watermark_layout Variable that will hold the watermark layout * Mandatory configuration key (in case the feature is active) Operation Example <operation id=\"theme\" exception-handler-workflow=\"partial-error\" description=\"Apply the theme\"> <configurations> <configuration key=\"bumper-flavor\">branding/bumper</configuration> <configuration key=\"bumper-tags\">archive</configuration> <configuration key=\"trailer-flavor\">branding/trailer</configuration> <configuration key=\"trailer-tags\">archive</configuration> <configuration key=\"title-slide-flavor\">branding/titleslide</configuration> <configuration key=\"title-slide-tags\">archive</configuration> <configuration key=\"watermark-flavor\">branding/titleslide</configuration> <configuration key=\"watermark-tags\">archive</configuration> <configuration key=\"watermark-layout-variable\">theme_watermark_layout</configuration> </configurations> </operation>","title":"Theme"},{"location":"workflowoperationhandlers/theme-woh/#themeworkflowoperationhandler","text":"","title":"ThemeWorkflowOperationHandler"},{"location":"workflowoperationhandlers/theme-woh/#description","text":"The ThemeWorkflowOperation loads workflow properties and adds elements to the media package if available. This information can be used within workflow definitions to actually implement themes. Bumpers The property theme_bumper_active indicates whether the theme defines a bumper video. If true, the bumper video is added to the media package with the flavor bumper-flavor and/or tags bumper-tags . Trailers The property theme_trailer_active indicates whether the theme defines a trailer video. If true, the trailer video is added to the media package with the flavor trailer-flavor and/or tags trailer-tags . Title Slide The property theme_title_slide_active indicates whether the theme defines a title slide. Additionally, the property theme_title_slide_uploaded indicates whether the image needed as background for the generation of the title slide should be extracted from a video track or has been uploaded. In the later case, the background image is added to the media package with the flavor title-slide-flavor and/or tags title-slide-tags . Watermark The property theme_watermark_active indicates whether the theme defines a watermark. If true, the watermark image is added to the media package with the flavor watermark-flavor and/or tags watermark-tags . Additionally, a watermark layout compatible to the CompositeWorkflowOperation is added as property watermark_layout_variable*.","title":"Description"},{"location":"workflowoperationhandlers/theme-woh/#workflow-properties","text":"The ThemeWorkflowOperation will set the following workflow properties: Property Name Description theme_active true if the theme has active settings, false or undefined otherwise theme_bumper_active true if the theme has an active bumper video, false otherwise theme_trailer_active true if the theme has an active trailer video, false otherwise theme_title_slide_active true if the theme has an active title slide, false otherwise theme_title_slide_uploaded true if the theme come with an uploaded title slide, false otherwise theme_watermark_active true if the theme has an active watermark, false otherwise Note: The property theme_active can be used to test whether a theme has any active settings, i.e. at least one of the properties theme_*_active is true.","title":"Workflow Properties"},{"location":"workflowoperationhandlers/theme-woh/#parameter-table","text":"Configuration Keys Example Description *bumper-flavor branding/bumper Flavor of the bumper video *bumper-tags bumper Tags of of the bumper video *trailer-flavor branding/trailer Flavor of the trailer video *trailer-tags trailer Tags of the trailer video *title-slide-flavor branding/titleslide Flavor of the title slide image *title-slide-tags titleslide Tags of the title slide image *watermark-flavor branding/watermark Flavor of the watermark image *watermark-tags watermark Tags of the watermark image *watermark-layout-variable theme_watermark_layout Variable that will hold the watermark layout * Mandatory configuration key (in case the feature is active)","title":"Parameter Table"},{"location":"workflowoperationhandlers/theme-woh/#operation-example","text":"<operation id=\"theme\" exception-handler-workflow=\"partial-error\" description=\"Apply the theme\"> <configurations> <configuration key=\"bumper-flavor\">branding/bumper</configuration> <configuration key=\"bumper-tags\">archive</configuration> <configuration key=\"trailer-flavor\">branding/trailer</configuration> <configuration key=\"trailer-tags\">archive</configuration> <configuration key=\"title-slide-flavor\">branding/titleslide</configuration> <configuration key=\"title-slide-tags\">archive</configuration> <configuration key=\"watermark-flavor\">branding/titleslide</configuration> <configuration key=\"watermark-tags\">archive</configuration> <configuration key=\"watermark-layout-variable\">theme_watermark_layout</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/timelinepreviews-woh/","text":"TimelinePreviewsWorkflowOperationHandler Description The timeline previews operation creates preview images for the given track that can be shown when hovering above the timeline. It will generate the in image-count specified number of preview images, that will all be saved in one large image file. You can use the source-flavor to specify for which video the preview images will be generated. In the engage player only the preview images of one video are shown (the first that is found), so to make sure the correct preview images are shown, better generate them only for one video. Parameter Table configuration keys example description default value source-flavors */trimmed Specifies which media should be processed. The *-operator can be used if the preview images should be created for all flavors with a certain subtype (like \"trimmed\" in the example) Hereby you can for example choose whether you want to create the timeline preview images from a presenter or a presentation video. EMPTY target-flavor */timeline+preview Specifies the flavor the new files will get. This should use the *-operator if it was used in the source-flavor too. This flavor has to contain the words \"timeline\" and \"preview\" for the file to be found by the player. EMPTY target-tags engage-download Specifies the tags the new files will get. EMPTY image-count 100 Specifies the number of generated timeline preview images. In the example 100 timeline preview images will be generated and stored in a 10x10 grid in the output image 100 process-first-match-only true Only use the first resource that matches the source-flavor and/or target-tag false Operation Example <operation id=\"timelinepreviews\" description=\"Creating presentation timeline preview images\"> <configurations> <configuration key=\"source-flavor\">*/trimmed</configuration> <configuration key=\"target-flavor\">*/timeline+preview</configuration> <configuration key=\"target-tags\">engage-download</configuration> <configuration key=\"image-count\">100</configuration> <!-- If there is more than one file that match the source-tags, use only the first one --> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation>","title":"Timelinepreviews"},{"location":"workflowoperationhandlers/timelinepreviews-woh/#timelinepreviewsworkflowoperationhandler","text":"","title":"TimelinePreviewsWorkflowOperationHandler"},{"location":"workflowoperationhandlers/timelinepreviews-woh/#description","text":"The timeline previews operation creates preview images for the given track that can be shown when hovering above the timeline. It will generate the in image-count specified number of preview images, that will all be saved in one large image file. You can use the source-flavor to specify for which video the preview images will be generated. In the engage player only the preview images of one video are shown (the first that is found), so to make sure the correct preview images are shown, better generate them only for one video.","title":"Description"},{"location":"workflowoperationhandlers/timelinepreviews-woh/#parameter-table","text":"configuration keys example description default value source-flavors */trimmed Specifies which media should be processed. The *-operator can be used if the preview images should be created for all flavors with a certain subtype (like \"trimmed\" in the example) Hereby you can for example choose whether you want to create the timeline preview images from a presenter or a presentation video. EMPTY target-flavor */timeline+preview Specifies the flavor the new files will get. This should use the *-operator if it was used in the source-flavor too. This flavor has to contain the words \"timeline\" and \"preview\" for the file to be found by the player. EMPTY target-tags engage-download Specifies the tags the new files will get. EMPTY image-count 100 Specifies the number of generated timeline preview images. In the example 100 timeline preview images will be generated and stored in a 10x10 grid in the output image 100 process-first-match-only true Only use the first resource that matches the source-flavor and/or target-tag false","title":"Parameter Table"},{"location":"workflowoperationhandlers/timelinepreviews-woh/#operation-example","text":"<operation id=\"timelinepreviews\" description=\"Creating presentation timeline preview images\"> <configurations> <configuration key=\"source-flavor\">*/trimmed</configuration> <configuration key=\"target-flavor\">*/timeline+preview</configuration> <configuration key=\"target-tags\">engage-download</configuration> <configuration key=\"image-count\">100</configuration> <!-- If there is more than one file that match the source-tags, use only the first one --> <configuration key=\"process-first-match-only\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/transfer-metadata-woh/","text":"Transfer Metadata Workflow Operation Description The transfer metadata operation allows to transfer arbitrary metadata fields from one metadata catalog to another one. Parameter Table configuration key example description source-flavor dublincore/episode The catalog from which the metadata is copied target-flavor myterms/episode The catalog to which the data is copied source-element {http://purl.org/dc/terms/}creator The XML element to copy target-element {http://purl.org/dc/terms/}creator The XML element to which the values are copied force false Overwrite existing targets concat , Join multiple values by set delimiter target-prefix dcterms Prefix to use for the given namespace force By default, the operation will fail if a target element already exists at the specified location. If force is set, all existing target elements will be removed before copying the new elements. concat If multiple source elements are selected (e.g. the title in multiple languages), by default, all elements are copied to the destination. The language information are preserved in this operation. If concat is defined, the value of this option will be used as a delimiter for joining all selected source elements and only ever one element will be written. All language information for this combined element will be discarded in the process. target-prefix This option lets you specify the XML namespace identifier for the target elements namespace. For example, Opencast usually uses dcterms for elements from the set of DublinCore terms, resulting in elements like <dcterms:creator> . Operation Example <operation id=\"transfer-metadata\" description=\"Transfer dcterms:creator to myterms:owner\"> <configurations> <configuration key=\"source-flavor\">dublincore/episode</configuration> <configuration key=\"target-flavor\">myterms/episode</configuration> <configuration key=\"source-element\">{http://purl.org/dc/terms/}creator</configuration> <configuration key=\"target-element\">{http://my-institution.edu/metadata}owner</configuration> <configuration key=\"force\">true</configuration> </configurations> </operation>","title":"Transfer Metadata"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#transfer-metadata-workflow-operation","text":"","title":"Transfer Metadata Workflow Operation"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#description","text":"The transfer metadata operation allows to transfer arbitrary metadata fields from one metadata catalog to another one.","title":"Description"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#parameter-table","text":"configuration key example description source-flavor dublincore/episode The catalog from which the metadata is copied target-flavor myterms/episode The catalog to which the data is copied source-element {http://purl.org/dc/terms/}creator The XML element to copy target-element {http://purl.org/dc/terms/}creator The XML element to which the values are copied force false Overwrite existing targets concat , Join multiple values by set delimiter target-prefix dcterms Prefix to use for the given namespace","title":"Parameter Table"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#force","text":"By default, the operation will fail if a target element already exists at the specified location. If force is set, all existing target elements will be removed before copying the new elements.","title":"force"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#concat","text":"If multiple source elements are selected (e.g. the title in multiple languages), by default, all elements are copied to the destination. The language information are preserved in this operation. If concat is defined, the value of this option will be used as a delimiter for joining all selected source elements and only ever one element will be written. All language information for this combined element will be discarded in the process.","title":"concat"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#target-prefix","text":"This option lets you specify the XML namespace identifier for the target elements namespace. For example, Opencast usually uses dcterms for elements from the set of DublinCore terms, resulting in elements like <dcterms:creator> .","title":"target-prefix"},{"location":"workflowoperationhandlers/transfer-metadata-woh/#operation-example","text":"<operation id=\"transfer-metadata\" description=\"Transfer dcterms:creator to myterms:owner\"> <configurations> <configuration key=\"source-flavor\">dublincore/episode</configuration> <configuration key=\"target-flavor\">myterms/episode</configuration> <configuration key=\"source-element\">{http://purl.org/dc/terms/}creator</configuration> <configuration key=\"target-element\">{http://my-institution.edu/metadata}owner</configuration> <configuration key=\"force\">true</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/waveform-woh/","text":"WaveformWorkflowOperationHandler Description The waveform operation creates an image showing the temporal audio activity within the recording like this: The implementation uses an ffmpeg filter that produces a waveform PNG image file from an audio/video file with at least one audio channel. Parameter Table configuration example description default source-flavors */audio Flavor specifying tracks for which a waveform should be created n/a source-tags edit Tags specifying tracks for which a waveform should be created n/a target-flavor */waveform Flavor used for the generated waveform n/a target-tags preview Comma-separated list of tags to be added to the waveform n/a pixels-per-minute 400 Width of waveform image in pixels per minute 200 min-width 10000 Minimum width of waveform image in pixels 5000 max-width 30000 Maximum width of waveform image in pixels 20000 height 60 Height of waveform image in pixels 500 color black Color of waveform image, see ffmpeg.org/ffmpeg-all.html#Color black Additional notes: All media, that match either source-flavors or source tags will be processed. Using a wildcard in the target-flavor will cause the main flavor of the input being used. Operation Example <operation id=\"waveform\" description=\"Generating waveform\"> <configurations> <configuration key=\"source-flavor\">*/audio</configuration> <configuration key=\"target-flavor\">*/waveform</configuration> <configuration key=\"target-tags\">preview</configuration> <configuration key=\"pixels-per-minute\">200</configuration> <configuration key=\"min-width\">5000</configuration> <configuration key=\"max-width\">20000</configuration> <configuration key=\"height\">60</configuration> <configuration key=\"color\">black</configuration> </configurations> </operation>","title":"Waveform"},{"location":"workflowoperationhandlers/waveform-woh/#waveformworkflowoperationhandler","text":"","title":"WaveformWorkflowOperationHandler"},{"location":"workflowoperationhandlers/waveform-woh/#description","text":"The waveform operation creates an image showing the temporal audio activity within the recording like this: The implementation uses an ffmpeg filter that produces a waveform PNG image file from an audio/video file with at least one audio channel.","title":"Description"},{"location":"workflowoperationhandlers/waveform-woh/#parameter-table","text":"configuration example description default source-flavors */audio Flavor specifying tracks for which a waveform should be created n/a source-tags edit Tags specifying tracks for which a waveform should be created n/a target-flavor */waveform Flavor used for the generated waveform n/a target-tags preview Comma-separated list of tags to be added to the waveform n/a pixels-per-minute 400 Width of waveform image in pixels per minute 200 min-width 10000 Minimum width of waveform image in pixels 5000 max-width 30000 Maximum width of waveform image in pixels 20000 height 60 Height of waveform image in pixels 500 color black Color of waveform image, see ffmpeg.org/ffmpeg-all.html#Color black Additional notes: All media, that match either source-flavors or source tags will be processed. Using a wildcard in the target-flavor will cause the main flavor of the input being used.","title":"Parameter Table"},{"location":"workflowoperationhandlers/waveform-woh/#operation-example","text":"<operation id=\"waveform\" description=\"Generating waveform\"> <configurations> <configuration key=\"source-flavor\">*/audio</configuration> <configuration key=\"target-flavor\">*/waveform</configuration> <configuration key=\"target-tags\">preview</configuration> <configuration key=\"pixels-per-minute\">200</configuration> <configuration key=\"min-width\">5000</configuration> <configuration key=\"max-width\">20000</configuration> <configuration key=\"height\">60</configuration> <configuration key=\"color\">black</configuration> </configurations> </operation>","title":"Operation Example"},{"location":"workflowoperationhandlers/zip-woh/","text":"ZipWorkflowOperation Description The ZipWorkflowOperationHandler creates a zip archive including all elements of the current media package that are specified in the operation configuration. It then adds the archive to the media package as an attachment with the given flavor and tags and by default stores the zip file in the working file repository's \"zip\" collection. Parameter Table configuration example description default value zip-collection zips A comma separated list of flavors to preserve from deleting zip include-flavors */source,dublincore/* Which elements to include in the archive (all) target-flavor archive/zip The flavor of the created attachment archive/zip target-tags archive The tags to apply to the attachment compression true Whether to compress the archive content flase Additional notes: The include-flavors configuration parameter accepts exact flavors like presenter/source as well as wildcard flavor definitions like */source . Usually, for media content, zip compression does not reduce the size of the archive very much but adds significant processing time. That is why activating this is usually not recommended. Operation Example <operation id=\"zip\" description=\"Creating zipped recording archive\"> <configurations> <configuration key=\"zip-collection\">failed.zips</configuration> <configuration key=\"include-flavors\">*/source,dublincore/*</configuration> <configuration key=\"target-flavor\">all/zip</configuration> <configuration key=\"compression\">false</configuration> </configurations> </operation>","title":"Zip"},{"location":"workflowoperationhandlers/zip-woh/#zipworkflowoperation","text":"","title":"ZipWorkflowOperation"},{"location":"workflowoperationhandlers/zip-woh/#description","text":"The ZipWorkflowOperationHandler creates a zip archive including all elements of the current media package that are specified in the operation configuration. It then adds the archive to the media package as an attachment with the given flavor and tags and by default stores the zip file in the working file repository's \"zip\" collection.","title":"Description"},{"location":"workflowoperationhandlers/zip-woh/#parameter-table","text":"configuration example description default value zip-collection zips A comma separated list of flavors to preserve from deleting zip include-flavors */source,dublincore/* Which elements to include in the archive (all) target-flavor archive/zip The flavor of the created attachment archive/zip target-tags archive The tags to apply to the attachment compression true Whether to compress the archive content flase Additional notes: The include-flavors configuration parameter accepts exact flavors like presenter/source as well as wildcard flavor definitions like */source . Usually, for media content, zip compression does not reduce the size of the archive very much but adds significant processing time. That is why activating this is usually not recommended.","title":"Parameter Table"},{"location":"workflowoperationhandlers/zip-woh/#operation-example","text":"<operation id=\"zip\" description=\"Creating zipped recording archive\"> <configurations> <configuration key=\"zip-collection\">failed.zips</configuration> <configuration key=\"include-flavors\">*/source,dublincore/*</configuration> <configuration key=\"target-flavor\">all/zip</configuration> <configuration key=\"compression\">false</configuration> </configurations> </operation>","title":"Operation Example"}]}