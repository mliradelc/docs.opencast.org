{
    "docs": [
        {
            "location": "/",
            "text": "Opencast Administration Guide\n\n\nWelcome to the Opencast Universe! Opencast is an open-source enterprise level lecture recording system. The core of the\nsystem delivers functionality for scheduling, media encoding, editing and content delivery. For lecture capture,\nOpencast provides capture agent software and third party appliances are available. An awesome community provides new\nfeatures and support.\n\n\nThe Software\n\n\nOpencast contains everything you need for scheduling captures, trimming, captioning, and conversion of output media to\nseveral formats and our engage components.  The core can be deployed on one (all-in-one deployment) or many (distributed\ndeployment) Linux servers so your Opencast installation can grow with the needs of your university.\n\n\nRelease Documentation\n\n\nThe Opencast Release Documentation is the official Opencast documentation for each release. It contains:\n\n\n\n\nRelease Notes\n\n\nUpgrade\n\n\nChangelog\n\n\n\n\n\n\nInstallation Guides\n\n\nConfiguration Guides\n\n\nBasic Configuration\n\n\nDatabase Configuration\n\n\nHTTPS Configuration\n\n\nWorkflow Configuration\n\n\nEncoding Configuration\n\n\nmore...\n\n\n\n\n\n\nModule Documentation\n\n\nAtom and RSS Feed\n\n\nAWS S3 Distribution\n\n\nMedia Module\n\n\nStream Security\n\n\nText Extraction\n\n\nVideo Segmentation\n\n\nYouTube Publication\n\n\nmore...\n\n\n\n\n\n\nVersion Support\n\n\n\n\nFurther Documentation\n\n\nIn addition to this official documentation, further guides and tips can be found in the on the mailing lists, the IRC\nchannel and at the regular meetings.",
            "title": "Home"
        },
        {
            "location": "/#opencast-administration-guide",
            "text": "Welcome to the Opencast Universe! Opencast is an open-source enterprise level lecture recording system. The core of the\nsystem delivers functionality for scheduling, media encoding, editing and content delivery. For lecture capture,\nOpencast provides capture agent software and third party appliances are available. An awesome community provides new\nfeatures and support.",
            "title": "Opencast Administration Guide"
        },
        {
            "location": "/#the-software",
            "text": "Opencast contains everything you need for scheduling captures, trimming, captioning, and conversion of output media to\nseveral formats and our engage components.  The core can be deployed on one (all-in-one deployment) or many (distributed\ndeployment) Linux servers so your Opencast installation can grow with the needs of your university.",
            "title": "The Software"
        },
        {
            "location": "/#release-documentation",
            "text": "The Opencast Release Documentation is the official Opencast documentation for each release. It contains:   Release Notes  Upgrade  Changelog    Installation Guides  Configuration Guides  Basic Configuration  Database Configuration  HTTPS Configuration  Workflow Configuration  Encoding Configuration  more...    Module Documentation  Atom and RSS Feed  AWS S3 Distribution  Media Module  Stream Security  Text Extraction  Video Segmentation  YouTube Publication  more...    Version Support",
            "title": "Release Documentation"
        },
        {
            "location": "/#further-documentation",
            "text": "In addition to this official documentation, further guides and tips can be found in the on the mailing lists, the IRC\nchannel and at the regular meetings.",
            "title": "Further Documentation"
        },
        {
            "location": "/releasenotes/",
            "text": "Opencast 6: Release Notes\n\n\nNew Features\n\n\n\n\n\n\nVideo Editor - Thumbnails\n - When displaying lists of videos, thumbnails are usually used to make such lists more\n  appealing. The video editor allows the user to choose between the default thumbnail (automatically created), a\n  snapshot thumbnail (extract at current position from video stream) or an uploaded thumbnail.  This allows the user to\n  get the best thumbnails for his videos with as little effort as possible.\n\n\n\n\n\n\nVideo Editor - Track selection\n - In case multiple tracks have been ingested, the video editor allows the user to\n  choose which tracks should be processed. In case of a dual track lecture recording, the presenter track could be\n  exluded from publication in case the recorded person would want this.\n\n\n\n\n\n\nCheatsheet\n - A per page keyboard shortcut list is available so that users can at any time and page see what\n  keyboard shortcuts are currenlty available.\n\n\n\n\n\n\nCapture Agent Access Management\n - The Admin UI now supports access management for capture agents. This features\n  addresses the need to allow unprivileged users to access the Admin UI to manage their own content and cut videos\n  without allowing them to schedule events or change the scheduling as this task is usually in the responsibility of a\n  dedicated team.  It is also possible to permit users access to specific subsets of the available capture agents.\n\n\n\n\n\n\nExternal API 1.1.0\n - For the first time, Opencast takes advantage of its state-of-the-art versioned API by\n  introducing the External API 1.1.0.  The new version extends the API to support scheduling of events and access to\n  workflows.  The filter and sort facilities have been extended and additional fields are directly delivered by some\n  core requests with allows clients to access them way faster.  The External API 1.0.0 is still supported relieving\n  existing clients from the need to be timely adapted.\n\n\n\n\n\n\nProcessing Settings Persistency\n - A new persistence layer for processing settings has been introduced. This allows\n  the Admin UI to not just provide processing settings as input when starting workflows, but also to display processing\n  settings on event basis.\n\n\n\n\n\n\nNew Workflow Operation Handler\n\n\n\n\ndemux\n can be used to demux multiple streams from a container into seperate containers\n\n\nimage-convert\n can convert multiple source images into multiple target images with different encoding\n\n\nmattermost-notify\n sends notification to services like Mattermost or Slack\n\n\nmove-to-remote\n moves files in the asset manager from one storage system to another\n\n\nmulti-encode\n allows encoding of multiple source tracks into multiple target tracks with differnet encoding\n\n\nprocess-smil\n edits media files based on descriptions from a SMIL file\n\n\nselect-tracks\n can filter source tracks based on workflow properties\n\n\nstart-workflow\n allows a workflow to start another workflow\n\n\n\n\n\n\n\n\nAsset Manager Storage Layers\n - The Asset Manager now supports multiple storage layers natively.  This allows\n  users to move data from local storage to remote storage within Opencast.  These moves can be triggered manually, or\n  via a built-in timer.  Currently we support local file storage, and AWS S3 storage.\n\n\n\n\n\n\nImprovements\n\n\nA non-comprehensive list of improvements:\n\n\n\n\nThe event counters are now fully configurable\n\n\nWorkflows can be stopped and deleted in the Admin UI\n\n\nMultiple scheduled events can be edited at once\n\n\nDeleting Series now warns if series contains events. You can configure if the user is allowed to\n  delete a series containing events in the series endpoint config file.\n\n\nThe video editor can be opened while an event is processed\n\n\nAdd Moodle groups to Moodle role provider\n\n\nThe order of appearance of workflows can be configured\n\n\nAbility to send HTML emails\n\n\nAbility for blacklisting languages from the admin UI\n\n\nUpdate LTI Series Tool\n\n\nFill creator metadata field with actual user when new event\n\n\nVideo editor\n\n\nIntuitive Merging of Video Segments\n\n\nAdd new modal to edit multiple scheduled events at once\n\n\nAs an unprivileged user, I only want to see series and events that I have write access to.\n\n\nLossless Concat Operation\n\n\nCapture Agent User\n - Opencast 6.0 introduces per-tenant restricted access capture agent users to avoid the\n  global system account to be used to connect external devices.\n\n\nUpdate Paella Player to 6.0.x\n\n\n\n\nConfiguration changes\n\n\n\n\n\n\nThe tracking options defaults have changed to be more aware of the European Union's General Data Protection\n  Regulation. Note that this is \nstill configurable\n.\n\n\n\n\n\n\nThe role \nROLE_UI_EVENTS_DETAILS_GENERAL_VIEW\n for viewing the publications (previously general) tab in the event\n  details modal has been renamed to \nROLE_UI_EVENTS_DETAILS_PUBLICATIONS_VIEW\n for consistency.\n\n\n\n\n\n\nRelease Schedule\n\n\n\n\n\n\n\n\nDate\n\n\nPhase\n\n\n\n\n\n\n\n\n\n\nSep 25th 2018\n\n\nFeature Freeze\n\n\n\n\n\n\nOct 29th - Nov 4th 2018\n\n\nTranslation week\n\n\n\n\n\n\nNov 5th - Nov 18th 2018\n\n\nPublic QA phase\n\n\n\n\n\n\nDec 10th 2018\n\n\nRelease of Opencast 6.0\n\n\n\n\n\n\n\n\nRelease Managers\n\n\n\n\nMatthias Neugebauer (University of M\u00fcnster)\n\n\nLars Kiesow (ELAN e.V.)",
            "title": "Release Notes"
        },
        {
            "location": "/releasenotes/#opencast-6-release-notes",
            "text": "",
            "title": "Opencast 6: Release Notes"
        },
        {
            "location": "/releasenotes/#new-features",
            "text": "Video Editor - Thumbnails  - When displaying lists of videos, thumbnails are usually used to make such lists more\n  appealing. The video editor allows the user to choose between the default thumbnail (automatically created), a\n  snapshot thumbnail (extract at current position from video stream) or an uploaded thumbnail.  This allows the user to\n  get the best thumbnails for his videos with as little effort as possible.    Video Editor - Track selection  - In case multiple tracks have been ingested, the video editor allows the user to\n  choose which tracks should be processed. In case of a dual track lecture recording, the presenter track could be\n  exluded from publication in case the recorded person would want this.    Cheatsheet  - A per page keyboard shortcut list is available so that users can at any time and page see what\n  keyboard shortcuts are currenlty available.    Capture Agent Access Management  - The Admin UI now supports access management for capture agents. This features\n  addresses the need to allow unprivileged users to access the Admin UI to manage their own content and cut videos\n  without allowing them to schedule events or change the scheduling as this task is usually in the responsibility of a\n  dedicated team.  It is also possible to permit users access to specific subsets of the available capture agents.    External API 1.1.0  - For the first time, Opencast takes advantage of its state-of-the-art versioned API by\n  introducing the External API 1.1.0.  The new version extends the API to support scheduling of events and access to\n  workflows.  The filter and sort facilities have been extended and additional fields are directly delivered by some\n  core requests with allows clients to access them way faster.  The External API 1.0.0 is still supported relieving\n  existing clients from the need to be timely adapted.    Processing Settings Persistency  - A new persistence layer for processing settings has been introduced. This allows\n  the Admin UI to not just provide processing settings as input when starting workflows, but also to display processing\n  settings on event basis.    New Workflow Operation Handler   demux  can be used to demux multiple streams from a container into seperate containers  image-convert  can convert multiple source images into multiple target images with different encoding  mattermost-notify  sends notification to services like Mattermost or Slack  move-to-remote  moves files in the asset manager from one storage system to another  multi-encode  allows encoding of multiple source tracks into multiple target tracks with differnet encoding  process-smil  edits media files based on descriptions from a SMIL file  select-tracks  can filter source tracks based on workflow properties  start-workflow  allows a workflow to start another workflow     Asset Manager Storage Layers  - The Asset Manager now supports multiple storage layers natively.  This allows\n  users to move data from local storage to remote storage within Opencast.  These moves can be triggered manually, or\n  via a built-in timer.  Currently we support local file storage, and AWS S3 storage.",
            "title": "New Features"
        },
        {
            "location": "/releasenotes/#improvements",
            "text": "A non-comprehensive list of improvements:   The event counters are now fully configurable  Workflows can be stopped and deleted in the Admin UI  Multiple scheduled events can be edited at once  Deleting Series now warns if series contains events. You can configure if the user is allowed to\n  delete a series containing events in the series endpoint config file.  The video editor can be opened while an event is processed  Add Moodle groups to Moodle role provider  The order of appearance of workflows can be configured  Ability to send HTML emails  Ability for blacklisting languages from the admin UI  Update LTI Series Tool  Fill creator metadata field with actual user when new event  Video editor  Intuitive Merging of Video Segments  Add new modal to edit multiple scheduled events at once  As an unprivileged user, I only want to see series and events that I have write access to.  Lossless Concat Operation  Capture Agent User  - Opencast 6.0 introduces per-tenant restricted access capture agent users to avoid the\n  global system account to be used to connect external devices.  Update Paella Player to 6.0.x",
            "title": "Improvements"
        },
        {
            "location": "/releasenotes/#configuration-changes",
            "text": "The tracking options defaults have changed to be more aware of the European Union's General Data Protection\n  Regulation. Note that this is  still configurable .    The role  ROLE_UI_EVENTS_DETAILS_GENERAL_VIEW  for viewing the publications (previously general) tab in the event\n  details modal has been renamed to  ROLE_UI_EVENTS_DETAILS_PUBLICATIONS_VIEW  for consistency.",
            "title": "Configuration changes"
        },
        {
            "location": "/releasenotes/#release-schedule",
            "text": "Date  Phase      Sep 25th 2018  Feature Freeze    Oct 29th - Nov 4th 2018  Translation week    Nov 5th - Nov 18th 2018  Public QA phase    Dec 10th 2018  Release of Opencast 6.0",
            "title": "Release Schedule"
        },
        {
            "location": "/releasenotes/#release-managers",
            "text": "Matthias Neugebauer (University of M\u00fcnster)  Lars Kiesow (ELAN e.V.)",
            "title": "Release Managers"
        },
        {
            "location": "/upgrade/",
            "text": "Upgrading Opencast from 4.x to 5.0\n\n\nThis guide describes how to upgrade Opencast 4.x to 5.0. In case you need information about how to upgrade older\nversions of Opencast, please refer to the \nold release notes\n.\n\n\nHow to Upgrade\n\n\n\n\nStop your current Opencast instance\n\n\nReplace Opencast 4.x with 5.0\n\n\nBack-up Opencast files and database (optional)\n\n\nUpgrade the database\n\n\nUpgrade the ActiveMQ configuration\n\n\nReview the \nconfiguration changes\n and adjust your configuration accordingly\n\n\n\n\nDatabase Migration\n\n\nAs part of removing mentions of the old name Matterhorn, all database table names have been changed and are now prefixed\nwith \noc_\n.  This requires an database schema update. As with all database migrations, we recommend to make a database\nbackup before attempting the upgrade.\n\n\nYou can find the database upgrade script in \ndocs/upgrade/4_to_5/\n. There are two scripts which are essentially doing\nthe same thing with the MariaDB one running a few more checks on the database for safety which cannot be run like this\non MySQL.  More information about the differences can be found in the readme next to the scripts.\n\n\nActiveMQ Migration\n\n\nOpencast 5.0 needs a new ActiveMQ message broker configuration. Please follow the steps of the \nmessage broker\nconfiguration guide\n to deploy a new configuration. No data migration is required for\nthis since the message broker contains only temporary data.\n\n\nConfiguration Changes\n\n\nHTTP Basic authentication is enabled by default (see \netc/security/mh_default_org.xml\n). Make sure you've enabled\nHTTPS before using it.\n\n\nPaella Player has been included in Opencast 5.0. So you can choose between the Theodul and Paella player.\nThis can be done by setting the \nprop.player\n property in the tennant's configuration file (for example\n\netc/org.opencastproject.organization-mh_default_org.cfg\n).  Additionally, the path to the Paella player configuration\nfolder is added in \netc/custom.properties\n as \norg.opencastproject.engage.paella.config.folder\n with the default value\nof \n${karaf.etc}/paella\n. There you will find the default configuration. The Paella URL pattern was also added to the\ndefault security configuration \netc/security/mh_default_org.xml\n.\n\n\nWorkflow definition IDs have been changed and are no longer prefixed with \nng-\n anymore. If you are using the default\nworkflows or include them as part of your custom workflow, please adapt the changes. You can find the workflow\ndefinitions in \netc/workflows/*.xml\n. You may also want to adapt the workflow ID changes in the following configuration\nfiles:\n\n\n\n\n\n\n\n\nConfiguration file name\n\n\nProperty name\n\n\n\n\n\n\n\n\n\n\ncustom.properties\n\n\norg.opencastproject.workflow.default.definition\n\n\n\n\n\n\norg.opencastproject.ingest.scanner.InboxScannerService-inbox.cfg\n\n\nworkflow.definition\n\n\n\n\n\n\norg.opencastproject.transcription.ibmwatson.IBMWatsonTranscriptionService.cfg\n\n\nworkflow\n\n\n\n\n\n\n\n\nThe workflow control functionality includes some new REST endpoints.  Therefore the new URL patterns has been added to\nthe tenant's security configuration (e.g. \netc/security/mh_default_org.xml\n.)\n\n\nAs Piwik has been renamed to Matomo, Opencast changed the name for the plugin and configuration keys too.\nSo if you already configured a Piwik server please adapt the following keys in\n\netc/org.opencastproject.organization-mh_default_org.cfg\n:\n\n\n\n\nprop.player.piwik.server\n \u2192 \nprop.player.matomo.server\n\n\nprop.player.piwik.site_id\n \u2192 \nprop.player.matomo.site_id\n\n\nprop.player.piwik.heartbeat\n \u2192 \nprop.player.matomo.heartbeat\n\n\nprop.player.piwik.track_events\n \u2192 \nprop.player.matomo.track_events\n\n\n\n\nThe publication channel's listprovider configurations \netc/listproviders/publication.channel.labels.properties\n and\n\netc/listproviders/publication.channel.icons.properties\n have been merged into\n\netc/listproviders/publication.channels.properties\n.\n\n\nSeveral service job load values were updated. You can find these configuration files by running the command\n\ngrep job.load etc/org.opencastproject.*\n on the command line or by searching for \njob.load\n string in Opencast's\nservice configuration files.",
            "title": "Upgrade"
        },
        {
            "location": "/upgrade/#upgrading-opencast-from-4x-to-50",
            "text": "This guide describes how to upgrade Opencast 4.x to 5.0. In case you need information about how to upgrade older\nversions of Opencast, please refer to the  old release notes .",
            "title": "Upgrading Opencast from 4.x to 5.0"
        },
        {
            "location": "/upgrade/#how-to-upgrade",
            "text": "Stop your current Opencast instance  Replace Opencast 4.x with 5.0  Back-up Opencast files and database (optional)  Upgrade the database  Upgrade the ActiveMQ configuration  Review the  configuration changes  and adjust your configuration accordingly",
            "title": "How to Upgrade"
        },
        {
            "location": "/upgrade/#database-migration",
            "text": "As part of removing mentions of the old name Matterhorn, all database table names have been changed and are now prefixed\nwith  oc_ .  This requires an database schema update. As with all database migrations, we recommend to make a database\nbackup before attempting the upgrade.  You can find the database upgrade script in  docs/upgrade/4_to_5/ . There are two scripts which are essentially doing\nthe same thing with the MariaDB one running a few more checks on the database for safety which cannot be run like this\non MySQL.  More information about the differences can be found in the readme next to the scripts.",
            "title": "Database Migration"
        },
        {
            "location": "/upgrade/#activemq-migration",
            "text": "Opencast 5.0 needs a new ActiveMQ message broker configuration. Please follow the steps of the  message broker\nconfiguration guide  to deploy a new configuration. No data migration is required for\nthis since the message broker contains only temporary data.",
            "title": "ActiveMQ Migration"
        },
        {
            "location": "/upgrade/#configuration-changes",
            "text": "HTTP Basic authentication is enabled by default (see  etc/security/mh_default_org.xml ). Make sure you've enabled\nHTTPS before using it.  Paella Player has been included in Opencast 5.0. So you can choose between the Theodul and Paella player.\nThis can be done by setting the  prop.player  property in the tennant's configuration file (for example etc/org.opencastproject.organization-mh_default_org.cfg ).  Additionally, the path to the Paella player configuration\nfolder is added in  etc/custom.properties  as  org.opencastproject.engage.paella.config.folder  with the default value\nof  ${karaf.etc}/paella . There you will find the default configuration. The Paella URL pattern was also added to the\ndefault security configuration  etc/security/mh_default_org.xml .  Workflow definition IDs have been changed and are no longer prefixed with  ng-  anymore. If you are using the default\nworkflows or include them as part of your custom workflow, please adapt the changes. You can find the workflow\ndefinitions in  etc/workflows/*.xml . You may also want to adapt the workflow ID changes in the following configuration\nfiles:     Configuration file name  Property name      custom.properties  org.opencastproject.workflow.default.definition    org.opencastproject.ingest.scanner.InboxScannerService-inbox.cfg  workflow.definition    org.opencastproject.transcription.ibmwatson.IBMWatsonTranscriptionService.cfg  workflow     The workflow control functionality includes some new REST endpoints.  Therefore the new URL patterns has been added to\nthe tenant's security configuration (e.g.  etc/security/mh_default_org.xml .)  As Piwik has been renamed to Matomo, Opencast changed the name for the plugin and configuration keys too.\nSo if you already configured a Piwik server please adapt the following keys in etc/org.opencastproject.organization-mh_default_org.cfg :   prop.player.piwik.server  \u2192  prop.player.matomo.server  prop.player.piwik.site_id  \u2192  prop.player.matomo.site_id  prop.player.piwik.heartbeat  \u2192  prop.player.matomo.heartbeat  prop.player.piwik.track_events  \u2192  prop.player.matomo.track_events   The publication channel's listprovider configurations  etc/listproviders/publication.channel.labels.properties  and etc/listproviders/publication.channel.icons.properties  have been merged into etc/listproviders/publication.channels.properties .  Several service job load values were updated. You can find these configuration files by running the command grep job.load etc/org.opencastproject.*  on the command line or by searching for  job.load  string in Opencast's\nservice configuration files.",
            "title": "Configuration Changes"
        },
        {
            "location": "/changelog/",
            "text": "Changelog\n\n\nOpencast 5\n\n\nOpencast 5.1\n\n\nReleased on September 3, 2018\n\n\n\n\n[\nMH-13067\n][\n#404\n] -\n  Configuration panel does not work for default workflow\n\n\n[\nMH-13049\n][\n#400\n] -\n  Fix video editor zoom dropdown showing wrong value\n\n\n[\nMH-13055\n][\n#396\n] -\n  Stop making events with no ACL public on ingest\n\n\n[\nMH-13048\n][\n#394\n] -\n  Improve stability of the series index rebuild\n\n\n[\nMH-13047\n][\n#393\n] -\n  Document using Nginx for HTTPS\n\n\n[\nMH-13044\n][\n#390\n] -\n  Organization server configuration documentation\n\n\n[\nMH-12016\n][\n#379\n] -\n  Scrolling role fetch\n\n\n[\nMH-13031\n][\n#377\n] -\n  Active transaction notification on top\n\n\n[\nMH-13029\n][\n#375\n] -\n  Don't show old notifications\n\n\n[\nMH-13023\n][\n#370\n] -\n  Let default value fulfill requirement\n\n\n[\nMH-13018\n][\n#367\n] -\n  re-add recordings json to 5x (includes MH-12828 re-add conflicts.json)\n\n\n[\nMH-13020\n][\n#366\n] -\n  Read listproviders as UTF-8\n\n\n[\nMH-13017\n][\n#363\n] -\n  JS syntax error in publish workflow\n\n\n[\nMH-13015\n][\n#361\n] -\n  5.x database upgrade scripts\n\n\n[\nMH-13014\n][\n#360\n] -\n  Don't show stale search results\n\n\n[\nMH-13006\n][\n#353\n] -\n  Waveform operation cleanup creates problem with asynchronous NFS\n\n\n[\nMH-13003\n][\n#352\n] -\n  Implement detection of already recorded (as opposed to yet to be recorded, scheduled) events by the index service\n\n\n[\nMH-13005\n][\n#351\n] -\n  Skip waveform operation when no tracks\n\n\n[\nMH-13001\n][\n#347\n] -\n  Fixed live scheduler service pom\n\n\n[\nMH-12988\n][\n#337\n] -\n  delete-scheduled-live Fix for scheduled live event not deleted\n\n\n[\nMH-12986\n][\n#333\n] -\n  Admin UI deployed debugging: include source in SourceMap files\n\n\n[\nMH-12981\n][\n#331\n] -\n  fix for local admin-ui develop finding main.css\n\n\n[\nMH-12979\n][\n#325\n] -\n  Automatically test ddl scripts\n\n\n[\nMH-12978\n][\n#324\n] -\n  Fix data-placeholder in add event wizard\n\n\n[\nMH-12974\n][\n#318\n] -\n  Access denial to event for unprivileged user\n\n\n[\nMH-12970\n][\n#315\n] -\n  Senseless XACML parsing\n\n\n[\nMH-12966\n][\n#312\n] -\n  Do not pre-select-from option in metadata property sheets\n\n\n[\nMH-12963\n][\n#310\n] -\n  Localize dates/times in add-event summary\n\n\n[\nMH-12950\n][\n#309\n] -\n  Fix for workflow with no acl in solr index\n\n\nNOJIRA: Skip install of Crowdin if it is already installed\n  \n\n\n[\nMH-12957\n][\n#300\n] -\n  Defaults on tab Source in Add Event wizards are broken\n\n\n[\nMH-12954\n][\n#297\n] -\n  wrong date format in coverimage file\n\n\n\n\nOpencast 5.0\n\n\nReleased on June 12, 2018\n\n\n\n\n[\nMH-12952\n][\n#295\n] -\n  animate WOH dependency version fixed\n\n\n[\nMH-12946\n][\n#290\n] -\n  Fix summary of add-event-dialog\n\n\n[\nMH-12944\n][\n#288\n] -\n  Remove bashism from start script\n\n\n[\nMH-12905\n][\n#287\n] -\n  TEMPORARY Karaf config assembly workaround (KARAF-5693)\n\n\n[\nMH-12943\n][\n#286\n] -\n  Minor Paella config REST endpoint improvements\n\n\n[\nMH-12942\n][\n#285\n] -\n  Paella player config REST endpoint should be accessible by anonymous user\n\n\n[\nMH-12941\n][\n#284\n] -\n  Gracefully handle empty flavors\n\n\n[\nMH-12940\n][\n#283\n] -\n  Ensure admin configuration is applied\n\n\n[\nMH-12864\n][\n#282\n] -\n  Don't attempt to parse 'undefined'\n\n\n[\nMH-12938\n][\n#281\n] -\n  Fix NullPointerException if no flavor is set\n\n\n[\nMH-12937\n][\n#280\n] -\n  Correctly place admin UI test helper\n\n\n[\nMH-12936\n][\n#279\n] -\n  Handle invalid flavors\n\n\n[\nMH-12935\n][\n#278\n] -\n  Update Docker image repository documentation\n\n\n[\nMH-12934\n][\n#277\n] -\n  Update translations\n\n\n[\nMH-12933\n][\n#276\n] -\n  Link documentation from Systemd unit\n\n\n[\nMH-12932\n][\n#275\n] -\n  Kernel Build Failure\n\n\n[\nMH-12922\n][\n#272\n] -\n  Job load fixes\n\n\n[\nMH-12929\n][\n#271\n] -\n  Change paella URL to /paella/ui\n\n\n[\nMH-12928\n][\n#270\n] -\n  Mitigation for KARAF-5526\n\n\n[\nMH-12926\n][\n#269\n] -\n  Prevent cluttering of logs by invalid access\n\n\n[\nMH-12924\n][\n#268\n] -\n  fix missing dropdown arrow\n\n\n[\nMH-12919\n][\n#262\n] -\n  REST Docs Dependencies\n\n\n[\nMH-12917\n][\n#260\n] -\n  Remove debug logging\n\n\n[\nMH-12916\n][\n#259\n] -\n  Admin Interface Configuration Defaults\n\n\n[\nMH-12914\n][\n#258\n] -\n  Remove deprecated IOUtils.closeQuietly\n\n\n[\nMH-12913\n][\n#257\n] -\n  Fix Admin Interface Deprecation Warnings\n\n\n[\nMH-12868\n][\n#255\n] -\n  Make frame-by-frame skipping function in the editor use the \"actual\" framerate\n\n\n[\nMH-12908\n][\n#251\n] -\n  Fix escaping of spaces\n\n\n[\nMH-12907\n][\n#250\n] -\n  Fix segmentation default job load\n\n\n[\nMH-12906\n][\n#249\n] -\n  Composoer should ignore system specific output pathes like /dev/null\n\n\n[\nMH-12902\n][\n#248\n] -\n  closing videoeditor should continue in events list\n\n\n[\nMH-12901\n][\n#247\n] -\n  Fix YouTube publication job loads\n\n\n[\nMH-12900\n][\n#246\n] -\n  Fix search service job loads\n\n\n[\nMH-12899\n][\n#245\n] -\n  Fix streaming distribution job load defaults\n\n\n[\nMH-12898\n][\n#244\n] -\n  Fix download distribution job load defaults\n\n\n[\nMH-12897\n][\n#243\n] -\n  Improve visibility of selected segments in the videoeditor\n\n\n[\nMH-12896\n][\n#242\n] -\n  Clarify default player configuration\n\n\n[\nMH-12894\n][\n#240\n] -\n  Update markdownlint\n\n\n[\nMH-12893\n][\n#239\n] -\n  Added ability to configure the job load for the aws s3 distribution service.\n\n\n[\nMH-12892\n][\n#238\n] -\n  Added ability to configure the job load for the transcription service.\n\n\n[\nMH-12888\n][\n#235\n] -\n  Missing FFmpeg on Travis CI\n\n\n[\nMH-12887\n][\n#234\n] -\n  Only set job date completed and runtime once.\n\n\n[\nMH-12883\n][\n#230\n] -\n  Maven build of admin-ui module without frontend profile\n\n\n[\nMH-12882\n][\n#229\n] -\n  Fix org.w3c.dom.smil version\n\n\n[\nMH-12881\n][\n#228\n] -\n  Remove deprecated method\n\n\n[\nMH-12880\n][\n#227\n] -\n  Remove redundant OSGI declarations\n\n\n[\nMH-12879\n][\n#226\n] -\n  Default location of paella configuration\n\n\n[\nMH-12878\n][\n#224\n] -\n  Don't verify NPM cache to speed up build process\n\n\n[\nMH-12874\n][\n#223\n] -\n  NotFoundException handling for OAI-PMH retract operation with non published event\n\n\n[\nMH-12872\n][\n#222\n] -\n  event can not be deleted\n\n\n[\nMH-12873\n][\n#221\n] -\n  Speed up test builds\n\n\n[\nMH-12864\n][\n#215\n] -\n  Readonly mode of fields not working correctly in property sheets\n\n\n[\nMH-12807\n][\n#213\n] -\n  Do not overwrite owner\n\n\n[\nMH-12863\n][\n#212\n] -\n  Fix default owner in SMIL endpoint\n\n\n[\nMH-12862\n][\n#211\n] -\n  Line break after required marker in REST docs\n\n\n[\nMH-12834\n][\n#207\n] -\n  Central documentation for filtering, sorting and pagination\n\n\n[\nMH-12833\n][\n#204\n] -\n  Consistently use External API as name\n\n\n[\nMH-12852\n][\n#203\n] -\n  Required fields not indicated in the event details and series details modals\n\n\n[\nMH-12843\n][\n#200\n] -\n  Fix \u201cAdd Event\u201d Tab Index\n\n\nUpdate main readme\n  \n\n\nFix tabs and trailing spaces in docs\n  \n\n\n[\nMH-12839\n][\n#196\n] -\n  fix all pom.xml\n\n\n[\nMH-12837\n][\n#194\n] -\n  external series API ACL is required\n\n\n[\nMH-12832\n][\n#192\n] -\n  Update to commons-collection4\n\n\n[\nMH-12836\n][\n#191\n] -\n  Fix event-comment dependencies not correctly specified\n\n\n[\nMH-12831\n][\n#190\n] -\n  Fixing dependencies\n\n\nNOJIRA fix engage paella url security rules\n  \n\n\nNOJIRA Localization developer guide updated\n  \n\n\n[\nMH-12780\n][\n#184\n] -\n  Fix sorting jobs by identifier in Systems->Jobs\n\n\n[\nMH-12824\n][\n#183\n] -\n  Speed up mvn site\n\n\nT/clarify wording of user tracking in documentation\n  \n\n\n[\nMH-12818\n][\n#177\n] -\n  Improve Sox service tests\n\n\nNOJIRA Crowdin project configuration updated\n  \n\n\nNOJIRA Crowdin documentation updated\n  \n\n\n[\nMH-12771\n][\n#173\n] -\n  Document fields of External API 1.0.0\n\n\n[\nMH-12795\n][\n#163\n] -\n  REST docs don't respect @Produces annotation on class level\n\n\n[\nMH-12788\n][\n#157\n] -\n  UTF-8 encoding settings in OAI-PMH publication service remote\n\n\n[\nMH-12616\n][\n#152\n] -\n  Admin UI Flexible Asset Upload override or fallback display text\n\n\n[\nMH-12775\n][\n#146\n] -\n  Add JavaScript source map generation\n\n\n[\nMH-12768\n][\n#142\n] -\n  Minor XACMLAuthorizationService fixes\n\n\n\n\n[\nMH-12825\n][\n#139\n] -\n  Add markdownlint to Travis CI\n\n\n\n\n\n\n[\nMH-12760\n][\n#160\n] -\n  Cross-link column date in events table to enable the start date filter\n\n\n\n\n[\nMH-12789\n][\n#158\n] -\n  Remove tabs and trailing spaces in LTI tools\n\n\n[\nMH-12509\n][\n#151\n] -\n  Enable HTTP basic auth in default config\n\n\n[\nMH-12759\n][\n#149\n] -\n  More Control Over Workflows\n\n\n[\nMH-12779\n][\n#147\n] -\n  Support X-Forwarded-Proto header\n\n\n[\nMH-12649\n][\n#138\n] -\n  clone workflow operation handler\n\n\n[\nMH-12764\n][\n#137\n] -\n  update license information for admin-ui\n\n\n[\nMH-12763\n][\n#136\n] -\n  Minor Composer Fixes\n\n\n[\nMH-12762\n][\n#135\n] -\n  Fix Spaces In Configuration\n\n\nFallback For Synfig Install\n  \n\n\nclean up woh documentation\n  \n\n\nMake Travis check for tabs in pom.xml files\n  \n\n\nAdd Mkdocs To Travis Builds\n  \n\n\n[\nMH-12757\n][\n#128\n] -\n  Fix ClassCastException\n\n\n[\nMH-12755\n][\n#127\n] -\n  Fix workflow-workflowoperation dependencies\n\n\n[\nMH-12746\n][\n#126\n] -\n  Update Checkstyle\n\n\n[\nMH-12746\n][\n#125\n] -\n  Update Apache HTTPComponents\n\n\n[\nMH-12746\n][\n#124\n] -\n  Update Mina\n\n\n[\nMH-12746\n][\n#123\n] -\n  Remove commons-logging\n\n\n[\nMH-12746\n][\n#122\n] -\n  Update Jackson\n\n\n[\nMH-12752\n][\n#121\n] -\n  Ignore VSCode project data\n\n\n[\nMH-12751\n][\n#120\n] -\n  Add Travis Badge\n\n\n[\nMH-12735\n][\n#119\n] -\n  Remove Undocumented Operations\n\n\n[\nMH-12746\n][\n#115\n] -\n  Library Update\n\n\n[\nMH-12742\n][\n#113\n] -\n  Update to Karaf 4.0.10\n\n\n[\nMH-12744\n][\n#111\n] -\n  Fix migration bundle dependencies\n\n\n[\nMH-12739\n][\n#109\n] -\n  Transcription Service updated to support Paella\n\n\n[\nMH-12737\n][\n#108\n] -\n  OAI-PMH publication service\n\n\n[\nMH-12732\n][\n#106\n] -\n  Remove Unused Remote Service Registry\n\n\n[\nMH-12731\n][\n#105\n] -\n  Improve Recreating Series Index\n\n\n[\nMH-12730\n][\n#104\n] -\n  Workflow Index Rebuild Performance\n\n\n[\nMH-12711\n][\n#100\n] -\n  improve xacml parser\n\n\n[\nMH-12726\n][\n#99\n] -\n  Add description to theme\n\n\n[\nMH-12704\n][\n#98\n] -\n  Captions support for paella\n\n\n[\nMH-12718\n][\n#97\n] -\n  Animate Service\n\n\n[\nMH-12713\n][\n#95\n] -\n  Series cannot be created\n\n\n[\nMH-12705\n][\n#87\n] -\n  Fix scheduler hot-deployment\n\n\n[\nMH-12701\n][\n#84\n] -\n  Paella: Localization files + crowdin config file\n\n\n[\nMH-12692\n][\n#83\n] -\n  update maven bundle plugin for java8\n\n\n[\nMH-12663\n][\n#81\n] -\n  Don't search for non-existing WFR files\n\n\n[\nMH-12694\n][\n#80\n] -\n  Save\" button in the editor now stays on the same page.\n\n\n[\nMH-12693\n][\n#77\n] -\n  Notes on how to enable, upgrade to HTTPS\n\n\n[\nMH-12675\n][\n#76\n] -\n  Send default startdate to backend also if it hasn't been changed.\n\n\n[\nMH-12656\n][\n#75\n] -\n  Updates to Theodul Matomo (formerly Piwik) Plugin\n\n\n[\nMH-12684\n][\n#69\n] -\n  Make License List Provider More Flexible\n\n\n[\nMH-12683\n][\n#68\n] -\n  Improve Video Editor Tests\n\n\n[\nMH-12681\n][\n#66\n] -\n  update media package series catalogs on event metadata update\n\n\n[\nMH-12677\n][\n#65\n] -\n  Be less technical about displaying the version number\n\n\n[\nMH-12674\n][\n#63\n] -\n  Remove unused hard-coded list providers\n\n\n[\nMH-12665\n][\n#62\n] -\n  Sort table on startup\n\n\n[\nMH-12649\n][\n#59\n] -\n  clone workflow operation handler\n\n\n[\nMH-12668\n][\n#58\n] -\n  Update packages of admin ui build pipeline\n\n\nUse $timeout instead of $interval to resolve MH-12667\n  \n\n\n[\nMH-12661\n][\n#52\n] -\n  Update angular-translate to 2.17.0\n\n\n[\nMH-12660\n][\n#51\n] -\n  Scheduling Events by Specifying End Time\n\n\n[\nMH-12658\n][\n#50\n] -\n  Disable Jasmine for Theodul\n\n\n[\nMH-12653\n][\n#46\n] -\n  Authorization service should use workspace#read() wherever possible\n\n\n[\nMH-12600\n][\n#45\n] -\n  Move userdirectory stuff from bundle \nkernel\n to \nuserdirectory\n\n\n[\nMH-12648\n][\n#42\n] -\n  As a system administrator, I want to use different encoding \u2026\n\n\n[\nMH-12645\n][\n#39\n] -\n  Created an option to rebuild index for an specific service\n\n\n[\nMH-12644\n][\n#37\n] -\n  External API index schema fixes\n\n\n[\nMH-12538\n][\n#36\n] -\n  Remove obsolete ACL distribution service and WOH distribute-acl\n\n\n[\nMH-12639\n][\n#35\n] -\n  update angular-chosen to 1.8.0\n\n\n[\nMH-11984\n][\n#32\n] -\n  Allow customization of the username-to-user-role mapping\n\n\n[\nMH-12367\n][\n#30\n] -\n  Renaming all database tables\n\n\n[\nMH-12633\n][\n#29\n] -\n  Fix version of maven-dependency-plugin\n\n\n[\nMH-12544\n][\n#26\n] -\n  Play Deleted Segments in Video Editor\n\n\n[\nMH-12575\n][\n#25\n] -\n  Upgrade to AngularJS 1.5.11\n\n\n[\nMH-12595\n][\n#24\n] -\n  Improve Publications Usability\n\n\n[\nMH-12613\n][\n#23\n] -\n  New WorkflowOperationHandler 'create-event'\n\n\n[\nMH-12628\n][\n#20\n] -\n  MH-12629, MH-12630, Minor database fixes\n\n\n[\nMH-10560\n][\n#19\n] -\n  Live Scheduler Service\n\n\n[\nMH-12615\n][\n#17\n] -\n  Improve the languages drop-down menu\n\n\n[\nMH-12623\n][\n#16\n] -\n  Improve workflow dropdown menu\n\n\n[\nMH-12621\n][\n#15\n] -\n  submit paella player\n\n\n[\nMH-12624\n][\n#11\n] -\n  Fix link to Karaf remote debugging documentation\n\n\nUpdate debs.md\n  \n\n\n[\nMH-12472\n][\n#8\n] -\n  FFmpeg Composer Implementation\n\n\n[\nMH-12502\n][\n#7\n] -\n  Do Not Leave Files In Workspace\n\n\n[\nMH-12477\n][\n#6\n] -\n  Operation To Log Workflow State\n\n\n[\nMH-12555\n][\n#5\n] -\n  Add support for Piwik Media Analytics\n\n\n[\nMH-10016\n][\n#4\n] -\n  Default Workflow\n\n\n[\nMH-12603\n][\n#2\n] -\n  Consistent Workflow IDs\n\n\n[\nMH-12622\n][\n#1\n] -\n  Surefire Versions Should Not Diverge\n\n\n\n\nOpencast 4\n\n\nOpencast 4.4\n\n\nReleased on May 31, 2018\n\n\n\n\n[MH-12923]\n - ServiceRegistry does not close db connction\n\n\n[MH-12841]\n - Opencast is ignoring permissions\n\n\n[MH-12840]\n - LTI user provider may allow LMS admins to become Opencast admins\n\n\n\n\nOpencast 4.3\n\n\nReleased on March 28, 2018\n\n\n\n\n[MH-12774]\n - Fix differences in provided security configurations\n\n\n[MH-12773]\n - Fix that non-admins cannot add new assets\n\n\n[MH-12772]\n - Fix acces to assets for non-admins\n\n\n[MH-12789]\n - Remove tabs and trailing spaces in LTI tools\n\n\n[MH-12790]\n - Make LTI respect player configuration\n\n\n\n\nOpencast 4.2\n\n\nReleased on March 14, 2018\n\n\n\n\n[MH-12766]\n - Metadata view and edit roles where at some places set\n  incorrectly\n\n\n[MH-12765]\n - Navigating through series in the series details modal causes\n  failing attempts to save ACLs\n\n\n[MH-12758]\n - Changing the ACLs does not trigger AssetManagerDecorators\n\n\n[MH-12747]\n - Heartbeat is broken\n\n\n[MH-12745]\n - Fix heartbeat config logging\n\n\n[MH-12743]\n - OAIPMH-Republish-Operation tries to republish to ASW3\n\n\n[MH-12728]\n - Add LAST-MODIFIED to ical event properties\n\n\n[MH-12727]\n - OptimisticLockException on worker node can cause jobs to be\n  stuck in DISPATCHING state\n\n\n[MH-12725]\n - Series/Events ACL update causes scheduled recordings in the\n  series/the events to disappear from CA calendar\n\n\n[MH-12717]\n - Series metadata update causes scheduled recordings in the\n  series to disappear from CA calendar\n\n\n[MH-12711]\n - XACML Parser should be more robust\n\n\n[MH-12707]\n - Fix problem with non-strict mode in URL-Signing\n\n\n[MH-12706]\n - Old zombie workflows cannot be stopped, suspended etc.\n\n\n[MH-12668]\n - Update admin ui build pipeline\n\n\n[MH-12651]\n - Scheduling repeating events through Admin UI is very slow\n\n\n\n\nOpencast 4.1\n\n\nReleased on Februar 7, 2018\n\n\n\n\n[MH-12695]\n - Improve Synchronization in WorkflowService\n\n\n[MH-12689]\n - Flickering filter: When loading the page, all filters\n  briefly appear and disappear again\n\n\n[MH-12687]\n - Date filters not working\n\n\n[MH-12685]\n - Performance issue in filters\n\n\n[MH-12682]\n - TimelinePreview Concurrency Problem\n\n\n[MH-12676]\n - List provider service implementation is not thread-safe\n\n\n[MH-12673]\n - Content-Type is not set for JavaScript files\n\n\n[MH-12664]\n - Ensure series can be deleted\n\n\n[MH-12662]\n - Special characters in modal window titles are double-escaped\n\n\n[MH-12657]\n - Users of non-admin groups cannot create events\n\n\n[MH-12652]\n - Scheduler service needs to restrict queries to episodes\n  owned by it\n\n\n[MH-12641]\n - Asset manager conflict checks are very slow\n\n\n[MH-12638]\n - Migration bundle needs to have a higher runlevel\n\n\n[MH-12637]\n - Remove event id from episode DC catalog during migration\n\n\n[MH-12632]\n - Make index rebuild robust\n\n\n[MH-12631]\n - Drop the ORGANIZER field from the ical feed\n\n\n[MH-12627]\n - Start Task copies files into workspace\n\n\n[MH-12620]\n - Document ActiveMQ memory requirements\n\n\n[MH-12610]\n - Navigating through events in the event details modal causes\n  failing attempts to save ACLs\n\n\n[MH-12609]\n - As a user, I expect scheduling of events to be working\n\n\n[MH-12606]\n - Using \"Start Task\" with a workflow containing an embedded\n  script in the configuration which somehow modifies the input parameters does not update those values properly\n\n\n[MH-12602]\n - External API gives 500 error for migrated series that do not\n  have creator field\n\n\n[MH-12601]\n - Fast Workflow Does Not Attach Series Metadata\n\n\n[MH-12582]\n - Editor WOH should not encode videos unless it is strictly\n  necessary (to save time and resources)\n\n\n[MH-12495]\n - Job dispatching with loads needs optimization\n\n\n[MH-12476]\n - Delay start of job dispatching on startup\n\n\n[MH-10016]\n - Cannot Change Default Workflow\n\n\n\n\nOpencast 4.0\n\n\nReleased on December 8, 2017\n\n\n\n\n[MH-12597]\n - When reindexing, some events may incorrectly be displayed as\n  \"Scheduled\" instead of \"Processed\" or \"Failed\"\n\n\n[MH-12596]\n - Video Editor Ignores Workspace\n\n\n[MH-12594]\n - Description field in metadata editor doesn't handle newlines\n  properly\n\n\n[MH-12591]\n - AssetManager reindex produces \"No organization found!\"\n  warnings\n\n\n[MH-12590]\n - Fix Workflow WOH Workspace Mock\n\n\n[MH-12589]\n - Fix Timelinepreview Dependencies\n\n\n[MH-12588]\n - Stream Security Leaks Secrets\n\n\n[MH-12587]\n - ActiveMQ config ships with 3rd party tool enabled by default\n\n\n[MH-12583]\n - Reduce frequency of index rebuild messages for comments and\n  asset manager\n\n\n[MH-12579]\n - Simplify XACML Handling\n\n\n[MH-12578]\n - Color of Crosslinks Makes Tables Look Noisy\n\n\n[MH-12574]\n - Audio keeps playing when leaving the playback or editor page\n\n\n[MH-12573]\n - Unprivileged users cannot delete events\n\n\n[MH-12572]\n - Dependency Fixes\n\n\n[MH-12570]\n - Admin UI Regressions And Minor Bugs\n\n\n[MH-12569]\n - Don't fail hard if attempting to distribute a non-track\n  media package element to streaming server\n\n\n[MH-12568]\n - EditableSingleValue Has Focus Issues\n\n\n[MH-12567]\n - Index Service Dependencies\n\n\n[MH-12566]\n - Remove Unused Participation List Provider\n\n\n[MH-12560]\n - Streaming media distribution does not work in a distributed\n  cluster\n\n\n[MH-12559]\n - CSS: Delete And Retract Dialogs For Events Are Messed up\n\n\n[MH-12558]\n - CSS: Buttons in Confirm Modals Too Big\n\n\n[MH-12557]\n - CSS: Checkbox Alignment in Tables\n\n\n[MH-12556]\n - Video Editor CSS Enhancements\n\n\n[MH-12554]\n - Downloading translations from Crowdin doesn't work anymore\n\n\n[MH-12553]\n - As an administrator, I want to configure the order in which\n  the different adaptive streaming video qualities are listed\n\n\n[MH-12552]\n - The \"delete\" button in the Admin UI may leave the \"preview\"\n  artifacts undeleted\n\n\n[MH-12551]\n - Redo changes of MH-11660 that got lost in means of a\n  regression\n\n\n[MH-12550]\n - hasActiveTransaction is triggered permantly for edited jobs\n\n\n[MH-12548]\n - Matterhorn Kernel Test Issues\n\n\n[MH-12547]\n - Group related settings in custom.properties\n\n\n[MH-12546]\n - 3.x to 4.0 upgrade is ugly\n\n\n[MH-12545]\n - Multi Value Editable Loses Value on Blur\n\n\n[MH-12543]\n - Adjust Log Level During Build Time\n\n\n[MH-12542]\n - Fix Ingest Service API Dependencies\n\n\n[MH-12541]\n - Events not searchable after migration if event was subject\n  to a workflow with two publish-engage operations\n\n\n[MH-12540]\n - Add documentation for WOH failing\n\n\n[MH-12539]\n - Add documentation for WOH include\n\n\n[MH-12537]\n - Admin UI Asset upload: Order Assets as listed in properties\n  file (vs alphabetical)\n\n\n[MH-12535]\n - Add language support for Hebrew\n\n\n[MH-12534]\n - Broken Labels In Default Workflow\n\n\n[MH-12532]\n - The bundle \nworkflow-workflowoperation\n creates (and leaves)\n  temporary files in \n/tmp\n\n\n[MH-12529]\n - External API returns negative Event duration\n\n\n[MH-12526]\n - External (LDAP) users cannot not see their own role\n  (ROLE_USER_XXXX) in the access policy of the events they create.\n\n\n[MH-12525]\n - Non-admin users cannot modify ACLs in their own events\n\n\n[MH-12523]\n - \"Submit\" button in retract modal is always disabled\n\n\n[MH-12522]\n - Improve Waveform Service Dependency Specification\n\n\n[MH-12520]\n - Duplicate Series When Double Clicking Create Button\n\n\n[MH-12519]\n - Improve Admin-NG Dependency Specification\n\n\n[MH-12518]\n - Ugly exception appears in stdout/Karaf console\n\n\n[MH-12517]\n - Some job data is not copied correctly\n\n\n[MH-12514]\n - Opencast Allows Multiple Simultaneous Workflows For Same\n  Media Package\n\n\n[MH-12513]\n - MigrationService fails\n\n\n[MH-12512]\n - Frontend-Maven-Plugin configuration is missing the mandatory\n  \"versionRange\" parameter\n\n\n[MH-12511]\n - Deleting an event with inconsistent search index state\n  doesn't work\n\n\n[MH-12510]\n - System doesn't recover from ActiveMQ downtime\n\n\n[MH-12507]\n - Textanalyzer Has Nondeclared Dependencies\n\n\n[MH-12503]\n - Log statements do not require Object or String arrays to\n  provide 3 parameters or more\n\n\n[MH-12500]\n - Fix incorrect usage of method \"URL#getFile()\"\n\n\n[MH-12499]\n - Admin UI event tools dialog can't be closed with the close\n  button\n\n\n[MH-12498]\n - External API: Cannot get series if description field is\n  empty\n\n\n[MH-12497]\n - Improve usability of admin UI forms\n\n\n[MH-12492]\n - AssetManager endpoint return server error on assets, which\n  the user not allowed to read\n\n\n[MH-12489]\n - Failed test: MySQL DDL Scripts (Update) \ufffc\n\n\n[MH-12488]\n - Publish worklow always fail\n\n\n[MH-12480]\n - Waveform Operation Should Have Tests\n\n\n[MH-12479]\n - Waveform Operation Should Not leave Files In Workspace\n\n\n[MH-12475]\n - Make mimetypes consistent\n\n\n[MH-12470]\n - Prematurely deleted scheduler properties lead to undeletable\n  events\n\n\n[MH-12469]\n - Auto Update OAIPMH republishes deleted Events\n\n\n[MH-12467]\n - Scheduled event fails due to not finding a workflow\n  definition to use\n\n\n[MH-12465]\n - Propagate Changes of Series Extended Metadata to Events and\n  OAI-PMH\n\n\n[MH-12463]\n - Hyphens in event/series search return no results\n\n\n[MH-12456]\n - Clean Up PathSupport\n\n\n[MH-12455]\n - FFmpeg does not terminate when Opencast is shut down\n\n\n[MH-12454]\n - PathSupport.changeFileExtension does not properly handle\n  files with no extension\n\n\n[MH-12453]\n - TimelinePreview Path Handling\n\n\n[MH-12451]\n - Lock file utility method should throw exceptions\n\n\n[MH-12450]\n - Clean up *EncoderEngine code\n\n\n[MH-12449]\n - Ensure temporary files are deleted on composer failure\n\n\n[MH-12448]\n - Remove unconfigured send-mail WOH\n\n\n[MH-12447]\n - OAI-PMH autorepublish fails if series was deleted\n\n\n[MH-12446]\n - Do not leave ZIP files in workspace when a Workflow fails\n\n\n[MH-12445]\n - underlying code showing on metadata source tab when creating\n  event\n\n\n[MH-12443]\n - editing event changes status from scheduled to finished\n\n\n[MH-12442]\n - Maven site is broken\n\n\n[MH-12436]\n - Add Christian Greweling to Comitters list\n\n\n[MH-12431]\n - Update Crowdin translations for r/4.x\n\n\n[MH-12428]\n - Performance Issue In Event Metadata\n\n\n[MH-12427]\n - Submit button in Editor typo\n\n\n[MH-12423]\n - Date Parse Error When Changing Certain Metadata\n\n\n[MH-12420]\n - Update frontend-maven-plugin\n\n\n[MH-12417]\n - Poor performace on scheduler /recordings/calendars\n\n\n[MH-12411]\n - Database user requires additional permissions\n\n\n[MH-12409]\n - Conductor logs ClassCastException when receiving\n  DeleteSnapshot\n\n\n[MH-12407]\n - \"The task could not be created\" message by starting task on\n  multiple events\n\n\n[MH-12406]\n - Splitting in the video editor while a video is playing\n  causes time jump\n\n\n[MH-12401]\n - Video editor segment times stay blank (timing)\n\n\n[MH-12399]\n - Oaipmh Retract very slow\n\n\n[MH-12396]\n - Cannot select filter two times in a row from dropdown\n\n\n[MH-12395]\n - REST: Handle Scheduling Conflict\n\n\n[MH-12394]\n - Video editor allows the submission of an event with no\n  active segments\n\n\n[MH-12390]\n - Gracefully handle unregistration of non-existing host\n\n\n[MH-12385]\n - Ingest Code Cleanup\n\n\n[MH-12382]\n - As a system administrator, I want to see the capture agent\n  configuration in the user interface, so that I don't need to look into the database directly\n\n\n[MH-12380]\n - External API v1.0.0 Broken Due To StartDate Format Change\n\n\n[MH-12372]\n - Make waveform service more flexible by allowing pre- and\n  post-filters to be configured\n\n\n[MH-12366]\n - authorization-manager depends on download-impl\n\n\n[MH-12365]\n - Losing ActiveMQ connection spams the logs\n\n\n[MH-12356]\n - As an administrator, I'd like to resolve or delete comments\n  in workflows by comment reason only\n\n\n[MH-12355]\n - Include Wowza Adaptive Streaming Module in Opencast\n\n\n[MH-12354]\n - Admin UI Video Editor wont let you edit segements at the end\n\n\n[MH-12352]\n - Include support for user Groups in LDAP\n\n\n[MH-12350]\n - Recreate adminui-Index stops, if Asset of Event ist missing\n\n\n[MH-12349]\n - Exception handler should not throw an IO exception on\n  deleting temporary directory\n\n\n[MH-12348]\n - As an administrator, I want to use the \"send-email\" WOH with\n  multiple recipients and also use the CC and BCC fields\n\n\n[MH-12346]\n - Publications are not shown in the admin interface\n\n\n[MH-12330]\n - The series WOH only updates the series' title and ID on the\n  episode's catalog, but sometimes more fields should be updated\n\n\n[MH-12328]\n - Update AngularJS from 1.3.x to 1.4.x\n\n\n[MH-12325]\n - Maven warning when building r/3.x\n\n\n[MH-12314]\n - As a developer, I expect the Admin UI tests being skipped if\n  I build Opencast using -DskipTests\n\n\n[MH-12312]\n - Event Counter For \"Today\"\n\n\n[MH-12309]\n - Use Matching FontAwesome Icons\n\n\n[MH-12304]\n - Configurable Notification Durations\n\n\n[MH-12302]\n - Do Not Warn About Default Configuration\n\n\n[MH-12289]\n - Publish extended metadata to OAI-PMH\n\n\n[MH-12287]\n - prevent reload of Admin UI when opening the editor\n\n\n[MH-12286]\n - As an Opencast admin, I want to set workflow properties from\n  an external script\n\n\n[MH-12284]\n - Unprivileged users cannot upload any files when creating or\n  editing a theme\n\n\n[MH-12283]\n - Support MPEG DASH in Player\n\n\n[MH-12278]\n - NullPointerException in CleanupWorkflowOperationHandler\n\n\n[MH-12274]\n - Ingest service REST endpoint should be verbosable and expect\n  input UTF-8 encoded\n\n\n[MH-12266]\n - As a user, I expect metadata changes to be propagated to\n  third-party applications\n\n\n[MH-12259]\n - Ingest-download WOH fail on downloading publication elements\n\n\n[MH-12258]\n - Update angular-translate to version 2.15.2\n\n\n[MH-12250]\n - Synchronize Dublin Core date created and start date in DC\n  temporal\n\n\n[MH-12242]\n - Theodul: Quality selector does not display/load\n\n\n[MH-12234]\n - Cleanup WOH does not remove all files as it should do\n\n\n[MH-12227]\n - As a user, I don't want to be informed about services not\n  being working correctly\n\n\n[MH-12223]\n - Oaipmh Publish is very slow\n\n\n[MH-12200]\n - Improve LDAP integration after the changes brought by\n  MH-12016\n\n\n[MH-12196]\n - Use a date and time picker instead of separate inputs for\n  date and time in admin UI\n\n\n[MH-12191]\n - Add support for automated captions/transcripts (IBM Watson)\n\n\n[MH-12168]\n - As a user, I need cross-page links that help me to work more\n  efficiently\n\n\n[MH-12166]\n - As a user, I'm not willing to perform that many clicks to\n  actually use the filters\n\n\n[MH-12111]\n - Require Java 8\n\n\n[MH-12104]\n - As a producer, I want to access assets of my tenant while a\n  workflow is running\n\n\n[MH-12099]\n - Wrong started date/time on workflow details view\n\n\n[MH-12082]\n - Contribute Asset Manager/Scheduler work (ETH)\n\n\n[MH-12052]\n - As an Administrator, I'd like to know that ActiveMQ is\n  running properly\n\n\n[MH-12000]\n - Cross-tenant URL signing\n\n\n[MH-11703]\n - Service error states not immediately visible in admin UI\n\n\n[MH-11458]\n - Update translations from crowdin\n\n\n[MH-11274]\n - Workflow Operations of Scheduled Event are not editable\n\n\n[MH-11195]\n - Ability to Search on part of a Series Identifier, instead of\n  just exact match\n\n\n[MH-11042]\n - Admin UI NG tests fail in +5:30 timezone\n\n\n[MH-10156]\n - Misspelling in LtiLaunchAuthenticationHandler.java\n\n\n\n\nOpencast 3.x\n\n\nOpencast 3.7\n\n\nReleased on Oct 16, 2018\n\n\n\n\n[\nMH-12982\n] - 3.0 database upgrade error\n\n\n[\nMH-13022\n] - Fix LTI highly trusted keys being discarded\n\n\n[\nMH-13034\n] - Add lis_person_sourcedid back as LTI source field for the\n  username\n\n\n[\nMH-13082\n] - Fix LTI security vulnerability and refactor LTI and OAuth\n  classes\n\n\n[\nMH-13152\n] - Reduce Workflow Messages, backport of Lars fix for >=r/5.x\n\n\n[\nMH-13156\n] - Set the auth scheme to digest for inter-server\n  communication\n\n\n\n\nOpencast 3.6\n\n\nReleased on May 31, 2018\n\n\n\n\n[MH-12910]\n - When switching between branches with different module\n  naming schemes, the git tree is left unclean sometimes\n\n\n[MH-12860]\n - Opencast does not build at DEBUG logging level\n\n\n[MH-12841]\n - Opencast is ignoring permissions\n\n\n[MH-12840]\n - LTI user provider may allow LMS admins to become Opencast\n  admins\n\n\n[MH-12830]\n - Fix mvn site generation\n\n\n[MH-12743]\n - OAIPMH-Republish-Operation tries to republish to ASW3\n\n\n[MH-12441]\n - Fix multi-server configuration docs and config details\n\n\n[MH-12091]\n - Create a Capture Agent digest user with its own role\n\n\n\n\nOpencast 3.5\n\n\nReleased on February 6, 2018\n\n\n\n\n[MH-12620]\n - Document ActiveMQ memory requirements\n\n\n[MH-12606]\n - Using \"Start Task\" with a workflow containing an embedded\n  script in the configuration which somehow modifies the input parameters does not update those values properly\n\n\n[MH-12582]\n - Editor WOH should not encode videos unless it is strictly\n  necessary (to save time and resources)\n\n\n[MH-12495]\n - Job dispatching with loads needs optimization\n\n\n[MH-12487]\n - Add job load settings to the default encoding profles\n\n\n[MH-12399]\n - Oaipmh Retract very slow\n\n\n\n\nOpencast 3.4\n\n\nReleased on December 4, 2017\n\n\n\n\n[MH-12588]\n - Stream Security Leaks Secrets\n\n\n[MH-12587]\n - ActiveMQ config ships with 3rd party tool enabled by default\n\n\n[MH-12532]\n - The bundle \nworkflow-workflowoperation\n creates (and leaves)\n  temporary files in\n/tmp\n\n\n[MH-12516]\n - Oversize job acceptance logic is incorrect\n\n\n[MH-12505]\n - composer operations need to set job load from profile load\n  when creating jobs\n\n\n[MH-12501]\n - Incorrect logging in inbox scanner\n\n\n[MH-12496]\n - Feeds point to removed embed player\n\n\n[MH-12494]\n - JMX bean unregistration causing stack traces in unit tests\n\n\n[MH-12478]\n - Waveform filenames are not unique\n\n\n[MH-12471]\n - Workspace Cleaner Minor Fix\n\n\n[MH-12464]\n - Job dispatching can be slowed down excessively by host loads\n  query\n\n\n[MH-12439]\n - WorkspaceCleaner Should Clean All Files\n\n\n[MH-12437]\n - Admin UI ng fails mvn clean install if the node_modules\n  exists\n\n\n[MH-12435]\n - Race condition when workspace file deletion removes\n  collection\n\n\n[MH-12430]\n - Update Crowdin translations for r/3.x\n\n\n[MH-12422]\n - Adjust documentation to new Crowdin Opencast project\n\n\n[MH-12421]\n - Job dispatching halts because of http connection hang\n\n\n[MH-12415]\n - Improve performance of /api/events?withpublications=true\n\n\n[MH-12363]\n - org.json.simple.parser.JSONParser is not thread safe\n\n\n[MH-12000]\n - Cross-tenant URL signing\n\n\n[MH-11361]\n - date in engage is the creation date, not the recording date\n\n\n[MH-11042]\n - Admin UI NG tests fail in +5:30 timezone\n\n\n\n\nOpencast 3.3\n\n\nReleased on September 21, 2017\n\n\n\n\n[MH-12383]\n - Upgrade/Unify Library Versions\n\n\n[MH-12413]\n - Don't present the user a previous/next item button if there\n  is no previous/next item\n\n\n[MH-12405]\n - Catastrophic Oveload in Calendar generation\n\n\n[MH-12400]\n - Player: Embed Links disabled\n\n\n[MH-12393]\n - Retract workflow fails if run when a video is being played\n  (with nfs storage)\n\n\n[MH-12389]\n - Set operation to failed when setting workflow to failed on\n  exception path\n\n\n[MH-12386]\n - Update Postgresql Connector\n\n\n[MH-12384]\n - Catch possible NPE in FileSupport.delete()\n\n\n[MH-12366]\n - authorization-manager depends on download-impl\n\n\n[MH-12365]\n - Losing ActiveMQ connection spams the logs\n\n\n[MH-12364]\n - /broker/status endpoint returns incorrect 204 when ActiveMQ\n  is shut down\n\n\n[MH-12362]\n - Less verbose logging for ExportWorkflowPropertiesWOH\n\n\n[MH-12360]\n - Race condition in workspace collection add and delete\n\n\n[MH-12359]\n - Milliseconds trim bug in videoeditor-workflowoperation\n  formatTime() javaScript\n\n\n[MH-12358]\n - Only 6 series were displayed on the distribution node\n\n\n[MH-12353]\n - Theodul player does not load reliably after restart\n\n\n[MH-12350]\n - Recreate adminui-Index stops, if Asset of Event ist missing\n\n\n[MH-12329]\n - File copy can fail with jetty timeout\n\n\n[MH-12326]\n - Reduce log level for IllegalStateException in\n  StaticResourceServlet\n\n\n[MH-12317]\n - AdminUI create every 5 seconds stats request and may crash\n  on heavy server load\n\n\n[MH-12303]\n - Sort the REST endpoints alphabetically\n\n\n[MH-12131]\n - Migrate documentation of capture agent communication\n  protocol to markdown\n\n\n[MH-12085]\n - Make file upload in Admin UI more flexible\n\n\n[MH-11768]\n - Timeline preview images\n\n\n\n\nOpencast 3.2\n\n\nReleased on August 16, 2017\n\n\n\n\n[MH-12347]\n - Opencast generates invalid XML catalogs when a \"default\"\n  (empty) Namespace is used.\n\n\n[MH-12345]\n - Ingest fails because /recordings/{id}/acls returns 500 if\n  event has not ACLs\n\n\n[MH-12342]\n - A \"Scanner\" instance in the ExecuteServiceImpl class is not\n  properly closed: possible resource leak\n\n\n[MH-12333]\n - Feed generator separates lists of tags incorrectly\n\n\n[MH-12327]\n - CAS Authentication is not working\n\n\n[MH-12324]\n - Reduce frequency of index update messages for rebuilds\n\n\n[MH-12318]\n - Remove Webconsole Default Installation\n\n\n[MH-12316]\n - IllegalStateException: Committed\n\n\n[MH-12315]\n - Database Query of Users from UserlistProvider is very slow\n\n\n[MH-12311]\n - Update Admin UI build tools\n\n\n[MH-12307]\n - OAI-PMH REST endpoint docs fix\n\n\n[MH-12305]\n - Admin UI should stop polling event stats if the event tab\n  isn't shown\n\n\n[MH-12288]\n - Set default max idle time if not configured and log key pool\n  parameters\n\n\n[MH-12280]\n - Create an Opencast group for Sakai instructors\n\n\n[MH-12278]\n - NullPointerException in CleanupWorkflowOperationHandler\n\n\n[MH-12275]\n - MH-12261 / Avoid race condition between index and cleanup\n  operations\n\n\n[MH-12271]\n - MH-12261 / Update WFR put action to update files atomically\n\n\n[MH-12270]\n - Don't swallow unknown SMIL exceptions\n\n\n[MH-12263]\n - MH-12261 / FileSupport > link - copy file action should use\n  overwrite argument (Throws FileFileAlreadyExists)\n\n\n[MH-12261]\n - Race condition leads to FileAlreadyExistsException and\n  FileNotFoundException\n\n\n[MH-12079]\n - Misleading logging in some indexing message receivers\n\n\n[MH-12007]\n - Revive the Execute Service\n\n\n[MH-11542]\n - Failed test: Process video after cutting (Safari)\n\n\n[MH-10650]\n - Intermittent failure to detect hard links when starting a\n  cluster\n\n\n[MH-10523]\n - Misleading exception parameter in getFileFromCollection\n\n\n\n\nOpencast 3.1\n\n\nReleased on July 14, 2017\n\n\n\n\n[MH-12296]\n - getSeries Performance Issue\n\n\n[MH-12295]\n - Update Karaf to 4.0.9\n\n\n[MH-12291]\n - Remove obsolete Speech Recognition API\n\n\n[MH-12279]\n - As a user, I expect the video editor to correctly visualize\n  the audio track\n\n\n[MH-12253]\n - Example workflows are inconsistent in Formatting and\n  Configuration of Publication Options\n\n\n[MH-12215]\n - Extended metadata should be applied on event create wizard\n\n\n[MH-12157]\n - Series index query performs bad on system with many series\n\n\n[MH-11742]\n - Document criteria for inclusion and exclusion of\n  translations\n\n\n\n\nOpencast 3.0\n\n\nReleased on June 13, 2017\n\n\n\n\n[MH-12257]\n - HttpsFilter is not called before\n  OAuthProviderProcessingFilter\n\n\n[MH-12255]\n - OC cannot add PyCA capture agent when server ending with /\n\n\n[MH-12252]\n - LTI default launch goes to the wrong URL for sample tool\n\n\n[MH-12249]\n - Media Module: Paging forgets search parameters\n\n\n[MH-12248]\n - Capture Calendar Modification Caching Implementation is very\n  Inefficient\n\n\n[MH-12247]\n - Archive Synchronization fix doesn't working in >=2.3\n\n\n[MH-12235]\n - WOH partial-import: No track matching smil Track-id\n\n\n[MH-12230]\n - Notifications appear again although the user has closed them\n\n\n[MH-12228]\n - player controls: use dropup instead of a dropdown if\n  controls are below the video\n\n\n[MH-12226]\n - Add documentation about configuration of publication channel\n  names and icons\n\n\n[MH-12222]\n - As a user, I don't want an empty tab be presented to me\n  since I don't necessarily understand, what that means\n\n\n[MH-12221]\n - As a user, I expect meaningful placeholder texts in the\n  filter selection components\n\n\n[MH-12213]\n - Internal distribution fails if download url is not default\n\n\n[MH-12211]\n - As a service provider, I need to be able to deal with\n  multiple users that have the same name\n\n\n[MH-12207]\n - Incorrect comment identifiers in some workflows\n\n\n[MH-12205]\n - Update version of javax.ws.rs - jsr311-api\n\n\n[MH-12204]\n - Rearrange the config\n\n\n[MH-12202]\n - ProxyMiddleware does ignore host port\n\n\n[MH-12199]\n - 3.x release notes mention \"comprehensive\" LDAP support,\n  which is not (yet) true\n\n\n[MH-12198]\n - Remove outdated file location in LDAP documentation\n\n\n[MH-12197]\n - IllegalStateException: Response is committed\n\n\n[MH-12195]\n - Unprivileged users cannot view media package element details\n  on Recordings->Events->\"Event Details\"->Assets->Media\n\n\n[MH-12193]\n - OAI-PMH distribution fails on adaptive streaming artifacts\n\n\n[MH-12189]\n - Sakai userdirectory provider is not properly bundled\n\n\n[MH-12183]\n - Theodul does not load\n\n\n[MH-12181]\n - As a course admin, I want to allow roles in the UI for ACLs\n  that match a pattern\n\n\n[MH-12180]\n - Cannot specify ValuefFor probe-resolution woh\n\n\n[MH-12174]\n - The Admin UI temporarily displays wrong table content\n  because data is not cleared upon page navigation\n\n\n[MH-12173]\n - The Admin UI temporarily displays wrong table content\n  because data requests are not cancelled\n\n\n[MH-12170]\n - Safari does not display metadata once entered\n\n\n[MH-12169]\n - As a user, I expect search strings to match non-word\n  boundaries in searchable dropdown lists\n\n\n[MH-12167]\n - As a user, I need to be able to search for values offered by\n  the filters, so that I actually find the value I am looking for\n\n\n[MH-12156]\n - Fix version of matterhorn-engage-theodul-plugin-custom-piwik\n\n\n[MH-12153]\n - Reduce Database Space usage\n\n\n[MH-12149]\n - Upgrade Elastic Search to 1.7.6\n\n\n[MH-12148]\n - Undocumented Archive WOH Requirements\n\n\n[MH-12147]\n - TOC links in REST docs overlap\n\n\n[MH-12142]\n - As a system administrator, I would like a documented hint\n  that the user running Opencast needs RW access to the optional storage directory\n\n\n[MH-12141]\n - As service provider, I want to restrict access granted to\n  tenant administrators\n\n\n[MH-12138]\n - Added release notes\n\n\n[MH-12137]\n - AWS S3 tries to distribute attachments from OAI-PMH\n  distribution\n\n\n[MH-12133]\n - OAI-PMH Tests Fails Regularly\n\n\n[MH-12130]\n - Filters set by selecting a category in the dashboard are not\n  shown\n\n\n[MH-12128]\n - REST docs are too eager to check for a valid value\n\n\n[MH-12126]\n - Fast workflow needs AWS distribution to default to false.\n\n\n[MH-12124]\n - Cutting a video multiple times results in multiple\n  smil/cutting catalogs\n\n\n[MH-12121]\n - Update grunt-ng-annotate to 3.0.0 and grunt-contrib-uglify\n  to 2.2.0\n\n\n[MH-12120]\n - pub service oaipmh wants distribution api\n\n\n[MH-12117]\n - As an adopter I would like to get collect data with Piwik\n\n\n[MH-12115]\n - Republish Metadata to OAI-PMH fails\n\n\n[MH-12113]\n - Update outdated comment about the \"lifecycle-mapping\" plugin\n  in the main pom.xml\n\n\n[MH-12112]\n - Update Node Version\n\n\n[MH-12110]\n - frontend-maven-plugin is executed on every module\n\n\n[MH-12109]\n - Creating comments does not work anymore\n\n\n[MH-12108]\n - Set Workflow Variables Based On Resolution\n\n\n[MH-12104]\n - As a producer, I want to access assets of my tenant while a\n  workflow is running\n\n\n[MH-12103]\n - As a producer, I want to be able to execute WOH\n  partial-import on archived sources\n\n\n[MH-12102]\n - Add Workflow Variables Based On Media Properties\n\n\n[MH-12084]\n - The class \"AsyncTimeoutRedirectFilter\" swallows almost all\n  the exceptions\n\n\n[MH-12074]\n - Remove workflow MissedCaptureScanner and MissedIngestScanner\n\n\n[MH-12073]\n - Typo in rest_docs entry box\n\n\n[MH-12070]\n - Order the event counters to reflect the event lifecycle\n\n\n[MH-12067]\n - Initial REST Docs Search\n\n\n[MH-12066]\n - Missing feature.xml Installation\n\n\n[MH-12065]\n - Fix bundle info REST endpoint description\n\n\n[MH-12064]\n - Handle missing meta.abstract gracefully\n\n\n[MH-12060]\n - Simplify Default WOH\n\n\n[MH-12056]\n - As an Administrator, I'd like to add some custom roles for\n  managing access\n\n\n[MH-12055]\n - Update REST Documentation Template\n\n\n[MH-12054]\n - Incorrect or misleading documentation about WOH conditional\n  execution\n\n\n[MH-12049]\n - Update REST Documentation Overview\n\n\n[MH-12043]\n - Allow more then one additional authentication algorithms\n  beside digest\n\n\n[MH-12038]\n - Fallback decoding for mediapackage date values in unixtime\n  rather than W3CDTF\n\n\n[MH-12037]\n - NullPoiinterException when starting embedded Solr\n\n\n[MH-12035]\n - Setting Default Download Directory\n\n\n[MH-12034]\n - Make the UserAndRoleDirectoryService cache configurable\n\n\n[MH-12033]\n - Add indicator lights for capture agent status\n\n\n[MH-12032]\n - Add an authenticated ACL template\n\n\n[MH-12031]\n - Add additional docs for inspection WOH\n\n\n[MH-12029]\n - As a user, I want to use my existing AAI login for Opencast,\n  too\n\n\n[MH-12023]\n - Make development builds faster\n\n\n[MH-12022]\n - /ingest/addTrackURL broken\n\n\n[MH-12019]\n - Ensure Test Files Are Deleted\n\n\n[MH-12017]\n - CoverImage WOH should provide metadata for recording\n  start/end time\n\n\n[MH-12016]\n - Fix and improve user, group, role and provider handling\n\n\n[MH-12015]\n - Typo in External API role name\n\n\n[MH-12014]\n - Incorrect number of roles returned when limit is specified\n\n\n[MH-12013]\n - Contribute OAI-PMH work (ETH)\n\n\n[MH-12002]\n - Date & time format should be customizable in cover images\n\n\n[MH-11994]\n - UserIdRoleProvider should check user existence from user\n  providers\n\n\n[MH-11993]\n - WOH partial-import should support output framerate\n\n\n[MH-11990]\n - Remove configuration file of removed module\n  matterhorn-load-test\n\n\n[MH-11982]\n - As an Opencast administrator, I would like a dashboard\n  counter for active recordings\n\n\n[MH-11979]\n - The video editor does not highlight the selected segment if\n  it is cut\n\n\n[MH-11978]\n - Hotkeys for common tasks in Admin UI\n\n\n[MH-11977]\n - Remove Unused OSGI Bindings From IndexService\n\n\n[MH-11976]\n - Adjust DownloadDistribution Logs\n\n\n[MH-11975]\n - Update some maven plugins\n\n\n[MH-11971]\n - Update maven-surfire-test plugin to latest version\n\n\n[MH-11969]\n - Fullscreen button in embedded view of Theodul player missing\n  after update to 2.2.4\n\n\n[MH-11967]\n - Publish internal fails on Distrubuted System Admin/Engage\n\n\n[MH-11965]\n - Update to Karaf 4.0.8\n\n\n[MH-11957]\n - Make availability check of WOH publish-configure\n  configurable\n\n\n[MH-11956]\n - Allow fine-grained control of accurate frame count\n\n\n[MH-11954]\n - Fixing Javadoc Build\n\n\n[MH-11952]\n - HTML in Translations\n\n\n[MH-11944]\n - MH-11817 use keyboard shortcuts to control the editor\n\n\n[MH-11916]\n - Add convenience workflow instance variable to indicate\n  whether a theme is involved\n\n\n[MH-11910]\n - WOH composite should be able to respect resolution of its\n  input\n\n\n[MH-11904]\n - Missing IDClass Warnings\n\n\n[MH-11903]\n - Cannot Configure Authentication For Webconsole\n\n\n[MH-11902]\n - Update to latest 5.x MySQL connector\n\n\n[MH-11894]\n - Suppress context menu on video element\n\n\n[MH-11885]\n - Add support for search and filtering to\n  Organization->Access Policies\n\n\n[MH-11881]\n - ArchiveRestEndpoint has conflicting endpoints\n\n\n[MH-11880]\n - Multiple issues with LDAP in branch 2.3.x\n\n\n[MH-11873]\n - org.ops4j.pax.web.pax-web-extender-whiteboard causes\n  exception when shutting down\n\n\n[MH-11868]\n - redesign loginpages\n\n\n[MH-11861]\n - MH-11817 Change default view to editor in admin ui tools\n  area\n\n\n[MH-11849]\n - Edit metadata fields by click inside and focus cursor in\n  field\n\n\n[MH-11822]\n - Admin UI Video Editor - Improved Segment Controls\n\n\n[MH-11821]\n - Admin UI Video Editor - Comment and Metadata Editing\n\n\n[MH-11818]\n - Admin UI Video Editor - Improved playback and timeline\n\n\n[MH-11806]\n - Output Frame Rate on Concat Operation\n\n\n[MH-11797]\n - Upgrade Karaf to 4.0.6\n\n\n[MH-11796]\n - Add support for watermarks to themes\n\n\n[MH-11782]\n - MH-11780 Create configure-by-dcterm workflow operation\n  handler\n\n\n[MH-11781]\n - MH-11780 Create tag-by-dcterm workflow operation handler\n\n\n[MH-11780]\n - As a developer I want to be able to manipulate a workflow\n  based on metadata in the Mediapackage\n\n\n[MH-11766]\n - enhance REST Ingest/addTrack Ingest/addCatalog\n  Ingest/AddAttachment to add tags\n\n\n[MH-11761]\n - Captions for player\n\n\n[MH-11732]\n - Make distribution and retraction efficient\n\n\n[MH-11719]\n - When configuring LDAP with default file things are broken\n\n\n[MH-11717]\n - MH-11713 Not possible to add external roles to an ACL\n  through the admin UI\n\n\n[MH-11715]\n - MH-11713 Externally provisioned roles should not be\n  persisted\n\n\n[MH-11713]\n - Users may have roles in Opencast which are granted from an\n  external system (e.g. LMS)\n\n\n[MH-11684]\n - WOH silence does not support tags\n\n\n[MH-11474]\n - Assigning a user to a certain \"ROLE_GROUP_<name>\" role\n  does not really put the user in such group\n\n\n[MH-11466]\n - Improve handling of long strings in cover images\n\n\n[MH-11379]\n - Service to distribute delivery files to AWS S3\n\n\n[MH-11229]\n - workflowoperation unit tests are incredible slow\n\n\n[MH-11036]\n - Adapt Fast Testing Workflow for Admin NG\n\n\n[MH-10871]\n - Sakai User Provider for Opencast-Sakai integration\n\n\n[MH-10819]\n - When creating a new event, metadata field can only be edited\n  by clicking on the pencil icon\n\n\n[MH-10753]\n - Stale database connection causes job failure\n\n\n[MH-10310]\n - Add ERROR state for capture agent\n\n\n\n\nOpencast 2.3.x\n\n\nOpencast 2.3.5\n\n\nReleased on December 04, 2017\n\n\n\n\n[MH-12588]\n - Stream Security Leaks Secrets\n\n\n[MH-12317]\n - AdminUI create every 5 seconds stats request and may crash\n  on heavy server load\n\n\n[MH-12269]\n - Clarify in the documentation the recommendation of setting\n  \ndispatchinterval\n to 0 applies to non-admin nodes only\n\n\n[MH-12190]\n - Script injection in Media Module and Player\n\n\n[MH-12000]\n - Cross-tenant URL signing\n\n\n[MH-11042]\n - Admin UI NG tests fail in +5:30 timezone\n\n\n\n\nOpencast 2.3.4\n\n\nReleased on August 03, 2017\n\n\n\n\n[MH-12183]\n - Theodul does not load\n\n\n[MH-12203]\n - Unescaped event and series titles when editing event or\n  series (XSS)\n\n\n[MH-12242]\n - Theodul: Quality selector does not display/load\n\n\n[MH-12246]\n - Series WOH does not apply series DublinCore catalogs\n\n\n[MH-12249]\n - Media Module: Paging forgets search parameters\n\n\n\n\nOpencast 2.3.3\n\n\nReleased on May 02, 2017\n\n\n\n\n[MH-10558]\n - Mime type not identified for matroska / mkv files\n\n\n[MH-10595]\n - Incident service returns internal server error if\n  cascade=true requested for deleted workflow\n\n\n[MH-10747]\n - Inputs for capture device should be pre-selected\n\n\n[MH-11736]\n - Difference in start time displayed in overview and metadata\n  details\n\n\n[MH-11811]\n - Opencast build fails when system timezone is set to PDT\n  (Pacific Daylight Time)\n\n\n[MH-12048]\n - Series drop-down not sorted alphabetically in filter\n\n\n[MH-12069]\n - Deleting an event leaves behind orphaned comments\n\n\n[MH-12095]\n - Server default timezone can be incorrect\n\n\n[MH-12106]\n - Preserve user attributes from providers during\n  authentication\n\n\n[MH-12107]\n - Improve performance of Servers table in Admin UI\n\n\n[MH-12118]\n - Paging in media module is broken\n\n\n[MH-12129]\n - Media module only works with english localized browsers\n\n\n[MH-12130]\n - Filters set by selecting a category in the dashboard are not\n  shown\n\n\n[MH-12148]\n - Undocumented Archive WOH Requirements\n\n\n[MH-12150]\n - Matroska files are not recognized\n\n\n[MH-12158]\n - Workflow job dispatching failures\n\n\n[MH-12162]\n - JpaJob object toString override for better log messages\n\n\n[MH-12163]\n - Events with stopped workflows sometimes cannot be deleted\n\n\n[MH-12164]\n - Updating serviceregistry config while running leaves\n  Opencast in a non-functional state\n\n\n[MH-12190]\n - Script injection in Media Module and Player\n\n\n\n\nOpencast 2.3.2\n\n\nReleased on March 22, 2017\n\n\n\n\n[MH-11224]\n - Attempting to view source metadata through the new admin UI\n  generates a stack trace\n\n\n[MH-11340]\n - Uncaught NullPointer Exception in Karaf console from\n  com.entwinemedia.fn.data.json.SimpleSerializer.toJson\n\n\n[MH-11616]\n - Search Service will not remove mp from index if it is not\n  found in database\n\n\n[MH-11743]\n - event.hasPreview() broken\n\n\n[MH-11760]\n - Event edit warning cannot be removed\n\n\n[MH-11790]\n - Slide Previews and slide text are not shown in Theodul\n  Engage player\n\n\n[MH-11817]\n - Unhide volume controls in video-editor\n\n\n[MH-11819]\n - Admin UI Video Editor - Improved Zoom Controls\n\n\n[MH-12009]\n - Admin UI Video Editor: Segmentation lost after publishing\n\n\n[MH-12058]\n - Ingests fail if specified workflow does not exist\n\n\n[MH-12059]\n - Catch invalid dates when indexing\n\n\n[MH-12061]\n - Reduce the number of activemq messages and log entries\n  during index rebuild\n\n\n[MH-12062]\n - Improve robustness of scheduler re-indexing\n\n\n[MH-12063]\n - Catch incomplete archive entries when indexing\n\n\n[MH-12072]\n - Wrong destinationId for External API message receiver\n\n\n[MH-12084]\n - The class \"AsyncTimeoutRedirectFilter\" swallows almost all\n  the exceptions\n\n\n[MH-12087]\n - Null bitrate can cause UI display of source media to fail\n\n\n[MH-12092]\n - Return event ID when event is created through Scheduler API\n\n\n[MH-12097]\n - SegmentVideoWorkflowOperation: Modules not included in Admin\n  Presentation build.\n\n\n\n\nOpencast 2.3.1\n\n\nReleased on Janurary 25, 2017\n\n\n\n\n[MH-11267]\n - Wrong notification text when deleting series\n\n\n[MH-11458]\n - Update translations from crowdin\n\n\n[MH-11687]\n - UI date formats are wrong for most of the English-speaking\n  world\n\n\n[MH-11776]\n - CaptureAgentStateServiceImplTest incorrectly passes a\n  non-long recording id, misses finding the NullPointer in Impl\n\n\n[MH-11960]\n - matterhorn-adminui-ng fails on first build\n\n\n[MH-11961]\n - Cannot access slidetext.xml should not break re-indexing\n\n\n[MH-11963]\n - Fix ingest REST docs\n\n\n[MH-11966]\n - Confusing AdminUI Groups Endpoint Documentation\n\n\n[MH-11967]\n - Publish internal fails on Distrubuted System Admin/Engage\n\n\n[MH-11983]\n - Only administrators should be allowed to assign the admin\n  roles to other users\n\n\n[MH-11987]\n - Declare Admin UI Facade as module internal interface\n\n\n[MH-11988]\n - Advise to change karaf shutdown command in the docs\n\n\n[MH-11989]\n - Allow unknown as well as offline CAs to be removed via UI\n\n\n[MH-11992]\n - Compatibility issue when using contrib Wowza adaptive\n  streaming module\n\n\n[MH-11998]\n - /info/me.json sometimes doesn't provide full information\n  about the user\n\n\n[MH-12004]\n - Removing an recording does not remove all correspronding\n  jobs\n\n\n[MH-12005]\n - UI shows inconsistent version due to missing version in\n  cover-image-remote\n\n\n[MH-12006]\n - Security Issue Allowing Arbitrary Code Execution\n\n\n\n\nOpencast 2.3.0\n\n\nReleased on December 13, 2016\n\n\n\n\n[MH-10342]\n - As an external device I want to immediate start and stop a\n  capture\n\n\n[MH-11327]\n - De-couple smilImpl/wfrImpl from ingestImpl\n\n\n[MH-11378]\n - Conditionally synchronize Archive Service's add mediapackge\n\n\n[MH-11380]\n - As a customer, I want to integrate my third party\n  application to Opencast, so that I can use Opencast content in my application\n\n\n[MH-11381]\n - Remove documentation of items that have never been\n  implemented\n\n\n[MH-11411]\n - move dashboard to header\n\n\n[MH-11675]\n - Add documentation for External API to the Admin Guide\n\n\n[MH-11688]\n - Set java file encoding on startup\n\n\n[MH-11718]\n - As a producer, I want to be able to make workflow settings\n  persistent so that I can reuse them later\n\n\n[MH-11725]\n - Give users a starting point how to report bugs\n\n\n[MH-11726]\n - Add AdminUI style guide to developer guide\n\n\n[MH-11728]\n - Use Apache Commons Lang 3\n\n\n[MH-11729]\n - External API: Add documentation for Groups Endpoint\n\n\n[MH-11731]\n - Typofix Documentation\n\n\n[MH-11737]\n - Comment (mh_event_comment and mh_event_comment_reply)\n  text field is VARCHAR(255) should be TEXT\n\n\n[MH-11740]\n - optimization of segmentation\n\n\n[MH-11741]\n - Admin UI has timezone issues\n\n\n[MH-11749]\n - External API: Add REST documentation for Endpoints\n\n\n[MH-11750]\n - Clean-Up Opencast Code Base\n\n\n[MH-11752]\n - Upgrade Karaf to 3.0.8\n\n\n[MH-11756]\n - Admin UI NG Update CSS+HTML (1): FontAwesome, improve HTML,\n  remove redundant images\n\n\n[MH-11763]\n - Counters hide series tab\n\n\n[MH-11772]\n - Admin UI source dropdowns inappropriately advance\n\n\n[MH-11774]\n - Admin UI Needs better documentation for debugging\n\n\n[MH-11775]\n - Library Update\n\n\n[MH-11783]\n - Custom publications labels not displayed when doing a\n  mouse-over on Events->Published\n\n\n[MH-11784]\n - Remove Participation Management Code Pieces\n\n\n[MH-11786]\n - HttpsRequestWrapper wrongly sets the new URL\n\n\n[MH-11791]\n - As service provider I want to configure which kind of users\n  can see the event counters\n\n\n[MH-11792]\n - NPM Proxy via Nexus\n\n\n[MH-11794]\n - NPM fails on first build\n\n\n[MH-11795]\n - Add support for title slides\n\n\n[MH-11799]\n - Maven bundle names too long\n\n\n[MH-11800]\n - LTI between Opencast and Moodle does not work\n\n\n[MH-11801]\n - Wowza streaming server needs flv: prefix for flv files\n\n\n[MH-11802]\n - Opencast Logo is missing in Player\n\n\n[MH-11803]\n - Player redirect is missing\n\n\n[MH-11804]\n - No video controls in embed mode\n\n\n[MH-11808]\n - Pre-select workflow in case only one option is available\n\n\n[MH-11809]\n - Fix syntax error in encoding profile composite.http\n\n\n[MH-11812]\n - Fix security configuration for ROLE_UI_TASKS_CREATE\n\n\n[MH-11813]\n - Agent state REST endpoint documentation\n\n\n[MH-11815]\n - As a user I expect changes to be reflected in the Admin UI\n  immediately\n\n\n[MH-11817]\n - Admin UI Video Editor - Bug Fixes\n\n\n[MH-11817]\n - Display video details in preview player/ editor of the admin\n  ui\n\n\n[MH-11817]\n - Improve Button Hover Indication\n\n\n[MH-11817]\n - Make Next/Last Frame controls in videoeditor better\n  recognizeable\n\n\n[MH-11827]\n - Recordings->Events->\"Event Details\"->Metadata: Incorrect\n  translation used\n\n\n[MH-11828]\n - exception-handler-workflow not set correctly\n\n\n[MH-11829]\n - High memory usage on the admin server by dispatching jobs\n\n\n[MH-11831]\n - As a service provider, I want to configure whether Opencast\n  creates an admin user automatically\n\n\n[MH-11834]\n - Unable to set capture agent configuration as JSON\n\n\n[MH-11836]\n - Additional ACL actions of series are missing when creating a\n  new event in that series\n\n\n[MH-11837]\n - Unprivileged users have no access to fonts\n\n\n[MH-11839]\n - typo in Event Details: Comments\n\n\n[MH-11841]\n - Wait for NFS shares before start Opencast service\n\n\n[MH-11842]\n - Revert accidental downgrade of grunt version\n\n\n[MH-11851]\n - org.opencastproject.security.admin/pass can't be changed\n\n\n[MH-11857]\n - Fix log output \"Unable to delete non existing object %s/%s\"\n\n\n[MH-11862]\n - Search API handles roles wrong\n\n\n[MH-11863]\n - WOH analyze-tracks & WOH failing cause exceptions when\n  shutting down Opencast\n\n\n[MH-11864]\n - WOH tag shall implement AbstractWorkflowOperationHandler\n\n\n[MH-11865]\n - Videoeditor Preview mixes in 2 Audiofiles\n\n\n[MH-11866]\n - Search box in Organization >> Groups not working\n\n\n[MH-11867]\n - Filter box in Organization >> Groups not working\n\n\n[MH-11869]\n - Deleting Series with 'Actions' is not working\n\n\n[MH-11870]\n - Wordlength in other languages except english too long\n\n\n[MH-11871]\n - ElasticSearch shall bind to 127.0.0.1\n\n\n[MH-11875]\n - ActiveMQ should not listen to all hosts by default\n\n\n[MH-11880]\n - Multiple issues with LDAP in branch 2.3.x\n\n\n[MH-11883]\n - Larger files may remain in system temp directory\n\n\n[MH-11886]\n - login pages throw errors on loading unnecessary scripts\n\n\n[MH-11888]\n - Organization Filter uses Provider where table uses Type\n\n\n[MH-11889]\n - Row size too large\n\n\n[MH-11890]\n - MySQL Connector Version Should Be Consistent\n\n\n[MH-11891]\n - Event counters query large amounts of useless data\n\n\n[MH-11895]\n - \u201cAdd Event\u201d Wizard Input Fields Broken\n\n\n[MH-11896]\n - Java Warnings in AbstractEventEndpoint\n\n\n[MH-11897]\n - Remove Deprecated StringHelper\n\n\n[MH-11898]\n - Fix Technical Duration Calculation\n\n\n[MH-11899]\n - Prevent Requesting Event Objects Multiple Times\n\n\n[MH-11900]\n - Minor Index Service Fixes\n\n\n[MH-11905]\n - Publish Configure WOH incorrectly retracts publications\n\n\n[MH-11912]\n - No slider in playback video player\n\n\n[MH-11919]\n - WOH image claims SUCCEEDED when actually skipping\n\n\n[MH-11920]\n - WOH prepare-av: Misleading log message\n\n\n[MH-11921]\n - WOH partial-import looses partial audio tracks in specific\n  cases\n\n\n[MH-11950]\n - Javadocs build error\n\n\n[MH-11955]\n - Add en-GB to Languages\n\n\n\n\nOpencast 2.2.x\n\n\nOpencast 2.2.5\n\n\nReleased on June 7, 2017\n\n\n\n\n[MH-11983]\n - Only admins should be able to modify other admins\n\n\n[MH-12006]\n - Security Issue Allowing Arbitrary Code Execution\n\n\n[MH-11962]\n - Missing slidetext.xml should not break re-indexing\n\n\n\n\nOpencast 2.2.4\n\n\nReleased on October 13, 2016\n\n\n\n\n[MH-11831]\n - As a service provider, I want to configure whether Opencast\n  creates an admin user automatically\n\n\n[MH-11851]\n - org.opencastproject.security.admin/pass can't be changed\n\n\n[MH-11862]\n - Search API handles roles wrong\n\n\n[MH-11875]\n - ActiveMQ should not listen to all hosts by default\n\n\n\n\nOpencast 2.2.3\n\n\nReleased on October 13, 2016\n\n\n\n\n[MH-11285]\n - Improve developers documentation: remote debugger with karaf\n\n\n[MH-11741]\n - Admin UI has timezone issues\n\n\n[MH-11771]\n - Improve section localization in developer guide\n\n\n[MH-11773]\n - Embed player does not use space very well and has scaling\n  problems\n\n\n[MH-11774]\n - Admin UI Needs better documentation for debugging\n\n\n[MH-11777]\n - Event Details->Comments and Event Details->Assets don't\n  work for unprivileged users\n\n\n[MH-11787]\n - Add release dates to changelog\n\n\n[MH-11800]\n - LTI between Opencast and Moodle does not work\n\n\n[MH-11801]\n - Wowza streaming server needs flv: prefix for flv files\n\n\n\n\nOpencast 2.2.2\n\n\nReleased on September 14, 2016\n\n\n\n\n[MH-11194]\n - created themes not showing up in series branding tab\n\n\n[MH-11572]\n - FFmpeg Inspection Service Test - accurateFrameCount\n\n\n[MH-11587]\n - SQL Error\n\n\n[MH-11714]\n - Fix unit test: Event controller #accessSave saves the event\n  access\n\n\n[MH-11724]\n - Additional actions not available in create event wizard\n  anymore\n\n\n[MH-11734]\n - Fix el7 RPM docs\n\n\n[MH-11735]\n - Fix Stream Security Documentation\n\n\n[MH-11744]\n - Actions->Start Task: Various localization bugs\n\n\n[MH-11748]\n - Inconsistent and incorrect use of translate directive\n\n\n[MH-11751]\n - Player won't work if there are no segments\n\n\n[MH-11755]\n - No quality selection in Theodul Player\n\n\n[MH-11759]\n - Make Inspector Unit Tests More Robust\n\n\n\n\nOpencast 2.2.1\n\n\n\n\nReleased on July 30, 2016\n\n\n\n\n[MH-11092]\n - Every Browser has an other \"Remember me\" checkbox\n\n\n[MH-11169]\n - Trimming points not set correctly after workflow is finished\n\n\n[MH-11538]\n - \"No compatible source was found for this video\" videojs\n  player error in iOS device\n\n\n[MH-11561]\n - Style (CSS): Setting a server in Maintenance (srv-det-01)\n\n\n[MH-11598]\n - Wizards should not re-use data that has entered before\n\n\n[MH-11644]\n - Missing Admin Interface Mock Data\n\n\n[MH-11653]\n - Jobs do not always proceed\n\n\n[MH-11655]\n - Jobs with high job load never get processed\n\n\n[MH-11659]\n - Warning is missing that metada and ACL cannot be edited\n  while job is processing.\n\n\n[MH-11661]\n - Link on logo on the media module points to admin ui or\n  welcome page, instead of something that is accessable for every user\n\n\n[MH-11664]\n - Incorrect Inconsistency status when built from tarball\n\n\n[MH-11665]\n - Systems->Servers & Systems->Services show wrong mean\n  runtime and mean queue time\n\n\n[MH-11667]\n - Align main table content\n\n\n[MH-11668]\n - Missing segment previews let to an erro in the player\n\n\n[MH-11669]\n - Do not archive OCR texts\n\n\n[MH-11673]\n - Add documentation for additional ACL actions\n\n\n[MH-11674]\n - Add documentation for metadata configuration\n\n\n[MH-11679]\n - Page size cannot be changed in any table\n\n\n[MH-11681]\n - Add documentation for role-based visibility\n\n\n[MH-11682]\n - Remove useless roles from roles.txt\n\n\n[MH-11686]\n - Extended metadata tab not shown although user has the role\n  ROLE_UI_EVENTS_DETAILS_METADATA_VIEW\n\n\n[MH-11690]\n - Various Documentation Improvements\n\n\n[MH-11692]\n - Remove Superfluous Mh-Db-Version\n\n\n[MH-11693]\n - Remove Superfluous Dependency Versions\n\n\n[MH-11694]\n - JavaDoc Generation Broken\n\n\n[MH-11702]\n - After an upgrade to 2.2.0, series are not displayed in the\n  UI because the series creation date is now mandatory\n\n\n[MH-11720]\n - Opencast 2.2 requires Git to be installed at build time\n\n\n[MH-11727]\n - Fix unit test: adminNg.services.language #toLocalTime\n  converts a zulu time string back to local time FAILED\n\n\n[MH-11730]\n - Make the automatic role prefix in LDAPUserProvider\n  configurable\n\n\n\n\nOpencast 2.2.0\n\n\nReleased on June 15, 2016\n\n\n\n\n[MH-9511]\n - Wrong log level in Tesseract\n\n\n[MH-9831]\n - ehcache and quartz phones home\n\n\n[MH-9950]\n - Update player dependencies\n\n\n[MH-10029]\n - Remove Unnecessary Image Conversion Step From\n  TextAnalysisService\n\n\n[MH-10173]\n - Do not ignore exceptions when closing Closeable's\n\n\n[MH-10748]\n - Matterhorn has to be restarted to schedule an event on a new\n  capture device\n\n\n[MH-10794]\n - Delete Action should be disabled if nothing is selected\n\n\n[MH-10869]\n - ActiveMQ Configuration and Connection Problems\n\n\n[MH-10870]\n - ActiveMQ Exceptions While Shutting Down Matterhorn\n\n\n[MH-10887]\n - Users can schedule events in the past\n\n\n[MH-10898]\n - Update Apache HttpComponents (3.1.7 \u2192 4.4.1)\n\n\n[MH-10923]\n - Theodul player : Filtering \"composite\" tags results in error\n  when the composite workflow is used\n\n\n[MH-10942]\n - Events are not deselected after applying a task\n\n\n[MH-10965]\n - Theodul player : Videos not playable on IE10\n\n\n[MH-10971]\n - Newly created Series don't show up in Series dropdown\n  selection lists without page reload\n\n\n[MH-10978]\n - Unable to retract 'internal' publications\n\n\n[MH-10979]\n - Opencast needs to better distribute load across the\n  available nodes\n\n\n[MH-10984]\n - Extend ingest service by partial upload\n\n\n[MH-11010]\n - Stream Security should be able to prevent cross-tenants\n  access\n\n\n[MH-11014]\n - Add support for additional ACL actions\n\n\n[MH-11077]\n - The Publish Workflow will not retract already published\n  material\n\n\n[MH-11097]\n - View modes not working correctly\n\n\n[MH-11107]\n - Group list pagination not working\n\n\n[MH-11121]\n - MacOS X Installation Guide Needs 2.1 Update\n\n\n[MH-11124]\n - Incorrect documentation on how to create users\n\n\n[MH-11128]\n - Docs about SilenceDetector threashold are incorrect\n\n\n[MH-11139]\n - Unable to find mimetype for mkv\n\n\n[MH-11140]\n - Forward and backward buttons are greyed out\n\n\n[MH-11143]\n - Link to Media Module in Admin UI\n\n\n[MH-11148]\n - Search box layout incorrect: Icon overlaps text\n\n\n[MH-11156]\n - Users: Search box not implemented\n\n\n[MH-11157]\n - Groups: Search box not implemented\n\n\n[MH-11165]\n - Sorting does not work on Systems->Jobs,\n  Systems->Servers and Systems->Services\n\n\n[MH-11167]\n - Layout problem on Workflow Error Details view\n\n\n[MH-11183]\n - Capture->Locations: Search box not implemented\n\n\n[MH-11190]\n - Theodul Shortcuts: Description could be improved\n\n\n[MH-11191]\n - Event Details->Assets: Use human-readable units for\n  duration, bitrates and sizes\n\n\n[MH-11192]\n - Audio level slider does not change audio level while\n  dragging\n\n\n[MH-11199]\n - Playback & video editor don't work while workflow is running\n\n\n[MH-11209]\n - LTI Documentation needs to be incorporated into new docs\n\n\n[MH-11222]\n - Replace System.out.println with logger\n\n\n[MH-11229]\n - workflowoperation unit tests are incredible slow\n\n\n[MH-11252]\n - Some service configuration files are stored in the wrong\n  directory\n\n\n[MH-11265]\n - Ensure configuration files end with newline characters\n\n\n[MH-11266]\n - Logger ConversionPattern stated twice\n\n\n[MH-11276]\n - HttpNotificationWorkflowOperationHandlerTest fails if a\n  certain Domain Exists\n\n\n[MH-11280]\n - Opencast fails to compile due to missing dependencies in\n  test-harness\n\n\n[MH-11281]\n - Enhance WOH image to support extraction of multiple images\n  using multiple encoding profiles from multiple sources\n\n\n[MH-11282]\n - Enhance WOH composite to support single video streams\n\n\n[MH-11287]\n - Update Apereo/Apache License List\n\n\n[MH-11289]\n - Change text extraction documentation or file name\n\n\n[MH-11294]\n - Create admin-worker and ingest distribution\n\n\n[MH-11296]\n - HTTP method POST is not supported by this url in r/2.1.x\n\n\n[MH-11298]\n - Fix json-simple version specification\n\n\n[MH-11300]\n - WOH partial-import looses partial audio tracks beginning at\n  position zero\n\n\n[MH-11304]\n - Documentation for WOH partial-import and load configuration\n  not listed in pages configuration\n\n\n[MH-11306]\n - Change job dispatcher sort order to: restart jobs, non-wf\n  jobs, creation date\n\n\n[MH-11307]\n - Distribution Service is not on Presentation Node\n\n\n[MH-11310]\n - Document encoding profiles used by WOH partial-import\n\n\n[MH-11311]\n - Use existing encoding profiles in WOH partial-import example\n\n\n[MH-11312]\n - Fix Encode WOH Documentation\n\n\n[MH-11313]\n - Update Parallel Encode Profiles\n\n\n[MH-11319]\n - Media Module Always Uses Second Attachment as Preview\n\n\n[MH-11320]\n - Missing Image Preparation for text Extraction\n\n\n[MH-11321]\n - Fix default workflow configuration panel\n\n\n[MH-11322]\n - Update WebM Profiles\n\n\n[MH-11355]\n - Slide texts are not shown correctly in theodul player,\n  except the first segment there a now slide texts shown (\"No slide text available\"). In the XML file the texts are\n  correct\n\n\n[MH-11356]\n - Update Documentation Index Page\n\n\n[MH-11357]\n - Notifications are not removed after a while\n\n\n[MH-11358]\n - Dismiss Button for comments has an inconsistent design\n\n\n[MH-11363]\n - Notification that server is not reachable is missing\n\n\n[MH-11364]\n - Reasons in Comments section are no longer translated\n\n\n[MH-11368]\n - Changing to Chinese translation doesn't work\n\n\n[MH-11369]\n - Series filter displays series id instead of series title\n\n\n[MH-11374]\n - Videoeditor: Times are wrong in zoomed waveform view\n\n\n[MH-11385]\n - Metadata summary not showing any metadata at event creation\n\n\n[MH-11386]\n - Silence Detection / Video Editor Waveform bug\n\n\n[MH-11389]\n - security 1\n\n\n[MH-11391]\n - Improve Flavor creation and parsing\n\n\n[MH-11392]\n - Sorting by series.created does not work correctly\n\n\n[MH-11401]\n - Hiding of columns is globally broken\n\n\n[MH-11404]\n - Group editor shows users and roles twice\n\n\n[MH-11405]\n - Pagination broken for groups table\n\n\n[MH-11409]\n - Translation key\n  EVENTS.EVENTS.GENERAL.SELECT_WORKFLOW_EMPTY is missing\n\n\n[MH-11413]\n - AdminUI comment dialog translations missing\n\n\n[MH-11414]\n - Logger is missing from several modules\n\n\n[MH-11415]\n - Incorrect Urlsigning Module Name\n\n\n[MH-11416]\n - Specify Opencast's Requirements\n\n\n[MH-11417]\n - Tab names of modals not vertically centered\n\n\n[MH-11419]\n - Tables not drawn correctly\n\n\n[MH-11422]\n - add event tab titles not translated\n\n\n[MH-11427]\n - Can't get host details from Serviceregistry REST endpoint\n\n\n[MH-11428]\n - Default Workflow Option Does Not Work\n\n\n[MH-11430]\n - Prevent user from accidentally press \"Save & process\" in\n  Video Editor multiple times\n\n\n[MH-11431]\n - Prevent users from accidentally pressing the Delete/Retract\n  button multiple times\n\n\n[MH-11432]\n - JSHint settings are missing\n\n\n[MH-11434]\n - \"The task could not be created\" error notification always\n  appear when starting a task on multiple events\n\n\n[MH-11435]\n - Fix code style errors in Gruntfile.js\n\n\n[MH-11436]\n - Matterhorn on Login/Welcome Page\n\n\n[MH-11437]\n - Resource Problems On Login Page\n\n\n[MH-11438]\n - Resource Problem on Welcome Page\n\n\n[MH-11439]\n - Event description not available in WOH cover-image\n\n\n[MH-11441]\n - Clicking on Logo in top left corner will nmot get you to the\n  start page\n\n\n[MH-11443]\n - Seeking is not possible before pressing play button at least\n  once?!?\n\n\n[MH-11446]\n - Remove eclipse-gemini repository from main pom.xml\n\n\n[MH-11447]\n - Scheduling conflicts reporting completely broken\n\n\n[MH-11448]\n - Tipps on developing on admin ui ng\n\n\n[MH-11450]\n - Fix Defaults For Documentation Links\n\n\n[MH-11453]\n - Correctly link the stream security documentation\n\n\n[MH-11457]\n - Remove duplicate keys from Admin UI english translation\n\n\n[MH-11458]\n - Update translations from crowdin\n\n\n[MH-11459]\n - Logger Logs Nullpointer on Error\n\n\n[MH-11462]\n - Cover WOH is not included in a useful way\n\n\n[MH-11464]\n - setting personal preferences in admin UI fails\n\n\n[MH-11468]\n - There are unused ressources\n\n\n[MH-11475]\n - Fix typos in English master translation\n\n\n[MH-11476]\n - Series->Actions->Delete displays wrong notifications\n\n\n[MH-11477]\n - Editing status of series displays wrong notification when\n  saving fails for all series\n\n\n[MH-11480]\n - Replace horizontal ellipsis\n\n\n[MH-11481]\n - Workflows started by unprivileged users hang\n\n\n[MH-11492]\n - forward and backward section not working in safari\n\n\n[MH-11509]\n - Failed test: Sorting groups list (grp-lis-01)\n\n\n[MH-11511]\n - Failed test: Manual set time in textbook for IE11\n\n\n[MH-11512]\n - hello world does not follow import statements rules\n\n\n[MH-11518]\n - Language selector is always displayed in system language\n\n\n[MH-11519]\n - Languages are only distinguished by main language\n\n\n[MH-11520]\n - Remove company logos\n\n\n[MH-11521]\n - ActiveMQ Library Configuration\n\n\n[MH-11522]\n - DataLoader Default Value\n\n\n[MH-11523]\n - Working file repository default value\n\n\n[MH-11524]\n - Distribution Service Default Values\n\n\n[MH-11532]\n - Wider language support in player\n\n\n[MH-11534]\n - Add language support for Chinese Simplified\n\n\n[MH-11535]\n - Add documentation about Crowdin to Developer Guide\n\n\n[MH-11536]\n - Remove Commercial Code From Core\n\n\n[MH-11537]\n - Execute Service WOH Cannot be Built\n\n\n[MH-11539]\n - Remove Old MH Logos in Favor of Opencast SVG Logos\n\n\n[MH-11544]\n - Admin UI links used inconsistently\n\n\n[MH-11546]\n - Pagination buttons too small for large numbers\n\n\n[MH-11548]\n - The \"Edit\" button at the top-right corner of the tables\n  doesn't support localization\n\n\n[MH-11550]\n - Update Migration documentation 2.1 to 2.2\n\n\n[MH-11554]\n - Filtering does not work on Systems->Jobs,\n  Systems->Servers and Systems->Services\n\n\n[MH-11555]\n - Localisation of Recordings->Events and\n  Recordings->Series buggy\n\n\n[MH-11556]\n - Failed test: Filter locations (T1733, Filter by status does\n  not work)\n\n\n[MH-11559]\n - outdated shortcurts configuration prevents player from\n  loading.\n\n\n[MH-11571]\n - Elasticsearch shutdown command handler crash opencast\n\n\n[MH-11573]\n - Do not hide warnings\n\n\n[MH-11574]\n - Jetty Error on Large Workflow Instances\n\n\n[MH-11575]\n - Inspection Service Tests Fail With Certain FFmpeg Versions\n\n\n[MH-11576]\n - Servlet Filter Improvements\n\n\n[MH-11578]\n - Improve default order of columns in Systems->Jobs\n\n\n[MH-11579]\n - Admin UI mockup data for Systems->Jobs incomplete\n\n\n[MH-11580]\n - Unit tests for Admin UI language selection broken\n\n\n[MH-11581]\n - Systems->Jobs table not working correctly\n\n\n[MH-11583]\n - Fix Code Style\n\n\n[MH-11588]\n - Create side-by-side preview for video editor\n\n\n[MH-11589]\n - Feedback button does not work\n\n\n[MH-11590]\n - The WorkflowServiceImpl constructor sets the\n  \"waitForResources\" argument incorrectly\n\n\n[MH-11594]\n - Add language support for Galician\n\n\n[MH-11595]\n - Fix admin ui unit tests for tableService\n\n\n[MH-11597]\n - Building matterhorn-engage-theodul-plugin-video-videojs\n  reports a lot of code style issues\n\n\n[MH-11600]\n - Failed test: i18n (gen-int-01)\n\n\n[MH-11601]\n - current language can have undefined state\n\n\n[MH-11604]\n - Date picker for setting up the schedule is always french\n\n\n[MH-11605]\n - Disabling link to mediaplayer creates a broken link and\n  missing logo\n\n\n[MH-11606]\n - Add language support for Greek\n\n\n[MH-11608]\n - Add documentation for WOH cleanup\n\n\n[MH-11613]\n - WOH editor fails when input has uneven width or height\n\n\n[MH-11614]\n - Partial matches not working anymore\n\n\n[MH-11617]\n - Add language support for Dutch\n\n\n[MH-11620]\n - Non privileged user can not login on presentation node\n\n\n[MH-11623]\n - Server statistics: Slow Query\n\n\n[MH-11624]\n - Workflow owners do not necessarily have access to their\n  workflows: user comparison fails\n\n\n[MH-11627]\n - NullPointerException when creating a new Solr index\n\n\n[MH-11629]\n - Hide Some Confusing Warnings\n\n\n[MH-11630]\n - Service registry lacks of getActiveJobs() function\n\n\n[MH-11631]\n - Remove columns \"Blacklisted from\" and \"Blacklisted until\"\n  from Capture->Locations\n\n\n[MH-11632]\n - Library Bugfix Upgrade\n\n\n[MH-11636]\n - Adjust FFmpegComposer Logging for Newer FFmpeg Versions\n\n\n[MH-11637]\n - Add language support for Swedish\n\n\n[MH-11638]\n - Improve Encoding Profiles\n\n\n[MH-11639]\n - Media module login form has poor usability and bugs\n\n\n[MH-11642]\n - Remove binding to non-existing method in WOH analyze-tracks\n\n\n[MH-11643]\n - Add language support for Polish\n\n\n[MH-11645]\n - Open AdminUI menu links in new tab does not work\n\n\n[MH-11646]\n - Add documentation for WOH comment\n\n\n[MH-11652]\n - Unit tests for servicesController broken\n\n\n[MH-11654]\n - Failed ingest jobs block system from dispatching other jobs\n\n\n[MH-11656]\n - Add documentation for WOH copy\n\n\n[MH-11657]\n - Improve documentation for workflow execution conditions\n\n\n[MH-11658]\n - Better quality for video editor previews\n\n\n[MH-11663]\n - Hide Participation Management from UI since not yet working\n\n\n[MH-11666]\n - Not all WOH listed in WOH overview\n\n\n\n\nOpencast 2.1.x\n\n\nOpencast 2.1.2\n\n\nReleased on May 10, 2016\n\n\n\n\n[MH-9831]\n - ehcache and quartz phones home\n\n\n[MH-11121]\n - MacOS X Installation Guide Needs 2.1 Update\n\n\n[MH-11124]\n - Incorrect documentation on how to create users\n\n\n[MH-11128]\n - Docs about SilenceDetector threashold are incorrect\n\n\n[MH-11209]\n - LTI Documentation needs to be incorporated into new docs\n\n\n[MH-11229]\n - workflowoperation unit tests are incredible slow\n\n\n[MH-11283]\n - post-mediapackage WOH breaks further processing\n\n\n[MH-11287]\n - Update Apereo/Apache License List\n\n\n[MH-11296]\n - HTTP method POST is not supported by this url in r/2.1.x\n\n\n[MH-11298]\n - Fix json-simple version specification\n\n\n[MH-11307]\n - Distribution Service is not on Presentation Node\n\n\n[MH-11319]\n - Media Module Always Uses Second Attachment as Preview\n\n\n[MH-11320]\n - Missing Image Preparation for text Extraction\n\n\n[MH-11321]\n - Fix default workflow configuration panel\n\n\n[MH-11323]\n - Workflow Docs are Incorrect\n\n\n[MH-11332]\n - Document acceptance criteria for proposals\n\n\n[MH-11356]\n - Update Documentation Index Page\n\n\n[MH-11377]\n - Opencast does not have an ingest assembly\n\n\n\n\nOpencast 2.1.1\n\n\nReleased on January 22, 2016\n\n\n\n\n[MH-11107]\n - Group list pagination not working\n\n\n[MH-11265]\n - Ensure configuration files end with newline characters\n\n\n[MH-11266]\n - Logger ConversionPattern stated twice\n\n\n[MH-11276]\n - HttpNotificationWorkflowOperationHandlerTest fails if a\n  certain Domain Exists\n\n\n[MH-11280]\n - Opencast fails to compile due to missing dependencies in\n  test-harness\n\n\n\n\nOpencast 2.1.0\n\n\nReleased on December 22, 2015\n\n\n\n\n[MH-10637]\n - Hello World service\n\n\n[MH-10651]\n - Workspace cleaner job param in wrong units (ms vs s) and\n  wrong logic\n\n\n[MH-10714]\n - Two clock icons at the time stamp of a comment\n\n\n[MH-10805]\n - The confirmation dialog are not translated\n\n\n[MH-10818]\n - The creation date is presented as ISO string in the event\n  metadata\n\n\n[MH-10869]\n - ActiveMQ Configuration and Connection Problems\n\n\n[MH-10874]\n - Plugin does not properly handle multiple keys\n\n\n[MH-10875]\n - Include search capabilities into mkdocs documentation build\n\n\n[MH-10890]\n - Update Apache Commons Lang (2.6 \u2192 3.4)\n\n\n[MH-10908]\n - Assemblie Module Names Too Long\n\n\n[MH-10908]\n - Consistency in Documentation: Presentation Server VS Engage\n  Server\n\n\n[MH-10908]\n - Misconfigured Checkstyle Plug-in in Assemblies\n\n\n[MH-10919]\n - Top row for setting roles in the access policy for an event\n  is not showing the right value\n\n\n[MH-10953]\n - Spanish layout is broken\n\n\n[MH-10955]\n - Make sure recent versions of mkdocs work\n\n\n[MH-10956]\n - Update Synchronize.js\n\n\n[MH-10985]\n - As an operator I want to check the health status of Opencast\n\n\n[MH-10986]\n - Scheduling around DST change fails\n\n\n[MH-10987]\n - Improve workflow query to accept paging by index\n\n\n[MH-10988]\n - Rewrite workspace to fix several small issues\n\n\n[MH-10989]\n - Improve working file repository stream response\n\n\n[MH-11007]\n - Remove 3rd party tool script\n\n\n[MH-11026]\n - Several invalid links in the Opencast User Guides\n\n\n[MH-11031]\n - Missing option to create new event using files ingested from\n  the inbox\n\n\n[MH-11036]\n - Adapt Fast Testing Workflow for Admin NG\n\n\n[MH-11051]\n - Fix WOH Documentation\n\n\n[MH-11069]\n - When creating new series, warning about read/write\n  requirements is shown twice.\n\n\n[MH-11072]\n - The ACL editor needs enhanced validation\n\n\n[MH-11074]\n - Admin UI Test: New Event API Resource assembles the metadata\n  for SCHEDULE_MULTIPLE with DST change is failing\n\n\n[MH-11083]\n - Clean-up Codebase after Karaf\n\n\n[MH-11085]\n - Make sure bundle cache is cleared when restarting\n\n\n[MH-11086]\n - Shorten File Names in Log Output\n\n\n[MH-11088]\n - translation error in theodul player\n\n\n[MH-11089]\n - Theodul player seems not to work with Internet Explorer at\n  all\n\n\n[MH-11093]\n - single video screen size jump when clicked\n\n\n[MH-11094]\n - Problems in Theodul controls plugin due to wrong resolves of\n  merge conflicts\n\n\n[MH-11095]\n - Make assemblies more user firedly\n\n\n[MH-11096]\n - Errors when loading admin-ng login page\n\n\n[MH-11099]\n - Removing one role from an Access Policy (acl-det-05)\n\n\n[MH-11101]\n - Creating a Theme with 2 bumper videos - In and Out\n  (thm-new-01)\n\n\n[MH-11109]\n - Event details tab cannot handle long event titles well\n\n\n[MH-11110]\n - minor updates to ffmpeg video-editor and silence detection\n  based on gregs review of the feature in 1.6.3\n\n\n[MH-11111]\n - Formatting issues in \u201cTheodul Pass Player - URL Parameters\u201d\n\n\n[MH-11114]\n - Remove System.out.println from FileReadDeleteTest\n\n\n[MH-11120]\n - Several Services Fail During Shutdown\n\n\n[MH-11122]\n - Create Service Files (Systemd/SysV-Init)\n\n\n[MH-11126]\n - Fix Translation for 2.1\n\n\n[MH-11133]\n - i18n: Theme Detail view layout broken in Spanish\n\n\n[MH-11135]\n - Create Release Manager Docs\n\n\n[MH-11137]\n - Comment reasons are not working correctly\n\n\n[MH-11138]\n - Clock icon displayed twice next to comment creation date\n\n\n[MH-11141]\n - Playback Speed in player needs more useful defaults\n\n\n[MH-11142]\n - fix translations for shortcuts\n\n\n[MH-11144]\n - update documentation regarding property for mediamodule logo\n\n\n[MH-11147]\n - Missing translations: FILTERS.USERS.PROVIDER.LABEL &\n  FILTERS.USERS.ROLE.LABEL\n\n\n[MH-11149]\n - Filter locations: Translations FILTERS.AGENTS.NAME.LABEL &\n  FILTERS.AGENTS.STATUS.LABEL missing\n\n\n[MH-11151]\n - Plaback speed from menu\n\n\n[MH-11152]\n - Editing ACL: Translation for\n  USERS.ACLS.DETAILS.ACCESS.ACCESS_POLICY.DESCRIPTION missing\n\n\n[MH-11153]\n - Access Policy Details: Cannot navigate to previous or next\n  ACL\n\n\n[MH-11154]\n - New Access Policy: Translation for\n  USERS.ACLS.NEW.ACCESS.ACCESS_POLICY.DESCRIPTION missing\n\n\n[MH-11155]\n - ACL Editor: Role not displayed at all\n\n\n[MH-11158]\n - Playback Tool: Time can be edited, but editing has no effect\n\n\n[MH-11159]\n - Users sorting: Sort order for 'Name' not correct\n\n\n[MH-11160]\n - Create Group overwrites existing groups without warning\n\n\n[MH-11162]\n - security_sample_cas.xml in MH 2.0.1 Points to Wrong\n  Welcome Page\n\n\n[MH-11166]\n - Number of rows not displayed on Systems->Servers\n\n\n[MH-11176]\n - Cannot playback a recording via LTI in 2.x\n\n\n[MH-11177]\n - Fix Player OSGI Dependencies\n\n\n[MH-11178]\n - Prevent FFmpeg Experimental AAC Encoder Bug to Affect\n  Opencast\n\n\n[MH-11180]\n - Update video.js to latest 4.x version\n\n\n[MH-11181]\n - Flash streaming with multi-quality video does not work\n\n\n[MH-11185]\n - Event Details->Assets->: Asset size is always 0\n\n\n[MH-11186]\n - Event Details->Assets->Media->Media Details:\n  Superfluous row 'Flavor'\n\n\n[MH-11187]\n - Configuration->Themes: Number of rows not displayed\n  correctly\n\n\n[MH-11189]\n - Actions->Start Task: User can press create button\n  multiple times\n\n\n[MH-11193]\n - Setting audio level slider to \"zero\" does not set the actual\n  audio level to \"zero\"\n\n\n[MH-11196]\n - REST docs cannot be found in new admin ui\n\n\n[MH-11198]\n - Event dashboard seems not to support i18n\n\n\n[MH-11201]\n - Maven Assembly Plug-in Listed Twice\n\n\n[MH-11202]\n - FFmpeg video editor operation is synchronized\n\n\n[MH-11212]\n - Main Pom Clean-Up\n\n\n[MH-11218]\n - Karaf based Solr configuration\n\n\n[MH-11221]\n - ComposerServiceImpl creates incorrect incidents and error\n  messages\n\n\n[MH-11223]\n - Remove unused files\n\n\n[MH-11234]\n - Admin-NG throws a couple of 404 errors\n\n\n[MH-11236]\n - Security ACL \nsee security list\n\n\n[MH-11237]\n - Service files are missing\n\n\n[MH-11238]\n - Silence-detection does not read configuration value for\n  ffmpeg binary path\n\n\n[MH-11248]\n - Publish-Engage Workflow Operation Documentation is Missing\n  Configuration Keys\n\n\n[MH-11249]\n - Apply-ACL WOH not properly replaced by Seried-WOH in\n  Documentation\n\n\n[MH-11250]\n - Put temporary files in karaf data not in opencast.storage\n\n\n[MH-11251]\n - Capture-Admin Tests May Fail When Executed Too Fast\n\n\n[MH-11257]\n - Deprecated Mkdocs Config\n\n\n[MH-11258]\n - Make host configuration easier\n\n\n\n\nOpencast 2.0.x\n\n\nOpencast 2.0.2\n\n\nReleased on December 22, 2015\n\n\n\n\n[MH-10235]\n - Users are unable to determine the Version of Matterhorn\n\n\n[MH-10484]\n - Remove Mediainfo from 3rd-Party-Tools\n\n\n[MH-10558]\n - Mime type not identified for matroska / mkv files\n\n\n[MH-10588]\n - Improve MySQL DDL to make it consistent again\n\n\n[MH-10759]\n - Write QA documentation for Access Policies\n\n\n[MH-10759]\n - Write QA documentation for Series\n\n\n[MH-10759]\n - Write QA documentation for Themes\n\n\n[MH-10818]\n - The creation date is presented as ISO string in the event\n  metadata\n\n\n[MH-10918]\n - Improve the representation of the\n  attachments/catalogs/media/publications in the event details\n\n\n[MH-10956]\n - Update Synchronize.js\n\n\n[MH-10964]\n - The Opencast start script does not work on Mac OS X\n\n\n[MH-10976]\n - Eclipse (m2e) throws NullPointerException erros due to a\n  missing property in the pom.xml file\n\n\n[MH-11007]\n - Remove 3rd party tool script\n\n\n[MH-11007]\n - Switch subtitle embedder to FFmpeg\n\n\n[MH-11026]\n - Several invalid links in the Opencast User Guides\n\n\n[MH-11038]\n - Make ListProviderScanner Scanner Less verbose\n\n\n[MH-11048]\n - admin ui tries to load missing library\n\n\n[MH-11051]\n - Fix WOH Documentation\n\n\n[MH-11060]\n - ActiveMQ settings filename fix (r/2.0.x)\n\n\n[MH-11068]\n - Table 'mh_bundleinfo' doesn't exist\n\n\n[MH-11110]\n - minor updates to ffmpeg video-editor and silence detection\n  based on gregs review of the feature in 1.6.3\n\n\n[MH-11176]\n - Cannot playback a recording via LTI in 2.x\n\n\n[MH-11177]\n - Fix Player OSGI Dependencies\n\n\n[MH-11181]\n - Flash streaming with multi-quality video does not work\n\n\n[MH-11202]\n - FFmpeg video editor operation is synchronized\n\n\n[MH-11221]\n - ComposerServiceImpl creates incorrect incidents and error\n  messages\n\n\n[MH-11236]\n - Security ACL \nsee security list\n\n\n[MH-11238]\n - Silence-detection does not read configuration value for\n  ffmpeg binary path\n\n\n[MH-11256]\n - Opencast docs do not build anymore\n\n\n\n\nOpencast 2.0.1\n\n\nReleased on September 3, 2015\n\n\n\n\n[MH-10822]\n - Possible to create new access policy template without a role\n  with read/write permissions\n\n\n[MH-10938]\n - Missing views counter in player\n\n\n[MH-10941]\n - Usertracking Service Missing Endpoint\n\n\n[MH-10955]\n - Make sure recent versions of mkdocs work\n\n\n[MH-10962]\n - Add missing licenses to NOTICES\n\n\n[MH-10968]\n - Add note about ffmpeg/libav on Ubuntu\n\n\n[MH-10975]\n - async loading of translations\n\n\n[MH-10995]\n - Gathering workflow statistics for JMX causes extreme\n  performance issues\n\n\n\n\nOpencast 2.0.0\n\n\nReleased on July 17, 2015\n\n\n\n\n[MH-9950]\n - \"Clean up\"/Split up nested functions in the core routine\n  (core.js)\n\n\n[MH-9950]\n - Load CSS files in the core HTML file, not the JavaScript\n\n\n[MH-9950]\n - Scrolling is required to see the controls if they are\n  configured to be below the video.\n\n\n[MH-9950]\n - Some Keys don't work\n\n\n[MH-9950]\n - Theodul Core Jasmine Tests Sometimes Failing\n\n\n[MH-10029]\n - FFmpeg based Videosegmenter\n\n\n[MH-10140]\n - Capture agent with no configuration is always shown as\n  \"idle\"\n\n\n[MH-10202]\n - No ACL in new series when ingested a new mediapackage with a\n  new series.\n\n\n[MH-10230]\n - Typos on the welcome page\n\n\n[MH-10332]\n - Remove Mediainfo Inspection Service\n\n\n[MH-10382]\n - Add a UI Element to Easily Unregister Capture Agents\n\n\n[MH-10419]\n - Improve user tracking tables\n\n\n[MH-10510]\n - Move Workflow Operation Handler into their own Packages\n\n\n[MH-10550]\n - Non-Interactive Foreground Mode For Matterhorn\n\n\n[MH-10572]\n - ShibbolethLoginHandler: 500 Error when login the first time\n\n\n[MH-10594]\n - Re-configure Start Scripts for Different Deployment Types\n\n\n[MH-10615]\n - Enable Optional Compiler Arguments\n\n\n[MH-10620]\n - Port Silence Detector from GStreamer to FFmpeg\n\n\n[MH-10622]\n - Wave Generation Improvement\n\n\n[MH-10623]\n - Set Sensible Default for Workspace Cleanup Period\n\n\n[MH-10624]\n - Fixes for FFmpeg Videosegmenter (Set Binary)\n\n\n[MH-10630]\n - Extending common functionality\n\n\n[MH-10631]\n - Scheduler service authorization handling\n\n\n[MH-10635]\n - Text extractor dead lock\n\n\n[MH-10640]\n - several problems with the metadata form to create a new\n  event\n\n\n[MH-10656]\n - Login Screen: Placeholder and Focus\n\n\n[MH-10658]\n - Email template: diverse problems\n\n\n[MH-10664]\n - What is a template in Access Policy and how do I create it?\n\n\n[MH-10665]\n - 404 for variables.json\n\n\n[MH-10667]\n - Previous Button does not always work\n\n\n[MH-10681]\n - Time is missing when a workflow operation has been started\n  and stopped\n\n\n[MH-10683]\n - Remove Capture Agent\n\n\n[MH-10683]\n - Remove the Capture Agent integration tests\n\n\n[MH-10684]\n - Admin UI seems only unresponsive if server is down\n\n\n[MH-10689]\n - I should get a warning, if I leave the Admin UI while I\n  still create an event (upload a file)\n\n\n[MH-10698]\n - workflow after videoeditor does not produce any \n*/delivery\n\n  flavors\n\n\n[MH-10700]\n - Service Registry throws NPE exception on startup\n\n\n[MH-10704]\n - Workflows fail if adding themes\n\n\n[MH-10705]\n - Row counter in Jobs table is 1 too much\n\n\n[MH-10707]\n - Unit Test Failure\n\n\n[MH-10710]\n - NullPointerException in VideoSegmentationWOH\n\n\n[MH-10711]\n - OptimisticLockException after ingest\n\n\n[MH-10712]\n - Workflow cleanup out of memory error\n\n\n[MH-10713]\n - Cache util blocks forever\n\n\n[MH-10726]\n - Archive operation should use filesystem copy rather than\n  http download\n\n\n[MH-10736]\n - Engage is currently broken and won't play videos but\n  Theodule does\n\n\n[MH-10740]\n - NPE in ToolsEndpoint\n\n\n[MH-10746]\n - There is no event status column\n\n\n[MH-10758]\n - Issues found in production use of Theodul: changing icons,\n  seeking in Chrome, using configured logos, wording, layout...\n\n\n[MH-10759]\n - Write QA documentation for Events\n\n\n[MH-10759]\n - Write QA documentation for Groups\n\n\n[MH-10759]\n - Write QA documentation for Servers\n\n\n[MH-10759]\n - Write QA documentation for Services\n\n\n[MH-10763]\n - Remove Old Confirations\n\n\n[MH-10765]\n - Operation details doesn't show operation attributes when\n  state is instantiated\n\n\n[MH-10768]\n - Workflow operations table in the events details should\n  refresh automatically\n\n\n[MH-10769]\n - Add (x) icon in the events and series tableview to allow\n  deletion of single Events/Series\n\n\n[MH-10770]\n - Some captions of tabs are not yet translated\n\n\n[MH-10772]\n - Ensure that buttons order is consistent in the actions\n  column\n\n\n[MH-10773]\n - Allow to have free-text value for presenters, contributors,\n  organizers or publishers\n\n\n[MH-10774]\n - ACL editing should be locked on the Series level when events\n  of the series are being processed\n\n\n[MH-10775]\n - All the roles with read/write rights can be deleted from the\n  ACL editor in Events/Series details\n\n\n[MH-10776]\n - Include Spanish and French translation into Theodul.\n\n\n[MH-10780]\n - Specify Requirements\n\n\n[MH-10781]\n - Respect tags while filtering for suitable tracks in Theodul\n  player\n\n\n[MH-10792]\n - Pom.xml Extra Modules\n\n\n[MH-10798]\n - Event Details tile shows hash identifier\n\n\n[MH-10799]\n - Videoeditor operation does not properly handle missing\n  preview formats\n\n\n[MH-10804]\n - It is unclear in which timezone you schedule in the admin-ui\n\n\n[MH-10807]\n - New event POST request contains every series and user\n\n\n[MH-10808]\n - Disable Demo Users\n\n\n[MH-10810]\n - Rename upgrade script form 1.6 to 2.0\n\n\n[MH-10812]\n - Use bundles.configuration.location in admin ng settings.yml\n\n\n[MH-10814]\n - Pressing play while buffering breaks player\n\n\n[MH-10816]\n - Move Message Broker Configuration to Global Config\n\n\n[MH-10821]\n - Severe Issue with Scheduled Events\n\n\n[MH-10829]\n - Unchecking \"Remember me\" checkbox has no effect when logged\n  out. Pressing the browsers back button you're still logged in an d can use all functions.\n\n\n[MH-10836]\n - Issues with matterhorn-engage-theodul-plugin-archetype\n\n\n[MH-10837]\n - Bulk deletion of events doesn't work correctly\n\n\n[MH-10843]\n - different video qualities are not filtered correctly.\n\n\n[MH-10845]\n - Summary of \"Add Events\" and \"Add Series\" shows irrelevant\n  data\n\n\n[MH-10847]\n - Missing with-role directive in \"Start Task\" option in\n  Actions dropdown\n\n\n[MH-10848]\n - Event conflict endpoint returns Server error 500\n\n\n[MH-10849]\n - Temporary videoeditor files get not deleted\n\n\n[MH-10850]\n - Interface MatterhornConstans has a typo\n\n\n[MH-10853]\n - Improve admin UI ng workflows\n\n\n[MH-10855]\n - Task Menu displays wrong UI\n\n\n[MH-10864]\n - Remove Trailing Spaces From Less Files\n\n\n[MH-10866]\n - Documentation: Incorrect Repository Links\n\n\n[MH-10868]\n - Linebreak before last segment in player\n\n\n[MH-10873]\n - capture-admin-service-impl tests randomly failing\n\n\n[MH-10876]\n - Admin UI NG makes calls to remote resources\n\n\n[MH-10880]\n - Remote base keeps try to call a service\n\n\n[MH-10881]\n - Wrong links to r/2.0.x on documentation page\n\n\n[MH-10884]\n - WokflowOperation getTimeInQueue should return 0 if value is\n  NULL\n\n\n[MH-10888]\n - Theodul player: audio-only does not work - player checked\n  for unavailable size.\n\n\n[MH-10901]\n - Execute Service is not in main pom.xml and will not be built\n\n\n[MH-10902]\n - ./modules/matterhorn-publication-service-youtube/ obsolete\n\n\n[MH-10905]\n - FFmpeg videoeditor only works with audio and video available\n\n\n[MH-10911]\n - Remove executable flag from non-executables\n\n\n[MH-10912]\n - Init scripts contain undefined references to DEBUG_PORT and\n  DEBUG_SUSPEND\n\n\n[MH-10913]\n - Add Event: License Metadata Field Text\n\n\n[MH-10924]\n - Update to new Opencast logos\n\n\n[MH-10926]\n - Extensive PhantomJS warnings when building admin-ng\n\n\n[MH-10928]\n - Adjust loglevel in DictionaryService\n\n\n[MH-10929]\n - Cutting and Review are skipped when config is set to do so\n\n\n[MH-10930]\n - Fix missing German translation\n\n\n[MH-10934]\n - Once set, one cannot remove some metadata in the create\n  event dialog\n\n\n[MH-10938]\n - Missing views counter in player\n\n\n[MH-10939]\n - Task Summary does not display configuration values\n\n\n[MH-10946]\n - Fix Opencast 2 Installation Guides\n\n\n[MH-10950]\n - Fix DDL Readme\n\n\n[MH-10952]\n - Fix matterhorn-execute-operations naming\n\n\n[MH-10957]\n - Add License Guide for Developers",
            "title": "Changelog"
        },
        {
            "location": "/changelog/#changelog",
            "text": "",
            "title": "Changelog"
        },
        {
            "location": "/changelog/#opencast-5",
            "text": "",
            "title": "Opencast 5"
        },
        {
            "location": "/changelog/#opencast-51",
            "text": "Released on September 3, 2018   [ MH-13067 ][ #404 ] -\n  Configuration panel does not work for default workflow  [ MH-13049 ][ #400 ] -\n  Fix video editor zoom dropdown showing wrong value  [ MH-13055 ][ #396 ] -\n  Stop making events with no ACL public on ingest  [ MH-13048 ][ #394 ] -\n  Improve stability of the series index rebuild  [ MH-13047 ][ #393 ] -\n  Document using Nginx for HTTPS  [ MH-13044 ][ #390 ] -\n  Organization server configuration documentation  [ MH-12016 ][ #379 ] -\n  Scrolling role fetch  [ MH-13031 ][ #377 ] -\n  Active transaction notification on top  [ MH-13029 ][ #375 ] -\n  Don't show old notifications  [ MH-13023 ][ #370 ] -\n  Let default value fulfill requirement  [ MH-13018 ][ #367 ] -\n  re-add recordings json to 5x (includes MH-12828 re-add conflicts.json)  [ MH-13020 ][ #366 ] -\n  Read listproviders as UTF-8  [ MH-13017 ][ #363 ] -\n  JS syntax error in publish workflow  [ MH-13015 ][ #361 ] -\n  5.x database upgrade scripts  [ MH-13014 ][ #360 ] -\n  Don't show stale search results  [ MH-13006 ][ #353 ] -\n  Waveform operation cleanup creates problem with asynchronous NFS  [ MH-13003 ][ #352 ] -\n  Implement detection of already recorded (as opposed to yet to be recorded, scheduled) events by the index service  [ MH-13005 ][ #351 ] -\n  Skip waveform operation when no tracks  [ MH-13001 ][ #347 ] -\n  Fixed live scheduler service pom  [ MH-12988 ][ #337 ] -\n  delete-scheduled-live Fix for scheduled live event not deleted  [ MH-12986 ][ #333 ] -\n  Admin UI deployed debugging: include source in SourceMap files  [ MH-12981 ][ #331 ] -\n  fix for local admin-ui develop finding main.css  [ MH-12979 ][ #325 ] -\n  Automatically test ddl scripts  [ MH-12978 ][ #324 ] -\n  Fix data-placeholder in add event wizard  [ MH-12974 ][ #318 ] -\n  Access denial to event for unprivileged user  [ MH-12970 ][ #315 ] -\n  Senseless XACML parsing  [ MH-12966 ][ #312 ] -\n  Do not pre-select-from option in metadata property sheets  [ MH-12963 ][ #310 ] -\n  Localize dates/times in add-event summary  [ MH-12950 ][ #309 ] -\n  Fix for workflow with no acl in solr index  NOJIRA: Skip install of Crowdin if it is already installed\n    [ MH-12957 ][ #300 ] -\n  Defaults on tab Source in Add Event wizards are broken  [ MH-12954 ][ #297 ] -\n  wrong date format in coverimage file",
            "title": "Opencast 5.1"
        },
        {
            "location": "/changelog/#opencast-50",
            "text": "Released on June 12, 2018   [ MH-12952 ][ #295 ] -\n  animate WOH dependency version fixed  [ MH-12946 ][ #290 ] -\n  Fix summary of add-event-dialog  [ MH-12944 ][ #288 ] -\n  Remove bashism from start script  [ MH-12905 ][ #287 ] -\n  TEMPORARY Karaf config assembly workaround (KARAF-5693)  [ MH-12943 ][ #286 ] -\n  Minor Paella config REST endpoint improvements  [ MH-12942 ][ #285 ] -\n  Paella player config REST endpoint should be accessible by anonymous user  [ MH-12941 ][ #284 ] -\n  Gracefully handle empty flavors  [ MH-12940 ][ #283 ] -\n  Ensure admin configuration is applied  [ MH-12864 ][ #282 ] -\n  Don't attempt to parse 'undefined'  [ MH-12938 ][ #281 ] -\n  Fix NullPointerException if no flavor is set  [ MH-12937 ][ #280 ] -\n  Correctly place admin UI test helper  [ MH-12936 ][ #279 ] -\n  Handle invalid flavors  [ MH-12935 ][ #278 ] -\n  Update Docker image repository documentation  [ MH-12934 ][ #277 ] -\n  Update translations  [ MH-12933 ][ #276 ] -\n  Link documentation from Systemd unit  [ MH-12932 ][ #275 ] -\n  Kernel Build Failure  [ MH-12922 ][ #272 ] -\n  Job load fixes  [ MH-12929 ][ #271 ] -\n  Change paella URL to /paella/ui  [ MH-12928 ][ #270 ] -\n  Mitigation for KARAF-5526  [ MH-12926 ][ #269 ] -\n  Prevent cluttering of logs by invalid access  [ MH-12924 ][ #268 ] -\n  fix missing dropdown arrow  [ MH-12919 ][ #262 ] -\n  REST Docs Dependencies  [ MH-12917 ][ #260 ] -\n  Remove debug logging  [ MH-12916 ][ #259 ] -\n  Admin Interface Configuration Defaults  [ MH-12914 ][ #258 ] -\n  Remove deprecated IOUtils.closeQuietly  [ MH-12913 ][ #257 ] -\n  Fix Admin Interface Deprecation Warnings  [ MH-12868 ][ #255 ] -\n  Make frame-by-frame skipping function in the editor use the \"actual\" framerate  [ MH-12908 ][ #251 ] -\n  Fix escaping of spaces  [ MH-12907 ][ #250 ] -\n  Fix segmentation default job load  [ MH-12906 ][ #249 ] -\n  Composoer should ignore system specific output pathes like /dev/null  [ MH-12902 ][ #248 ] -\n  closing videoeditor should continue in events list  [ MH-12901 ][ #247 ] -\n  Fix YouTube publication job loads  [ MH-12900 ][ #246 ] -\n  Fix search service job loads  [ MH-12899 ][ #245 ] -\n  Fix streaming distribution job load defaults  [ MH-12898 ][ #244 ] -\n  Fix download distribution job load defaults  [ MH-12897 ][ #243 ] -\n  Improve visibility of selected segments in the videoeditor  [ MH-12896 ][ #242 ] -\n  Clarify default player configuration  [ MH-12894 ][ #240 ] -\n  Update markdownlint  [ MH-12893 ][ #239 ] -\n  Added ability to configure the job load for the aws s3 distribution service.  [ MH-12892 ][ #238 ] -\n  Added ability to configure the job load for the transcription service.  [ MH-12888 ][ #235 ] -\n  Missing FFmpeg on Travis CI  [ MH-12887 ][ #234 ] -\n  Only set job date completed and runtime once.  [ MH-12883 ][ #230 ] -\n  Maven build of admin-ui module without frontend profile  [ MH-12882 ][ #229 ] -\n  Fix org.w3c.dom.smil version  [ MH-12881 ][ #228 ] -\n  Remove deprecated method  [ MH-12880 ][ #227 ] -\n  Remove redundant OSGI declarations  [ MH-12879 ][ #226 ] -\n  Default location of paella configuration  [ MH-12878 ][ #224 ] -\n  Don't verify NPM cache to speed up build process  [ MH-12874 ][ #223 ] -\n  NotFoundException handling for OAI-PMH retract operation with non published event  [ MH-12872 ][ #222 ] -\n  event can not be deleted  [ MH-12873 ][ #221 ] -\n  Speed up test builds  [ MH-12864 ][ #215 ] -\n  Readonly mode of fields not working correctly in property sheets  [ MH-12807 ][ #213 ] -\n  Do not overwrite owner  [ MH-12863 ][ #212 ] -\n  Fix default owner in SMIL endpoint  [ MH-12862 ][ #211 ] -\n  Line break after required marker in REST docs  [ MH-12834 ][ #207 ] -\n  Central documentation for filtering, sorting and pagination  [ MH-12833 ][ #204 ] -\n  Consistently use External API as name  [ MH-12852 ][ #203 ] -\n  Required fields not indicated in the event details and series details modals  [ MH-12843 ][ #200 ] -\n  Fix \u201cAdd Event\u201d Tab Index  Update main readme\n    Fix tabs and trailing spaces in docs\n    [ MH-12839 ][ #196 ] -\n  fix all pom.xml  [ MH-12837 ][ #194 ] -\n  external series API ACL is required  [ MH-12832 ][ #192 ] -\n  Update to commons-collection4  [ MH-12836 ][ #191 ] -\n  Fix event-comment dependencies not correctly specified  [ MH-12831 ][ #190 ] -\n  Fixing dependencies  NOJIRA fix engage paella url security rules\n    NOJIRA Localization developer guide updated\n    [ MH-12780 ][ #184 ] -\n  Fix sorting jobs by identifier in Systems->Jobs  [ MH-12824 ][ #183 ] -\n  Speed up mvn site  T/clarify wording of user tracking in documentation\n    [ MH-12818 ][ #177 ] -\n  Improve Sox service tests  NOJIRA Crowdin project configuration updated\n    NOJIRA Crowdin documentation updated\n    [ MH-12771 ][ #173 ] -\n  Document fields of External API 1.0.0  [ MH-12795 ][ #163 ] -\n  REST docs don't respect @Produces annotation on class level  [ MH-12788 ][ #157 ] -\n  UTF-8 encoding settings in OAI-PMH publication service remote  [ MH-12616 ][ #152 ] -\n  Admin UI Flexible Asset Upload override or fallback display text  [ MH-12775 ][ #146 ] -\n  Add JavaScript source map generation  [ MH-12768 ][ #142 ] -\n  Minor XACMLAuthorizationService fixes   [ MH-12825 ][ #139 ] -\n  Add markdownlint to Travis CI    [ MH-12760 ][ #160 ] -\n  Cross-link column date in events table to enable the start date filter   [ MH-12789 ][ #158 ] -\n  Remove tabs and trailing spaces in LTI tools  [ MH-12509 ][ #151 ] -\n  Enable HTTP basic auth in default config  [ MH-12759 ][ #149 ] -\n  More Control Over Workflows  [ MH-12779 ][ #147 ] -\n  Support X-Forwarded-Proto header  [ MH-12649 ][ #138 ] -\n  clone workflow operation handler  [ MH-12764 ][ #137 ] -\n  update license information for admin-ui  [ MH-12763 ][ #136 ] -\n  Minor Composer Fixes  [ MH-12762 ][ #135 ] -\n  Fix Spaces In Configuration  Fallback For Synfig Install\n    clean up woh documentation\n    Make Travis check for tabs in pom.xml files\n    Add Mkdocs To Travis Builds\n    [ MH-12757 ][ #128 ] -\n  Fix ClassCastException  [ MH-12755 ][ #127 ] -\n  Fix workflow-workflowoperation dependencies  [ MH-12746 ][ #126 ] -\n  Update Checkstyle  [ MH-12746 ][ #125 ] -\n  Update Apache HTTPComponents  [ MH-12746 ][ #124 ] -\n  Update Mina  [ MH-12746 ][ #123 ] -\n  Remove commons-logging  [ MH-12746 ][ #122 ] -\n  Update Jackson  [ MH-12752 ][ #121 ] -\n  Ignore VSCode project data  [ MH-12751 ][ #120 ] -\n  Add Travis Badge  [ MH-12735 ][ #119 ] -\n  Remove Undocumented Operations  [ MH-12746 ][ #115 ] -\n  Library Update  [ MH-12742 ][ #113 ] -\n  Update to Karaf 4.0.10  [ MH-12744 ][ #111 ] -\n  Fix migration bundle dependencies  [ MH-12739 ][ #109 ] -\n  Transcription Service updated to support Paella  [ MH-12737 ][ #108 ] -\n  OAI-PMH publication service  [ MH-12732 ][ #106 ] -\n  Remove Unused Remote Service Registry  [ MH-12731 ][ #105 ] -\n  Improve Recreating Series Index  [ MH-12730 ][ #104 ] -\n  Workflow Index Rebuild Performance  [ MH-12711 ][ #100 ] -\n  improve xacml parser  [ MH-12726 ][ #99 ] -\n  Add description to theme  [ MH-12704 ][ #98 ] -\n  Captions support for paella  [ MH-12718 ][ #97 ] -\n  Animate Service  [ MH-12713 ][ #95 ] -\n  Series cannot be created  [ MH-12705 ][ #87 ] -\n  Fix scheduler hot-deployment  [ MH-12701 ][ #84 ] -\n  Paella: Localization files + crowdin config file  [ MH-12692 ][ #83 ] -\n  update maven bundle plugin for java8  [ MH-12663 ][ #81 ] -\n  Don't search for non-existing WFR files  [ MH-12694 ][ #80 ] -\n  Save\" button in the editor now stays on the same page.  [ MH-12693 ][ #77 ] -\n  Notes on how to enable, upgrade to HTTPS  [ MH-12675 ][ #76 ] -\n  Send default startdate to backend also if it hasn't been changed.  [ MH-12656 ][ #75 ] -\n  Updates to Theodul Matomo (formerly Piwik) Plugin  [ MH-12684 ][ #69 ] -\n  Make License List Provider More Flexible  [ MH-12683 ][ #68 ] -\n  Improve Video Editor Tests  [ MH-12681 ][ #66 ] -\n  update media package series catalogs on event metadata update  [ MH-12677 ][ #65 ] -\n  Be less technical about displaying the version number  [ MH-12674 ][ #63 ] -\n  Remove unused hard-coded list providers  [ MH-12665 ][ #62 ] -\n  Sort table on startup  [ MH-12649 ][ #59 ] -\n  clone workflow operation handler  [ MH-12668 ][ #58 ] -\n  Update packages of admin ui build pipeline  Use $timeout instead of $interval to resolve MH-12667\n    [ MH-12661 ][ #52 ] -\n  Update angular-translate to 2.17.0  [ MH-12660 ][ #51 ] -\n  Scheduling Events by Specifying End Time  [ MH-12658 ][ #50 ] -\n  Disable Jasmine for Theodul  [ MH-12653 ][ #46 ] -\n  Authorization service should use workspace#read() wherever possible  [ MH-12600 ][ #45 ] -\n  Move userdirectory stuff from bundle  kernel  to  userdirectory  [ MH-12648 ][ #42 ] -\n  As a system administrator, I want to use different encoding \u2026  [ MH-12645 ][ #39 ] -\n  Created an option to rebuild index for an specific service  [ MH-12644 ][ #37 ] -\n  External API index schema fixes  [ MH-12538 ][ #36 ] -\n  Remove obsolete ACL distribution service and WOH distribute-acl  [ MH-12639 ][ #35 ] -\n  update angular-chosen to 1.8.0  [ MH-11984 ][ #32 ] -\n  Allow customization of the username-to-user-role mapping  [ MH-12367 ][ #30 ] -\n  Renaming all database tables  [ MH-12633 ][ #29 ] -\n  Fix version of maven-dependency-plugin  [ MH-12544 ][ #26 ] -\n  Play Deleted Segments in Video Editor  [ MH-12575 ][ #25 ] -\n  Upgrade to AngularJS 1.5.11  [ MH-12595 ][ #24 ] -\n  Improve Publications Usability  [ MH-12613 ][ #23 ] -\n  New WorkflowOperationHandler 'create-event'  [ MH-12628 ][ #20 ] -\n  MH-12629, MH-12630, Minor database fixes  [ MH-10560 ][ #19 ] -\n  Live Scheduler Service  [ MH-12615 ][ #17 ] -\n  Improve the languages drop-down menu  [ MH-12623 ][ #16 ] -\n  Improve workflow dropdown menu  [ MH-12621 ][ #15 ] -\n  submit paella player  [ MH-12624 ][ #11 ] -\n  Fix link to Karaf remote debugging documentation  Update debs.md\n    [ MH-12472 ][ #8 ] -\n  FFmpeg Composer Implementation  [ MH-12502 ][ #7 ] -\n  Do Not Leave Files In Workspace  [ MH-12477 ][ #6 ] -\n  Operation To Log Workflow State  [ MH-12555 ][ #5 ] -\n  Add support for Piwik Media Analytics  [ MH-10016 ][ #4 ] -\n  Default Workflow  [ MH-12603 ][ #2 ] -\n  Consistent Workflow IDs  [ MH-12622 ][ #1 ] -\n  Surefire Versions Should Not Diverge",
            "title": "Opencast 5.0"
        },
        {
            "location": "/changelog/#opencast-4",
            "text": "",
            "title": "Opencast 4"
        },
        {
            "location": "/changelog/#opencast-44",
            "text": "Released on May 31, 2018   [MH-12923]  - ServiceRegistry does not close db connction  [MH-12841]  - Opencast is ignoring permissions  [MH-12840]  - LTI user provider may allow LMS admins to become Opencast admins",
            "title": "Opencast 4.4"
        },
        {
            "location": "/changelog/#opencast-43",
            "text": "Released on March 28, 2018   [MH-12774]  - Fix differences in provided security configurations  [MH-12773]  - Fix that non-admins cannot add new assets  [MH-12772]  - Fix acces to assets for non-admins  [MH-12789]  - Remove tabs and trailing spaces in LTI tools  [MH-12790]  - Make LTI respect player configuration",
            "title": "Opencast 4.3"
        },
        {
            "location": "/changelog/#opencast-42",
            "text": "Released on March 14, 2018   [MH-12766]  - Metadata view and edit roles where at some places set\n  incorrectly  [MH-12765]  - Navigating through series in the series details modal causes\n  failing attempts to save ACLs  [MH-12758]  - Changing the ACLs does not trigger AssetManagerDecorators  [MH-12747]  - Heartbeat is broken  [MH-12745]  - Fix heartbeat config logging  [MH-12743]  - OAIPMH-Republish-Operation tries to republish to ASW3  [MH-12728]  - Add LAST-MODIFIED to ical event properties  [MH-12727]  - OptimisticLockException on worker node can cause jobs to be\n  stuck in DISPATCHING state  [MH-12725]  - Series/Events ACL update causes scheduled recordings in the\n  series/the events to disappear from CA calendar  [MH-12717]  - Series metadata update causes scheduled recordings in the\n  series to disappear from CA calendar  [MH-12711]  - XACML Parser should be more robust  [MH-12707]  - Fix problem with non-strict mode in URL-Signing  [MH-12706]  - Old zombie workflows cannot be stopped, suspended etc.  [MH-12668]  - Update admin ui build pipeline  [MH-12651]  - Scheduling repeating events through Admin UI is very slow",
            "title": "Opencast 4.2"
        },
        {
            "location": "/changelog/#opencast-41",
            "text": "Released on Februar 7, 2018   [MH-12695]  - Improve Synchronization in WorkflowService  [MH-12689]  - Flickering filter: When loading the page, all filters\n  briefly appear and disappear again  [MH-12687]  - Date filters not working  [MH-12685]  - Performance issue in filters  [MH-12682]  - TimelinePreview Concurrency Problem  [MH-12676]  - List provider service implementation is not thread-safe  [MH-12673]  - Content-Type is not set for JavaScript files  [MH-12664]  - Ensure series can be deleted  [MH-12662]  - Special characters in modal window titles are double-escaped  [MH-12657]  - Users of non-admin groups cannot create events  [MH-12652]  - Scheduler service needs to restrict queries to episodes\n  owned by it  [MH-12641]  - Asset manager conflict checks are very slow  [MH-12638]  - Migration bundle needs to have a higher runlevel  [MH-12637]  - Remove event id from episode DC catalog during migration  [MH-12632]  - Make index rebuild robust  [MH-12631]  - Drop the ORGANIZER field from the ical feed  [MH-12627]  - Start Task copies files into workspace  [MH-12620]  - Document ActiveMQ memory requirements  [MH-12610]  - Navigating through events in the event details modal causes\n  failing attempts to save ACLs  [MH-12609]  - As a user, I expect scheduling of events to be working  [MH-12606]  - Using \"Start Task\" with a workflow containing an embedded\n  script in the configuration which somehow modifies the input parameters does not update those values properly  [MH-12602]  - External API gives 500 error for migrated series that do not\n  have creator field  [MH-12601]  - Fast Workflow Does Not Attach Series Metadata  [MH-12582]  - Editor WOH should not encode videos unless it is strictly\n  necessary (to save time and resources)  [MH-12495]  - Job dispatching with loads needs optimization  [MH-12476]  - Delay start of job dispatching on startup  [MH-10016]  - Cannot Change Default Workflow",
            "title": "Opencast 4.1"
        },
        {
            "location": "/changelog/#opencast-40",
            "text": "Released on December 8, 2017   [MH-12597]  - When reindexing, some events may incorrectly be displayed as\n  \"Scheduled\" instead of \"Processed\" or \"Failed\"  [MH-12596]  - Video Editor Ignores Workspace  [MH-12594]  - Description field in metadata editor doesn't handle newlines\n  properly  [MH-12591]  - AssetManager reindex produces \"No organization found!\"\n  warnings  [MH-12590]  - Fix Workflow WOH Workspace Mock  [MH-12589]  - Fix Timelinepreview Dependencies  [MH-12588]  - Stream Security Leaks Secrets  [MH-12587]  - ActiveMQ config ships with 3rd party tool enabled by default  [MH-12583]  - Reduce frequency of index rebuild messages for comments and\n  asset manager  [MH-12579]  - Simplify XACML Handling  [MH-12578]  - Color of Crosslinks Makes Tables Look Noisy  [MH-12574]  - Audio keeps playing when leaving the playback or editor page  [MH-12573]  - Unprivileged users cannot delete events  [MH-12572]  - Dependency Fixes  [MH-12570]  - Admin UI Regressions And Minor Bugs  [MH-12569]  - Don't fail hard if attempting to distribute a non-track\n  media package element to streaming server  [MH-12568]  - EditableSingleValue Has Focus Issues  [MH-12567]  - Index Service Dependencies  [MH-12566]  - Remove Unused Participation List Provider  [MH-12560]  - Streaming media distribution does not work in a distributed\n  cluster  [MH-12559]  - CSS: Delete And Retract Dialogs For Events Are Messed up  [MH-12558]  - CSS: Buttons in Confirm Modals Too Big  [MH-12557]  - CSS: Checkbox Alignment in Tables  [MH-12556]  - Video Editor CSS Enhancements  [MH-12554]  - Downloading translations from Crowdin doesn't work anymore  [MH-12553]  - As an administrator, I want to configure the order in which\n  the different adaptive streaming video qualities are listed  [MH-12552]  - The \"delete\" button in the Admin UI may leave the \"preview\"\n  artifacts undeleted  [MH-12551]  - Redo changes of MH-11660 that got lost in means of a\n  regression  [MH-12550]  - hasActiveTransaction is triggered permantly for edited jobs  [MH-12548]  - Matterhorn Kernel Test Issues  [MH-12547]  - Group related settings in custom.properties  [MH-12546]  - 3.x to 4.0 upgrade is ugly  [MH-12545]  - Multi Value Editable Loses Value on Blur  [MH-12543]  - Adjust Log Level During Build Time  [MH-12542]  - Fix Ingest Service API Dependencies  [MH-12541]  - Events not searchable after migration if event was subject\n  to a workflow with two publish-engage operations  [MH-12540]  - Add documentation for WOH failing  [MH-12539]  - Add documentation for WOH include  [MH-12537]  - Admin UI Asset upload: Order Assets as listed in properties\n  file (vs alphabetical)  [MH-12535]  - Add language support for Hebrew  [MH-12534]  - Broken Labels In Default Workflow  [MH-12532]  - The bundle  workflow-workflowoperation  creates (and leaves)\n  temporary files in  /tmp  [MH-12529]  - External API returns negative Event duration  [MH-12526]  - External (LDAP) users cannot not see their own role\n  (ROLE_USER_XXXX) in the access policy of the events they create.  [MH-12525]  - Non-admin users cannot modify ACLs in their own events  [MH-12523]  - \"Submit\" button in retract modal is always disabled  [MH-12522]  - Improve Waveform Service Dependency Specification  [MH-12520]  - Duplicate Series When Double Clicking Create Button  [MH-12519]  - Improve Admin-NG Dependency Specification  [MH-12518]  - Ugly exception appears in stdout/Karaf console  [MH-12517]  - Some job data is not copied correctly  [MH-12514]  - Opencast Allows Multiple Simultaneous Workflows For Same\n  Media Package  [MH-12513]  - MigrationService fails  [MH-12512]  - Frontend-Maven-Plugin configuration is missing the mandatory\n  \"versionRange\" parameter  [MH-12511]  - Deleting an event with inconsistent search index state\n  doesn't work  [MH-12510]  - System doesn't recover from ActiveMQ downtime  [MH-12507]  - Textanalyzer Has Nondeclared Dependencies  [MH-12503]  - Log statements do not require Object or String arrays to\n  provide 3 parameters or more  [MH-12500]  - Fix incorrect usage of method \"URL#getFile()\"  [MH-12499]  - Admin UI event tools dialog can't be closed with the close\n  button  [MH-12498]  - External API: Cannot get series if description field is\n  empty  [MH-12497]  - Improve usability of admin UI forms  [MH-12492]  - AssetManager endpoint return server error on assets, which\n  the user not allowed to read  [MH-12489]  - Failed test: MySQL DDL Scripts (Update) \ufffc  [MH-12488]  - Publish worklow always fail  [MH-12480]  - Waveform Operation Should Have Tests  [MH-12479]  - Waveform Operation Should Not leave Files In Workspace  [MH-12475]  - Make mimetypes consistent  [MH-12470]  - Prematurely deleted scheduler properties lead to undeletable\n  events  [MH-12469]  - Auto Update OAIPMH republishes deleted Events  [MH-12467]  - Scheduled event fails due to not finding a workflow\n  definition to use  [MH-12465]  - Propagate Changes of Series Extended Metadata to Events and\n  OAI-PMH  [MH-12463]  - Hyphens in event/series search return no results  [MH-12456]  - Clean Up PathSupport  [MH-12455]  - FFmpeg does not terminate when Opencast is shut down  [MH-12454]  - PathSupport.changeFileExtension does not properly handle\n  files with no extension  [MH-12453]  - TimelinePreview Path Handling  [MH-12451]  - Lock file utility method should throw exceptions  [MH-12450]  - Clean up *EncoderEngine code  [MH-12449]  - Ensure temporary files are deleted on composer failure  [MH-12448]  - Remove unconfigured send-mail WOH  [MH-12447]  - OAI-PMH autorepublish fails if series was deleted  [MH-12446]  - Do not leave ZIP files in workspace when a Workflow fails  [MH-12445]  - underlying code showing on metadata source tab when creating\n  event  [MH-12443]  - editing event changes status from scheduled to finished  [MH-12442]  - Maven site is broken  [MH-12436]  - Add Christian Greweling to Comitters list  [MH-12431]  - Update Crowdin translations for r/4.x  [MH-12428]  - Performance Issue In Event Metadata  [MH-12427]  - Submit button in Editor typo  [MH-12423]  - Date Parse Error When Changing Certain Metadata  [MH-12420]  - Update frontend-maven-plugin  [MH-12417]  - Poor performace on scheduler /recordings/calendars  [MH-12411]  - Database user requires additional permissions  [MH-12409]  - Conductor logs ClassCastException when receiving\n  DeleteSnapshot  [MH-12407]  - \"The task could not be created\" message by starting task on\n  multiple events  [MH-12406]  - Splitting in the video editor while a video is playing\n  causes time jump  [MH-12401]  - Video editor segment times stay blank (timing)  [MH-12399]  - Oaipmh Retract very slow  [MH-12396]  - Cannot select filter two times in a row from dropdown  [MH-12395]  - REST: Handle Scheduling Conflict  [MH-12394]  - Video editor allows the submission of an event with no\n  active segments  [MH-12390]  - Gracefully handle unregistration of non-existing host  [MH-12385]  - Ingest Code Cleanup  [MH-12382]  - As a system administrator, I want to see the capture agent\n  configuration in the user interface, so that I don't need to look into the database directly  [MH-12380]  - External API v1.0.0 Broken Due To StartDate Format Change  [MH-12372]  - Make waveform service more flexible by allowing pre- and\n  post-filters to be configured  [MH-12366]  - authorization-manager depends on download-impl  [MH-12365]  - Losing ActiveMQ connection spams the logs  [MH-12356]  - As an administrator, I'd like to resolve or delete comments\n  in workflows by comment reason only  [MH-12355]  - Include Wowza Adaptive Streaming Module in Opencast  [MH-12354]  - Admin UI Video Editor wont let you edit segements at the end  [MH-12352]  - Include support for user Groups in LDAP  [MH-12350]  - Recreate adminui-Index stops, if Asset of Event ist missing  [MH-12349]  - Exception handler should not throw an IO exception on\n  deleting temporary directory  [MH-12348]  - As an administrator, I want to use the \"send-email\" WOH with\n  multiple recipients and also use the CC and BCC fields  [MH-12346]  - Publications are not shown in the admin interface  [MH-12330]  - The series WOH only updates the series' title and ID on the\n  episode's catalog, but sometimes more fields should be updated  [MH-12328]  - Update AngularJS from 1.3.x to 1.4.x  [MH-12325]  - Maven warning when building r/3.x  [MH-12314]  - As a developer, I expect the Admin UI tests being skipped if\n  I build Opencast using -DskipTests  [MH-12312]  - Event Counter For \"Today\"  [MH-12309]  - Use Matching FontAwesome Icons  [MH-12304]  - Configurable Notification Durations  [MH-12302]  - Do Not Warn About Default Configuration  [MH-12289]  - Publish extended metadata to OAI-PMH  [MH-12287]  - prevent reload of Admin UI when opening the editor  [MH-12286]  - As an Opencast admin, I want to set workflow properties from\n  an external script  [MH-12284]  - Unprivileged users cannot upload any files when creating or\n  editing a theme  [MH-12283]  - Support MPEG DASH in Player  [MH-12278]  - NullPointerException in CleanupWorkflowOperationHandler  [MH-12274]  - Ingest service REST endpoint should be verbosable and expect\n  input UTF-8 encoded  [MH-12266]  - As a user, I expect metadata changes to be propagated to\n  third-party applications  [MH-12259]  - Ingest-download WOH fail on downloading publication elements  [MH-12258]  - Update angular-translate to version 2.15.2  [MH-12250]  - Synchronize Dublin Core date created and start date in DC\n  temporal  [MH-12242]  - Theodul: Quality selector does not display/load  [MH-12234]  - Cleanup WOH does not remove all files as it should do  [MH-12227]  - As a user, I don't want to be informed about services not\n  being working correctly  [MH-12223]  - Oaipmh Publish is very slow  [MH-12200]  - Improve LDAP integration after the changes brought by\n  MH-12016  [MH-12196]  - Use a date and time picker instead of separate inputs for\n  date and time in admin UI  [MH-12191]  - Add support for automated captions/transcripts (IBM Watson)  [MH-12168]  - As a user, I need cross-page links that help me to work more\n  efficiently  [MH-12166]  - As a user, I'm not willing to perform that many clicks to\n  actually use the filters  [MH-12111]  - Require Java 8  [MH-12104]  - As a producer, I want to access assets of my tenant while a\n  workflow is running  [MH-12099]  - Wrong started date/time on workflow details view  [MH-12082]  - Contribute Asset Manager/Scheduler work (ETH)  [MH-12052]  - As an Administrator, I'd like to know that ActiveMQ is\n  running properly  [MH-12000]  - Cross-tenant URL signing  [MH-11703]  - Service error states not immediately visible in admin UI  [MH-11458]  - Update translations from crowdin  [MH-11274]  - Workflow Operations of Scheduled Event are not editable  [MH-11195]  - Ability to Search on part of a Series Identifier, instead of\n  just exact match  [MH-11042]  - Admin UI NG tests fail in +5:30 timezone  [MH-10156]  - Misspelling in LtiLaunchAuthenticationHandler.java",
            "title": "Opencast 4.0"
        },
        {
            "location": "/changelog/#opencast-3x",
            "text": "",
            "title": "Opencast 3.x"
        },
        {
            "location": "/changelog/#opencast-37",
            "text": "Released on Oct 16, 2018   [ MH-12982 ] - 3.0 database upgrade error  [ MH-13022 ] - Fix LTI highly trusted keys being discarded  [ MH-13034 ] - Add lis_person_sourcedid back as LTI source field for the\n  username  [ MH-13082 ] - Fix LTI security vulnerability and refactor LTI and OAuth\n  classes  [ MH-13152 ] - Reduce Workflow Messages, backport of Lars fix for >=r/5.x  [ MH-13156 ] - Set the auth scheme to digest for inter-server\n  communication",
            "title": "Opencast 3.7"
        },
        {
            "location": "/changelog/#opencast-36",
            "text": "Released on May 31, 2018   [MH-12910]  - When switching between branches with different module\n  naming schemes, the git tree is left unclean sometimes  [MH-12860]  - Opencast does not build at DEBUG logging level  [MH-12841]  - Opencast is ignoring permissions  [MH-12840]  - LTI user provider may allow LMS admins to become Opencast\n  admins  [MH-12830]  - Fix mvn site generation  [MH-12743]  - OAIPMH-Republish-Operation tries to republish to ASW3  [MH-12441]  - Fix multi-server configuration docs and config details  [MH-12091]  - Create a Capture Agent digest user with its own role",
            "title": "Opencast 3.6"
        },
        {
            "location": "/changelog/#opencast-35",
            "text": "Released on February 6, 2018   [MH-12620]  - Document ActiveMQ memory requirements  [MH-12606]  - Using \"Start Task\" with a workflow containing an embedded\n  script in the configuration which somehow modifies the input parameters does not update those values properly  [MH-12582]  - Editor WOH should not encode videos unless it is strictly\n  necessary (to save time and resources)  [MH-12495]  - Job dispatching with loads needs optimization  [MH-12487]  - Add job load settings to the default encoding profles  [MH-12399]  - Oaipmh Retract very slow",
            "title": "Opencast 3.5"
        },
        {
            "location": "/changelog/#opencast-34",
            "text": "Released on December 4, 2017   [MH-12588]  - Stream Security Leaks Secrets  [MH-12587]  - ActiveMQ config ships with 3rd party tool enabled by default  [MH-12532]  - The bundle  workflow-workflowoperation  creates (and leaves)\n  temporary files in /tmp  [MH-12516]  - Oversize job acceptance logic is incorrect  [MH-12505]  - composer operations need to set job load from profile load\n  when creating jobs  [MH-12501]  - Incorrect logging in inbox scanner  [MH-12496]  - Feeds point to removed embed player  [MH-12494]  - JMX bean unregistration causing stack traces in unit tests  [MH-12478]  - Waveform filenames are not unique  [MH-12471]  - Workspace Cleaner Minor Fix  [MH-12464]  - Job dispatching can be slowed down excessively by host loads\n  query  [MH-12439]  - WorkspaceCleaner Should Clean All Files  [MH-12437]  - Admin UI ng fails mvn clean install if the node_modules\n  exists  [MH-12435]  - Race condition when workspace file deletion removes\n  collection  [MH-12430]  - Update Crowdin translations for r/3.x  [MH-12422]  - Adjust documentation to new Crowdin Opencast project  [MH-12421]  - Job dispatching halts because of http connection hang  [MH-12415]  - Improve performance of /api/events?withpublications=true  [MH-12363]  - org.json.simple.parser.JSONParser is not thread safe  [MH-12000]  - Cross-tenant URL signing  [MH-11361]  - date in engage is the creation date, not the recording date  [MH-11042]  - Admin UI NG tests fail in +5:30 timezone",
            "title": "Opencast 3.4"
        },
        {
            "location": "/changelog/#opencast-33",
            "text": "Released on September 21, 2017   [MH-12383]  - Upgrade/Unify Library Versions  [MH-12413]  - Don't present the user a previous/next item button if there\n  is no previous/next item  [MH-12405]  - Catastrophic Oveload in Calendar generation  [MH-12400]  - Player: Embed Links disabled  [MH-12393]  - Retract workflow fails if run when a video is being played\n  (with nfs storage)  [MH-12389]  - Set operation to failed when setting workflow to failed on\n  exception path  [MH-12386]  - Update Postgresql Connector  [MH-12384]  - Catch possible NPE in FileSupport.delete()  [MH-12366]  - authorization-manager depends on download-impl  [MH-12365]  - Losing ActiveMQ connection spams the logs  [MH-12364]  - /broker/status endpoint returns incorrect 204 when ActiveMQ\n  is shut down  [MH-12362]  - Less verbose logging for ExportWorkflowPropertiesWOH  [MH-12360]  - Race condition in workspace collection add and delete  [MH-12359]  - Milliseconds trim bug in videoeditor-workflowoperation\n  formatTime() javaScript  [MH-12358]  - Only 6 series were displayed on the distribution node  [MH-12353]  - Theodul player does not load reliably after restart  [MH-12350]  - Recreate adminui-Index stops, if Asset of Event ist missing  [MH-12329]  - File copy can fail with jetty timeout  [MH-12326]  - Reduce log level for IllegalStateException in\n  StaticResourceServlet  [MH-12317]  - AdminUI create every 5 seconds stats request and may crash\n  on heavy server load  [MH-12303]  - Sort the REST endpoints alphabetically  [MH-12131]  - Migrate documentation of capture agent communication\n  protocol to markdown  [MH-12085]  - Make file upload in Admin UI more flexible  [MH-11768]  - Timeline preview images",
            "title": "Opencast 3.3"
        },
        {
            "location": "/changelog/#opencast-32",
            "text": "Released on August 16, 2017   [MH-12347]  - Opencast generates invalid XML catalogs when a \"default\"\n  (empty) Namespace is used.  [MH-12345]  - Ingest fails because /recordings/{id}/acls returns 500 if\n  event has not ACLs  [MH-12342]  - A \"Scanner\" instance in the ExecuteServiceImpl class is not\n  properly closed: possible resource leak  [MH-12333]  - Feed generator separates lists of tags incorrectly  [MH-12327]  - CAS Authentication is not working  [MH-12324]  - Reduce frequency of index update messages for rebuilds  [MH-12318]  - Remove Webconsole Default Installation  [MH-12316]  - IllegalStateException: Committed  [MH-12315]  - Database Query of Users from UserlistProvider is very slow  [MH-12311]  - Update Admin UI build tools  [MH-12307]  - OAI-PMH REST endpoint docs fix  [MH-12305]  - Admin UI should stop polling event stats if the event tab\n  isn't shown  [MH-12288]  - Set default max idle time if not configured and log key pool\n  parameters  [MH-12280]  - Create an Opencast group for Sakai instructors  [MH-12278]  - NullPointerException in CleanupWorkflowOperationHandler  [MH-12275]  - MH-12261 / Avoid race condition between index and cleanup\n  operations  [MH-12271]  - MH-12261 / Update WFR put action to update files atomically  [MH-12270]  - Don't swallow unknown SMIL exceptions  [MH-12263]  - MH-12261 / FileSupport > link - copy file action should use\n  overwrite argument (Throws FileFileAlreadyExists)  [MH-12261]  - Race condition leads to FileAlreadyExistsException and\n  FileNotFoundException  [MH-12079]  - Misleading logging in some indexing message receivers  [MH-12007]  - Revive the Execute Service  [MH-11542]  - Failed test: Process video after cutting (Safari)  [MH-10650]  - Intermittent failure to detect hard links when starting a\n  cluster  [MH-10523]  - Misleading exception parameter in getFileFromCollection",
            "title": "Opencast 3.2"
        },
        {
            "location": "/changelog/#opencast-31",
            "text": "Released on July 14, 2017   [MH-12296]  - getSeries Performance Issue  [MH-12295]  - Update Karaf to 4.0.9  [MH-12291]  - Remove obsolete Speech Recognition API  [MH-12279]  - As a user, I expect the video editor to correctly visualize\n  the audio track  [MH-12253]  - Example workflows are inconsistent in Formatting and\n  Configuration of Publication Options  [MH-12215]  - Extended metadata should be applied on event create wizard  [MH-12157]  - Series index query performs bad on system with many series  [MH-11742]  - Document criteria for inclusion and exclusion of\n  translations",
            "title": "Opencast 3.1"
        },
        {
            "location": "/changelog/#opencast-30",
            "text": "Released on June 13, 2017   [MH-12257]  - HttpsFilter is not called before\n  OAuthProviderProcessingFilter  [MH-12255]  - OC cannot add PyCA capture agent when server ending with /  [MH-12252]  - LTI default launch goes to the wrong URL for sample tool  [MH-12249]  - Media Module: Paging forgets search parameters  [MH-12248]  - Capture Calendar Modification Caching Implementation is very\n  Inefficient  [MH-12247]  - Archive Synchronization fix doesn't working in >=2.3  [MH-12235]  - WOH partial-import: No track matching smil Track-id  [MH-12230]  - Notifications appear again although the user has closed them  [MH-12228]  - player controls: use dropup instead of a dropdown if\n  controls are below the video  [MH-12226]  - Add documentation about configuration of publication channel\n  names and icons  [MH-12222]  - As a user, I don't want an empty tab be presented to me\n  since I don't necessarily understand, what that means  [MH-12221]  - As a user, I expect meaningful placeholder texts in the\n  filter selection components  [MH-12213]  - Internal distribution fails if download url is not default  [MH-12211]  - As a service provider, I need to be able to deal with\n  multiple users that have the same name  [MH-12207]  - Incorrect comment identifiers in some workflows  [MH-12205]  - Update version of javax.ws.rs - jsr311-api  [MH-12204]  - Rearrange the config  [MH-12202]  - ProxyMiddleware does ignore host port  [MH-12199]  - 3.x release notes mention \"comprehensive\" LDAP support,\n  which is not (yet) true  [MH-12198]  - Remove outdated file location in LDAP documentation  [MH-12197]  - IllegalStateException: Response is committed  [MH-12195]  - Unprivileged users cannot view media package element details\n  on Recordings->Events->\"Event Details\"->Assets->Media  [MH-12193]  - OAI-PMH distribution fails on adaptive streaming artifacts  [MH-12189]  - Sakai userdirectory provider is not properly bundled  [MH-12183]  - Theodul does not load  [MH-12181]  - As a course admin, I want to allow roles in the UI for ACLs\n  that match a pattern  [MH-12180]  - Cannot specify ValuefFor probe-resolution woh  [MH-12174]  - The Admin UI temporarily displays wrong table content\n  because data is not cleared upon page navigation  [MH-12173]  - The Admin UI temporarily displays wrong table content\n  because data requests are not cancelled  [MH-12170]  - Safari does not display metadata once entered  [MH-12169]  - As a user, I expect search strings to match non-word\n  boundaries in searchable dropdown lists  [MH-12167]  - As a user, I need to be able to search for values offered by\n  the filters, so that I actually find the value I am looking for  [MH-12156]  - Fix version of matterhorn-engage-theodul-plugin-custom-piwik  [MH-12153]  - Reduce Database Space usage  [MH-12149]  - Upgrade Elastic Search to 1.7.6  [MH-12148]  - Undocumented Archive WOH Requirements  [MH-12147]  - TOC links in REST docs overlap  [MH-12142]  - As a system administrator, I would like a documented hint\n  that the user running Opencast needs RW access to the optional storage directory  [MH-12141]  - As service provider, I want to restrict access granted to\n  tenant administrators  [MH-12138]  - Added release notes  [MH-12137]  - AWS S3 tries to distribute attachments from OAI-PMH\n  distribution  [MH-12133]  - OAI-PMH Tests Fails Regularly  [MH-12130]  - Filters set by selecting a category in the dashboard are not\n  shown  [MH-12128]  - REST docs are too eager to check for a valid value  [MH-12126]  - Fast workflow needs AWS distribution to default to false.  [MH-12124]  - Cutting a video multiple times results in multiple\n  smil/cutting catalogs  [MH-12121]  - Update grunt-ng-annotate to 3.0.0 and grunt-contrib-uglify\n  to 2.2.0  [MH-12120]  - pub service oaipmh wants distribution api  [MH-12117]  - As an adopter I would like to get collect data with Piwik  [MH-12115]  - Republish Metadata to OAI-PMH fails  [MH-12113]  - Update outdated comment about the \"lifecycle-mapping\" plugin\n  in the main pom.xml  [MH-12112]  - Update Node Version  [MH-12110]  - frontend-maven-plugin is executed on every module  [MH-12109]  - Creating comments does not work anymore  [MH-12108]  - Set Workflow Variables Based On Resolution  [MH-12104]  - As a producer, I want to access assets of my tenant while a\n  workflow is running  [MH-12103]  - As a producer, I want to be able to execute WOH\n  partial-import on archived sources  [MH-12102]  - Add Workflow Variables Based On Media Properties  [MH-12084]  - The class \"AsyncTimeoutRedirectFilter\" swallows almost all\n  the exceptions  [MH-12074]  - Remove workflow MissedCaptureScanner and MissedIngestScanner  [MH-12073]  - Typo in rest_docs entry box  [MH-12070]  - Order the event counters to reflect the event lifecycle  [MH-12067]  - Initial REST Docs Search  [MH-12066]  - Missing feature.xml Installation  [MH-12065]  - Fix bundle info REST endpoint description  [MH-12064]  - Handle missing meta.abstract gracefully  [MH-12060]  - Simplify Default WOH  [MH-12056]  - As an Administrator, I'd like to add some custom roles for\n  managing access  [MH-12055]  - Update REST Documentation Template  [MH-12054]  - Incorrect or misleading documentation about WOH conditional\n  execution  [MH-12049]  - Update REST Documentation Overview  [MH-12043]  - Allow more then one additional authentication algorithms\n  beside digest  [MH-12038]  - Fallback decoding for mediapackage date values in unixtime\n  rather than W3CDTF  [MH-12037]  - NullPoiinterException when starting embedded Solr  [MH-12035]  - Setting Default Download Directory  [MH-12034]  - Make the UserAndRoleDirectoryService cache configurable  [MH-12033]  - Add indicator lights for capture agent status  [MH-12032]  - Add an authenticated ACL template  [MH-12031]  - Add additional docs for inspection WOH  [MH-12029]  - As a user, I want to use my existing AAI login for Opencast,\n  too  [MH-12023]  - Make development builds faster  [MH-12022]  - /ingest/addTrackURL broken  [MH-12019]  - Ensure Test Files Are Deleted  [MH-12017]  - CoverImage WOH should provide metadata for recording\n  start/end time  [MH-12016]  - Fix and improve user, group, role and provider handling  [MH-12015]  - Typo in External API role name  [MH-12014]  - Incorrect number of roles returned when limit is specified  [MH-12013]  - Contribute OAI-PMH work (ETH)  [MH-12002]  - Date & time format should be customizable in cover images  [MH-11994]  - UserIdRoleProvider should check user existence from user\n  providers  [MH-11993]  - WOH partial-import should support output framerate  [MH-11990]  - Remove configuration file of removed module\n  matterhorn-load-test  [MH-11982]  - As an Opencast administrator, I would like a dashboard\n  counter for active recordings  [MH-11979]  - The video editor does not highlight the selected segment if\n  it is cut  [MH-11978]  - Hotkeys for common tasks in Admin UI  [MH-11977]  - Remove Unused OSGI Bindings From IndexService  [MH-11976]  - Adjust DownloadDistribution Logs  [MH-11975]  - Update some maven plugins  [MH-11971]  - Update maven-surfire-test plugin to latest version  [MH-11969]  - Fullscreen button in embedded view of Theodul player missing\n  after update to 2.2.4  [MH-11967]  - Publish internal fails on Distrubuted System Admin/Engage  [MH-11965]  - Update to Karaf 4.0.8  [MH-11957]  - Make availability check of WOH publish-configure\n  configurable  [MH-11956]  - Allow fine-grained control of accurate frame count  [MH-11954]  - Fixing Javadoc Build  [MH-11952]  - HTML in Translations  [MH-11944]  - MH-11817 use keyboard shortcuts to control the editor  [MH-11916]  - Add convenience workflow instance variable to indicate\n  whether a theme is involved  [MH-11910]  - WOH composite should be able to respect resolution of its\n  input  [MH-11904]  - Missing IDClass Warnings  [MH-11903]  - Cannot Configure Authentication For Webconsole  [MH-11902]  - Update to latest 5.x MySQL connector  [MH-11894]  - Suppress context menu on video element  [MH-11885]  - Add support for search and filtering to\n  Organization->Access Policies  [MH-11881]  - ArchiveRestEndpoint has conflicting endpoints  [MH-11880]  - Multiple issues with LDAP in branch 2.3.x  [MH-11873]  - org.ops4j.pax.web.pax-web-extender-whiteboard causes\n  exception when shutting down  [MH-11868]  - redesign loginpages  [MH-11861]  - MH-11817 Change default view to editor in admin ui tools\n  area  [MH-11849]  - Edit metadata fields by click inside and focus cursor in\n  field  [MH-11822]  - Admin UI Video Editor - Improved Segment Controls  [MH-11821]  - Admin UI Video Editor - Comment and Metadata Editing  [MH-11818]  - Admin UI Video Editor - Improved playback and timeline  [MH-11806]  - Output Frame Rate on Concat Operation  [MH-11797]  - Upgrade Karaf to 4.0.6  [MH-11796]  - Add support for watermarks to themes  [MH-11782]  - MH-11780 Create configure-by-dcterm workflow operation\n  handler  [MH-11781]  - MH-11780 Create tag-by-dcterm workflow operation handler  [MH-11780]  - As a developer I want to be able to manipulate a workflow\n  based on metadata in the Mediapackage  [MH-11766]  - enhance REST Ingest/addTrack Ingest/addCatalog\n  Ingest/AddAttachment to add tags  [MH-11761]  - Captions for player  [MH-11732]  - Make distribution and retraction efficient  [MH-11719]  - When configuring LDAP with default file things are broken  [MH-11717]  - MH-11713 Not possible to add external roles to an ACL\n  through the admin UI  [MH-11715]  - MH-11713 Externally provisioned roles should not be\n  persisted  [MH-11713]  - Users may have roles in Opencast which are granted from an\n  external system (e.g. LMS)  [MH-11684]  - WOH silence does not support tags  [MH-11474]  - Assigning a user to a certain \"ROLE_GROUP_<name>\" role\n  does not really put the user in such group  [MH-11466]  - Improve handling of long strings in cover images  [MH-11379]  - Service to distribute delivery files to AWS S3  [MH-11229]  - workflowoperation unit tests are incredible slow  [MH-11036]  - Adapt Fast Testing Workflow for Admin NG  [MH-10871]  - Sakai User Provider for Opencast-Sakai integration  [MH-10819]  - When creating a new event, metadata field can only be edited\n  by clicking on the pencil icon  [MH-10753]  - Stale database connection causes job failure  [MH-10310]  - Add ERROR state for capture agent",
            "title": "Opencast 3.0"
        },
        {
            "location": "/changelog/#opencast-23x",
            "text": "",
            "title": "Opencast 2.3.x"
        },
        {
            "location": "/changelog/#opencast-235",
            "text": "Released on December 04, 2017   [MH-12588]  - Stream Security Leaks Secrets  [MH-12317]  - AdminUI create every 5 seconds stats request and may crash\n  on heavy server load  [MH-12269]  - Clarify in the documentation the recommendation of setting\n   dispatchinterval  to 0 applies to non-admin nodes only  [MH-12190]  - Script injection in Media Module and Player  [MH-12000]  - Cross-tenant URL signing  [MH-11042]  - Admin UI NG tests fail in +5:30 timezone",
            "title": "Opencast 2.3.5"
        },
        {
            "location": "/changelog/#opencast-234",
            "text": "Released on August 03, 2017   [MH-12183]  - Theodul does not load  [MH-12203]  - Unescaped event and series titles when editing event or\n  series (XSS)  [MH-12242]  - Theodul: Quality selector does not display/load  [MH-12246]  - Series WOH does not apply series DublinCore catalogs  [MH-12249]  - Media Module: Paging forgets search parameters",
            "title": "Opencast 2.3.4"
        },
        {
            "location": "/changelog/#opencast-233",
            "text": "Released on May 02, 2017   [MH-10558]  - Mime type not identified for matroska / mkv files  [MH-10595]  - Incident service returns internal server error if\n  cascade=true requested for deleted workflow  [MH-10747]  - Inputs for capture device should be pre-selected  [MH-11736]  - Difference in start time displayed in overview and metadata\n  details  [MH-11811]  - Opencast build fails when system timezone is set to PDT\n  (Pacific Daylight Time)  [MH-12048]  - Series drop-down not sorted alphabetically in filter  [MH-12069]  - Deleting an event leaves behind orphaned comments  [MH-12095]  - Server default timezone can be incorrect  [MH-12106]  - Preserve user attributes from providers during\n  authentication  [MH-12107]  - Improve performance of Servers table in Admin UI  [MH-12118]  - Paging in media module is broken  [MH-12129]  - Media module only works with english localized browsers  [MH-12130]  - Filters set by selecting a category in the dashboard are not\n  shown  [MH-12148]  - Undocumented Archive WOH Requirements  [MH-12150]  - Matroska files are not recognized  [MH-12158]  - Workflow job dispatching failures  [MH-12162]  - JpaJob object toString override for better log messages  [MH-12163]  - Events with stopped workflows sometimes cannot be deleted  [MH-12164]  - Updating serviceregistry config while running leaves\n  Opencast in a non-functional state  [MH-12190]  - Script injection in Media Module and Player",
            "title": "Opencast 2.3.3"
        },
        {
            "location": "/changelog/#opencast-232",
            "text": "Released on March 22, 2017   [MH-11224]  - Attempting to view source metadata through the new admin UI\n  generates a stack trace  [MH-11340]  - Uncaught NullPointer Exception in Karaf console from\n  com.entwinemedia.fn.data.json.SimpleSerializer.toJson  [MH-11616]  - Search Service will not remove mp from index if it is not\n  found in database  [MH-11743]  - event.hasPreview() broken  [MH-11760]  - Event edit warning cannot be removed  [MH-11790]  - Slide Previews and slide text are not shown in Theodul\n  Engage player  [MH-11817]  - Unhide volume controls in video-editor  [MH-11819]  - Admin UI Video Editor - Improved Zoom Controls  [MH-12009]  - Admin UI Video Editor: Segmentation lost after publishing  [MH-12058]  - Ingests fail if specified workflow does not exist  [MH-12059]  - Catch invalid dates when indexing  [MH-12061]  - Reduce the number of activemq messages and log entries\n  during index rebuild  [MH-12062]  - Improve robustness of scheduler re-indexing  [MH-12063]  - Catch incomplete archive entries when indexing  [MH-12072]  - Wrong destinationId for External API message receiver  [MH-12084]  - The class \"AsyncTimeoutRedirectFilter\" swallows almost all\n  the exceptions  [MH-12087]  - Null bitrate can cause UI display of source media to fail  [MH-12092]  - Return event ID when event is created through Scheduler API  [MH-12097]  - SegmentVideoWorkflowOperation: Modules not included in Admin\n  Presentation build.",
            "title": "Opencast 2.3.2"
        },
        {
            "location": "/changelog/#opencast-231",
            "text": "Released on Janurary 25, 2017   [MH-11267]  - Wrong notification text when deleting series  [MH-11458]  - Update translations from crowdin  [MH-11687]  - UI date formats are wrong for most of the English-speaking\n  world  [MH-11776]  - CaptureAgentStateServiceImplTest incorrectly passes a\n  non-long recording id, misses finding the NullPointer in Impl  [MH-11960]  - matterhorn-adminui-ng fails on first build  [MH-11961]  - Cannot access slidetext.xml should not break re-indexing  [MH-11963]  - Fix ingest REST docs  [MH-11966]  - Confusing AdminUI Groups Endpoint Documentation  [MH-11967]  - Publish internal fails on Distrubuted System Admin/Engage  [MH-11983]  - Only administrators should be allowed to assign the admin\n  roles to other users  [MH-11987]  - Declare Admin UI Facade as module internal interface  [MH-11988]  - Advise to change karaf shutdown command in the docs  [MH-11989]  - Allow unknown as well as offline CAs to be removed via UI  [MH-11992]  - Compatibility issue when using contrib Wowza adaptive\n  streaming module  [MH-11998]  - /info/me.json sometimes doesn't provide full information\n  about the user  [MH-12004]  - Removing an recording does not remove all correspronding\n  jobs  [MH-12005]  - UI shows inconsistent version due to missing version in\n  cover-image-remote  [MH-12006]  - Security Issue Allowing Arbitrary Code Execution",
            "title": "Opencast 2.3.1"
        },
        {
            "location": "/changelog/#opencast-230",
            "text": "Released on December 13, 2016   [MH-10342]  - As an external device I want to immediate start and stop a\n  capture  [MH-11327]  - De-couple smilImpl/wfrImpl from ingestImpl  [MH-11378]  - Conditionally synchronize Archive Service's add mediapackge  [MH-11380]  - As a customer, I want to integrate my third party\n  application to Opencast, so that I can use Opencast content in my application  [MH-11381]  - Remove documentation of items that have never been\n  implemented  [MH-11411]  - move dashboard to header  [MH-11675]  - Add documentation for External API to the Admin Guide  [MH-11688]  - Set java file encoding on startup  [MH-11718]  - As a producer, I want to be able to make workflow settings\n  persistent so that I can reuse them later  [MH-11725]  - Give users a starting point how to report bugs  [MH-11726]  - Add AdminUI style guide to developer guide  [MH-11728]  - Use Apache Commons Lang 3  [MH-11729]  - External API: Add documentation for Groups Endpoint  [MH-11731]  - Typofix Documentation  [MH-11737]  - Comment (mh_event_comment and mh_event_comment_reply)\n  text field is VARCHAR(255) should be TEXT  [MH-11740]  - optimization of segmentation  [MH-11741]  - Admin UI has timezone issues  [MH-11749]  - External API: Add REST documentation for Endpoints  [MH-11750]  - Clean-Up Opencast Code Base  [MH-11752]  - Upgrade Karaf to 3.0.8  [MH-11756]  - Admin UI NG Update CSS+HTML (1): FontAwesome, improve HTML,\n  remove redundant images  [MH-11763]  - Counters hide series tab  [MH-11772]  - Admin UI source dropdowns inappropriately advance  [MH-11774]  - Admin UI Needs better documentation for debugging  [MH-11775]  - Library Update  [MH-11783]  - Custom publications labels not displayed when doing a\n  mouse-over on Events->Published  [MH-11784]  - Remove Participation Management Code Pieces  [MH-11786]  - HttpsRequestWrapper wrongly sets the new URL  [MH-11791]  - As service provider I want to configure which kind of users\n  can see the event counters  [MH-11792]  - NPM Proxy via Nexus  [MH-11794]  - NPM fails on first build  [MH-11795]  - Add support for title slides  [MH-11799]  - Maven bundle names too long  [MH-11800]  - LTI between Opencast and Moodle does not work  [MH-11801]  - Wowza streaming server needs flv: prefix for flv files  [MH-11802]  - Opencast Logo is missing in Player  [MH-11803]  - Player redirect is missing  [MH-11804]  - No video controls in embed mode  [MH-11808]  - Pre-select workflow in case only one option is available  [MH-11809]  - Fix syntax error in encoding profile composite.http  [MH-11812]  - Fix security configuration for ROLE_UI_TASKS_CREATE  [MH-11813]  - Agent state REST endpoint documentation  [MH-11815]  - As a user I expect changes to be reflected in the Admin UI\n  immediately  [MH-11817]  - Admin UI Video Editor - Bug Fixes  [MH-11817]  - Display video details in preview player/ editor of the admin\n  ui  [MH-11817]  - Improve Button Hover Indication  [MH-11817]  - Make Next/Last Frame controls in videoeditor better\n  recognizeable  [MH-11827]  - Recordings->Events->\"Event Details\"->Metadata: Incorrect\n  translation used  [MH-11828]  - exception-handler-workflow not set correctly  [MH-11829]  - High memory usage on the admin server by dispatching jobs  [MH-11831]  - As a service provider, I want to configure whether Opencast\n  creates an admin user automatically  [MH-11834]  - Unable to set capture agent configuration as JSON  [MH-11836]  - Additional ACL actions of series are missing when creating a\n  new event in that series  [MH-11837]  - Unprivileged users have no access to fonts  [MH-11839]  - typo in Event Details: Comments  [MH-11841]  - Wait for NFS shares before start Opencast service  [MH-11842]  - Revert accidental downgrade of grunt version  [MH-11851]  - org.opencastproject.security.admin/pass can't be changed  [MH-11857]  - Fix log output \"Unable to delete non existing object %s/%s\"  [MH-11862]  - Search API handles roles wrong  [MH-11863]  - WOH analyze-tracks & WOH failing cause exceptions when\n  shutting down Opencast  [MH-11864]  - WOH tag shall implement AbstractWorkflowOperationHandler  [MH-11865]  - Videoeditor Preview mixes in 2 Audiofiles  [MH-11866]  - Search box in Organization >> Groups not working  [MH-11867]  - Filter box in Organization >> Groups not working  [MH-11869]  - Deleting Series with 'Actions' is not working  [MH-11870]  - Wordlength in other languages except english too long  [MH-11871]  - ElasticSearch shall bind to 127.0.0.1  [MH-11875]  - ActiveMQ should not listen to all hosts by default  [MH-11880]  - Multiple issues with LDAP in branch 2.3.x  [MH-11883]  - Larger files may remain in system temp directory  [MH-11886]  - login pages throw errors on loading unnecessary scripts  [MH-11888]  - Organization Filter uses Provider where table uses Type  [MH-11889]  - Row size too large  [MH-11890]  - MySQL Connector Version Should Be Consistent  [MH-11891]  - Event counters query large amounts of useless data  [MH-11895]  - \u201cAdd Event\u201d Wizard Input Fields Broken  [MH-11896]  - Java Warnings in AbstractEventEndpoint  [MH-11897]  - Remove Deprecated StringHelper  [MH-11898]  - Fix Technical Duration Calculation  [MH-11899]  - Prevent Requesting Event Objects Multiple Times  [MH-11900]  - Minor Index Service Fixes  [MH-11905]  - Publish Configure WOH incorrectly retracts publications  [MH-11912]  - No slider in playback video player  [MH-11919]  - WOH image claims SUCCEEDED when actually skipping  [MH-11920]  - WOH prepare-av: Misleading log message  [MH-11921]  - WOH partial-import looses partial audio tracks in specific\n  cases  [MH-11950]  - Javadocs build error  [MH-11955]  - Add en-GB to Languages",
            "title": "Opencast 2.3.0"
        },
        {
            "location": "/changelog/#opencast-22x",
            "text": "",
            "title": "Opencast 2.2.x"
        },
        {
            "location": "/changelog/#opencast-225",
            "text": "Released on June 7, 2017   [MH-11983]  - Only admins should be able to modify other admins  [MH-12006]  - Security Issue Allowing Arbitrary Code Execution  [MH-11962]  - Missing slidetext.xml should not break re-indexing",
            "title": "Opencast 2.2.5"
        },
        {
            "location": "/changelog/#opencast-224",
            "text": "Released on October 13, 2016   [MH-11831]  - As a service provider, I want to configure whether Opencast\n  creates an admin user automatically  [MH-11851]  - org.opencastproject.security.admin/pass can't be changed  [MH-11862]  - Search API handles roles wrong  [MH-11875]  - ActiveMQ should not listen to all hosts by default",
            "title": "Opencast 2.2.4"
        },
        {
            "location": "/changelog/#opencast-223",
            "text": "Released on October 13, 2016   [MH-11285]  - Improve developers documentation: remote debugger with karaf  [MH-11741]  - Admin UI has timezone issues  [MH-11771]  - Improve section localization in developer guide  [MH-11773]  - Embed player does not use space very well and has scaling\n  problems  [MH-11774]  - Admin UI Needs better documentation for debugging  [MH-11777]  - Event Details->Comments and Event Details->Assets don't\n  work for unprivileged users  [MH-11787]  - Add release dates to changelog  [MH-11800]  - LTI between Opencast and Moodle does not work  [MH-11801]  - Wowza streaming server needs flv: prefix for flv files",
            "title": "Opencast 2.2.3"
        },
        {
            "location": "/changelog/#opencast-222",
            "text": "Released on September 14, 2016   [MH-11194]  - created themes not showing up in series branding tab  [MH-11572]  - FFmpeg Inspection Service Test - accurateFrameCount  [MH-11587]  - SQL Error  [MH-11714]  - Fix unit test: Event controller #accessSave saves the event\n  access  [MH-11724]  - Additional actions not available in create event wizard\n  anymore  [MH-11734]  - Fix el7 RPM docs  [MH-11735]  - Fix Stream Security Documentation  [MH-11744]  - Actions->Start Task: Various localization bugs  [MH-11748]  - Inconsistent and incorrect use of translate directive  [MH-11751]  - Player won't work if there are no segments  [MH-11755]  - No quality selection in Theodul Player  [MH-11759]  - Make Inspector Unit Tests More Robust",
            "title": "Opencast 2.2.2"
        },
        {
            "location": "/changelog/#opencast-221",
            "text": "Released on July 30, 2016   [MH-11092]  - Every Browser has an other \"Remember me\" checkbox  [MH-11169]  - Trimming points not set correctly after workflow is finished  [MH-11538]  - \"No compatible source was found for this video\" videojs\n  player error in iOS device  [MH-11561]  - Style (CSS): Setting a server in Maintenance (srv-det-01)  [MH-11598]  - Wizards should not re-use data that has entered before  [MH-11644]  - Missing Admin Interface Mock Data  [MH-11653]  - Jobs do not always proceed  [MH-11655]  - Jobs with high job load never get processed  [MH-11659]  - Warning is missing that metada and ACL cannot be edited\n  while job is processing.  [MH-11661]  - Link on logo on the media module points to admin ui or\n  welcome page, instead of something that is accessable for every user  [MH-11664]  - Incorrect Inconsistency status when built from tarball  [MH-11665]  - Systems->Servers & Systems->Services show wrong mean\n  runtime and mean queue time  [MH-11667]  - Align main table content  [MH-11668]  - Missing segment previews let to an erro in the player  [MH-11669]  - Do not archive OCR texts  [MH-11673]  - Add documentation for additional ACL actions  [MH-11674]  - Add documentation for metadata configuration  [MH-11679]  - Page size cannot be changed in any table  [MH-11681]  - Add documentation for role-based visibility  [MH-11682]  - Remove useless roles from roles.txt  [MH-11686]  - Extended metadata tab not shown although user has the role\n  ROLE_UI_EVENTS_DETAILS_METADATA_VIEW  [MH-11690]  - Various Documentation Improvements  [MH-11692]  - Remove Superfluous Mh-Db-Version  [MH-11693]  - Remove Superfluous Dependency Versions  [MH-11694]  - JavaDoc Generation Broken  [MH-11702]  - After an upgrade to 2.2.0, series are not displayed in the\n  UI because the series creation date is now mandatory  [MH-11720]  - Opencast 2.2 requires Git to be installed at build time  [MH-11727]  - Fix unit test: adminNg.services.language #toLocalTime\n  converts a zulu time string back to local time FAILED  [MH-11730]  - Make the automatic role prefix in LDAPUserProvider\n  configurable",
            "title": "Opencast 2.2.1"
        },
        {
            "location": "/changelog/#opencast-220",
            "text": "Released on June 15, 2016   [MH-9511]  - Wrong log level in Tesseract  [MH-9831]  - ehcache and quartz phones home  [MH-9950]  - Update player dependencies  [MH-10029]  - Remove Unnecessary Image Conversion Step From\n  TextAnalysisService  [MH-10173]  - Do not ignore exceptions when closing Closeable's  [MH-10748]  - Matterhorn has to be restarted to schedule an event on a new\n  capture device  [MH-10794]  - Delete Action should be disabled if nothing is selected  [MH-10869]  - ActiveMQ Configuration and Connection Problems  [MH-10870]  - ActiveMQ Exceptions While Shutting Down Matterhorn  [MH-10887]  - Users can schedule events in the past  [MH-10898]  - Update Apache HttpComponents (3.1.7 \u2192 4.4.1)  [MH-10923]  - Theodul player : Filtering \"composite\" tags results in error\n  when the composite workflow is used  [MH-10942]  - Events are not deselected after applying a task  [MH-10965]  - Theodul player : Videos not playable on IE10  [MH-10971]  - Newly created Series don't show up in Series dropdown\n  selection lists without page reload  [MH-10978]  - Unable to retract 'internal' publications  [MH-10979]  - Opencast needs to better distribute load across the\n  available nodes  [MH-10984]  - Extend ingest service by partial upload  [MH-11010]  - Stream Security should be able to prevent cross-tenants\n  access  [MH-11014]  - Add support for additional ACL actions  [MH-11077]  - The Publish Workflow will not retract already published\n  material  [MH-11097]  - View modes not working correctly  [MH-11107]  - Group list pagination not working  [MH-11121]  - MacOS X Installation Guide Needs 2.1 Update  [MH-11124]  - Incorrect documentation on how to create users  [MH-11128]  - Docs about SilenceDetector threashold are incorrect  [MH-11139]  - Unable to find mimetype for mkv  [MH-11140]  - Forward and backward buttons are greyed out  [MH-11143]  - Link to Media Module in Admin UI  [MH-11148]  - Search box layout incorrect: Icon overlaps text  [MH-11156]  - Users: Search box not implemented  [MH-11157]  - Groups: Search box not implemented  [MH-11165]  - Sorting does not work on Systems->Jobs,\n  Systems->Servers and Systems->Services  [MH-11167]  - Layout problem on Workflow Error Details view  [MH-11183]  - Capture->Locations: Search box not implemented  [MH-11190]  - Theodul Shortcuts: Description could be improved  [MH-11191]  - Event Details->Assets: Use human-readable units for\n  duration, bitrates and sizes  [MH-11192]  - Audio level slider does not change audio level while\n  dragging  [MH-11199]  - Playback & video editor don't work while workflow is running  [MH-11209]  - LTI Documentation needs to be incorporated into new docs  [MH-11222]  - Replace System.out.println with logger  [MH-11229]  - workflowoperation unit tests are incredible slow  [MH-11252]  - Some service configuration files are stored in the wrong\n  directory  [MH-11265]  - Ensure configuration files end with newline characters  [MH-11266]  - Logger ConversionPattern stated twice  [MH-11276]  - HttpNotificationWorkflowOperationHandlerTest fails if a\n  certain Domain Exists  [MH-11280]  - Opencast fails to compile due to missing dependencies in\n  test-harness  [MH-11281]  - Enhance WOH image to support extraction of multiple images\n  using multiple encoding profiles from multiple sources  [MH-11282]  - Enhance WOH composite to support single video streams  [MH-11287]  - Update Apereo/Apache License List  [MH-11289]  - Change text extraction documentation or file name  [MH-11294]  - Create admin-worker and ingest distribution  [MH-11296]  - HTTP method POST is not supported by this url in r/2.1.x  [MH-11298]  - Fix json-simple version specification  [MH-11300]  - WOH partial-import looses partial audio tracks beginning at\n  position zero  [MH-11304]  - Documentation for WOH partial-import and load configuration\n  not listed in pages configuration  [MH-11306]  - Change job dispatcher sort order to: restart jobs, non-wf\n  jobs, creation date  [MH-11307]  - Distribution Service is not on Presentation Node  [MH-11310]  - Document encoding profiles used by WOH partial-import  [MH-11311]  - Use existing encoding profiles in WOH partial-import example  [MH-11312]  - Fix Encode WOH Documentation  [MH-11313]  - Update Parallel Encode Profiles  [MH-11319]  - Media Module Always Uses Second Attachment as Preview  [MH-11320]  - Missing Image Preparation for text Extraction  [MH-11321]  - Fix default workflow configuration panel  [MH-11322]  - Update WebM Profiles  [MH-11355]  - Slide texts are not shown correctly in theodul player,\n  except the first segment there a now slide texts shown (\"No slide text available\"). In the XML file the texts are\n  correct  [MH-11356]  - Update Documentation Index Page  [MH-11357]  - Notifications are not removed after a while  [MH-11358]  - Dismiss Button for comments has an inconsistent design  [MH-11363]  - Notification that server is not reachable is missing  [MH-11364]  - Reasons in Comments section are no longer translated  [MH-11368]  - Changing to Chinese translation doesn't work  [MH-11369]  - Series filter displays series id instead of series title  [MH-11374]  - Videoeditor: Times are wrong in zoomed waveform view  [MH-11385]  - Metadata summary not showing any metadata at event creation  [MH-11386]  - Silence Detection / Video Editor Waveform bug  [MH-11389]  - security 1  [MH-11391]  - Improve Flavor creation and parsing  [MH-11392]  - Sorting by series.created does not work correctly  [MH-11401]  - Hiding of columns is globally broken  [MH-11404]  - Group editor shows users and roles twice  [MH-11405]  - Pagination broken for groups table  [MH-11409]  - Translation key\n  EVENTS.EVENTS.GENERAL.SELECT_WORKFLOW_EMPTY is missing  [MH-11413]  - AdminUI comment dialog translations missing  [MH-11414]  - Logger is missing from several modules  [MH-11415]  - Incorrect Urlsigning Module Name  [MH-11416]  - Specify Opencast's Requirements  [MH-11417]  - Tab names of modals not vertically centered  [MH-11419]  - Tables not drawn correctly  [MH-11422]  - add event tab titles not translated  [MH-11427]  - Can't get host details from Serviceregistry REST endpoint  [MH-11428]  - Default Workflow Option Does Not Work  [MH-11430]  - Prevent user from accidentally press \"Save & process\" in\n  Video Editor multiple times  [MH-11431]  - Prevent users from accidentally pressing the Delete/Retract\n  button multiple times  [MH-11432]  - JSHint settings are missing  [MH-11434]  - \"The task could not be created\" error notification always\n  appear when starting a task on multiple events  [MH-11435]  - Fix code style errors in Gruntfile.js  [MH-11436]  - Matterhorn on Login/Welcome Page  [MH-11437]  - Resource Problems On Login Page  [MH-11438]  - Resource Problem on Welcome Page  [MH-11439]  - Event description not available in WOH cover-image  [MH-11441]  - Clicking on Logo in top left corner will nmot get you to the\n  start page  [MH-11443]  - Seeking is not possible before pressing play button at least\n  once?!?  [MH-11446]  - Remove eclipse-gemini repository from main pom.xml  [MH-11447]  - Scheduling conflicts reporting completely broken  [MH-11448]  - Tipps on developing on admin ui ng  [MH-11450]  - Fix Defaults For Documentation Links  [MH-11453]  - Correctly link the stream security documentation  [MH-11457]  - Remove duplicate keys from Admin UI english translation  [MH-11458]  - Update translations from crowdin  [MH-11459]  - Logger Logs Nullpointer on Error  [MH-11462]  - Cover WOH is not included in a useful way  [MH-11464]  - setting personal preferences in admin UI fails  [MH-11468]  - There are unused ressources  [MH-11475]  - Fix typos in English master translation  [MH-11476]  - Series->Actions->Delete displays wrong notifications  [MH-11477]  - Editing status of series displays wrong notification when\n  saving fails for all series  [MH-11480]  - Replace horizontal ellipsis  [MH-11481]  - Workflows started by unprivileged users hang  [MH-11492]  - forward and backward section not working in safari  [MH-11509]  - Failed test: Sorting groups list (grp-lis-01)  [MH-11511]  - Failed test: Manual set time in textbook for IE11  [MH-11512]  - hello world does not follow import statements rules  [MH-11518]  - Language selector is always displayed in system language  [MH-11519]  - Languages are only distinguished by main language  [MH-11520]  - Remove company logos  [MH-11521]  - ActiveMQ Library Configuration  [MH-11522]  - DataLoader Default Value  [MH-11523]  - Working file repository default value  [MH-11524]  - Distribution Service Default Values  [MH-11532]  - Wider language support in player  [MH-11534]  - Add language support for Chinese Simplified  [MH-11535]  - Add documentation about Crowdin to Developer Guide  [MH-11536]  - Remove Commercial Code From Core  [MH-11537]  - Execute Service WOH Cannot be Built  [MH-11539]  - Remove Old MH Logos in Favor of Opencast SVG Logos  [MH-11544]  - Admin UI links used inconsistently  [MH-11546]  - Pagination buttons too small for large numbers  [MH-11548]  - The \"Edit\" button at the top-right corner of the tables\n  doesn't support localization  [MH-11550]  - Update Migration documentation 2.1 to 2.2  [MH-11554]  - Filtering does not work on Systems->Jobs,\n  Systems->Servers and Systems->Services  [MH-11555]  - Localisation of Recordings->Events and\n  Recordings->Series buggy  [MH-11556]  - Failed test: Filter locations (T1733, Filter by status does\n  not work)  [MH-11559]  - outdated shortcurts configuration prevents player from\n  loading.  [MH-11571]  - Elasticsearch shutdown command handler crash opencast  [MH-11573]  - Do not hide warnings  [MH-11574]  - Jetty Error on Large Workflow Instances  [MH-11575]  - Inspection Service Tests Fail With Certain FFmpeg Versions  [MH-11576]  - Servlet Filter Improvements  [MH-11578]  - Improve default order of columns in Systems->Jobs  [MH-11579]  - Admin UI mockup data for Systems->Jobs incomplete  [MH-11580]  - Unit tests for Admin UI language selection broken  [MH-11581]  - Systems->Jobs table not working correctly  [MH-11583]  - Fix Code Style  [MH-11588]  - Create side-by-side preview for video editor  [MH-11589]  - Feedback button does not work  [MH-11590]  - The WorkflowServiceImpl constructor sets the\n  \"waitForResources\" argument incorrectly  [MH-11594]  - Add language support for Galician  [MH-11595]  - Fix admin ui unit tests for tableService  [MH-11597]  - Building matterhorn-engage-theodul-plugin-video-videojs\n  reports a lot of code style issues  [MH-11600]  - Failed test: i18n (gen-int-01)  [MH-11601]  - current language can have undefined state  [MH-11604]  - Date picker for setting up the schedule is always french  [MH-11605]  - Disabling link to mediaplayer creates a broken link and\n  missing logo  [MH-11606]  - Add language support for Greek  [MH-11608]  - Add documentation for WOH cleanup  [MH-11613]  - WOH editor fails when input has uneven width or height  [MH-11614]  - Partial matches not working anymore  [MH-11617]  - Add language support for Dutch  [MH-11620]  - Non privileged user can not login on presentation node  [MH-11623]  - Server statistics: Slow Query  [MH-11624]  - Workflow owners do not necessarily have access to their\n  workflows: user comparison fails  [MH-11627]  - NullPointerException when creating a new Solr index  [MH-11629]  - Hide Some Confusing Warnings  [MH-11630]  - Service registry lacks of getActiveJobs() function  [MH-11631]  - Remove columns \"Blacklisted from\" and \"Blacklisted until\"\n  from Capture->Locations  [MH-11632]  - Library Bugfix Upgrade  [MH-11636]  - Adjust FFmpegComposer Logging for Newer FFmpeg Versions  [MH-11637]  - Add language support for Swedish  [MH-11638]  - Improve Encoding Profiles  [MH-11639]  - Media module login form has poor usability and bugs  [MH-11642]  - Remove binding to non-existing method in WOH analyze-tracks  [MH-11643]  - Add language support for Polish  [MH-11645]  - Open AdminUI menu links in new tab does not work  [MH-11646]  - Add documentation for WOH comment  [MH-11652]  - Unit tests for servicesController broken  [MH-11654]  - Failed ingest jobs block system from dispatching other jobs  [MH-11656]  - Add documentation for WOH copy  [MH-11657]  - Improve documentation for workflow execution conditions  [MH-11658]  - Better quality for video editor previews  [MH-11663]  - Hide Participation Management from UI since not yet working  [MH-11666]  - Not all WOH listed in WOH overview",
            "title": "Opencast 2.2.0"
        },
        {
            "location": "/changelog/#opencast-21x",
            "text": "",
            "title": "Opencast 2.1.x"
        },
        {
            "location": "/changelog/#opencast-212",
            "text": "Released on May 10, 2016   [MH-9831]  - ehcache and quartz phones home  [MH-11121]  - MacOS X Installation Guide Needs 2.1 Update  [MH-11124]  - Incorrect documentation on how to create users  [MH-11128]  - Docs about SilenceDetector threashold are incorrect  [MH-11209]  - LTI Documentation needs to be incorporated into new docs  [MH-11229]  - workflowoperation unit tests are incredible slow  [MH-11283]  - post-mediapackage WOH breaks further processing  [MH-11287]  - Update Apereo/Apache License List  [MH-11296]  - HTTP method POST is not supported by this url in r/2.1.x  [MH-11298]  - Fix json-simple version specification  [MH-11307]  - Distribution Service is not on Presentation Node  [MH-11319]  - Media Module Always Uses Second Attachment as Preview  [MH-11320]  - Missing Image Preparation for text Extraction  [MH-11321]  - Fix default workflow configuration panel  [MH-11323]  - Workflow Docs are Incorrect  [MH-11332]  - Document acceptance criteria for proposals  [MH-11356]  - Update Documentation Index Page  [MH-11377]  - Opencast does not have an ingest assembly",
            "title": "Opencast 2.1.2"
        },
        {
            "location": "/changelog/#opencast-211",
            "text": "Released on January 22, 2016   [MH-11107]  - Group list pagination not working  [MH-11265]  - Ensure configuration files end with newline characters  [MH-11266]  - Logger ConversionPattern stated twice  [MH-11276]  - HttpNotificationWorkflowOperationHandlerTest fails if a\n  certain Domain Exists  [MH-11280]  - Opencast fails to compile due to missing dependencies in\n  test-harness",
            "title": "Opencast 2.1.1"
        },
        {
            "location": "/changelog/#opencast-210",
            "text": "Released on December 22, 2015   [MH-10637]  - Hello World service  [MH-10651]  - Workspace cleaner job param in wrong units (ms vs s) and\n  wrong logic  [MH-10714]  - Two clock icons at the time stamp of a comment  [MH-10805]  - The confirmation dialog are not translated  [MH-10818]  - The creation date is presented as ISO string in the event\n  metadata  [MH-10869]  - ActiveMQ Configuration and Connection Problems  [MH-10874]  - Plugin does not properly handle multiple keys  [MH-10875]  - Include search capabilities into mkdocs documentation build  [MH-10890]  - Update Apache Commons Lang (2.6 \u2192 3.4)  [MH-10908]  - Assemblie Module Names Too Long  [MH-10908]  - Consistency in Documentation: Presentation Server VS Engage\n  Server  [MH-10908]  - Misconfigured Checkstyle Plug-in in Assemblies  [MH-10919]  - Top row for setting roles in the access policy for an event\n  is not showing the right value  [MH-10953]  - Spanish layout is broken  [MH-10955]  - Make sure recent versions of mkdocs work  [MH-10956]  - Update Synchronize.js  [MH-10985]  - As an operator I want to check the health status of Opencast  [MH-10986]  - Scheduling around DST change fails  [MH-10987]  - Improve workflow query to accept paging by index  [MH-10988]  - Rewrite workspace to fix several small issues  [MH-10989]  - Improve working file repository stream response  [MH-11007]  - Remove 3rd party tool script  [MH-11026]  - Several invalid links in the Opencast User Guides  [MH-11031]  - Missing option to create new event using files ingested from\n  the inbox  [MH-11036]  - Adapt Fast Testing Workflow for Admin NG  [MH-11051]  - Fix WOH Documentation  [MH-11069]  - When creating new series, warning about read/write\n  requirements is shown twice.  [MH-11072]  - The ACL editor needs enhanced validation  [MH-11074]  - Admin UI Test: New Event API Resource assembles the metadata\n  for SCHEDULE_MULTIPLE with DST change is failing  [MH-11083]  - Clean-up Codebase after Karaf  [MH-11085]  - Make sure bundle cache is cleared when restarting  [MH-11086]  - Shorten File Names in Log Output  [MH-11088]  - translation error in theodul player  [MH-11089]  - Theodul player seems not to work with Internet Explorer at\n  all  [MH-11093]  - single video screen size jump when clicked  [MH-11094]  - Problems in Theodul controls plugin due to wrong resolves of\n  merge conflicts  [MH-11095]  - Make assemblies more user firedly  [MH-11096]  - Errors when loading admin-ng login page  [MH-11099]  - Removing one role from an Access Policy (acl-det-05)  [MH-11101]  - Creating a Theme with 2 bumper videos - In and Out\n  (thm-new-01)  [MH-11109]  - Event details tab cannot handle long event titles well  [MH-11110]  - minor updates to ffmpeg video-editor and silence detection\n  based on gregs review of the feature in 1.6.3  [MH-11111]  - Formatting issues in \u201cTheodul Pass Player - URL Parameters\u201d  [MH-11114]  - Remove System.out.println from FileReadDeleteTest  [MH-11120]  - Several Services Fail During Shutdown  [MH-11122]  - Create Service Files (Systemd/SysV-Init)  [MH-11126]  - Fix Translation for 2.1  [MH-11133]  - i18n: Theme Detail view layout broken in Spanish  [MH-11135]  - Create Release Manager Docs  [MH-11137]  - Comment reasons are not working correctly  [MH-11138]  - Clock icon displayed twice next to comment creation date  [MH-11141]  - Playback Speed in player needs more useful defaults  [MH-11142]  - fix translations for shortcuts  [MH-11144]  - update documentation regarding property for mediamodule logo  [MH-11147]  - Missing translations: FILTERS.USERS.PROVIDER.LABEL &\n  FILTERS.USERS.ROLE.LABEL  [MH-11149]  - Filter locations: Translations FILTERS.AGENTS.NAME.LABEL &\n  FILTERS.AGENTS.STATUS.LABEL missing  [MH-11151]  - Plaback speed from menu  [MH-11152]  - Editing ACL: Translation for\n  USERS.ACLS.DETAILS.ACCESS.ACCESS_POLICY.DESCRIPTION missing  [MH-11153]  - Access Policy Details: Cannot navigate to previous or next\n  ACL  [MH-11154]  - New Access Policy: Translation for\n  USERS.ACLS.NEW.ACCESS.ACCESS_POLICY.DESCRIPTION missing  [MH-11155]  - ACL Editor: Role not displayed at all  [MH-11158]  - Playback Tool: Time can be edited, but editing has no effect  [MH-11159]  - Users sorting: Sort order for 'Name' not correct  [MH-11160]  - Create Group overwrites existing groups without warning  [MH-11162]  - security_sample_cas.xml in MH 2.0.1 Points to Wrong\n  Welcome Page  [MH-11166]  - Number of rows not displayed on Systems->Servers  [MH-11176]  - Cannot playback a recording via LTI in 2.x  [MH-11177]  - Fix Player OSGI Dependencies  [MH-11178]  - Prevent FFmpeg Experimental AAC Encoder Bug to Affect\n  Opencast  [MH-11180]  - Update video.js to latest 4.x version  [MH-11181]  - Flash streaming with multi-quality video does not work  [MH-11185]  - Event Details->Assets->: Asset size is always 0  [MH-11186]  - Event Details->Assets->Media->Media Details:\n  Superfluous row 'Flavor'  [MH-11187]  - Configuration->Themes: Number of rows not displayed\n  correctly  [MH-11189]  - Actions->Start Task: User can press create button\n  multiple times  [MH-11193]  - Setting audio level slider to \"zero\" does not set the actual\n  audio level to \"zero\"  [MH-11196]  - REST docs cannot be found in new admin ui  [MH-11198]  - Event dashboard seems not to support i18n  [MH-11201]  - Maven Assembly Plug-in Listed Twice  [MH-11202]  - FFmpeg video editor operation is synchronized  [MH-11212]  - Main Pom Clean-Up  [MH-11218]  - Karaf based Solr configuration  [MH-11221]  - ComposerServiceImpl creates incorrect incidents and error\n  messages  [MH-11223]  - Remove unused files  [MH-11234]  - Admin-NG throws a couple of 404 errors  [MH-11236]  - Security ACL  see security list  [MH-11237]  - Service files are missing  [MH-11238]  - Silence-detection does not read configuration value for\n  ffmpeg binary path  [MH-11248]  - Publish-Engage Workflow Operation Documentation is Missing\n  Configuration Keys  [MH-11249]  - Apply-ACL WOH not properly replaced by Seried-WOH in\n  Documentation  [MH-11250]  - Put temporary files in karaf data not in opencast.storage  [MH-11251]  - Capture-Admin Tests May Fail When Executed Too Fast  [MH-11257]  - Deprecated Mkdocs Config  [MH-11258]  - Make host configuration easier",
            "title": "Opencast 2.1.0"
        },
        {
            "location": "/changelog/#opencast-20x",
            "text": "",
            "title": "Opencast 2.0.x"
        },
        {
            "location": "/changelog/#opencast-202",
            "text": "Released on December 22, 2015   [MH-10235]  - Users are unable to determine the Version of Matterhorn  [MH-10484]  - Remove Mediainfo from 3rd-Party-Tools  [MH-10558]  - Mime type not identified for matroska / mkv files  [MH-10588]  - Improve MySQL DDL to make it consistent again  [MH-10759]  - Write QA documentation for Access Policies  [MH-10759]  - Write QA documentation for Series  [MH-10759]  - Write QA documentation for Themes  [MH-10818]  - The creation date is presented as ISO string in the event\n  metadata  [MH-10918]  - Improve the representation of the\n  attachments/catalogs/media/publications in the event details  [MH-10956]  - Update Synchronize.js  [MH-10964]  - The Opencast start script does not work on Mac OS X  [MH-10976]  - Eclipse (m2e) throws NullPointerException erros due to a\n  missing property in the pom.xml file  [MH-11007]  - Remove 3rd party tool script  [MH-11007]  - Switch subtitle embedder to FFmpeg  [MH-11026]  - Several invalid links in the Opencast User Guides  [MH-11038]  - Make ListProviderScanner Scanner Less verbose  [MH-11048]  - admin ui tries to load missing library  [MH-11051]  - Fix WOH Documentation  [MH-11060]  - ActiveMQ settings filename fix (r/2.0.x)  [MH-11068]  - Table 'mh_bundleinfo' doesn't exist  [MH-11110]  - minor updates to ffmpeg video-editor and silence detection\n  based on gregs review of the feature in 1.6.3  [MH-11176]  - Cannot playback a recording via LTI in 2.x  [MH-11177]  - Fix Player OSGI Dependencies  [MH-11181]  - Flash streaming with multi-quality video does not work  [MH-11202]  - FFmpeg video editor operation is synchronized  [MH-11221]  - ComposerServiceImpl creates incorrect incidents and error\n  messages  [MH-11236]  - Security ACL  see security list  [MH-11238]  - Silence-detection does not read configuration value for\n  ffmpeg binary path  [MH-11256]  - Opencast docs do not build anymore",
            "title": "Opencast 2.0.2"
        },
        {
            "location": "/changelog/#opencast-201",
            "text": "Released on September 3, 2015   [MH-10822]  - Possible to create new access policy template without a role\n  with read/write permissions  [MH-10938]  - Missing views counter in player  [MH-10941]  - Usertracking Service Missing Endpoint  [MH-10955]  - Make sure recent versions of mkdocs work  [MH-10962]  - Add missing licenses to NOTICES  [MH-10968]  - Add note about ffmpeg/libav on Ubuntu  [MH-10975]  - async loading of translations  [MH-10995]  - Gathering workflow statistics for JMX causes extreme\n  performance issues",
            "title": "Opencast 2.0.1"
        },
        {
            "location": "/changelog/#opencast-200",
            "text": "Released on July 17, 2015   [MH-9950]  - \"Clean up\"/Split up nested functions in the core routine\n  (core.js)  [MH-9950]  - Load CSS files in the core HTML file, not the JavaScript  [MH-9950]  - Scrolling is required to see the controls if they are\n  configured to be below the video.  [MH-9950]  - Some Keys don't work  [MH-9950]  - Theodul Core Jasmine Tests Sometimes Failing  [MH-10029]  - FFmpeg based Videosegmenter  [MH-10140]  - Capture agent with no configuration is always shown as\n  \"idle\"  [MH-10202]  - No ACL in new series when ingested a new mediapackage with a\n  new series.  [MH-10230]  - Typos on the welcome page  [MH-10332]  - Remove Mediainfo Inspection Service  [MH-10382]  - Add a UI Element to Easily Unregister Capture Agents  [MH-10419]  - Improve user tracking tables  [MH-10510]  - Move Workflow Operation Handler into their own Packages  [MH-10550]  - Non-Interactive Foreground Mode For Matterhorn  [MH-10572]  - ShibbolethLoginHandler: 500 Error when login the first time  [MH-10594]  - Re-configure Start Scripts for Different Deployment Types  [MH-10615]  - Enable Optional Compiler Arguments  [MH-10620]  - Port Silence Detector from GStreamer to FFmpeg  [MH-10622]  - Wave Generation Improvement  [MH-10623]  - Set Sensible Default for Workspace Cleanup Period  [MH-10624]  - Fixes for FFmpeg Videosegmenter (Set Binary)  [MH-10630]  - Extending common functionality  [MH-10631]  - Scheduler service authorization handling  [MH-10635]  - Text extractor dead lock  [MH-10640]  - several problems with the metadata form to create a new\n  event  [MH-10656]  - Login Screen: Placeholder and Focus  [MH-10658]  - Email template: diverse problems  [MH-10664]  - What is a template in Access Policy and how do I create it?  [MH-10665]  - 404 for variables.json  [MH-10667]  - Previous Button does not always work  [MH-10681]  - Time is missing when a workflow operation has been started\n  and stopped  [MH-10683]  - Remove Capture Agent  [MH-10683]  - Remove the Capture Agent integration tests  [MH-10684]  - Admin UI seems only unresponsive if server is down  [MH-10689]  - I should get a warning, if I leave the Admin UI while I\n  still create an event (upload a file)  [MH-10698]  - workflow after videoeditor does not produce any  */delivery \n  flavors  [MH-10700]  - Service Registry throws NPE exception on startup  [MH-10704]  - Workflows fail if adding themes  [MH-10705]  - Row counter in Jobs table is 1 too much  [MH-10707]  - Unit Test Failure  [MH-10710]  - NullPointerException in VideoSegmentationWOH  [MH-10711]  - OptimisticLockException after ingest  [MH-10712]  - Workflow cleanup out of memory error  [MH-10713]  - Cache util blocks forever  [MH-10726]  - Archive operation should use filesystem copy rather than\n  http download  [MH-10736]  - Engage is currently broken and won't play videos but\n  Theodule does  [MH-10740]  - NPE in ToolsEndpoint  [MH-10746]  - There is no event status column  [MH-10758]  - Issues found in production use of Theodul: changing icons,\n  seeking in Chrome, using configured logos, wording, layout...  [MH-10759]  - Write QA documentation for Events  [MH-10759]  - Write QA documentation for Groups  [MH-10759]  - Write QA documentation for Servers  [MH-10759]  - Write QA documentation for Services  [MH-10763]  - Remove Old Confirations  [MH-10765]  - Operation details doesn't show operation attributes when\n  state is instantiated  [MH-10768]  - Workflow operations table in the events details should\n  refresh automatically  [MH-10769]  - Add (x) icon in the events and series tableview to allow\n  deletion of single Events/Series  [MH-10770]  - Some captions of tabs are not yet translated  [MH-10772]  - Ensure that buttons order is consistent in the actions\n  column  [MH-10773]  - Allow to have free-text value for presenters, contributors,\n  organizers or publishers  [MH-10774]  - ACL editing should be locked on the Series level when events\n  of the series are being processed  [MH-10775]  - All the roles with read/write rights can be deleted from the\n  ACL editor in Events/Series details  [MH-10776]  - Include Spanish and French translation into Theodul.  [MH-10780]  - Specify Requirements  [MH-10781]  - Respect tags while filtering for suitable tracks in Theodul\n  player  [MH-10792]  - Pom.xml Extra Modules  [MH-10798]  - Event Details tile shows hash identifier  [MH-10799]  - Videoeditor operation does not properly handle missing\n  preview formats  [MH-10804]  - It is unclear in which timezone you schedule in the admin-ui  [MH-10807]  - New event POST request contains every series and user  [MH-10808]  - Disable Demo Users  [MH-10810]  - Rename upgrade script form 1.6 to 2.0  [MH-10812]  - Use bundles.configuration.location in admin ng settings.yml  [MH-10814]  - Pressing play while buffering breaks player  [MH-10816]  - Move Message Broker Configuration to Global Config  [MH-10821]  - Severe Issue with Scheduled Events  [MH-10829]  - Unchecking \"Remember me\" checkbox has no effect when logged\n  out. Pressing the browsers back button you're still logged in an d can use all functions.  [MH-10836]  - Issues with matterhorn-engage-theodul-plugin-archetype  [MH-10837]  - Bulk deletion of events doesn't work correctly  [MH-10843]  - different video qualities are not filtered correctly.  [MH-10845]  - Summary of \"Add Events\" and \"Add Series\" shows irrelevant\n  data  [MH-10847]  - Missing with-role directive in \"Start Task\" option in\n  Actions dropdown  [MH-10848]  - Event conflict endpoint returns Server error 500  [MH-10849]  - Temporary videoeditor files get not deleted  [MH-10850]  - Interface MatterhornConstans has a typo  [MH-10853]  - Improve admin UI ng workflows  [MH-10855]  - Task Menu displays wrong UI  [MH-10864]  - Remove Trailing Spaces From Less Files  [MH-10866]  - Documentation: Incorrect Repository Links  [MH-10868]  - Linebreak before last segment in player  [MH-10873]  - capture-admin-service-impl tests randomly failing  [MH-10876]  - Admin UI NG makes calls to remote resources  [MH-10880]  - Remote base keeps try to call a service  [MH-10881]  - Wrong links to r/2.0.x on documentation page  [MH-10884]  - WokflowOperation getTimeInQueue should return 0 if value is\n  NULL  [MH-10888]  - Theodul player: audio-only does not work - player checked\n  for unavailable size.  [MH-10901]  - Execute Service is not in main pom.xml and will not be built  [MH-10902]  - ./modules/matterhorn-publication-service-youtube/ obsolete  [MH-10905]  - FFmpeg videoeditor only works with audio and video available  [MH-10911]  - Remove executable flag from non-executables  [MH-10912]  - Init scripts contain undefined references to DEBUG_PORT and\n  DEBUG_SUSPEND  [MH-10913]  - Add Event: License Metadata Field Text  [MH-10924]  - Update to new Opencast logos  [MH-10926]  - Extensive PhantomJS warnings when building admin-ng  [MH-10928]  - Adjust loglevel in DictionaryService  [MH-10929]  - Cutting and Review are skipped when config is set to do so  [MH-10930]  - Fix missing German translation  [MH-10934]  - Once set, one cannot remove some metadata in the create\n  event dialog  [MH-10938]  - Missing views counter in player  [MH-10939]  - Task Summary does not display configuration values  [MH-10946]  - Fix Opencast 2 Installation Guides  [MH-10950]  - Fix DDL Readme  [MH-10952]  - Fix matterhorn-execute-operations naming  [MH-10957]  - Add License Guide for Developers",
            "title": "Opencast 2.0.0"
        },
        {
            "location": "/installation/",
            "text": "Install Opencast\n\n\nInstallation from Source\n\n\nThese guides will help you to build Opencast, including all necessary third party tools. This method will most likely\nwork on all Unix-like systems.\n\n\n\n\nRedHat Enterprise Linux\n\n\nCentOS\n\n\nScientific Linux\n\n\nFedora\n\n\nDebian\n\n\nUbuntu\n\n\nMac OS X\n\n\n\n\nBuilding on most other Unix-like operating systems should be very much alike.\n\n\nInstallation from Repository\n\n\nThere is an RPM repository available for some operating systems. It provides packages containing pre-configured and\npre-built Opencast installations.\n\n\n\n\nRedHat Enterprise Linux\n\n\nCentOS\n\n\nScientific Linux\n\n\nFedora\n\n\nDebian\n\n\nUbuntu\n\n\n\n\nInstallation with Docker\n\n\nYou can also use Docker to quickly install or test Opencast. There are multiple Docker images available for installing\nOpencast on either a single or multiple server.\n\n\n\n\nTesting Locally with Docker\n\n\n\n\nInstallation Across Multiple Servers\n\n\nFor production systems, it is recommended to install Opencast across multiple servers to separate the processing,\nmanagement and presentation layer, so that, for example, even if the processing layer is under full load, users can\nstill watch recordings unaffected since the presentation layer is running on a separate machine.\n\n\n\n\nInstallation Across Multiple Servers",
            "title": "Overview"
        },
        {
            "location": "/installation/#install-opencast",
            "text": "",
            "title": "Install Opencast"
        },
        {
            "location": "/installation/#installation-from-source",
            "text": "These guides will help you to build Opencast, including all necessary third party tools. This method will most likely\nwork on all Unix-like systems.   RedHat Enterprise Linux  CentOS  Scientific Linux  Fedora  Debian  Ubuntu  Mac OS X   Building on most other Unix-like operating systems should be very much alike.",
            "title": "Installation from Source"
        },
        {
            "location": "/installation/#installation-from-repository",
            "text": "There is an RPM repository available for some operating systems. It provides packages containing pre-configured and\npre-built Opencast installations.   RedHat Enterprise Linux  CentOS  Scientific Linux  Fedora  Debian  Ubuntu",
            "title": "Installation from Repository"
        },
        {
            "location": "/installation/#installation-with-docker",
            "text": "You can also use Docker to quickly install or test Opencast. There are multiple Docker images available for installing\nOpencast on either a single or multiple server.   Testing Locally with Docker",
            "title": "Installation with Docker"
        },
        {
            "location": "/installation/#installation-across-multiple-servers",
            "text": "For production systems, it is recommended to install Opencast across multiple servers to separate the processing,\nmanagement and presentation layer, so that, for example, even if the processing layer is under full load, users can\nstill watch recordings unaffected since the presentation layer is running on a separate machine.   Installation Across Multiple Servers",
            "title": "Installation Across Multiple Servers"
        },
        {
            "location": "/installation/multiple-servers/",
            "text": "Install Across Multiple Servers\n\n\nNote that this is not a comprehensive guide of all possible ways to install Opencast. It is more like a guide to good\npractices and presents what a lot of people are running.\n\n\nStep 1: Install Opencast\n\n\nOpencast consists of a large set of modules which together build the whole system. In a distributed set-up, different\nkinds of nodes are basically only defined by the existence or absence of specific modules.\n\n\nWhile it is possible to stick together a system module by module, opencast comes with a set of pre-defined distribution\nwhich can directly be built and installed. To build these distributions, you would compile Opencast just like it is\noutlined in the basic installation guides and will then find a set of different distributions, both as archive and in a\nseparate directory.\n\n\nTo list all distributions, run the following command after Opencast is built:\n\n\n% ls -1 build/*.tar.gz\nbuild/opencast-dist-admin-${version}.tar.gz\nbuild/opencast-dist-allinone-${version}.tar.gz\nbuild/opencast-dist-presentation-${version}.tar.gz\nbuild/opencast-dist-worker-${version}.tar.g\n...\n\n\n\nThe same distributions can be found in the packages provided in the Opencast RPM repository.  These packages will\nautomatically install all dependencies for a given node type. For example, to install an Opencast worker node, you would\ninstall the package \nopencast21-distribution-worker\n.\n\n\nThe following list describes possible set-ups:\n\n\nAll-In-One\n\n\nThis is the default set-up described in the basic installation guides. It works fine for testing purposes. It should\nusually not be used in production. It is not distributed but is listed here to have a comprehensive list of predefined\ndistributions.\n\n\nTwo-Server Set-up\n\n\nThis set-up is the minimum set-up recommended for productive use. It will separate the presentation layer from the\nadministrative and working layer. This means that even if one server is under heavy load while videos are processed, it\nwill not effect the distribution and users should still be able to watch videos smoothly. However, it might happen that\nunder heavy load the handling of the administrative user interface gets a bit rough.\n\n\nThree (or more) Server Set-up\n\n\nWhile in the last example we have created one combined node for both the administrative tools and the workers, in this\nexample we will split it into dedicated worker and admin nodes. Using this set-up it is easy to increase the systems\nperformance simply by adding further worker nodes to the system.\n\n\nStep 2: Set-Up NFS Server\n\n\nThough it is possible to have Opencast run without shared storage, it is still a good idea to do so, as hard links can\nbe used to link files instead of copying them and not everything has to be tunneled over HTTP.\n\n\nThus you should first set-up your NFS server. The best solution is certainly to have a dedicated storage server. For\nsmaller set-ups, however, it can also be put on one of the Opencast nodes, i.e. on the admin node.\n\n\nTo do this, you first have to install and enable the NFS server:\n\n\nyum install nfs-utils nfs-utils-lib\nchkconfig  --level 345 nfs on\nservice nfs start\n\n\n\nYou want to have one common user on all your systems, so that file permissions do not become an issue.. As preparation\nfor this it makes sense to manually create an \nopencast\n user and group with a common UID and GID:\n\n\ngroupadd -g 1234 opencast\nuseradd -g 1234 -u 1234 opencast\n\n\n\nIf the user and group id \n1234\n is already used, just pick another one but make sure to pick the same one on all your\nOpencast nodes.\n\n\nThen create the directory to be shared and set its ownership to the newly created users:\n\n\nmkdir -p /srv/opencast\nchown opencast:opencast /srv/opencast\n\n\n\nNext we actually share the storage dir. For this we need to edit the file \n/etc/exports\n and set:\n\n\n/srv/opencast  131.173.172.190(rw,sync,no_subtree_check)\n\n\n\nwith 131.173.172.190 being the IP address of the other machine that should get access. Finally we enable the share with:\n\n\nexportfs -a\n\n\n\nOf cause you have to open the necessary ports in your firewall configuration.  For iptables, appropriate rules could be\nfor example:\n\n\n-A INPUT -m state --state NEW -p tcp -m multiport --dport 111,892,2049,32803 -j ACCEPT\n-A INPUT -m state --state NEW -p udp -m multiport --dport 111,892,2049,32803 -j ACCEPT\n\n\n\nYou can set them by editing \n/etc/sysconfig/iptables\n and restarting the service afterwards.\n\n\nNow you have set-up your storage server. What is still left to do is to mount the network storage on all other servers\nof the Opencast clusters except the capture agents. To do that you need to edit the \n/etc/fstab\n on each server and add\nthe command to mount the network storage on startup:\n\n\nstorageserver.example.com:/srv/opencast /srv/opencast   nfs rw,hard,intr,rsize=32768,wsize=32768 0 0\n\n\n\nImportant:\n Do not use multiple NFS shares for different parts of the Opencast storage dir. Opencast will check if\nhard links are possible across in a distributed set-up, but the detection may fail if hard links are only possible\nbetween certain parts of the storage. This may lead to failures.\n\n\nImportant:\n Do not share the Karaf data directory. Doing so will cause Opencast to fail. Please share the storage\ndirectory only.\n\n\nStep 3: Set-Up the Database\n\n\nFirst make sure to follow the \nregular database set-up\n.\n\n\nDo not forget to set the user also for the remote servers and grant them the necessary rights. Additionally, you need to\nconfigure your firewall:\n\n\n-A INPUT -p tcp -s 131.173.172.190 --dport 3306 -m state --state NEW,ESTABLISHED -j ACCEPT\n\n\n\nStep 4: Set-Up ActiveMQ\n\n\nSince version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user\ninterface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the\nadmin node).\n\n\nActiveMQ 5.10 or above should work. ActiveMQ 5.6 will not work. Versions in between are untested.\n\n\nInstallation\n\n\n\n\nIf you use the Opencast RPM repository, simply install the \nactivemq-dist\n package.\n\n\nIf you are running RHEL, CentOS or Fedora you can use the \nActiveMQ-dist Copr RPM\n  repository\n\n\nYou can download binary distributions from the \nApache ActiveMQ website\n\n\n\n\nConfiguration\n\n\nWhat you basically need to do is to point all your Opencast nodes to your message broker. For more information about\nthe configuration, have a look at the \nMessage Broker Set-Up Guide\n.\n\n\nDo not forget that ActiveMQ uses TCP port 61616 (default configuration) for communication which you might have to allow\nin your firewall.\n\n\nStep 5: Configure Opencast\n\n\nYou did already set-up and configured your database and message broker in the last steps, but there is some more\nconfiguration you have to do. First of all you should follow the Basic Configuration guide which will tell you how to\nset the login credentials etc. After that continue with the following steps:\n\n\ncustom.properties\n\n\nSet the server URL to the public URL of each server (admin URL on admin, worker URL on worker, presentation URL on\npresentation, \u2026).  This may either be this nodes IP address or preferable its domain name:\n\n\norg.opencastproject.server.url=http://<URL>:8080\n\n\n\nSet the location of the shared storage directory:\n\n\norg.opencastproject.storage.dir=/srv/opencast\n\n\n\nDefine that the file repository shall access all files locally:\n\n\norg.opencastproject.file.repo.url=${org.opencastproject.admin.ui.url}\n\n\n\norg.opencastproject.organization-mh_default_org.cfg\n\n\nSet the base URL of the server hosting the administrative tools. Again use a domain name instead of an IP address if\npossible:\n\n\nprop.org.opencastproject.admin.ui.url=http://<ADMIN-URL>:8080\n\n\n\nSet the base URL of the server hosting the engage tools (usually the presentation node):\n\n\nprop.org.opencastproject.engage.ui.url=http://<ENGAGE-URL>:8080\n\n\n\nSet the base URL of the file server. When using a shared filesystem between servers,\nset all servers to use the same URL (e.g. URL of the admin node).\n\n\nprop.org.opencastproject.file.repo.url=http://<ADMIN-URL>:8080\n\n\n\norg.opencastproject.serviceregistry.impl.ServiceRegistryJpaImpl.cfg\n\n\nTo ensure that jobs are not dispatched by non-admin nodes, on these you should also set:\n\n\ndispatchinterval=0",
            "title": "Multiple Servers"
        },
        {
            "location": "/installation/multiple-servers/#install-across-multiple-servers",
            "text": "Note that this is not a comprehensive guide of all possible ways to install Opencast. It is more like a guide to good\npractices and presents what a lot of people are running.",
            "title": "Install Across Multiple Servers"
        },
        {
            "location": "/installation/multiple-servers/#step-1-install-opencast",
            "text": "Opencast consists of a large set of modules which together build the whole system. In a distributed set-up, different\nkinds of nodes are basically only defined by the existence or absence of specific modules.  While it is possible to stick together a system module by module, opencast comes with a set of pre-defined distribution\nwhich can directly be built and installed. To build these distributions, you would compile Opencast just like it is\noutlined in the basic installation guides and will then find a set of different distributions, both as archive and in a\nseparate directory.  To list all distributions, run the following command after Opencast is built:  % ls -1 build/*.tar.gz\nbuild/opencast-dist-admin-${version}.tar.gz\nbuild/opencast-dist-allinone-${version}.tar.gz\nbuild/opencast-dist-presentation-${version}.tar.gz\nbuild/opencast-dist-worker-${version}.tar.g\n...  The same distributions can be found in the packages provided in the Opencast RPM repository.  These packages will\nautomatically install all dependencies for a given node type. For example, to install an Opencast worker node, you would\ninstall the package  opencast21-distribution-worker .  The following list describes possible set-ups:",
            "title": "Step 1: Install Opencast"
        },
        {
            "location": "/installation/multiple-servers/#all-in-one",
            "text": "This is the default set-up described in the basic installation guides. It works fine for testing purposes. It should\nusually not be used in production. It is not distributed but is listed here to have a comprehensive list of predefined\ndistributions.",
            "title": "All-In-One"
        },
        {
            "location": "/installation/multiple-servers/#two-server-set-up",
            "text": "This set-up is the minimum set-up recommended for productive use. It will separate the presentation layer from the\nadministrative and working layer. This means that even if one server is under heavy load while videos are processed, it\nwill not effect the distribution and users should still be able to watch videos smoothly. However, it might happen that\nunder heavy load the handling of the administrative user interface gets a bit rough.",
            "title": "Two-Server Set-up"
        },
        {
            "location": "/installation/multiple-servers/#three-or-more-server-set-up",
            "text": "While in the last example we have created one combined node for both the administrative tools and the workers, in this\nexample we will split it into dedicated worker and admin nodes. Using this set-up it is easy to increase the systems\nperformance simply by adding further worker nodes to the system.",
            "title": "Three (or more) Server Set-up"
        },
        {
            "location": "/installation/multiple-servers/#step-2-set-up-nfs-server",
            "text": "Though it is possible to have Opencast run without shared storage, it is still a good idea to do so, as hard links can\nbe used to link files instead of copying them and not everything has to be tunneled over HTTP.  Thus you should first set-up your NFS server. The best solution is certainly to have a dedicated storage server. For\nsmaller set-ups, however, it can also be put on one of the Opencast nodes, i.e. on the admin node.  To do this, you first have to install and enable the NFS server:  yum install nfs-utils nfs-utils-lib\nchkconfig  --level 345 nfs on\nservice nfs start  You want to have one common user on all your systems, so that file permissions do not become an issue.. As preparation\nfor this it makes sense to manually create an  opencast  user and group with a common UID and GID:  groupadd -g 1234 opencast\nuseradd -g 1234 -u 1234 opencast  If the user and group id  1234  is already used, just pick another one but make sure to pick the same one on all your\nOpencast nodes.  Then create the directory to be shared and set its ownership to the newly created users:  mkdir -p /srv/opencast\nchown opencast:opencast /srv/opencast  Next we actually share the storage dir. For this we need to edit the file  /etc/exports  and set:  /srv/opencast  131.173.172.190(rw,sync,no_subtree_check)  with 131.173.172.190 being the IP address of the other machine that should get access. Finally we enable the share with:  exportfs -a  Of cause you have to open the necessary ports in your firewall configuration.  For iptables, appropriate rules could be\nfor example:  -A INPUT -m state --state NEW -p tcp -m multiport --dport 111,892,2049,32803 -j ACCEPT\n-A INPUT -m state --state NEW -p udp -m multiport --dport 111,892,2049,32803 -j ACCEPT  You can set them by editing  /etc/sysconfig/iptables  and restarting the service afterwards.  Now you have set-up your storage server. What is still left to do is to mount the network storage on all other servers\nof the Opencast clusters except the capture agents. To do that you need to edit the  /etc/fstab  on each server and add\nthe command to mount the network storage on startup:  storageserver.example.com:/srv/opencast /srv/opencast   nfs rw,hard,intr,rsize=32768,wsize=32768 0 0  Important:  Do not use multiple NFS shares for different parts of the Opencast storage dir. Opencast will check if\nhard links are possible across in a distributed set-up, but the detection may fail if hard links are only possible\nbetween certain parts of the storage. This may lead to failures.  Important:  Do not share the Karaf data directory. Doing so will cause Opencast to fail. Please share the storage\ndirectory only.",
            "title": "Step 2: Set-Up NFS Server"
        },
        {
            "location": "/installation/multiple-servers/#step-3-set-up-the-database",
            "text": "First make sure to follow the  regular database set-up .  Do not forget to set the user also for the remote servers and grant them the necessary rights. Additionally, you need to\nconfigure your firewall:  -A INPUT -p tcp -s 131.173.172.190 --dport 3306 -m state --state NEW,ESTABLISHED -j ACCEPT",
            "title": "Step 3: Set-Up the Database"
        },
        {
            "location": "/installation/multiple-servers/#step-4-set-up-activemq",
            "text": "Since version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user\ninterface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the\nadmin node).  ActiveMQ 5.10 or above should work. ActiveMQ 5.6 will not work. Versions in between are untested.",
            "title": "Step 4: Set-Up ActiveMQ"
        },
        {
            "location": "/installation/multiple-servers/#installation",
            "text": "If you use the Opencast RPM repository, simply install the  activemq-dist  package.  If you are running RHEL, CentOS or Fedora you can use the  ActiveMQ-dist Copr RPM\n  repository  You can download binary distributions from the  Apache ActiveMQ website",
            "title": "Installation"
        },
        {
            "location": "/installation/multiple-servers/#configuration",
            "text": "What you basically need to do is to point all your Opencast nodes to your message broker. For more information about\nthe configuration, have a look at the  Message Broker Set-Up Guide .  Do not forget that ActiveMQ uses TCP port 61616 (default configuration) for communication which you might have to allow\nin your firewall.",
            "title": "Configuration"
        },
        {
            "location": "/installation/multiple-servers/#step-5-configure-opencast",
            "text": "You did already set-up and configured your database and message broker in the last steps, but there is some more\nconfiguration you have to do. First of all you should follow the Basic Configuration guide which will tell you how to\nset the login credentials etc. After that continue with the following steps:",
            "title": "Step 5: Configure Opencast"
        },
        {
            "location": "/installation/multiple-servers/#customproperties",
            "text": "Set the server URL to the public URL of each server (admin URL on admin, worker URL on worker, presentation URL on\npresentation, \u2026).  This may either be this nodes IP address or preferable its domain name:  org.opencastproject.server.url=http://<URL>:8080  Set the location of the shared storage directory:  org.opencastproject.storage.dir=/srv/opencast  Define that the file repository shall access all files locally:  org.opencastproject.file.repo.url=${org.opencastproject.admin.ui.url}",
            "title": "custom.properties"
        },
        {
            "location": "/installation/multiple-servers/#orgopencastprojectorganization-mh95default95orgcfg",
            "text": "Set the base URL of the server hosting the administrative tools. Again use a domain name instead of an IP address if\npossible:  prop.org.opencastproject.admin.ui.url=http://<ADMIN-URL>:8080  Set the base URL of the server hosting the engage tools (usually the presentation node):  prop.org.opencastproject.engage.ui.url=http://<ENGAGE-URL>:8080  Set the base URL of the file server. When using a shared filesystem between servers,\nset all servers to use the same URL (e.g. URL of the admin node).  prop.org.opencastproject.file.repo.url=http://<ADMIN-URL>:8080",
            "title": "org.opencastproject.organization-mh_default_org.cfg"
        },
        {
            "location": "/installation/multiple-servers/#orgopencastprojectserviceregistryimplserviceregistryjpaimplcfg",
            "text": "To ensure that jobs are not dispatched by non-admin nodes, on these you should also set:  dispatchinterval=0",
            "title": "org.opencastproject.serviceregistry.impl.ServiceRegistryJpaImpl.cfg"
        },
        {
            "location": "/installation/source-linux/",
            "text": "Install from Source (Linux)\n\n\nThese instructions outline how to install an all in one Opencast system on Linux.\n\n\nPreparation\n\n\nCreate a dedicated Opencast system user:\n\n\nuseradd -r -d /opt/opencast opencast\n\n\n\nGet Opencast source:\n\n\nYou can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git\nrepository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The\nprior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git.\n\n\nUsing the tarball:\n\n\nSelect the tarball for the version you want to install\nfrom the \nGitHub releases section\n.\n\n\n# Download desired tarball\ncurl -OL https://github.com/opencast/opencast/archive/[...].tar.gz\ntar xf [...].tar.gz\ncd opencast--[...]\n\n\n\nCloning the Git repository:\n\n\ngit clone https://github.com/opencast/opencast.git\ncd opencast\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version\n\n\n\nInstall Dependencies\n\n\nPlease make sure to install the following dependencies.\n\n\nRequired:\n\n\njava-1.8.0-openjdk-devel.x86_64 / openjdk-8-jdk\nffmpeg >= 3.2.4\nmaven >= 3.1\nunzip\ngcc-c++\ntar\nbzip2\nnc\n\n\n\nRequired (not necessarily on the same machine):\n\n\nActiveMQ >= 5.10 (older versions untested)\n\n\n\nRequired for text extraction (recommended):\n\n\ntesseract >= 3\n\n\n\nRequired for hunspell based text filtering (optional):\n\n\nhunspell >= 1.2.8\n\n\n\nRequired for audio normalization (optional):\n\n\nsox >= 14.4\n\n\n\nRequired for animate service (optional):\n\n\nsynfig\n\n\n\nDependency Download\n\n\nPre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project\nwebsite:\n\n\n\n\nGet FFmpeg\n\n\nGet Apache Maven\n\n\nGet Apache ActiveMQ\n\n\n\n\nBuilding Opencast\n\n\nAutomatically build all Opencast modules and assemble distributions for different server types:\n\n\ncd opencast-dir\nmvn clean install\n\n\n\nDeploy all-in-one distribution:\n\n\ncd build/\nmv opencast-dist-allinone-*/ /opt/opencast\n\n\n\nMake sure everything belongs to the user \nopencast\n:\n\n\nsudo chown -R opencast:opencast /opt/opencast\n\n\n\nConfigure\n\n\nPlease follow the steps of the \nBasic Configuration guide\n. It will help you to set your\nhostname, login information, \u2026\n\n\nRunning Opencast\n\n\nTo start Opencast, run \n.../bin/start-opencast\n as user \nopencast\n:\n\n\nsudo -u opencast /opt/opencast/bin/start-opencast\n\n\n\nAs soon as Opencast is completely started, browse to \nhttp://localhost:8080\n to get to the\nadministration interface.\n\n\nRun Opencast as a service\n\n\nUsually, you do not want to run Opencast in interactive mode but as system service to make sure it is only running\nonce on a system and is started automatically.\n\n\nYou will find service files for Opencast in \ndocs/scripts/service/{opt,system}/\n.\n\n\nUsing Systemd\n\n\nMake sure the path to Opencast is set correctly:\n\n\nvim docs/scripts/service/opencast.service\n\n\n\nInstall the unit file:\n\n\ncp docs/scripts/service/opencast.service /etc/systemd/system/\nsystemctl daemon-reload\n\n\n\nStart Opencast and make it run automatically:\n\n\nsystemctl start opencast.service\nsystemctl enable opencast.service\n\n\n\nUsing SysV-Init\n\n\n\n\nNote that this option is for compatibility to older systems. If you have the choice of either using the Systemd unit\nfile or the Init script, it is recommended to use the Systemd unit file.\n\n\n\n\nMake sure the path to Opencast is set correctly:\n\n\nvim docs/scripts/service/etc-init.d-opencast\n\n\n\n\n\n\n\nInstall init script:\n\n\ncp docs/scripts/service/etc-init.d-opencast /etc/init.d/opencast\n\n\n\n\n\n\n\nEnable service using \nchkconfig\n or \nupdate-rc.d\n\n\n\n\n\n\nStart Opencast using\n\n\nservice opencast start",
            "title": "Linux"
        },
        {
            "location": "/installation/source-linux/#install-from-source-linux",
            "text": "These instructions outline how to install an all in one Opencast system on Linux.",
            "title": "Install from Source (Linux)"
        },
        {
            "location": "/installation/source-linux/#preparation",
            "text": "Create a dedicated Opencast system user:  useradd -r -d /opt/opencast opencast  Get Opencast source:  You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git\nrepository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The\nprior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git.  Using the tarball:  Select the tarball for the version you want to install\nfrom the  GitHub releases section .  # Download desired tarball\ncurl -OL https://github.com/opencast/opencast/archive/[...].tar.gz\ntar xf [...].tar.gz\ncd opencast--[...]  Cloning the Git repository:  git clone https://github.com/opencast/opencast.git\ncd opencast\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version",
            "title": "Preparation"
        },
        {
            "location": "/installation/source-linux/#install-dependencies",
            "text": "Please make sure to install the following dependencies.  Required:  java-1.8.0-openjdk-devel.x86_64 / openjdk-8-jdk\nffmpeg >= 3.2.4\nmaven >= 3.1\nunzip\ngcc-c++\ntar\nbzip2\nnc  Required (not necessarily on the same machine):  ActiveMQ >= 5.10 (older versions untested)  Required for text extraction (recommended):  tesseract >= 3  Required for hunspell based text filtering (optional):  hunspell >= 1.2.8  Required for audio normalization (optional):  sox >= 14.4  Required for animate service (optional):  synfig",
            "title": "Install Dependencies"
        },
        {
            "location": "/installation/source-linux/#dependency-download",
            "text": "Pre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project\nwebsite:   Get FFmpeg  Get Apache Maven  Get Apache ActiveMQ",
            "title": "Dependency Download"
        },
        {
            "location": "/installation/source-linux/#building-opencast",
            "text": "Automatically build all Opencast modules and assemble distributions for different server types:  cd opencast-dir\nmvn clean install  Deploy all-in-one distribution:  cd build/\nmv opencast-dist-allinone-*/ /opt/opencast  Make sure everything belongs to the user  opencast :  sudo chown -R opencast:opencast /opt/opencast",
            "title": "Building Opencast"
        },
        {
            "location": "/installation/source-linux/#configure",
            "text": "Please follow the steps of the  Basic Configuration guide . It will help you to set your\nhostname, login information, \u2026",
            "title": "Configure"
        },
        {
            "location": "/installation/source-linux/#running-opencast",
            "text": "To start Opencast, run  .../bin/start-opencast  as user  opencast :  sudo -u opencast /opt/opencast/bin/start-opencast  As soon as Opencast is completely started, browse to  http://localhost:8080  to get to the\nadministration interface.",
            "title": "Running Opencast"
        },
        {
            "location": "/installation/source-linux/#run-opencast-as-a-service",
            "text": "Usually, you do not want to run Opencast in interactive mode but as system service to make sure it is only running\nonce on a system and is started automatically.  You will find service files for Opencast in  docs/scripts/service/{opt,system}/ .",
            "title": "Run Opencast as a service"
        },
        {
            "location": "/installation/source-linux/#using-systemd",
            "text": "Make sure the path to Opencast is set correctly:  vim docs/scripts/service/opencast.service  Install the unit file:  cp docs/scripts/service/opencast.service /etc/systemd/system/\nsystemctl daemon-reload  Start Opencast and make it run automatically:  systemctl start opencast.service\nsystemctl enable opencast.service",
            "title": "Using Systemd"
        },
        {
            "location": "/installation/source-linux/#using-sysv-init",
            "text": "Note that this option is for compatibility to older systems. If you have the choice of either using the Systemd unit\nfile or the Init script, it is recommended to use the Systemd unit file.   Make sure the path to Opencast is set correctly:  vim docs/scripts/service/etc-init.d-opencast    Install init script:  cp docs/scripts/service/etc-init.d-opencast /etc/init.d/opencast    Enable service using  chkconfig  or  update-rc.d    Start Opencast using  service opencast start",
            "title": "Using SysV-Init"
        },
        {
            "location": "/installation/source-macosx/",
            "text": "Install from Source (Mac OS X)\n\n\nThese instructions outline how to install an all in one Opencast system on the Mac OS X operating system.\nTested on OS X 10.13.6 High Sierra.\n\n\n\n\nThe installation on Mac OS X is not officially supported. Use this at your own risk.\n\n\n\n\nPreparation\n\n\nOpen a Terminal and switch to the directory, in which the Opencast installation should be placed, e.g. \n/opt/\n,\n\n~/develop/\n or whatever you prefer.\n\n\nGet Opencast source\n\n\nYou can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git\nrepository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The\nprior option, the tarball download, needs less tools and you don't have to download nearly as much as with Git.\n\n\nCloning the Git repository:\n\n\ngit clone https://github.com/opencast/opencast.git\ncd opencast\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version\n\n\n\nUsing the tarball:\n\n\nSelect the tarball for the version you want to install\nfrom the \nGitHub releases section\n under the \"Tags\" tab and download it\ndirectly from there or with the curl command specified below.\n\n\n# Download desired tarball, replace [...] with the desired version\ncurl -OL https://github.com/opencast/opencast/archive/[...].tar.gz\ntar xf [...].tar.gz\n\n\n\nInstall Dependencies\n\n\nPlease make sure to install the following dependencies.\n\n\nRequired:\n\n\nXcode\njdk 8\nffmpeg >= 3.2.4\nmaven >= 3.1\n\n\n\n(If you are using \njEnv\n to set up your environment, make sure to \nenable the maven plugin\n.)\n\n\nRequired (not necessarily on the same machine):\n\n\nActiveMQ >= 5.10 (older versions untested)\n\n\n\nRequired for text extraction:\n\n\ntesseract >= 3\n\n\n\nRequired for hunspell based text filtering:\n\n\nhunspell >= 1.2.8\n\n\n\nRequired for audio normalization:\n\n\nsox >= 14.4 (with MP3, FLAC and OGG support)\n\n\n\nRequired for animate service:\n\n\nsynfig\n\n\n\nDependency Download\n\n\nYou can download Xcode in the Mac App Store. JDK 8 for OS X is available from\n\nOracle\n.\n\n\nUsing Homebrew\n\n\nHomebrew is a package manager for OS X. For installation instruction see \ntheir website\n.\n\n\nbrew install maven\nbrew install ffmpeg\nbrew install apache-activemq\n\nbrew install tesseract\nbrew install hunspell\nbrew install sox\n\n\n\nUsing pre-built binaries\n\n\nPre-built versions of most dependencies can be downloaded from the respective project website:\n\n\n\n\nGet Apache Maven\n\n\nGet FFmpeg\n\n\nGet Apache ActiveMQ\n\n\n\n\nBuilding Opencast\n\n\nSwitch to the opencast folder. If you downloaded the tarball, this is the folder you just unpacked (called something\nlike \nopencast-community-opencast-[\u2026]\n). If you chose to download via git, use \ncd opencast\n. You can proceed by\nbuilding opencast (depending on the folder permissions, you might need to start the command with \nsudo\n):\n\n\nmvn clean install\n\n\n\n\n\nPlease be patient, as building Opencast for the first time will take quite long.\n\n\n\n\nConfigure\n\n\nPlease follow the steps of the \nBasic Configuration guide\n. It will help you to set your host\nname, login information, etc. Be aware that the config files now reside in the build folders for the desired\ndistribution. For the allinone distribution, this would be\n\n/your/path/to/opencast/build/opencast-dist-allinone-[\u2026]/etc/\n, again with \n[\u2026]\n representing the selected version.\n\n\nAs specified in the guide, make sure you replace the default ActiveMQ configuration with the one provided in\n\ndocs/scripts/activemq/activemq.xml\n. If you installed ActiveMQ using homebrew, you can find the installation path with\n\nbrew info activemq\n.\n\n\nRunning Opencast\n\n\nMake sure you have ActiveMQ running (unless you're running it on a different machine). Then you can start Opencast using\nthe start-opencast script:\n\n\nactivemq start\ncd /your/path/to/opencast/\ncd build/opencast-dist-allinone-[\u2026]\n./bin/start-opencast\n\n\n\nAs soon as Opencast is completely started, browse to \nhttp://localhost:8080\n to get to the\nadministration interface.",
            "title": "MacOS X"
        },
        {
            "location": "/installation/source-macosx/#install-from-source-mac-os-x",
            "text": "These instructions outline how to install an all in one Opencast system on the Mac OS X operating system.\nTested on OS X 10.13.6 High Sierra.   The installation on Mac OS X is not officially supported. Use this at your own risk.",
            "title": "Install from Source (Mac OS X)"
        },
        {
            "location": "/installation/source-macosx/#preparation",
            "text": "Open a Terminal and switch to the directory, in which the Opencast installation should be placed, e.g.  /opt/ , ~/develop/  or whatever you prefer.",
            "title": "Preparation"
        },
        {
            "location": "/installation/source-macosx/#get-opencast-source",
            "text": "You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git\nrepository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The\nprior option, the tarball download, needs less tools and you don't have to download nearly as much as with Git.  Cloning the Git repository:  git clone https://github.com/opencast/opencast.git\ncd opencast\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version  Using the tarball:  Select the tarball for the version you want to install\nfrom the  GitHub releases section  under the \"Tags\" tab and download it\ndirectly from there or with the curl command specified below.  # Download desired tarball, replace [...] with the desired version\ncurl -OL https://github.com/opencast/opencast/archive/[...].tar.gz\ntar xf [...].tar.gz",
            "title": "Get Opencast source"
        },
        {
            "location": "/installation/source-macosx/#install-dependencies",
            "text": "Please make sure to install the following dependencies.  Required:  Xcode\njdk 8\nffmpeg >= 3.2.4\nmaven >= 3.1  (If you are using  jEnv  to set up your environment, make sure to  enable the maven plugin .)  Required (not necessarily on the same machine):  ActiveMQ >= 5.10 (older versions untested)  Required for text extraction:  tesseract >= 3  Required for hunspell based text filtering:  hunspell >= 1.2.8  Required for audio normalization:  sox >= 14.4 (with MP3, FLAC and OGG support)  Required for animate service:  synfig",
            "title": "Install Dependencies"
        },
        {
            "location": "/installation/source-macosx/#dependency-download",
            "text": "You can download Xcode in the Mac App Store. JDK 8 for OS X is available from Oracle .",
            "title": "Dependency Download"
        },
        {
            "location": "/installation/source-macosx/#using-homebrew",
            "text": "Homebrew is a package manager for OS X. For installation instruction see  their website .  brew install maven\nbrew install ffmpeg\nbrew install apache-activemq\n\nbrew install tesseract\nbrew install hunspell\nbrew install sox",
            "title": "Using Homebrew"
        },
        {
            "location": "/installation/source-macosx/#using-pre-built-binaries",
            "text": "Pre-built versions of most dependencies can be downloaded from the respective project website:   Get Apache Maven  Get FFmpeg  Get Apache ActiveMQ",
            "title": "Using pre-built binaries"
        },
        {
            "location": "/installation/source-macosx/#building-opencast",
            "text": "Switch to the opencast folder. If you downloaded the tarball, this is the folder you just unpacked (called something\nlike  opencast-community-opencast-[\u2026] ). If you chose to download via git, use  cd opencast . You can proceed by\nbuilding opencast (depending on the folder permissions, you might need to start the command with  sudo ):  mvn clean install   Please be patient, as building Opencast for the first time will take quite long.",
            "title": "Building Opencast"
        },
        {
            "location": "/installation/source-macosx/#configure",
            "text": "Please follow the steps of the  Basic Configuration guide . It will help you to set your host\nname, login information, etc. Be aware that the config files now reside in the build folders for the desired\ndistribution. For the allinone distribution, this would be /your/path/to/opencast/build/opencast-dist-allinone-[\u2026]/etc/ , again with  [\u2026]  representing the selected version.  As specified in the guide, make sure you replace the default ActiveMQ configuration with the one provided in docs/scripts/activemq/activemq.xml . If you installed ActiveMQ using homebrew, you can find the installation path with brew info activemq .",
            "title": "Configure"
        },
        {
            "location": "/installation/source-macosx/#running-opencast",
            "text": "Make sure you have ActiveMQ running (unless you're running it on a different machine). Then you can start Opencast using\nthe start-opencast script:  activemq start\ncd /your/path/to/opencast/\ncd build/opencast-dist-allinone-[\u2026]\n./bin/start-opencast  As soon as Opencast is completely started, browse to  http://localhost:8080  to get to the\nadministration interface.",
            "title": "Running Opencast"
        },
        {
            "location": "/installation/debs/",
            "text": "Install from Repository (Debian, Ubuntu)\n\n\nThere is a Debian software repository (DEB) available for Debian-based Linux distributions provided by Greg Logan, and\nhosted at University of Osnabr\u00fcck. This repository provides prebuilt Opencast installations, including all\n3rd-Party-Tools. Using this method, you do not have to compile the software by yourself, but you still need to configure\nit.\n\n\nIt may also be interesting for developers as all dependencies for Opencast usage, testing and development are provided\nby the Debian repository.\n\n\nAvailability\n\n\nNote that it may take some time (usually about two weeks after a new release is out) before the DEBs are available.\nWatch for announcements on list or just check which versions are available in the repository.\n\n\nCurrently Supported\n\n\n\n\nDebian 8/9 amd64\n\n\nUbuntu 16.04 amd64\n\n\n\n\nDebian 8 requires a manual OpenJDK install\n\n\n\n\n\n\nAdd jessie-backports to your sources, replacing the mirror URL with your local mirror:\n\n\necho \"deb http://[YOUR_MIRROR]/debian jessie-backports main\" | sudo tee /etc/apt/sources.list.d/jessie-backports.list\n\n\n\n\n\n\n\nUpdate your package listing\n\n\napt-get update\n\n\n\n\n\n\n\nInstall OpenJDK 8 from the backports\n\n\napt-get install -t jessie-backports openjdk-8-jre\n\n\n\n\n\n\n\n\n\nOther architectures like i386, i686, arm, \u2026 are not supported!\n\n\n\n\nRegistration\n\n\nBefore you can start you need to get an account for the repository. You will need the credentials that you get by mail\nafter the registration to successfully complete this manual. The placeholders \n[your_username]\n and \n[your_password]\n\nare used in this manual wherever the credentials are needed.\n\n\nPlease visit https://pkg.opencast.org\n\n\nActivate Repository\n\n\nFirst you have to install the necessary repositories so that your package manager can access them:\n\n\n\n\n\n\nEnsure https repositories are supported:\n\n\napt-get install apt-transport-https ca-certificates sudo\n\n\n\n\n\n\n\nAdd Opencast repository:\n\n\ncd /etc/apt/sources.list.d/\necho \"deb https://[YOUR_USERNAME]:[YOUR_PASSWORD]@pkg.opencast.org/debian stable/\" | sudo tee opencast.list\n\n\n\nIt might take some time after the release of a new Opencast version before the Debs are moved to the stable\nrepository. If you need the new release prior to its promotion to stable you can use the testing repository.\nNote that the testing repository is an additional repository and still requires the stable repository to be active.\n\n\ncd /etc/apt/sources.list.d/\necho \"deb https://[YOUR_USERNAME]:[YOUR_PASSWORD]@pkg.opencast.org/debian testing/\" | sudo tee opencast.list\n\n\n\n\n\n\n\nAdd the repository key to your apt keyring:\n\n\nwget -qO - https://pkg.opencast.org/gpgkeys/opencast-deb.key | sudo apt-key add -\n\n\n\n\n\n\n\nUpdate your package listing\n\n\napt-get update\n\n\n\n\n\n\n\nInstall Apache ActiveMQ\n\n\nThe Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be\ninstalled on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the\nthe normal software repositories for your distribution:\n\n\n    apt-get install activemq-dist\n\n\n\nA prepared configuration file for ActiveMQ can be found at \n/usr/share/opencast/docs/scripts/activemq/activemq.xml\n\n\nafter Opencast itself has been installed\n and should replace \n/etc/activemq/activemq.xml\n. For an all-in-one\ninstallation the following command should suffice:\n\n\ncp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml\n\n\n\nActiveMQ must be started \nprior to\n Opencast startup.\n\n\nMore information about how to properly set up ActiveMQ for Opencast can be found in the \nmessage broker configuration\ndocumentation\n.\n\n\nNote that most Debian based distributions also have activemq packaged by upstream package maintainers. These packages\nwill work, however the ActiveMQ configuration file will require modification to function correctly.\n\n\nInstall Opencast\n\n\nFor this guide we will be installing the latest released version of Opencast 3.x, however if you wish to install another\nversion please change the name accordingly.\n\n\nBasic Installation\n\n\nFor a basic installation (All-In-One) just run:\n\n\napt-get install opencast-3-allinone\n\n\n\nThis will install the default distribution of Opencast and all its dependencies, including the 3rd-Party-Tools.  Note\nthat while the repository provides a packaged version of ffmpeg, your distribution may have a version which is\npre-installed or otherwise takes precedence.  This version may work, however Opencast only formally supports the\nversion(s) in the repository.\n\n\nAt this point Opencast is installed and will work locally, but it is not completely configured.  Please follow the\n\nBasic Configuration guide\n from here.  Once you are ready, start Opencast:\n\n\n\n\n\n\nOn a SysV-init based system\n\n\nservice opencast start\n\n\n\n\n\n\n\nOn a Systemd based system\n\n\nsystemctl start opencast.service\n\n\n\n\n\n\n\nAdvanced Installation\n\n\nWhile the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might\nwant to have more control over your system and deploy it over several machines by choosing which parts of Opencast you\nwant to install. You can list all Opencast packages with:\n\n\napt-cache search opencast\n\n\n\nThis will list all available Opencast distributions in the form \nopencast-<version>-<dist-type>\n\n\nSome available distributions are:\n\n\n\n\nopencast-X-allinone\n\n\nopencast-X-admin\n\n\nopencast-X-presentation\n\n\nopencast-X-worker\n\n\n\n\n\u2026where \nX\n stands for a specific Opencast version. These packages will install the latest release for a given version,\nso opencast-3-admin will install the admin profile for Opencast 3.x (currently 3.3). Once Opencast 3.4 has been packaged\nand made available your system will automatically update to Opencast 3.4 using the standard \napt-get\n tools.\n\n\nPoint Revisions (Experts only)\n\n\nIf for some reason you wish to install a specific point revision of Opencast, and the repository still hosts that point\nrevision, you can select it by adding it, and the packaging build, to your \napt-get install\n line.  For example:\n\n\n    apt-get install opencast-3-admin=3.2-2\n\n\n\nInstalls an Opencast 3.2 admin node, using the second build of that series.  Not all series have more than a single build,\nand older point revisions may be removed once superceded, so please explore the repository prior to attempting this.\n\n\nInstall 3rd-party-tools\n\n\nThis step is optional and only recommended for those who want to build Opencast from source. If you install Opencast\nfrom the repository, all necessary dependencies will be installed automatically.\n\n\nYou can install all necessary 3rd-Party-Tools for Opencast like this:\n\n\napt-get install ffmpeg-dist tesseract-ocr sox hunspell synfig netcat\n\n\n\nUpgrading Major Versions\n\n\nWhile these packages will automatically upgrade you to the latest point version in a release series, they do not\nautomatically upgrade you to the latest major version. In other words, if you install \nopencast3-admin\n you get the\nlatest 3.x release, not the latest 4.x release. To upgrade from one version to another you first stop Opencast:\n\n\n\n\n\n\nOn a SysV-init based system\n\n\nservice opencast stop\n\n\n\n\n\n\n\nOn a Systemd based system\n\n\nsystemctl stop opencast.service\n\n\n\n\n\n\n\nAs a reminder, these instructions will change your Opencast installation, and files to a new version which is likely\nincompatible with older versions. If you are performing this on a production system, please ensure you have valid\nbackups prior to taking the next steps.\n\n\nUninstall your current Opencast packaging (using Opencast 3 as an example):\n\n\napt-get remove opencast-3-*\n\n\n\nThen install the new version (using Opencast 4 as an example):\n\n\napt-get install opencast-4-allinone\n\n\n\nAt this point you must follow the relevant \nupgrade\n instructions, prior to starting Opencast again.\n\n\nUninstall Opencast\n\n\nTo uninstall Opencast, you can run:\n\n\napt-get remove 'opencast*'\n\n\n\nThis will not touch your created media files or modified configuration files.  If you want to remove them as well, you\nhave to do that by yourself.\n\n\n# Remove media files\nsudo rm -rf /srv/opencast\n\n# Remove local db, search indexes and working files\nsudo rm -rf /var/lib/opencast\n\n# Remove configuration files\nsudo rm -rf /etc/opencast\n\n# Remove logs\nsudo rm -rf /var/log/opencast\n\n\n\nTroubleshooting\n\n\nMissing Dependencies\n\n\nThis repository expects that the \nstable\n section is always available, regardless of which version of Opencast you have\ninstalled.  The 3rd party tools (ActiveMQ, FFmpeg) may or may not be in the other sections, but if they are there it is\nonly during a testing period for a new version.  For day-to-day use, please install them from \nstable\n!",
            "title": "Debian/Ubuntu"
        },
        {
            "location": "/installation/debs/#install-from-repository-debian-ubuntu",
            "text": "There is a Debian software repository (DEB) available for Debian-based Linux distributions provided by Greg Logan, and\nhosted at University of Osnabr\u00fcck. This repository provides prebuilt Opencast installations, including all\n3rd-Party-Tools. Using this method, you do not have to compile the software by yourself, but you still need to configure\nit.  It may also be interesting for developers as all dependencies for Opencast usage, testing and development are provided\nby the Debian repository.",
            "title": "Install from Repository (Debian, Ubuntu)"
        },
        {
            "location": "/installation/debs/#availability",
            "text": "Note that it may take some time (usually about two weeks after a new release is out) before the DEBs are available.\nWatch for announcements on list or just check which versions are available in the repository.",
            "title": "Availability"
        },
        {
            "location": "/installation/debs/#currently-supported",
            "text": "Debian 8/9 amd64  Ubuntu 16.04 amd64   Debian 8 requires a manual OpenJDK install    Add jessie-backports to your sources, replacing the mirror URL with your local mirror:  echo \"deb http://[YOUR_MIRROR]/debian jessie-backports main\" | sudo tee /etc/apt/sources.list.d/jessie-backports.list    Update your package listing  apt-get update    Install OpenJDK 8 from the backports  apt-get install -t jessie-backports openjdk-8-jre     Other architectures like i386, i686, arm, \u2026 are not supported!",
            "title": "Currently Supported"
        },
        {
            "location": "/installation/debs/#registration",
            "text": "Before you can start you need to get an account for the repository. You will need the credentials that you get by mail\nafter the registration to successfully complete this manual. The placeholders  [your_username]  and  [your_password] \nare used in this manual wherever the credentials are needed.  Please visit https://pkg.opencast.org",
            "title": "Registration"
        },
        {
            "location": "/installation/debs/#activate-repository",
            "text": "First you have to install the necessary repositories so that your package manager can access them:    Ensure https repositories are supported:  apt-get install apt-transport-https ca-certificates sudo    Add Opencast repository:  cd /etc/apt/sources.list.d/\necho \"deb https://[YOUR_USERNAME]:[YOUR_PASSWORD]@pkg.opencast.org/debian stable/\" | sudo tee opencast.list  It might take some time after the release of a new Opencast version before the Debs are moved to the stable\nrepository. If you need the new release prior to its promotion to stable you can use the testing repository.\nNote that the testing repository is an additional repository and still requires the stable repository to be active.  cd /etc/apt/sources.list.d/\necho \"deb https://[YOUR_USERNAME]:[YOUR_PASSWORD]@pkg.opencast.org/debian testing/\" | sudo tee opencast.list    Add the repository key to your apt keyring:  wget -qO - https://pkg.opencast.org/gpgkeys/opencast-deb.key | sudo apt-key add -    Update your package listing  apt-get update",
            "title": "Activate Repository"
        },
        {
            "location": "/installation/debs/#install-apache-activemq",
            "text": "The Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be\ninstalled on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the\nthe normal software repositories for your distribution:      apt-get install activemq-dist  A prepared configuration file for ActiveMQ can be found at  /usr/share/opencast/docs/scripts/activemq/activemq.xml  after Opencast itself has been installed  and should replace  /etc/activemq/activemq.xml . For an all-in-one\ninstallation the following command should suffice:  cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml  ActiveMQ must be started  prior to  Opencast startup.  More information about how to properly set up ActiveMQ for Opencast can be found in the  message broker configuration\ndocumentation .  Note that most Debian based distributions also have activemq packaged by upstream package maintainers. These packages\nwill work, however the ActiveMQ configuration file will require modification to function correctly.",
            "title": "Install Apache ActiveMQ"
        },
        {
            "location": "/installation/debs/#install-opencast",
            "text": "For this guide we will be installing the latest released version of Opencast 3.x, however if you wish to install another\nversion please change the name accordingly.",
            "title": "Install Opencast"
        },
        {
            "location": "/installation/debs/#basic-installation",
            "text": "For a basic installation (All-In-One) just run:  apt-get install opencast-3-allinone  This will install the default distribution of Opencast and all its dependencies, including the 3rd-Party-Tools.  Note\nthat while the repository provides a packaged version of ffmpeg, your distribution may have a version which is\npre-installed or otherwise takes precedence.  This version may work, however Opencast only formally supports the\nversion(s) in the repository.  At this point Opencast is installed and will work locally, but it is not completely configured.  Please follow the Basic Configuration guide  from here.  Once you are ready, start Opencast:    On a SysV-init based system  service opencast start    On a Systemd based system  systemctl start opencast.service",
            "title": "Basic Installation"
        },
        {
            "location": "/installation/debs/#advanced-installation",
            "text": "While the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might\nwant to have more control over your system and deploy it over several machines by choosing which parts of Opencast you\nwant to install. You can list all Opencast packages with:  apt-cache search opencast  This will list all available Opencast distributions in the form  opencast-<version>-<dist-type>  Some available distributions are:   opencast-X-allinone  opencast-X-admin  opencast-X-presentation  opencast-X-worker   \u2026where  X  stands for a specific Opencast version. These packages will install the latest release for a given version,\nso opencast-3-admin will install the admin profile for Opencast 3.x (currently 3.3). Once Opencast 3.4 has been packaged\nand made available your system will automatically update to Opencast 3.4 using the standard  apt-get  tools.",
            "title": "Advanced Installation"
        },
        {
            "location": "/installation/debs/#point-revisions-experts-only",
            "text": "If for some reason you wish to install a specific point revision of Opencast, and the repository still hosts that point\nrevision, you can select it by adding it, and the packaging build, to your  apt-get install  line.  For example:      apt-get install opencast-3-admin=3.2-2  Installs an Opencast 3.2 admin node, using the second build of that series.  Not all series have more than a single build,\nand older point revisions may be removed once superceded, so please explore the repository prior to attempting this.",
            "title": "Point Revisions (Experts only)"
        },
        {
            "location": "/installation/debs/#install-3rd-party-tools",
            "text": "This step is optional and only recommended for those who want to build Opencast from source. If you install Opencast\nfrom the repository, all necessary dependencies will be installed automatically.  You can install all necessary 3rd-Party-Tools for Opencast like this:  apt-get install ffmpeg-dist tesseract-ocr sox hunspell synfig netcat",
            "title": "Install 3rd-party-tools"
        },
        {
            "location": "/installation/debs/#upgrading-major-versions",
            "text": "While these packages will automatically upgrade you to the latest point version in a release series, they do not\nautomatically upgrade you to the latest major version. In other words, if you install  opencast3-admin  you get the\nlatest 3.x release, not the latest 4.x release. To upgrade from one version to another you first stop Opencast:    On a SysV-init based system  service opencast stop    On a Systemd based system  systemctl stop opencast.service    As a reminder, these instructions will change your Opencast installation, and files to a new version which is likely\nincompatible with older versions. If you are performing this on a production system, please ensure you have valid\nbackups prior to taking the next steps.  Uninstall your current Opencast packaging (using Opencast 3 as an example):  apt-get remove opencast-3-*  Then install the new version (using Opencast 4 as an example):  apt-get install opencast-4-allinone  At this point you must follow the relevant  upgrade  instructions, prior to starting Opencast again.",
            "title": "Upgrading Major Versions"
        },
        {
            "location": "/installation/debs/#uninstall-opencast",
            "text": "To uninstall Opencast, you can run:  apt-get remove 'opencast*'  This will not touch your created media files or modified configuration files.  If you want to remove them as well, you\nhave to do that by yourself.  # Remove media files\nsudo rm -rf /srv/opencast\n\n# Remove local db, search indexes and working files\nsudo rm -rf /var/lib/opencast\n\n# Remove configuration files\nsudo rm -rf /etc/opencast\n\n# Remove logs\nsudo rm -rf /var/log/opencast",
            "title": "Uninstall Opencast"
        },
        {
            "location": "/installation/debs/#troubleshooting",
            "text": "",
            "title": "Troubleshooting"
        },
        {
            "location": "/installation/debs/#missing-dependencies",
            "text": "This repository expects that the  stable  section is always available, regardless of which version of Opencast you have\ninstalled.  The 3rd party tools (ActiveMQ, FFmpeg) may or may not be in the other sections, but if they are there it is\nonly during a testing period for a new version.  For day-to-day use, please install them from  stable !",
            "title": "Missing Dependencies"
        },
        {
            "location": "/installation/rpm-fedora/",
            "text": "Install from Repository (Fedora)\n\n\nThe Opencast RPM repository for Fedora has been discontinued since Fedora with RPMfusion now provides nearly all\nnecessary dependencies for Opencast. Use the following steps to install them, then continue with the \ninstallation from\nsource\n.\n\n\nThis guide is to be merged into the guide for the installation from source.\n\n\nAdd RPMfusion repository\n\n\nRPMFusion\n is a community-driven RPM repository for Fedora. It provides tools like FFmpeg. You\ncan activate it using:\n\n\ndnf install --nogpgcheck \\\n  http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm \\\n  http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm\n\n\n\nInstall 3rd-party-tools\n\n\nYou can install all necessary 3rd-Party-Tools for Opencast like this:\n\n\ndnf install maven ffmpeg tesseract hunspell sox synfig nmap-ncat\n\n\n\nFor additional Unicode tests run during the build process, you can also install:\n\n\ndnf install hunspell-de tesseract-langpack-deu\n\n\n\nInstall Apache ActiveMQ\n\n\nThe Apache ActiveMQ message broker is commonly installed on the same machine as Opencast for an all-in-one system. The\nversion of ActiveMQ shipped with Fedora is too old but you can use the \nActiveMQ-dist Copr RPM repository\n\n\n\nMake sure it is properly configured for Opencast. For more information about the setup, have a look at the\n\nmessage broker configuration documentation\n.\n\n\nInstall Opencast\n\n\nFor the installation of Opencast, please have a look at the \ninstallation from source documentation\n\n.",
            "title": "Fedora"
        },
        {
            "location": "/installation/rpm-fedora/#install-from-repository-fedora",
            "text": "The Opencast RPM repository for Fedora has been discontinued since Fedora with RPMfusion now provides nearly all\nnecessary dependencies for Opencast. Use the following steps to install them, then continue with the  installation from\nsource .  This guide is to be merged into the guide for the installation from source.",
            "title": "Install from Repository (Fedora)"
        },
        {
            "location": "/installation/rpm-fedora/#add-rpmfusion-repository",
            "text": "RPMFusion  is a community-driven RPM repository for Fedora. It provides tools like FFmpeg. You\ncan activate it using:  dnf install --nogpgcheck \\\n  http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm \\\n  http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm",
            "title": "Add RPMfusion repository"
        },
        {
            "location": "/installation/rpm-fedora/#install-3rd-party-tools",
            "text": "You can install all necessary 3rd-Party-Tools for Opencast like this:  dnf install maven ffmpeg tesseract hunspell sox synfig nmap-ncat  For additional Unicode tests run during the build process, you can also install:  dnf install hunspell-de tesseract-langpack-deu",
            "title": "Install 3rd-party-tools"
        },
        {
            "location": "/installation/rpm-fedora/#install-apache-activemq",
            "text": "The Apache ActiveMQ message broker is commonly installed on the same machine as Opencast for an all-in-one system. The\nversion of ActiveMQ shipped with Fedora is too old but you can use the  ActiveMQ-dist Copr RPM repository  Make sure it is properly configured for Opencast. For more information about the setup, have a look at the message broker configuration documentation .",
            "title": "Install Apache ActiveMQ"
        },
        {
            "location": "/installation/rpm-fedora/#install-opencast",
            "text": "For the installation of Opencast, please have a look at the  installation from source documentation .",
            "title": "Install Opencast"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/",
            "text": "Install from Repository (RedHat Enterprise Linux, CentOS, Scientific Linux)\n\n\nThere is an RPM software repository available for Red Hat-based Linux distributions provided by the University of\nOsnabr\u00fcck. This repository provides preconfigured Opencast installations, including all 3rd-Party-Tools. Using this\nmethod, you do not have to compile the software by yourself.\n\n\nIt may also be interesting for developers as all dependencies for Opencast usage, testing and development are provided\nby the RPM repository.\n\n\nAvailability\n\n\nNote that it may take some time (usually about two weeks after a new release is out) before the RPMs are available.\nWatch for announcements on list or just check which versions are available in the repository.\n\n\nCurrently Supported\n\n\n\n\nCentOS 7.x (x86_64)\n\n\nRed Hat Enterprise Linux 7.x (x86_64)\n\n\nScientific Linux 7.x (x86_64)\n\n\n\n\n\n\nOther architectures like i386, i686, arm, \u2026 are not supported!\n\n\n\n\nRegistration\n\n\nBefore you can start you need to get an account for the repository. You will need the credentials that you get by mail\nafter the registration to successfully complete this manual. The placeholders \n[your_username]\n and \n[your_password]\n\nare used in this manual wherever the credentials are needed.\n\n\nPlease visit https://pkg.opencast.org\n\n\nActivate Repository\n\n\nFirst you have to install the necessary repositories so that your package manager can access them:\n\n\n\n\n\n\nAdd Opencast repository:\n\n\ncd /etc/yum.repos.d\ncurl -O https://pkg.opencast.org/opencast.repo \\\n   -d os=el -d version=7 -u [YOUR_USERNAME]\n\n\n\nYou will be asked for your password.\n\n\nIt might take some time after the release of a new Opencast version before the RPMs are moved to the stable\nrepository. Until then, you can use \n.../opencast-testing.repo\n instead to get the latest version. Note that the\ntesting repository is an additional repository and still requires the stable repository to be active.\n\n\n\n\n\n\nAdd the Extra Packages for Enterprise Linux (EPEL) repository:\n\n\nyum install epel-release\n\n\n\nIf this package is not available, please enable this repository manually. For that, follow the \ninstructions in the\nEPEL documentation\n.\n\n\n\n\n\n\nInstall Apache ActiveMQ\n\n\nThe Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be\ninstalled on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the\nOpencast RPM repository as well and can be installed by running:\n\n\nyum install activemq-dist\n\n\n\nA prepared configuration file for ActiveMQ can be found at \n/usr/share/opencast/docs/scripts/activemq/activemq.xml\n\n\nafter Opencast itself has been installed\n and should replace \n/etc/activemq/activemq.xml\n. For an all-in-one\ninstallation the following command should suffice:\n\n\ncp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml\n\n\n\nActiveMQ should be started \nprior to\n Opencast.\n\n\nMore information about how to properly set up ActiveMQ for Opencast can be found in the \nmessage broker configuration\ndocumentation\n.\n\n\nInstall Opencast\n\n\nFor this guide, \nopencast3-*\n is used as placeholder for the package name. It will install the latest version of the\nOpencast 3.x branch. If you want to install another version, please change the name accordingly.\n\n\nBasic Installation\n\n\nFor a basic installation (All-In-One) just run:\n\n\nyum install opencast3-allinone\n\n\n\nThis will install the default distribution of Opencast and all its dependencies, including the 3rd-Party-Tools.\n\n\nNow you can start Opencast:\n\n\n\n\n\n\nOn a SysV-init based system\n\n\nservice opencast start\n\n\n\n\n\n\n\nOn a Systemd based system\n\n\nsystemctl start opencast.service\n\n\n\n\n\n\n\nWhile Opencast is preconfigured, it is strongly recommended to follow at least the \nBasic Configuration\nguide\n. It will help you to set your hostname, login information, \u2026\n\n\nAdvanced Installation\n\n\nWhile the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might\nwant to have more control over your system and deploy it over several machines by choosing which parts of Opencast you\nwant to install. You can list all Opencast packages with:\n\n\nyum search opencast\n\n\n\nThis will list all available Opencast distributions in the form \nopencast<version>-<dist-type>\n\n\nSome available distributions are:\n\n\n\n\nopencastX-allinone\n\n\nopencastX-admin\n\n\nopencastX-presentation\n\n\nopencastX-worker\n\n\n\n\n\u2026where \nX\n stands for a specific Opencast version.\n\n\nInstall 3rd-party-tools\n\n\nThis step is optional and only recommended for those who want to build Opencast from source. If you install Opencast\nfrom the repository, all necessary dependencies will be installed automatically.\n\n\nYou can install all necessary 3rd-Party-Tools for Opencast like this:\n\n\nyum install ffmpeg tesseract hunspell sox synfig nmap-ncat\n\n\n\nUpgrading Major Versions\n\n\nWhile these packages will automatically upgrade you to the latest point version in a release series, they do not\nautomatically upgrade you to the latest major version. In other words, if you install \nopencast3-admin\n you get the\nlatest 3.x release, not the latest 4.x release. To upgrade from one version to another you first stop Opencast:\n\n\n\n\n\n\nOn a SysV-init based system\n\n\nservice opencast stop\n\n\n\n\n\n\n\nOn a Systemd based system\n\n\nsystemctl stop opencast.service\n\n\n\n\n\n\n\nAs a reminder, these instructions will change your Opencast installation, and files to a new version which is likely\nincompatible with older versions. If you are performing this on a production system, please ensure you have valid\nbackups prior to taking the next steps.\n\n\nUninstall your current Opencast packaging (using Opencast 3 as an example):\n\n\nyum remove opencast3-*\n\n\n\nThen install the new version (using Opencast 4 as an example):\n\n\nyum install opencast4-allinone\n\n\n\nAt this point you must follow the relevant \nupgrade\n instructions, prior to starting Opencast again.\n\n\nUninstall Opencast\n\n\nTo uninstall Opencast, you can run:\n\n\nyum remove 'opencast*'\n\n\n\nThis will not touch your created media files or modified configuration files.  If you want to remove them as well, you\nhave to do that by yourself.\n\n\n# Remove media files\nsudo rm -rf /srv/opencast\n\n# Remove local db, search indexes and working files\nsudo rm -rf /var/lib/opencast\n\n# Remove configuration files\nsudo rm -rf /etc/opencast\n\n# Remove logs\nsudo rm -rf /var/log/opencast\n\n\n\nTroubleshooting\n\n\nMissing Dependencies\n\n\nIf you try to install Opencast but yum is complaining about missing dependencies, please check if the epel repository is\nreally activated on your system. Some distributions come with epel preinstalled but disabled. The installation of the\nepel-release package will not fix this. You can check what repositories are installed and enabled by executing \nyum\nrepolist enabled\n which should give you a list with epel, opencast and opencast-noarch in it. To enable a repository,\nedit the configuration file in \n/etc/yum.repos.d/\n.",
            "title": "RHEL/CentOS"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#install-from-repository-redhat-enterprise-linux-centos-scientific-linux",
            "text": "There is an RPM software repository available for Red Hat-based Linux distributions provided by the University of\nOsnabr\u00fcck. This repository provides preconfigured Opencast installations, including all 3rd-Party-Tools. Using this\nmethod, you do not have to compile the software by yourself.  It may also be interesting for developers as all dependencies for Opencast usage, testing and development are provided\nby the RPM repository.",
            "title": "Install from Repository (RedHat Enterprise Linux, CentOS, Scientific Linux)"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#availability",
            "text": "Note that it may take some time (usually about two weeks after a new release is out) before the RPMs are available.\nWatch for announcements on list or just check which versions are available in the repository.",
            "title": "Availability"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#currently-supported",
            "text": "CentOS 7.x (x86_64)  Red Hat Enterprise Linux 7.x (x86_64)  Scientific Linux 7.x (x86_64)    Other architectures like i386, i686, arm, \u2026 are not supported!",
            "title": "Currently Supported"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#registration",
            "text": "Before you can start you need to get an account for the repository. You will need the credentials that you get by mail\nafter the registration to successfully complete this manual. The placeholders  [your_username]  and  [your_password] \nare used in this manual wherever the credentials are needed.  Please visit https://pkg.opencast.org",
            "title": "Registration"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#activate-repository",
            "text": "First you have to install the necessary repositories so that your package manager can access them:    Add Opencast repository:  cd /etc/yum.repos.d\ncurl -O https://pkg.opencast.org/opencast.repo \\\n   -d os=el -d version=7 -u [YOUR_USERNAME]  You will be asked for your password.  It might take some time after the release of a new Opencast version before the RPMs are moved to the stable\nrepository. Until then, you can use  .../opencast-testing.repo  instead to get the latest version. Note that the\ntesting repository is an additional repository and still requires the stable repository to be active.    Add the Extra Packages for Enterprise Linux (EPEL) repository:  yum install epel-release  If this package is not available, please enable this repository manually. For that, follow the  instructions in the\nEPEL documentation .",
            "title": "Activate Repository"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#install-apache-activemq",
            "text": "The Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be\ninstalled on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the\nOpencast RPM repository as well and can be installed by running:  yum install activemq-dist  A prepared configuration file for ActiveMQ can be found at  /usr/share/opencast/docs/scripts/activemq/activemq.xml  after Opencast itself has been installed  and should replace  /etc/activemq/activemq.xml . For an all-in-one\ninstallation the following command should suffice:  cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml  ActiveMQ should be started  prior to  Opencast.  More information about how to properly set up ActiveMQ for Opencast can be found in the  message broker configuration\ndocumentation .",
            "title": "Install Apache ActiveMQ"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#install-opencast",
            "text": "For this guide,  opencast3-*  is used as placeholder for the package name. It will install the latest version of the\nOpencast 3.x branch. If you want to install another version, please change the name accordingly.",
            "title": "Install Opencast"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#basic-installation",
            "text": "For a basic installation (All-In-One) just run:  yum install opencast3-allinone  This will install the default distribution of Opencast and all its dependencies, including the 3rd-Party-Tools.  Now you can start Opencast:    On a SysV-init based system  service opencast start    On a Systemd based system  systemctl start opencast.service    While Opencast is preconfigured, it is strongly recommended to follow at least the  Basic Configuration\nguide . It will help you to set your hostname, login information, \u2026",
            "title": "Basic Installation"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#advanced-installation",
            "text": "While the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might\nwant to have more control over your system and deploy it over several machines by choosing which parts of Opencast you\nwant to install. You can list all Opencast packages with:  yum search opencast  This will list all available Opencast distributions in the form  opencast<version>-<dist-type>  Some available distributions are:   opencastX-allinone  opencastX-admin  opencastX-presentation  opencastX-worker   \u2026where  X  stands for a specific Opencast version.",
            "title": "Advanced Installation"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#install-3rd-party-tools",
            "text": "This step is optional and only recommended for those who want to build Opencast from source. If you install Opencast\nfrom the repository, all necessary dependencies will be installed automatically.  You can install all necessary 3rd-Party-Tools for Opencast like this:  yum install ffmpeg tesseract hunspell sox synfig nmap-ncat",
            "title": "Install 3rd-party-tools"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#upgrading-major-versions",
            "text": "While these packages will automatically upgrade you to the latest point version in a release series, they do not\nautomatically upgrade you to the latest major version. In other words, if you install  opencast3-admin  you get the\nlatest 3.x release, not the latest 4.x release. To upgrade from one version to another you first stop Opencast:    On a SysV-init based system  service opencast stop    On a Systemd based system  systemctl stop opencast.service    As a reminder, these instructions will change your Opencast installation, and files to a new version which is likely\nincompatible with older versions. If you are performing this on a production system, please ensure you have valid\nbackups prior to taking the next steps.  Uninstall your current Opencast packaging (using Opencast 3 as an example):  yum remove opencast3-*  Then install the new version (using Opencast 4 as an example):  yum install opencast4-allinone  At this point you must follow the relevant  upgrade  instructions, prior to starting Opencast again.",
            "title": "Upgrading Major Versions"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#uninstall-opencast",
            "text": "To uninstall Opencast, you can run:  yum remove 'opencast*'  This will not touch your created media files or modified configuration files.  If you want to remove them as well, you\nhave to do that by yourself.  # Remove media files\nsudo rm -rf /srv/opencast\n\n# Remove local db, search indexes and working files\nsudo rm -rf /var/lib/opencast\n\n# Remove configuration files\nsudo rm -rf /etc/opencast\n\n# Remove logs\nsudo rm -rf /var/log/opencast",
            "title": "Uninstall Opencast"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#troubleshooting",
            "text": "",
            "title": "Troubleshooting"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#missing-dependencies",
            "text": "If you try to install Opencast but yum is complaining about missing dependencies, please check if the epel repository is\nreally activated on your system. Some distributions come with epel preinstalled but disabled. The installation of the\nepel-release package will not fix this. You can check what repositories are installed and enabled by executing  yum\nrepolist enabled  which should give you a list with epel, opencast and opencast-noarch in it. To enable a repository,\nedit the configuration file in  /etc/yum.repos.d/ .",
            "title": "Missing Dependencies"
        },
        {
            "location": "/installation/docker-local/",
            "text": "Testing Locally with Docker\n\n\nOpencast is a complex system that requires multiple steps to install and configure properly, which may be too\ncomplicated for quick, local testing. Therefore, the University of M\u00fcnster provides various Docker images for Opencast\nthat can simplify this process. The only requirement is an \nx86_64\n Linux system with a running Docker Engine.\n\n\nThis method is ideal for new adopters who just want to try out Opencast. It can also be used to test workflows. Because\nof the isolation that Docker provides, multiple instances of Opencast can run in parallel on a single system. This might\nbe helpful for developers.\n\n\nInstall Docker\n\n\nDocker is available for multiple Linux distributions. Please have a look at the \nofficial\ndocumentation\n for the latest installation instructions. Note that it\nmight be necessary to install \ndocker-compose\n separately.\n\n\nStart with docker-compose\n\n\nOpencast is packaged into multiple distributions. There is a separate Docker image for each distribution. Simple\ninstallations can use the all-in-one distribution.\n\n\nOpencast requires a database and a message broker (Apache ActiveMQ). We currently support H2 or MySQL/MariaDB databases.\nThe Docker Hub repository has official Docker images for MySQL and MariaDB. H2 is already integrated into Opencast so\nthat no database container is needed. There are multiple 3rd-party Docker images for ActiveMQ; this guide uses\n\nwebcenter/activemq\n.\n\n\ndocker-compose\n can be used to configure, start and connect all services automatically. The \nopencast-docker\nrepository\n contains multiple configuration\nexamples:\n\n\n\n\n\n\n\n\nConfiguration\n\n\nCompose file\n\n\n\n\n\n\n\n\n\n\nall-in-one + H2\n\n\nhttps://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.h2.yml\n\n\n\n\n\n\nall-in-one + MariaDB\n\n\nhttps://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.mariadb.yml\n\n\n\n\n\n\nadmin, presentation, worker + MariaDB\n\n\nhttps://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.multiserver.mariadb.yml\n\n\n\n\n\n\n\n\nChoose and download a configuration:\n\n\n$ curl -o docker-compose.yml <URL>\n\n\n\n\nYou might want to edit the compose file and add extra volumes to include custom configurations or workflows (see\n\ncompose file reference\n).\n\n\nThe compose files assume that the ActiveMQ configuration is located at \n./assets/activemq.xml\n. Additionally, if you use\nMariaDB, the SQL DDL commands for the Opencast database must be available at \n./assets/opencast-ddl.sql\n. You can\ndownload both files from the repository:\n\n\n$ mkdir assets\n$ curl -o assets/activemq.xml https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/assets/activemq.xml\n$ curl -o assets/opencast-ddl.sql https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/assets/opencast-ddl.sql\n\n\n\n\nAlternatively, you can use the Docker images to generate these files. This has the advantage that the correct version is\nalways used:\n\n\n$ mkdir assets\n\n$ docker run -it --rm \\\n    quay.io/opencast/allinone:<version> \\\n    app:print:activemq.xml > assets/activemq.xml\n\n$ docker run -it --rm \\\n    -e ORG_OPENCASTPROJECT_DB_VENDOR=MySQL \\\n    quay.io/opencast/allinone:<version> \\\n    app:print:ddl > assets/opencast-ddl.sql\n\n\n\n\nAt this point you are ready to start Opencast with the \nup\n command:\n\n\n$ docker-compose up\n\n\n\n\nAfter downloading the necessary Docker images, \ndocker-compose\n should start all relevant services and you should see\nthe logging output. Alternatively, adding the \n-d\n flag will start Opencast in the background and hide the log messages.\nThe admin UI is available at \nhttp://localhost:8080\n.\n\n\nThe \ndown\n command will stop Opencast and remove the created Docker containers. All relevant Opencast files are still\npreserved in Docker volumes. To remove them as well, run \ndown -v\n instead.",
            "title": "Testing Locally"
        },
        {
            "location": "/installation/docker-local/#testing-locally-with-docker",
            "text": "Opencast is a complex system that requires multiple steps to install and configure properly, which may be too\ncomplicated for quick, local testing. Therefore, the University of M\u00fcnster provides various Docker images for Opencast\nthat can simplify this process. The only requirement is an  x86_64  Linux system with a running Docker Engine.  This method is ideal for new adopters who just want to try out Opencast. It can also be used to test workflows. Because\nof the isolation that Docker provides, multiple instances of Opencast can run in parallel on a single system. This might\nbe helpful for developers.",
            "title": "Testing Locally with Docker"
        },
        {
            "location": "/installation/docker-local/#install-docker",
            "text": "Docker is available for multiple Linux distributions. Please have a look at the  official\ndocumentation  for the latest installation instructions. Note that it\nmight be necessary to install  docker-compose  separately.",
            "title": "Install Docker"
        },
        {
            "location": "/installation/docker-local/#start-with-docker-compose",
            "text": "Opencast is packaged into multiple distributions. There is a separate Docker image for each distribution. Simple\ninstallations can use the all-in-one distribution.  Opencast requires a database and a message broker (Apache ActiveMQ). We currently support H2 or MySQL/MariaDB databases.\nThe Docker Hub repository has official Docker images for MySQL and MariaDB. H2 is already integrated into Opencast so\nthat no database container is needed. There are multiple 3rd-party Docker images for ActiveMQ; this guide uses webcenter/activemq .  docker-compose  can be used to configure, start and connect all services automatically. The  opencast-docker\nrepository  contains multiple configuration\nexamples:     Configuration  Compose file      all-in-one + H2  https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.h2.yml    all-in-one + MariaDB  https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.allinone.mariadb.yml    admin, presentation, worker + MariaDB  https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.multiserver.mariadb.yml     Choose and download a configuration:  $ curl -o docker-compose.yml <URL>  You might want to edit the compose file and add extra volumes to include custom configurations or workflows (see compose file reference ).  The compose files assume that the ActiveMQ configuration is located at  ./assets/activemq.xml . Additionally, if you use\nMariaDB, the SQL DDL commands for the Opencast database must be available at  ./assets/opencast-ddl.sql . You can\ndownload both files from the repository:  $ mkdir assets\n$ curl -o assets/activemq.xml https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/assets/activemq.xml\n$ curl -o assets/opencast-ddl.sql https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/assets/opencast-ddl.sql  Alternatively, you can use the Docker images to generate these files. This has the advantage that the correct version is\nalways used:  $ mkdir assets\n\n$ docker run -it --rm \\\n    quay.io/opencast/allinone:<version> \\\n    app:print:activemq.xml > assets/activemq.xml\n\n$ docker run -it --rm \\\n    -e ORG_OPENCASTPROJECT_DB_VENDOR=MySQL \\\n    quay.io/opencast/allinone:<version> \\\n    app:print:ddl > assets/opencast-ddl.sql  At this point you are ready to start Opencast with the  up  command:  $ docker-compose up  After downloading the necessary Docker images,  docker-compose  should start all relevant services and you should see\nthe logging output. Alternatively, adding the  -d  flag will start Opencast in the background and hide the log messages.\nThe admin UI is available at  http://localhost:8080 .  The  down  command will stop Opencast and remove the created Docker containers. All relevant Opencast files are still\npreserved in Docker volumes. To remove them as well, run  down -v  instead.",
            "title": "Start with docker-compose"
        },
        {
            "location": "/configuration/",
            "text": "Opencast Configuration Guides\n\n\nThese guides will help you to configure Opencast. If you are a first-time user, please make sure to at lease have a look\nat the \nbasic configuration guide\n.\n\n\nGeneral Configuration\n\n\n\n\nBasic Configuration\n\n\nDatabase Configuration\n\n\nHTTPS Configuration\n\n\nEncoding Profile Configuration\n\n\nLoad Configuration\n\n\nLog Configuration\n\n\nUser Statistics and Privacy Configuration\n\n\nMessage Broker Configuration\n\n\nMetadata Configuration\n\n\nManual Asset Upload Configuration\n\n\nMulti Tenancy Configuration\n\n\nAuthentication, Autorization and User Management\n\n\nCAS Security Configuration\n\n\nLDAP Authentication and Authorization (without CAS)\n\n\nMoodle User Provider\n\n\nSakai User Provider\n\n\nAuthentication and Authorization Infrastructure (AAI)\n\n\nAccess Control Lists\n\n\nStream Security\n\n\n\n\n\n\nWorkflow Configuration\n\n\nWorkflow Operation Handler\n\n\n\n\n\n\nExternal API Configuration\n\n\nOAI-PMH Configuration\n\n\nAdmin UI Configuration",
            "title": "Overview"
        },
        {
            "location": "/configuration/#opencast-configuration-guides",
            "text": "These guides will help you to configure Opencast. If you are a first-time user, please make sure to at lease have a look\nat the  basic configuration guide .",
            "title": "Opencast Configuration Guides"
        },
        {
            "location": "/configuration/#general-configuration",
            "text": "Basic Configuration  Database Configuration  HTTPS Configuration  Encoding Profile Configuration  Load Configuration  Log Configuration  User Statistics and Privacy Configuration  Message Broker Configuration  Metadata Configuration  Manual Asset Upload Configuration  Multi Tenancy Configuration  Authentication, Autorization and User Management  CAS Security Configuration  LDAP Authentication and Authorization (without CAS)  Moodle User Provider  Sakai User Provider  Authentication and Authorization Infrastructure (AAI)  Access Control Lists  Stream Security    Workflow Configuration  Workflow Operation Handler    External API Configuration  OAI-PMH Configuration  Admin UI Configuration",
            "title": "General Configuration"
        },
        {
            "location": "/configuration/basic/",
            "text": "Basic Configuration\n\n\nThis guide will help you to change the basic configuration settings which are required or at least strongly recommended\nfor each Opencast installation. This is basically what you should do, right after installing Opencast on your machine.\n\n\nAll settings are made to files, residing in the Opencast configuration directory. In most cases, that should be either\n\n/etc/opencast/custom.properties\n or \n/opt/opencast/etc/custom.properties\n. Edit the files, using the editor of your\nchoice, e.g.:\n\n\nvim /etc/opencast/custom.properties\n\n\n\nStep 1: Setting the Server URL\n\n\nBy default, only connections from the local machine are accepted by Opencast.  You want to change this if the system\nshould be accessible within a network.\n\n\nFirst, find the property \norg.opencastproject.server.url\n in your \ncustom.properties\n configuration file and set it to\nyour own domain name:\n\n\norg.opencastproject.server.url=http://example.com:8080\n\n\n\nNote:\n This value will be written to all generated mediapackages and thus cannot be changed easily for already\nprocessed media. At least not without an extra amount of work involving modifications to the database. That is why you\nshould think about this setting carefully.\n\n\nSecond, adjust the binding address in \norg.ops4j.pax.web.cfg\n. The binding address can be set to \n0.0.0.0\n for general\nnetwork access. The property to modify is:\n\n\norg.ops4j.pax.web.listening.addresses=127.0.0.1\n\n\n\nIt may be necessary to adjust the jetty http connector idleTimeout value for processing large files in some configurations.\nTo do so, uncomment this line in \norg.ops4j.pax.web.cfg\n:\n\n\norg.ops4j.pax.web.config.file=${karaf.etc}/jetty-opencast.xml\n\n\n\nand modify the host and if necessary port values in \njetty-opencast.xml\n to match the ops4j configuration:\n\n\n<Set name=\"host\">127.0.0.1</Set>\n\n\n\nStep 2: Setting the Login Details\n\n\nThere are two authentication methods for Opencast. HTTP Digest authentication and form-based authentication. Both\nmethods need a username and a password. Change the password for both! The important keys for this are:\n\n\n\n\norg.opencastproject.security.admin.user\n\n\nThe user for the administrative account. This is set to \nadmin\n by default.\n\n\n\n\n\n\norg.opencastproject.security.admin.pass\n\n\nThe password for the administrative account. This is set to \nopencast\n by default.\n\n\n\n\n\n\norg.opencastproject.security.digest.user\n\n\nThe user for the communication between Opencast nodes, as well as for capture agents. This is set to\n\nopencast_system_account\n by default.\n\n\n\n\n\n\norg.opencastproject.security.digest.pass\n\n\nThe password for the communication between Opencast nodes and capture agents. This is set to \nCHANGE_ME\n by default.\n\n\n\n\n\n\n\n\nNote:\n The digest credentials are also used for internal communication of Opencast servers. So these keys have to be\nset to the same value on each of you Opencast nodes (Core, Worker, Capture Agent, \u2026)\n\n\nStep 3: Change the default shutdown command\n\n\nKaraf provides a socket over wich you can send a shutdown command. The socket does not provide any kind of\nauthentication. Therefore anyone who obtains write access to this socket is able to shutdown karaf and everything\nthat runs on it. There is a default \nkaraf.shutdown.command\n defined in \ncustom.properties\n. Change this to something\nsecret.\n\n\nStep 4: Setting up Apache ActiveMQ Message Broker\n\n\nSince version 2.0, Opencast requires a running Apache ActiveMQ instance with a specific configuration.  The message\nbroker is mostly run on the admin server of Opencast but can be run separately. It needs to be started before Opencast.\nFor more details about the setup, have a look at the \nApache ActiveMQ configuration guide\n.\n\n\nStep 5: Database Configuration\n\n\nOpencast uses an integrated HSQL database by default. While you will find it perfectly functional, it has certain\ndrawbacks:\n\n\n\n\nIt is rather slow\n\n\nIt cannot be used for distributed set-ups\n\n\nUpgrading Opencast with this database is not possible\n\n\n\n\nFor testing, it is totally fine to keep the internal database, but you are highly encouraged to switch to a stand-alone\ndatabase for productional use. For more information about database configuration, have a look at the \nDatabase\nConfiguration\n section.\n\n\nStep 6: Setting the Storage Directory (optional)\n\n\nEven though it is not important for all systems \u2013 on test setups you can probably omit this \u2013 you will often want to set\nthe storage directory. This directory is used to store all media, metadata, \u2026 Often, an NFS mount is used for this. You\ncan set the directory by changing \norg.opencastproject.storage.dir\n like:\n\n\norg.opencastproject.storage.dir=/media/mhdatamount\n\n\n\nPlease keep in mind that the user running Opencast must have read/write permissions to the storage directory.",
            "title": "Basic"
        },
        {
            "location": "/configuration/basic/#basic-configuration",
            "text": "This guide will help you to change the basic configuration settings which are required or at least strongly recommended\nfor each Opencast installation. This is basically what you should do, right after installing Opencast on your machine.  All settings are made to files, residing in the Opencast configuration directory. In most cases, that should be either /etc/opencast/custom.properties  or  /opt/opencast/etc/custom.properties . Edit the files, using the editor of your\nchoice, e.g.:  vim /etc/opencast/custom.properties",
            "title": "Basic Configuration"
        },
        {
            "location": "/configuration/basic/#step-1-setting-the-server-url",
            "text": "By default, only connections from the local machine are accepted by Opencast.  You want to change this if the system\nshould be accessible within a network.  First, find the property  org.opencastproject.server.url  in your  custom.properties  configuration file and set it to\nyour own domain name:  org.opencastproject.server.url=http://example.com:8080  Note:  This value will be written to all generated mediapackages and thus cannot be changed easily for already\nprocessed media. At least not without an extra amount of work involving modifications to the database. That is why you\nshould think about this setting carefully.  Second, adjust the binding address in  org.ops4j.pax.web.cfg . The binding address can be set to  0.0.0.0  for general\nnetwork access. The property to modify is:  org.ops4j.pax.web.listening.addresses=127.0.0.1  It may be necessary to adjust the jetty http connector idleTimeout value for processing large files in some configurations.\nTo do so, uncomment this line in  org.ops4j.pax.web.cfg :  org.ops4j.pax.web.config.file=${karaf.etc}/jetty-opencast.xml  and modify the host and if necessary port values in  jetty-opencast.xml  to match the ops4j configuration:  <Set name=\"host\">127.0.0.1</Set>",
            "title": "Step 1: Setting the Server URL"
        },
        {
            "location": "/configuration/basic/#step-2-setting-the-login-details",
            "text": "There are two authentication methods for Opencast. HTTP Digest authentication and form-based authentication. Both\nmethods need a username and a password. Change the password for both! The important keys for this are:   org.opencastproject.security.admin.user  The user for the administrative account. This is set to  admin  by default.    org.opencastproject.security.admin.pass  The password for the administrative account. This is set to  opencast  by default.    org.opencastproject.security.digest.user  The user for the communication between Opencast nodes, as well as for capture agents. This is set to opencast_system_account  by default.    org.opencastproject.security.digest.pass  The password for the communication between Opencast nodes and capture agents. This is set to  CHANGE_ME  by default.     Note:  The digest credentials are also used for internal communication of Opencast servers. So these keys have to be\nset to the same value on each of you Opencast nodes (Core, Worker, Capture Agent, \u2026)",
            "title": "Step 2: Setting the Login Details"
        },
        {
            "location": "/configuration/basic/#step-3-change-the-default-shutdown-command",
            "text": "Karaf provides a socket over wich you can send a shutdown command. The socket does not provide any kind of\nauthentication. Therefore anyone who obtains write access to this socket is able to shutdown karaf and everything\nthat runs on it. There is a default  karaf.shutdown.command  defined in  custom.properties . Change this to something\nsecret.",
            "title": "Step 3: Change the default shutdown command"
        },
        {
            "location": "/configuration/basic/#step-4-setting-up-apache-activemq-message-broker",
            "text": "Since version 2.0, Opencast requires a running Apache ActiveMQ instance with a specific configuration.  The message\nbroker is mostly run on the admin server of Opencast but can be run separately. It needs to be started before Opencast.\nFor more details about the setup, have a look at the  Apache ActiveMQ configuration guide .",
            "title": "Step 4: Setting up Apache ActiveMQ Message Broker"
        },
        {
            "location": "/configuration/basic/#step-5-database-configuration",
            "text": "Opencast uses an integrated HSQL database by default. While you will find it perfectly functional, it has certain\ndrawbacks:   It is rather slow  It cannot be used for distributed set-ups  Upgrading Opencast with this database is not possible   For testing, it is totally fine to keep the internal database, but you are highly encouraged to switch to a stand-alone\ndatabase for productional use. For more information about database configuration, have a look at the  Database\nConfiguration  section.",
            "title": "Step 5: Database Configuration"
        },
        {
            "location": "/configuration/basic/#step-6-setting-the-storage-directory-optional",
            "text": "Even though it is not important for all systems \u2013 on test setups you can probably omit this \u2013 you will often want to set\nthe storage directory. This directory is used to store all media, metadata, \u2026 Often, an NFS mount is used for this. You\ncan set the directory by changing  org.opencastproject.storage.dir  like:  org.opencastproject.storage.dir=/media/mhdatamount  Please keep in mind that the user running Opencast must have read/write permissions to the storage directory.",
            "title": "Step 6: Setting the Storage Directory (optional)"
        },
        {
            "location": "/configuration/database/",
            "text": "Database Configuration\n\n\nOpencast ships with embedded JDBC drivers for the H2, MySQL and MariaDB databases. The built-in H2 database is used by\ndefault and needs no configuration, but it is strongly recommended to use MariaDB for production.\nperformance gain.\n\n\n\n\nNotice:\n H2 is neither supported for updates, nor for distributed systems. Use it for testing only!\n\n\n\n\nOther databases\n\n\nRunning Opencast with PostgreSQL should be possible and there is some community support for this. While it should work,\nthe support for this is unofficial and we cannot guarantee that every new feature is well tested on that platform.\n\n\nThe EclipseLink JPA implementation which is used in Opencast supports other databases as well and it should be\npossible to attach other database engines.\n\n\nSetting up MariaDB/MySQL\n\n\nRequirements\n\n\nBefore following this guide, you should have:\n\n\n\n\nInstalled the Opencast Core System\n\n\nFollowed the \nBasic Configuration instructions\n\n\n\n\nStep 0: Set-up MariaDB/MySQL\n\n\nThis step is not Opencast-specific and may be different depending on your scenario (e.g. if you want to have a dedicated\ndatabase server). It shall only be a guide for people with no experience setting up MariaDB/MySQL to help them get\nstarted.  MariaDB is used for this guide but if your distribution includes MySQL instead, the installation should be\nvery much the same.\n\n\nFirst, install the MariaDB server. On RedHat-based systems, use:\n\n\nyum install mariadb mariadb-server\n\n\n\nAfterward, start the server and set it up to start automatically after each reboot:\n\n\nsystemctl start mariadb.service\nsystemctl enable mariadb.service\n\n\n\nNow you have MariaDB running, but without a properly configured root account (no password, etc.) which might pose a\nsecurity risk. MariaDB includes a useful tool to secure your database server. You can launch it by executing (yes, it is\nstill called mysql\u2026):\n\n\nmysql_secure_installation\n\n\n\nIt will guide you through the steps of setting up a root account with password, etc.\n\n\nStep 1: Create an Opencast Database\n\n\nThe first step, if you have not already done this, is to create a database for Opencast. You can use the following SQL\ncode to to that. For executing the SQL, use the MariaDB/MySQL client (run \nmysql\n from your shell) or use a graphical\ntool like phpMyAdmin. For now, we will use the MySQL shell client and the default administrative (root) user. Launch the\nclient with:\n\n\nmysql -u root -p\n\n\n\nYou will be asked for the password of the user root. When logged in, you will end up in the MariaDB/MySQL shell.  Next,\ncreate a database called \nopencast\n by executing:\n\n\nCREATE DATABASE opencast CHARACTER SET utf8 COLLATE utf8_general_ci;\n\n\n\nThen create a user \nopencast\n with a password and grant it all necessary rights:\n\n\nGRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP,INDEX,TRIGGER,CREATE TEMPORARY TABLES ON opencast.*\n  TO 'opencast'@'localhost' IDENTIFIED BY 'opencast_password';\n\n\n\nYou can choose another name for the user and database and should use a different password.\n\n\nIn a distributed system, apart from \n'username'@'localhost'\n (which would allow access from the local machine only),\nyou should grant a external user access to the database by running the same command for a user like\n\n'username'@'10.0.1.%'\n, where the \n10.0.1.%\n specifies the IP range allowed to access the server with \n%\n being a\nwildcard for \"anything\". For more details on MariaDB/MySQL user creation have a look at any of the following links:\n\n\n\n\nMariaDB Reference Manual :: \nGRANT\n statement\n\n\nMySQL Reference Manual :: Adding User Accounts\n.\n\n\n\n\nFinally, leave the client and restart the database server to enable the new user(s):\n\n\nsystemctl restart mariadb.service\n\n\n\nStep 2: Set up the Database Structure\n\n\nTo set up the database structure you can (and should!) use the Opencast ddl scripts. You can find them in\n\n\u2026/docs/scripts/ddl/mysql5.sql\n or download them from GitHub.\n\n\nTo import the database structure using the MariaDB client, switch to the directory that contains the \nmysql5.sql\n file,\nrun the client with the user you created in the previous step (\n-u opencast\n) and switch to the database you want to use\n(e.g. \nopencast\n):\n\n\nmysql -u opencast -p opencast\n\n\n\nRun the ddl script:\n\n\nmysql> source mysql5.sql;\n\n\n\nAlternatively, you can import the script directly from the command line:\n\n\nmysql -u opencast -p opencast < \u2026/docs/scripts/ddl/mysql5.sql\n\n\n\nStep 3: Configure Opencast\n\n\nThe following changes must be made in \n\u2026/etc/custom.properties\n (\n/etc/opencast/custom.properties\n in a package\ninstallation).\n\n\n\n\n\n\nChange the following configuration key (uncomment if necessary):\n\n\norg.opencastproject.db.ddl.generation=false\n\n\n\nIf set to true, the database structure will be generated automatically. It works, but without all the database\noptimizations implemented in the DDL scripts used in the step 2. While convenient for development, you should never\nset this to \ntrue\n in a production environment.\n\n\n\n\n\n\nConfigure Opencast to use MariaDB/MySQL:\n\n\norg.opencastproject.db.vendor=MySQL\n\n\n\n\n\n\n\nConfigure Opencast to use the JDBC driver for MariaDB/MySQL:\n\n\norg.opencastproject.db.jdbc.driver=com.mysql.jdbc.Driver\n\n\n\n\n\n\n\nConfigure the host where Opencast should find the database (\nlocalhost\n) and the database name (\nopencast\n). Adjust\nthe names in this example to match your configuration:\n\n\norg.opencastproject.db.jdbc.url=jdbc:mysql://localhost/opencast\n\n\n\n\n\n\n\nConfigure the username and password which Opencast should use to access the database:\n\n\norg.opencastproject.db.jdbc.user=opencast\norg.opencastproject.db.jdbc.pass=opencast_password",
            "title": "Database"
        },
        {
            "location": "/configuration/database/#database-configuration",
            "text": "Opencast ships with embedded JDBC drivers for the H2, MySQL and MariaDB databases. The built-in H2 database is used by\ndefault and needs no configuration, but it is strongly recommended to use MariaDB for production.\nperformance gain.   Notice:  H2 is neither supported for updates, nor for distributed systems. Use it for testing only!",
            "title": "Database Configuration"
        },
        {
            "location": "/configuration/database/#other-databases",
            "text": "Running Opencast with PostgreSQL should be possible and there is some community support for this. While it should work,\nthe support for this is unofficial and we cannot guarantee that every new feature is well tested on that platform.  The EclipseLink JPA implementation which is used in Opencast supports other databases as well and it should be\npossible to attach other database engines.",
            "title": "Other databases"
        },
        {
            "location": "/configuration/database/#setting-up-mariadbmysql",
            "text": "",
            "title": "Setting up MariaDB/MySQL"
        },
        {
            "location": "/configuration/database/#requirements",
            "text": "Before following this guide, you should have:   Installed the Opencast Core System  Followed the  Basic Configuration instructions",
            "title": "Requirements"
        },
        {
            "location": "/configuration/database/#step-0-set-up-mariadbmysql",
            "text": "This step is not Opencast-specific and may be different depending on your scenario (e.g. if you want to have a dedicated\ndatabase server). It shall only be a guide for people with no experience setting up MariaDB/MySQL to help them get\nstarted.  MariaDB is used for this guide but if your distribution includes MySQL instead, the installation should be\nvery much the same.  First, install the MariaDB server. On RedHat-based systems, use:  yum install mariadb mariadb-server  Afterward, start the server and set it up to start automatically after each reboot:  systemctl start mariadb.service\nsystemctl enable mariadb.service  Now you have MariaDB running, but without a properly configured root account (no password, etc.) which might pose a\nsecurity risk. MariaDB includes a useful tool to secure your database server. You can launch it by executing (yes, it is\nstill called mysql\u2026):  mysql_secure_installation  It will guide you through the steps of setting up a root account with password, etc.",
            "title": "Step 0: Set-up MariaDB/MySQL"
        },
        {
            "location": "/configuration/database/#step-1-create-an-opencast-database",
            "text": "The first step, if you have not already done this, is to create a database for Opencast. You can use the following SQL\ncode to to that. For executing the SQL, use the MariaDB/MySQL client (run  mysql  from your shell) or use a graphical\ntool like phpMyAdmin. For now, we will use the MySQL shell client and the default administrative (root) user. Launch the\nclient with:  mysql -u root -p  You will be asked for the password of the user root. When logged in, you will end up in the MariaDB/MySQL shell.  Next,\ncreate a database called  opencast  by executing:  CREATE DATABASE opencast CHARACTER SET utf8 COLLATE utf8_general_ci;  Then create a user  opencast  with a password and grant it all necessary rights:  GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP,INDEX,TRIGGER,CREATE TEMPORARY TABLES ON opencast.*\n  TO 'opencast'@'localhost' IDENTIFIED BY 'opencast_password';  You can choose another name for the user and database and should use a different password.  In a distributed system, apart from  'username'@'localhost'  (which would allow access from the local machine only),\nyou should grant a external user access to the database by running the same command for a user like 'username'@'10.0.1.%' , where the  10.0.1.%  specifies the IP range allowed to access the server with  %  being a\nwildcard for \"anything\". For more details on MariaDB/MySQL user creation have a look at any of the following links:   MariaDB Reference Manual ::  GRANT  statement  MySQL Reference Manual :: Adding User Accounts .   Finally, leave the client and restart the database server to enable the new user(s):  systemctl restart mariadb.service",
            "title": "Step 1: Create an Opencast Database"
        },
        {
            "location": "/configuration/database/#step-2-set-up-the-database-structure",
            "text": "To set up the database structure you can (and should!) use the Opencast ddl scripts. You can find them in \u2026/docs/scripts/ddl/mysql5.sql  or download them from GitHub.  To import the database structure using the MariaDB client, switch to the directory that contains the  mysql5.sql  file,\nrun the client with the user you created in the previous step ( -u opencast ) and switch to the database you want to use\n(e.g.  opencast ):  mysql -u opencast -p opencast  Run the ddl script:  mysql> source mysql5.sql;  Alternatively, you can import the script directly from the command line:  mysql -u opencast -p opencast < \u2026/docs/scripts/ddl/mysql5.sql",
            "title": "Step 2: Set up the Database Structure"
        },
        {
            "location": "/configuration/database/#step-3-configure-opencast",
            "text": "The following changes must be made in  \u2026/etc/custom.properties  ( /etc/opencast/custom.properties  in a package\ninstallation).    Change the following configuration key (uncomment if necessary):  org.opencastproject.db.ddl.generation=false  If set to true, the database structure will be generated automatically. It works, but without all the database\noptimizations implemented in the DDL scripts used in the step 2. While convenient for development, you should never\nset this to  true  in a production environment.    Configure Opencast to use MariaDB/MySQL:  org.opencastproject.db.vendor=MySQL    Configure Opencast to use the JDBC driver for MariaDB/MySQL:  org.opencastproject.db.jdbc.driver=com.mysql.jdbc.Driver    Configure the host where Opencast should find the database ( localhost ) and the database name ( opencast ). Adjust\nthe names in this example to match your configuration:  org.opencastproject.db.jdbc.url=jdbc:mysql://localhost/opencast    Configure the username and password which Opencast should use to access the database:  org.opencastproject.db.jdbc.user=opencast\norg.opencastproject.db.jdbc.pass=opencast_password",
            "title": "Step 3: Configure Opencast"
        },
        {
            "location": "/configuration/https/",
            "text": "Serve Content Via HTTPS\n\n\nFor all production systems you want to enable HTTPS. To archieve that, you can either use an HTTP(S) proxy like Apache\nhttpd or Nginx (recommended) or enable HTTPS directly in Opencast.\n\n\n\n\nUsing Nginx to enable HTTPS\n\n\nEnable HTTPS directly in Opencast\n\n\n\n\nNote that introducing HTTPS will not automatically migrate old content. It may still use the previously configured HTTP\nprorocol. For a semi-automatic migration, please take a look at the following guide:\n\n\n\n\nMigrating old content to HTTPS\n\n\n\n\nGeneral Recommendations\n\n\nIt's hard to keep up with security (e.g. proper TLS configuration). That is why we recommend using a proxy like Nginx or\nApache as, due to their general popularity, it is usually much easier to find good configuration recommenations.\n\n\nThere are also a couple of great sites to test your final setup:\n\n\n\n\nObservatory by Mozilla\n\n\nQualys SSL Labs\n\n\n\n\nAdditionally, if you have no easy way of obtaining proper TLS certificates for your organization, please consider using\n\nLet\u2019s Encrypt\n instead of self-signed certificates.",
            "title": "Overview"
        },
        {
            "location": "/configuration/https/#serve-content-via-https",
            "text": "For all production systems you want to enable HTTPS. To archieve that, you can either use an HTTP(S) proxy like Apache\nhttpd or Nginx (recommended) or enable HTTPS directly in Opencast.   Using Nginx to enable HTTPS  Enable HTTPS directly in Opencast   Note that introducing HTTPS will not automatically migrate old content. It may still use the previously configured HTTP\nprorocol. For a semi-automatic migration, please take a look at the following guide:   Migrating old content to HTTPS",
            "title": "Serve Content Via HTTPS"
        },
        {
            "location": "/configuration/https/#general-recommendations",
            "text": "It's hard to keep up with security (e.g. proper TLS configuration). That is why we recommend using a proxy like Nginx or\nApache as, due to their general popularity, it is usually much easier to find good configuration recommenations.  There are also a couple of great sites to test your final setup:   Observatory by Mozilla  Qualys SSL Labs   Additionally, if you have no easy way of obtaining proper TLS certificates for your organization, please consider using Let\u2019s Encrypt  instead of self-signed certificates.",
            "title": "General Recommendations"
        },
        {
            "location": "/configuration/https/nginx/",
            "text": "Enable HTTPS using Nginx\n\n\nThis guide will help you to configure Nginx to act as HTTP(S) proxy for Opencast.\n\n\nOpencast Configuration\n\n\nMake sure to use \nhttps\n as protocol for \norg.opencastproject.server.url\n in \netc/custom.properties\n.\n\n\norg.opencastproject.server.url=https://example.opencast.org\n\n\n\n\nNo other configuration is required. Do not enable TLS in Opencast. Listen to local connections only. Both are the\ndefault settings.\n\n\nMinimal Set-up\n\n\n\n\nNote that this guide does not give any security advise but is meant to provide a minimal working example which works\nwell with Opencast.\n\n\n\n\nThe following configuration is an example for \n/etc/nginx/nginx.conf\n. Note that depending on your distributions\npackaging, often \nconf.d\n or \nsites-enabled\n directories are used. But since this is an Opencast only set-up (we do not\nuse the web server for anything else), we are just using the main configuration file.\n\n\nExplanations for the configuration directives are provided inline. Please make sure to replace \nexample.opencast.org\n\nwith your nodes domain name.\n\n\nThe main goals of this set-up are:\n\n\n\n\nAlways redirect to HTTPS\n\n\nProxy to Opencast and take care of TLS\n\n\nAvoid caching\n\n\n\n\n# Check your distributions default nginx.conf to make sure the first\n# configuration keys (up until the http section) make sense within your\n# distribution's set-up.\n\n# Defines user and group credentials used by worker processes. If group is\n# omitted, a group whose name equals that of user is used.\nuser    nginx;\n\n# Configures logging to `/var/log/\u2026`. Log level `error` is used by default.\nerror_log    /var/log/nginx/error.log;\n\n# Defines a file that will store the process ID of the main process. This needs\n# to match the Systemd unit file.\npid /run/nginx.pid;\n\nevents {\n    # Sets the maximum number of simultaneous connections that can be opened by\n    # a worker process.\n    worker_connections 1024;\n}\n\n###\n# What follows is the specific http(s) set-up for Opencast.\n##\n\nhttp {\n\n    # HTTP set-up\n    server {\n        listen 80;\n        listen [::]:80;\n        server_name example.opencast.org;\n\n        # Enforce HTTPS by redirecting requests\n        location / {\n            return 301 https://example.opencast.org$request_uri;\n        }\n    }\n\n    # HTTPS set-up\n    server {\n        listen      443 ssl http2;\n        listen [::]:443 ssl http2;\n        server_name example.opencast.org;\n\n        # Path to the TLS certificate and private key. In almost all cases, you\n        # need to provide intermediate certificates as well to ensure browsers\n        # get the whole certificate chain.\n        ssl_certificate_key /path/to/example.opencast.org.key;\n        ssl_certificate     /path/to/example.opencast.org.crt;\n\n        # Accept large ingests. There should be no limit since Opencast may get\n        # really large ingests.\n        client_max_body_size 0;\n\n        # Proxy configuration for Opencast\n        location / {\n\n            # Make sure to pass the real addresses as well as the fact that\n            # outwards we are using HTTPS to Opencast.\n            proxy_set_header        Host $host;\n            proxy_set_header        X-Real-IP $remote_addr;\n            proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header        X-Forwarded-Proto $scheme;\n\n            # Pass requests to this location. This expects Opencast to be\n            # running locally on port 8080 which should be the default set-up.\n            proxy_pass              http://127.0.0.1:8080;\n\n            # Make sure to redirect location headers to HTTPS. This is just a\n            # precaution and shouldn't strictly be necessary but it did prevent\n            # some issues in the past and it does not cost much performance.\n            proxy_redirect          http://$host https://$host;\n\n            # Do not buffer responses\n            proxy_buffering         off;\n\n            # Do not buffer requests\n            proxy_request_buffering off;\n        }\n    }\n}",
            "title": "Using Nginx"
        },
        {
            "location": "/configuration/https/nginx/#enable-https-using-nginx",
            "text": "This guide will help you to configure Nginx to act as HTTP(S) proxy for Opencast.",
            "title": "Enable HTTPS using Nginx"
        },
        {
            "location": "/configuration/https/nginx/#opencast-configuration",
            "text": "Make sure to use  https  as protocol for  org.opencastproject.server.url  in  etc/custom.properties .  org.opencastproject.server.url=https://example.opencast.org  No other configuration is required. Do not enable TLS in Opencast. Listen to local connections only. Both are the\ndefault settings.",
            "title": "Opencast Configuration"
        },
        {
            "location": "/configuration/https/nginx/#minimal-set-up",
            "text": "Note that this guide does not give any security advise but is meant to provide a minimal working example which works\nwell with Opencast.   The following configuration is an example for  /etc/nginx/nginx.conf . Note that depending on your distributions\npackaging, often  conf.d  or  sites-enabled  directories are used. But since this is an Opencast only set-up (we do not\nuse the web server for anything else), we are just using the main configuration file.  Explanations for the configuration directives are provided inline. Please make sure to replace  example.opencast.org \nwith your nodes domain name.  The main goals of this set-up are:   Always redirect to HTTPS  Proxy to Opencast and take care of TLS  Avoid caching   # Check your distributions default nginx.conf to make sure the first\n# configuration keys (up until the http section) make sense within your\n# distribution's set-up.\n\n# Defines user and group credentials used by worker processes. If group is\n# omitted, a group whose name equals that of user is used.\nuser    nginx;\n\n# Configures logging to `/var/log/\u2026`. Log level `error` is used by default.\nerror_log    /var/log/nginx/error.log;\n\n# Defines a file that will store the process ID of the main process. This needs\n# to match the Systemd unit file.\npid /run/nginx.pid;\n\nevents {\n    # Sets the maximum number of simultaneous connections that can be opened by\n    # a worker process.\n    worker_connections 1024;\n}\n\n###\n# What follows is the specific http(s) set-up for Opencast.\n##\n\nhttp {\n\n    # HTTP set-up\n    server {\n        listen 80;\n        listen [::]:80;\n        server_name example.opencast.org;\n\n        # Enforce HTTPS by redirecting requests\n        location / {\n            return 301 https://example.opencast.org$request_uri;\n        }\n    }\n\n    # HTTPS set-up\n    server {\n        listen      443 ssl http2;\n        listen [::]:443 ssl http2;\n        server_name example.opencast.org;\n\n        # Path to the TLS certificate and private key. In almost all cases, you\n        # need to provide intermediate certificates as well to ensure browsers\n        # get the whole certificate chain.\n        ssl_certificate_key /path/to/example.opencast.org.key;\n        ssl_certificate     /path/to/example.opencast.org.crt;\n\n        # Accept large ingests. There should be no limit since Opencast may get\n        # really large ingests.\n        client_max_body_size 0;\n\n        # Proxy configuration for Opencast\n        location / {\n\n            # Make sure to pass the real addresses as well as the fact that\n            # outwards we are using HTTPS to Opencast.\n            proxy_set_header        Host $host;\n            proxy_set_header        X-Real-IP $remote_addr;\n            proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header        X-Forwarded-Proto $scheme;\n\n            # Pass requests to this location. This expects Opencast to be\n            # running locally on port 8080 which should be the default set-up.\n            proxy_pass              http://127.0.0.1:8080;\n\n            # Make sure to redirect location headers to HTTPS. This is just a\n            # precaution and shouldn't strictly be necessary but it did prevent\n            # some issues in the past and it does not cost much performance.\n            proxy_redirect          http://$host https://$host;\n\n            # Do not buffer responses\n            proxy_buffering         off;\n\n            # Do not buffer requests\n            proxy_request_buffering off;\n        }\n    }\n}",
            "title": "Minimal Set-up"
        },
        {
            "location": "/configuration/https/opencast.only/",
            "text": "Enable HTTPS directly in Opencast\n\n\nIn \nopencast/etc/\n, use the \norg.ops4j.pax.web.cfg\n file for\nconfiguration:\n\n\n# ...\n\n# Whether Opencast itself should handle HTTPS traffic.\n# Even if you set this to 'false',you can still use an HTTP proxy to handle SSL.\norg.osgi.service.http.secure.enabled=true\n\n# The secure server port to use if running Opencast with HTTPS (as opposed to\n# a proxy handling HTTPS).\n# Note that we use the docker proxy for the port-mapping from 8843 from within\n# the container to 443 at the host\n# Don't run Opencast with root privileges, which is a security issue\norg.osgi.service.http.port.secure=8443\n\n# Path to the keystore file.\n# Use the Java `keytool` to generate this file.\n# Example:\n#   keytool -genkey -keyalg RSA -validity 365 -alias serverkey \\\n#     -keypass password -storepass password -keystore keystore.jks\norg.ops4j.pax.web.ssl.keystore=<path_to_keystore>\n\n# Password used for keystore integrity check.\norg.ops4j.pax.web.ssl.password=<the_keystore_password>\n\n# Password used for keystore.\norg.ops4j.pax.web.ssl.keypassword=<the_key_password>\n\n\n\n\nPort-Forwarding required\n\n\nNote that Opencast most likely can't bind to port 443. That's why you still\nneed to reverse-proxy or port-forward if you want to avoid URLs with port\nspecified like \nhttps://host:8443/\n which is technically perfectly okay but may\nconfuse users or may be perceived as \"ugly\".\n\n\nHere is a non-comprehensive lists of tools and methods which can be used for\nport forwarding:\n\n\nPort-Forwarding with iptables\n\n\nA rule like\n\n\niptables -A PREROUTING -t nat -i eth0 -p tcp --dport 443 -j REDIRECT --to-port 8443\n# Allow also localhost traffic to use :443\n# iptables -A OUTPUT -t nat -o lo -p tcp --dport 443 -j REDIRECT --to-port 8443\n\n\n\n\nshould do the job after replacing \neth0\n with the network interface your\nOpencast consumers will connect on. Note that you usually want to persist the\nrule.\n\n\nPort-Forwarding with docker(-proxy)\n\n\nWhen starting a container from an Opencast image, either insert a\ncommand line argument to docker run: \n-p 443:8443\n or add a \nports:\n\nin \ndocker-compose.yaml\n.\n\n\nPort-Forwarding with sniproxy\n\n\nSniproxy\n can be used as well,\nespecially if you have multiple servers running on the same machine that handle\nHTTPS individually (no termination proxy).\n\n\nuser, pidfile, error_log ...\n\nlisten 443 {\n    proto tls\n    table https_hosts\n    fallback 127.0.0.1:8443\n\n    access_log {\n        filename /var/log/sniproxy/https_access.log\n        priority notice\n    }\n}\n\ntable https_hosts {\n    .*\\.opencast\\.example\\.org 127.0.0.1:8443\n}\n\n\n\n\nCreating the keystore\n\n\nWhat you need, is the TLS private key and the certificate including the\nwhole chain between the root certificate, all intermediates and the\ncertificate itself.\n\n\nObtaining the certificate chain\n\n\nIf you only have the key and the certificate, I recommend\n\ncertificatechain.io\n or\n\ncert-chain-resolver\n.\nThe latter can be used as follows:\n\n\n# Obtain the chain for cert.pem and save it at opencast.chain.pem.tmp\n# The -s command switch includes the root certificate; this is not\n# mandatory and might add some overhead\ncert-chain-resolver -s -o \"opencast.chain.pem.tmp\" \"cert.pem\"\n\n# Verify the certificate using the chain\nopenssl verify -crl_download -crl_check -untrusted \"opencast.chain.pem.tmp\" \"cert.pem\"\n\n\n\n\nCreate the p12 keystore\n\n\nIf the private key (assumed to be \nkey.pem\n) is encrypted\n(password protected), issue the following command. Note that there\nare safer ways supplying the key's password to OpenSSL.\n\n\nopenssl pkcs12 \\\n        -export \\\n        -inkey \"key.pem\" \\\n        -passin \"pass:<the_keys_password>\" \\\n        -in \"opencast.chain.pem.tmp\" \\\n        -name \"serverkey\" \\\n        -out \"opencast.p12\" \\\n        -passout \"pass:<the_keystore_password>\"\n\n\n\n\nIn case the private key is not protected by password:\n\n\nopenssl pkcs12 \\\n        -export \\\n        -inkey \"key.pem\" \\\n        -in \"opencast.chain.pem.tmp\" \\\n        -name \"serverkey\" \\\n        -out \"opencast.p12\" \\\n        -passout \"pass:<the_keystore_password>\"\n\n\n\n\nImport the p12 keystore into a Java keystore:\n\n\nkeytool \\\n        -importkeystore \\\n        -srckeystore \"opencast.p12\" \\\n        -srcstoretype \"pkcs12\" \\\n        -srcstorepass \"<the_keystore_password>\" \\\n        -destkeystore \"keystore.jks\" \\\n        -storepass \"<the_keystore_password>\"\n# print out details about the JKS built\nkeytool \\\n        -keystore \"keystore.jks\" \\\n        -list \\\n        -destalias serverkey \\\n        -storepass \"<the_keystore_password>\"\n\n\n\n\nThere exists a shell script automating that task\n\n.\n\n\nDefault to HTTPS\n\n\nWhen finished, restarted and verified that HTTPS works as expected,\nyou can change Opencast's default URL to the HTTPS one.\n\n\nSet \norg.opencastproject.server.url\n to the  HTTPS-URL in\n\netc/custom.properties\n.\n\n\norg.opencastproject.server.url=https://opencast.example.com",
            "title": "Internal HTTPS"
        },
        {
            "location": "/configuration/https/opencast.only/#enable-https-directly-in-opencast",
            "text": "In  opencast/etc/ , use the  org.ops4j.pax.web.cfg  file for\nconfiguration:  # ...\n\n# Whether Opencast itself should handle HTTPS traffic.\n# Even if you set this to 'false',you can still use an HTTP proxy to handle SSL.\norg.osgi.service.http.secure.enabled=true\n\n# The secure server port to use if running Opencast with HTTPS (as opposed to\n# a proxy handling HTTPS).\n# Note that we use the docker proxy for the port-mapping from 8843 from within\n# the container to 443 at the host\n# Don't run Opencast with root privileges, which is a security issue\norg.osgi.service.http.port.secure=8443\n\n# Path to the keystore file.\n# Use the Java `keytool` to generate this file.\n# Example:\n#   keytool -genkey -keyalg RSA -validity 365 -alias serverkey \\\n#     -keypass password -storepass password -keystore keystore.jks\norg.ops4j.pax.web.ssl.keystore=<path_to_keystore>\n\n# Password used for keystore integrity check.\norg.ops4j.pax.web.ssl.password=<the_keystore_password>\n\n# Password used for keystore.\norg.ops4j.pax.web.ssl.keypassword=<the_key_password>",
            "title": "Enable HTTPS directly in Opencast"
        },
        {
            "location": "/configuration/https/opencast.only/#port-forwarding-required",
            "text": "Note that Opencast most likely can't bind to port 443. That's why you still\nneed to reverse-proxy or port-forward if you want to avoid URLs with port\nspecified like  https://host:8443/  which is technically perfectly okay but may\nconfuse users or may be perceived as \"ugly\".  Here is a non-comprehensive lists of tools and methods which can be used for\nport forwarding:",
            "title": "Port-Forwarding required"
        },
        {
            "location": "/configuration/https/opencast.only/#port-forwarding-with-iptables",
            "text": "A rule like  iptables -A PREROUTING -t nat -i eth0 -p tcp --dport 443 -j REDIRECT --to-port 8443\n# Allow also localhost traffic to use :443\n# iptables -A OUTPUT -t nat -o lo -p tcp --dport 443 -j REDIRECT --to-port 8443  should do the job after replacing  eth0  with the network interface your\nOpencast consumers will connect on. Note that you usually want to persist the\nrule.",
            "title": "Port-Forwarding with iptables"
        },
        {
            "location": "/configuration/https/opencast.only/#port-forwarding-with-docker-proxy",
            "text": "When starting a container from an Opencast image, either insert a\ncommand line argument to docker run:  -p 443:8443  or add a  ports: \nin  docker-compose.yaml .",
            "title": "Port-Forwarding with docker(-proxy)"
        },
        {
            "location": "/configuration/https/opencast.only/#port-forwarding-with-sniproxy",
            "text": "Sniproxy  can be used as well,\nespecially if you have multiple servers running on the same machine that handle\nHTTPS individually (no termination proxy).  user, pidfile, error_log ...\n\nlisten 443 {\n    proto tls\n    table https_hosts\n    fallback 127.0.0.1:8443\n\n    access_log {\n        filename /var/log/sniproxy/https_access.log\n        priority notice\n    }\n}\n\ntable https_hosts {\n    .*\\.opencast\\.example\\.org 127.0.0.1:8443\n}",
            "title": "Port-Forwarding with sniproxy"
        },
        {
            "location": "/configuration/https/opencast.only/#creating-the-keystore",
            "text": "What you need, is the TLS private key and the certificate including the\nwhole chain between the root certificate, all intermediates and the\ncertificate itself.",
            "title": "Creating the keystore"
        },
        {
            "location": "/configuration/https/opencast.only/#obtaining-the-certificate-chain",
            "text": "If you only have the key and the certificate, I recommend certificatechain.io  or cert-chain-resolver .\nThe latter can be used as follows:  # Obtain the chain for cert.pem and save it at opencast.chain.pem.tmp\n# The -s command switch includes the root certificate; this is not\n# mandatory and might add some overhead\ncert-chain-resolver -s -o \"opencast.chain.pem.tmp\" \"cert.pem\"\n\n# Verify the certificate using the chain\nopenssl verify -crl_download -crl_check -untrusted \"opencast.chain.pem.tmp\" \"cert.pem\"",
            "title": "Obtaining the certificate chain"
        },
        {
            "location": "/configuration/https/opencast.only/#create-the-p12-keystore",
            "text": "If the private key (assumed to be  key.pem ) is encrypted\n(password protected), issue the following command. Note that there\nare safer ways supplying the key's password to OpenSSL.  openssl pkcs12 \\\n        -export \\\n        -inkey \"key.pem\" \\\n        -passin \"pass:<the_keys_password>\" \\\n        -in \"opencast.chain.pem.tmp\" \\\n        -name \"serverkey\" \\\n        -out \"opencast.p12\" \\\n        -passout \"pass:<the_keystore_password>\"  In case the private key is not protected by password:  openssl pkcs12 \\\n        -export \\\n        -inkey \"key.pem\" \\\n        -in \"opencast.chain.pem.tmp\" \\\n        -name \"serverkey\" \\\n        -out \"opencast.p12\" \\\n        -passout \"pass:<the_keystore_password>\"",
            "title": "Create the p12 keystore"
        },
        {
            "location": "/configuration/https/opencast.only/#import-the-p12-keystore-into-a-java-keystore",
            "text": "keytool \\\n        -importkeystore \\\n        -srckeystore \"opencast.p12\" \\\n        -srcstoretype \"pkcs12\" \\\n        -srcstorepass \"<the_keystore_password>\" \\\n        -destkeystore \"keystore.jks\" \\\n        -storepass \"<the_keystore_password>\"\n# print out details about the JKS built\nkeytool \\\n        -keystore \"keystore.jks\" \\\n        -list \\\n        -destalias serverkey \\\n        -storepass \"<the_keystore_password>\"  There exists a shell script automating that task .",
            "title": "Import the p12 keystore into a Java keystore:"
        },
        {
            "location": "/configuration/https/opencast.only/#default-to-https",
            "text": "When finished, restarted and verified that HTTPS works as expected,\nyou can change Opencast's default URL to the HTTPS one.  Set  org.opencastproject.server.url  to the  HTTPS-URL in etc/custom.properties .  org.opencastproject.server.url=https://opencast.example.com",
            "title": "Default to HTTPS"
        },
        {
            "location": "/configuration/https/migration/",
            "text": "Migrating old content to HTTPS\n\n\nOpencast will not modify already published events. This means that old publications might still use HTTP as protocol if\nit was used before.  Re-processing or re-publishing will update the links but this may not be an option for larger\nmigrations. For that, the following steps might help.\n\n\n\n\nNote that you modify stored data directly without any safety nets usually provided by Opencast. You should understand\nwhat you are doing!\n\n\n\n\n\n\nBackup your database, and the Solr and Elasticsearch indexes.\n\n\nElasticsearch: \n{data}/index\n\n\nSolr: \n{data}/solr-indexes\n\n\n\n\n\n\nConfigure Opencast to use HTTPS and test your set-up with a new publication.\n\n\nPut all your nodes into maintenance mode or, at least, do not process any videos.\n\n\n\n\nUpdate the media packages:\n\n\nfind . -type f -name \"*.xml\" -exec \\\n  sed -i 's/http\\:\\/\\/oc-presentation\\.example\\.com\\:80/https:\\/\\/oc-presentation.example.com/g' {} +`\n\n\n\n\n\n\n\nUpdate database tables. Note that Opencast 5 did change the database table name prefix from \nmh\n to \noc\n:\n\n\nUPDATE opencast.oc_assets_snapshot\n   SET mediapackage_xml =\n   REPLACE( mediapackage_xml,\n            'http://oc-presentation.example.com:80',\n            'https://oc-presentation.example.com')\n   WHERE INSTR( mediapackage_xml,\n                'http://oc-presentation.example.com:80') > 0;\nUPDATE opencast.oc_search\n   SET mediapackage_xml =\n   REPLACE( mediapackage_xml,\n            'http://oc-presentation.example.com:80',\n            'https://oc-presentation.example.com')\n   WHERE INSTR( mediapackage_xml,\n                'http://oc-presentation.example.com:80') > 0;\n\n\n\n\n\n\n\nRebuild the Elasticsearch indices using the REST endpoint listed in the docs:\n   https://admin.opencast.example.com/docs.html?path=/admin-ng/index\n\n\n\n\nRemove the search service's Solr index. It usually is located at \nsolr-indexes/search\n but its location really\n   depends on \norg.opencastproject.solr.dir\n and \norg.opencastproject.search.solr.dir\n\n\nRebuild the Solr indices by re-starting your Opencast node running the search service (usually presentation).",
            "title": "Migrating old content to HTTPS"
        },
        {
            "location": "/configuration/https/migration/#migrating-old-content-to-https",
            "text": "Opencast will not modify already published events. This means that old publications might still use HTTP as protocol if\nit was used before.  Re-processing or re-publishing will update the links but this may not be an option for larger\nmigrations. For that, the following steps might help.   Note that you modify stored data directly without any safety nets usually provided by Opencast. You should understand\nwhat you are doing!    Backup your database, and the Solr and Elasticsearch indexes.  Elasticsearch:  {data}/index  Solr:  {data}/solr-indexes    Configure Opencast to use HTTPS and test your set-up with a new publication.  Put all your nodes into maintenance mode or, at least, do not process any videos.   Update the media packages:  find . -type f -name \"*.xml\" -exec \\\n  sed -i 's/http\\:\\/\\/oc-presentation\\.example\\.com\\:80/https:\\/\\/oc-presentation.example.com/g' {} +`    Update database tables. Note that Opencast 5 did change the database table name prefix from  mh  to  oc :  UPDATE opencast.oc_assets_snapshot\n   SET mediapackage_xml =\n   REPLACE( mediapackage_xml,\n            'http://oc-presentation.example.com:80',\n            'https://oc-presentation.example.com')\n   WHERE INSTR( mediapackage_xml,\n                'http://oc-presentation.example.com:80') > 0;\nUPDATE opencast.oc_search\n   SET mediapackage_xml =\n   REPLACE( mediapackage_xml,\n            'http://oc-presentation.example.com:80',\n            'https://oc-presentation.example.com')\n   WHERE INSTR( mediapackage_xml,\n                'http://oc-presentation.example.com:80') > 0;    Rebuild the Elasticsearch indices using the REST endpoint listed in the docs:\n   https://admin.opencast.example.com/docs.html?path=/admin-ng/index   Remove the search service's Solr index. It usually is located at  solr-indexes/search  but its location really\n   depends on  org.opencastproject.solr.dir  and  org.opencastproject.search.solr.dir  Rebuild the Solr indices by re-starting your Opencast node running the search service (usually presentation).",
            "title": "Migrating old content to HTTPS"
        },
        {
            "location": "/configuration/asset-manager/",
            "text": "Asset Manager Configuration\n\n\nHow can I use a different storage backend?\n\n\nConfigure an alternate storage backend, and then either use the REST endpoints or the\n\nMove Storage\n workflow operation as part of a workflow.  Note that\nthe REST endpoints trigger workflows, the workflow operation handlers are generally only useful as part of an automated\nstorage tiering system.\n\n\nREST Endpoints\n\n\nThe REST endpoints can be accessed from \n$server_url/assets/docs\n. The value of \n$server_url\n is set during\n\nbasic configuration\n. There is no other current user interface for storage tiering at this time.\n\n\nConfig Options\n\n\nFile System Based Asset Store\n\n\nConfigure the file system based asset store in \ncustom.properties\n.\n\n\n\n\norg.opencastproject.episode.rootdir\n\n   The path where the file system based asset store of the default implementation stores the assets. This key is optional.\n\n\norg.opencastproject.storage.dir\n\n  This is Opencast\u2019s general config key to configure the base path of everything storage related.\n  If no storage directory is configured explicitely, the file system based asset store will use\n  \n${org.opencastproject.storage.dir}/archive\n as its base path.",
            "title": "Asset Manager"
        },
        {
            "location": "/configuration/asset-manager/#asset-manager-configuration",
            "text": "",
            "title": "Asset Manager Configuration"
        },
        {
            "location": "/configuration/asset-manager/#how-can-i-use-a-different-storage-backend",
            "text": "Configure an alternate storage backend, and then either use the REST endpoints or the Move Storage  workflow operation as part of a workflow.  Note that\nthe REST endpoints trigger workflows, the workflow operation handlers are generally only useful as part of an automated\nstorage tiering system.",
            "title": "How can I use a different storage backend?"
        },
        {
            "location": "/configuration/asset-manager/#rest-endpoints",
            "text": "The REST endpoints can be accessed from  $server_url/assets/docs . The value of  $server_url  is set during basic configuration . There is no other current user interface for storage tiering at this time.",
            "title": "REST Endpoints"
        },
        {
            "location": "/configuration/asset-manager/#config-options",
            "text": "",
            "title": "Config Options"
        },
        {
            "location": "/configuration/asset-manager/#file-system-based-asset-store",
            "text": "Configure the file system based asset store in  custom.properties .   org.opencastproject.episode.rootdir \n   The path where the file system based asset store of the default implementation stores the assets. This key is optional.  org.opencastproject.storage.dir \n  This is Opencast\u2019s general config key to configure the base path of everything storage related.\n  If no storage directory is configured explicitely, the file system based asset store will use\n   ${org.opencastproject.storage.dir}/archive  as its base path.",
            "title": "File System Based Asset Store"
        },
        {
            "location": "/configuration/message-broker/",
            "text": "Message Broker Configuration\n\n\nSince version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user\ninterface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the\nadmin node).\n\n\nRequired Version\n\n\n\n\nActiveMQ 5.10 or above\n\n\n\n\nInstallation\n\n\n\n\nIf you use the Opencast package repository, simply install the \nactivemq-dist\n package.\n\n\nIf you are running RHEL, CentOS or Fedora you can use the \nActiveMQ-dist Copr RPM\n  repository\n\n\nNewer Debian based operating systems contain a sufficient new version, however the ActiveMQ configuration file will\n  require modification to function correctly.\n\n\nYou can download binary distributions from the \nApache ActiveMQ website\n\n\n\n\nConfiguration\n\n\nWhat you need to do:\n\n\n\n\nSet-up required message queues for Opencast\n\n\nPoint all your Opencast nodes to your message broker.\n\n\nConfigure authentication and access control\n\n\n\n\nThe first task is easy. Opencast comes with a ActiveMQ configuration file, located at\n\ndocs/scripts/activemq/activemq.xml\n (RPM repo: \n/usr/share/opencast/docs/scripts/activemq/activemq.xml\n). This file\nwill give you a basic configuration with all queues set-up and accepting connections from the local host over TCP port\n\n61616\n.\n\n\nReplacing the default ActiveMQ configuration with this file will already give you a fully functional ActiveMQ set-up for\nan all-in-one server. You will find the configuration in the usually locations, e.g. \n/etc/activemq/\n. On Debian you\nfirst need to activate or create a new ActiveMQ instance. For more details on that see\n\n/usr/share/doc/activemq/README.Debian\n.\n\n\nNote that the default configuration needs to be adjusted for distributed set-ups since:\n\n\n\n\nActiveMQ listens to localhost only (\nactivemq.xml\n)\n\n\nOpencast tries to connect to ActiveMQ locally (\ncustom.properties\n)\n\n\nNo password is set (\nactivemq.xml\n, \ncustom.properties\n)\n\n\n\n\nConnection\n\n\nThe ActiveMQ connection is configured in the \ncustom.properties\n. The default configuration points to a local\ninstallation of ActiveMQ. You can easily configure this to point somewhere else:\n\n\nactivemq.broker.url = failover://tcp://example.opencast.org:61616\n\n\n\nBind Host\n\n\nThe default configuration tells ActiveMQ to listen to \n127.0.0.1\n only. On a distributed system, you want to set this to\n\n0.0.0.0\n to listen to all hosts by changing the \ntransportConnector\n:\n\n\n<transportConnector name=\"openwire\" uri=\"tcp://127.0.0.1:61616?...\"/>\n\n\n\nUsername and Password\n\n\nActiveMQ can secure its message queues by requiring login credentials. This section will go through the steps of setting\nup a username and a password. Have a look at the \nActiveMQ security site\n for\ndetails about using alternative authentication and authorization providers.\n\n\nCreate ActiveMQ Admin User\n\n\nFirst, you need to create a new user that will have access to the queues. This is configured in the \nusers.properties\n\nconfiguration file in the configuration directory for ActiveMQ. It is a list of the format \nusername = password\n so, for\nexample, we could create a new admin user with the following file contents:\n\n\nadmin=password\n\n\n\nCreate ActiveMQ Admin Group\n\n\nThe next step is to provide a group that will have our user in it and will secure access to the message queues. This is\nconfigured in the file \ngroups.properties\n in the configuration directory for ActiveMQ. It is a list of the format\n\ngroup = user1,user2,\u2026\n. For example:\n\n\ngroups=user1,user2,user3\n\n\n\nTo set-up our new user to be a part of the admins group:\n\n\nadmins=admin\n\n\n\nConfigure Users and Groups Configuration Files\n\n\nNext, we need to make sure that ActiveMQ is using our \nusers.properties\n and \ngroups.properties\n files to authenticate\nand authorize users. The \nlogin.config\n file should be in the ActiveMQ configuration directory and contain:\n\n\nactivemq {\n    org.apache.activemq.jaas.PropertiesLoginModule required\n    org.apache.activemq.jaas.properties.user=\"users.properties\"\n    org.apache.activemq.jaas.properties.group=\"groups.properties\";\n};\n\n\n\nConfigure Message Broker Security\n\n\nThe final step to secure the ActiveMQ queues is to limit access to a specific group. This can be done by editing\n\nactivemq.xml\n in the ActiveMQ configuration directory. In this file, we need to add some XML in between these tags:\n\n\n<broker></broker>\n\n\n\nWe will add the following plugin configuration:\n\n\n<plugins>\n  <jaasAuthenticationPlugin configuration=\"activemq\" />\n  <authorizationPlugin>\n    <map>\n      <authorizationMap>\n        <authorizationEntries>\n          <authorizationEntry queue=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" />\n          <authorizationEntry topic=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" />\n          <authorizationEntry topic=\"ActiveMQ.Advisory.>\" read=\"admins\" write=\"admins\" admin=\"admins\"/>\n        </authorizationEntries>\n      </authorizationMap>\n    </map>\n  </authorizationPlugin>\n</plugins>\n\n\n\n\n\n\n\nThe \njaasAuthenticationPlugin\n configures the broker to use our \nlogin.config\n file for the authentication.\n\n\n<jaasAuthenticationPlugin configuration=\"activemq\" />\n\n\n\n\n\n\n\nThe property:\n\n\nconfiguration=activemq\n\n\n\n\n\n\n\nneeds to match the name given for surrounding object in \nlogin.config\n i.e. activemq{};\n\n\n\n\nThe \nauthorizationEntry\n restricts read, write and admin access for queues and topics to members of the group admins.\n\n\n\n\nConfigure Opencast to Connect with Username and Password to Message Broker\n\n\nNow that we have secured the queues, Opencast will complain that it is unable to connect, using the current username and\npassword. The username and password used above need to be added to the \ncustom.properties\n file of Opencast.  There are\ntwo properties to set:\n\n\nactivemq.broker.username=admin\nactivemq.broker.password=password\n\n\n\nFirewall\n\n\nDo not forget that ActiveMQ uses the TCP port 61616 (default configuration) for communication. You probably want to\nallow communication over this port in your firewall on a distributed setup or explicitly forbid public access on an\nall-in-one installation.\n\n\nMemory settings\n\n\nWhen ActiveMQ is under heavy load it may require additional RAM. There are two places to change this:\n\n\nIn \ndocs/scripts/activemq/activemq.xml\n:\n\n\n...\n<systemUsage>\n  <systemUsage>\n    <memoryUsage>\n      <!--<memoryUsage percentOfJvmHeap=\"70\" />-->\n      <memoryUsage limit=\"2048 MB\"/>\n...\n\n\n\nThis controls the allowed memory of ActiveMQ inside of its JVM instance. For more information see \nthe ActiveMQ\ndocumentation\n\n\nIn \n/usr/share/activemq/bin/env\n:\n\n\nACTIVEMQ_OPTS_MEMORY=\"-Xms64M -Xmx4G\"\n\n\n\nThese are the classic JVM minimum and maximum memory flags.",
            "title": "Message Broker"
        },
        {
            "location": "/configuration/message-broker/#message-broker-configuration",
            "text": "Since version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user\ninterface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the\nadmin node).",
            "title": "Message Broker Configuration"
        },
        {
            "location": "/configuration/message-broker/#required-version",
            "text": "ActiveMQ 5.10 or above",
            "title": "Required Version"
        },
        {
            "location": "/configuration/message-broker/#installation",
            "text": "If you use the Opencast package repository, simply install the  activemq-dist  package.  If you are running RHEL, CentOS or Fedora you can use the  ActiveMQ-dist Copr RPM\n  repository  Newer Debian based operating systems contain a sufficient new version, however the ActiveMQ configuration file will\n  require modification to function correctly.  You can download binary distributions from the  Apache ActiveMQ website",
            "title": "Installation"
        },
        {
            "location": "/configuration/message-broker/#configuration",
            "text": "What you need to do:   Set-up required message queues for Opencast  Point all your Opencast nodes to your message broker.  Configure authentication and access control   The first task is easy. Opencast comes with a ActiveMQ configuration file, located at docs/scripts/activemq/activemq.xml  (RPM repo:  /usr/share/opencast/docs/scripts/activemq/activemq.xml ). This file\nwill give you a basic configuration with all queues set-up and accepting connections from the local host over TCP port 61616 .  Replacing the default ActiveMQ configuration with this file will already give you a fully functional ActiveMQ set-up for\nan all-in-one server. You will find the configuration in the usually locations, e.g.  /etc/activemq/ . On Debian you\nfirst need to activate or create a new ActiveMQ instance. For more details on that see /usr/share/doc/activemq/README.Debian .  Note that the default configuration needs to be adjusted for distributed set-ups since:   ActiveMQ listens to localhost only ( activemq.xml )  Opencast tries to connect to ActiveMQ locally ( custom.properties )  No password is set ( activemq.xml ,  custom.properties )",
            "title": "Configuration"
        },
        {
            "location": "/configuration/message-broker/#connection",
            "text": "The ActiveMQ connection is configured in the  custom.properties . The default configuration points to a local\ninstallation of ActiveMQ. You can easily configure this to point somewhere else:  activemq.broker.url = failover://tcp://example.opencast.org:61616",
            "title": "Connection"
        },
        {
            "location": "/configuration/message-broker/#bind-host",
            "text": "The default configuration tells ActiveMQ to listen to  127.0.0.1  only. On a distributed system, you want to set this to 0.0.0.0  to listen to all hosts by changing the  transportConnector :  <transportConnector name=\"openwire\" uri=\"tcp://127.0.0.1:61616?...\"/>",
            "title": "Bind Host"
        },
        {
            "location": "/configuration/message-broker/#username-and-password",
            "text": "ActiveMQ can secure its message queues by requiring login credentials. This section will go through the steps of setting\nup a username and a password. Have a look at the  ActiveMQ security site  for\ndetails about using alternative authentication and authorization providers.",
            "title": "Username and Password"
        },
        {
            "location": "/configuration/message-broker/#create-activemq-admin-user",
            "text": "First, you need to create a new user that will have access to the queues. This is configured in the  users.properties \nconfiguration file in the configuration directory for ActiveMQ. It is a list of the format  username = password  so, for\nexample, we could create a new admin user with the following file contents:  admin=password",
            "title": "Create ActiveMQ Admin User"
        },
        {
            "location": "/configuration/message-broker/#create-activemq-admin-group",
            "text": "The next step is to provide a group that will have our user in it and will secure access to the message queues. This is\nconfigured in the file  groups.properties  in the configuration directory for ActiveMQ. It is a list of the format group = user1,user2,\u2026 . For example:  groups=user1,user2,user3  To set-up our new user to be a part of the admins group:  admins=admin",
            "title": "Create ActiveMQ Admin Group"
        },
        {
            "location": "/configuration/message-broker/#configure-users-and-groups-configuration-files",
            "text": "Next, we need to make sure that ActiveMQ is using our  users.properties  and  groups.properties  files to authenticate\nand authorize users. The  login.config  file should be in the ActiveMQ configuration directory and contain:  activemq {\n    org.apache.activemq.jaas.PropertiesLoginModule required\n    org.apache.activemq.jaas.properties.user=\"users.properties\"\n    org.apache.activemq.jaas.properties.group=\"groups.properties\";\n};",
            "title": "Configure Users and Groups Configuration Files"
        },
        {
            "location": "/configuration/message-broker/#configure-message-broker-security",
            "text": "The final step to secure the ActiveMQ queues is to limit access to a specific group. This can be done by editing activemq.xml  in the ActiveMQ configuration directory. In this file, we need to add some XML in between these tags:  <broker></broker>  We will add the following plugin configuration:  <plugins>\n  <jaasAuthenticationPlugin configuration=\"activemq\" />\n  <authorizationPlugin>\n    <map>\n      <authorizationMap>\n        <authorizationEntries>\n          <authorizationEntry queue=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" />\n          <authorizationEntry topic=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" />\n          <authorizationEntry topic=\"ActiveMQ.Advisory.>\" read=\"admins\" write=\"admins\" admin=\"admins\"/>\n        </authorizationEntries>\n      </authorizationMap>\n    </map>\n  </authorizationPlugin>\n</plugins>    The  jaasAuthenticationPlugin  configures the broker to use our  login.config  file for the authentication.  <jaasAuthenticationPlugin configuration=\"activemq\" />    The property:  configuration=activemq    needs to match the name given for surrounding object in  login.config  i.e. activemq{};   The  authorizationEntry  restricts read, write and admin access for queues and topics to members of the group admins.",
            "title": "Configure Message Broker Security"
        },
        {
            "location": "/configuration/message-broker/#configure-opencast-to-connect-with-username-and-password-to-message-broker",
            "text": "Now that we have secured the queues, Opencast will complain that it is unable to connect, using the current username and\npassword. The username and password used above need to be added to the  custom.properties  file of Opencast.  There are\ntwo properties to set:  activemq.broker.username=admin\nactivemq.broker.password=password",
            "title": "Configure Opencast to Connect with Username and Password to Message Broker"
        },
        {
            "location": "/configuration/message-broker/#firewall",
            "text": "Do not forget that ActiveMQ uses the TCP port 61616 (default configuration) for communication. You probably want to\nallow communication over this port in your firewall on a distributed setup or explicitly forbid public access on an\nall-in-one installation.",
            "title": "Firewall"
        },
        {
            "location": "/configuration/message-broker/#memory-settings",
            "text": "When ActiveMQ is under heavy load it may require additional RAM. There are two places to change this:  In  docs/scripts/activemq/activemq.xml :  ...\n<systemUsage>\n  <systemUsage>\n    <memoryUsage>\n      <!--<memoryUsage percentOfJvmHeap=\"70\" />-->\n      <memoryUsage limit=\"2048 MB\"/>\n...  This controls the allowed memory of ActiveMQ inside of its JVM instance. For more information see  the ActiveMQ\ndocumentation  In  /usr/share/activemq/bin/env :  ACTIVEMQ_OPTS_MEMORY=\"-Xms64M -Xmx4G\"  These are the classic JVM minimum and maximum memory flags.",
            "title": "Memory settings"
        },
        {
            "location": "/configuration/metadata/",
            "text": "Overview\n\n\nIn Opencast, metadata is stored in so-called metadata catalogs. For each event or series, an arbiraty number of\nsuch configurable metadata catalog can be managed. A common set of metadata has been standarized to form a\ncommon basis (standard metadata), whereas administrators can configure Opencast to support other metadata sets\n(extended metadata).\n\n\nThis document provides an overview over Opencast's metadata capabilities and its configuration.\n\n\nStandard Metadata\n\n\nFor both events and series, a common set of metadata is supported by Opencast out-of-the box. Since metadata catalogs\nare referenced from within media package, flavors can be used to identify a specific metadata catalog. The following\nflavors are treated by Opencast as standard metadata in means of Opencast expects them to be present:\n\n\n\n\ndublincore/episode\n holds the standard metadata of an event\n\n\ndublincore/series\n holds the standard metadata of a series\n\n\n\n\nOpencast assumes specific metadata fields to be present in the standard metadata in means of defining hard-coded\nfilters, table columns and search indices.\n\n\nTo adjust the standard metadata to your specific needs, you can configure them in\n\n/opt/opencast/etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg\n and\n\n/opt/opencast/etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common.cfg\n.\n\n\nFor details on how to configure metadata catalogs, see section Configuring Metadata Catalogs.\n\n\nAs mentioned above, however, Opencast expects specific metafields to be present to work correctly. In case you want\nto map metadata specific to your use case, you might consider to use the extended metadata capbilities of Opencast\ndescribed in the next section.\n\n\nExtended Metadata\n\n\nFor both events and series, Opencast support an arbitrary number of customized metadata catalogs.\n\n\nTo add extended metadata catalogs, create a configuration file with a valid filename of the form\n\norg.opencastproject.ui.metadata.CatalogUIAdapterFactory-<name>.cfg\n in \n/opt/opencast/etc.\n on the admin node.\n\n\nFor details on how to configure metadata catalogs, see section Configuring Metadata Catalogs.\n\n\nLimitations:\n\n\n\n\nCannot be sorted, searched or filtered\n\n\nCannot be displayed in tables\n\n\n\n\nMetadata Catalog Configuration\n\n\nThe metadata configuration file format can be logically split up into different parts:\n\n\nPart 1: General catalog information\n\n\n\n\n\n\n\n\nConfiguration key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntype\n\n\nevents\n\n\nTwo different types of catalog UI adapters may be configured, such for events and others for series.\n\n\n\n\n\n\norganization\n\n\nmh_default_org\n\n\nA custom catalog definition is mapped 1:1 to an organization and is available to this one organization only.\n\n\n\n\n\n\nflavor\n\n\nmycompany/episode\n\n\nThe catalog must be of a certain flavor. For a events catalog, the flavor consists of the form type/subtype whereas for series you only need to define the subtype. Attention: For series catalogs, the type (the part before the slash '/') is used as element type.\n\n\n\n\n\n\ntitle\n\n\nMy Personal Catalog Name\n\n\nThis is the title that is displayed in the UI. It should be something that is readable by humans.\n\n\n\n\n\n\n\n\nPart 2: XML serialization information\n\n\nThe only supported serialization of catalogs is currently the XML file format. The file follows the recommendation of\nthe Dublin Core Metadata Initiative.\n\n\n\n\n\n\n\n\nConfiguration key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nxml.rootElement.name\n\n\nmycatalog\n\n\nThe name of the XML root element\n\n\n\n\n\n\nxml.rootElement.namespace.URI\n\n\nhttp://myorg.com/metadata/catalog\n\n\nThe URI of the XML namespace of the root element\n\n\n\n\n\n\n\n\nNamespace bindings\n\n\nTo properly serialize to XML each prefix has to be bound to an XML namespace. Multiple namespace bindings can be\nconfigured, each identified by its unique name.\n\n\n\n\n\n\n\n\nConfiguration key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nxml.namespaceBinding.{name}.URI\n\n\nhttp://myorg.com/metadata/terms\n\n\nThe URI of the XML namespace\n\n\n\n\n\n\nxml.namespaceBinding.{name}.prefix\n\n\nmyterms\n\n\nThe prefix used to identify elements of the namespace\n\n\n\n\n\n\n\n\nPart 3: Catalog fields configuration\n\n\n{field-id}\n must be a unique identifier for each property for a given catalog and can be the same as the input or\noutput id to make it easy to find.\n\n\n\n\n\n\n\n\nConfiguration key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nproperty.{field-id}.inputID*\n\n\ntitle\n\n\nThe id used to identify this property in the catalog e.g. The name of the property inside the xml file of a Dublin Core catalog. If an outputID is not specified then this inputID is used for both the catalog and the front end id. This value is mandatory.\n\n\n\n\n\n\nproperty.{field-id}.outputID\n\n\ntitle\n\n\nThe id used inside the json for this property. If this value is missing then the inputID will be used instead.\n\n\n\n\n\n\nproperty.{field-id}.namespace\n\n\nhttp://purl.org/dc/terms/\n\n\nThe URL that represents the namespace for this property. Different properties in the same catalog can have different namespaces.\n\n\n\n\n\n\nproperty.{field-id}.label\n\n\n\"EVENTS.EVENTS.DETAILS.METADATA.TITLE\" or \"Event Title\"\n\n\nThe label to show for this property in the UI. If there is a i18n support for a label that should be the value used so that it will be translated, if you don't mind it being locked to one translation just put that single value in.\n\n\n\n\n\n\nproperty.{field-id}.type\n\n\ntext\n\n\nThe type of the metadata field.\n\n\n\n\n\n\nproperty.{field-id}.pattern\n\n\nyyyy-MM-dd\n\n\nApplies to date and time types for now. It is used to format their values using the java DateTimeFormatter values**\n\n\n\n\n\n\nproperty.{field-id}.readOnly\n\n\nfalse\n\n\nIf the property can be edited in the UI or if it should only be displayed.\n\n\n\n\n\n\nproperty.{field-id}.required\n\n\ntrue\n\n\nIf the property has to have a value before the metadata can be saved (the UI's save button will be disabled until all of the required fields are entered)\n\n\n\n\n\n\nproperty.{field-id}.collectionID\n\n\nUSERS\n\n\nThe id of the list provider that will be used to validate the input in the backend. So for example entering a username that doesn't exist will throw an error in this case.\n\n\n\n\n\n\nproperty.{field-id}.listprovider\n\n\nUSERS\n\n\nThe id of the list provider that will be used as a drop down option for that field. So for example using the USERS list provider means that in the front end the user will be able to choose the field value from the list of users in Opencast.\n\n\n\n\n\n\nproperty.{field-id}.order\n\n\n3\n\n\nDefines the order of properties where this property should be oriented in the UI i.e. 0 means the property should come first, 1 means it should come second etc. Giving two properties the same number will cause them to be next to one another but doesn't guarantee one above or below the other.\n\n\n\n\n\n\n\n\n* Mandatory field attribute\n\n\n** See https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html\n\n\nField types\n\n\n\n\n\n\n\n\nType\n\n\nDescription\n\n\nExample value in catalog\n\n\nExample value in UI\n\n\nJSON response example\n\n\n\n\n\n\n\n\n\n\nboolean\n\n\nRepresents a true / false value in the UI that is represented by a check box.\n\n\nfalse\n\n\nfalse\n\n\n\n\n\n\n\n\ndate\n\n\nA Java Date object that can include the year, month, day, hour, minute second ... and is formatted by the pattern value.\n\n\n2014-12-10T16:29:43Z\n\n\n2014-12-10\n\n\n\n\n\n\n\n\ntext\n\n\nA text input value for entering in one line of text. It supports more, it just won't increase in size for the interface.\n\n\nThis is the Title\n\n\nThis is the Title\n\n\n\n\n\n\n\n\ntext_long\n\n\nA textarea which allows for more than 1 row of text\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.\n\n\n{\n\"id\": \"notesEpisode\",\n\"readOnly\": false,\n\"value\": \"\",\n\"label\": \"Notes\",\n\"required\": false,\n\"type\":\"text_long\"\n}\n\n\n\n\n\n\niterable_text\n\n\nA text input value for entering in a list of text objects that are comma separated in the front end but stored separately in the catalog.\n\n\nAdam,Basil,Lukas\n\n\nvalue : [\"Adam\",\"Basil\",\"Lukas\"]\n\n\n{\n\"id\": \"contributor\",\n \"readOnly\": true,\n\"value\": [\"Adam\", \"Basil\", \"Lukas\"],\n\"label\": \"Contributor(s)\",\n\"required\": false,\n\"type\": \"text\"\n}\n\n\n\n\n\n\nstart_date\n\n\nThe start date portion of a Dublin Core Catalog Period.\n\n\nstart=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF;\n\n\n2014-11-04\n\n\n\n\n\n\n\n\nstart_time\n\n\nThe start time portion of a Dublin Core Catalog Period.\n\n\nstart=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF;\n\n\n19:00:00\n\n\n\n\n\n\n\n\nduration\n\n\nThe duration of the event portion of a Dublin Core Catalog Period.\n\n\nstart=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF;\n\n\n01:00:00\n\n\n\n\n\n\n\n\n\n\nWorkflow Configuration\n\n\nSince the extended metadata don't have the \ndublincore/*\n flavor, a tagging operation for the archive has to be added\nfor the extended catalogs.\nIn our examples below, we use ext/episode as a flavor, so the following operation should be added to the workflows\n\n\n<!-- Tag the extended metadata catalogs for publishing -->\n<operation\n    id=\"tag\"\n    description=\"Tagging extended metadata catalogs for archival and/or publication\">\n    <configurations>\n        <configuration key=\"source-flavors\">ext/*</configuration>\n        <configuration key=\"target-tags\">+archive</configuration>\n    </configurations>\n</operation>\n\n\n\nIf you want the extended metadata to be published the same way as the standard metadata, you can update the existing\ntagging operation for dublincore metadata the following way\n\n\n<!-- Tag the incoming metadata catalogs for publishing -->\n<operation\n  id=\"tag\"\n  description=\"Tagging metadata catalogs for archival and publication\">\n  <configurations>\n    <configuration key=\"source-flavors\">dublincore/*,ext/*</configuration>\n    <configuration key=\"target-tags\">+archive,+engage-download</configuration>\n  </configurations>\n</operation>",
            "title": "Metadata"
        },
        {
            "location": "/configuration/metadata/#overview",
            "text": "In Opencast, metadata is stored in so-called metadata catalogs. For each event or series, an arbiraty number of\nsuch configurable metadata catalog can be managed. A common set of metadata has been standarized to form a\ncommon basis (standard metadata), whereas administrators can configure Opencast to support other metadata sets\n(extended metadata).  This document provides an overview over Opencast's metadata capabilities and its configuration.",
            "title": "Overview"
        },
        {
            "location": "/configuration/metadata/#standard-metadata",
            "text": "For both events and series, a common set of metadata is supported by Opencast out-of-the box. Since metadata catalogs\nare referenced from within media package, flavors can be used to identify a specific metadata catalog. The following\nflavors are treated by Opencast as standard metadata in means of Opencast expects them to be present:   dublincore/episode  holds the standard metadata of an event  dublincore/series  holds the standard metadata of a series   Opencast assumes specific metadata fields to be present in the standard metadata in means of defining hard-coded\nfilters, table columns and search indices.  To adjust the standard metadata to your specific needs, you can configure them in /opt/opencast/etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg  and /opt/opencast/etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common.cfg .  For details on how to configure metadata catalogs, see section Configuring Metadata Catalogs.  As mentioned above, however, Opencast expects specific metafields to be present to work correctly. In case you want\nto map metadata specific to your use case, you might consider to use the extended metadata capbilities of Opencast\ndescribed in the next section.",
            "title": "Standard Metadata"
        },
        {
            "location": "/configuration/metadata/#extended-metadata",
            "text": "For both events and series, Opencast support an arbitrary number of customized metadata catalogs.  To add extended metadata catalogs, create a configuration file with a valid filename of the form org.opencastproject.ui.metadata.CatalogUIAdapterFactory-<name>.cfg  in  /opt/opencast/etc.  on the admin node.  For details on how to configure metadata catalogs, see section Configuring Metadata Catalogs.  Limitations:   Cannot be sorted, searched or filtered  Cannot be displayed in tables",
            "title": "Extended Metadata"
        },
        {
            "location": "/configuration/metadata/#metadata-catalog-configuration",
            "text": "The metadata configuration file format can be logically split up into different parts:",
            "title": "Metadata Catalog Configuration"
        },
        {
            "location": "/configuration/metadata/#part-1-general-catalog-information",
            "text": "Configuration key  Example  Description      type  events  Two different types of catalog UI adapters may be configured, such for events and others for series.    organization  mh_default_org  A custom catalog definition is mapped 1:1 to an organization and is available to this one organization only.    flavor  mycompany/episode  The catalog must be of a certain flavor. For a events catalog, the flavor consists of the form type/subtype whereas for series you only need to define the subtype. Attention: For series catalogs, the type (the part before the slash '/') is used as element type.    title  My Personal Catalog Name  This is the title that is displayed in the UI. It should be something that is readable by humans.",
            "title": "Part 1: General catalog information"
        },
        {
            "location": "/configuration/metadata/#part-2-xml-serialization-information",
            "text": "The only supported serialization of catalogs is currently the XML file format. The file follows the recommendation of\nthe Dublin Core Metadata Initiative.     Configuration key  Example  Description      xml.rootElement.name  mycatalog  The name of the XML root element    xml.rootElement.namespace.URI  http://myorg.com/metadata/catalog  The URI of the XML namespace of the root element     Namespace bindings  To properly serialize to XML each prefix has to be bound to an XML namespace. Multiple namespace bindings can be\nconfigured, each identified by its unique name.     Configuration key  Example  Description      xml.namespaceBinding.{name}.URI  http://myorg.com/metadata/terms  The URI of the XML namespace    xml.namespaceBinding.{name}.prefix  myterms  The prefix used to identify elements of the namespace",
            "title": "Part 2: XML serialization information"
        },
        {
            "location": "/configuration/metadata/#part-3-catalog-fields-configuration",
            "text": "{field-id}  must be a unique identifier for each property for a given catalog and can be the same as the input or\noutput id to make it easy to find.     Configuration key  Example  Description      property.{field-id}.inputID*  title  The id used to identify this property in the catalog e.g. The name of the property inside the xml file of a Dublin Core catalog. If an outputID is not specified then this inputID is used for both the catalog and the front end id. This value is mandatory.    property.{field-id}.outputID  title  The id used inside the json for this property. If this value is missing then the inputID will be used instead.    property.{field-id}.namespace  http://purl.org/dc/terms/  The URL that represents the namespace for this property. Different properties in the same catalog can have different namespaces.    property.{field-id}.label  \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\" or \"Event Title\"  The label to show for this property in the UI. If there is a i18n support for a label that should be the value used so that it will be translated, if you don't mind it being locked to one translation just put that single value in.    property.{field-id}.type  text  The type of the metadata field.    property.{field-id}.pattern  yyyy-MM-dd  Applies to date and time types for now. It is used to format their values using the java DateTimeFormatter values**    property.{field-id}.readOnly  false  If the property can be edited in the UI or if it should only be displayed.    property.{field-id}.required  true  If the property has to have a value before the metadata can be saved (the UI's save button will be disabled until all of the required fields are entered)    property.{field-id}.collectionID  USERS  The id of the list provider that will be used to validate the input in the backend. So for example entering a username that doesn't exist will throw an error in this case.    property.{field-id}.listprovider  USERS  The id of the list provider that will be used as a drop down option for that field. So for example using the USERS list provider means that in the front end the user will be able to choose the field value from the list of users in Opencast.    property.{field-id}.order  3  Defines the order of properties where this property should be oriented in the UI i.e. 0 means the property should come first, 1 means it should come second etc. Giving two properties the same number will cause them to be next to one another but doesn't guarantee one above or below the other.     * Mandatory field attribute  ** See https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html  Field types     Type  Description  Example value in catalog  Example value in UI  JSON response example      boolean  Represents a true / false value in the UI that is represented by a check box.  false  false     date  A Java Date object that can include the year, month, day, hour, minute second ... and is formatted by the pattern value.  2014-12-10T16:29:43Z  2014-12-10     text  A text input value for entering in one line of text. It supports more, it just won't increase in size for the interface.  This is the Title  This is the Title     text_long  A textarea which allows for more than 1 row of text  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.  Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.  { \"id\": \"notesEpisode\", \"readOnly\": false, \"value\": \"\", \"label\": \"Notes\", \"required\": false, \"type\":\"text_long\" }    iterable_text  A text input value for entering in a list of text objects that are comma separated in the front end but stored separately in the catalog.  Adam,Basil,Lukas  value : [\"Adam\",\"Basil\",\"Lukas\"]  { \"id\": \"contributor\",  \"readOnly\": true, \"value\": [\"Adam\", \"Basil\", \"Lukas\"], \"label\": \"Contributor(s)\", \"required\": false, \"type\": \"text\" }    start_date  The start date portion of a Dublin Core Catalog Period.  start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF;  2014-11-04     start_time  The start time portion of a Dublin Core Catalog Period.  start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF;  19:00:00     duration  The duration of the event portion of a Dublin Core Catalog Period.  start=2014-11-04T19:00:00Z; end=2014-11-05T20:00:00Z; scheme=W3C-DTF;  01:00:00      Workflow Configuration  Since the extended metadata don't have the  dublincore/*  flavor, a tagging operation for the archive has to be added\nfor the extended catalogs.\nIn our examples below, we use ext/episode as a flavor, so the following operation should be added to the workflows  <!-- Tag the extended metadata catalogs for publishing -->\n<operation\n    id=\"tag\"\n    description=\"Tagging extended metadata catalogs for archival and/or publication\">\n    <configurations>\n        <configuration key=\"source-flavors\">ext/*</configuration>\n        <configuration key=\"target-tags\">+archive</configuration>\n    </configurations>\n</operation>  If you want the extended metadata to be published the same way as the standard metadata, you can update the existing\ntagging operation for dublincore metadata the following way  <!-- Tag the incoming metadata catalogs for publishing -->\n<operation\n  id=\"tag\"\n  description=\"Tagging metadata catalogs for archival and publication\">\n  <configurations>\n    <configuration key=\"source-flavors\">dublincore/*,ext/*</configuration>\n    <configuration key=\"target-tags\">+archive,+engage-download</configuration>\n  </configurations>\n</operation>",
            "title": "Part 3: Catalog fields configuration"
        },
        {
            "location": "/configuration/asset-upload-ui/",
            "text": "Asset Upload Options\n\n\nDescription\n\n\nThis guide will help you customize manual upload asset options for the Admin UI.\n\n\nOpencast event media packages reference several different types of assets. These may include video file tracks,\nmetadata catalogs, image files and class handout notes. Some assets are automatically created through workflow\nevents. Others need to be manually attached to the mediapackage. An example of automatically created assets are\nnavigation slides. An example of a manually attached assets are handout notes.\n\n\nThis guide describes how to customize the Admin UI to support new asset upload options.\n\n\nDefault Setup\n\n\nOut of the box, Opencast provides preconfigured asset and source upload configuration. The configuration is a\nlistprovider properties file:\n\n\netc/listproviders/event.upload.asset.options.properties\n\n\n\nTwo source types are enabled by default for use in the Admin UI.\n\n\nEVENTS.EVENTS.NEW.SOURCE.UPLOAD.NON_SEGMENTABLE={\n   \"id\":\"track_presenter\", \"type\":\"track\", \"flavorType\":\"presenter\",\n   \"flavorSubType\":\"source\", \"multiple\":false, \"displayOrder\": 1}\n\nEVENTS.EVENTS.NEW.SOURCE.UPLOAD.SEGMENTABLE={\n   \"id\":\"track_presentation\", \"type\":\"track\", \"flavorType\":\"presentation\",\n   \"flavorSubType\":\"source\", \"multiple\":false, \"displayOrder\": 2}\n\n\n\nSource upload options as displayed in the Admin UI Create event:\n    \n\n\nAsset flavor and sub-flavor are used by default Opencast workflows. When you add new asset types, you may need to adjust\nworkflows to process the new asset flavor.\n\n\nThese workflow variables are avaiable to workflows started by the create event or add asset action:\n\n\n\n\n\n\n\n\nVariable Name\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nuploadedSearchPreview\n\n\nboolean\n\n\ntrue if manually uploaded preview image, false otherwise. Used to prevent image extraction overwrite in compose operation\n\n\n\n\n\n\ndownloadSourceflavorsExist\n\n\nboolean\n\n\ntrue if download-source-flavors variable exists, false otherwise. Identifies existence of download-source-flavors var for tagging\n\n\n\n\n\n\ndownload-source-flavors\n\n\ncomma separated list\n\n\nA convenience variable that lists manually uploaded asset flavors.\n\n\n\n\n\n\n\n\nExample of variables in a workflow:\n\n\n    <!-- Tag any optionally uploaded assets -->\n    <operation\n      id=\"tag\"\n      if=\"${downloadSourceflavorsExist}\"\n      exception-handler-workflow=\"partial-error\"\n      description=\"Tagging uploaded assets for distribution\">\n      <configurations>\n        <configuration key=\"source-flavors\">${download-source-flavors}</configuration>\n        <configuration key=\"target-tags\">+engage-download</configuration>\n      </configurations>\n    </operation>\n\n\n\n\nHow to Enable Preconfigured Asset Options\n\n\nCatalogs and attachments can be added to new and existing events. Source tracks are uploaded as new events. Some\npredefined catalog and attachment examples are commented out in the properties file. You can uncomment any of these\nto make them upload options in the Admin UI. The workflow \npublish-uploaded-assets\n will automatically distribute,\npublish, and archive uploaded assets on existing events.\n\n\n# Attachments and catalogs upload options are for new and existing events.\n# Only one file can be uploaded for each of these options, the uploaded file replaces existing elements of the same\n# type and flavor in the mediapackage.\n# EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_DFXP={\"id\":\"catalog_captions_dfxp\", \"type\": \"catalog\",\n#     \"flavorType\": \"captions\", \"flavorSubType\": \"timedtext\", \"displayOrder\": 2}\n# EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_WEBVTT={\"id\":\"attachment_captions_webvtt\",\n#     \"type\": \"attachment\", \"flavorType\": \"text\", \"flavorSubType\": \"webvtt\", \"displayOrder\": 3}\n# EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CLASS_HANDOUT_NOTES={\"id\": \"attachment_class_handout_notes\",\n#     \"type\": \"attachment\", \"flavorType\": \"attachment\", \"flavorSubType\": \"notes\", \"displayOrder\": 4}\n# EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.SMIL={\"id\":\"catalog_smil\", \"type\":\"catalog\", \"flavorType\": \"smil\",\n#      \"flavorSubType\": \"smil\", \"displayOrder\": 5}\n# EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.PREVIEW_IMAGE={\"id\":\"attachment_preview_image\",\n#     \"type\":\"attachment\", \"flavorType\": \"presenter\",\"flavorSubType\": \"search+preview\", \"displayOrder\": 6}\nEVENTS.EVENTS.NEW.UPLOAD_ASSET.WORKFLOWDEFID=publish-uploaded-assets\n\n# The video source track upload options are only for new events.\n# Unlike the other assets, multiple source tracks can be uploaded for a single flavor.\n# The MULTIPLE_PARTS example shows how to enable choosing multiple source files for a single flavor. In this case,\n# a fictional \"multipart/part+source\".\n# EVENTS.EVENTS.NEW.SOURCE.UPLOAD.MULTIPLE_PARTS={\"id\": \"track_parts\",\"type\":\"track\",\n#    \"flavorType\": \"multipart\", \"flavorSubType\": \"part+source\", \"multiple\":true, \"displayOrder\": 10}\n# EVENTS.EVENTS.NEW.SOURCE.UPLOAD.AUDIO_ONLY={\"id\": \"track_audio\",\"type\":\"track\",\n#     \"flavorType\": \"presenter-audio\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 11}\nEVENTS.EVENTS.NEW.SOURCE.UPLOAD.NON_SEGMENTABLE={\"id\": \"track_presenter\",\"type\":\"track\",\n     \"flavorType\":\"presenter\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 12}\nEVENTS.EVENTS.NEW.SOURCE.UPLOAD.SEGMENTABLE={\"id\": \"track_presentation\",\"type\":\"track\",\n     \"flavorType\":\"presentation\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 13}\n\n\n\nHow to Upload Assets in the Admin UI\n\n\nAfter enabling an upload option, a new navigation area becomes visible in the \"Create event\", called \"Asset Upload\".\nAssets can be uploaded to new events. The \"Asset Upload\" navigation disapears for scheduled events.\nAssets cannot be uploaded for scheduled events until after the scheduled event is processed.\n    \n\n\nThe manually uploaded assets appear in the Create event summary\n    \n\n\nTo Upload an asset to an existing event, go into the existing event details Assets tab, and click \"Add Asset >\" link\n    \n\n\nThe option selection is the same as for Create event, execpt the \"Add Asset\" button automatically executes the workflow\ndefined by \nEVENTS.EVENTS.NEW.UPLOAD_ASSET.WORKFLOWDEFID\n\n    \n\n\nHow to Create a New Asset Option\n\n\nThe following steps will assist you in creating a new asset upload option. As mentioned before, only catalog and\nattachments can be added to existing events. New source types can be added to new events.\n\n\nTasks:\n\n\n\n\nModify \netc/listproviders/event.upload.asset.options.properties\n\n\nAdd Admin UI translation for the new asset name\n  \nmodules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/...\n\n\nModify your workflow from \netc/workflows/...\n\n\nTest your changes\n\n\n\n\nThe following steps describe how to change the properties configuration.\n\n\nStep 1. Determine your new option type and processing needs\n\n\nThere are 3 asset upload types:\n\n\n\n\ntrack\n is a media source such as video file\n\n\ncatalog\n is an XML formatted metadata file\n\n\nattachment\n can be any type of file. For example jpeg, pdf, text, etc.\n\n\n\n\nTracks are usually associated with workflow processing. If you need special processing with your custom track flavors,\nupdate or create  workflows to work with your new track flavor.\n\n\nAttachments and Catalogs, such as smil files, can also be used for processing. If you only need to publish manually\nuploaded assets with a unique flavor, this is already built into the default workflows.\n\n\nStep 2. Add your new option to the list configuration\n\n\nYou add your new asset upload configuration as a row to this file:\n\n\netc/listproviders/event.upload.asset.options.properties\n\n\n\nCopy an existing row as a template for your new asset. Retain the property key prefix \nEVENTS.EVENTS.NEW.SOURCE.\n\nor \nEVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.\n\n\nYour unique asset identifier will follow the last dot after the prefix, in all capital alphabetical characters.\nUnderbars are allowed. CONFIGURATION values are in JSON object format.\n\n\n\n\n\n\n\n\nAttribute\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nid\n\n\ntrack_presenter\n\n\nOne of \"attachment\" or \"catalog\" or \"track\", underbar (_), unique text (no spaces)\n\n\n\n\n\n\ntype\n\n\ntrack\n\n\nOne of \"attachment\" or \"catalog\" or \"track\" to designate asset type (must match id prefix)\n\n\n\n\n\n\nflavorType\n\n\npresentation\n\n\nThe primary flavor type. Used to reference asset in workflows, player, and media module\n\n\n\n\n\n\nflavorSubType\n\n\nsource\n\n\nThe sub flavor type. Used to identify the sub flavor of this flavor type\n\n\n\n\n\n\nmultiple\n\n\nfalse\n\n\ntrue or false, used by the admin UI to enable single or multiple file input selection\n\n\n\n\n\n\ndisplayOrder\n\n\n32\n\n\nInteger number, used by the admin UI to sort the display of upload options in the UI\n\n\n\n\n\n\ndisplayOverride\n\n\n'My New Catalog'\n\n\nA short asset title which overrides all translations\n\n\n\n\n\n\ndisplayFallback\n\n\n'My New Catalog'\n\n\nA short asset title which displays when no translation is found\n\n\n\n\n\n\ndisplayOverride.SHORT\n\n\n'Video of a Presenter'\n\n\nA short source title which overrides all translations\n\n\n\n\n\n\ndisplayFallback.SHORT\n\n\n'Video of a Presenter'\n\n\nA short source title which displays when no translation is found\n\n\n\n\n\n\ndisplayOverride.DETAIL\n\n\n'A recording that showing the lecturer speaking'\n\n\nA longer source description which overrides all translation\n\n\n\n\n\n\ndisplayFallback.DETAIL\n\n\n'A recording that showing the lecturer speaking'\n\n\nA longer source description which displays when no translation is found\n\n\n\n\n\n\n\n\nThe parameter key is internationalized as the display text in the admin UI\nref: modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/\n\n\nStep 3. Add translation for the new option\n\n\nThe option property key is internationalized for display in the Admin UI.\nAdd a translation for the option property when adding new option, otherwise the Admin UI will display the raw key.\n\n\nThe translation language files are located:\n\n\nmodules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/...\n\n\n\nExample of US English translation for \nEVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_WEBVTT\n:\n\n\nmodules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/lang-en_US.json\n\n\n\n{\n  ...\n  \"EVENTS\": {\n    ...\n    \"EVENTS\": {\n       ...\n       \"NEW\": {\n        ...\n        \"UPLOAD_ASSET\": {\n             ...\n            \"CAPTIONS_WEBVTT\" : \"Captions WebVTT\",\n             ...\n\n\n\n\nNow you are ready to test and deploy.",
            "title": "Manual Asset Upload"
        },
        {
            "location": "/configuration/asset-upload-ui/#asset-upload-options",
            "text": "",
            "title": "Asset Upload Options"
        },
        {
            "location": "/configuration/asset-upload-ui/#description",
            "text": "This guide will help you customize manual upload asset options for the Admin UI.  Opencast event media packages reference several different types of assets. These may include video file tracks,\nmetadata catalogs, image files and class handout notes. Some assets are automatically created through workflow\nevents. Others need to be manually attached to the mediapackage. An example of automatically created assets are\nnavigation slides. An example of a manually attached assets are handout notes.  This guide describes how to customize the Admin UI to support new asset upload options.",
            "title": "Description"
        },
        {
            "location": "/configuration/asset-upload-ui/#default-setup",
            "text": "Out of the box, Opencast provides preconfigured asset and source upload configuration. The configuration is a\nlistprovider properties file:  etc/listproviders/event.upload.asset.options.properties  Two source types are enabled by default for use in the Admin UI.  EVENTS.EVENTS.NEW.SOURCE.UPLOAD.NON_SEGMENTABLE={\n   \"id\":\"track_presenter\", \"type\":\"track\", \"flavorType\":\"presenter\",\n   \"flavorSubType\":\"source\", \"multiple\":false, \"displayOrder\": 1}\n\nEVENTS.EVENTS.NEW.SOURCE.UPLOAD.SEGMENTABLE={\n   \"id\":\"track_presentation\", \"type\":\"track\", \"flavorType\":\"presentation\",\n   \"flavorSubType\":\"source\", \"multiple\":false, \"displayOrder\": 2}  Source upload options as displayed in the Admin UI Create event:\n      Asset flavor and sub-flavor are used by default Opencast workflows. When you add new asset types, you may need to adjust\nworkflows to process the new asset flavor.  These workflow variables are avaiable to workflows started by the create event or add asset action:     Variable Name  Type  Description      uploadedSearchPreview  boolean  true if manually uploaded preview image, false otherwise. Used to prevent image extraction overwrite in compose operation    downloadSourceflavorsExist  boolean  true if download-source-flavors variable exists, false otherwise. Identifies existence of download-source-flavors var for tagging    download-source-flavors  comma separated list  A convenience variable that lists manually uploaded asset flavors.     Example of variables in a workflow:      <!-- Tag any optionally uploaded assets -->\n    <operation\n      id=\"tag\"\n      if=\"${downloadSourceflavorsExist}\"\n      exception-handler-workflow=\"partial-error\"\n      description=\"Tagging uploaded assets for distribution\">\n      <configurations>\n        <configuration key=\"source-flavors\">${download-source-flavors}</configuration>\n        <configuration key=\"target-tags\">+engage-download</configuration>\n      </configurations>\n    </operation>",
            "title": "Default Setup"
        },
        {
            "location": "/configuration/asset-upload-ui/#how-to-enable-preconfigured-asset-options",
            "text": "Catalogs and attachments can be added to new and existing events. Source tracks are uploaded as new events. Some\npredefined catalog and attachment examples are commented out in the properties file. You can uncomment any of these\nto make them upload options in the Admin UI. The workflow  publish-uploaded-assets  will automatically distribute,\npublish, and archive uploaded assets on existing events.  # Attachments and catalogs upload options are for new and existing events.\n# Only one file can be uploaded for each of these options, the uploaded file replaces existing elements of the same\n# type and flavor in the mediapackage.\n# EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_DFXP={\"id\":\"catalog_captions_dfxp\", \"type\": \"catalog\",\n#     \"flavorType\": \"captions\", \"flavorSubType\": \"timedtext\", \"displayOrder\": 2}\n# EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_WEBVTT={\"id\":\"attachment_captions_webvtt\",\n#     \"type\": \"attachment\", \"flavorType\": \"text\", \"flavorSubType\": \"webvtt\", \"displayOrder\": 3}\n# EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CLASS_HANDOUT_NOTES={\"id\": \"attachment_class_handout_notes\",\n#     \"type\": \"attachment\", \"flavorType\": \"attachment\", \"flavorSubType\": \"notes\", \"displayOrder\": 4}\n# EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.SMIL={\"id\":\"catalog_smil\", \"type\":\"catalog\", \"flavorType\": \"smil\",\n#      \"flavorSubType\": \"smil\", \"displayOrder\": 5}\n# EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.PREVIEW_IMAGE={\"id\":\"attachment_preview_image\",\n#     \"type\":\"attachment\", \"flavorType\": \"presenter\",\"flavorSubType\": \"search+preview\", \"displayOrder\": 6}\nEVENTS.EVENTS.NEW.UPLOAD_ASSET.WORKFLOWDEFID=publish-uploaded-assets\n\n# The video source track upload options are only for new events.\n# Unlike the other assets, multiple source tracks can be uploaded for a single flavor.\n# The MULTIPLE_PARTS example shows how to enable choosing multiple source files for a single flavor. In this case,\n# a fictional \"multipart/part+source\".\n# EVENTS.EVENTS.NEW.SOURCE.UPLOAD.MULTIPLE_PARTS={\"id\": \"track_parts\",\"type\":\"track\",\n#    \"flavorType\": \"multipart\", \"flavorSubType\": \"part+source\", \"multiple\":true, \"displayOrder\": 10}\n# EVENTS.EVENTS.NEW.SOURCE.UPLOAD.AUDIO_ONLY={\"id\": \"track_audio\",\"type\":\"track\",\n#     \"flavorType\": \"presenter-audio\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 11}\nEVENTS.EVENTS.NEW.SOURCE.UPLOAD.NON_SEGMENTABLE={\"id\": \"track_presenter\",\"type\":\"track\",\n     \"flavorType\":\"presenter\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 12}\nEVENTS.EVENTS.NEW.SOURCE.UPLOAD.SEGMENTABLE={\"id\": \"track_presentation\",\"type\":\"track\",\n     \"flavorType\":\"presentation\", \"flavorSubType\": \"source\", \"multiple\":false, \"displayOrder\": 13}",
            "title": "How to Enable Preconfigured Asset Options"
        },
        {
            "location": "/configuration/asset-upload-ui/#how-to-upload-assets-in-the-admin-ui",
            "text": "After enabling an upload option, a new navigation area becomes visible in the \"Create event\", called \"Asset Upload\".\nAssets can be uploaded to new events. The \"Asset Upload\" navigation disapears for scheduled events.\nAssets cannot be uploaded for scheduled events until after the scheduled event is processed.\n      The manually uploaded assets appear in the Create event summary\n      To Upload an asset to an existing event, go into the existing event details Assets tab, and click \"Add Asset >\" link\n      The option selection is the same as for Create event, execpt the \"Add Asset\" button automatically executes the workflow\ndefined by  EVENTS.EVENTS.NEW.UPLOAD_ASSET.WORKFLOWDEFID",
            "title": "How to Upload Assets in the Admin UI"
        },
        {
            "location": "/configuration/asset-upload-ui/#how-to-create-a-new-asset-option",
            "text": "The following steps will assist you in creating a new asset upload option. As mentioned before, only catalog and\nattachments can be added to existing events. New source types can be added to new events.  Tasks:   Modify  etc/listproviders/event.upload.asset.options.properties  Add Admin UI translation for the new asset name\n   modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/...  Modify your workflow from  etc/workflows/...  Test your changes   The following steps describe how to change the properties configuration.",
            "title": "How to Create a New Asset Option"
        },
        {
            "location": "/configuration/asset-upload-ui/#step-1-determine-your-new-option-type-and-processing-needs",
            "text": "There are 3 asset upload types:   track  is a media source such as video file  catalog  is an XML formatted metadata file  attachment  can be any type of file. For example jpeg, pdf, text, etc.   Tracks are usually associated with workflow processing. If you need special processing with your custom track flavors,\nupdate or create  workflows to work with your new track flavor.  Attachments and Catalogs, such as smil files, can also be used for processing. If you only need to publish manually\nuploaded assets with a unique flavor, this is already built into the default workflows.",
            "title": "Step 1. Determine your new option type and processing needs"
        },
        {
            "location": "/configuration/asset-upload-ui/#step-2-add-your-new-option-to-the-list-configuration",
            "text": "You add your new asset upload configuration as a row to this file:  etc/listproviders/event.upload.asset.options.properties  Copy an existing row as a template for your new asset. Retain the property key prefix  EVENTS.EVENTS.NEW.SOURCE. \nor  EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.  Your unique asset identifier will follow the last dot after the prefix, in all capital alphabetical characters.\nUnderbars are allowed. CONFIGURATION values are in JSON object format.     Attribute  Example  Description      id  track_presenter  One of \"attachment\" or \"catalog\" or \"track\", underbar (_), unique text (no spaces)    type  track  One of \"attachment\" or \"catalog\" or \"track\" to designate asset type (must match id prefix)    flavorType  presentation  The primary flavor type. Used to reference asset in workflows, player, and media module    flavorSubType  source  The sub flavor type. Used to identify the sub flavor of this flavor type    multiple  false  true or false, used by the admin UI to enable single or multiple file input selection    displayOrder  32  Integer number, used by the admin UI to sort the display of upload options in the UI    displayOverride  'My New Catalog'  A short asset title which overrides all translations    displayFallback  'My New Catalog'  A short asset title which displays when no translation is found    displayOverride.SHORT  'Video of a Presenter'  A short source title which overrides all translations    displayFallback.SHORT  'Video of a Presenter'  A short source title which displays when no translation is found    displayOverride.DETAIL  'A recording that showing the lecturer speaking'  A longer source description which overrides all translation    displayFallback.DETAIL  'A recording that showing the lecturer speaking'  A longer source description which displays when no translation is found     The parameter key is internationalized as the display text in the admin UI\nref: modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/",
            "title": "Step 2. Add your new option to the list configuration"
        },
        {
            "location": "/configuration/asset-upload-ui/#step-3-add-translation-for-the-new-option",
            "text": "The option property key is internationalized for display in the Admin UI.\nAdd a translation for the option property when adding new option, otherwise the Admin UI will display the raw key.  The translation language files are located:  modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/...  Example of US English translation for  EVENTS.EVENTS.NEW.UPLOAD_ASSET.OPTION.CAPTIONS_WEBVTT :  modules/admin-ui/src/main/resources/public/org/opencastproject/adminui/languages/lang-en_US.json  {\n  ...\n  \"EVENTS\": {\n    ...\n    \"EVENTS\": {\n       ...\n       \"NEW\": {\n        ...\n        \"UPLOAD_ASSET\": {\n             ...\n            \"CAPTIONS_WEBVTT\" : \"Captions WebVTT\",\n             ...  Now you are ready to test and deploy.",
            "title": "Step 3. Add translation for the new option"
        },
        {
            "location": "/configuration/encoding/",
            "text": "Encoding Profile Configuration\n\n\nA workflow defines which operations are applied to media ingested into Opencast and the order of these operations. An\noperation can be something general like \u201cencode this video\u201d. The encoding profiles then specify exactly how a media is\nancoded, which filters are applied, which codecs are used and in which container these will be stored, \u2026\n\n\nOpencast comes with a set of such profiles generating files for both online playback and download. These profiles are\nbuild to work for everyone, meaning that in most cases optimization can be done according to local needs. So modifying\nthese profiles or building new ones often makes sense. This document will help you modify or augment Opencast's\ndefault encoding profiles for audio, video and still images.\n\n\nDefault Profiles and Possible Settings\n\n\nThis section contains some notes about the default profiles, explaining some thoughts behind those profiles and pointing\nat things you might want to change depending on your local set-up.\n\n\nA/V-Muxing: From lossless to safe\n\n\nThe audio/video muxing (\nprofile.mux-av.work\n) is applied if audio and video is sent to Opencast separately. The basic\nidea behind this is, to combine these separate files into one file which can later be converted in one step.\n\n\nPossible settings:\n\n\n\n\nIf you get an audio and a video file separately, it is possible to just copy the streams and put them together into a\n   new file. This is very fast (you only have to copy the streams) and most importantly, it is lossless, as no\n   re-encoding is done. The question is: What a/v container format can/should you use for such an operation.\n\n\nYou can try to use the video container the input video came in and just add the audio. This means that you will never\n   have an unexpected video container you don't know of. I.e. if you put an .mp4 video in, it still uses and .mp4\n   container after musing, etc. This might, however, lead to problems if you throw in an audio file that cannot be muxed\n   in the specific container format (i.e. you have a FLAC audio file and an FLV container). This is, what Opencast\n   does at the moment.\n\n\nTo circumvent the container problem, we could also use a container format which can hold almost everything (i.e. mkv)\n   regardless of the input. This would mean that Opencast can handle more combinations of a/v streams but you will\n   always end up with a Matroska file after muxing. Of cause, you can then encode it to mp4, etc. later on.\n\n\n\n\nThe safest option for muxing is to always re-encode the streams. It is far slower than re-using the existing bit\nstreams. It also, always means a quality loss.\n\n\nCreate an Encoding Profile\n\n\nThis section will help you to understand how you can modify an existing profile or create a completely new one.\n\n\nCreating a new encoding profile is a matter of creating a configuration file and placing it in the encoding profiles\nwatch folder.\n\n\nEncoding Profile Folder\n\n\nThe \n<config_dir>/encoding\n folder allows you to quickly augment Opencast's existing behavior, simply by modifying or\nadding new configuration files. The file names should follow the pattern \n*.properties\n.\n\n\nThe Encoding Profile\n\n\nEncoding profiles consist of a set of key-value pairs that conform to the following pattern:\n\n\nprofile.<name>.<context>.<property> = <value>\n\n\n\nFor example:\n\n\nprofile.mp4.http.name = Enocde Mp4 files for download\n\n\n\nAll profiles should have the following properties:\n\n\n.name\n.input  = [audio|visual|stream|image]\n.output = [audio|visual|stream|image]\n.suffix\n.ffmpeg.command\n\n\n\nFor example:\n\n\n// My audio/video encoding profile\nprofile.my-av-profile.http.name           = my audio/video encoding profile\nprofile.my-av-profile.http.input          = visual\nprofile.my-av-profile.http.output         = visual\nprofile.my-av-profile.http.suffix         = -encoded.enc\nprofile.my-av-profile.http.ffmpeg.command = -i #{in.video.path} -c:v venc -c:a aenc #{out.dir}/#{out.name}#{out.suffix}\n\n\n\nThe most important part of this profile is the \nffmpeg.command\n. This line specifies FFmpeg command line options using\n\n#{expression}\n for string replacement.\n\n\nFFmpeg\n\n\nTo create a new profile you have basically one task to do: Find an appropriate FFmpeg command line for whatever you want\nto do. For more information about FFmpeg, its options and how you can build FFmpeg with additional functionality have a\nlook at the \nOfficial FFmpeg Wiki\n. For trying out new encoding settings, just call FFmpeg\nfrom the command line.\n\n\nUsing a Profile\n\n\nOnce defined, use your encoding profile in your workflow by setting the encoding-profile property to the profiles name:\n\n\n<operation\n    id=\"compose\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encode presenter using my audio/video encoding profile\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/work</configuration>\n    <configuration key=\"target-flavor\">presenter/delivery</configuration>\n    <configuration key=\"target-tags\">rss, atom, captioning</configuration>\n    <configuration key=\"encoding-profile\">my-av-profile.http</configuration>\n  </configuration>\n</operation>\n\n\n\nHave a look at the \nWorkflow Configuration section\n for more details about workflows and workflow\noperations.",
            "title": "Encoding"
        },
        {
            "location": "/configuration/encoding/#encoding-profile-configuration",
            "text": "A workflow defines which operations are applied to media ingested into Opencast and the order of these operations. An\noperation can be something general like \u201cencode this video\u201d. The encoding profiles then specify exactly how a media is\nancoded, which filters are applied, which codecs are used and in which container these will be stored, \u2026  Opencast comes with a set of such profiles generating files for both online playback and download. These profiles are\nbuild to work for everyone, meaning that in most cases optimization can be done according to local needs. So modifying\nthese profiles or building new ones often makes sense. This document will help you modify or augment Opencast's\ndefault encoding profiles for audio, video and still images.",
            "title": "Encoding Profile Configuration"
        },
        {
            "location": "/configuration/encoding/#default-profiles-and-possible-settings",
            "text": "This section contains some notes about the default profiles, explaining some thoughts behind those profiles and pointing\nat things you might want to change depending on your local set-up.",
            "title": "Default Profiles and Possible Settings"
        },
        {
            "location": "/configuration/encoding/#av-muxing-from-lossless-to-safe",
            "text": "The audio/video muxing ( profile.mux-av.work ) is applied if audio and video is sent to Opencast separately. The basic\nidea behind this is, to combine these separate files into one file which can later be converted in one step.  Possible settings:   If you get an audio and a video file separately, it is possible to just copy the streams and put them together into a\n   new file. This is very fast (you only have to copy the streams) and most importantly, it is lossless, as no\n   re-encoding is done. The question is: What a/v container format can/should you use for such an operation.  You can try to use the video container the input video came in and just add the audio. This means that you will never\n   have an unexpected video container you don't know of. I.e. if you put an .mp4 video in, it still uses and .mp4\n   container after musing, etc. This might, however, lead to problems if you throw in an audio file that cannot be muxed\n   in the specific container format (i.e. you have a FLAC audio file and an FLV container). This is, what Opencast\n   does at the moment.  To circumvent the container problem, we could also use a container format which can hold almost everything (i.e. mkv)\n   regardless of the input. This would mean that Opencast can handle more combinations of a/v streams but you will\n   always end up with a Matroska file after muxing. Of cause, you can then encode it to mp4, etc. later on.   The safest option for muxing is to always re-encode the streams. It is far slower than re-using the existing bit\nstreams. It also, always means a quality loss.",
            "title": "A/V-Muxing: From lossless to safe"
        },
        {
            "location": "/configuration/encoding/#create-an-encoding-profile",
            "text": "This section will help you to understand how you can modify an existing profile or create a completely new one.  Creating a new encoding profile is a matter of creating a configuration file and placing it in the encoding profiles\nwatch folder.",
            "title": "Create an Encoding Profile"
        },
        {
            "location": "/configuration/encoding/#encoding-profile-folder",
            "text": "The  <config_dir>/encoding  folder allows you to quickly augment Opencast's existing behavior, simply by modifying or\nadding new configuration files. The file names should follow the pattern  *.properties .",
            "title": "Encoding Profile Folder"
        },
        {
            "location": "/configuration/encoding/#the-encoding-profile",
            "text": "Encoding profiles consist of a set of key-value pairs that conform to the following pattern:  profile.<name>.<context>.<property> = <value>  For example:  profile.mp4.http.name = Enocde Mp4 files for download  All profiles should have the following properties:  .name\n.input  = [audio|visual|stream|image]\n.output = [audio|visual|stream|image]\n.suffix\n.ffmpeg.command  For example:  // My audio/video encoding profile\nprofile.my-av-profile.http.name           = my audio/video encoding profile\nprofile.my-av-profile.http.input          = visual\nprofile.my-av-profile.http.output         = visual\nprofile.my-av-profile.http.suffix         = -encoded.enc\nprofile.my-av-profile.http.ffmpeg.command = -i #{in.video.path} -c:v venc -c:a aenc #{out.dir}/#{out.name}#{out.suffix}  The most important part of this profile is the  ffmpeg.command . This line specifies FFmpeg command line options using #{expression}  for string replacement.",
            "title": "The Encoding Profile"
        },
        {
            "location": "/configuration/encoding/#ffmpeg",
            "text": "To create a new profile you have basically one task to do: Find an appropriate FFmpeg command line for whatever you want\nto do. For more information about FFmpeg, its options and how you can build FFmpeg with additional functionality have a\nlook at the  Official FFmpeg Wiki . For trying out new encoding settings, just call FFmpeg\nfrom the command line.",
            "title": "FFmpeg"
        },
        {
            "location": "/configuration/encoding/#using-a-profile",
            "text": "Once defined, use your encoding profile in your workflow by setting the encoding-profile property to the profiles name:  <operation\n    id=\"compose\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encode presenter using my audio/video encoding profile\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/work</configuration>\n    <configuration key=\"target-flavor\">presenter/delivery</configuration>\n    <configuration key=\"target-tags\">rss, atom, captioning</configuration>\n    <configuration key=\"encoding-profile\">my-av-profile.http</configuration>\n  </configuration>\n</operation>  Have a look at the  Workflow Configuration section  for more details about workflows and workflow\noperations.",
            "title": "Using a Profile"
        },
        {
            "location": "/configuration/load/",
            "text": "Load Configuration\n\n\nThis guide will help you to set up the load configuration settings which are strongly recommended for each Opencast\ninstallation.  These settings control how many jobs are running on your various hardware nodes.  These settings can be\nleft at their defaults initially, but as your installation grows you will likely wish to fine-tune these to get the best\nperformance you can out of your hardware.\n\n\nBackground: What is a load value\n\n\nEvery job obviously imposes a certain amount of load on its processing system, the question is how can we quantify this?\nThe settings this document will walk you through are estimates of the load placed on your system(s) by each job type.\nThis means that every individual instance of that job type will count for a certain amount of load, and Opencast will\nrefuse to process more than a certain configurable amount of load at any given time on a given node.  These loads are\ntracked on a per-node basis, so a job running on one node imposes no load on another.\n\n\nAs an example, say we have a worker with 8 cores.  With Opencast 1.x all jobs, even expensive jobs like encoding, had an\neffective load value of 1.0.  This meant that Opencast would schedule up to 8 encodes on worker 1! Obviously this is not\nideal, since most encoding jobs consume multiple cores.  Since Opencast 2.1 you can now specify on an encoding profile\nlevel how much load is imposed on a node.  Likewise, all other jobs (video segmentation, publishing, etc) also now have\nconfigurable loads.\n\n\nJob loads can be any floating point value between 0.0, and Java's MAXFLOAT.  Fractional loads are supported, since many\nof the jobs that Opencast spawns as a regular part of its workflows are very small.  There is no sanity checking for the\nconfigured loads, aside from assuring they are not negative.  This means that improperly set load values can cause\ndeadlocks!  Fortunately, this is easy to fix.  See Troubleshooting for more details.\n\n\nStep 1: Determine your load values\n\n\nThis is a very subjective process, but is arguably the most imporant: How much load does each job and encoding profile\nadd to your system? We have tried our best to set useful loads for each job, however these are only estimates.  If your\ninstallation has, for example, hardware assisted encoding then your encoding jobs may be very inexpensive.  In general,\nit is safe to assume that the first load value from the output of \nuptime\n is a good estimate of the load imposed by a\njob.\n\n\nNote: These job loads are specific for each \nnode\n in the cluster.  This means that for any given job, each node can\nhave a different load value associated.  For instance, if worker A has no job load specified for its encoding profiles,\nand worker B has job loads specified then any encoding jobs created by A will have the default load (0.8), and jobs\ncreated by B will have a different, presumably higher load.  There are edge cases where this may be useful, but in\nmost cases this will only cause confusion.  It is therefore highly recommended that these settings be put into your\nconfiguration management system, and be applied on a cluster level to ensure consistency across all nodes.\n\n\nStep 2: Setting the load values for system jobs\n\n\nEach Opencast instance has its own maximum load.  By default this is set to the number of CPU cores present in the\nsystem.  If you wish to change this, set the \norg.opencastproject.server.maxload\n key in config.properties to the\nmaximum load you want this node to accept.  Keep in mind that exceeding the number of CPU cores present in the system is\nnot recommended.\n\n\nThe load values for the non-encoding jobs are set in the configuration files in the \netc\n directory.  Search this\ndirectory for files that contain the string \njob.load\n to find the relevant configuration keys.  These\nconfiguration keys control the load for each job type.  For example, the \njob.load.download.distribute\n configuration\nkey controls the load placed on the system when a download distribution job is running.\n\n\nNote: Ingest jobs are a special case in Opencast.  Because of their immediate nature there is no way to limit the number\nof running jobs.  However, these jobs will block other jobs from running on the ingest/admin nodes if enough ingests\nrunning concurrently.\n\n\nStep 3: Setting the load values for encoding profiles\n\n\nEach encoding profile can have a load value associated with it.  By default, we have not set any, which means that the\ndefault value of 0.8 is used.  To set the load associated with a profile, you simply add a .jobload key to the profile.\nFor example, the composite encoding profile is prefixed with \nprofile.composite.http\n.  If we want to set a different\njob load than the default, we would create the \nprofile.composite.http.jobload\n key, and set it to an appropriate job value.\n\n\nStep 4: Restart Opencast\n\n\nMany of these configuration files are only read on startup, so restarting Opencast is strongly recommended.\n\n\nTroubleshooting\n\n\nHelp, my system has deadlocked, or there are jobs which are always queued even if the system is otherwise idle\n\n\nThis can be caused by setting a job weight that exceeds the maximum load for \nall\n services of a given type.  For\nexample, if you have a single worker with 8 cores and set an encoding job to have a jobload of 9.  Fortunately, there is\na simple resolution to this issue.  Jobs which have already been created do \nnot\n update their load values, even after\nrestarting Opencast.  To resolve a deadlock caused by job loads follow these instructions.  First determine the queued\njob's ID from the admin UI.  This will be an integer greater than zero.  We will call this $jobid.  Once you have the\njob ID, follow these steps:\n\n\n\n\nStop Opencast\n\n\nLog into your database\n\n\nMake sure you are using the right schema. Currently the default is called \nopencast\n\n\nUpdate the job's load\n\n\nThis will look something like \nUPDATE mh_job SET job\\_load=0.0 WHERE id=$jobid\n\n\n\n\n\n\nLog out of your database\n\n\nChange the load specified in the configuration file to an appropriate value\n\n\nThis may need to happen across all nodes!\n\n\n\n\n\n\nRestart Opencast",
            "title": "Load"
        },
        {
            "location": "/configuration/load/#load-configuration",
            "text": "This guide will help you to set up the load configuration settings which are strongly recommended for each Opencast\ninstallation.  These settings control how many jobs are running on your various hardware nodes.  These settings can be\nleft at their defaults initially, but as your installation grows you will likely wish to fine-tune these to get the best\nperformance you can out of your hardware.",
            "title": "Load Configuration"
        },
        {
            "location": "/configuration/load/#background-what-is-a-load-value",
            "text": "Every job obviously imposes a certain amount of load on its processing system, the question is how can we quantify this?\nThe settings this document will walk you through are estimates of the load placed on your system(s) by each job type.\nThis means that every individual instance of that job type will count for a certain amount of load, and Opencast will\nrefuse to process more than a certain configurable amount of load at any given time on a given node.  These loads are\ntracked on a per-node basis, so a job running on one node imposes no load on another.  As an example, say we have a worker with 8 cores.  With Opencast 1.x all jobs, even expensive jobs like encoding, had an\neffective load value of 1.0.  This meant that Opencast would schedule up to 8 encodes on worker 1! Obviously this is not\nideal, since most encoding jobs consume multiple cores.  Since Opencast 2.1 you can now specify on an encoding profile\nlevel how much load is imposed on a node.  Likewise, all other jobs (video segmentation, publishing, etc) also now have\nconfigurable loads.  Job loads can be any floating point value between 0.0, and Java's MAXFLOAT.  Fractional loads are supported, since many\nof the jobs that Opencast spawns as a regular part of its workflows are very small.  There is no sanity checking for the\nconfigured loads, aside from assuring they are not negative.  This means that improperly set load values can cause\ndeadlocks!  Fortunately, this is easy to fix.  See Troubleshooting for more details.",
            "title": "Background: What is a load value"
        },
        {
            "location": "/configuration/load/#step-1-determine-your-load-values",
            "text": "This is a very subjective process, but is arguably the most imporant: How much load does each job and encoding profile\nadd to your system? We have tried our best to set useful loads for each job, however these are only estimates.  If your\ninstallation has, for example, hardware assisted encoding then your encoding jobs may be very inexpensive.  In general,\nit is safe to assume that the first load value from the output of  uptime  is a good estimate of the load imposed by a\njob.  Note: These job loads are specific for each  node  in the cluster.  This means that for any given job, each node can\nhave a different load value associated.  For instance, if worker A has no job load specified for its encoding profiles,\nand worker B has job loads specified then any encoding jobs created by A will have the default load (0.8), and jobs\ncreated by B will have a different, presumably higher load.  There are edge cases where this may be useful, but in\nmost cases this will only cause confusion.  It is therefore highly recommended that these settings be put into your\nconfiguration management system, and be applied on a cluster level to ensure consistency across all nodes.",
            "title": "Step 1: Determine your load values"
        },
        {
            "location": "/configuration/load/#step-2-setting-the-load-values-for-system-jobs",
            "text": "Each Opencast instance has its own maximum load.  By default this is set to the number of CPU cores present in the\nsystem.  If you wish to change this, set the  org.opencastproject.server.maxload  key in config.properties to the\nmaximum load you want this node to accept.  Keep in mind that exceeding the number of CPU cores present in the system is\nnot recommended.  The load values for the non-encoding jobs are set in the configuration files in the  etc  directory.  Search this\ndirectory for files that contain the string  job.load  to find the relevant configuration keys.  These\nconfiguration keys control the load for each job type.  For example, the  job.load.download.distribute  configuration\nkey controls the load placed on the system when a download distribution job is running.  Note: Ingest jobs are a special case in Opencast.  Because of their immediate nature there is no way to limit the number\nof running jobs.  However, these jobs will block other jobs from running on the ingest/admin nodes if enough ingests\nrunning concurrently.",
            "title": "Step 2: Setting the load values for system jobs"
        },
        {
            "location": "/configuration/load/#step-3-setting-the-load-values-for-encoding-profiles",
            "text": "Each encoding profile can have a load value associated with it.  By default, we have not set any, which means that the\ndefault value of 0.8 is used.  To set the load associated with a profile, you simply add a .jobload key to the profile.\nFor example, the composite encoding profile is prefixed with  profile.composite.http .  If we want to set a different\njob load than the default, we would create the  profile.composite.http.jobload  key, and set it to an appropriate job value.",
            "title": "Step 3: Setting the load values for encoding profiles"
        },
        {
            "location": "/configuration/load/#step-4-restart-opencast",
            "text": "Many of these configuration files are only read on startup, so restarting Opencast is strongly recommended.",
            "title": "Step 4: Restart Opencast"
        },
        {
            "location": "/configuration/load/#troubleshooting",
            "text": "",
            "title": "Troubleshooting"
        },
        {
            "location": "/configuration/load/#help-my-system-has-deadlocked-or-there-are-jobs-which-are-always-queued-even-if-the-system-is-otherwise-idle",
            "text": "This can be caused by setting a job weight that exceeds the maximum load for  all  services of a given type.  For\nexample, if you have a single worker with 8 cores and set an encoding job to have a jobload of 9.  Fortunately, there is\na simple resolution to this issue.  Jobs which have already been created do  not  update their load values, even after\nrestarting Opencast.  To resolve a deadlock caused by job loads follow these instructions.  First determine the queued\njob's ID from the admin UI.  This will be an integer greater than zero.  We will call this $jobid.  Once you have the\njob ID, follow these steps:   Stop Opencast  Log into your database  Make sure you are using the right schema. Currently the default is called  opencast  Update the job's load  This will look something like  UPDATE mh_job SET job\\_load=0.0 WHERE id=$jobid    Log out of your database  Change the load specified in the configuration file to an appropriate value  This may need to happen across all nodes!    Restart Opencast",
            "title": "Help, my system has deadlocked, or there are jobs which are always queued even if the system is otherwise idle"
        },
        {
            "location": "/configuration/log/",
            "text": "Log\n\n\nThe settings for logging can be found in:\n\n\n.../etc/org.ops4j.pax.logging.cfg\n\n\n\nEach Log4J appender can be configured in a similar fashion to the graylog example down below. The following\nrequirements have to be met:\n\n It needs to be a Log4J appender\n\n The used bundle needs to be a fragment-bundle\n\n\nGraylog\n\n\nTo have all log data available and accessible in one central location one can use graylog. A guide to install\ngraylog can be found \nhere\n.\n\n\nAdd gelfj-X.X.X.jar (works up to version 1.1.14) to the appropriate folder in the karaf system folder (e.g. \n/system/org/graylog2/gelfj/X.X.X/gelfj-X.X.X.jar\n)\nThe directory has the same structure as a maven repository!\n\n\nIt is important that the appender jar is a valid fragment-bundle of \norg.ops4j.pax.logging.pax-logging-service\n.\n\n\nThat means the jar MANIFEST.MF must contain this section \nFragment-Host: org.ops4j.pax.logging.pax-logging-service\n.\n\n\nAdd the following line at the beginning of the startup.properties file:\n\n\nmvn\\:org.graylog2/gelfj/X.X.X = 7\n\n\n\n\nWe use startlevel \n7\n here, because it's need to be loaded before the \npax-logging\n.\n\n\nAdd this custom logging configuration example to the org.ops4j.pax.logging.cfg file\n\n\n# Async wrapper for send queue in case of GELF destination is unavailable\nlog4j.appender.gelfasync=org.apache.log4j.AsyncAppender\nlog4j.appender.gelfasync.blocking=false\nlog4j.appender.gelfasync.bufferSize=20000\nlog4j.appender.gelfasync.appenders=gelf\n\n# Define the GELF destination\nlog4j.appender.gelf=org.graylog2.log.GelfAppender\nlog4j.appender.gelf.graylogHost=<HOSTNAME OF GRAYLOG INPUT>\nlog4j.appender.gelf.graylogPort=<PORT OF GRAYLOG INPUT>\nlog4j.appender.gelf.originHost=<NAME OF SERVICE>\nlog4j.appender.gelf.facility=karaf\nlog4j.appender.gelf.layout=org.apache.log4j.PatternLayout\nlog4j.appender.gelf.extractStacktrace=true\nlog4j.appender.gelf.addExtendedInformation=true\nlog4j.appender.gelf.includeLocation=true\nlog4j.appender.gelf.additionalFields={'environment': 'EXAMPLE-ENV', 'application': 'EXAMPLE-APP'}\n\n\n\n\nNote:\n The default protocol is UDP to use TCP instead, prefix hostname with \ntcp:\n.\n\n\nAdd the new appender to the rootLogger\n\n\nlog4j.rootLogger=WARN, stdout, osgi:*, gelfasync\n\n\n\n\nExample Configuration\n\n\n# Define the GELF destination\nlog4j.appender.gelf=org.graylog2.log.GelfAppender\nlog4j.appender.gelf.graylogHost=tcp:graylog.opencast.org\nlog4j.appender.gelf.graylogPort=12290\nlog4j.appender.gelf.originHost=test.opencast.org\nlog4j.appender.gelf.facility=karaf\nlog4j.appender.gelf.layout=org.apache.log4j.PatternLayout\nlog4j.appender.gelf.extractStacktrace=true\nlog4j.appender.gelf.addExtendedInformation=true\nlog4j.appender.gelf.includeLocation=true\nlog4j.appender.gelf.additionalFields={'environment': 'OPENCAST-TEST-ENV', 'application': 'OC-ADMIN'}\n\n\n\n\nYou can find further gelf appender documentation \nhere\n.",
            "title": "Log"
        },
        {
            "location": "/configuration/log/#log",
            "text": "The settings for logging can be found in:  .../etc/org.ops4j.pax.logging.cfg  Each Log4J appender can be configured in a similar fashion to the graylog example down below. The following\nrequirements have to be met:  It needs to be a Log4J appender  The used bundle needs to be a fragment-bundle",
            "title": "Log"
        },
        {
            "location": "/configuration/log/#graylog",
            "text": "To have all log data available and accessible in one central location one can use graylog. A guide to install\ngraylog can be found  here .  Add gelfj-X.X.X.jar (works up to version 1.1.14) to the appropriate folder in the karaf system folder (e.g.  /system/org/graylog2/gelfj/X.X.X/gelfj-X.X.X.jar )\nThe directory has the same structure as a maven repository!  It is important that the appender jar is a valid fragment-bundle of  org.ops4j.pax.logging.pax-logging-service .  That means the jar MANIFEST.MF must contain this section  Fragment-Host: org.ops4j.pax.logging.pax-logging-service .  Add the following line at the beginning of the startup.properties file:  mvn\\:org.graylog2/gelfj/X.X.X = 7  We use startlevel  7  here, because it's need to be loaded before the  pax-logging .  Add this custom logging configuration example to the org.ops4j.pax.logging.cfg file  # Async wrapper for send queue in case of GELF destination is unavailable\nlog4j.appender.gelfasync=org.apache.log4j.AsyncAppender\nlog4j.appender.gelfasync.blocking=false\nlog4j.appender.gelfasync.bufferSize=20000\nlog4j.appender.gelfasync.appenders=gelf\n\n# Define the GELF destination\nlog4j.appender.gelf=org.graylog2.log.GelfAppender\nlog4j.appender.gelf.graylogHost=<HOSTNAME OF GRAYLOG INPUT>\nlog4j.appender.gelf.graylogPort=<PORT OF GRAYLOG INPUT>\nlog4j.appender.gelf.originHost=<NAME OF SERVICE>\nlog4j.appender.gelf.facility=karaf\nlog4j.appender.gelf.layout=org.apache.log4j.PatternLayout\nlog4j.appender.gelf.extractStacktrace=true\nlog4j.appender.gelf.addExtendedInformation=true\nlog4j.appender.gelf.includeLocation=true\nlog4j.appender.gelf.additionalFields={'environment': 'EXAMPLE-ENV', 'application': 'EXAMPLE-APP'}  Note:  The default protocol is UDP to use TCP instead, prefix hostname with  tcp: .  Add the new appender to the rootLogger  log4j.rootLogger=WARN, stdout, osgi:*, gelfasync",
            "title": "Graylog"
        },
        {
            "location": "/configuration/log/#example-configuration",
            "text": "# Define the GELF destination\nlog4j.appender.gelf=org.graylog2.log.GelfAppender\nlog4j.appender.gelf.graylogHost=tcp:graylog.opencast.org\nlog4j.appender.gelf.graylogPort=12290\nlog4j.appender.gelf.originHost=test.opencast.org\nlog4j.appender.gelf.facility=karaf\nlog4j.appender.gelf.layout=org.apache.log4j.PatternLayout\nlog4j.appender.gelf.extractStacktrace=true\nlog4j.appender.gelf.addExtendedInformation=true\nlog4j.appender.gelf.includeLocation=true\nlog4j.appender.gelf.additionalFields={'environment': 'OPENCAST-TEST-ENV', 'application': 'OC-ADMIN'}  You can find further gelf appender documentation  here .",
            "title": "Example Configuration"
        },
        {
            "location": "/configuration/user-statistics.and.privacy/",
            "text": "User Statistics and Privacy\n\n\nThere exists a newer and more complete tracking service using Matomo included \nas a module\n.\n\n\nThe Opencast User-Tracking service stores user actions of the Opencast players in the database. This data is used for\nthe footprint feature of the player and for the optional analytics component.\n\n\n\n\nNote that enabling all of the tracking options may result in legal problems depending on your country's privacy laws\nand the type of service you are running.\n\n\n\n\nThe settings for tracking user data can be found in:\n\n\n.../etc/org.opencastproject.usertracking.impl.UserTrackingServiceImpl.cfg\n\n\n\nTracking of user data can be controlled on two levels. First, tracking can be generally activated or deactivated. Second,\nif it is activated, the data being tracked can be defined.\n\n\norg.opencastproject.usertracking.detailedtrack\n defines if the user tracking JavaScript code is loaded and data about\nuser actions are being sent to and stored by Opencast. Deactivating this will effectively stop all tracking. This may\neffect features like the footprints in the Opencast player.  Default: \ntrue\n.\n\n\nIf tracking is still activated, the following keys may be used to define the kind of data that is being tracked. The keys\nhave no effect if tracking is turned off.\n\n\n\n\n\n\n\n\nKey\n\n\nData to be tracked\n\n\nDefault value\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.usertracking.log.ip\n\n\nIP addresses\n\n\nfalse\n\n\n\n\n\n\norg.opencastproject.usertracking.log.user\n\n\nlogin names of users\n\n\nfalse\n\n\n\n\n\n\norg.opencastproject.usertracking.log.session\n\n\nBrowser session-IDs\n\n\nfalse\n\n\n\n\n\n\n\n\nIf you want to use the footprint feature but do not want to store any user specific data you can turn the tracking of IP\naddresses, usernames and session-IDs off.",
            "title": "User Statistics and Privacy Configuration"
        },
        {
            "location": "/configuration/user-statistics.and.privacy/#user-statistics-and-privacy",
            "text": "There exists a newer and more complete tracking service using Matomo included  as a module .  The Opencast User-Tracking service stores user actions of the Opencast players in the database. This data is used for\nthe footprint feature of the player and for the optional analytics component.   Note that enabling all of the tracking options may result in legal problems depending on your country's privacy laws\nand the type of service you are running.   The settings for tracking user data can be found in:  .../etc/org.opencastproject.usertracking.impl.UserTrackingServiceImpl.cfg  Tracking of user data can be controlled on two levels. First, tracking can be generally activated or deactivated. Second,\nif it is activated, the data being tracked can be defined.  org.opencastproject.usertracking.detailedtrack  defines if the user tracking JavaScript code is loaded and data about\nuser actions are being sent to and stored by Opencast. Deactivating this will effectively stop all tracking. This may\neffect features like the footprints in the Opencast player.  Default:  true .  If tracking is still activated, the following keys may be used to define the kind of data that is being tracked. The keys\nhave no effect if tracking is turned off.     Key  Data to be tracked  Default value      org.opencastproject.usertracking.log.ip  IP addresses  false    org.opencastproject.usertracking.log.user  login names of users  false    org.opencastproject.usertracking.log.session  Browser session-IDs  false     If you want to use the footprint feature but do not want to store any user specific data you can turn the tracking of IP\naddresses, usernames and session-IDs off.",
            "title": "User Statistics and Privacy"
        },
        {
            "location": "/configuration/multi.tenancy/",
            "text": "Multi Tenancy Configuration\n\n\nIntroduction\n\n\nA single Opencast instance can handle mutliple tenants, each of which have their own recordings in the system.\nOpencast refers to tenants as \norganizations\n, and an HTTP request to the Opencast installation is mapped to an\norganization using the server name. Therefore, a Opencast instance will usually be set up with multiple DNS names\npointing to the same IP, for example:\n\n\n\n\nadmin.example.org\n\n\ntenant1-admin.example.org\n\n\ntenant2-admin.example.org\n\n\n\n\nshould all resolve to the same IP.\n\n\nA tenant configuration thus consists mainly of the DNS name that is mapped to that tenant.\n\n\nDefault Setup\n\n\nOut of the box, Opencast has one tenant configured, called \nmh_default_org\n that is mapped to the server name\n\nlocalhost:8080\n. As long as there is one tenant configuration only, Opencast will map every request to that tenant\nregardless of the server name. As soon as a second tenant configuration is available, requests will be mapped to\norganizations using the server name, and an HTTP status code 404 will be returned for requests that hit the Opencast\nintallation that cannot be mapped to any organization.\n\n\nLimitations\n\n\nMulti tenancy in Opencast is working, however it is not fully finished. Certain objects are still shared amongst\norganizations, most notably workflow definitions, RSS/Atom feeds and encoding profiles.\n\n\nAdding A Tenant\n\n\nTo add a tenant to the installation, two things need to be put in place: a tenant configuration and a set of security\nrules. For this example we have a three node install of \nadmin.opencast.org\n, \nworker.opencast.org\n, and\n\npresentation.opencast.org\n.  Assume that the new tenant is called \ntenant1\n and should be mapped to\n\ntenant1-*.opencast.org\n.\n\n\nTenant Configuration\n\n\nCreate a file called org.opencastproject.organization-tenant1.cfg in the \netc/\n directory of your Opencast\ninstallation, on each of the nodes.  As an example, this is what the admin node looks like:\n\n\nid=tenant1\nname=Tenant 1\nserver=tenant1-admin.opencast.org,tenant1-presentation.opencast.org\nport=8080\nadmin_role=ROLE_ADMIN\nanonymous_role=ROLE_ANONYMOUS\n\n# Admin and Presentation Server Urls\nprop.org.opencastproject.admin.ui.url=https://tenant1-admin.opencast.org\nprop.org.opencastproject.engage.ui.url=https://tenant1-presentation.opencast.org\n\n# Default properties for the user interface\nprop.logo_mediamodule=/engage/ui/img/logo/opencast-icon.svg\nprop.logo_player=/engage/ui/img/logo/opencast.svg\n\n\n\nThere are more options available than in this example. The easiest way of creating that file is probably to create a\ncopy of the already existing \norg.opencastproject.organization-mh_default_org.cfg\n.\n\n\nNote, the default organization file \norg.opencastproject.organization-mh_default_org.org\n \nmust\n refer to the actual\nserver names:\n\n\nserver=admin.opencast.org\n\n\n\nThis file sets the default organization that is selected.  This is currently required because some Opencast components\ndo not support multitenancy.\n\n\nNote that if you are running Apache httpd with mod_proxy in front of the Opencast installation, the port number will be\n-1 in both files.\n\n\nSecurity Configuration\n\n\nCreate a file called tenant1.xml in /etc/security. This file specifies access rules for individual urls that specify\nwhich roles are needed in order to access a given url. In addition, it allows to define the directory services that are\nused to authenticate users. The file follows the standard ways on configuring Spring Security and you are free to add\nanything that can go into a Spring Security configuration.\n\n\nThe easiest way of creating that file is probably to create a copy of the already existing \nmh_default_org.xml\n.\n\n\nOther Configuration\n\n\nTwo additional files should be copied: \norg.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg\n\nshould be copied to \norg.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common-tenant1.cfg\n, and\n\norg.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common.cfg\n should be copied to\n\norg.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common-tenant1.cfg\n.\n\n\nIn each of the new configuration files, change \norganization\n key to match the tenant id, and change the\n\ncommon-metadata\n key to false.  Create a copy of the files for each tenant.  Note: The original \n...-common.cfg\n files\n\nmust\n have their \ncommon-metadata\n keys set to true, otherwise metadata will only be available in one tenant and you\nwill experience a number of odd errors.",
            "title": "Multi Tenancy"
        },
        {
            "location": "/configuration/multi.tenancy/#multi-tenancy-configuration",
            "text": "",
            "title": "Multi Tenancy Configuration"
        },
        {
            "location": "/configuration/multi.tenancy/#introduction",
            "text": "A single Opencast instance can handle mutliple tenants, each of which have their own recordings in the system.\nOpencast refers to tenants as  organizations , and an HTTP request to the Opencast installation is mapped to an\norganization using the server name. Therefore, a Opencast instance will usually be set up with multiple DNS names\npointing to the same IP, for example:   admin.example.org  tenant1-admin.example.org  tenant2-admin.example.org   should all resolve to the same IP.  A tenant configuration thus consists mainly of the DNS name that is mapped to that tenant.",
            "title": "Introduction"
        },
        {
            "location": "/configuration/multi.tenancy/#default-setup",
            "text": "Out of the box, Opencast has one tenant configured, called  mh_default_org  that is mapped to the server name localhost:8080 . As long as there is one tenant configuration only, Opencast will map every request to that tenant\nregardless of the server name. As soon as a second tenant configuration is available, requests will be mapped to\norganizations using the server name, and an HTTP status code 404 will be returned for requests that hit the Opencast\nintallation that cannot be mapped to any organization.",
            "title": "Default Setup"
        },
        {
            "location": "/configuration/multi.tenancy/#limitations",
            "text": "Multi tenancy in Opencast is working, however it is not fully finished. Certain objects are still shared amongst\norganizations, most notably workflow definitions, RSS/Atom feeds and encoding profiles.",
            "title": "Limitations"
        },
        {
            "location": "/configuration/multi.tenancy/#adding-a-tenant",
            "text": "To add a tenant to the installation, two things need to be put in place: a tenant configuration and a set of security\nrules. For this example we have a three node install of  admin.opencast.org ,  worker.opencast.org , and presentation.opencast.org .  Assume that the new tenant is called  tenant1  and should be mapped to tenant1-*.opencast.org .",
            "title": "Adding A Tenant"
        },
        {
            "location": "/configuration/multi.tenancy/#tenant-configuration",
            "text": "Create a file called org.opencastproject.organization-tenant1.cfg in the  etc/  directory of your Opencast\ninstallation, on each of the nodes.  As an example, this is what the admin node looks like:  id=tenant1\nname=Tenant 1\nserver=tenant1-admin.opencast.org,tenant1-presentation.opencast.org\nport=8080\nadmin_role=ROLE_ADMIN\nanonymous_role=ROLE_ANONYMOUS\n\n# Admin and Presentation Server Urls\nprop.org.opencastproject.admin.ui.url=https://tenant1-admin.opencast.org\nprop.org.opencastproject.engage.ui.url=https://tenant1-presentation.opencast.org\n\n# Default properties for the user interface\nprop.logo_mediamodule=/engage/ui/img/logo/opencast-icon.svg\nprop.logo_player=/engage/ui/img/logo/opencast.svg  There are more options available than in this example. The easiest way of creating that file is probably to create a\ncopy of the already existing  org.opencastproject.organization-mh_default_org.cfg .  Note, the default organization file  org.opencastproject.organization-mh_default_org.org   must  refer to the actual\nserver names:  server=admin.opencast.org  This file sets the default organization that is selected.  This is currently required because some Opencast components\ndo not support multitenancy.  Note that if you are running Apache httpd with mod_proxy in front of the Opencast installation, the port number will be\n-1 in both files.",
            "title": "Tenant Configuration"
        },
        {
            "location": "/configuration/multi.tenancy/#security-configuration",
            "text": "Create a file called tenant1.xml in /etc/security. This file specifies access rules for individual urls that specify\nwhich roles are needed in order to access a given url. In addition, it allows to define the directory services that are\nused to authenticate users. The file follows the standard ways on configuring Spring Security and you are free to add\nanything that can go into a Spring Security configuration.  The easiest way of creating that file is probably to create a copy of the already existing  mh_default_org.xml .",
            "title": "Security Configuration"
        },
        {
            "location": "/configuration/multi.tenancy/#other-configuration",
            "text": "Two additional files should be copied:  org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg \nshould be copied to  org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common-tenant1.cfg , and org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common.cfg  should be copied to org.opencastproject.ui.metadata.CatalogUIAdapterFactory-series-common-tenant1.cfg .  In each of the new configuration files, change  organization  key to match the tenant id, and change the common-metadata  key to false.  Create a copy of the files for each tenant.  Note: The original  ...-common.cfg  files must  have their  common-metadata  keys set to true, otherwise metadata will only be available in one tenant and you\nwill experience a number of odd errors.",
            "title": "Other Configuration"
        },
        {
            "location": "/configuration/security/",
            "text": "Security Configuration\n\n\nThis document will help you configure the Opencast security policy.\n\n\nIntroduction\n\n\nOpencast service endpoints and user interfaces are secured by default using a set of servlet filters. The following\ndiagram illustrates the flow of an HTTP request and response through these filters.\n\n\n\n\nThe Spring Security filters used here are very powerful, but are also somewhat complicated. Please familiarize yourself\nwith the basic concepts and vocabulary described in the Spring Security documentation, then edit the xml files in\n\netc/security\n, as described below.\n\n\nConfigure Access\n\n\nTo configure access roles and URL patterns for a tenant, modify \n/etc/security/{{tenant_identifier.xml}}\n.  If you are\nnot hosting multiple tenants on your Opencast server or cluster, all configuration should be done in\n\nmh_default_org.xml\n.\n\n\nSome examples:\n\n\n<!-- Allow anonymous access to the welcome.html URLs -->\n<sec:intercept-url pattern='/welcome.html' access='ROLE_ANONYMOUS,ROLE_USER'/>\n\n<!-- Allow anonymous GET to the search service, but not POST or PUT -->\n<sec:intercept-url pattern='/search/**' method=\"GET\" access='ROLE_ANONYMOUS,ROLE_USER' />\n\n<!-- Allow users with the admin role to do anything -->\n<sec:intercept-url pattern='/**' access='ROLE_ADMIN'/>\n\n\n\nAuthentication Provider\n\n\nOpencast specifies an AuthenticationProvider by default, using a UserDetailService that is obtained from the OSGI\nservice registry.\n\n\nYou can use this simple provider as is, loading users into the \nmh_user\n and \nmh_role\n database tables, and specifying\nan administrative username and password in \ncustom.properties\n:\n\n\norg.opencastproject.security.digest.user=opencast_system_account\norg.opencastproject.security.digest.pass=CHANGE_ME\n\n\n\nUser and Role Providers\n\n\nOpencast allows user and role information to be supplied from external systems through user and role providers.\nTwo user providers are available by default:\n\n\n\n\nLDAP User Provider, described in \nLDAP Security and Authorization\n\n\nSakai User Provider\n\n\n\n\nThe set of user and role providers can be configured. If you do not want to keep users and passwords in Opencast's\ndatabase, you can replace the JpaUserAndRoleProvider with the LdapUserProvider by replacing the\nuserdirectory-jpa jar with the userdirectory-ldap jar.\n\n\nFurther Authentication Configuration\n\n\n\n\nConfigure Central Authentication Service (CAS)\n\n\nConfigure LDAP Authentication and Authorization\n\n\nConfigure Authentication and Authorization Infrastructure (AAI))",
            "title": "General Security"
        },
        {
            "location": "/configuration/security/#security-configuration",
            "text": "This document will help you configure the Opencast security policy.",
            "title": "Security Configuration"
        },
        {
            "location": "/configuration/security/#introduction",
            "text": "Opencast service endpoints and user interfaces are secured by default using a set of servlet filters. The following\ndiagram illustrates the flow of an HTTP request and response through these filters.   The Spring Security filters used here are very powerful, but are also somewhat complicated. Please familiarize yourself\nwith the basic concepts and vocabulary described in the Spring Security documentation, then edit the xml files in etc/security , as described below.",
            "title": "Introduction"
        },
        {
            "location": "/configuration/security/#configure-access",
            "text": "To configure access roles and URL patterns for a tenant, modify  /etc/security/{{tenant_identifier.xml}} .  If you are\nnot hosting multiple tenants on your Opencast server or cluster, all configuration should be done in mh_default_org.xml .  Some examples:  <!-- Allow anonymous access to the welcome.html URLs -->\n<sec:intercept-url pattern='/welcome.html' access='ROLE_ANONYMOUS,ROLE_USER'/>\n\n<!-- Allow anonymous GET to the search service, but not POST or PUT -->\n<sec:intercept-url pattern='/search/**' method=\"GET\" access='ROLE_ANONYMOUS,ROLE_USER' />\n\n<!-- Allow users with the admin role to do anything -->\n<sec:intercept-url pattern='/**' access='ROLE_ADMIN'/>",
            "title": "Configure Access"
        },
        {
            "location": "/configuration/security/#authentication-provider",
            "text": "Opencast specifies an AuthenticationProvider by default, using a UserDetailService that is obtained from the OSGI\nservice registry.  You can use this simple provider as is, loading users into the  mh_user  and  mh_role  database tables, and specifying\nan administrative username and password in  custom.properties :  org.opencastproject.security.digest.user=opencast_system_account\norg.opencastproject.security.digest.pass=CHANGE_ME",
            "title": "Authentication Provider"
        },
        {
            "location": "/configuration/security/#user-and-role-providers",
            "text": "Opencast allows user and role information to be supplied from external systems through user and role providers.\nTwo user providers are available by default:   LDAP User Provider, described in  LDAP Security and Authorization  Sakai User Provider   The set of user and role providers can be configured. If you do not want to keep users and passwords in Opencast's\ndatabase, you can replace the JpaUserAndRoleProvider with the LdapUserProvider by replacing the\nuserdirectory-jpa jar with the userdirectory-ldap jar.",
            "title": "User and Role Providers"
        },
        {
            "location": "/configuration/security/#further-authentication-configuration",
            "text": "Configure Central Authentication Service (CAS)  Configure LDAP Authentication and Authorization  Configure Authentication and Authorization Infrastructure (AAI))",
            "title": "Further Authentication Configuration"
        },
        {
            "location": "/configuration/acl/",
            "text": "Access Control List Configuration\n\n\nThis document describes configuration options considering the access control lists (ACL) used by\nOpencast for authorization.\n\n\nACL Templates\n\n\nOn startup, Opencast loads all ACL templates found in \n/opt/opencast/etc/acl/\n.\n\n\nNotes:\n\n\n\n\nACL templates can also be created and managed directly in the Admin UI\n\n\n\n\nAdditional ACL Actions\n\n\nOpencast uses to ACL actions to authorize roles to perform specific actions on a given object:\n\n\n\n\nread\n allows the role to access to object\n\n\nwrite\n allows the role to modify the object\n\n\n\n\nThose built-in actions are known to Opencast.\n\n\nIn case you need other ACL actions, you can configure additional ACL actions in\n\n/opt/opencast/etc/listprovides/acl.additional.actions.properties\n. Those additional ACL actions are not affecting the way\nOpencast treats objects but are simply just forwarded to publication channels so that third-party applications\n(expecting those specific ACL actions) can implement the respective authorization logic.\n\n\nExample:\n\n\nlist.name=ACL.ACTIONS\n# This list provider allows you to configure custom actions that can be added\n# to ACLs. The default actions are read and write.\n# The pattern for adding them is\n# UI_LABEL=actionId\n#\nUpload=myorg_upload\nDownload=myorg_downlaod\n\n\n\nIn the example above, the two additional ACL actions \nUpload\n and \nDownload\n have been configured.\nThe ACL editor of the Admin UI will allow the user to set those actions.\n\n\nNotes:\n\n\n\n\nTo ensure compatibility with future Opencast versions, it is highly recommended to use a prefix for your\ncustomized additional actions in case later Opencast versions would introduce an action with the same name",
            "title": "Access Control Lists"
        },
        {
            "location": "/configuration/acl/#access-control-list-configuration",
            "text": "This document describes configuration options considering the access control lists (ACL) used by\nOpencast for authorization.",
            "title": "Access Control List Configuration"
        },
        {
            "location": "/configuration/acl/#acl-templates",
            "text": "On startup, Opencast loads all ACL templates found in  /opt/opencast/etc/acl/ .  Notes:   ACL templates can also be created and managed directly in the Admin UI",
            "title": "ACL Templates"
        },
        {
            "location": "/configuration/acl/#additional-acl-actions",
            "text": "Opencast uses to ACL actions to authorize roles to perform specific actions on a given object:   read  allows the role to access to object  write  allows the role to modify the object   Those built-in actions are known to Opencast.  In case you need other ACL actions, you can configure additional ACL actions in /opt/opencast/etc/listprovides/acl.additional.actions.properties . Those additional ACL actions are not affecting the way\nOpencast treats objects but are simply just forwarded to publication channels so that third-party applications\n(expecting those specific ACL actions) can implement the respective authorization logic.  Example:  list.name=ACL.ACTIONS\n# This list provider allows you to configure custom actions that can be added\n# to ACLs. The default actions are read and write.\n# The pattern for adding them is\n# UI_LABEL=actionId\n#\nUpload=myorg_upload\nDownload=myorg_downlaod  In the example above, the two additional ACL actions  Upload  and  Download  have been configured.\nThe ACL editor of the Admin UI will allow the user to set those actions.  Notes:   To ensure compatibility with future Opencast versions, it is highly recommended to use a prefix for your\ncustomized additional actions in case later Opencast versions would introduce an action with the same name",
            "title": "Additional ACL Actions"
        },
        {
            "location": "/configuration/security.aai/",
            "text": "Authentication and Authorization Infrastructure (AAI) Configuration\n\n\nThis page describes how to configure Opencast to take advantage of the Authentication and Authorization\nInfrastructure (AAI).\n\n\nPrerequesites\n\n\nThis guides assumes that you know how to setup and configure a Shibboleth Service Provider, i.e. you are assumed\nto already have performed the following steps:\n\n\n\n\nRegisteration of your Shibboleth Service Provider at your Shibboleth Federation Service Registry\n\n\nSetup and configuration of Shibboleth on the servers you want to use it\n\n\nConfiguration of your web server\n\n\n\n\nIn case you require help on this, contact the institution responsilbe for managing the Shibboleth Federation you\nare part of.\n\n\nAn informative list of Shibboleth Federations can be found on:\n\n\nhttps://refeds.org/federations\n\n\nStep 1: Configuration of the AAI Login handler\n\n\nOpencast ships with a configurable AAI Login handler that needs to be adjusted to your environment.\nThe configuration can be found in \netc/org.opencastproject.security.aai.ConfigurableLoginHandler.cfg\n.\n\n\nFirst off all, enable the AAI login handler:\n\n\nenabled=true\n\n\n\nFor bootstrapping purposes, you might want to configure the AAI bootstrap user:\n\n\nbootstrap.user.id=<AAI ID>\n\n\n\nThat user will be assigned ROLE_ADMIN at login time. This enables you to access the administrative UI and\nconfigure user authorization without the need to fiddle with the database directly.\nOnce user authorization has been setup, disable the AAI bootstrap user.\n\n\nSince the HTTP request header names required by the AAI login handler are specific to Shibboleth Federations,\nyou will need to first adjust the following properties.\n\n\nSet the following header names to the correct values:\n\n\nheader.given_name = \"<Name of Shibboleth attribute>\"\nheader.surname = \"<Name of Shibboleth attribute>\"\nheader.email = \"<Name of Shibboleth attribute>\"\nheader.home_organization = \"<Name of Shibboleth attribute>\"\n\n\n\nOptionally, you can configure the name of some basic roles the AAI login handler will assign to authenticated users.\n\n\nThe prefix of the user role will determine what unique role a given Shibboleth user has. The role is of the\nform \nrole.user.prefix + Unique ID provided by Shibboleth\n.\n\n\nrole.user.prefix = \"ROLE_AAI_USER_\"\n\n\n\nTo indicate the AAI home organization a user belongs to, the organization membership role is assigned to the user.\nThe role is of the form \nrole.organization.prefix + Home Organization provided by Shibboleth +\nrole.organization.suffix\n\n\nrole.organization.prefix = \"ROLE_AAI_ORG_\"\nrole.organization.suffix = \"_MEMBER\"\n\n\n\nTo indicate the fact that a user has authenticated himself using Shibboleth, the login handler assigns the\nrole as specified by the property \nrole.federation\n.\n\n\nrole.federation = \"ROLE_AAI_USER\"\n\n\n\nStep 2: Spring Security Configuration\n\n\nIn order to take advantage of Shibboleth authentication, you will need to uncomment the following lines found\nin \netc/security/mh_default_org.xml\n:\n\n\nThe Shibboleth header authentification filter needs to be enabled to get access to the Shibboleth information\nwithin the HTTP request headers.\n\n\n<!-- Shibboleth header authentication filter -->\n<sec:custom-filter ref=\"shibbolethHeaderFilter\" position=\"PRE_AUTH_FILTER\"/>\n\n\n\nTo ensure that a logout is not just logging out the user from the Opencast application but also from Shibboleth,\nyou will need to configure the logout-success-url:\n\n\n<!-- Enables log out -->\n<sec:logout logout-success-url=\"/Shibboleth.sso/Logout?return=www.opencast.org\" />\n\n\n\nIMPORTANT:\n In the section \nShibboleth Support\n, be sure to adapt the value of \nprincipalRequestHeader\n to the\nrespective name of the Shibboleth attribute you use in your Shibboleth Federation:\n\n\n<!-- ###################### -->\n<!-- # Shibboleth Support # -->\n<!-- ###################### -->\n\n<!-- General Shibboleth header extration filter -->\n<bean id=\"shibbolethHeaderFilter\"\n      class=\"org.opencastproject.security.shibboleth.ShibbolethRequestHeaderAuthenticationFilter\">\n  <property name=\"principalRequestHeader\" value=\"<Shibboleth attribute name>\"/>\n  <property name=\"authenticationManager\" ref=\"authenticationManager\" />\n  <property name=\"userDetailsService\" ref=\"userDetailsService\" />\n  <property name=\"userDirectoryService\" ref=\"userDirectoryService\" />\n  <property name=\"shibbolethLoginHandler\" ref=\"configurableLoginHandler\" />\n  <property name=\"exceptionIfHeaderMissing\" value=\"false\" />\n</bean>\n\n<!-- AAI specific header extractor and user generator -->\n<bean id=\"configurableLoginHandler\" class=\"org.opencastproject.security.aai.ConfigurableLoginHandler\">\n  <property name=\"securityService\" ref=\"securityService\" />\n  <property name=\"userReferenceProvider\" ref=\"userReferenceProvider\" />\n</bean>\n\n<bean id=\"preauthAuthProvider\"\n      class=\"org.springframework.security.web.authentication.preauth.PreAuthenticatedAuthenticationProvider\">\n  <property name=\"preAuthenticatedUserDetailsService\">\n    <bean id=\"userDetailsServiceWrapper\"\n          class=\"org.springframework.security.core.userdetails.UserDetailsByNameServiceWrapper\">\n      <property name=\"userDetailsService\" ref=\"userDetailsService\"/>\n    </bean>\n  </property>\n</bean>\n\n\n\nFinally be sure to enable the user reference provider to enable support for externally provided users:\n\n\n<osgi:reference id=\"userReferenceProvider\" cardinality=\"1..1\"\n              interface=\"org.opencastproject.userdirectory.api.UserReferenceProvider\" />\n\n\n\nSince the Opencast login page is not used when Shibboleth authentication is in place, there is no point in redirecting\nunauthenticated requests to the Opencast login form. You can redirect them directly to the administrative user\ninterface which is supposed to be protected by Shibboleth.\n\n\n<!-- Redirects unauthenticated requests to the login form -->\n<bean id=\"userEntryPoint\" class=\"org.springframework.security.web.authentication.LoginUrlAuthenticationEntryPoint\">\n  <property name=\"loginFormUrl\" value=\"/admin-ng/index.html\" />\n</bean>\n\n\n\nLast but not least, you need to add the \npreauthAuthProvider\n authentication provider to the \nauthentication-manager\n:\n\n\n<sec:authentication-manager alias=\"authenticationManager\">\n  <sec:authentication-provider ref=\"preauthAuthProvider\">\n  <sec:authentication-provider user-service-ref=\"userDetailsService\">\n    <sec:password-encoder hash=\"md5\"><sec:salt-source user-property=\"username\" /></sec:password-encoder>\n  </sec:authentication-provider>\n</sec:authentication-manager>\n\n\n\nStep 3: Protecting HTML pages by Shibboleth\n\n\nIt is important to understand that Shibboleth is only used to protect content that is accessed by human users.\nAccess to APIs is protected by other means of authentication as, for example, digest authentication.\n\n\nTo protect HTML pages, you will need to adapt the configuration of your web server:\n\n\n<LocationMatch \\.(htm|html)$>\n    AuthType shibboleth\n    ShibRequireSession On\n    ShibUseHeaders On\n    require valid-user\n</LocationMatch>",
            "title": "Authentication and Authorization Infrastructure (AAI)"
        },
        {
            "location": "/configuration/security.aai/#authentication-and-authorization-infrastructure-aai-configuration",
            "text": "This page describes how to configure Opencast to take advantage of the Authentication and Authorization\nInfrastructure (AAI).",
            "title": "Authentication and Authorization Infrastructure (AAI) Configuration"
        },
        {
            "location": "/configuration/security.aai/#prerequesites",
            "text": "This guides assumes that you know how to setup and configure a Shibboleth Service Provider, i.e. you are assumed\nto already have performed the following steps:   Registeration of your Shibboleth Service Provider at your Shibboleth Federation Service Registry  Setup and configuration of Shibboleth on the servers you want to use it  Configuration of your web server   In case you require help on this, contact the institution responsilbe for managing the Shibboleth Federation you\nare part of.  An informative list of Shibboleth Federations can be found on:  https://refeds.org/federations",
            "title": "Prerequesites"
        },
        {
            "location": "/configuration/security.aai/#step-1-configuration-of-the-aai-login-handler",
            "text": "Opencast ships with a configurable AAI Login handler that needs to be adjusted to your environment.\nThe configuration can be found in  etc/org.opencastproject.security.aai.ConfigurableLoginHandler.cfg .  First off all, enable the AAI login handler:  enabled=true  For bootstrapping purposes, you might want to configure the AAI bootstrap user:  bootstrap.user.id=<AAI ID>  That user will be assigned ROLE_ADMIN at login time. This enables you to access the administrative UI and\nconfigure user authorization without the need to fiddle with the database directly.\nOnce user authorization has been setup, disable the AAI bootstrap user.  Since the HTTP request header names required by the AAI login handler are specific to Shibboleth Federations,\nyou will need to first adjust the following properties.  Set the following header names to the correct values:  header.given_name = \"<Name of Shibboleth attribute>\"\nheader.surname = \"<Name of Shibboleth attribute>\"\nheader.email = \"<Name of Shibboleth attribute>\"\nheader.home_organization = \"<Name of Shibboleth attribute>\"  Optionally, you can configure the name of some basic roles the AAI login handler will assign to authenticated users.  The prefix of the user role will determine what unique role a given Shibboleth user has. The role is of the\nform  role.user.prefix + Unique ID provided by Shibboleth .  role.user.prefix = \"ROLE_AAI_USER_\"  To indicate the AAI home organization a user belongs to, the organization membership role is assigned to the user.\nThe role is of the form  role.organization.prefix + Home Organization provided by Shibboleth +\nrole.organization.suffix  role.organization.prefix = \"ROLE_AAI_ORG_\"\nrole.organization.suffix = \"_MEMBER\"  To indicate the fact that a user has authenticated himself using Shibboleth, the login handler assigns the\nrole as specified by the property  role.federation .  role.federation = \"ROLE_AAI_USER\"",
            "title": "Step 1: Configuration of the AAI Login handler"
        },
        {
            "location": "/configuration/security.aai/#step-2-spring-security-configuration",
            "text": "In order to take advantage of Shibboleth authentication, you will need to uncomment the following lines found\nin  etc/security/mh_default_org.xml :  The Shibboleth header authentification filter needs to be enabled to get access to the Shibboleth information\nwithin the HTTP request headers.  <!-- Shibboleth header authentication filter -->\n<sec:custom-filter ref=\"shibbolethHeaderFilter\" position=\"PRE_AUTH_FILTER\"/>  To ensure that a logout is not just logging out the user from the Opencast application but also from Shibboleth,\nyou will need to configure the logout-success-url:  <!-- Enables log out -->\n<sec:logout logout-success-url=\"/Shibboleth.sso/Logout?return=www.opencast.org\" />  IMPORTANT:  In the section  Shibboleth Support , be sure to adapt the value of  principalRequestHeader  to the\nrespective name of the Shibboleth attribute you use in your Shibboleth Federation:  <!-- ###################### -->\n<!-- # Shibboleth Support # -->\n<!-- ###################### -->\n\n<!-- General Shibboleth header extration filter -->\n<bean id=\"shibbolethHeaderFilter\"\n      class=\"org.opencastproject.security.shibboleth.ShibbolethRequestHeaderAuthenticationFilter\">\n  <property name=\"principalRequestHeader\" value=\"<Shibboleth attribute name>\"/>\n  <property name=\"authenticationManager\" ref=\"authenticationManager\" />\n  <property name=\"userDetailsService\" ref=\"userDetailsService\" />\n  <property name=\"userDirectoryService\" ref=\"userDirectoryService\" />\n  <property name=\"shibbolethLoginHandler\" ref=\"configurableLoginHandler\" />\n  <property name=\"exceptionIfHeaderMissing\" value=\"false\" />\n</bean>\n\n<!-- AAI specific header extractor and user generator -->\n<bean id=\"configurableLoginHandler\" class=\"org.opencastproject.security.aai.ConfigurableLoginHandler\">\n  <property name=\"securityService\" ref=\"securityService\" />\n  <property name=\"userReferenceProvider\" ref=\"userReferenceProvider\" />\n</bean>\n\n<bean id=\"preauthAuthProvider\"\n      class=\"org.springframework.security.web.authentication.preauth.PreAuthenticatedAuthenticationProvider\">\n  <property name=\"preAuthenticatedUserDetailsService\">\n    <bean id=\"userDetailsServiceWrapper\"\n          class=\"org.springframework.security.core.userdetails.UserDetailsByNameServiceWrapper\">\n      <property name=\"userDetailsService\" ref=\"userDetailsService\"/>\n    </bean>\n  </property>\n</bean>  Finally be sure to enable the user reference provider to enable support for externally provided users:  <osgi:reference id=\"userReferenceProvider\" cardinality=\"1..1\"\n              interface=\"org.opencastproject.userdirectory.api.UserReferenceProvider\" />  Since the Opencast login page is not used when Shibboleth authentication is in place, there is no point in redirecting\nunauthenticated requests to the Opencast login form. You can redirect them directly to the administrative user\ninterface which is supposed to be protected by Shibboleth.  <!-- Redirects unauthenticated requests to the login form -->\n<bean id=\"userEntryPoint\" class=\"org.springframework.security.web.authentication.LoginUrlAuthenticationEntryPoint\">\n  <property name=\"loginFormUrl\" value=\"/admin-ng/index.html\" />\n</bean>  Last but not least, you need to add the  preauthAuthProvider  authentication provider to the  authentication-manager :  <sec:authentication-manager alias=\"authenticationManager\">\n  <sec:authentication-provider ref=\"preauthAuthProvider\">\n  <sec:authentication-provider user-service-ref=\"userDetailsService\">\n    <sec:password-encoder hash=\"md5\"><sec:salt-source user-property=\"username\" /></sec:password-encoder>\n  </sec:authentication-provider>\n</sec:authentication-manager>",
            "title": "Step 2: Spring Security Configuration"
        },
        {
            "location": "/configuration/security.aai/#step-3-protecting-html-pages-by-shibboleth",
            "text": "It is important to understand that Shibboleth is only used to protect content that is accessed by human users.\nAccess to APIs is protected by other means of authentication as, for example, digest authentication.  To protect HTML pages, you will need to adapt the configuration of your web server:  <LocationMatch \\.(htm|html)$>\n    AuthType shibboleth\n    ShibRequireSession On\n    ShibUseHeaders On\n    require valid-user\n</LocationMatch>",
            "title": "Step 3: Protecting HTML pages by Shibboleth"
        },
        {
            "location": "/configuration/security.cas/",
            "text": "Configure Central Authentication Service (CAS)\n\n\nAuthentication\n\n\nMany campuses use some kind of single sign on, such as JASIG's Central Authentication Service, or CAS. This guide\ndescribes how to integrate Opencast into such a system.\n\n\nStep 1\n\n\nFirst, you need to edit the file \netc/org.apache.karaf.features.cfg\n and add the \nopencast-security-cas\n to the\n\nfeaturesBoot\n variable.\n\n\nfeaturesBoot = ..., opencast-security-cas\n\n\n\nStep 2\n\n\nIn a single-tenant deployment, your \nsecurity.xml\n file is under \nOPENCAST_HOME/etc/security/mh_default_org.xml\n. In an\nRPM/DEB based installation, it is located in \n/etc/opencast/security/mh_default_org.xml\n. You should make a backup copy\nof the file and substitute it by the sample file named \nsecurity_sample_cas.xml-example\n. In other words:\n\n\n$> cd etc/security\n$> mv mh_default_org.xml mh_default_org.xml.old\n$> cp security_sample_cas.xml-example mh_default_org.xml\n\n\n\nThe sample file should be exactly the same as the default security file, except for the parts only relevant to the\nCAS. If you have done custom modifications to your security file, make sure to incorporate them to the new file, too.\n\n\nStep 3\n\n\nAdd the necessary configuration values to the CAS section of the new security file. The comments should be\nself-explanatory.\n\n\nYou must modify several settings in the sample to point to your CAS server:\n\n\n<bean id=\"casEntryPoint\" class=\"org.springframework.security.cas.web.CasAuthenticationEntryPoint\">\n  <property name=\"loginUrl\" value=\"https://auth-test.berkeley.edu/cas/login\"/>\n  <property name=\"serviceProperties\" ref=\"serviceProperties\"/>\n</bean>\n\n<bean id=\"casAuthenticationProvider\" class=\"org.springframework.security.cas.authentication.CasAuthenticationProvider\">\n  <property name=\"userDetailsService\" ref=\"userDetailsService\"/>\n  <property name=\"serviceProperties\" ref=\"serviceProperties\" />\n  <property name=\"ticketValidator\">\n    <bean class=\"org.jasig.cas.client.validation.Cas20ServiceTicketValidator\">\n      <constructor-arg index=\"0\" value=\"https://auth-test.berkeley.edu/cas\" />\n    </bean>\n  </property>\n  <property name=\"key\" value=\"cas\"/>\n</bean>\n\n\n\nYou will also need to set the public URL for your Opencast server:\n\n\n<bean id=\"serviceProperties\" class=\"org.springframework.security.cas.ServiceProperties\">\n  <property name=\"service\" value=\"http://localhost:8080/j_spring_cas_security_check\"/>\n  <property name=\"sendRenew\" value=\"false\"/>\n</bean>\n\n\n\nAuthorization\n\n\nNow the system knows all the information necessary to authenticate users against CAS, but also need some authorization\ninformation, to tell which services the user is allowed to use and which resources is allowed to see and/or modify.\n\n\nYou will need to configure a UserProvider to look up users as identified by CAS.\n\n\n\n\nSakai User Provider\n\n\nLDAP User Provider\n (Section \nAuthorization/Step 2\n)\n\n\n\n\nOriginal documentation from University of Saskatchewan\n\n\nUniversity of Saskatchewan CAS and LDAP\nintegration",
            "title": "Central Authentication Service (CAS)"
        },
        {
            "location": "/configuration/security.cas/#configure-central-authentication-service-cas",
            "text": "",
            "title": "Configure Central Authentication Service (CAS)"
        },
        {
            "location": "/configuration/security.cas/#authentication",
            "text": "Many campuses use some kind of single sign on, such as JASIG's Central Authentication Service, or CAS. This guide\ndescribes how to integrate Opencast into such a system.",
            "title": "Authentication"
        },
        {
            "location": "/configuration/security.cas/#step-1",
            "text": "First, you need to edit the file  etc/org.apache.karaf.features.cfg  and add the  opencast-security-cas  to the featuresBoot  variable.  featuresBoot = ..., opencast-security-cas",
            "title": "Step 1"
        },
        {
            "location": "/configuration/security.cas/#step-2",
            "text": "In a single-tenant deployment, your  security.xml  file is under  OPENCAST_HOME/etc/security/mh_default_org.xml . In an\nRPM/DEB based installation, it is located in  /etc/opencast/security/mh_default_org.xml . You should make a backup copy\nof the file and substitute it by the sample file named  security_sample_cas.xml-example . In other words:  $> cd etc/security\n$> mv mh_default_org.xml mh_default_org.xml.old\n$> cp security_sample_cas.xml-example mh_default_org.xml  The sample file should be exactly the same as the default security file, except for the parts only relevant to the\nCAS. If you have done custom modifications to your security file, make sure to incorporate them to the new file, too.",
            "title": "Step 2"
        },
        {
            "location": "/configuration/security.cas/#step-3",
            "text": "Add the necessary configuration values to the CAS section of the new security file. The comments should be\nself-explanatory.  You must modify several settings in the sample to point to your CAS server:  <bean id=\"casEntryPoint\" class=\"org.springframework.security.cas.web.CasAuthenticationEntryPoint\">\n  <property name=\"loginUrl\" value=\"https://auth-test.berkeley.edu/cas/login\"/>\n  <property name=\"serviceProperties\" ref=\"serviceProperties\"/>\n</bean>\n\n<bean id=\"casAuthenticationProvider\" class=\"org.springframework.security.cas.authentication.CasAuthenticationProvider\">\n  <property name=\"userDetailsService\" ref=\"userDetailsService\"/>\n  <property name=\"serviceProperties\" ref=\"serviceProperties\" />\n  <property name=\"ticketValidator\">\n    <bean class=\"org.jasig.cas.client.validation.Cas20ServiceTicketValidator\">\n      <constructor-arg index=\"0\" value=\"https://auth-test.berkeley.edu/cas\" />\n    </bean>\n  </property>\n  <property name=\"key\" value=\"cas\"/>\n</bean>  You will also need to set the public URL for your Opencast server:  <bean id=\"serviceProperties\" class=\"org.springframework.security.cas.ServiceProperties\">\n  <property name=\"service\" value=\"http://localhost:8080/j_spring_cas_security_check\"/>\n  <property name=\"sendRenew\" value=\"false\"/>\n</bean>",
            "title": "Step 3"
        },
        {
            "location": "/configuration/security.cas/#authorization",
            "text": "Now the system knows all the information necessary to authenticate users against CAS, but also need some authorization\ninformation, to tell which services the user is allowed to use and which resources is allowed to see and/or modify.  You will need to configure a UserProvider to look up users as identified by CAS.   Sakai User Provider  LDAP User Provider  (Section  Authorization/Step 2 )",
            "title": "Authorization"
        },
        {
            "location": "/configuration/security.cas/#original-documentation-from-university-of-saskatchewan",
            "text": "University of Saskatchewan CAS and LDAP\nintegration",
            "title": "Original documentation from University of Saskatchewan"
        },
        {
            "location": "/configuration/security.ldap/",
            "text": "LDAP Authentication and Authorization (without CAS)\n\n\n\n\n\n\nThis page describes how to use only an LDAP server to authenticate users in Opencast. If you just want to use LDAP\n\n\nas an identity provider for another authentication mechanism, such as a CAS server, this guide does not apply to\n\n\nyou.\n\n\nYou may find the instructions to configure an LDAP-backed CAS server \nhere\n.\n\n\n\n\n\n\n\n\nThe variable \n$OPENCAST_ETC\n used below stands for the location of Opencast's configuration folder within your\n\n\nsystem. Its location varies depending on whether Opencast was installed from source or a packaged version (e.g. RPM)\n\n\nwas used:\n\n\n\n\nSource installation:\n The \netc\n folder within the directory containing the Opencast code.\n\n\nPackaged installation:\n A subdirectory of your system's usual configuration directory, most likely\n\n\n/etc/opencast\n.*\n\n\n\n\n\n\n\n\nSet up an LDAP provider\n\n\nStep 1\n\n\nOpencast's \nsecurity.xml\n files are located in the folder \n$OPENCAST_ETC/security\n. In a single-tenant deployment, the\nfile is named \n$OPENCAST_ETC/security/mh_default_org.xml\n for the default organization. In a multi-tenant installation,\nor when a non-default organization is used, the file(s) are \n$OPENCAST_ETC/security/<organization_id>.xml\n.\n\n\nYou should make a backup copy of the file and substitute it with the sample file named \nsecurity_sample_ldap.xml-example\n.\nIn other words:\n\n\n$> cd $OPENCAST_ETC/security\n$> mv mh_default_org.xml mh_default_org.xml.old\n$> cp security_sample_ldap.xml-example mh_default_org.xml\n\n\n\nThe sample file should be exactly the same as the replaced security file, except for the parts only relevant to the\nLDAP which will be discussed below. If you have done custom modifications to your security file, please make sure to\nincorporate them to the new file, too.\n\n\nStep 2\n\n\nAdd the necessary configuration values to the LDAP section of the new security file.\n\n\nThe first relevant section defines a context source. This contains the basic login information that enables Opencast to\nrequest information about users from the LDAP server in order to authenticate them.\n\n\n<bean id=\"contextSource\"\n  class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\">\n  <!-- URL of the LDAP server -->\n  <constructor-arg value=\"ldap://myldapserver:myport\" />\n  <!-- \"Distinguished name\" for the unprivileged user -->\n  <!-- This user is merely to perform searches in the LDAP to find the users to login -->\n  <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" />\n  <!-- Password of the user above -->\n  <property name=\"password\" value=\"mypassword\" />\n</bean>\n\n\n\nThe next part tells the system how to search for users in the LDAP server:\n\n\n<constructor-arg>\n  <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\">\n    <constructor-arg ref=\"contextSource\" />\n    <property name=\"userDnPatterns\">\n      <list>\n        <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed -->\n        <value>uid={0},ou=Group,dc=my-institution,dc=country</value>\n      </list>\n    </property>\n    <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them -->\n    <!-- This property can be used together with the \"userDnPatterns\" above -->\n    <!--\n    <property name=\"userSearch\">\n      <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\">\n        < ! - - Base Dn from where the users will be searched for - - >\n        <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" />\n        < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - >\n        <constructor-arg index=\"1\" value=\"(uid={0})\" />\n        <constructor-arg ref=\"contextSource\" />\n      </bean>\n    </property>\n    -->\n  </bean>\n</constructor-arg>\n\n\n\nAs the previous snippet shows, there are two alternative ways to find users in your LDAP:\n\n\n\n\nUsing the property userDnPatterns:\n This property accepts a list of search patterns to match against the user's\nDN. The patterns will be tried in order until a match is found. The placeholder \n{0}\n can be used to represent the\nusername in such patterns.\n\n\nUsing a userSearch filter:\n With the previous approach, it is not possible to find users whose login name is not\n    part of their DN. In such cases, you can use the userSearch property, that allows you to search the users based on a\n    filter. The filter requires three parameters:\n\n\nThe first parameter specifies the \"root node\" where the searches will start from.\n\n\nThe second one specifies the filter, where, again, the placeholder \n{0}\n will be substituted by the username\n  during the searches.\n\n\nThe third parameter should be the contextSource defined above.\n\n\n\n\n\n\n\n\nBoth methods are not mutually exclusive --i.e. both can be activated at the same time, even though only the first one\nis uncommented in the sample file because it is the most usual.\n\n\nThe last constructor argument is defined as follows:\n\n\n<!-- Defines how the user attributes are converted to authorities (roles) -->\n<constructor-arg ref=\"authoritiesPopulator\" />\n\n\n\n, which refers to the following definition:\n\n\n<osgi:reference id=\"authoritiesPopulator\" cardinality=\"1..1\"\n                interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\"\n                filter=\"(instanceId=theId)\"/>\n\n\n\nYou may edit \ntheId\n to any value, ideally one that is descriptive of the LDAP connection being configured. The same\nvalue used here must be set as the \norg.opencastproject.userdirectory.ldap.id\n in the LDAP configuration file described\nbelow.\n\n\n Step 3\n\n\nMake a copy of the file \n$OPENCAST_ETC/org.opencastproject.userdirectory.ldap.cfg.template\n in the same directory and\nrename it as:\n\n\norg.opencastproject.userdirectory.ldap-<ID>.cfg\n\n\n\n, where \n<ID>\n is a unique identifier for each LDAP connection. This identifier is only use to distinguish between the\nfiles and is not used internally. It might have any value, but for the sake of clarity, it is recommended to use the\nsame value as in the \norg.opencastproject.userdirectory.ldap.id\n parameter in the file.\n\n\nStep 4\n\n\nEdit the parameters in the file with your particular configuration. Unfortunately, some of those are duplicated in the\n\nsecurity.xml\n file, but this situation cannot currently be avoided.\n\n\nThe parameters that are exclusive to this \n.cfg\n file control the user authorization, i.e. how the roles obtained from\nthe LDAP are handled and assigned to the users. Please refer to the documentation in the file itself to know the meaning\nof these parameters and how to use them.\n\n\nIMPORTANT\n: The \norg.opencastproject.userdirectory.ldap.id\n parameter in the file must be configured to the same\nvalue as the ID of the OSGI reference in the \nsecurity.xml\n file above (at the end of the step #2).\n\n\nCombination with Existing authorization Mechanisms\n\n\nIn the default configuration included in the \nsecurity_sample_ldap.xml-example\n file, the LDAP is tried after the\nnormal authorization mechanisms (i.e. the database). This means that if a user is present in both the database and the\nLDAP, the database will take precedence. The order is determined by the order in which the authentication providers\nappear on the security file. The relevant snippet is this:\n\n\n<sec:authentication-manager alias=\"authenticationManager\">\n  <sec:authentication-provider user-service-ref=\"userDetailsService\">  # \\\n    <sec:password-encoder hash=\"md5\">                                  # |\n      <sec:salt-source user-property=\"username\" />                     # -> These lines must be moved as a block\n    </sec:password-encoder>                                            # |\n  </sec:authentication-provider>                                       # /\n  <sec:authentication-provider ref=\"ldapAuthProvider\" />               # The LDAP provider appears in the second position, therefore it is the second provider to consider\n</sec:authentication-manager>\n\n\n\nBy switching the position of the authentication providers, you will give them more or less priority.\n\n\nAdding more LDAP servers\n\n\nMore LDAP servers can be added to the configuration by including the LDAP-related sections as many times as necessary\nwith their corresponding configurations. The new authentication providers must also be added to the providers list\nat the bottom of the file. Please see the example below:\n\n\n<bean id=\"contextSource\"\n  class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\">\n  <!-- URL of the LDAP server -->\n  <constructor-arg value=\"ldap://myldapserver:myport\" />\n  <!-- \"Distinguished name\" for the unprivileged user -->\n  <!-- This user is merely to perform searches in the LDAP to find the users to login -->\n  <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" />\n  <!-- Password of the user above -->\n  <property name=\"password\" value=\"mypassword\" />\n</bean>\n\n<bean id=\"ldapAuthProvider\"\n  class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\">\n  <constructor-arg>\n    <bean\n      class=\"org.springframework.security.ldap.authentication.BindAuthenticator\">\n      <constructor-arg ref=\"contextSource\" />\n      <property name=\"userDnPatterns\">\n        <list>\n          <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed -->\n          <value>uid={0},ou=Group,dc=my-institution,dc=country</value>\n        </list>\n     </property>\n     <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them -->\n     <!-- This property can be used together with the \"userDnPatterns\" above -->\n     <!--\n     <property name=\"userSearch\">\n       <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\">\n         < ! - - Base Dn from where the users will be searched for - - >\n         <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" />\n         < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - >\n         <constructor-arg index=\"1\" value=\"(uid={0})\" />\n         <constructor-arg ref=\"contextSource\" />\n       </bean>\n      </property>\n     -->\n    </bean>\n  </constructor-arg>\n  <!-- Defines how the user attributes are converted to authorities (roles) -->\n  <constructor-arg ref=\"authoritiesPopulator\" />\n</bean>\n\n<!-- PLEASE NOTE: The ID below must be changed for each context source instance -->\n<bean id=\"contextSource2\"\n  class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\">\n  <constructor-arg value=\"ldap://myldapserver:myport\" />\n  <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" />\n  <property name=\"password\" value=\"mypassword\" />\n</bean>\n\n<!-- PLEASE NOTE: The ID below must be changed for each LDAP authentication provider instance -->\n<bean id=\"ldapAuthProvider2\"\n  class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\">\n  <constructor-arg>\n    <bean\n      class=\"org.springframework.security.ldap.authentication.BindAuthenticator\">\n      <!-- PLEASE NOTE: the ref below must match the corresponding context source ID -->\n      <constructor-arg ref=\"contextSource2\" />\n       <property name=\"userDnPatterns\">\n        <list>\n          <value>uid={0},ou=OtherGroup,dc=my-other-institution,dc=other-country</value>\n        </list>\n       </property>\n    <property name=\"userSearch\">\n      <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\">\n        <constructor-arg index=\"0\" value=\"ou=OtherGroup,dc=my-other-institution,dc=other-country\" />\n        <constructor-arg index=\"1\" value=\"(uid={0})\" />\n             <!-- PLEASE NOTE: the ref below must match the corresponding context source ID -->\n        <constructor-arg ref=\"contextSource2\" />\n         </bean>\n       </property>\n     </bean>\n  </constructor-arg>\n  <!-- Defines how the user attributes are converted to authorities (roles) -->\n  <!-- PLEASE NOTE: the ref below must match the corresponding authoritiesPopulator -->\n  <constructor-arg ref=\"authoritiesPopulator2\" />\n</bean>\n\n<!-- [ ... SKIPPED LINES ... ] -->\n\n<osgi:reference id=\"authoritiesPopulator\" cardinality=\"1..1\"\n                interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\"\n                filter=\"(instanceId=theId)\"/>\n<osgi:reference id=\"authoritiesPopulator2\" cardinality=\"1..1\"\n                interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\"\n                filter=\"(instanceId=theId2)\"/>\n\n<!-- [ ... SKIPPED LINES ... ] -->\n\n<sec:authentication-manager alias=\"authenticationManager\">\n  <sec:authentication-provider user-service-ref=\"userDetailsService\">\n    <sec:password-encoder hash=\"md5\">\n      <sec:salt-source user-property=\"username\" />\n    </sec:password-encoder>\n  </sec:authentication-provider>\n  <!-- PLEASE NOTE: In this example, the 2nd LDAP provider defined in the file has more priority that the first one -->\n  <sec:authentication-provider ref=\"ldapAuthProvider2\" />\n  <sec:authentication-provider ref=\"ldapAuthProvider\" />\n</sec:authentication-manager>\n\n\n\nThen, a separate \n.cfg\n must be generated for each of the configured providers, as explained \nhere\n. Please make\nsure to configure the \norg.opencastproject.userdirectory.ldap.id\n parameter correctly. In this case, the values should\nbe \ntheId\n and \ntheId2\n, respectively.",
            "title": "LDAP Authentication and Authorization (without CAS)"
        },
        {
            "location": "/configuration/security.ldap/#ldap-authentication-and-authorization-without-cas",
            "text": "This page describes how to use only an LDAP server to authenticate users in Opencast. If you just want to use LDAP  as an identity provider for another authentication mechanism, such as a CAS server, this guide does not apply to  you.  You may find the instructions to configure an LDAP-backed CAS server  here .     The variable  $OPENCAST_ETC  used below stands for the location of Opencast's configuration folder within your  system. Its location varies depending on whether Opencast was installed from source or a packaged version (e.g. RPM)  was used:   Source installation:  The  etc  folder within the directory containing the Opencast code.  Packaged installation:  A subdirectory of your system's usual configuration directory, most likely  /etc/opencast .*",
            "title": "LDAP Authentication and Authorization (without CAS)"
        },
        {
            "location": "/configuration/security.ldap/#set-up-an-ldap-provider",
            "text": "",
            "title": "Set up an LDAP provider"
        },
        {
            "location": "/configuration/security.ldap/#step-1",
            "text": "Opencast's  security.xml  files are located in the folder  $OPENCAST_ETC/security . In a single-tenant deployment, the\nfile is named  $OPENCAST_ETC/security/mh_default_org.xml  for the default organization. In a multi-tenant installation,\nor when a non-default organization is used, the file(s) are  $OPENCAST_ETC/security/<organization_id>.xml .  You should make a backup copy of the file and substitute it with the sample file named  security_sample_ldap.xml-example .\nIn other words:  $> cd $OPENCAST_ETC/security\n$> mv mh_default_org.xml mh_default_org.xml.old\n$> cp security_sample_ldap.xml-example mh_default_org.xml  The sample file should be exactly the same as the replaced security file, except for the parts only relevant to the\nLDAP which will be discussed below. If you have done custom modifications to your security file, please make sure to\nincorporate them to the new file, too.",
            "title": "Step 1"
        },
        {
            "location": "/configuration/security.ldap/#step-2",
            "text": "Add the necessary configuration values to the LDAP section of the new security file.  The first relevant section defines a context source. This contains the basic login information that enables Opencast to\nrequest information about users from the LDAP server in order to authenticate them.  <bean id=\"contextSource\"\n  class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\">\n  <!-- URL of the LDAP server -->\n  <constructor-arg value=\"ldap://myldapserver:myport\" />\n  <!-- \"Distinguished name\" for the unprivileged user -->\n  <!-- This user is merely to perform searches in the LDAP to find the users to login -->\n  <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" />\n  <!-- Password of the user above -->\n  <property name=\"password\" value=\"mypassword\" />\n</bean>  The next part tells the system how to search for users in the LDAP server:  <constructor-arg>\n  <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\">\n    <constructor-arg ref=\"contextSource\" />\n    <property name=\"userDnPatterns\">\n      <list>\n        <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed -->\n        <value>uid={0},ou=Group,dc=my-institution,dc=country</value>\n      </list>\n    </property>\n    <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them -->\n    <!-- This property can be used together with the \"userDnPatterns\" above -->\n    <!--\n    <property name=\"userSearch\">\n      <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\">\n        < ! - - Base Dn from where the users will be searched for - - >\n        <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" />\n        < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - >\n        <constructor-arg index=\"1\" value=\"(uid={0})\" />\n        <constructor-arg ref=\"contextSource\" />\n      </bean>\n    </property>\n    -->\n  </bean>\n</constructor-arg>  As the previous snippet shows, there are two alternative ways to find users in your LDAP:   Using the property userDnPatterns:  This property accepts a list of search patterns to match against the user's\nDN. The patterns will be tried in order until a match is found. The placeholder  {0}  can be used to represent the\nusername in such patterns.  Using a userSearch filter:  With the previous approach, it is not possible to find users whose login name is not\n    part of their DN. In such cases, you can use the userSearch property, that allows you to search the users based on a\n    filter. The filter requires three parameters:  The first parameter specifies the \"root node\" where the searches will start from.  The second one specifies the filter, where, again, the placeholder  {0}  will be substituted by the username\n  during the searches.  The third parameter should be the contextSource defined above.     Both methods are not mutually exclusive --i.e. both can be activated at the same time, even though only the first one\nis uncommented in the sample file because it is the most usual.  The last constructor argument is defined as follows:  <!-- Defines how the user attributes are converted to authorities (roles) -->\n<constructor-arg ref=\"authoritiesPopulator\" />  , which refers to the following definition:  <osgi:reference id=\"authoritiesPopulator\" cardinality=\"1..1\"\n                interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\"\n                filter=\"(instanceId=theId)\"/>  You may edit  theId  to any value, ideally one that is descriptive of the LDAP connection being configured. The same\nvalue used here must be set as the  org.opencastproject.userdirectory.ldap.id  in the LDAP configuration file described\nbelow.",
            "title": "Step 2"
        },
        {
            "location": "/configuration/security.ldap/#step-4",
            "text": "Edit the parameters in the file with your particular configuration. Unfortunately, some of those are duplicated in the security.xml  file, but this situation cannot currently be avoided.  The parameters that are exclusive to this  .cfg  file control the user authorization, i.e. how the roles obtained from\nthe LDAP are handled and assigned to the users. Please refer to the documentation in the file itself to know the meaning\nof these parameters and how to use them.  IMPORTANT : The  org.opencastproject.userdirectory.ldap.id  parameter in the file must be configured to the same\nvalue as the ID of the OSGI reference in the  security.xml  file above (at the end of the step #2).",
            "title": "Step 4"
        },
        {
            "location": "/configuration/security.ldap/#combination-with-existing-authorization-mechanisms",
            "text": "In the default configuration included in the  security_sample_ldap.xml-example  file, the LDAP is tried after the\nnormal authorization mechanisms (i.e. the database). This means that if a user is present in both the database and the\nLDAP, the database will take precedence. The order is determined by the order in which the authentication providers\nappear on the security file. The relevant snippet is this:  <sec:authentication-manager alias=\"authenticationManager\">\n  <sec:authentication-provider user-service-ref=\"userDetailsService\">  # \\\n    <sec:password-encoder hash=\"md5\">                                  # |\n      <sec:salt-source user-property=\"username\" />                     # -> These lines must be moved as a block\n    </sec:password-encoder>                                            # |\n  </sec:authentication-provider>                                       # /\n  <sec:authentication-provider ref=\"ldapAuthProvider\" />               # The LDAP provider appears in the second position, therefore it is the second provider to consider\n</sec:authentication-manager>  By switching the position of the authentication providers, you will give them more or less priority.",
            "title": "Combination with Existing authorization Mechanisms"
        },
        {
            "location": "/configuration/security.ldap/#adding-more-ldap-servers",
            "text": "More LDAP servers can be added to the configuration by including the LDAP-related sections as many times as necessary\nwith their corresponding configurations. The new authentication providers must also be added to the providers list\nat the bottom of the file. Please see the example below:  <bean id=\"contextSource\"\n  class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\">\n  <!-- URL of the LDAP server -->\n  <constructor-arg value=\"ldap://myldapserver:myport\" />\n  <!-- \"Distinguished name\" for the unprivileged user -->\n  <!-- This user is merely to perform searches in the LDAP to find the users to login -->\n  <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" />\n  <!-- Password of the user above -->\n  <property name=\"password\" value=\"mypassword\" />\n</bean>\n\n<bean id=\"ldapAuthProvider\"\n  class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\">\n  <constructor-arg>\n    <bean\n      class=\"org.springframework.security.ldap.authentication.BindAuthenticator\">\n      <constructor-arg ref=\"contextSource\" />\n      <property name=\"userDnPatterns\">\n        <list>\n          <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed -->\n          <value>uid={0},ou=Group,dc=my-institution,dc=country</value>\n        </list>\n     </property>\n     <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them -->\n     <!-- This property can be used together with the \"userDnPatterns\" above -->\n     <!--\n     <property name=\"userSearch\">\n       <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\">\n         < ! - - Base Dn from where the users will be searched for - - >\n         <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" />\n         < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - >\n         <constructor-arg index=\"1\" value=\"(uid={0})\" />\n         <constructor-arg ref=\"contextSource\" />\n       </bean>\n      </property>\n     -->\n    </bean>\n  </constructor-arg>\n  <!-- Defines how the user attributes are converted to authorities (roles) -->\n  <constructor-arg ref=\"authoritiesPopulator\" />\n</bean>\n\n<!-- PLEASE NOTE: The ID below must be changed for each context source instance -->\n<bean id=\"contextSource2\"\n  class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\">\n  <constructor-arg value=\"ldap://myldapserver:myport\" />\n  <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" />\n  <property name=\"password\" value=\"mypassword\" />\n</bean>\n\n<!-- PLEASE NOTE: The ID below must be changed for each LDAP authentication provider instance -->\n<bean id=\"ldapAuthProvider2\"\n  class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\">\n  <constructor-arg>\n    <bean\n      class=\"org.springframework.security.ldap.authentication.BindAuthenticator\">\n      <!-- PLEASE NOTE: the ref below must match the corresponding context source ID -->\n      <constructor-arg ref=\"contextSource2\" />\n       <property name=\"userDnPatterns\">\n        <list>\n          <value>uid={0},ou=OtherGroup,dc=my-other-institution,dc=other-country</value>\n        </list>\n       </property>\n    <property name=\"userSearch\">\n      <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\">\n        <constructor-arg index=\"0\" value=\"ou=OtherGroup,dc=my-other-institution,dc=other-country\" />\n        <constructor-arg index=\"1\" value=\"(uid={0})\" />\n             <!-- PLEASE NOTE: the ref below must match the corresponding context source ID -->\n        <constructor-arg ref=\"contextSource2\" />\n         </bean>\n       </property>\n     </bean>\n  </constructor-arg>\n  <!-- Defines how the user attributes are converted to authorities (roles) -->\n  <!-- PLEASE NOTE: the ref below must match the corresponding authoritiesPopulator -->\n  <constructor-arg ref=\"authoritiesPopulator2\" />\n</bean>\n\n<!-- [ ... SKIPPED LINES ... ] -->\n\n<osgi:reference id=\"authoritiesPopulator\" cardinality=\"1..1\"\n                interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\"\n                filter=\"(instanceId=theId)\"/>\n<osgi:reference id=\"authoritiesPopulator2\" cardinality=\"1..1\"\n                interface=\"org.springframework.security.ldap.userdetails.LdapAuthoritiesPopulator\"\n                filter=\"(instanceId=theId2)\"/>\n\n<!-- [ ... SKIPPED LINES ... ] -->\n\n<sec:authentication-manager alias=\"authenticationManager\">\n  <sec:authentication-provider user-service-ref=\"userDetailsService\">\n    <sec:password-encoder hash=\"md5\">\n      <sec:salt-source user-property=\"username\" />\n    </sec:password-encoder>\n  </sec:authentication-provider>\n  <!-- PLEASE NOTE: In this example, the 2nd LDAP provider defined in the file has more priority that the first one -->\n  <sec:authentication-provider ref=\"ldapAuthProvider2\" />\n  <sec:authentication-provider ref=\"ldapAuthProvider\" />\n</sec:authentication-manager>  Then, a separate  .cfg  must be generated for each of the configured providers, as explained  here . Please make\nsure to configure the  org.opencastproject.userdirectory.ldap.id  parameter correctly. In this case, the values should\nbe  theId  and  theId2 , respectively.",
            "title": "Adding more LDAP servers"
        },
        {
            "location": "/configuration/security.user.moodle/",
            "text": "What it does\n\n\nThe \nMoodle\n User Provider enriches Opencast users with a\nset of roles made up of the user's membership in Moodle courses, of the form\nCOURSEID_Role. For example, an Opencast user who is also a Moodle user and a\nmember of the Moodle course \nmyCourseID\n with the Moodle capability\n\ntool/opencast:learner\n will be granted the Opencast role \nmyCourseID_Learner\n.\nAnalogously, users with the capability \ntool/opencast:instructor\n will recieve\nthe Opencast role \nmyCourseID_Instructor\n. Note that by default, Moodle course\nIDs are opaque ID values such as \n10765\n. The \nROLE_GROUP_MOODLE\n Opencast group\nrole is granted to all users that also exist in Moodle.\n\n\nThe mapping of Moodle courses and capabilities to Opencast roles is consistent\nwith the course and role mapping used by the \nLTI\n\nendpoint. The Moodle User Provider can therefore be used with LTI or another\nmethod of authenticating users.\n\n\nThe Moodle Role Provider allows Moodle course and capability combinations to be\nused in Event and Series ACLs. For example, the role \nmyCourseID_Learner\n can be\nadded to a Series ACL to grant access to the Series to members of the\n\nmyCourseID\n course in Moodle.\n\n\nRequirements\n\n\nThe Moodle User Provider requires the\n\nmoodle-tool_opencast\n\nplug-in that extends Moodle with the necessary API functions and capabilities.\nAs this plug-in also provides base settings for additional Moodle plug-ins, the\nuser is asked to provide Opencast API login information during the installation.\nThe values can be arbitrary, if only the Moodle User Provider should be\nconfigured.\n\n\nAfter the installation, a new user with the capabilities\n\nwebservice/rest:use\n, \ntool/opencast:externalapi\n, \nmoodle/user:viewalldetails\n,\n\nmoodle/user:viewdetails\n and \nmoodle/site:accessallgroups\n has to be created.\nThen generate a new web service token and add that user to the \"Opencast web\nservice\" service.\n\n\nStep 1\n\n\nTo enable the Moodle User Provider, copy and rename the bundled configuration\ntemplate from\n\nOPENCAST/etc/org.opencastproject.userdirectory.moodle-default.cfg.template\n to\n\nOPENCAST/etc/org.opencastproject.userdirectory.moodle-default.cfg\n\n\nEdit the configuration file to set your Moodle URL and the web service token of\nthe Moodle user that should be used for API calls.\n\n\n# The URL and token for the Moodle REST webservice\norg.opencastproject.userdirectory.moodle.url=http://localhost/webservice/rest/server.php\norg.opencastproject.userdirectory.moodle.token=mytoken1234abcdef\n\n\n\n\nStep 2\n\n\nVerify that the Moodle User Provider starts up with the correct Moodle URL by looking\nfor a log entry like this:\n\n\n(MoodleUserProviderInstance:143) - Creating new MoodleUserProviderInstance(pid=org.opencastproject.userdirectory.moodle.378cdff4-825f-4b60-b1ed-33f75aa7f265, url=http://localhost/webservice/rest/server.php, cacheSize=1000, cacheExpiration=60)\n\n\n\n\nThen login to Opencast using a username which also exists in your Moodle system.\nVerify the roles granted to the user by opening the url\nOPENCAST-URL/info/me.json in a new browser tab, or navigate to the user details\nand open the tab \"Effective Roles\".\n\n\nIf necessary, you can increase the logging detail from the Moodle user provider\nby adding an entry to \nOPENCAST/etc/org.ops4j.pax.logging.cfg\n:\n\n\nlog4j.logger.org.opencastproject.userdirectory.moodle=DEBUG\n\n\n\n\nStep 3\n\n\nYou can grant additional roles to all Moodle users in Opencast by creating a\ngroup with the name 'Moodle'. You can then add additional roles to this group,\nwhich will be inherited by all Moodle users.\n\n\nYou can also use the group role name \nROLE_GROUP_MOODLE\n in Event or Series\nACLs.",
            "title": "Moodle User Provider"
        },
        {
            "location": "/configuration/security.user.moodle/#what-it-does",
            "text": "The  Moodle  User Provider enriches Opencast users with a\nset of roles made up of the user's membership in Moodle courses, of the form\nCOURSEID_Role. For example, an Opencast user who is also a Moodle user and a\nmember of the Moodle course  myCourseID  with the Moodle capability tool/opencast:learner  will be granted the Opencast role  myCourseID_Learner .\nAnalogously, users with the capability  tool/opencast:instructor  will recieve\nthe Opencast role  myCourseID_Instructor . Note that by default, Moodle course\nIDs are opaque ID values such as  10765 . The  ROLE_GROUP_MOODLE  Opencast group\nrole is granted to all users that also exist in Moodle.  The mapping of Moodle courses and capabilities to Opencast roles is consistent\nwith the course and role mapping used by the  LTI \nendpoint. The Moodle User Provider can therefore be used with LTI or another\nmethod of authenticating users.  The Moodle Role Provider allows Moodle course and capability combinations to be\nused in Event and Series ACLs. For example, the role  myCourseID_Learner  can be\nadded to a Series ACL to grant access to the Series to members of the myCourseID  course in Moodle.",
            "title": "What it does"
        },
        {
            "location": "/configuration/security.user.moodle/#requirements",
            "text": "The Moodle User Provider requires the moodle-tool_opencast \nplug-in that extends Moodle with the necessary API functions and capabilities.\nAs this plug-in also provides base settings for additional Moodle plug-ins, the\nuser is asked to provide Opencast API login information during the installation.\nThe values can be arbitrary, if only the Moodle User Provider should be\nconfigured.  After the installation, a new user with the capabilities webservice/rest:use ,  tool/opencast:externalapi ,  moodle/user:viewalldetails , moodle/user:viewdetails  and  moodle/site:accessallgroups  has to be created.\nThen generate a new web service token and add that user to the \"Opencast web\nservice\" service.",
            "title": "Requirements"
        },
        {
            "location": "/configuration/security.user.moodle/#step-1",
            "text": "To enable the Moodle User Provider, copy and rename the bundled configuration\ntemplate from OPENCAST/etc/org.opencastproject.userdirectory.moodle-default.cfg.template  to OPENCAST/etc/org.opencastproject.userdirectory.moodle-default.cfg  Edit the configuration file to set your Moodle URL and the web service token of\nthe Moodle user that should be used for API calls.  # The URL and token for the Moodle REST webservice\norg.opencastproject.userdirectory.moodle.url=http://localhost/webservice/rest/server.php\norg.opencastproject.userdirectory.moodle.token=mytoken1234abcdef",
            "title": "Step 1"
        },
        {
            "location": "/configuration/security.user.moodle/#step-2",
            "text": "Verify that the Moodle User Provider starts up with the correct Moodle URL by looking\nfor a log entry like this:  (MoodleUserProviderInstance:143) - Creating new MoodleUserProviderInstance(pid=org.opencastproject.userdirectory.moodle.378cdff4-825f-4b60-b1ed-33f75aa7f265, url=http://localhost/webservice/rest/server.php, cacheSize=1000, cacheExpiration=60)  Then login to Opencast using a username which also exists in your Moodle system.\nVerify the roles granted to the user by opening the url\nOPENCAST-URL/info/me.json in a new browser tab, or navigate to the user details\nand open the tab \"Effective Roles\".  If necessary, you can increase the logging detail from the Moodle user provider\nby adding an entry to  OPENCAST/etc/org.ops4j.pax.logging.cfg :  log4j.logger.org.opencastproject.userdirectory.moodle=DEBUG",
            "title": "Step 2"
        },
        {
            "location": "/configuration/security.user.moodle/#step-3",
            "text": "You can grant additional roles to all Moodle users in Opencast by creating a\ngroup with the name 'Moodle'. You can then add additional roles to this group,\nwhich will be inherited by all Moodle users.  You can also use the group role name  ROLE_GROUP_MOODLE  in Event or Series\nACLs.",
            "title": "Step 3"
        },
        {
            "location": "/configuration/security.user.sakai/",
            "text": "What it does\n\n\nThe \nSakai\n User Provider enriches Opencast users\nwith a set of roles made up of the user's membership in Sakai sites, of the form\nSITEID_Role. For example, an Opencast user who is also a Sakai user and a member\nof the Sakai site \nmysiteid\n with the Sakai role \nStudent\n will be granted the\nOpencast role \nmysiteid_Learner\n. Note that by default, Sakai site IDs are opaque\nGUID values such as \nd02f250e-be2d-4b72-009a-161d66ed6df9\n.\n\n\nThe mapping of Sakai sites and roles to Opencast roles is consistent with the site\nand role mapping used by the \nLTI\n endpoint. The Sakai\nUser Provider can therefore be used with LTI or another method of authenticating\nusers.\n\n\nThe Sakai Role Provider allows Sakai site and role combinations to be used in\nEvent and Series ACLs. For example, the role \nmysiteid_Learner\n can be added to a\nSeries ACL to grant access to the Series to members of the \nmysiteid\n site in Sakai.\n\n\nRequirements\n\n\nThe Sakai User Provider requires Sakai 11.0 or later, and an admin-equivalent\naccount on the Sakai instance.\n\n\nStep 1\n\n\nTo enable the Sakai User Provider, copy and rename the bundled configuration template from\n\nOPENCAST/etc/org.opencastproject.userdirectory.sakai-default.cfg.template\n to\n\nOPENCAST/etc/org.opencastproject.userdirectory.sakai-default.cfg\n\n\nEdit the configuration file to set your Sakai URL, and the username and password of\nthe admin user on the Sakai system:\n\n\nsakai.url=https://mysakai.my.domain\nsakai.user=opencast\nsakai.password=CHANGE_ME\n\n\n\n\nStep 2\n\n\nVerify that the Sakai User Provider starts up with the correct Sakai URL by looking\nfor a log entry like this:\n\n\n(SakaiUserProviderInstance:154) - Creating new SakaiUserProviderInstance(pid=org.opencastproject.userdirectory.sakai.f1fad141-8cc8-41ee-b514-8dad00984af6, url=https://mysakai.my.domain, cacheSize=1000, cacheExpiration=60)\n\n\n\n\nThen login to Opencast using a username which also exists in your Sakai system.\nVerify the roles granted to the user by opening the url OPENCAST-URL/info/me.json\nin a new browser tab.\n\n\nIf necessary, you can increase the logging detail from the Sakai user provider by\nadding an entry to \nOPENCAST/etc/org.ops4j.pax.logging.cfg\n:\n\n\nlog4j.logger.org.opencastproject.userdirectory.sakai=DEBUG\n\n\n\n\nStep 3\n\n\nYou can grant additional roles to all Sakai users in Opencast by creating a group\nwith the title 'Sakai'. You can then add additional roles to this group, which will\nbe inherited by all Sakai users.\n\n\nYou can also use the group role name ROLE_GROUP_SAKAI in Event or Series ACLs.",
            "title": "Sakai User Provider"
        },
        {
            "location": "/configuration/security.user.sakai/#what-it-does",
            "text": "The  Sakai  User Provider enriches Opencast users\nwith a set of roles made up of the user's membership in Sakai sites, of the form\nSITEID_Role. For example, an Opencast user who is also a Sakai user and a member\nof the Sakai site  mysiteid  with the Sakai role  Student  will be granted the\nOpencast role  mysiteid_Learner . Note that by default, Sakai site IDs are opaque\nGUID values such as  d02f250e-be2d-4b72-009a-161d66ed6df9 .  The mapping of Sakai sites and roles to Opencast roles is consistent with the site\nand role mapping used by the  LTI  endpoint. The Sakai\nUser Provider can therefore be used with LTI or another method of authenticating\nusers.  The Sakai Role Provider allows Sakai site and role combinations to be used in\nEvent and Series ACLs. For example, the role  mysiteid_Learner  can be added to a\nSeries ACL to grant access to the Series to members of the  mysiteid  site in Sakai.",
            "title": "What it does"
        },
        {
            "location": "/configuration/security.user.sakai/#requirements",
            "text": "The Sakai User Provider requires Sakai 11.0 or later, and an admin-equivalent\naccount on the Sakai instance.",
            "title": "Requirements"
        },
        {
            "location": "/configuration/security.user.sakai/#step-1",
            "text": "To enable the Sakai User Provider, copy and rename the bundled configuration template from OPENCAST/etc/org.opencastproject.userdirectory.sakai-default.cfg.template  to OPENCAST/etc/org.opencastproject.userdirectory.sakai-default.cfg  Edit the configuration file to set your Sakai URL, and the username and password of\nthe admin user on the Sakai system:  sakai.url=https://mysakai.my.domain\nsakai.user=opencast\nsakai.password=CHANGE_ME",
            "title": "Step 1"
        },
        {
            "location": "/configuration/security.user.sakai/#step-2",
            "text": "Verify that the Sakai User Provider starts up with the correct Sakai URL by looking\nfor a log entry like this:  (SakaiUserProviderInstance:154) - Creating new SakaiUserProviderInstance(pid=org.opencastproject.userdirectory.sakai.f1fad141-8cc8-41ee-b514-8dad00984af6, url=https://mysakai.my.domain, cacheSize=1000, cacheExpiration=60)  Then login to Opencast using a username which also exists in your Sakai system.\nVerify the roles granted to the user by opening the url OPENCAST-URL/info/me.json\nin a new browser tab.  If necessary, you can increase the logging detail from the Sakai user provider by\nadding an entry to  OPENCAST/etc/org.ops4j.pax.logging.cfg :  log4j.logger.org.opencastproject.userdirectory.sakai=DEBUG",
            "title": "Step 2"
        },
        {
            "location": "/configuration/security.user.sakai/#step-3",
            "text": "You can grant additional roles to all Sakai users in Opencast by creating a group\nwith the title 'Sakai'. You can then add additional roles to this group, which will\nbe inherited by all Sakai users.  You can also use the group role name ROLE_GROUP_SAKAI in Event or Series ACLs.",
            "title": "Step 3"
        },
        {
            "location": "/configuration/stream-security/",
            "text": "Configuration of Stream Security\n\n\nTo get an introduction to stream security before deploying, please read the overview at:\n\n\n\n\nStream Security Overview\n\n\n\n\nIt is important to note that if stream security is enabled, all resources will be signed and protected, even ones that\ndo not have any access restrictions defined in their access control lists. Accessing resources with unsigned URLs will\nnot be possible.\n\n\nOn a high level, to use Stream security, these steps are required:\n\n\n\n\nInstall and configure the URL signing service and signing providers\n\n\nConfigure Opencast services (and, optionally, 3rd party services) that use the signing infrastructure to sign requests\n\n\nInstall and configure verification components\n\n\n\n\nURL Signing Service Installation\n\n\nThere are three modules that are built by default and need to be present on each Opencast node in order to initiate URL\nsigning:\n\n\n\n\nurlsigning-common\n\n\nurlsigning-service-api\n\n\nurlsigning-service-impl\n\n\n\n\nIf these modules are present, the URL signing service will be available, to which the URL signing providers can then\nregister themselves.\n\n\nConfiguration of Signing Providers\n\n\nThe GenericUrlSigningProvider that comes with Opencast has its own configuration file:\n\n\netc/org.opencastproject.security.urlsigning.provider.impl.GenericUrlSigningProvider.cfg\n\n\n\nAll signing providers follow the same configuration structure and support multiple configuration blocks, providing the\nsettings for separate distributions (i.e. download or streaming servers, services or paths).\n\n\nEach configuration block consists of the following items:\n\n\n\n\nKey ID:\n Key identifier, e.g. \ndemoKeyOne\n\n\nKey secret:\n Key value, e.g. \n25DA2BA549CB62EF297977845259A\n. The key-length is not predefined, but a key length of\n  at least 128 bit is recommended. Any larger value will not increase security of the underlying algorithm.\n\n\nURL prefix:\n The URL signing provider will only sign URLs that start with this value. This allows to support\n  multiple distributions and different key pairs.\n\n\n\n\nA typical configuration looks like this:\n\n\nid.1=demoKeyOne\nkey.1=6EDB5EDDCF994B7432C371D7C274F\nurl.1=http://download.opencast.org/engage\n\nid.2=demoKeyTwo\nkey.2=6EDB5EDDCF994B7432C371D7C274F\nurl.2=http://download.opencast.org/custom\n\n\n\nThe properties defined in the configuration file take a numeric suffix that must start at \n1\n and increase in single\nincrements. In the example above these can be seen as: \n.1\n and \n.2\n. As soon as there is a missing number it will stop\nlooking for further entries.\n\n\nNote that id and key form a fixed pair, while the same key can be used in more than one configuration block.\n\n\nConfiguration of URL Signing Timeout Values\n\n\nOnce stream security is turned on by configuring the signing providers, multiple different services within Opencast will\nbe signing URLs, and while some services are signing on behalf of administrative users working in the Opencast\nadministrative user interface, others are signing URLs in order to grant access to learners playing back video content\ni.e. the functionality we have been talking about up to now.\n\n\nThis section explains how to best configure URLs to ensure that they expire at the right time. This might be required if\nthe default valid times do not seem secure enough or is more secure than needed.\n\n\nSigning for external access\n\n\nThe lifetime of the signed URLs can be configured by setting a custom value for the property\n\nurl.signing.expires.seconds\n that defines the validity in seconds. The default valid time is 7200 seconds (2 hours).\nThe signed URLs can also be configured to restrict access to the user\u2019s IP address by setting the property\n\nurl.signing.use.client.ip\n to true. By default this is disabled.\n\n\nOverview of configuration files for services that are able to automatically sign URLs on behalf of users:\n\n\n\n\n\n\n\n\nURLs That Are Signed\n\n\nConfiguration File Name\n\n\n\n\n\n\n\n\n\n\nVideo player content\n\n\norg.opencastproject.security.urlsigning.SigningMediaPackageSerializer.cfg\n\n\n\n\n\n\nAdmin UI links\n\n\norg.opencastproject.adminui.endpoint.OsgiEventEndpoint.cfg\n\n\n\n\n\n\nPreview and editor files\n\n\norg.opencastproject.adminui.endpoint.ToolsEndpoint.cfg\n\n\n\n\n\n\n\n\nThe URLs will be signed by the first signing provider that will accept the URL\u2019s path based upon the signing provider\u2019s\nconfiguration. This makes it flexible to support many different scenarios. For example, we could configure the signing\nprovider to have one key for any URL that begins with one scheme, such as http, which would cover all of the URLs to be\nsigned with a single key. Or it could be configured so that each different scheme and hostname pair would have a\ndifferent keys protecting each host\u2019s URLs separately etc. Having the timing configurations separate from the key\nconfiguration allows the different types of URLs to be signed differently depending on the needs of the users without\nneeding to configure this timing for all of the different keys.\n\n\nSigning for Opencast-internal access\n\n\nSigning of requests for internal use is performed by a core component called \nTrustedHttpClientImpl\n, which is used to\nestablish all internal HTTP connections. More specifically, the HTTP client needs access to internal storage areas such\nas the working file repository as well as to distributed artifacts on the downloads and streaming servers, all of which\nare protected by verification components.\n\n\nThe default expiration time for signed internal requests is 60 seconds. This can be changed by setting a value in\nseconds for the \norg.opencastproject.security.internal.url.signing.duration\n property in the \ncustom.properties\n\nconfiguration file. Since those URLs are signed right before the request is made, the valid time of 60 seconds should be\nsufficiently long.\n\n\nConfiguration of Verification Components\n\n\nThe verification components ensure that only valid and correctly signed URLs are accessible at any given time. URLs\nwhich are not properly signed or have expired will be rejected.\n\n\nOut of the box, Opencast provides an internal verification component:\n\n\n\n\nOpencast internal UrlSigningFilter\n\n\n\n\nThe following section is dedicated to the installation and configuration of the Opencast internal UrlSigningFilter. The\nstream security architecture allows the implementation for URL verification for third-party applications which are not\ncovered in this documentation.\n\n\nConfiguration of Opencast verification filter\n\n\nThe Servlet filter providing the verification of requests to Opencast internal resources is implemented in the bundles:\n\n\n\n\nurlsigning-verifier-service-api\n\n\nurlsigning-verifier-service-impl\n\n\n\n\nThe filter uses a set of regular expressions to determine which requests to an Opencast instance need to be verified.\n\n\nInstallation\n\n\nThe bundles are built by default and as soon as they are running in Opencast, the filter is active, and ready to be\nenabled.\n\n\nConfiguration\n\n\nTwo things need to be configured for the Opencast verification filter:\n\n\n\n\nkey pairs used to verify the signatures\n\n\npaths and endpoints that need to be protected\n\n\n\n\nThe configuration is located at:\n\n\netc/org.opencastproject.security.urlsigning.verifier.impl.UrlSigningVerifierImpl.cfg\n\n\n\nFirst of all, the key pairs used to sign must be configured in order to allow the filter to verify the signatures. More\nthan one key pair can be defined by increasing the counter (1, 2, 3, ...) in steps of 1. If you miss any numbers it will\nstop looking for further configurations.\n\n\nExample:\n\n\nid.1=demoKeyOne\nkey.1=6EDB5EDDCF994B7432C371D7C274F\n\nid.2=demoKeyTwo\nkey.2=C843C21ECF59F2B38872A1BCAA774\n\n\n\nThe entries in this file need to have the same values for the signing providers configuration.\n\n\nThe second step is to configure the filter defining the endpoints to be protected. The configuration file is located at:\n\n\netc/org.opencastproject.security.urlsigning.filter.UrlSigningFilter.cfg\n\n\n\nThe configuration defaults to a set of regular expressions which match all of the endpoints that serve files, and avoid\nprotecting endpoints that only serve data. Therefore, the remaining step is enabling the filter by setting the property\n\nenabled\n to \ntrue\n and determining whether strict or non-strict verification of the resource is required.\n\n\nNote that strict verification of resources means the entire URL will be considered when comparing the incoming request\nfor a resource against the policy, including the scheme (http, https, etc.), hostname and port. If turned off, only the\npath to the resource will be considered. So if the resource \nhttp://httpdserver:8080/the/full/path/video.mp4\n is\nrequested, only the \n/the/full/path/video.mp4\n part of the URL will be checked against the policy\u2019s path. As mentioned\nbefore, this is useful when using a load balancer so that the requested host name does not have to match the actual\nhostname or if a video player is rewriting requests, e.g. by inserting the port number.\n\n\nExample:\n\n\nenabled=true\n\nstrict=true\n\nurl.regex.1=.*files\\/collection\\/.*\nurl.regex.2=.*files\\/mediapackage\\/.*\nurl.regex.3=(?\\=(.*staticfiles.*))(?=^(?!.*staticfiles.*url|.*docs.*).*$)(.*)\nurl.regex.4=.*archive\\/archive\\/mediapackage\\/.*\\/.*\\/.*\nurl.regex.5=.*static.*\n\n\n\nTesting\n\n\nOnce all components of Stream Security are installed and properly configured, it is important to verify that the system\nis working as expected. It is especially important to try to access resources that should \nnot\n be accessible.\n\n\nThere are ways to test in a structured way which will be explained below.\n\n\nCreating Signed URLs with Signing Endpoint\n\n\nThe signing service provides a REST endpoint, which allows for the signing of arbitrary URLs. For manual use it is\nrecommended to visit the endpoint\u2019s documentation page at \nhttp://localhost:8080/signing/docs\n.\n\n\nIs the URL accepted?\n\n\nCheck if the URL to be signed is accepted by the signing service (or by one of its signing providers respectively) by\nusing the \n/signing/accepts\n endpoint. If that is not the case, the configuration of the signing providers should be\nchecked again to ensure that at least one signing provider is responsible for the URL in question.\n\n\nIf the service is fully operational, the response code will be \n200 OK\n and the response body either \ntrue\n (accepted)\nor \nfalse\n (refused).\n\n\nSigning the URL\n\n\nOn the same documentation page URLs can be signed using the \n/signing/sign\n endpoint, and the access policy may be\nspecified in that form as well. With this, several scenarios can be tested. Examples are:\n\n\n\n\nURLs that have already expired or will expire at a known date\n\n\nURLs that are not yet valid (if you provided a validFrom data in the access policy)\n\n\nURLs that are missing some or all of the signing parameters (policy, keyId or signature)\n\n\nURLs that are attempting to use signing parameters (policy and signature) from a different signed URL\n\n\n\n\nVerifying the URL\n\n\nThe signed URLs can then be passed to the appropriate testing tool (web browser, cURL, player, \u2026) to test the\nfunctionality of the verification component(s). The following table is the return codes associated with different\nrejection conditions:\n\n\n\n\n\n\n\n\nCase\n\n\nReturn Code\n\n\n\n\n\n\n\n\n\n\nIf any of the query string parameters are missing or are the wrong case / spelt incorrectly\n\n\nBad Request (400)\n\n\n\n\n\n\nIf any of the required policy variables are missing\n\n\nBad Request (400)\n\n\n\n\n\n\nNo encryption key that matches the KeyID known by the plugin\n\n\nBad Request (400)\n\n\n\n\n\n\nThe Policy and Signature don\u2019t match in any way\n\n\nForbidden (403)\n\n\n\n\n\n\nIf client IP is specified and doesn\u2019t match\n\n\nForbidden (403)\n\n\n\n\n\n\nThe current time has passed the DateGreaterThan, the time the URL expires\n\n\nGone (410)\n\n\n\n\n\n\nThe current time is before the DateLessThan, the time the URL becomes available\n\n\nGone (410)\n\n\n\n\n\n\n\n\nThe components that verify a URL is signed will run before a request is checked to be valid, so if a non-existent URL is\nsigned for example, the above conditions will need to be fixed before a missing (404) response code will be returned.\n\n\nInspect policy\n\n\nThe generated policy which is added to the signed URLs can be inspected. It needs to be decoded from Base64 and the\nresult must be a JSON document that contains exactly the values which have been passed during signing.\n\n\nDecoding this Base64 encoded policy\n\n\neyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRh\ndGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0\n\n\n\n\u2026would result in this JSON document (policy):\n\n\n{\n  \"Statement\":{\n    \"Resource\":\"http:\\/\\/opencast.org\\/engage\\/resource.mp4\",\n    \"Condition\":{\n      \"DateLessThan\":1425170777000,\n      \"DateGreaterThan\":1425084379000,\n      \"IpAddress\":\"10.0.0.1\"\n    }\n  }\n}\n\n\n\n\nInspecting and modifying the policy is useful for advanced testing, such as:\n\n\n\n\nURLs where the policy was modified after signing\n\n\nURLs where the policy was modified and resigned with a different key\n\n\n\n\nFurther information\n\n\nFor an overview of Stream Security:\n\n\n\n\nStream Security Overview\n\n\n\n\nFor further developer information, please have a look at the stream security section in the developer guide.",
            "title": "Stream Security"
        },
        {
            "location": "/configuration/stream-security/#configuration-of-stream-security",
            "text": "To get an introduction to stream security before deploying, please read the overview at:   Stream Security Overview   It is important to note that if stream security is enabled, all resources will be signed and protected, even ones that\ndo not have any access restrictions defined in their access control lists. Accessing resources with unsigned URLs will\nnot be possible.  On a high level, to use Stream security, these steps are required:   Install and configure the URL signing service and signing providers  Configure Opencast services (and, optionally, 3rd party services) that use the signing infrastructure to sign requests  Install and configure verification components",
            "title": "Configuration of Stream Security"
        },
        {
            "location": "/configuration/stream-security/#url-signing-service-installation",
            "text": "There are three modules that are built by default and need to be present on each Opencast node in order to initiate URL\nsigning:   urlsigning-common  urlsigning-service-api  urlsigning-service-impl   If these modules are present, the URL signing service will be available, to which the URL signing providers can then\nregister themselves.",
            "title": "URL Signing Service Installation"
        },
        {
            "location": "/configuration/stream-security/#configuration-of-signing-providers",
            "text": "The GenericUrlSigningProvider that comes with Opencast has its own configuration file:  etc/org.opencastproject.security.urlsigning.provider.impl.GenericUrlSigningProvider.cfg  All signing providers follow the same configuration structure and support multiple configuration blocks, providing the\nsettings for separate distributions (i.e. download or streaming servers, services or paths).  Each configuration block consists of the following items:   Key ID:  Key identifier, e.g.  demoKeyOne  Key secret:  Key value, e.g.  25DA2BA549CB62EF297977845259A . The key-length is not predefined, but a key length of\n  at least 128 bit is recommended. Any larger value will not increase security of the underlying algorithm.  URL prefix:  The URL signing provider will only sign URLs that start with this value. This allows to support\n  multiple distributions and different key pairs.   A typical configuration looks like this:  id.1=demoKeyOne\nkey.1=6EDB5EDDCF994B7432C371D7C274F\nurl.1=http://download.opencast.org/engage\n\nid.2=demoKeyTwo\nkey.2=6EDB5EDDCF994B7432C371D7C274F\nurl.2=http://download.opencast.org/custom  The properties defined in the configuration file take a numeric suffix that must start at  1  and increase in single\nincrements. In the example above these can be seen as:  .1  and  .2 . As soon as there is a missing number it will stop\nlooking for further entries.  Note that id and key form a fixed pair, while the same key can be used in more than one configuration block.",
            "title": "Configuration of Signing Providers"
        },
        {
            "location": "/configuration/stream-security/#configuration-of-url-signing-timeout-values",
            "text": "Once stream security is turned on by configuring the signing providers, multiple different services within Opencast will\nbe signing URLs, and while some services are signing on behalf of administrative users working in the Opencast\nadministrative user interface, others are signing URLs in order to grant access to learners playing back video content\ni.e. the functionality we have been talking about up to now.  This section explains how to best configure URLs to ensure that they expire at the right time. This might be required if\nthe default valid times do not seem secure enough or is more secure than needed.",
            "title": "Configuration of URL Signing Timeout Values"
        },
        {
            "location": "/configuration/stream-security/#signing-for-external-access",
            "text": "The lifetime of the signed URLs can be configured by setting a custom value for the property url.signing.expires.seconds  that defines the validity in seconds. The default valid time is 7200 seconds (2 hours).\nThe signed URLs can also be configured to restrict access to the user\u2019s IP address by setting the property url.signing.use.client.ip  to true. By default this is disabled.  Overview of configuration files for services that are able to automatically sign URLs on behalf of users:     URLs That Are Signed  Configuration File Name      Video player content  org.opencastproject.security.urlsigning.SigningMediaPackageSerializer.cfg    Admin UI links  org.opencastproject.adminui.endpoint.OsgiEventEndpoint.cfg    Preview and editor files  org.opencastproject.adminui.endpoint.ToolsEndpoint.cfg     The URLs will be signed by the first signing provider that will accept the URL\u2019s path based upon the signing provider\u2019s\nconfiguration. This makes it flexible to support many different scenarios. For example, we could configure the signing\nprovider to have one key for any URL that begins with one scheme, such as http, which would cover all of the URLs to be\nsigned with a single key. Or it could be configured so that each different scheme and hostname pair would have a\ndifferent keys protecting each host\u2019s URLs separately etc. Having the timing configurations separate from the key\nconfiguration allows the different types of URLs to be signed differently depending on the needs of the users without\nneeding to configure this timing for all of the different keys.",
            "title": "Signing for external access"
        },
        {
            "location": "/configuration/stream-security/#signing-for-opencast-internal-access",
            "text": "Signing of requests for internal use is performed by a core component called  TrustedHttpClientImpl , which is used to\nestablish all internal HTTP connections. More specifically, the HTTP client needs access to internal storage areas such\nas the working file repository as well as to distributed artifacts on the downloads and streaming servers, all of which\nare protected by verification components.  The default expiration time for signed internal requests is 60 seconds. This can be changed by setting a value in\nseconds for the  org.opencastproject.security.internal.url.signing.duration  property in the  custom.properties \nconfiguration file. Since those URLs are signed right before the request is made, the valid time of 60 seconds should be\nsufficiently long.",
            "title": "Signing for Opencast-internal access"
        },
        {
            "location": "/configuration/stream-security/#configuration-of-verification-components",
            "text": "The verification components ensure that only valid and correctly signed URLs are accessible at any given time. URLs\nwhich are not properly signed or have expired will be rejected.  Out of the box, Opencast provides an internal verification component:   Opencast internal UrlSigningFilter   The following section is dedicated to the installation and configuration of the Opencast internal UrlSigningFilter. The\nstream security architecture allows the implementation for URL verification for third-party applications which are not\ncovered in this documentation.",
            "title": "Configuration of Verification Components"
        },
        {
            "location": "/configuration/stream-security/#configuration-of-opencast-verification-filter",
            "text": "The Servlet filter providing the verification of requests to Opencast internal resources is implemented in the bundles:   urlsigning-verifier-service-api  urlsigning-verifier-service-impl   The filter uses a set of regular expressions to determine which requests to an Opencast instance need to be verified.",
            "title": "Configuration of Opencast verification filter"
        },
        {
            "location": "/configuration/stream-security/#installation",
            "text": "The bundles are built by default and as soon as they are running in Opencast, the filter is active, and ready to be\nenabled.",
            "title": "Installation"
        },
        {
            "location": "/configuration/stream-security/#configuration",
            "text": "Two things need to be configured for the Opencast verification filter:   key pairs used to verify the signatures  paths and endpoints that need to be protected   The configuration is located at:  etc/org.opencastproject.security.urlsigning.verifier.impl.UrlSigningVerifierImpl.cfg  First of all, the key pairs used to sign must be configured in order to allow the filter to verify the signatures. More\nthan one key pair can be defined by increasing the counter (1, 2, 3, ...) in steps of 1. If you miss any numbers it will\nstop looking for further configurations.  Example:  id.1=demoKeyOne\nkey.1=6EDB5EDDCF994B7432C371D7C274F\n\nid.2=demoKeyTwo\nkey.2=C843C21ECF59F2B38872A1BCAA774  The entries in this file need to have the same values for the signing providers configuration.  The second step is to configure the filter defining the endpoints to be protected. The configuration file is located at:  etc/org.opencastproject.security.urlsigning.filter.UrlSigningFilter.cfg  The configuration defaults to a set of regular expressions which match all of the endpoints that serve files, and avoid\nprotecting endpoints that only serve data. Therefore, the remaining step is enabling the filter by setting the property enabled  to  true  and determining whether strict or non-strict verification of the resource is required.  Note that strict verification of resources means the entire URL will be considered when comparing the incoming request\nfor a resource against the policy, including the scheme (http, https, etc.), hostname and port. If turned off, only the\npath to the resource will be considered. So if the resource  http://httpdserver:8080/the/full/path/video.mp4  is\nrequested, only the  /the/full/path/video.mp4  part of the URL will be checked against the policy\u2019s path. As mentioned\nbefore, this is useful when using a load balancer so that the requested host name does not have to match the actual\nhostname or if a video player is rewriting requests, e.g. by inserting the port number.  Example:  enabled=true\n\nstrict=true\n\nurl.regex.1=.*files\\/collection\\/.*\nurl.regex.2=.*files\\/mediapackage\\/.*\nurl.regex.3=(?\\=(.*staticfiles.*))(?=^(?!.*staticfiles.*url|.*docs.*).*$)(.*)\nurl.regex.4=.*archive\\/archive\\/mediapackage\\/.*\\/.*\\/.*\nurl.regex.5=.*static.*",
            "title": "Configuration"
        },
        {
            "location": "/configuration/stream-security/#testing",
            "text": "Once all components of Stream Security are installed and properly configured, it is important to verify that the system\nis working as expected. It is especially important to try to access resources that should  not  be accessible.  There are ways to test in a structured way which will be explained below.",
            "title": "Testing"
        },
        {
            "location": "/configuration/stream-security/#creating-signed-urls-with-signing-endpoint",
            "text": "The signing service provides a REST endpoint, which allows for the signing of arbitrary URLs. For manual use it is\nrecommended to visit the endpoint\u2019s documentation page at  http://localhost:8080/signing/docs .",
            "title": "Creating Signed URLs with Signing Endpoint"
        },
        {
            "location": "/configuration/stream-security/#is-the-url-accepted",
            "text": "Check if the URL to be signed is accepted by the signing service (or by one of its signing providers respectively) by\nusing the  /signing/accepts  endpoint. If that is not the case, the configuration of the signing providers should be\nchecked again to ensure that at least one signing provider is responsible for the URL in question.  If the service is fully operational, the response code will be  200 OK  and the response body either  true  (accepted)\nor  false  (refused).",
            "title": "Is the URL accepted?"
        },
        {
            "location": "/configuration/stream-security/#signing-the-url",
            "text": "On the same documentation page URLs can be signed using the  /signing/sign  endpoint, and the access policy may be\nspecified in that form as well. With this, several scenarios can be tested. Examples are:   URLs that have already expired or will expire at a known date  URLs that are not yet valid (if you provided a validFrom data in the access policy)  URLs that are missing some or all of the signing parameters (policy, keyId or signature)  URLs that are attempting to use signing parameters (policy and signature) from a different signed URL",
            "title": "Signing the URL"
        },
        {
            "location": "/configuration/stream-security/#verifying-the-url",
            "text": "The signed URLs can then be passed to the appropriate testing tool (web browser, cURL, player, \u2026) to test the\nfunctionality of the verification component(s). The following table is the return codes associated with different\nrejection conditions:     Case  Return Code      If any of the query string parameters are missing or are the wrong case / spelt incorrectly  Bad Request (400)    If any of the required policy variables are missing  Bad Request (400)    No encryption key that matches the KeyID known by the plugin  Bad Request (400)    The Policy and Signature don\u2019t match in any way  Forbidden (403)    If client IP is specified and doesn\u2019t match  Forbidden (403)    The current time has passed the DateGreaterThan, the time the URL expires  Gone (410)    The current time is before the DateLessThan, the time the URL becomes available  Gone (410)     The components that verify a URL is signed will run before a request is checked to be valid, so if a non-existent URL is\nsigned for example, the above conditions will need to be fixed before a missing (404) response code will be returned.",
            "title": "Verifying the URL"
        },
        {
            "location": "/configuration/stream-security/#inspect-policy",
            "text": "The generated policy which is added to the signed URLs can be inspected. It needs to be decoded from Base64 and the\nresult must be a JSON document that contains exactly the values which have been passed during signing.  Decoding this Base64 encoded policy  eyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRh\ndGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0  \u2026would result in this JSON document (policy):  {\n  \"Statement\":{\n    \"Resource\":\"http:\\/\\/opencast.org\\/engage\\/resource.mp4\",\n    \"Condition\":{\n      \"DateLessThan\":1425170777000,\n      \"DateGreaterThan\":1425084379000,\n      \"IpAddress\":\"10.0.0.1\"\n    }\n  }\n}  Inspecting and modifying the policy is useful for advanced testing, such as:   URLs where the policy was modified after signing  URLs where the policy was modified and resigned with a different key",
            "title": "Inspect policy"
        },
        {
            "location": "/configuration/stream-security/#further-information",
            "text": "For an overview of Stream Security:   Stream Security Overview   For further developer information, please have a look at the stream security section in the developer guide.",
            "title": "Further information"
        },
        {
            "location": "/configuration/workflow/",
            "text": "Create a Custom Workflow\n\n\nThis document will help you get started with creating your own Opencast workflows. For a list of available workflow\noperations, see:\n\n\n\n\nList of Workflow Operation Handler\n\n\n\n\nOverview\n\n\nA Opencast workflow is an ordered list of operations. There is no limit to the number of operations or their\nrepetition in a given workflow.\n\n\nWorkflow operations can be configured using configuration elements. The use of string replacement in configuration\nvalues allows workflows to dynamically adapt to a given input or user decision.\n\n\nDocument\n\n\nOpencast workflows are defined in XML.  The structure of a Opencast workflow looks like this:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  <id></id>\n  <title></title>\n  <tags></tags>\n  <description></description>\n  <displayOrder></displayOrder>\n\n  <!-- Operations -->\n  <operations>\n    <operation></operation>\n    ...\n  </operations>\n\n</definition>\n\n\n\nCreate a Workflow\n\n\nThis sections will walk you through creating a custom workflow, which will encode ingested tracks to defined output\nformat.\n\n\nEncoding Profiles\n\n\nFirst create or select the encoding profiles you want to use. For more details on this, have a look at the \nEncoding\nProfile Configuration Guide\n. For this guide we assume that we have an encoding profile \nmov-low.http\n\nwhich creates a distribution format definition for mp4 video and a \nfeed-cover.http\n encoding profile to create\nthumbnail images for the videos.\n\n\nDescribe the Workflow\n\n\nStart by naming the workflow and giving it a meaningful description:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  <id>example</id>\n  <title>Encode Mp4, Distribute and Publish</title>\n  <tags>\n    <!-- Tell the UI where to show this workflow -->\n    <tag>upload</tag>\n    <tag>schedule</tag>\n    <tag>archive</tag>\n  </tags>\n  <description>\n    Encode to Mp4 and thumbnail.\n    Distribute to local repository.\n    Publish to search index.\n  </description>\n  <displayOrder>10</displayOrder>\n\n  <!-- Operations -->\n  <operations></operations>\n\n</definition>\n\n\n\n\n\nThe \nid\n is used in several Opencast endpoints to identify and select this workflow. Make sure that this identifier\n  is unique among all endpoints in the system.\n\n\nThe \ntags\n define where the user interfaces may use these workflows. Useful tags are:\n\n\nupload\n: Usable for uploaded media\n\n\nschedule\n: Usable for scheduled events\n\n\narchive\n: Usable for archived media\n\n\ndelete\n: Usable for deletion of events with publications\n\n\neditor\n: Usable from the video editor\n\n\n\n\n\n\nThe \ndisplayOrder\n is an integer that indicates in what order workflow definitions shall be displayed by clients.\n  If ommitted, the \ndisplayOrder\n defaults to \n0\n. Clients are expected to list workflow definitions in descending order.\n\n\n\n\nInspect the Media\n\n\nThe first operation will be to inspect the media for technical metadata, such as format and length:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    <operation\n      id=\"inspect\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Inspect media package\">\n    </operation>\n\n  </operations>\n\n</definition>\n\n\n\nThe \nfail-on-error\n attribute is a boolean determining whether the workflow will throw an error to the\nexception-handler-workflow or simply proceed with the remaining operations.\n\n\nEncoding\n\n\nThe next operations will encode the media to the Mp4 format:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    ...\n\n    <!-- encode: mp4 -->\n    <operation\n      id=\"compose\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode camera to mp4\">\n      <configurations>\n        <configuration key=\"source-flavor\">presenter/source</configuration>\n        <configuration key=\"target-flavor\">presenter/delivery</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">mov-low.http</configuration>\n      </configurations>\n    </operation>\n\n    <operation\n      id=\"compose\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode screen to mp4\">\n      <configurations>\n        <configuration key=\"source-flavor\">presentation/source</configuration>\n        <configuration key=\"target-flavor\">presentation/delivery</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">mov-low.http</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>\n\n\n\n\n\nThe \ntarget-tags\n attribute causes the resulting media to be tagged. For example, this could be used to define these\n  media as input for other operations, using their \nsource-tags\n attribute.\n\n\nThe \nencoding-profile\n attribute refers to an encoding profile defined in \netc/encoding\n.\n\n\n\n\nEncode to Thumbnail\n\n\nThe next operations will create thumbnails from the media:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n  ...\n  <operations>\n    ...\n    <!-- encode: images -->\n    <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode camera to thumbnail\">\n      <configurations>\n        <configuration key=\"source-flavor\">presenter/source</configuration>\n        <configuration key=\"source-tags\"></configuration>\n        <configuration key=\"target-flavor\">cover/source</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">feed-cover.http</configuration>\n        <configuration key=\"time\">1</configuration>\n      </configurations>\n    </operation>\n\n    <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode screen to thumbnail\">\n      <configurations>\n        <configuration key=\"source-flavor\">presentation/source</configuration>\n        <configuration key=\"source-tags\"></configuration>\n        <configuration key=\"target-flavor\">cover/source</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">feed-cover.http</configuration>\n        <configuration key=\"time\">1</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>\n\n\n\n\n\nThe time attribute determines the approximate frame of the source media is used. The time unit is in seconds.\n\n\n\n\nDistribute the Media\n\n\nThe next operation copies the encoded media to the Opencast distribution channel:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n  ...\n  <operations>\n\n    <!-- distribute: local -->\n    <operation\n      id=\"publish-engage\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Distribute media to the local distribution channel\">\n      <configurations>\n        <configuration key=\"download-source-tags\">publish,rss,atom</configuration>\n        <configuration key=\"streaming-source-tags\"></configuration>\n        <configuration key=\"check-availability\">true</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>\n\n\n\n\n\nThe publish-engage operation uses all media tagged as \nrss\n or \natom\n as input.\n\n\n\n\nAccept User Input\n\n\nWorkflow definitions may optionally include variables to be replaced by user input. For instance, this may be used to\nselect optional parts of a workflow. To enable user control of individual workflow instances, the workflow definition\nmust:\n\n\n\n\nuse the \n${variable}\n notation in the workflow definition\n\n\ncontain a custom configuration panel.\n\n\n\n\nHere is an example of a configurable operation:\n\n\n<operation id=\"...\" if=\"${somevar}\">\n  ...\n</operation>\n\n\n\nThe attribute \nif\n specifies the execution condition in means of the operation only being executed if that condition\nevaluates to true. You can find more details on conditional execution in the next section.\n\n\nOnce the operation is configured to accept a variable, we need to describe how to gather the value from the\nadministrative user. The \n<configuration_panel>\n element of a workflow definitions describes this user interface\nsnippet.  A simple configuration panel could look like this:\n\n\n<configuration_panel>\n  <![CDATA[\n    <input id=\"someaction\" name=\"someaction\" type=\"checkbox\" value=\"true\" />\n    <label for=\"someaction\">Execute some operation?</label>\n  ]]>\n</configuration_panel>\n\n\n\nThe checkbox in this \n<configuration_panel>\n will now be displayed in the administrative tools, and the user's\nselection will be used to replace the \n${someaction}\n variable in the workflow.\n\n\nThis input can also be sent by capture agents, using the ingest endpoints. Please note that capture agents usually do\nnot load the configuration panel. Hence defaults set in the user interface will not apply to ingests. To circumvent\nthis, the \ndefaults operation\n can be used.\n\n\nConditional Execution\n\n\nThe attribute \nif\n of the \noperation\n element can be used to specify a condition to control whether the workflow\noperation should be executed. This so-called execution condition is a boolean expression of the following form:\n\n\n<expression> ::= <term> [\"OR\" <expression>]\n<term> ::= <value> [\"AND\" <term>]\n<value> ::= [\"NOT\"]* ( \"(\" <expression> \")\" | <relation> | <bool-literal> )\n<relation> ::= <relation-factor> <rel-literal> <relation-factor>\n<relation-factor> ::= <operation> | <number>\n<operation> ::= <number> <op-literal> <number>\n<rel-literal> ::= \">=\" | \">\" | \"<=\" | \"<\" | \"==\" | \"!=\"\n<op-literal> ::= \"+\" | \"-\" | \"*\" | \"/\"\n<bool-literal> ::= \"true\" | \"false\"\n\n\n\nAs the formal description above explains, such boolean expressions may contain the booelan constants (\ntrue\n and\n\nfalse\n) and numbers, as well as references to the variables of the workflow instance that contain these data types.\nWorkflow instance variables can be accessed by using \n${variableName}\n.\n\n\nExample:\n\n\n<operation id=\"...\" if=\"${variableName1} AND NOT (${variableName2} OR ${variableName3})\">\n  \u2026\n</operation>\n\n\n\nNote that XML requires certain characters like the \n<\n and \n>\n operators to be written as XML entities. Even if they are\nused quoted in attributes. The following table shows all those characters:\n\n\n\"  \u2192  &quot;\n'  \u2192  &apos;\n<  \u2192  &lt;\n>  \u2192  &gt;\n&  \u2192  &amp;\n\n\n\n\nExample:\n\n\n<operation id=\"...\" if=\"${yresolution} &gt; 720\">\n  \u2026\n</operation>\n\n\n\nThumbnail Support\n\n\nThe Admin UI comes with explicit support for thumbnails that are supposed to represent events visually, e.g. in lists\nof events as commonly used in video portals and other similar systems.\nTo make it possible to implement the required processing and retain flexibility, the Admin UI will store the following\ninformation in variables of workflow instances:\n\n\n\n\n\n\n\n\nVariable\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nthumbnailType\n\n\nThe type of the thumbnail as number (see table below)\n\n\n\n\n\n\nthumbnailPosition\n\n\nThe time position in case of snapshot thumbnails\n\n\n\n\n\n\nthumbnailTrack\n\n\nThe source track in case of snapshot thumbnails\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThumbnail Type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n0\n\n\nThe default thumbnail shall be extracted at a configured time position\n\n\n\n\n\n\n1\n\n\nThe thumbnail has been uploaded and is stored in the asset manager as media package attachment\n\n\n\n\n\n\n2\n\n\nThe thumbnail shall be extracted at a given time position from a given track\n\n\n\n\n\n\n\n\nAt any given point of time, there is exactly one thumbnail available for each published event.\nThere are three different kinds of thumbnails:\n\n\n\n\nDefault thumbnail\n\n\nUploaded thumbnail\n\n\nSnapshot thumbnail\n\n\n\n\nDefault Thumbnail\n\n\nThis thumbnail is supposed to be automatically generated without user interaction. It is extracted from the time\nposition as you define it in your workflow.\n\n\nIf you are not using the default time position, be sure to adapt the value of \nthumbnail.default.position\n in\n\netc/org.opencastproject.adminui.cfg\n. This is required to allow the Admin UI to dynamically generate a preview\nimage for the default thumbnail.\n\n\nUploaded Thumbnail\n\n\nThe Admin UI supports the upload of an image to be used as thumbnail. This thumbnail image will available to\nworkflows for further processing as media package attachment with a configurable flavour\n(default: \nthumbnail/source\n).\n\n\nIf you need another flavor for the thumbnail in your specific environment, be sure to adapt the value of\n\nthumbnail.source.flavor.type\n and \nthumbnail.source.flavor.subtype\n in \netc/org.opencastproject.adminui.cfg\n\nso that the Admin UI adds the thumbnail images with the expected flavour.\n\n\nSnapshot Thumbnail\n\n\nAs a balance between the quality of the thumbnail (default) and the effort to create a thumbnail (upload), the Admin UI\nsupports thumbnails that are be extracted from existing tracks. This allows users to take a snapshot at an arbitrary\ntime position from a source track by simply selecting the position and pressing a button.\n\n\nThe variable \nthumbnailPosition\n holds the time value (in seconds as floating point) and the variable \nthumbnailTrack\n\nholds the flavour type of the track where that thumbnail is supposed to be extracted.\n\n\nPlease note that \nthumbnailPosition\n refers to the (unmodified) track identified by  \nthumbnailTrack\n.\n\n\nThumbnail Preview\n\n\nThe Admin UI is capable of presenting a preview image of the currently used thumbnail which a) must be\ncreated by the workflow that generates previews for the Admin UI initially and b) will be created and re-distributed\nby the Admin UI each time the thumbnail is changed.\n\n\nThe Admin UI manages this preview image of the thumbnail in the publication channel \ninternal\n. To make this thumbnail\npreview work in environments that use custom flavors, a number of configuration options are available in\n\netc/org.opencastproject.adminui.cfg\n:\n\n\n\n\n\n\n\n\nOption\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nthumbnail.preview.flavor\n\n\nthumbnail/preview\n\n\nThe flavor of the thumbnail preview image\n\n\n\n\n\n\nthumbnail.default.position\n\n\n1.0\n\n\nThe time position where the default thumbnail is extracted at\n\n\n\n\n\n\nthumbnail.default.track.primary\n\n\npresenter\n\n\nThe flavor type of the track where the default thumbnail is extracted\n\n\n\n\n\n\nthumbnail.default.track.secondary\n\n\npresentation\n\n\nThe flavor type of the track where the default thumbnail is extracted in case no track with flavor type thumbnail.default.track.primary is available\n\n\n\n\n\n\n\n\nNote that the preview image for the default thumbnail needs to be initially created and published which usually is done\nin the workflow definition responsible for creating the previews required by the Admin UI.\n\n\nTest the Workflow\n\n\nThe easiest way to test a workflow is to just put it into the workflow folder where it will be picked up by Opencast\nautomatically and will be available in Opencast a few seconds later.",
            "title": "Workflow"
        },
        {
            "location": "/configuration/workflow/#create-a-custom-workflow",
            "text": "This document will help you get started with creating your own Opencast workflows. For a list of available workflow\noperations, see:   List of Workflow Operation Handler",
            "title": "Create a Custom Workflow"
        },
        {
            "location": "/configuration/workflow/#overview",
            "text": "A Opencast workflow is an ordered list of operations. There is no limit to the number of operations or their\nrepetition in a given workflow.  Workflow operations can be configured using configuration elements. The use of string replacement in configuration\nvalues allows workflows to dynamically adapt to a given input or user decision.",
            "title": "Overview"
        },
        {
            "location": "/configuration/workflow/#document",
            "text": "Opencast workflows are defined in XML.  The structure of a Opencast workflow looks like this:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  <id></id>\n  <title></title>\n  <tags></tags>\n  <description></description>\n  <displayOrder></displayOrder>\n\n  <!-- Operations -->\n  <operations>\n    <operation></operation>\n    ...\n  </operations>\n\n</definition>",
            "title": "Document"
        },
        {
            "location": "/configuration/workflow/#create-a-workflow",
            "text": "This sections will walk you through creating a custom workflow, which will encode ingested tracks to defined output\nformat.",
            "title": "Create a Workflow"
        },
        {
            "location": "/configuration/workflow/#encoding-profiles",
            "text": "First create or select the encoding profiles you want to use. For more details on this, have a look at the  Encoding\nProfile Configuration Guide . For this guide we assume that we have an encoding profile  mov-low.http \nwhich creates a distribution format definition for mp4 video and a  feed-cover.http  encoding profile to create\nthumbnail images for the videos.",
            "title": "Encoding Profiles"
        },
        {
            "location": "/configuration/workflow/#describe-the-workflow",
            "text": "Start by naming the workflow and giving it a meaningful description:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  <id>example</id>\n  <title>Encode Mp4, Distribute and Publish</title>\n  <tags>\n    <!-- Tell the UI where to show this workflow -->\n    <tag>upload</tag>\n    <tag>schedule</tag>\n    <tag>archive</tag>\n  </tags>\n  <description>\n    Encode to Mp4 and thumbnail.\n    Distribute to local repository.\n    Publish to search index.\n  </description>\n  <displayOrder>10</displayOrder>\n\n  <!-- Operations -->\n  <operations></operations>\n\n</definition>   The  id  is used in several Opencast endpoints to identify and select this workflow. Make sure that this identifier\n  is unique among all endpoints in the system.  The  tags  define where the user interfaces may use these workflows. Useful tags are:  upload : Usable for uploaded media  schedule : Usable for scheduled events  archive : Usable for archived media  delete : Usable for deletion of events with publications  editor : Usable from the video editor    The  displayOrder  is an integer that indicates in what order workflow definitions shall be displayed by clients.\n  If ommitted, the  displayOrder  defaults to  0 . Clients are expected to list workflow definitions in descending order.",
            "title": "Describe the Workflow"
        },
        {
            "location": "/configuration/workflow/#inspect-the-media",
            "text": "The first operation will be to inspect the media for technical metadata, such as format and length:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    <operation\n      id=\"inspect\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Inspect media package\">\n    </operation>\n\n  </operations>\n\n</definition>  The  fail-on-error  attribute is a boolean determining whether the workflow will throw an error to the\nexception-handler-workflow or simply proceed with the remaining operations.",
            "title": "Inspect the Media"
        },
        {
            "location": "/configuration/workflow/#encoding",
            "text": "The next operations will encode the media to the Mp4 format:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    ...\n\n    <!-- encode: mp4 -->\n    <operation\n      id=\"compose\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode camera to mp4\">\n      <configurations>\n        <configuration key=\"source-flavor\">presenter/source</configuration>\n        <configuration key=\"target-flavor\">presenter/delivery</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">mov-low.http</configuration>\n      </configurations>\n    </operation>\n\n    <operation\n      id=\"compose\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode screen to mp4\">\n      <configurations>\n        <configuration key=\"source-flavor\">presentation/source</configuration>\n        <configuration key=\"target-flavor\">presentation/delivery</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">mov-low.http</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>   The  target-tags  attribute causes the resulting media to be tagged. For example, this could be used to define these\n  media as input for other operations, using their  source-tags  attribute.  The  encoding-profile  attribute refers to an encoding profile defined in  etc/encoding .",
            "title": "Encoding"
        },
        {
            "location": "/configuration/workflow/#encode-to-thumbnail",
            "text": "The next operations will create thumbnails from the media:  <definition xmlns=\"http://workflow.opencastproject.org\">\n  ...\n  <operations>\n    ...\n    <!-- encode: images -->\n    <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode camera to thumbnail\">\n      <configurations>\n        <configuration key=\"source-flavor\">presenter/source</configuration>\n        <configuration key=\"source-tags\"></configuration>\n        <configuration key=\"target-flavor\">cover/source</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">feed-cover.http</configuration>\n        <configuration key=\"time\">1</configuration>\n      </configurations>\n    </operation>\n\n    <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode screen to thumbnail\">\n      <configurations>\n        <configuration key=\"source-flavor\">presentation/source</configuration>\n        <configuration key=\"source-tags\"></configuration>\n        <configuration key=\"target-flavor\">cover/source</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">feed-cover.http</configuration>\n        <configuration key=\"time\">1</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>   The time attribute determines the approximate frame of the source media is used. The time unit is in seconds.",
            "title": "Encode to Thumbnail"
        },
        {
            "location": "/configuration/workflow/#distribute-the-media",
            "text": "The next operation copies the encoded media to the Opencast distribution channel:  <definition xmlns=\"http://workflow.opencastproject.org\">\n  ...\n  <operations>\n\n    <!-- distribute: local -->\n    <operation\n      id=\"publish-engage\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Distribute media to the local distribution channel\">\n      <configurations>\n        <configuration key=\"download-source-tags\">publish,rss,atom</configuration>\n        <configuration key=\"streaming-source-tags\"></configuration>\n        <configuration key=\"check-availability\">true</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>   The publish-engage operation uses all media tagged as  rss  or  atom  as input.",
            "title": "Distribute the Media"
        },
        {
            "location": "/configuration/workflow/#accept-user-input",
            "text": "Workflow definitions may optionally include variables to be replaced by user input. For instance, this may be used to\nselect optional parts of a workflow. To enable user control of individual workflow instances, the workflow definition\nmust:   use the  ${variable}  notation in the workflow definition  contain a custom configuration panel.   Here is an example of a configurable operation:  <operation id=\"...\" if=\"${somevar}\">\n  ...\n</operation>  The attribute  if  specifies the execution condition in means of the operation only being executed if that condition\nevaluates to true. You can find more details on conditional execution in the next section.  Once the operation is configured to accept a variable, we need to describe how to gather the value from the\nadministrative user. The  <configuration_panel>  element of a workflow definitions describes this user interface\nsnippet.  A simple configuration panel could look like this:  <configuration_panel>\n  <![CDATA[\n    <input id=\"someaction\" name=\"someaction\" type=\"checkbox\" value=\"true\" />\n    <label for=\"someaction\">Execute some operation?</label>\n  ]]>\n</configuration_panel>  The checkbox in this  <configuration_panel>  will now be displayed in the administrative tools, and the user's\nselection will be used to replace the  ${someaction}  variable in the workflow.  This input can also be sent by capture agents, using the ingest endpoints. Please note that capture agents usually do\nnot load the configuration panel. Hence defaults set in the user interface will not apply to ingests. To circumvent\nthis, the  defaults operation  can be used.",
            "title": "Accept User Input"
        },
        {
            "location": "/configuration/workflow/#conditional-execution",
            "text": "The attribute  if  of the  operation  element can be used to specify a condition to control whether the workflow\noperation should be executed. This so-called execution condition is a boolean expression of the following form:  <expression> ::= <term> [\"OR\" <expression>]\n<term> ::= <value> [\"AND\" <term>]\n<value> ::= [\"NOT\"]* ( \"(\" <expression> \")\" | <relation> | <bool-literal> )\n<relation> ::= <relation-factor> <rel-literal> <relation-factor>\n<relation-factor> ::= <operation> | <number>\n<operation> ::= <number> <op-literal> <number>\n<rel-literal> ::= \">=\" | \">\" | \"<=\" | \"<\" | \"==\" | \"!=\"\n<op-literal> ::= \"+\" | \"-\" | \"*\" | \"/\"\n<bool-literal> ::= \"true\" | \"false\"  As the formal description above explains, such boolean expressions may contain the booelan constants ( true  and false ) and numbers, as well as references to the variables of the workflow instance that contain these data types.\nWorkflow instance variables can be accessed by using  ${variableName} .  Example:  <operation id=\"...\" if=\"${variableName1} AND NOT (${variableName2} OR ${variableName3})\">\n  \u2026\n</operation>  Note that XML requires certain characters like the  <  and  >  operators to be written as XML entities. Even if they are\nused quoted in attributes. The following table shows all those characters:  \"  \u2192  &quot;\n'  \u2192  &apos;\n<  \u2192  &lt;\n>  \u2192  &gt;\n&  \u2192  &amp;  Example:  <operation id=\"...\" if=\"${yresolution} &gt; 720\">\n  \u2026\n</operation>",
            "title": "Conditional Execution"
        },
        {
            "location": "/configuration/workflow/#thumbnail-support",
            "text": "The Admin UI comes with explicit support for thumbnails that are supposed to represent events visually, e.g. in lists\nof events as commonly used in video portals and other similar systems.\nTo make it possible to implement the required processing and retain flexibility, the Admin UI will store the following\ninformation in variables of workflow instances:     Variable  Description      thumbnailType  The type of the thumbnail as number (see table below)    thumbnailPosition  The time position in case of snapshot thumbnails    thumbnailTrack  The source track in case of snapshot thumbnails        Thumbnail Type  Description      0  The default thumbnail shall be extracted at a configured time position    1  The thumbnail has been uploaded and is stored in the asset manager as media package attachment    2  The thumbnail shall be extracted at a given time position from a given track     At any given point of time, there is exactly one thumbnail available for each published event.\nThere are three different kinds of thumbnails:   Default thumbnail  Uploaded thumbnail  Snapshot thumbnail",
            "title": "Thumbnail Support"
        },
        {
            "location": "/configuration/workflow/#default-thumbnail",
            "text": "This thumbnail is supposed to be automatically generated without user interaction. It is extracted from the time\nposition as you define it in your workflow.  If you are not using the default time position, be sure to adapt the value of  thumbnail.default.position  in etc/org.opencastproject.adminui.cfg . This is required to allow the Admin UI to dynamically generate a preview\nimage for the default thumbnail.",
            "title": "Default Thumbnail"
        },
        {
            "location": "/configuration/workflow/#uploaded-thumbnail",
            "text": "The Admin UI supports the upload of an image to be used as thumbnail. This thumbnail image will available to\nworkflows for further processing as media package attachment with a configurable flavour\n(default:  thumbnail/source ).  If you need another flavor for the thumbnail in your specific environment, be sure to adapt the value of thumbnail.source.flavor.type  and  thumbnail.source.flavor.subtype  in  etc/org.opencastproject.adminui.cfg \nso that the Admin UI adds the thumbnail images with the expected flavour.",
            "title": "Uploaded Thumbnail"
        },
        {
            "location": "/configuration/workflow/#snapshot-thumbnail",
            "text": "As a balance between the quality of the thumbnail (default) and the effort to create a thumbnail (upload), the Admin UI\nsupports thumbnails that are be extracted from existing tracks. This allows users to take a snapshot at an arbitrary\ntime position from a source track by simply selecting the position and pressing a button.  The variable  thumbnailPosition  holds the time value (in seconds as floating point) and the variable  thumbnailTrack \nholds the flavour type of the track where that thumbnail is supposed to be extracted.  Please note that  thumbnailPosition  refers to the (unmodified) track identified by   thumbnailTrack .",
            "title": "Snapshot Thumbnail"
        },
        {
            "location": "/configuration/workflow/#thumbnail-preview",
            "text": "The Admin UI is capable of presenting a preview image of the currently used thumbnail which a) must be\ncreated by the workflow that generates previews for the Admin UI initially and b) will be created and re-distributed\nby the Admin UI each time the thumbnail is changed.  The Admin UI manages this preview image of the thumbnail in the publication channel  internal . To make this thumbnail\npreview work in environments that use custom flavors, a number of configuration options are available in etc/org.opencastproject.adminui.cfg :     Option  Default  Description      thumbnail.preview.flavor  thumbnail/preview  The flavor of the thumbnail preview image    thumbnail.default.position  1.0  The time position where the default thumbnail is extracted at    thumbnail.default.track.primary  presenter  The flavor type of the track where the default thumbnail is extracted    thumbnail.default.track.secondary  presentation  The flavor type of the track where the default thumbnail is extracted in case no track with flavor type thumbnail.default.track.primary is available     Note that the preview image for the default thumbnail needs to be initially created and published which usually is done\nin the workflow definition responsible for creating the previews required by the Admin UI.",
            "title": "Thumbnail Preview"
        },
        {
            "location": "/configuration/workflow/#test-the-workflow",
            "text": "The easiest way to test a workflow is to just put it into the workflow folder where it will be picked up by Opencast\nautomatically and will be available in Opencast a few seconds later.",
            "title": "Test the Workflow"
        },
        {
            "location": "/configuration/external-api/",
            "text": "External API Configuration\n\n\nThe External API is an integral part of Opencast and therefore does not need to be enabled. To be able to access the\nExternal API, you need to configure a user that is authorized to do so.\n\n\nPerform the following steps to get the External API running:\n\n\n\n\nEnable basic authentication (see section Authentication)\n\n\nCreate a new user or choose an existing user (administrative user interface)\n\n\nAuthorize the user to access the External API (see section Authorization)\n\n\nTest whether access works (see section Testing)\n\n\n\n\nAuthentication\n\n\nThe External API currenlty only supports basic authentication. To enable basic authentication, uncomment the following\nblocks in \n/etc/security/mh_default.org\n:\n\n\n<!-- Basic authentication\n<sec:custom-filter after=\"BASIC_AUTH_FILTER\" ref=\"basicAuthenticationFilter\" />\n-->\n\n<!-- Basic authentication\n<bean id=\"basicEntryPoint\" class=\"org.springframework.security.web.authentication.www.BasicAuthenticationEntryPoint\">\n  <property name=\"realmName\" value=\"Opencast\"/>\n</bean>\n-->\n\n<!-- Basic authentication\n<bean id=\"basicAuthenticationFilter\" class=\"org.springframework.security.web.authentication.www.BasicAuthenticationFilter\">\n  <property name=\"authenticationManager\" ref=\"authenticationManager\"/>\n  <property name=\"authenticationEntryPoint\" ref=\"basicEntryPoint\"/>\n</bean>\n-->\n\n\n\nNote:\n Since basic authentication involves sending unencrypted passwords over the network, it is strongly\nrecommended to use HTTPS.\n\n\nAuthorization\n\n\nThe External API supports fine-grained access control on request level allowing it to be tailored to your\nspecific needs. A number of roles are used to authorize access to individual endpoints. Those roles can be configured\ndirectly in the Opencast administrative user interface.\n\n\nNote:\n Users owning the role ROLE_ADMIN have full access to the External API.\n\n\nBase API\n\n\n\n\n\n\n\n\nROLE\n\n\nMETHOD\n\n\nURL\n\n\n\n\n\n\n\n\n\n\nROLE_API\n\n\nGET\n\n\n/api\n/api/info/*\n/api/info/me/*\n/api/version\n/api/version/*\n\n\n\n\n\n\n\n\nEvents API\n\n\n\n\n\n\n\n\nROLE\n\n\nMETHOD\n\n\nURL\n\n\n\n\n\n\n\n\n\n\nROLE_API_EVENTS_CREATE\n\n\nPOST\n\n\n/api/events\n\n\n\n\n\n\nROLE_API_EVENTS_VIEW\n\n\nGET\n\n\n/api/events\n/api/events/*\n\n\n\n\n\n\nROLE_API_EVENTS_EDIT\n\n\nPUT\nPOST\n\n\n/api/events/*\n/api/events/*\n\n\n\n\n\n\nROLE_API_EVENTS_DELETE\n\n\nDELETE\n\n\n/api/events/*\n\n\n\n\n\n\nROLE_API_EVENTS_ACL_VIEW\n\n\nGET\n\n\n/api/events/*/acl\n\n\n\n\n\n\nROLE_API_EVENTS_ACL_EDIT\n\n\nPUT\nPOST\n\n\n/api/events/*/acl\n/api/events/*/acl/*\n\n\n\n\n\n\nROLE_API_EVENTS_ACL_DELETE\n\n\nDELETE\n\n\n/api/events/*/acl/*/*\n\n\n\n\n\n\nROLE_API_EVENTS_MEDIA_VIEW\n\n\nGET\n\n\n/api/events/*/media\n/api/events/*/media/*\n\n\n\n\n\n\nROLE_API_EVENTS_METADATA_VIEW\n\n\nGET\n\n\n/api/events/*/metadata\n/api/events/*/metadata/*\n\n\n\n\n\n\nROLE_API_EVENTS_METADATA_EDIT\n\n\nPUT\n\n\n/api/events/*/metadata\n/api/events/*/metadata/*\n\n\n\n\n\n\nROLE_API_EVENTS_METADATA_DELETE\n\n\nDELETE\n\n\n/api/events/*/metadata\n/api/events/*/metadata/*\n\n\n\n\n\n\nROLE_API_EVENTS_PUBLICATIONS_VIEW\n\n\nGET\n\n\n/api/events/*/publications\n/api/events/*/publications/*\n\n\n\n\n\n\nROLE_API_EVENTS_SCHEDULING_EDIT\n\n\nPUT\n\n\n/api/events/*/scheduling\n\n\n\n\n\n\nROLE_API_EVENTS_SCHEDULING_VIEW\n\n\nGET\n\n\n/api/events/*/scheduling\n\n\n\n\n\n\n\n\nSeries API\n\n\n\n\n\n\n\n\nROLE\n\n\nMETHOD\n\n\nURL\n\n\n\n\n\n\n\n\n\n\nROLE_API_SERIES_CREATE\n\n\nPOST\n\n\n/api/series\n\n\n\n\n\n\nROLE_API_SERIES_VIEW\n\n\nGET\n\n\n/api/series\n/api/series/*\n\n\n\n\n\n\nROLE_API_SERIES_EDIT\n\n\nPUT\n\n\n/api/series/*\n\n\n\n\n\n\nROLE_API_SERIES_ACL_VIEW\n\n\nGET\n\n\n/api/series/*/acl\n\n\n\n\n\n\nROLE_API_SERIES_ACL_EDIT\n\n\nPUT\n\n\n/api/series/*/metadata\n/api/series/*/metadata/*\n\n\n\n\n\n\nROLE_API_SERIES_METADATA_VIEW\n\n\nGET\n\n\n/api/series/*/metadata\n/api/series/*/metadata/*\n\n\n\n\n\n\nROLE_API_SERIES_METADATA_EDIT\n\n\nPUT\n\n\n/api/series/*/metadata\n/api/series/*/metadata/*\n\n\n\n\n\n\nROLE_API_SERIES_METADATA_DELETE\n\n\nDELETE\n\n\n/api/series/*/metadata\n/api/series/*/metadata/*\n\n\n\n\n\n\nROLE_API_SERIES_PROPERTIES_VIEW\n\n\nGET\n\n\n/api/series/*/properties\n\n\n\n\n\n\nROLE_API_SERIES_PROPERTIES_EDIT\n\n\nPUT\n\n\n/api/series/*/properties\n\n\n\n\n\n\nROLE_API_SERIES_DELETE\n\n\nDELETE\n\n\n/api/series/*\n\n\n\n\n\n\n\n\nGroups API\n\n\n\n\n\n\n\n\nROLE\n\n\nMETHOD\n\n\nURL\n\n\n\n\n\n\n\n\n\n\nROLE_API_GROUPS_CREATE\n\n\nPOST\n\n\n/api/groups\n\n\n\n\n\n\nROLE_API_GROUPS_VIEW\n\n\nGET\n\n\n/api/groups\n/api/groups/*\n\n\n\n\n\n\nROLE_API_GROUPS_EDIT\n\n\nPUT\nPOST\n\n\n/api/groups/*\n/api/groups/*/members/*\n\n\n\n\n\n\nROLE_API_GROUPS_DELETE\n\n\nDELETE\n\n\n/api/groups/*\n\n\n\n\n\n\n\n\nSecurity API\n\n\n\n\n\n\n\n\nROLE\n\n\nMETHOD\n\n\nURL\n\n\n\n\n\n\n\n\n\n\nROLE_API_SECURITY_EDIT\n\n\nPOST\n\n\n/api/security/sign\n\n\n\n\n\n\n\n\nAgents API\n\n\n\n\n\n\n\n\nROLE\n\n\nMETHOD\n\n\nURL\n\n\n\n\n\n\n\n\n\n\nROLE_API_CAPTURE_AGENTS_VIEW\n\n\nGET\n\n\n/api/agents\n/api/agents/*\n\n\n\n\n\n\n\n\nAdministrative API\n\n\n\n\n\n\n\n\nROLE\n\n\nMETHOD\n\n\nURL\n\n\n\n\n\n\n\n\n\n\nROLE_ADMIN\n\n\nPOST\n\n\n/api/recreateIndex\n\n\n\n\n\n\n\n\nWorkflow API\n\n\n\n\n\n\n\n\nROLE\n\n\nMETHOD\n\n\nURL\n\n\n\n\n\n\n\n\n\n\nROLE_API_WORKFLOW_INSTANCE_CREATE\n\n\nPOST\n\n\n/api/workflow\n\n\n\n\n\n\nROLE_API_WORKFLOW_INSTANCE_VIEW\n\n\nGET\n\n\n/api/workflow\n/api/workflow/*\n\n\n\n\n\n\nROLE_API_WORKFLOW_INSTANCE_EDIT\n\n\nPUT\n\n\n/api/workflow/*\n\n\n\n\n\n\nROLE_API_WORKFLOW_INSTANCE_DELETE\n\n\nDELETE\n\n\n/api/workflow/*\n\n\n\n\n\n\nROLE_API_WORKFLOW_DEFINITION_VIEW\n\n\nGET\n\n\n/api/workflow-definitions\n/api/workflow-definitions/*\n\n\n\n\n\n\n\n\nUser- and Role-switching\n\n\nThe External API supports user- and role-switching, i.e. it is possible to perform requests on behalf of another\nuser or role. The be able to perform this kind of requests, the user doing the actual requests needs to own ROLE_SUDO.\n\n\nFor more details on this API, please take a look at the developer documentation under External API.\n\n\nTesting\n\n\ncurl -u <api-user>:<api-user-passowrd> <admin-node>/api/info/me\n\n\n\nshould return a JSON containing information about the user \napi-user\n.\n\n\nAccessing Distribution Artefacts\n\n\nA major use case of the External API is to provide External Applications secure access to distribution artefacts.\n\n\nFor this purpose, Opencast comes with a special workflow operation: WOH publish-configure\n(see \nConfigurablePublishWorkflowOperationHandler\n)\ncreates publication elements that do not just contain a single URL to the publication channel,\nbut also contain URLs for each of the attachments and tracks that have been published.\n\n\nNote:\n Secure access to distribution artefacts requires stream security to be enabled,\nsee \nStream Security Configuration\n.",
            "title": "External API"
        },
        {
            "location": "/configuration/external-api/#external-api-configuration",
            "text": "The External API is an integral part of Opencast and therefore does not need to be enabled. To be able to access the\nExternal API, you need to configure a user that is authorized to do so.  Perform the following steps to get the External API running:   Enable basic authentication (see section Authentication)  Create a new user or choose an existing user (administrative user interface)  Authorize the user to access the External API (see section Authorization)  Test whether access works (see section Testing)",
            "title": "External API Configuration"
        },
        {
            "location": "/configuration/external-api/#authentication",
            "text": "The External API currenlty only supports basic authentication. To enable basic authentication, uncomment the following\nblocks in  /etc/security/mh_default.org :  <!-- Basic authentication\n<sec:custom-filter after=\"BASIC_AUTH_FILTER\" ref=\"basicAuthenticationFilter\" />\n-->\n\n<!-- Basic authentication\n<bean id=\"basicEntryPoint\" class=\"org.springframework.security.web.authentication.www.BasicAuthenticationEntryPoint\">\n  <property name=\"realmName\" value=\"Opencast\"/>\n</bean>\n-->\n\n<!-- Basic authentication\n<bean id=\"basicAuthenticationFilter\" class=\"org.springframework.security.web.authentication.www.BasicAuthenticationFilter\">\n  <property name=\"authenticationManager\" ref=\"authenticationManager\"/>\n  <property name=\"authenticationEntryPoint\" ref=\"basicEntryPoint\"/>\n</bean>\n-->  Note:  Since basic authentication involves sending unencrypted passwords over the network, it is strongly\nrecommended to use HTTPS.",
            "title": "Authentication"
        },
        {
            "location": "/configuration/external-api/#authorization",
            "text": "The External API supports fine-grained access control on request level allowing it to be tailored to your\nspecific needs. A number of roles are used to authorize access to individual endpoints. Those roles can be configured\ndirectly in the Opencast administrative user interface.  Note:  Users owning the role ROLE_ADMIN have full access to the External API.  Base API     ROLE  METHOD  URL      ROLE_API  GET  /api /api/info/* /api/info/me/* /api/version /api/version/*     Events API     ROLE  METHOD  URL      ROLE_API_EVENTS_CREATE  POST  /api/events    ROLE_API_EVENTS_VIEW  GET  /api/events /api/events/*    ROLE_API_EVENTS_EDIT  PUT POST  /api/events/* /api/events/*    ROLE_API_EVENTS_DELETE  DELETE  /api/events/*    ROLE_API_EVENTS_ACL_VIEW  GET  /api/events/*/acl    ROLE_API_EVENTS_ACL_EDIT  PUT POST  /api/events/*/acl /api/events/*/acl/*    ROLE_API_EVENTS_ACL_DELETE  DELETE  /api/events/*/acl/*/*    ROLE_API_EVENTS_MEDIA_VIEW  GET  /api/events/*/media /api/events/*/media/*    ROLE_API_EVENTS_METADATA_VIEW  GET  /api/events/*/metadata /api/events/*/metadata/*    ROLE_API_EVENTS_METADATA_EDIT  PUT  /api/events/*/metadata /api/events/*/metadata/*    ROLE_API_EVENTS_METADATA_DELETE  DELETE  /api/events/*/metadata /api/events/*/metadata/*    ROLE_API_EVENTS_PUBLICATIONS_VIEW  GET  /api/events/*/publications /api/events/*/publications/*    ROLE_API_EVENTS_SCHEDULING_EDIT  PUT  /api/events/*/scheduling    ROLE_API_EVENTS_SCHEDULING_VIEW  GET  /api/events/*/scheduling     Series API     ROLE  METHOD  URL      ROLE_API_SERIES_CREATE  POST  /api/series    ROLE_API_SERIES_VIEW  GET  /api/series /api/series/*    ROLE_API_SERIES_EDIT  PUT  /api/series/*    ROLE_API_SERIES_ACL_VIEW  GET  /api/series/*/acl    ROLE_API_SERIES_ACL_EDIT  PUT  /api/series/*/metadata /api/series/*/metadata/*    ROLE_API_SERIES_METADATA_VIEW  GET  /api/series/*/metadata /api/series/*/metadata/*    ROLE_API_SERIES_METADATA_EDIT  PUT  /api/series/*/metadata /api/series/*/metadata/*    ROLE_API_SERIES_METADATA_DELETE  DELETE  /api/series/*/metadata /api/series/*/metadata/*    ROLE_API_SERIES_PROPERTIES_VIEW  GET  /api/series/*/properties    ROLE_API_SERIES_PROPERTIES_EDIT  PUT  /api/series/*/properties    ROLE_API_SERIES_DELETE  DELETE  /api/series/*     Groups API     ROLE  METHOD  URL      ROLE_API_GROUPS_CREATE  POST  /api/groups    ROLE_API_GROUPS_VIEW  GET  /api/groups /api/groups/*    ROLE_API_GROUPS_EDIT  PUT POST  /api/groups/* /api/groups/*/members/*    ROLE_API_GROUPS_DELETE  DELETE  /api/groups/*     Security API     ROLE  METHOD  URL      ROLE_API_SECURITY_EDIT  POST  /api/security/sign     Agents API     ROLE  METHOD  URL      ROLE_API_CAPTURE_AGENTS_VIEW  GET  /api/agents /api/agents/*     Administrative API     ROLE  METHOD  URL      ROLE_ADMIN  POST  /api/recreateIndex     Workflow API     ROLE  METHOD  URL      ROLE_API_WORKFLOW_INSTANCE_CREATE  POST  /api/workflow    ROLE_API_WORKFLOW_INSTANCE_VIEW  GET  /api/workflow /api/workflow/*    ROLE_API_WORKFLOW_INSTANCE_EDIT  PUT  /api/workflow/*    ROLE_API_WORKFLOW_INSTANCE_DELETE  DELETE  /api/workflow/*    ROLE_API_WORKFLOW_DEFINITION_VIEW  GET  /api/workflow-definitions /api/workflow-definitions/*     User- and Role-switching  The External API supports user- and role-switching, i.e. it is possible to perform requests on behalf of another\nuser or role. The be able to perform this kind of requests, the user doing the actual requests needs to own ROLE_SUDO.  For more details on this API, please take a look at the developer documentation under External API.",
            "title": "Authorization"
        },
        {
            "location": "/configuration/external-api/#testing",
            "text": "curl -u <api-user>:<api-user-passowrd> <admin-node>/api/info/me  should return a JSON containing information about the user  api-user .",
            "title": "Testing"
        },
        {
            "location": "/configuration/external-api/#accessing-distribution-artefacts",
            "text": "A major use case of the External API is to provide External Applications secure access to distribution artefacts.  For this purpose, Opencast comes with a special workflow operation: WOH publish-configure\n(see  ConfigurablePublishWorkflowOperationHandler )\ncreates publication elements that do not just contain a single URL to the publication channel,\nbut also contain URLs for each of the attachments and tracks that have been published.  Note:  Secure access to distribution artefacts requires stream security to be enabled,\nsee  Stream Security Configuration .",
            "title": "Accessing Distribution Artefacts"
        },
        {
            "location": "/configuration/oaipmh/",
            "text": "OAI-PMH Configuration\n\n\nOverview\n\n\nOAI-PMH is an XML based protocol for metadata exchange using HTTP as the transport layer. An OAI-PMH system consists\nof two parts, a repository on the one and the harvester on the other end. The repository is an HTTP accessible server\nthat exposes metadata to its client, the harvester.\n\n\nOAI-PMH repositories will be accessed using URLs of the form:\n\n\n<OAI-PMH server> + <OAI-PMH mount point> + <OAI-PMH Repository>\n\n\n\nStep 1: Configure the URL of the OAI-PMH server\n\n\nThe property to configure the OAI-PMH server URL can be found in\n\netc/org.opencastproject.organization-mh_default_org.cfg\n:\n\n\nprop.org.opencastproject.oaipmh.server.hosturl=http://localhost:8080\n\n\n\nStep 2: Configure the OAI-PMH mount point\n\n\nThe property to configure the OAI-PMH mount point can be found in \netc/custom.properties\n:\n\n\norg.opencastproject.oaipmh.mountpoint=/oaipmh\n\n\n\nStep 3: Configure the OAI-PMH default repository\n\n\nIn case the repository is not included in the URL, the OAI-PMH default repository will be selected.\n\n\nThe property to configure the OAI-PMH default repository can be found in\n\netc/org.opencastproject.oaipmh.server.OaiPmhServer.cfg\n\n\ndefault-repository=default\n\n\n\nStep 4: Allow access to OAI-PMH mount point\n\n\nMake sure that the OAI-PMH mount point is accessible. For example, if the OAI-PMH mount point has\nbeen set to \n/oaipmh\n, the following two lines\n\n\n<sec:intercept-url pattern=\"/oaipmh/**\" method=\"GET\" access=\"ROLE_ANONYMOUS\"/>\n<sec:intercept-url pattern=\"/oaipmh/**\" method=\"POST\" access=\"ROLE_ANONYMOUS\"/>\n\n\n\nshould be present in \netc/security/mh_default_org.xml\n.\n\n\nNote that the OAI-PMH specification demands both GET and POST requests and that\nit does not feature any access restrictions. If you need to restrict access\nto OAI-PMH consider using Spring security or an iptables approach.",
            "title": "OAI-PMH"
        },
        {
            "location": "/configuration/oaipmh/#oai-pmh-configuration",
            "text": "",
            "title": "OAI-PMH Configuration"
        },
        {
            "location": "/configuration/oaipmh/#overview",
            "text": "OAI-PMH is an XML based protocol for metadata exchange using HTTP as the transport layer. An OAI-PMH system consists\nof two parts, a repository on the one and the harvester on the other end. The repository is an HTTP accessible server\nthat exposes metadata to its client, the harvester.  OAI-PMH repositories will be accessed using URLs of the form:  <OAI-PMH server> + <OAI-PMH mount point> + <OAI-PMH Repository>",
            "title": "Overview"
        },
        {
            "location": "/configuration/oaipmh/#step-1-configure-the-url-of-the-oai-pmh-server",
            "text": "The property to configure the OAI-PMH server URL can be found in etc/org.opencastproject.organization-mh_default_org.cfg :  prop.org.opencastproject.oaipmh.server.hosturl=http://localhost:8080",
            "title": "Step 1: Configure the URL of the OAI-PMH server"
        },
        {
            "location": "/configuration/oaipmh/#step-2-configure-the-oai-pmh-mount-point",
            "text": "The property to configure the OAI-PMH mount point can be found in  etc/custom.properties :  org.opencastproject.oaipmh.mountpoint=/oaipmh",
            "title": "Step 2: Configure the OAI-PMH mount point"
        },
        {
            "location": "/configuration/oaipmh/#step-3-configure-the-oai-pmh-default-repository",
            "text": "In case the repository is not included in the URL, the OAI-PMH default repository will be selected.  The property to configure the OAI-PMH default repository can be found in etc/org.opencastproject.oaipmh.server.OaiPmhServer.cfg  default-repository=default",
            "title": "Step 3: Configure the OAI-PMH default repository"
        },
        {
            "location": "/configuration/oaipmh/#step-4-allow-access-to-oai-pmh-mount-point",
            "text": "Make sure that the OAI-PMH mount point is accessible. For example, if the OAI-PMH mount point has\nbeen set to  /oaipmh , the following two lines  <sec:intercept-url pattern=\"/oaipmh/**\" method=\"GET\" access=\"ROLE_ANONYMOUS\"/>\n<sec:intercept-url pattern=\"/oaipmh/**\" method=\"POST\" access=\"ROLE_ANONYMOUS\"/>  should be present in  etc/security/mh_default_org.xml .  Note that the OAI-PMH specification demands both GET and POST requests and that\nit does not feature any access restrictions. If you need to restrict access\nto OAI-PMH consider using Spring security or an iptables approach.",
            "title": "Step 4: Allow access to OAI-PMH mount point"
        },
        {
            "location": "/configuration/ui/",
            "text": "Admin UI Configuration\n\n\nConfiguring the events filters\n\n\nAt the top right of the admin UI a set of predefined filters for events are available, displayed with a description and\nthe amount of events currently matching that filter. By default, the following filters are visible:\n\n\n\n\n\n\n\n\nStatistic\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nYesterday\n\n\nAll events with a start date sometime yesterday.\n\n\n\n\n\n\nToday\n\n\nAll events with a start date sometime today.\n\n\n\n\n\n\nTomorrow\n\n\nAll events with a start date sometime tomorrow.\n\n\n\n\n\n\nScheduled\n\n\nAll events with status \nScheduled\n.\n\n\n\n\n\n\nRecording\n\n\nAll events with status \nRecording\n.\n\n\n\n\n\n\nRunning\n\n\nAll events with status \nRunning\n.\n\n\n\n\n\n\nPaused\n\n\nAll events with status \nPaused\n.\n\n\n\n\n\n\nFailed\n\n\nAll events with status \nFailed\n.\n\n\n\n\n\n\nTodo\n\n\nAll events with status \nFinished\n and open comments.\n\n\n\n\n\n\nFinished\n\n\nAll events with status \nFinished\n.\n\n\n\n\n\n\n\n\nFilters can be added or removed by editing the file \netc/listproviders/adminui.stats.properties\n. For example, the\n\nFinished\n filter is defined as follows:\n\n\nFINISHED=\\\n{\"filters\": [{\"name\": \"status\", \"filter\": \"FILTERS.EVENTS.STATUS.LABEL\", \\\n\"value\": \"EVENTS.EVENTS.STATUS.PROCESSED\"}],\\\n\"description\": \"DASHBOARD.FINISHED\",\\\n\"order\":12}\n\n\n\n\n\nfilters\n defines a list containing at least one filter. Each filter is defined with\n\n\na \nname\n  that defines the event property to filter on for the backend\n\n\na \nfilter\n that defines the event property to filter on for the frontend\n\n\nand the \nvalue\n that property is supposed to have\n\n\n\n\n\n\ndescription\n contains the (possibly translated) description displayed in the UI\n\n\norder\n controls the order the filters are shown in the UI\n\n\n\n\nFilters with relative time spans\n\n\nFor defining filters that contain a relative time span like \nyesterday\n or \nthis week\n \nvalue\n can contain an object\ninstead of a string. This object has to contain a \nrelativeDateSpan\n property which itself contains the fields \nfrom\n,\n\nto\n and \nunit\n. The \nunit\n defines the unit of time that is being considered, e.g. \nhour\n, \nday\n, \nweek\n, \nmonth\n or\n\nyear\n, while \nfrom\n and \nto\n specify the beginning and end of the time span by defining an integer offset relative to\nthe current hour, day, ... depending on the unit. So if the \nunit\n is defined as \nday\n, \n0\n is the current day while\n\n-1\n is yesterday and \n1\n is tomorrow. If the unit is \nweek\n instead, \n0\n is the current week while \n-1\n is the\nlast and \n1\n the next week, and so on.\n\n\nEvery date/time unit below the one defined by \nunit\n depends on whether the offset is defined by \nto\n or \nfrom\n. So if\nthe unit is \nday\n, \nfrom: -1\n would be the beginning of yesterday (so the time is 00:00:00 in the user's timezone)\nwhile \nto: -1\n would be the end of yesterday (23:59:59). If the unit is \nweek\n, \nfrom: -1\n is the beginning of last\nweek (which day is the first day of the week is defined by the user's locale) and \nto: 0\n would be the end of this\nweek, so a filter defined as\n\n\nLAST_TWO_WEEKS=\\\n{\"filters\": [{\"name\": \"startDate\", \"filter\":\"FILTERS.EVENTS.START_DATE\",\n              \"value\": {\"relativeDateSpan\": {\"from\": \"-2\", \"to\": \"0\", \"unit\": \"week\"}}}],\\\n \"description\": \"DATES.LAST_TWO_WEEKS\",\\\n \"order\":15}\n\n\n\nwould cover all events whose start dates occur sometime during the last or current week.\n\n\nThis functionality is implemented with the library \nMoment.js\n by adding the values of \nto\n or\n\nfrom\n to the current date and time while considering the defined unit. A list of valid unit strings can be found in\nthe \ndocumentation\n.\n\n\nTo be considered\n\n\nSince only one unit can be defined per filter, time spans like \nthe beginning of this month until tomorrow\n are\ncurrently not possible.\n\n\nBe advised that a too big amount of filters can lead to filters disappearing from view depending on the width of the\nuser's screen.\n\n\nAvailable Language Configuration\n\n\nThe admin UI is translated into a number of languages by default.  If you wish to restrict the languages available to\nyour users, add the relevant locale code to \netc/org.opencastproject.adminui.endpoint.LanguageServiceEndpoint.cfg\n.\n\n\nConfiguring the events publisher metadata field\n\n\nThe metadata field can be used in two ways, and its meaning varies slightly:\n\n\n\n\nThe publisher is the creator of the event: when an event is created, this field is filled automatically with the\nlogged in user. It cannot be modified on creation of the event nor later.\n\n\nThe publisher is responsible for uploading the content but may not be the creator of the event in the UI:\nin this case, when the event is created, the publisher is selected from a list provider that includes the logged in user\n(selected by default) and it is also modifiable later, but then the logged in user is not selectable.\n\n\n\n\nThe configuration is done in the file: \netc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg\n.\n\n\nFirst option is the default one and the configuration is as follows:\n\n\nproperty.publisher.inputID=publisher\nproperty.publisher.label=EVENTS.EVENTS.DETAILS.METADATA.PUBLISHER\nproperty.publisher.type=text\nproperty.publisher.readOnly=true\nproperty.publisher.required=true\nproperty.publisher.order=16\n\n\n\nTo configure the second option:\n\n\nproperty.publisher.inputID=publisher\nproperty.publisher.label=EVENTS.EVENTS.DETAILS.METADATA.PUBLISHER\nproperty.publisher.type=text\nproperty.publisher.readOnly=false\nproperty.publisher.required=true\nproperty.publisher.listprovider=YOUR_LIST_PROVIDER\nproperty.publisher.order=16\n\n\n\nIf you want to use the publishers as list provider, you must set up the provider in this way:\n\n\nproperty.publisher.listprovider=EVENTS.PUBLISHER\n\n\n\nIn both cases, you can filter events by publisher.",
            "title": "Admin UI Configuration"
        },
        {
            "location": "/configuration/ui/#admin-ui-configuration",
            "text": "",
            "title": "Admin UI Configuration"
        },
        {
            "location": "/configuration/ui/#configuring-the-events-filters",
            "text": "At the top right of the admin UI a set of predefined filters for events are available, displayed with a description and\nthe amount of events currently matching that filter. By default, the following filters are visible:     Statistic  Description      Yesterday  All events with a start date sometime yesterday.    Today  All events with a start date sometime today.    Tomorrow  All events with a start date sometime tomorrow.    Scheduled  All events with status  Scheduled .    Recording  All events with status  Recording .    Running  All events with status  Running .    Paused  All events with status  Paused .    Failed  All events with status  Failed .    Todo  All events with status  Finished  and open comments.    Finished  All events with status  Finished .     Filters can be added or removed by editing the file  etc/listproviders/adminui.stats.properties . For example, the Finished  filter is defined as follows:  FINISHED=\\\n{\"filters\": [{\"name\": \"status\", \"filter\": \"FILTERS.EVENTS.STATUS.LABEL\", \\\n\"value\": \"EVENTS.EVENTS.STATUS.PROCESSED\"}],\\\n\"description\": \"DASHBOARD.FINISHED\",\\\n\"order\":12}   filters  defines a list containing at least one filter. Each filter is defined with  a  name   that defines the event property to filter on for the backend  a  filter  that defines the event property to filter on for the frontend  and the  value  that property is supposed to have    description  contains the (possibly translated) description displayed in the UI  order  controls the order the filters are shown in the UI",
            "title": "Configuring the events filters"
        },
        {
            "location": "/configuration/ui/#filters-with-relative-time-spans",
            "text": "For defining filters that contain a relative time span like  yesterday  or  this week   value  can contain an object\ninstead of a string. This object has to contain a  relativeDateSpan  property which itself contains the fields  from , to  and  unit . The  unit  defines the unit of time that is being considered, e.g.  hour ,  day ,  week ,  month  or year , while  from  and  to  specify the beginning and end of the time span by defining an integer offset relative to\nthe current hour, day, ... depending on the unit. So if the  unit  is defined as  day ,  0  is the current day while -1  is yesterday and  1  is tomorrow. If the unit is  week  instead,  0  is the current week while  -1  is the\nlast and  1  the next week, and so on.  Every date/time unit below the one defined by  unit  depends on whether the offset is defined by  to  or  from . So if\nthe unit is  day ,  from: -1  would be the beginning of yesterday (so the time is 00:00:00 in the user's timezone)\nwhile  to: -1  would be the end of yesterday (23:59:59). If the unit is  week ,  from: -1  is the beginning of last\nweek (which day is the first day of the week is defined by the user's locale) and  to: 0  would be the end of this\nweek, so a filter defined as  LAST_TWO_WEEKS=\\\n{\"filters\": [{\"name\": \"startDate\", \"filter\":\"FILTERS.EVENTS.START_DATE\",\n              \"value\": {\"relativeDateSpan\": {\"from\": \"-2\", \"to\": \"0\", \"unit\": \"week\"}}}],\\\n \"description\": \"DATES.LAST_TWO_WEEKS\",\\\n \"order\":15}  would cover all events whose start dates occur sometime during the last or current week.  This functionality is implemented with the library  Moment.js  by adding the values of  to  or from  to the current date and time while considering the defined unit. A list of valid unit strings can be found in\nthe  documentation .",
            "title": "Filters with relative time spans"
        },
        {
            "location": "/configuration/ui/#to-be-considered",
            "text": "Since only one unit can be defined per filter, time spans like  the beginning of this month until tomorrow  are\ncurrently not possible.  Be advised that a too big amount of filters can lead to filters disappearing from view depending on the width of the\nuser's screen.",
            "title": "To be considered"
        },
        {
            "location": "/configuration/ui/#available-language-configuration",
            "text": "The admin UI is translated into a number of languages by default.  If you wish to restrict the languages available to\nyour users, add the relevant locale code to  etc/org.opencastproject.adminui.endpoint.LanguageServiceEndpoint.cfg .",
            "title": "Available Language Configuration"
        },
        {
            "location": "/configuration/ui/#configuring-the-events-publisher-metadata-field",
            "text": "The metadata field can be used in two ways, and its meaning varies slightly:   The publisher is the creator of the event: when an event is created, this field is filled automatically with the\nlogged in user. It cannot be modified on creation of the event nor later.  The publisher is responsible for uploading the content but may not be the creator of the event in the UI:\nin this case, when the event is created, the publisher is selected from a list provider that includes the logged in user\n(selected by default) and it is also modifiable later, but then the logged in user is not selectable.   The configuration is done in the file:  etc/org.opencastproject.ui.metadata.CatalogUIAdapterFactory-episode-common.cfg .  First option is the default one and the configuration is as follows:  property.publisher.inputID=publisher\nproperty.publisher.label=EVENTS.EVENTS.DETAILS.METADATA.PUBLISHER\nproperty.publisher.type=text\nproperty.publisher.readOnly=true\nproperty.publisher.required=true\nproperty.publisher.order=16  To configure the second option:  property.publisher.inputID=publisher\nproperty.publisher.label=EVENTS.EVENTS.DETAILS.METADATA.PUBLISHER\nproperty.publisher.type=text\nproperty.publisher.readOnly=false\nproperty.publisher.required=true\nproperty.publisher.listprovider=YOUR_LIST_PROVIDER\nproperty.publisher.order=16  If you want to use the publishers as list provider, you must set up the provider in this way:  property.publisher.listprovider=EVENTS.PUBLISHER  In both cases, you can filter events by publisher.",
            "title": "Configuring the events publisher metadata field"
        },
        {
            "location": "/version-support/",
            "text": "Supported Versions\n\n\nOpencast has a standing policy of supporting the current version, and the previous version.  In general terms, this\nmeans a roughly 1 year support cycle for any given release due to our release process (see the development process\ndocumentation for more details).  Support, in this context, means development time; building fixes, applying them, and\nreleasing those changes.  For example, as of the time of writing we currently support versions 6.x, and 5.x.  Once\nversion 7.0 releases version 5.x will no longer be supported, but 6.x will.  This does not mean questions for older\nreleases will not be answered!  Our community has a good track record of addressing issues and answering questions\nregarding older versions as best we can, but developer time will usually not be allocated to fixing additional issues.\n\n\nExtended Support\n\n\nIn rare cases versions may get extended support, meaning new minor releases are provided for more than two years. For\nexample, the 1.6.x versions have been getting new minor releases for almost two years due to community interest and the\nbacking of some developers and institutions. Such extended support requires community members to fund such an effort, or\nprovide additional support time themselves.  If you are in need of extended support we encourage you to reach out to the\ndevelopment community; there may be others in your situation who could share funding, or contractors available to\nprovide this support.",
            "title": "Version Support"
        },
        {
            "location": "/version-support/#supported-versions",
            "text": "Opencast has a standing policy of supporting the current version, and the previous version.  In general terms, this\nmeans a roughly 1 year support cycle for any given release due to our release process (see the development process\ndocumentation for more details).  Support, in this context, means development time; building fixes, applying them, and\nreleasing those changes.  For example, as of the time of writing we currently support versions 6.x, and 5.x.  Once\nversion 7.0 releases version 5.x will no longer be supported, but 6.x will.  This does not mean questions for older\nreleases will not be answered!  Our community has a good track record of addressing issues and answering questions\nregarding older versions as best we can, but developer time will usually not be allocated to fixing additional issues.",
            "title": "Supported Versions"
        },
        {
            "location": "/version-support/#extended-support",
            "text": "In rare cases versions may get extended support, meaning new minor releases are provided for more than two years. For\nexample, the 1.6.x versions have been getting new minor releases for almost two years due to community interest and the\nbacking of some developers and institutions. Such extended support requires community members to fund such an effort, or\nprovide additional support time themselves.  If you are in need of extended support we encourage you to reach out to the\ndevelopment community; there may be others in your situation who could share funding, or contractors available to\nprovide this support.",
            "title": "Extended Support"
        },
        {
            "location": "/modules/",
            "text": "Module Documentation\n\n\nDocumentation for modules included in Opencast.\n\n\n\n\nAtom and RSS Feed\n\n\nAmazon Services\n\n\nAmazon S3 Archive Storage\n\n\nAmazon S3 Distribution\n\n\n\n\n\n\nExecute Service\n\n\nLive  Schedule\n\n\nLTI Module\n\n\nMedia Module\n\n\nPlayer\n\n\nConfiguration\n\n\nURL Parameter\n\n\n\n\n\n\nSearch Index\n\n\nStream Security\n\n\nText Extraction\n\n\nVideoeditor\n\n\nSetup\n\n\nArchitecture\n\n\n\n\n\n\nVideo Segmentation\n\n\nTranscripts (IBM Watson)\n\n\nYouTube Publication",
            "title": "Overview"
        },
        {
            "location": "/modules/#module-documentation",
            "text": "Documentation for modules included in Opencast.   Atom and RSS Feed  Amazon Services  Amazon S3 Archive Storage  Amazon S3 Distribution    Execute Service  Live  Schedule  LTI Module  Media Module  Player  Configuration  URL Parameter    Search Index  Stream Security  Text Extraction  Videoeditor  Setup  Architecture    Video Segmentation  Transcripts (IBM Watson)  YouTube Publication",
            "title": "Module Documentation"
        },
        {
            "location": "/modules/atomrss/",
            "text": "Configure Atom and RSS Feeds\n\n\nThis document will help you understand and configure the Opencast RSS and Atom feed catalog. The catalog supports\nmultiple versions of each syndication format.\n\n\nFeed Catalog\n\n\nThe catalog is located at:\n\n\nhttp://opencast.example.edu:8080/feeds\n\n\n\nIndividual feeds are located at:\n\n\nhttp://opencast.example.edu:8080/feeds/<feed_selector>\n\n\n\nDefaults\n\n\nThe catalog contains the following default feeds:\n\n\nLatest\n\n\nhttp://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/latest\n\n\n\nNeed an example? Visit http://demo.opencastproject.org/feeds/atom/1.0/latest\n\n\nSeries\n\n\nhttp://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/series/<series_id>\n\n\n\nAggregation (of a set of series)\n\n\nhttp://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/aggregated/<name_of_configured_aggregation>\n\n\n\nCustom\n\n\nhttp://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/custom/<query>\n\n\n\nAggregation\n\n\nThe feed allows administrators to pre-configure feeds for specific sets of series. Given the following configuration,\nhttp://opencast.example.edu:8080/feeds/aggregated/myseries would return the latest episodes from series \nseries_1\n and\n\nseries_2\n.\n\n\nThe Opencast feed specifications are located in:\n\n\n.../etc/feeds\n\n\n\nUpdate aggregation.properties, the specification for an example feed aggregation:\n\n\nfeed.selector=myseries\nfeed.series=series_1,series_2\n\n\n\nCustom\n\n\nThe Opencast feed specifications are located in:\n\n\n.../etc/feeds\n\n\n\nBelow is custom.properties, the default specification for an example custom feed of published episodes:\n\n\nfeed.class=org.opencastproject.feed.impl.CustomFeedService\nfeed.uri=custom\nfeed.size=20\nfeed.query=dc_title-sum:{0}\nfeed.name=Special episodes\nfeed.description=Special collection of episodes\nfeed.copyright=All rights reserved by The Opencast Project\nfeed.home=/engage/ui\nfeed.entry=/engage/ui/embed.html?id={0}\nfeed.cover=/engage/feed-cover.png\nfeed.rssflavors=presentation/delivery,presenter/delivery,presenter/feed+preview,presenter/search+preview\nfeed.rsstags=rss\nfeed.rssmediatype=video,audio\nfeed.atomflavors=presentation/delivery,presenter/delivery,presenter/feed+preview,presenter/search+preview\nfeed.atomtags=atom\n\n\n\nProperties\n\n\nThe following properties are common to all feed specifications:\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfeed.class\n\n\nJava implementation, e.g. LatestFeedService.\n\n\n\n\n\n\nfeed.uri\n\n\nFeed location/identifier\n\n\n\n\n\n\nfeed.size\n\n\nMaximum number of entries in the feed (defaul: 100). Set to 0 to include all available entries.\n\n\n\n\n\n\nfeed.selector\n\n\nFeed route pattern, e.g. latest.\n\n\n\n\n\n\nfeed.name\n\n\nFeed title\n\n\n\n\n\n\nfeed.description\n\n\nFeed description\n\n\n\n\n\n\nfeed.copyright\n\n\nFeed copyright notice\n\n\n\n\n\n\nfeed.home\n\n\nFeed catalog homepage, e.g. http://www.opencastproject.org.\n\n\n\n\n\n\nfeed.entry\n\n\nThe route pattern used to generate links to individual enclosures, e.g. /engage/ui/embed.html?id={0}.\n\n\n\n\n\n\nfeed.cover\n\n\nFeed image\n\n\n\n\n\n\nfeed.rssflavors\n\n\nThe RSS enclosure route pattern, e.g. presenter/delivery, selected according to their appearance.\n\n\n\n\n\n\nfeed.rsstags\n\n\nA comma, semi-colon or space-separated list of tags used to filter available enclosures\n\n\n\n\n\n\nfeed.rssmediatype\n\n\nA comma, semi-colon or space-separated list of tags used to decide whether to prefer video or audio enclosures\n\n\n\n\n\n\nfeed.atomflavors\n\n\nThe Atom enclosures route pattern, e.g. presenter/delivery.\n\n\n\n\n\n\nfeed.atomtags\n\n\nA comma, semi-colon or space-separated list of tags used to filter available enclosures\n\n\n\n\n\n\n\n\nThe following properties are specific to custom feeds:\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfeed.query\n\n\nA custom lucene query, matched again Java's MessageFormat using solr.\n\n\n\n\n\n\n\n\nThe query \nhttp://opencast.example.edu:8080/feeds/alphabetical/a\n would return all episodes starting with the letter a.\n\n\nfeed.selector=alphabetical\nfeed.query=dc_title:{0}*",
            "title": "Atom/RSS Feed"
        },
        {
            "location": "/modules/atomrss/#configure-atom-and-rss-feeds",
            "text": "This document will help you understand and configure the Opencast RSS and Atom feed catalog. The catalog supports\nmultiple versions of each syndication format.",
            "title": "Configure Atom and RSS Feeds"
        },
        {
            "location": "/modules/atomrss/#feed-catalog",
            "text": "The catalog is located at:  http://opencast.example.edu:8080/feeds  Individual feeds are located at:  http://opencast.example.edu:8080/feeds/<feed_selector>",
            "title": "Feed Catalog"
        },
        {
            "location": "/modules/atomrss/#defaults",
            "text": "The catalog contains the following default feeds:",
            "title": "Defaults"
        },
        {
            "location": "/modules/atomrss/#latest",
            "text": "http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/latest  Need an example? Visit http://demo.opencastproject.org/feeds/atom/1.0/latest",
            "title": "Latest"
        },
        {
            "location": "/modules/atomrss/#series",
            "text": "http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/series/<series_id>",
            "title": "Series"
        },
        {
            "location": "/modules/atomrss/#aggregation-of-a-set-of-series",
            "text": "http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/aggregated/<name_of_configured_aggregation>",
            "title": "Aggregation (of a set of series)"
        },
        {
            "location": "/modules/atomrss/#custom",
            "text": "http://demo.opencastproject.org/feeds/[atom|rss|*]/<version_number>/custom/<query>",
            "title": "Custom"
        },
        {
            "location": "/modules/atomrss/#aggregation",
            "text": "The feed allows administrators to pre-configure feeds for specific sets of series. Given the following configuration,\nhttp://opencast.example.edu:8080/feeds/aggregated/myseries would return the latest episodes from series  series_1  and series_2 .  The Opencast feed specifications are located in:  .../etc/feeds  Update aggregation.properties, the specification for an example feed aggregation:  feed.selector=myseries\nfeed.series=series_1,series_2",
            "title": "Aggregation"
        },
        {
            "location": "/modules/atomrss/#custom_1",
            "text": "The Opencast feed specifications are located in:  .../etc/feeds  Below is custom.properties, the default specification for an example custom feed of published episodes:  feed.class=org.opencastproject.feed.impl.CustomFeedService\nfeed.uri=custom\nfeed.size=20\nfeed.query=dc_title-sum:{0}\nfeed.name=Special episodes\nfeed.description=Special collection of episodes\nfeed.copyright=All rights reserved by The Opencast Project\nfeed.home=/engage/ui\nfeed.entry=/engage/ui/embed.html?id={0}\nfeed.cover=/engage/feed-cover.png\nfeed.rssflavors=presentation/delivery,presenter/delivery,presenter/feed+preview,presenter/search+preview\nfeed.rsstags=rss\nfeed.rssmediatype=video,audio\nfeed.atomflavors=presentation/delivery,presenter/delivery,presenter/feed+preview,presenter/search+preview\nfeed.atomtags=atom",
            "title": "Custom"
        },
        {
            "location": "/modules/atomrss/#properties",
            "text": "The following properties are common to all feed specifications:     Name  Description      feed.class  Java implementation, e.g. LatestFeedService.    feed.uri  Feed location/identifier    feed.size  Maximum number of entries in the feed (defaul: 100). Set to 0 to include all available entries.    feed.selector  Feed route pattern, e.g. latest.    feed.name  Feed title    feed.description  Feed description    feed.copyright  Feed copyright notice    feed.home  Feed catalog homepage, e.g. http://www.opencastproject.org.    feed.entry  The route pattern used to generate links to individual enclosures, e.g. /engage/ui/embed.html?id={0}.    feed.cover  Feed image    feed.rssflavors  The RSS enclosure route pattern, e.g. presenter/delivery, selected according to their appearance.    feed.rsstags  A comma, semi-colon or space-separated list of tags used to filter available enclosures    feed.rssmediatype  A comma, semi-colon or space-separated list of tags used to decide whether to prefer video or audio enclosures    feed.atomflavors  The Atom enclosures route pattern, e.g. presenter/delivery.    feed.atomtags  A comma, semi-colon or space-separated list of tags used to filter available enclosures     The following properties are specific to custom feeds:     Name  Description      feed.query  A custom lucene query, matched again Java's MessageFormat using solr.     The query  http://opencast.example.edu:8080/feeds/alphabetical/a  would return all episodes starting with the letter a.  feed.selector=alphabetical\nfeed.query=dc_title:{0}*",
            "title": "Properties"
        },
        {
            "location": "/modules/awss3archive/",
            "text": "AWS S3 Archive Configuration\n\n\nThis page documents the configuration for the AWS S3 components in the Opencast module \nasset-manager-storage-aws\n.\nThis configuration is only required on the admin node, and only if you are using Amazon S3 as an archive repository.\n\n\nAmazon User Configuration\n\n\nConfiguration of Amazon users is beyond the scope of this documentation, instead we suggest referring to\n\nAmazon's documentation\n.  You will, however,\nrequire an \nAccess Key ID and Secret Access Key\n.  The user to which\nthis key belongs \nrequires\n the \nAmazonS3FullAccess\n permission, which can be granted using\n\nthese instructions\n.\n\n\nA \nfree Amazon account\n will work for small scale testing, but be aware that S3\narchiving can cost you a lot of money very quickly.  Be aware of how much data and how many requests you are making,\nand be sure to \nset alarms\n to\nnotify you of cost overruns.\n\n\nAmazon Service Configuration\n\n\nThe development and testing it is generally safe to allow the Opencast AWS S3 Archive service to create the S3 bucket\nfor you.  It will create the bucket per its configuration, with private-only access to the files, and no versioning.\n\n\nOpencast Service Configuration\n\n\nThe Opencast AWS S3 Archive service has four configuration keys which can be found in the\n\norg.opencastproject.assetmanager.aws.s3.AwsS3ArchiveElementStore.cfg\n configuration file.\n\n\n\n\n\n\n\n\nKey name\n\n\nValue\n\n\nExample\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.assetmanager.aws.s3.enabled\n\n\nWhether to enable this service\n\n\ntrue\n\n\n\n\n\n\norg.opencastproject.archive.aws.s3.region\n\n\nThe AWS region to set\n\n\nus-west-2\n\n\n\n\n\n\norg.opencastproject.archive.aws.s3.bucket\n\n\nThe S3 bucket name\n\n\nexample-org-archive\n\n\n\n\n\n\norg.opencastproject.archive.aws.s3.access.id\n\n\nYour access ID\n\n\n20 alphanumeric characters\n\n\n\n\n\n\norg.opencastproject.archive.aws.s3.secret.key\n\n\nYour secret key\n\n\n40 characters\n\n\n\n\n\n\n\n\nUsing S3 Archiving\n\n\nThere are two major methods to access S3 archiving features: manually, and via a workflow.  Amazon S3 archiving is not\npart of the default workflows and manual S3 offload is disabled by default.  To enable manual S3 offload you must edit\nthe \noffload.xml\n workflow configuration file and change \nvar s3Enabled = false;\n to \nvar s3Enabled = true;\n.  To\nmanually offload a mediapackage follow the directions in the user documentation.\n\n\nTo automatically offload a mediapackage to S3 you must add the \nmove-storage\n workflow operation to your workflow.\nThe operation documentation can be found \nhere\n.\n\n\nMigrating to S3 Archiving with Pre-Existing Data\n\n\nArchiving to S3 is a non-destructive operation in that it is safe to move archive files back and forth between local\nstorage and S3.  To offload your local archive, select the workflow(s) and follow the manual offload steps described in\nthe user documentation.",
            "title": "Amazon S3 Archive Storage"
        },
        {
            "location": "/modules/awss3archive/#aws-s3-archive-configuration",
            "text": "This page documents the configuration for the AWS S3 components in the Opencast module  asset-manager-storage-aws .\nThis configuration is only required on the admin node, and only if you are using Amazon S3 as an archive repository.",
            "title": "AWS S3 Archive Configuration"
        },
        {
            "location": "/modules/awss3archive/#amazon-user-configuration",
            "text": "Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation .  You will, however,\nrequire an  Access Key ID and Secret Access Key .  The user to which\nthis key belongs  requires  the  AmazonS3FullAccess  permission, which can be granted using these instructions .  A  free Amazon account  will work for small scale testing, but be aware that S3\narchiving can cost you a lot of money very quickly.  Be aware of how much data and how many requests you are making,\nand be sure to  set alarms  to\nnotify you of cost overruns.",
            "title": "Amazon User Configuration"
        },
        {
            "location": "/modules/awss3archive/#amazon-service-configuration",
            "text": "The development and testing it is generally safe to allow the Opencast AWS S3 Archive service to create the S3 bucket\nfor you.  It will create the bucket per its configuration, with private-only access to the files, and no versioning.",
            "title": "Amazon Service Configuration"
        },
        {
            "location": "/modules/awss3archive/#opencast-service-configuration",
            "text": "The Opencast AWS S3 Archive service has four configuration keys which can be found in the org.opencastproject.assetmanager.aws.s3.AwsS3ArchiveElementStore.cfg  configuration file.     Key name  Value  Example      org.opencastproject.assetmanager.aws.s3.enabled  Whether to enable this service  true    org.opencastproject.archive.aws.s3.region  The AWS region to set  us-west-2    org.opencastproject.archive.aws.s3.bucket  The S3 bucket name  example-org-archive    org.opencastproject.archive.aws.s3.access.id  Your access ID  20 alphanumeric characters    org.opencastproject.archive.aws.s3.secret.key  Your secret key  40 characters",
            "title": "Opencast Service Configuration"
        },
        {
            "location": "/modules/awss3archive/#using-s3-archiving",
            "text": "There are two major methods to access S3 archiving features: manually, and via a workflow.  Amazon S3 archiving is not\npart of the default workflows and manual S3 offload is disabled by default.  To enable manual S3 offload you must edit\nthe  offload.xml  workflow configuration file and change  var s3Enabled = false;  to  var s3Enabled = true; .  To\nmanually offload a mediapackage follow the directions in the user documentation.  To automatically offload a mediapackage to S3 you must add the  move-storage  workflow operation to your workflow.\nThe operation documentation can be found  here .",
            "title": "Using S3 Archiving"
        },
        {
            "location": "/modules/awss3archive/#migrating-to-s3-archiving-with-pre-existing-data",
            "text": "Archiving to S3 is a non-destructive operation in that it is safe to move archive files back and forth between local\nstorage and S3.  To offload your local archive, select the workflow(s) and follow the manual offload steps described in\nthe user documentation.",
            "title": "Migrating to S3 Archiving with Pre-Existing Data"
        },
        {
            "location": "/modules/awss3distribution/",
            "text": "AWS S3 Distribution Configuration\n\n\nThis page documents the configuration for Opencast module \ndistribution-service-aws-s3\n.  This\nconfiguration is only required on the presentation node, and only if you are using Amazon S3 and/or Cloudfront for\ndistributing media to end users.\n\n\nAmazon User Configuration\n\n\nConfiguration of Amazon users is beyond the scope of this documentation, instead we suggest referring to\n\nAmazon's documentation\n.\nYou will, however, require to set up proper credentials by either:\n\n\n\n\nCreating an \nAccess Key ID and a Secret Access Key\n or\n\n\nUsing \nInstance Profile Credentials\n\n  (recommended when running Opencast on EC2 instances)\n\n\n\n\nAmazonS3FullAccess\n permission is \nrequired\n, which can be granted using\n\nthese instructions\n.\n\n\nA \nfree Amazon account\n will work for small scale testing, but be aware that S3\ndistribution can cost you a lot of money very quickly.  Be aware of how much data and how many requests you are making,\nand be sure to \nset alarms\n to\nnotify you of cost overruns.\n\n\nAmazon Service Configuration\n\n\nThe development and testing it is generally safe to allow the Opencast AWS S3 Distribution service to create the S3\nbucket for you.  It will create the bucket per its configuration, with public read-only access to the files, and no\nversioning.  For production use we suggest using Amazon CloudFront, which requires additional configuration.\n\n\nAmazon CloudFront\n\n\nAmazon CloudFront provides an \noptional\n way to better handle distributing your media to end users.  While fully\nconfiguring CloudFront is outside the scope of this documentation, we wish to note that this does affect one of the keys\ndescribed below.  Please ensure you use the correct distribution base format depending on which service you are using!\n\n\nOpencast Service Configuration\n\n\nThe Opencast AWS S3 Distribution service has five configuration keys, which can be found in the\n\norg.opencastproject.distribution.aws.s3.AwsS3DistributionServiceImpl.cfg\n configuration file.\n\n\n\n\n\n\n\n\nKey name\n\n\nValue\n\n\nExample\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.distribution.aws.s3.distribution.enable\n\n\nTrue to enable S3 distribution, false otherwise\n\n\ntrue\n\n\n\n\n\n\norg.opencastproject.distribution.aws.s3.region\n\n\nThe AWS region to set\n\n\nus-west-2\n\n\n\n\n\n\norg.opencastproject.distribution.aws.s3.bucket\n\n\nThe S3 bucket name\n\n\nexample-org-dist\n\n\n\n\n\n\norg.opencastproject.distribution.aws.s3.distribution.base\n\n\nWhere the S3 files are available from.  This value can be derived from the bucket and region values, or is set by CloudFront.\n\n\nhttp://s3-us-west-2.amazonaws.com/example-org-dist, or DOMAIN_NAME.cloudfront.net\n\n\n\n\n\n\norg.opencastproject.distribution.aws.s3.access.id\n\n\nYour access ID\n\n\n20 alphanumeric characters\n\n\n\n\n\n\norg.opencastproject.distribution.aws.s3.secret.key\n\n\nYour secret key\n\n\n40 characters\n\n\n\n\n\n\n\n\nIf \norg.opencastproject.distribution.aws.s3.access.id\n and \norg.opencastproject.distribution.aws.s3.secret.key\n are\n not \nexplicitly\n provided, search for credentials will be performed in the order specified by the\n \nDefault Credentials Provider Chain\n.\n\n\nUsing S3 Distribution\n\n\nAmazon S3 distribution is already included in the default Opencast workflows, however it must first be enabled.  The\n\nschedule-and-upload.xml\n and \npublish.xml\n workflow configuration files both contain lines containing the string\n\"Remove this line if you wish to publish to AWS S3\".  Both of these lines must be removed before publishing to AWS S3\nwill function correctly.\n\n\nIf you wish to use AWS S3 publishing with your own custom workflow, you must add the \npublish-aws\n workflow operation to\nyour workflow.  The operation documentation can be found \nhere\n.\n\n\nPublishing to multiple distribution services\n\n\nCurrently we do not support publication to multiple distribution services simultaneously.  This means that whichever\nworkflow operation is \nlast\n in the workflow will be the final publication.\n\n\nUsing this handler in custom workflows\n\n\nIf your workflow contains both \npublish-engage\n and \npublish-aws\n, in that order, and without a\n\nconditional\n you would have publication files stored both locally \nand\n in AWS.  This is\nlikely not what you want, so protect your workflow operations appropriately.  If you really do need these files stored\nin both places (for example, in cases where you need to make the files available immediately, and only push to AWS in\nsome cases) then remember to add a \nretract-engage\n in between the\npublication operations.  Note that if this step is omitted the files will remain available locally, but will not be\nused.  Of further note, if you retract after publication to AWS then your workflow \nwill not be available\n to users.\nTo summarize, this table presents a subset of the various situations that are possible\n\n\n|Workflow Operations|Files present in the Media Module|Files present in AWS|Files served from|\n|publish-engage | Yes | No | Opencast Media Module |\n|publish-aws| No | Yes | AWS |\n|publish-engage, publish-aws| Yes | Yes | AWS |\n|publish-aws, publish-engage| Yes | Yes | Opencast Media Module|\n|publish-engage, retract-engage, publish-aws | Temporary | Yes | AWS |\n|publish-engage, publish-aws, retract-engage | No | Yes | Not available |\n\n\nMigrating to S3 Distribution with Pre-Existing Data\n\n\nIf you already have data published to your local Opencast install, you should be able to republish the media selecting\nAWS S3 as the distribution service to use.",
            "title": "Amazon S3 Distribution"
        },
        {
            "location": "/modules/awss3distribution/#aws-s3-distribution-configuration",
            "text": "This page documents the configuration for Opencast module  distribution-service-aws-s3 .  This\nconfiguration is only required on the presentation node, and only if you are using Amazon S3 and/or Cloudfront for\ndistributing media to end users.",
            "title": "AWS S3 Distribution Configuration"
        },
        {
            "location": "/modules/awss3distribution/#amazon-user-configuration",
            "text": "Configuration of Amazon users is beyond the scope of this documentation, instead we suggest referring to Amazon's documentation .\nYou will, however, require to set up proper credentials by either:   Creating an  Access Key ID and a Secret Access Key  or  Using  Instance Profile Credentials \n  (recommended when running Opencast on EC2 instances)   AmazonS3FullAccess  permission is  required , which can be granted using these instructions .  A  free Amazon account  will work for small scale testing, but be aware that S3\ndistribution can cost you a lot of money very quickly.  Be aware of how much data and how many requests you are making,\nand be sure to  set alarms  to\nnotify you of cost overruns.",
            "title": "Amazon User Configuration"
        },
        {
            "location": "/modules/awss3distribution/#amazon-service-configuration",
            "text": "The development and testing it is generally safe to allow the Opencast AWS S3 Distribution service to create the S3\nbucket for you.  It will create the bucket per its configuration, with public read-only access to the files, and no\nversioning.  For production use we suggest using Amazon CloudFront, which requires additional configuration.",
            "title": "Amazon Service Configuration"
        },
        {
            "location": "/modules/awss3distribution/#amazon-cloudfront",
            "text": "Amazon CloudFront provides an  optional  way to better handle distributing your media to end users.  While fully\nconfiguring CloudFront is outside the scope of this documentation, we wish to note that this does affect one of the keys\ndescribed below.  Please ensure you use the correct distribution base format depending on which service you are using!",
            "title": "Amazon CloudFront"
        },
        {
            "location": "/modules/awss3distribution/#opencast-service-configuration",
            "text": "The Opencast AWS S3 Distribution service has five configuration keys, which can be found in the org.opencastproject.distribution.aws.s3.AwsS3DistributionServiceImpl.cfg  configuration file.     Key name  Value  Example      org.opencastproject.distribution.aws.s3.distribution.enable  True to enable S3 distribution, false otherwise  true    org.opencastproject.distribution.aws.s3.region  The AWS region to set  us-west-2    org.opencastproject.distribution.aws.s3.bucket  The S3 bucket name  example-org-dist    org.opencastproject.distribution.aws.s3.distribution.base  Where the S3 files are available from.  This value can be derived from the bucket and region values, or is set by CloudFront.  http://s3-us-west-2.amazonaws.com/example-org-dist, or DOMAIN_NAME.cloudfront.net    org.opencastproject.distribution.aws.s3.access.id  Your access ID  20 alphanumeric characters    org.opencastproject.distribution.aws.s3.secret.key  Your secret key  40 characters     If  org.opencastproject.distribution.aws.s3.access.id  and  org.opencastproject.distribution.aws.s3.secret.key  are\n not  explicitly  provided, search for credentials will be performed in the order specified by the\n  Default Credentials Provider Chain .",
            "title": "Opencast Service Configuration"
        },
        {
            "location": "/modules/awss3distribution/#using-s3-distribution",
            "text": "Amazon S3 distribution is already included in the default Opencast workflows, however it must first be enabled.  The schedule-and-upload.xml  and  publish.xml  workflow configuration files both contain lines containing the string\n\"Remove this line if you wish to publish to AWS S3\".  Both of these lines must be removed before publishing to AWS S3\nwill function correctly.  If you wish to use AWS S3 publishing with your own custom workflow, you must add the  publish-aws  workflow operation to\nyour workflow.  The operation documentation can be found  here .",
            "title": "Using S3 Distribution"
        },
        {
            "location": "/modules/awss3distribution/#publishing-to-multiple-distribution-services",
            "text": "Currently we do not support publication to multiple distribution services simultaneously.  This means that whichever\nworkflow operation is  last  in the workflow will be the final publication.",
            "title": "Publishing to multiple distribution services"
        },
        {
            "location": "/modules/awss3distribution/#using-this-handler-in-custom-workflows",
            "text": "If your workflow contains both  publish-engage  and  publish-aws , in that order, and without a conditional  you would have publication files stored both locally  and  in AWS.  This is\nlikely not what you want, so protect your workflow operations appropriately.  If you really do need these files stored\nin both places (for example, in cases where you need to make the files available immediately, and only push to AWS in\nsome cases) then remember to add a  retract-engage  in between the\npublication operations.  Note that if this step is omitted the files will remain available locally, but will not be\nused.  Of further note, if you retract after publication to AWS then your workflow  will not be available  to users.\nTo summarize, this table presents a subset of the various situations that are possible  |Workflow Operations|Files present in the Media Module|Files present in AWS|Files served from|\n|publish-engage | Yes | No | Opencast Media Module |\n|publish-aws| No | Yes | AWS |\n|publish-engage, publish-aws| Yes | Yes | AWS |\n|publish-aws, publish-engage| Yes | Yes | Opencast Media Module|\n|publish-engage, retract-engage, publish-aws | Temporary | Yes | AWS |\n|publish-engage, publish-aws, retract-engage | No | Yes | Not available |",
            "title": "Using this handler in custom workflows"
        },
        {
            "location": "/modules/awss3distribution/#migrating-to-s3-distribution-with-pre-existing-data",
            "text": "If you already have data published to your local Opencast install, you should be able to republish the media selecting\nAWS S3 as the distribution service to use.",
            "title": "Migrating to S3 Distribution with Pre-Existing Data"
        },
        {
            "location": "/modules/execute/",
            "text": "Execute Service\n\n\nThe Execute Service allows a workflow to run external scripts or applications with any MediaPackage element as arguments.\nThis provides a flexible way to operate with MediaPackage resources without the need to write Java code or build Opencast\nfrom source. Commands are executed on worker nodes.\n\n\nThere are two execute workflow operations:\n\n\n\n\nExecute Once\n: for running a single command\n   that may operate on multiple elements of a mediapackage\n\n\nExecute Many\n: for running a command\n   for each element in a mediapackage that matches the given criteria\n\n\n\n\nService Configuration\n\n\nThe Execute Service configuration in \norg.opencastproject.execute.impl.ExecuteServiceImpl.cfg\n must be updated to\ndefine which commands may be run:\n\n\n# Load factor\njob.load.execute = 1.0\n\n# The list of commands, separated by spaces, which may be run by the Execute Service.\n# A value of * means any command is allowed.\n# Default: empty (no commands allowed)\n#commands.allowed =\n\n\n\n\nIf \ncommands.allowed\n is empty or undefined (the default), the service won't be able to run any commands.\nUse the special key \n*\n to permit any command to be executed (not recommended for production systems).\n\n\nTo adjust the job load factor for a command, use the \nload\n parameter in the workflow operation rather than\nadjusting the \njob.load.execute\n parameter above.\n\n\nParameter substitution\n\n\nThe command arguments may contain placeholders, which are substituted by their corresponding values before\nthe command runs. The complete list of available placeholders is detailed in the table below.\n\n\n\n\n\n\n\n\nPlaceholder\n\n\nUsed in\n\n\nMeaning\n\n\n\n\n\n\n\n\n\n\n#{id}\n\n\nExecute Once\n\n\nThe Mediapackage ID\n\n\n\n\n\n\n#{flavor(some/flavor)}\n\n\nExecute Once\n\n\nThe absolute path of the element matching the specified flavor. If several elements have the same flavor, the first element returned by MediaPackage#getElementsByFlavor is used.\n\n\n\n\n\n\n#{in}\n\n\nExecute Many\n\n\nThe absolute path of the input element\n\n\n\n\n\n\n#{out}\n\n\nExecute Once, Execute Many\n\n\nThe absolute path of the output element, formed from the output-filename parameter\n\n\n\n\n\n\n\n\nUsing custom properties in the argument list\n\n\nCustom properties can be included in the command line by using the syntax \n#{name}\n, where name is the variable name,\nas defined in the Execute Service's configuration file or in the global configuration file \ncustom.properties\n.\n\n\nThe substitution will be done in the following order of precedence:\n\n\n\n\nPlaceholders defined in the table above.\n\n\nConfiguration keys defined in \norg.opencastproject.execute.impl.ExecuteServiceImpl.cfg\n.\n\n\nConfiguration keys defined in \ncustom.properties\n.\n\n\n\n\nFor instance, suppose you use the Execute Service with the following arguments:\n\n\n\"John Doe\" xyz #{my.property}\n\n\n\nthe command run will receive that argument list as-is, because my.property is not a valid placeholder, nor\nis it defined in the Execute Service's configuration file or \ncustom.properties\n.\n\n\nHowever, if you define my.property in \ncustom.properties\n:\n\n\nmy.property = foo\n\n\n\nthen the command will get the following argument list:\n\n\n\"John Doe\" xyz foo\n\n\n\nIf you define the same variable in the Execute Service's configuration file (regardless of whether the variable\nis defined in \ncustom.properties\n or not):\n\n\nmy.property = bar\n\n\n\nthen the actual argument list will be:\n\n\n\"John Doe\" xyz bar\n\n\n\nExecuting commands in workflows\n\n\nFor more information on how to execute a command in a workflow, see:\n\n\n\n\nExecute Once Workflow Operation\n\n\nExecute Many Workflow Operation",
            "title": "Execute Service"
        },
        {
            "location": "/modules/execute/#execute-service",
            "text": "The Execute Service allows a workflow to run external scripts or applications with any MediaPackage element as arguments.\nThis provides a flexible way to operate with MediaPackage resources without the need to write Java code or build Opencast\nfrom source. Commands are executed on worker nodes.  There are two execute workflow operations:   Execute Once : for running a single command\n   that may operate on multiple elements of a mediapackage  Execute Many : for running a command\n   for each element in a mediapackage that matches the given criteria",
            "title": "Execute Service"
        },
        {
            "location": "/modules/execute/#service-configuration",
            "text": "The Execute Service configuration in  org.opencastproject.execute.impl.ExecuteServiceImpl.cfg  must be updated to\ndefine which commands may be run:  # Load factor\njob.load.execute = 1.0\n\n# The list of commands, separated by spaces, which may be run by the Execute Service.\n# A value of * means any command is allowed.\n# Default: empty (no commands allowed)\n#commands.allowed =  If  commands.allowed  is empty or undefined (the default), the service won't be able to run any commands.\nUse the special key  *  to permit any command to be executed (not recommended for production systems).  To adjust the job load factor for a command, use the  load  parameter in the workflow operation rather than\nadjusting the  job.load.execute  parameter above.",
            "title": "Service Configuration"
        },
        {
            "location": "/modules/execute/#parameter-substitution",
            "text": "The command arguments may contain placeholders, which are substituted by their corresponding values before\nthe command runs. The complete list of available placeholders is detailed in the table below.     Placeholder  Used in  Meaning      #{id}  Execute Once  The Mediapackage ID    #{flavor(some/flavor)}  Execute Once  The absolute path of the element matching the specified flavor. If several elements have the same flavor, the first element returned by MediaPackage#getElementsByFlavor is used.    #{in}  Execute Many  The absolute path of the input element    #{out}  Execute Once, Execute Many  The absolute path of the output element, formed from the output-filename parameter",
            "title": "Parameter substitution"
        },
        {
            "location": "/modules/execute/#using-custom-properties-in-the-argument-list",
            "text": "Custom properties can be included in the command line by using the syntax  #{name} , where name is the variable name,\nas defined in the Execute Service's configuration file or in the global configuration file  custom.properties .  The substitution will be done in the following order of precedence:   Placeholders defined in the table above.  Configuration keys defined in  org.opencastproject.execute.impl.ExecuteServiceImpl.cfg .  Configuration keys defined in  custom.properties .   For instance, suppose you use the Execute Service with the following arguments:  \"John Doe\" xyz #{my.property}  the command run will receive that argument list as-is, because my.property is not a valid placeholder, nor\nis it defined in the Execute Service's configuration file or  custom.properties .  However, if you define my.property in  custom.properties :  my.property = foo  then the command will get the following argument list:  \"John Doe\" xyz foo  If you define the same variable in the Execute Service's configuration file (regardless of whether the variable\nis defined in  custom.properties  or not):  my.property = bar  then the actual argument list will be:  \"John Doe\" xyz bar",
            "title": "Using custom properties in the argument list"
        },
        {
            "location": "/modules/execute/#executing-commands-in-workflows",
            "text": "For more information on how to execute a command in a workflow, see:   Execute Once Workflow Operation  Execute Many Workflow Operation",
            "title": "Executing commands in workflows"
        },
        {
            "location": "/modules/liveschedule/",
            "text": "Live Schedule Service\n\n\nOverview\n\n\nThe Live Schedule Service manages a live event in the Search index on the engage server.\n\n\nWhen an event is scheduled and the publishLive configuration is set, a live media package is published to the Search\nindex. The live media package contains track(s) with live streaming urls.\n\n\nThe live media package is retracted from the Search index when the capture finishes or if it fails.\n\n\nIf event metadata, such as title or duration, are updated, the live media package in the Search index is updated\naccordingly.\n\n\nPre-requisites\n\n\nTo use this service, you need to have:\n\n\n\n\nA streaming server (Wowza, Adobe Media Server) or CDN already set up to stream live content\n\n\nA capture agent capable of streaming to it\n\n\nA player capable of playing live streams. The Paella player using the Flash component supports the rtmp protocol.\n   Other players/protocols have not been tested.\n\n\n\n\nConfiguration\n\n\nStep 1: Configure the service\n\n\nEdit  \netc/org.opencastproject.liveschedule.impl.LiveScheduleServiceImpl.cfg\n.\n\n\nIf your capture agent does not register a \ncapture.device.live.resolution.WIDTHxHEIGHT\n property, it's mandatory to\nconfigure the \nlive.streamingUrl\n.\n\n\nThe \nlive.streamingUrl\n should be set to your streaming server url (or the subscriber url specified by your CDN).\n\n\nThis is the url that the player will use to play the live stream. For instance, if using rtmp, set it to something like:\nrtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION/\n\n\n# Configuration for the Live Schedule Service\n\n#\n# If the capture agent doesn't register the capture.device.live.resolution.WIDTHxHEIGHT property,\n# specify live.streamingUrl, live.resolution, and live.streamName below:\n#\n# -----------------------------\n\n# The streaming base url e.g. rtmp://streaming.server/live/\n#live.streamingUrl=rtmp://streaming.server/live\n\n# If a comma-separated list is provided, several resolutions will be generated for each flavor\nlive.resolution=1920x540,960x270\n\n# Possible variable substitutions:\n# #{id} = media package id\n# #{flavor} = type-subtype of flavor\n# #{caName} = capture agent name\n# #{resolution} = video resolution e.g. 1920x1080\n#live.streamName=#{id}-#{flavor}.stream\nlive.streamName=#{caName}-#{flavor}.stream-#{resolution}\n\n# -----------------------------\n\n# The same mime-type applies to all flavors and resolutions\nlive.mimeType=video/x-flv\n\n# If a comma-separated list is provided, several streams links will be generated, one for each\n# resolution-targetFlavor combination.\n# Default is presenter/delivery\n#live.targetFlavors=presenter/delivery\n\n# The distribution service to use: download or aws.s3\nlive.distributionService=download\n\n\n\n\nStep 2: Configure the capture agent\n\n\nCapture agent does not register the \ncapture.device.live.resolution.WIDTHxHEIGHT\n property\n\n\nConfigure the capture agent to stream to your streaming server (or the publisher url specified by your CDN), using the\nsame stream name specified in live.streamName.\n\n\nCapture agent registers the \ncapture.device.live.resolution.WIDTHxHEIGHT\n property\n\n\nIf your capture agent supports configuring custom capture agent properties, instead of configuring the\nlive.streamingUrl, live.resolution, live.streamName, you can update the capture agent firmware to pass the following\nwhen registering to Opencast:\n\n\n\n\ncapture.device.names: add 'live' to the current list of devices\n\n\ncapture.device.live.resolution.WIDTHxHEIGHT=STREAMING_URL_USED_BY_PLAYER: one for each desired stream\n\n\n\n\nThen, the LiveScheduleService will generate as many live tracks as the resolutions registered, with their streaming\nurls, using 'presenter/delivery' (or the flavor configured, but only one flavor can be used).\n\n\nIf a property capture.device.live.resolution.WIDTHxHEIGHT was registered, it will take precedence over the\nLiveScheduleService configuration.\n\n\nExample 1:\n\n\nCapture agent does not register with capture.device.live.resolution.WIDTHxHEIGHT\n\n\nIf:\n\n\n\n\nlive.streamingUrl=rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION\n\n\nlive.streamName=#{caName}-#{flavor}.stream\n\n\nlive.targetFlavors=presenter/delivery\n\n\ncapture agent name: ca01\n\n\n\n\nThen, the capture agent should stream to ('/' is replaced by '-'):\nrtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION/ca01-presenter-delivery.stream\n\n\nNote: Please refer to your streaming server or CDN documentation for the correct syntax of the streaming url. The\n\nlive.streamingUrl\n may be very different from the url the capture agent streams to. For instance, with Akamai, the url\nused by the player will be something like live.streamingUrl=rtmp://xyz.live.edgefcs.net/live/ and the capture agent's\npublish url something like rtmp://a.bcd.e.akamaientrypoint.net/EntryPoint. The stream name should always match.\n\n\nExample 2:\n\n\nCapture agent registers with capture.device.live.resolution.WIDTHxHEIGHT\n\n\nIf the capture agent registers itself with:\n\n\n\n\n\n\n\n\nproperty  key\n\n\nvalue\n\n\n\n\n\n\n\n\n\n\ncapture.device.names\n\n\npresentation,presenter,live\n\n\n\n\n\n\ncapture.device.presentation.flavor\n\n\npresentation/source\n\n\n\n\n\n\ncapture.device.presenter.flavor\n\n\npresenter/source\n\n\n\n\n\n\ncapture.device.live.resolution.1920x540\n\n\nrtmp://xyz.live.edgefcs.net/live/presenter.stream-1920x540@12345\n\n\n\n\n\n\ncapture.device.live.resolution.960x270\n\n\nrtmp://xyz.live.edgefcs.net/live/presenter.stream-960x270@12345\n\n\n\n\n\n\n\n\nThe LiveScheduleService will generate a media package with two live tracks having the following urls:\n\n\n\n\nrtmp://xyz.live.edgefcs.net/live/presenter.stream-1920x540@12345\n\n\nrtmp://xyz.live.edgefcs.net/live/presenter.stream-960x270@12345\n\n\n\n\nStep 3: Configure the Workflow\n\n\nWhen scheduling a live event via the admin UI, the workflow needs to have the \npublishLive\n configuration set to true\n(this is already included in the sample workflows).\nIf not using the sample Opencast workflows, add to the \n<configuration_panel>\n:\n\n\n        <fieldset>\n          <legend>Publish live stream:</legend>\n          <ul>\n            <li>\n              <input id=\"publishLive\" name=\"publishLive\" type=\"checkbox\" class=\"configField\" value=\"false\" />\n              <label for=\"publishLive\">Add live event to Opencast Media Module</label>\n            </li>\n          </ul>\n        </fieldset>\n\n\n\n\nAnd to the \ndefaults\n operation:\n\n\n    <operation\n      id=\"defaults\"\n      description=\"Applying default configuration values\">\n      <configurations>\n        <configuration key=\"comment\">false</configuration>\n        <configuration key=\"publishToMediaModule\">true</configuration>\n        <configuration key=\"publishToOaiPmh\">true</configuration>\n        <configuration key=\"uploadedSearchPreview\">false</configuration>\n        <configuration key=\"publishLive\">false</configuration>\n      </configurations>\n    </operation>",
            "title": "Live Schedule"
        },
        {
            "location": "/modules/liveschedule/#live-schedule-service",
            "text": "",
            "title": "Live Schedule Service"
        },
        {
            "location": "/modules/liveschedule/#overview",
            "text": "The Live Schedule Service manages a live event in the Search index on the engage server.  When an event is scheduled and the publishLive configuration is set, a live media package is published to the Search\nindex. The live media package contains track(s) with live streaming urls.  The live media package is retracted from the Search index when the capture finishes or if it fails.  If event metadata, such as title or duration, are updated, the live media package in the Search index is updated\naccordingly.",
            "title": "Overview"
        },
        {
            "location": "/modules/liveschedule/#pre-requisites",
            "text": "To use this service, you need to have:   A streaming server (Wowza, Adobe Media Server) or CDN already set up to stream live content  A capture agent capable of streaming to it  A player capable of playing live streams. The Paella player using the Flash component supports the rtmp protocol.\n   Other players/protocols have not been tested.",
            "title": "Pre-requisites"
        },
        {
            "location": "/modules/liveschedule/#configuration",
            "text": "",
            "title": "Configuration"
        },
        {
            "location": "/modules/liveschedule/#step-1-configure-the-service",
            "text": "Edit   etc/org.opencastproject.liveschedule.impl.LiveScheduleServiceImpl.cfg .  If your capture agent does not register a  capture.device.live.resolution.WIDTHxHEIGHT  property, it's mandatory to\nconfigure the  live.streamingUrl .  The  live.streamingUrl  should be set to your streaming server url (or the subscriber url specified by your CDN).  This is the url that the player will use to play the live stream. For instance, if using rtmp, set it to something like:\nrtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION/  # Configuration for the Live Schedule Service\n\n#\n# If the capture agent doesn't register the capture.device.live.resolution.WIDTHxHEIGHT property,\n# specify live.streamingUrl, live.resolution, and live.streamName below:\n#\n# -----------------------------\n\n# The streaming base url e.g. rtmp://streaming.server/live/\n#live.streamingUrl=rtmp://streaming.server/live\n\n# If a comma-separated list is provided, several resolutions will be generated for each flavor\nlive.resolution=1920x540,960x270\n\n# Possible variable substitutions:\n# #{id} = media package id\n# #{flavor} = type-subtype of flavor\n# #{caName} = capture agent name\n# #{resolution} = video resolution e.g. 1920x1080\n#live.streamName=#{id}-#{flavor}.stream\nlive.streamName=#{caName}-#{flavor}.stream-#{resolution}\n\n# -----------------------------\n\n# The same mime-type applies to all flavors and resolutions\nlive.mimeType=video/x-flv\n\n# If a comma-separated list is provided, several streams links will be generated, one for each\n# resolution-targetFlavor combination.\n# Default is presenter/delivery\n#live.targetFlavors=presenter/delivery\n\n# The distribution service to use: download or aws.s3\nlive.distributionService=download",
            "title": "Step 1: Configure the service"
        },
        {
            "location": "/modules/liveschedule/#step-2-configure-the-capture-agent",
            "text": "",
            "title": "Step 2: Configure the capture agent"
        },
        {
            "location": "/modules/liveschedule/#capture-agent-does-not-register-the-capturedeviceliveresolutionwidthxheight-property",
            "text": "Configure the capture agent to stream to your streaming server (or the publisher url specified by your CDN), using the\nsame stream name specified in live.streamName.",
            "title": "Capture agent does not register the capture.device.live.resolution.WIDTHxHEIGHT property"
        },
        {
            "location": "/modules/liveschedule/#capture-agent-registers-the-capturedeviceliveresolutionwidthxheight-property",
            "text": "If your capture agent supports configuring custom capture agent properties, instead of configuring the\nlive.streamingUrl, live.resolution, live.streamName, you can update the capture agent firmware to pass the following\nwhen registering to Opencast:   capture.device.names: add 'live' to the current list of devices  capture.device.live.resolution.WIDTHxHEIGHT=STREAMING_URL_USED_BY_PLAYER: one for each desired stream   Then, the LiveScheduleService will generate as many live tracks as the resolutions registered, with their streaming\nurls, using 'presenter/delivery' (or the flavor configured, but only one flavor can be used).  If a property capture.device.live.resolution.WIDTHxHEIGHT was registered, it will take precedence over the\nLiveScheduleService configuration.",
            "title": "Capture agent registers the capture.device.live.resolution.WIDTHxHEIGHT property"
        },
        {
            "location": "/modules/liveschedule/#example-1",
            "text": "",
            "title": "Example 1:"
        },
        {
            "location": "/modules/liveschedule/#capture-agent-does-not-register-with-capturedeviceliveresolutionwidthxheight",
            "text": "If:   live.streamingUrl=rtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION  live.streamName=#{caName}-#{flavor}.stream  live.targetFlavors=presenter/delivery  capture agent name: ca01   Then, the capture agent should stream to ('/' is replaced by '-'):\nrtmp://STREAMING_SERVER_HOST:PORT/STREAMING_APPLICATION/ca01-presenter-delivery.stream  Note: Please refer to your streaming server or CDN documentation for the correct syntax of the streaming url. The live.streamingUrl  may be very different from the url the capture agent streams to. For instance, with Akamai, the url\nused by the player will be something like live.streamingUrl=rtmp://xyz.live.edgefcs.net/live/ and the capture agent's\npublish url something like rtmp://a.bcd.e.akamaientrypoint.net/EntryPoint. The stream name should always match.",
            "title": "Capture agent does not register with capture.device.live.resolution.WIDTHxHEIGHT"
        },
        {
            "location": "/modules/liveschedule/#example-2",
            "text": "",
            "title": "Example 2:"
        },
        {
            "location": "/modules/liveschedule/#capture-agent-registers-with-capturedeviceliveresolutionwidthxheight",
            "text": "If the capture agent registers itself with:     property  key  value      capture.device.names  presentation,presenter,live    capture.device.presentation.flavor  presentation/source    capture.device.presenter.flavor  presenter/source    capture.device.live.resolution.1920x540  rtmp://xyz.live.edgefcs.net/live/presenter.stream-1920x540@12345    capture.device.live.resolution.960x270  rtmp://xyz.live.edgefcs.net/live/presenter.stream-960x270@12345     The LiveScheduleService will generate a media package with two live tracks having the following urls:   rtmp://xyz.live.edgefcs.net/live/presenter.stream-1920x540@12345  rtmp://xyz.live.edgefcs.net/live/presenter.stream-960x270@12345",
            "title": "Capture agent registers with capture.device.live.resolution.WIDTHxHEIGHT"
        },
        {
            "location": "/modules/liveschedule/#step-3-configure-the-workflow",
            "text": "When scheduling a live event via the admin UI, the workflow needs to have the  publishLive  configuration set to true\n(this is already included in the sample workflows).\nIf not using the sample Opencast workflows, add to the  <configuration_panel> :          <fieldset>\n          <legend>Publish live stream:</legend>\n          <ul>\n            <li>\n              <input id=\"publishLive\" name=\"publishLive\" type=\"checkbox\" class=\"configField\" value=\"false\" />\n              <label for=\"publishLive\">Add live event to Opencast Media Module</label>\n            </li>\n          </ul>\n        </fieldset>  And to the  defaults  operation:      <operation\n      id=\"defaults\"\n      description=\"Applying default configuration values\">\n      <configurations>\n        <configuration key=\"comment\">false</configuration>\n        <configuration key=\"publishToMediaModule\">true</configuration>\n        <configuration key=\"publishToOaiPmh\">true</configuration>\n        <configuration key=\"uploadedSearchPreview\">false</configuration>\n        <configuration key=\"publishLive\">false</configuration>\n      </configurations>\n    </operation>",
            "title": "Step 3: Configure the Workflow"
        },
        {
            "location": "/modules/ltimodule/",
            "text": "Integrating Opencast in an LMS using LTI\n\n\nWhat it does\n\n\nThe Opencast LTI module provides an easy way to integrate Opencast into a Learning Management System (LMS),\nor any other system which supports the LTI standard as an LTI \ntool consumer\n.\n\n\nTypically, students enrolled in a course access Opencast through an LTI tool in the LMS course site,\nand can play back videos in an Opencast series set up for the course.\n\n\nMore information about the LTI specifications is available at\n\nIMS Learning Tools Interoperability\n.\n\n\nConfigure Opencast\n\n\nConfigure OAuth authentication\n\n\nLTI uses OAuth to authenticate users. To enable OAuth in Opencast, edit \nOPENCAST/etc/security/mh_default_org.xml\n and\nuncomment the oAuthProtectedResourceFilter in the Authentication Filters section:\n\n\n    <!-- 2-legged OAuth is used by trusted 3rd party applications, including LTI. -->\n    <!-- Uncomment the line below to support LTI or other OAuth clients.          -->\n    <ref bean=\"oauthProtectedResourceFilter\" />\n\n\n\n\nTo configure OAuth consumers (e.g. a LMS), edit\n\nOPENCAST/etc/org.opencastproject.kernel.security.OAuthConsumerDetailsService.cfg\n and replace CONSUMERNAME,\nCONSUMERKEY, and CONSUMERSECRET with the values you will use in your LMS:\n\n\noauth.consumer.name.1=CONSUMERNAME\noauth.consumer.key.1=CONSUMERKEY\noauth.consumer.secret.1=CONSUMERSECRET\n\n\n\n\nConfigure LTI (optional)\n\n\nTo give LMS users the same username in Opencast as the LMS username, edit\n\netc/org.opencastproject.kernel.security.LtiLaunchAuthenticationHandler.cfg\n and add the configured OAuth consumer key\nto the list of highly trusted keys.\n\n\nlti.oauth.highly_trusted_consumer_key.1=CONSUMERKEY\n\n\n\n\nUse can exempt specific users even if a highly trusted consumer is used by configuring a blacklist. Additionally, there\nare settings for excluding the system administrator as well as the digest user (enabled by default).\n\n\nlti.allow_system_administrator=false\nlti.allow_digest_user=false\nlti.blacklist.user.1=myAdminUser\n\n\n\n\n\n\nNotice:\n Marking a consumer key as highly trusted can be a security risk! If the usernames of sensitive Opencast\nusers are not blacklisted, the LMS administrator could create LMS users with the same username and use LTI to grant\nthat user access to Opencast. In the default configuration, that includes the \nadmin\n and \nopencast_system_account\n\nusers.\n\n\n\n\nConfigure and test an LTI tool in the LMS\n\n\nConfigure an LTI tool in the LMS with these values:\n\n\n\n\nLTI launch URL: \nOPENCAST-URL/lti\n\n\nLTI key: the value chosen for CONSUMERKEY in \norg.opencastproject.kernel.security.OAuthConsumerDetailsService.cfg\n\n\nLTI secret: the value chosen for CONSUMERSECRET in \norg.opencastproject.kernel.security.OAuthConsumerDetailsService.cfg\n\n\n\n\nIn a clustered Opencast system, choose the URL of the presentation server where the media module and player are available.\n\n\nAccess the LTI tool configured for Opencast in the LMS. The Opencast LTI Welcome page should appear. Click on the links\nprovided to \nOPENCAST-URL/lti\n and \nOPENCAST-URL/info/me.json\n to verify the LTI parameters provided to Opencast by the LMS,\nand the list of roles which the LTI user has in Opencast.\n\n\nLTI roles\n\n\nLTI users will only see Opencast series and videos which are public, or those to which they have access\nbecause of the Opencast roles which they have. The Opencast LTI module grants an LTI user the role(s) formed\nfrom the LTI parameters \ncontext_id\n and \nroles\n.\n\n\nThe LTI context is typically the LMS course ID, and the default LTI role for a student in a course is \nLearner\n.\nThe Opencast role granted would therefore be \nSITEID_Learner\n.\n\n\nTo make a series or video visible to students who access Opencast through LTI in an LMS course,\nadd the role \nSITEID_Learner\n to the Series or Event Access Control List (ACL).\n\n\nLTI users may also have additional roles if the LTI user is created as an Opencast user in the Admin UI and\ngiven additional roles, or if one or more Opencast User Providers or Role Providers are configured.\n\n\nCustomize the LTI tool in the LMS\n\n\nOpencast will redirect an LTI user to the URL specified by the LTI custom \ntool\n parameter. Some LMS systems allow\ncustom parameters to be defined separately in each place where an LTI tool is used, whereas other systems only allow\ncustom parameters to be defined globally.\n\n\n\n\nTo show the Opencast Media Module, use \ntool=engage/ui/\n\n\nTo show all videos for a single series, use \ntool=ltitools/series/index.html;series=SERIESID\n\n\nTo show a single video, use \ntool=engage/theodul/ui/core.html;id=MEDIAPACKAGEID\n\n\nTo show a short debugging page before proceeding to the tool page, add the parameter \ntest=true\n\n\n\n\nFor more information about how to set custom LTI parameters, please check the documentation of your LMS.",
            "title": "LTI Module"
        },
        {
            "location": "/modules/ltimodule/#integrating-opencast-in-an-lms-using-lti",
            "text": "",
            "title": "Integrating Opencast in an LMS using LTI"
        },
        {
            "location": "/modules/ltimodule/#what-it-does",
            "text": "The Opencast LTI module provides an easy way to integrate Opencast into a Learning Management System (LMS),\nor any other system which supports the LTI standard as an LTI  tool consumer .  Typically, students enrolled in a course access Opencast through an LTI tool in the LMS course site,\nand can play back videos in an Opencast series set up for the course.  More information about the LTI specifications is available at IMS Learning Tools Interoperability .",
            "title": "What it does"
        },
        {
            "location": "/modules/ltimodule/#configure-opencast",
            "text": "",
            "title": "Configure Opencast"
        },
        {
            "location": "/modules/ltimodule/#configure-oauth-authentication",
            "text": "LTI uses OAuth to authenticate users. To enable OAuth in Opencast, edit  OPENCAST/etc/security/mh_default_org.xml  and\nuncomment the oAuthProtectedResourceFilter in the Authentication Filters section:      <!-- 2-legged OAuth is used by trusted 3rd party applications, including LTI. -->\n    <!-- Uncomment the line below to support LTI or other OAuth clients.          -->\n    <ref bean=\"oauthProtectedResourceFilter\" />  To configure OAuth consumers (e.g. a LMS), edit OPENCAST/etc/org.opencastproject.kernel.security.OAuthConsumerDetailsService.cfg  and replace CONSUMERNAME,\nCONSUMERKEY, and CONSUMERSECRET with the values you will use in your LMS:  oauth.consumer.name.1=CONSUMERNAME\noauth.consumer.key.1=CONSUMERKEY\noauth.consumer.secret.1=CONSUMERSECRET",
            "title": "Configure OAuth authentication"
        },
        {
            "location": "/modules/ltimodule/#configure-lti-optional",
            "text": "To give LMS users the same username in Opencast as the LMS username, edit etc/org.opencastproject.kernel.security.LtiLaunchAuthenticationHandler.cfg  and add the configured OAuth consumer key\nto the list of highly trusted keys.  lti.oauth.highly_trusted_consumer_key.1=CONSUMERKEY  Use can exempt specific users even if a highly trusted consumer is used by configuring a blacklist. Additionally, there\nare settings for excluding the system administrator as well as the digest user (enabled by default).  lti.allow_system_administrator=false\nlti.allow_digest_user=false\nlti.blacklist.user.1=myAdminUser   Notice:  Marking a consumer key as highly trusted can be a security risk! If the usernames of sensitive Opencast\nusers are not blacklisted, the LMS administrator could create LMS users with the same username and use LTI to grant\nthat user access to Opencast. In the default configuration, that includes the  admin  and  opencast_system_account \nusers.",
            "title": "Configure LTI (optional)"
        },
        {
            "location": "/modules/ltimodule/#configure-and-test-an-lti-tool-in-the-lms",
            "text": "Configure an LTI tool in the LMS with these values:   LTI launch URL:  OPENCAST-URL/lti  LTI key: the value chosen for CONSUMERKEY in  org.opencastproject.kernel.security.OAuthConsumerDetailsService.cfg  LTI secret: the value chosen for CONSUMERSECRET in  org.opencastproject.kernel.security.OAuthConsumerDetailsService.cfg   In a clustered Opencast system, choose the URL of the presentation server where the media module and player are available.  Access the LTI tool configured for Opencast in the LMS. The Opencast LTI Welcome page should appear. Click on the links\nprovided to  OPENCAST-URL/lti  and  OPENCAST-URL/info/me.json  to verify the LTI parameters provided to Opencast by the LMS,\nand the list of roles which the LTI user has in Opencast.",
            "title": "Configure and test an LTI tool in the LMS"
        },
        {
            "location": "/modules/ltimodule/#lti-roles",
            "text": "LTI users will only see Opencast series and videos which are public, or those to which they have access\nbecause of the Opencast roles which they have. The Opencast LTI module grants an LTI user the role(s) formed\nfrom the LTI parameters  context_id  and  roles .  The LTI context is typically the LMS course ID, and the default LTI role for a student in a course is  Learner .\nThe Opencast role granted would therefore be  SITEID_Learner .  To make a series or video visible to students who access Opencast through LTI in an LMS course,\nadd the role  SITEID_Learner  to the Series or Event Access Control List (ACL).  LTI users may also have additional roles if the LTI user is created as an Opencast user in the Admin UI and\ngiven additional roles, or if one or more Opencast User Providers or Role Providers are configured.",
            "title": "LTI roles"
        },
        {
            "location": "/modules/ltimodule/#customize-the-lti-tool-in-the-lms",
            "text": "Opencast will redirect an LTI user to the URL specified by the LTI custom  tool  parameter. Some LMS systems allow\ncustom parameters to be defined separately in each place where an LTI tool is used, whereas other systems only allow\ncustom parameters to be defined globally.   To show the Opencast Media Module, use  tool=engage/ui/  To show all videos for a single series, use  tool=ltitools/series/index.html;series=SERIESID  To show a single video, use  tool=engage/theodul/ui/core.html;id=MEDIAPACKAGEID  To show a short debugging page before proceeding to the tool page, add the parameter  test=true   For more information about how to set custom LTI parameters, please check the documentation of your LMS.",
            "title": "Customize the LTI tool in the LMS"
        },
        {
            "location": "/modules/mediamodule.configuration/",
            "text": "Media Module Configuration\n\n\nThe Media Module is the default overview of the distributed media files.\n\n\nThe configurations for the Media Module are done for each tenant. So the configuration keys are located in\n\n<opencast_home>/etc/org.opencastproject.organization-mh_default_org.cfg\n:\n\n\n\n\nprop.logo_mediamodule\n\n\nThis logo file will be displayed in the upper left of the Media Module page\n\n\nDefault: an Opencast logo\n\n\n\n\n\n\nprop.player\n\n\nThe player that should be use to play the videos.\n\n\nDefault: Opencast 2.0 (Theodul) player",
            "title": "Media Module"
        },
        {
            "location": "/modules/mediamodule.configuration/#media-module-configuration",
            "text": "The Media Module is the default overview of the distributed media files.  The configurations for the Media Module are done for each tenant. So the configuration keys are located in <opencast_home>/etc/org.opencastproject.organization-mh_default_org.cfg :   prop.logo_mediamodule  This logo file will be displayed in the upper left of the Media Module page  Default: an Opencast logo    prop.player  The player that should be use to play the videos.  Default: Opencast 2.0 (Theodul) player",
            "title": "Media Module Configuration"
        },
        {
            "location": "/modules/player.configuration/",
            "text": "Opencast Player - Configuration\n\n\nThe configurations for the player are done for each tenant. So the configuration keys are located in\n\n.../etc/org.opencastproject.organization-mh_default_org.cfg\n.\n\n\nSelect the Opencast Player\n\n\nTo activate the player set:\n\n\nprop.player=/engage/theodul/ui/core.html\n\n\n\nConfiguration\n\n\n\n\n\n\n\n\nProperty\n\n\nDescription\n\n\nOptions\n\n\n\n\n\n\n\n\n\n\nprop.logo_player\n\n\nLogo in the top right corner\n\n\nAny URL or local path to an image file\n\n\n\n\n\n\nprop.player.positioncontrols\n\n\nPosition of player controls\n\n\ntop\n, \nbottom\n (default)\n\n\n\n\n\n\nprop.player.mastervideotype\n\n\nDefault flavor of the master video *\n\n\nAny flavor or nothing\n\n\n\n\n\n\nprop.player.hide_video_context_menu\n\n\nHide browser context menu for videos\n\n\ntrue\n, \nfalse\n\n\n\n\n\n\nprop.show_embed_links\n\n\nShow player embed code\n\n\ntrue\n, \nfalse\n\n\n\n\n\n\nprop.link_mediamodule\n\n\nIf to link to the media module\n\n\ntrue\n, \nfalse\n\n\n\n\n\n\nprop.player.shortcut.*\n\n\nKeyboard shortcut specifications\n\n\nAny key\n\n\n\n\n\n\n\n\nMaster Video Flavor\n\n\nThis specifies the flavor used to select the master video (the video on the left side in the video display). This video\nfile also provides the audio. If not set or no video of the specified type is available, the videos are taken in their\nsequence within the media package.",
            "title": "Configuration"
        },
        {
            "location": "/modules/player.configuration/#opencast-player-configuration",
            "text": "The configurations for the player are done for each tenant. So the configuration keys are located in .../etc/org.opencastproject.organization-mh_default_org.cfg .",
            "title": "Opencast Player - Configuration"
        },
        {
            "location": "/modules/player.configuration/#select-the-opencast-player",
            "text": "To activate the player set:  prop.player=/engage/theodul/ui/core.html",
            "title": "Select the Opencast Player"
        },
        {
            "location": "/modules/player.configuration/#configuration",
            "text": "Property  Description  Options      prop.logo_player  Logo in the top right corner  Any URL or local path to an image file    prop.player.positioncontrols  Position of player controls  top ,  bottom  (default)    prop.player.mastervideotype  Default flavor of the master video *  Any flavor or nothing    prop.player.hide_video_context_menu  Hide browser context menu for videos  true ,  false    prop.show_embed_links  Show player embed code  true ,  false    prop.link_mediamodule  If to link to the media module  true ,  false    prop.player.shortcut.*  Keyboard shortcut specifications  Any key",
            "title": "Configuration"
        },
        {
            "location": "/modules/player.configuration/#master-video-flavor",
            "text": "This specifies the flavor used to select the master video (the video on the left side in the video display). This video\nfile also provides the audio. If not set or no video of the specified type is available, the videos are taken in their\nsequence within the media package.",
            "title": "Master Video Flavor"
        },
        {
            "location": "/modules/player.url.parameter/",
            "text": "Opencast Player * URL Parameters\n\n\nURL Parameters\n\n\n\n\ntime\n\n\nPossible values\n\n\nMinutes (with value \nX\n) and seconds (with value \nY\n)\n\n\nXmYs\n\n\nYsXm\n\n\nXmY\n\n\n\n\n\n\nMinutes (with value \nX\n) only\n\n\nXm\n\n\n\n\n\n\nSeconds (with value \nY\n) only\n\n\nYs\n\n\nY\n\n\n\n\n\n\nDefault value\n\n\n-\n\n\n\n\n\n\nDescription\n\n\nSeeks intially automatically to a specified time\n\n\nautomatically plays the video from the specified time on\n\n\n\n\n\n\nautoplay\n\n\nPossible values\n\n\ntrue\n\n\nfalse\n\n\n\n\n\n\nDefault value\n\n\nfalse\n\n\n\n\n\n\nDescription\n\n\nAutomatically starts playing the video after a short delay\n\n\n\n\n\n\n\n\n\n\nquality\n\n\nPossible values\n\n\nlow\n\n\nmedium\n\n\nhigh\n\n\n\n\n\n\nDefault value\n\n\nmedium\n\n\n\n\n\n\nDescription\n\n\nSets a video quality if the video has been encoded in multiple qualities\n\n\n\n\n\n\n\n\n\n\nmode\n\n\nPossible values\n\n\ndesktop\n\n\nembed\n\n\nmobile\n\n\n\n\n\n\nDefault value\n\n\ndesktop\n\n\n\n\n\n\nDescription\n\n\nSets the player mode manually\n\n\n\n\n\n\n\n\n\n\nbrowser\n\n\nPossible values\n\n\nall\n\n\ndefault\n\n\n\n\n\n\nDefault value\n\n\ndefault\n\n\n\n\n\n\nDescription\n\n\nIf your browser is not supported, try the new player with this flag activated overwrites filtering for supported\nbrowsers with parameter set to \nall\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nhttp://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&time=3m30s\n\n\nDeveloper URL Parameters\n\n\n\n\ndebug\n\n\nPossible values\n\n\ntrue\n\n\nfalse\n\n\n\n\n\n\nDefault value\n\n\nfalse\n\n\n\n\n\n\nDescription\n\n\nprints debug output to the developer console\n\n\n\n\n\n\n\n\n\n\ndebugEvents\n\n\nPossible values\n\n\ntrue\n\n\nfalse\n\n\n\n\n\n\nDefault value\n\n\nfalse\n\n\n\n\n\n\nDescription\n\n\nPrints debug output to the developer console when an event occurs\n\n\n\n\n\n\n\n\n\n\nformat\n\n\nPossible Values\n\n\nhls\n: Apple HTTP Live Streaming\n\n\ndash\n: MPEG DASH\n\n\nrtmp\n: Adobe RTMP (Flash)\n\n\nmp4\n: MP4 videos (no streaming)\n\n\nwebm\n: WebM videos (no streaming)\n\n\naudio\n: audio only (no streaming)\n\n\ndefault\n: reset to defaults\n\n\n\n\n\n\nDefault value\n\n\ndefault\n\n\n\n\n\n\nDescription\n\n\nsets the preferred (streaming) format\n\n\nif not available, the defaults will be selected\n\n\nthe value is permanently stored for the browser in the local storage\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nhttp://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&debug=true&debugEvents=true",
            "title": "URL Parameters"
        },
        {
            "location": "/modules/player.url.parameter/#opencast-player-url-parameters",
            "text": "",
            "title": "Opencast Player * URL Parameters"
        },
        {
            "location": "/modules/player.url.parameter/#url-parameters",
            "text": "time  Possible values  Minutes (with value  X ) and seconds (with value  Y )  XmYs  YsXm  XmY    Minutes (with value  X ) only  Xm    Seconds (with value  Y ) only  Ys  Y    Default value  -    Description  Seeks intially automatically to a specified time  automatically plays the video from the specified time on    autoplay  Possible values  true  false    Default value  false    Description  Automatically starts playing the video after a short delay      quality  Possible values  low  medium  high    Default value  medium    Description  Sets a video quality if the video has been encoded in multiple qualities      mode  Possible values  desktop  embed  mobile    Default value  desktop    Description  Sets the player mode manually      browser  Possible values  all  default    Default value  default    Description  If your browser is not supported, try the new player with this flag activated overwrites filtering for supported\nbrowsers with parameter set to  all",
            "title": "URL Parameters"
        },
        {
            "location": "/modules/player.url.parameter/#example",
            "text": "http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&time=3m30s",
            "title": "Example"
        },
        {
            "location": "/modules/player.url.parameter/#developer-url-parameters",
            "text": "debug  Possible values  true  false    Default value  false    Description  prints debug output to the developer console      debugEvents  Possible values  true  false    Default value  false    Description  Prints debug output to the developer console when an event occurs      format  Possible Values  hls : Apple HTTP Live Streaming  dash : MPEG DASH  rtmp : Adobe RTMP (Flash)  mp4 : MP4 videos (no streaming)  webm : WebM videos (no streaming)  audio : audio only (no streaming)  default : reset to defaults    Default value  default    Description  sets the preferred (streaming) format  if not available, the defaults will be selected  the value is permanently stored for the browser in the local storage",
            "title": "Developer URL Parameters"
        },
        {
            "location": "/modules/player.url.parameter/#example_1",
            "text": "http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&debug=true&debugEvents=true",
            "title": "Example"
        },
        {
            "location": "/modules/player.matomo.tracking/",
            "text": "Opencast Player - Matomo Tracking Plugin\n\n\nThis plugin allows to use Matomo (https://matomo.org/), formerly known as Piwik, to track usage data. To setup Matomo\nplease follow the instructions on the Matomo website:\nhttps://matomo.org/docs/installation/#the-5-minute-matomo-installation\n\n\nThe plugin respects the \nDo-Not-Track\n settings of a browser. You might also\nneed to consider the legal requirements of your country when you setup Matomo.\n\n\nThis plugin uses a Matomo javascript library that is loaded from the remote Matomo server!\n\n\nTested Matomo version: 3.0.2+\n\n\nThe configurations for the Matomo player plugin are done for each tenant. So the configuration keys are located in\n\n.../etc/org.opencastproject.organization-mh_default_org.cfg\n.\n\n\nTo activate the plugin set:\n\n\nprop.player.matomo.server=http://localhost/matomo\n\n\n\nWhere localhost should be replaced with your Piwik server URL.\n\n\nConfiguration\n\n\nprop.player.matomo.server\n\n\nThe plugin shows a notification about the tracking to the user. This can be disabled with this option. (Default: true)\nBefore you disable the notification, make sure that you do not violate any local regulations.\n\n\nprop.player.matomo.server\n\n\nThe Matomo server from which the Piwik JS library will be loaded and where the data will be reported.\n\n\nprop.player.matomo.site_id=1\n\n\nThe Matomo site ID has to be numeric value. If not set this will be 1. It is recommended to use different site IDs for\neach tenant that is configured in Opencast.\n\n\nprop.player.matomo.heartbeat=30\n\n\nThe heartbeat setting to track how long a user stayed on the player page. Set to 0 or comment this line to\ndisable the heartbeat.\n\n\nprop.player.matomo.track_events\n\n\nThis setting lets you track several player events. Add the events that you want to track to the list. Comment this\nproperty to prevent event tracking.\n\n\nEvents that can be tracked:\n\n\n\n\nplay: play has been pressed (will also be called if after seeking).\n\n\npause: pause has been pressend (will also be called if before seeking).\n\n\nseek: user jumps to a different time. Time in seconds will be stored\n\n\nended: video has reached the end\n\n\nplaybackrate: user changes the playback speed (values 0.75 to 3.00)\n\n\nvolume: Volume change by the user value 0.0 to 1.0\n\n\nquality: manual change of video quality (quality tag is stored)\n\n\nfullscreen: user presses fullscreen button\n\n\nfocus: user selects one video to be enlarged (flavor of selected video is stored)\n\n\nlayout_reset: user switches back to default layout\n\n\nzoom: user changes the zoom of the video\n\n\n\n\nTracked Data\n\n\nAdditional to the event data that can be turned on for each event (see above), this Opencast specific data is tracked\nif tracking is allowed:\n\n\n\n\nPage name as \"\n - \n\"\n\n\nCustom Matomo variables:\n\n\n\"event\" as \"\n (\n)\"\n\n\n\"series\" as \"\n (\n)\"\n\n\n\"presenter\"\n\n\n\"view_mode\" which can be \"desktop\", \"mobile\" or \"embed\"\n\n\n\n\n\n\n\n\nHeartbeat data does not show how long a video has been played but how long a viewer remained on the page, while the page\nwas in the foreground.",
            "title": "Matomo Tracking"
        },
        {
            "location": "/modules/player.matomo.tracking/#opencast-player-matomo-tracking-plugin",
            "text": "This plugin allows to use Matomo (https://matomo.org/), formerly known as Piwik, to track usage data. To setup Matomo\nplease follow the instructions on the Matomo website:\nhttps://matomo.org/docs/installation/#the-5-minute-matomo-installation  The plugin respects the  Do-Not-Track  settings of a browser. You might also\nneed to consider the legal requirements of your country when you setup Matomo.  This plugin uses a Matomo javascript library that is loaded from the remote Matomo server!  Tested Matomo version: 3.0.2+  The configurations for the Matomo player plugin are done for each tenant. So the configuration keys are located in .../etc/org.opencastproject.organization-mh_default_org.cfg .  To activate the plugin set:  prop.player.matomo.server=http://localhost/matomo  Where localhost should be replaced with your Piwik server URL.",
            "title": "Opencast Player - Matomo Tracking Plugin"
        },
        {
            "location": "/modules/player.matomo.tracking/#configuration",
            "text": "",
            "title": "Configuration"
        },
        {
            "location": "/modules/player.matomo.tracking/#propplayermatomoserver",
            "text": "The plugin shows a notification about the tracking to the user. This can be disabled with this option. (Default: true)\nBefore you disable the notification, make sure that you do not violate any local regulations.",
            "title": "prop.player.matomo.server"
        },
        {
            "location": "/modules/player.matomo.tracking/#propplayermatomoserver_1",
            "text": "The Matomo server from which the Piwik JS library will be loaded and where the data will be reported.",
            "title": "prop.player.matomo.server"
        },
        {
            "location": "/modules/player.matomo.tracking/#propplayermatomosite_id1",
            "text": "The Matomo site ID has to be numeric value. If not set this will be 1. It is recommended to use different site IDs for\neach tenant that is configured in Opencast.",
            "title": "prop.player.matomo.site_id=1"
        },
        {
            "location": "/modules/player.matomo.tracking/#propplayermatomoheartbeat30",
            "text": "The heartbeat setting to track how long a user stayed on the player page. Set to 0 or comment this line to\ndisable the heartbeat.",
            "title": "prop.player.matomo.heartbeat=30"
        },
        {
            "location": "/modules/player.matomo.tracking/#propplayermatomotrack_events",
            "text": "This setting lets you track several player events. Add the events that you want to track to the list. Comment this\nproperty to prevent event tracking.  Events that can be tracked:   play: play has been pressed (will also be called if after seeking).  pause: pause has been pressend (will also be called if before seeking).  seek: user jumps to a different time. Time in seconds will be stored  ended: video has reached the end  playbackrate: user changes the playback speed (values 0.75 to 3.00)  volume: Volume change by the user value 0.0 to 1.0  quality: manual change of video quality (quality tag is stored)  fullscreen: user presses fullscreen button  focus: user selects one video to be enlarged (flavor of selected video is stored)  layout_reset: user switches back to default layout  zoom: user changes the zoom of the video",
            "title": "prop.player.matomo.track_events"
        },
        {
            "location": "/modules/player.matomo.tracking/#tracked-data",
            "text": "Additional to the event data that can be turned on for each event (see above), this Opencast specific data is tracked\nif tracking is allowed:   Page name as \"  -  \"  Custom Matomo variables:  \"event\" as \"  ( )\"  \"series\" as \"  ( )\"  \"presenter\"  \"view_mode\" which can be \"desktop\", \"mobile\" or \"embed\"     Heartbeat data does not show how long a video has been played but how long a viewer remained on the page, while the page\nwas in the foreground.",
            "title": "Tracked Data"
        },
        {
            "location": "/modules/paella.player/",
            "text": "Paella Player\n\n\nTo enable paella player you need to edit the \nprop.player\n variable.\nThis can be enabled for each tenant. So the configuration keys are located in\n\n.../etc/org.opencastproject.organization-mh_default_org.cfg\n.\n\n\nSelect the Paella Player\n\n\nTo activate the paella player set:\n\n\nprop.player=/paella/ui/watch.html",
            "title": "Paella player"
        },
        {
            "location": "/modules/paella.player/#paella-player",
            "text": "To enable paella player you need to edit the  prop.player  variable.\nThis can be enabled for each tenant. So the configuration keys are located in .../etc/org.opencastproject.organization-mh_default_org.cfg .",
            "title": "Paella Player"
        },
        {
            "location": "/modules/paella.player/#select-the-paella-player",
            "text": "To activate the paella player set:  prop.player=/paella/ui/watch.html",
            "title": "Select the Paella Player"
        },
        {
            "location": "/modules/searchindex/",
            "text": "Search Index Configuration\n\n\nOpencast has Solr included by default. This guide is only needed, if you want to run Solr on a separate server.\n\n\nThe software versions in these instructions are not the only versions that will work, they are just the version tested\nwhen this document was written.  Newer versions of both Tomcat and Solr are highly recommended.\n\n\nIntroduction\n\n\nOpencast services use filesystem, relational database, and/or search indexes to store and retrieve information. In\norder to cluster services across multiple servers, we must provide shared storage solutions for each of these\ntechnologies. We do this with NFS or ZFS for filesystems, JDBC for relational databases, and solr for search indexes. If\nyou plan on clustering either the workflow service or the search service, you must configure Opencast to use remote\nsolr servers as described below, otherwise no further action is required.\n\n\nObtaining the software\n\n\nSolr runs in any modern servlet environment such as Apache Tomcat 7. Download and unpack Tomcat.\n\n\n$ curl -O http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.5-beta/bin/apache-tomcat-7.0.5.zip\n$ unzip apache-tomcat-7.0.5.zip\n\n\n\nDownload solr from the closest mirror and unpack the zip file. Make sure the permissions are set properly (the zip file\ndoesn't retain proper unix permissions)\n\n\n$ curl -O http://archive.apache.org/dist/lucene/solr/1.4.1/apache-solr-1.4.1.zip\n$ unzip apache-solr-1.4.1.zip\n$ chmod 755 apache-tomcat-7.0.5/bin/*\n\n\n\nDeploy solr to tomcat\n\n\nCopy the solr example war file to tomcat's webapps directory and expand the war file.\n\n\n$ unzip apache-solr-1.4.1/example/webapps/solr.war -d apache-tomcat-7.0.5/webapps/solr/\n\n\n\nConfigure solr\n\n\nAdd the solr config files to the solr webapp in tomcat. If you are setting up the search service, use the solr config\nfrom the search module.\n\n\n$ cd apache-tomcat-7.0.5\n$ cp -R [opencast source]/modules/search-service-impl/src/main/resources/solr solr\n\n\n\nAlternatively, if this is the solr index supporting the workflow service, copy those files instead:\n\n\n$ cd apache-tomcat-7.0.5\n$ cp -R [opencast source]/modules/workflow-service-impl/src/main/resources/solr solr\n\n\n\nEdit the dataDir setting in solr/conf/solrconfig.xml to specify the directory you want to use for the index files.\n\n\nDependency of the workflow index\n\n\nThe index has a dependency on a Opencast class. The easiest way of getting rid of this dependency is providing a .jar\nfile with that class within a directory named lib in the solr folder (you may need to create it if it does not exist).\nThe .jar file can be the compiled solr bundle. Placing the jar in the main Tomcat lib directory does not\nwork.\n\n\nStart the server\n\n\n$ bin/startup.sh\nUsing CATALINA_BASE:   /Users/josh/Desktop/apache-tomcat-7.0.5\nUsing CATALINA_HOME:   /Users/josh/Desktop/apache-tomcat-7.0.5\nUsing CATALINA_TMPDIR: /Users/josh/Desktop/apache-tomcat-7.0.5/temp\nUsing JRE_HOME:        /System/Library/Frameworks/JavaVM.framework/Versions/CurrentJDK/Home\n\n\n\nYou should see that the solr server is running on http://localhost:8080/solr\n\n\n\n\nYou can use the admin screen to monitor the server or make ad-hoc queries:\n\n\n\n\n\n\nSecure the solr server\n\n\nJust like with a relational database server, it is critical that you limit access to the solr server. Opencast's\ncommunication with solr servers is unauthenticated, so you must secure a firewall on the solr servers that accepts HTTP\nrequests only from Opencast servers. If these servers were publicly accessible, anyone could make changes to\nOpencast data from outside Opencast itself.\n\n\nConfigure Opencast\n\n\nSet the URL to this solr server in Opencast's custom.properties file:\n\n\norg.opencastproject.search.solr.url=http://your.solr.server.edu:8080/solr/\n\n\n\nIf this solr server is supporting clustered workflow services:\n\n\norg.opencastproject.workflow.solr.url==http://your.solr.server.edu:8080/solr/\n\n\n\nIt is important to understand that a solr server provides exactly one schema, and one schema only. If you want to\ncluster both the workflow service and the search service, you will need two separate solr servers. These solr servers\ncan run on the same machine, but each will needs its own servlet container and port.",
            "title": "Search Index"
        },
        {
            "location": "/modules/searchindex/#search-index-configuration",
            "text": "Opencast has Solr included by default. This guide is only needed, if you want to run Solr on a separate server.  The software versions in these instructions are not the only versions that will work, they are just the version tested\nwhen this document was written.  Newer versions of both Tomcat and Solr are highly recommended.",
            "title": "Search Index Configuration"
        },
        {
            "location": "/modules/searchindex/#introduction",
            "text": "Opencast services use filesystem, relational database, and/or search indexes to store and retrieve information. In\norder to cluster services across multiple servers, we must provide shared storage solutions for each of these\ntechnologies. We do this with NFS or ZFS for filesystems, JDBC for relational databases, and solr for search indexes. If\nyou plan on clustering either the workflow service or the search service, you must configure Opencast to use remote\nsolr servers as described below, otherwise no further action is required.",
            "title": "Introduction"
        },
        {
            "location": "/modules/searchindex/#obtaining-the-software",
            "text": "Solr runs in any modern servlet environment such as Apache Tomcat 7. Download and unpack Tomcat.  $ curl -O http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.5-beta/bin/apache-tomcat-7.0.5.zip\n$ unzip apache-tomcat-7.0.5.zip  Download solr from the closest mirror and unpack the zip file. Make sure the permissions are set properly (the zip file\ndoesn't retain proper unix permissions)  $ curl -O http://archive.apache.org/dist/lucene/solr/1.4.1/apache-solr-1.4.1.zip\n$ unzip apache-solr-1.4.1.zip\n$ chmod 755 apache-tomcat-7.0.5/bin/*",
            "title": "Obtaining the software"
        },
        {
            "location": "/modules/searchindex/#deploy-solr-to-tomcat",
            "text": "Copy the solr example war file to tomcat's webapps directory and expand the war file.  $ unzip apache-solr-1.4.1/example/webapps/solr.war -d apache-tomcat-7.0.5/webapps/solr/",
            "title": "Deploy solr to tomcat"
        },
        {
            "location": "/modules/searchindex/#configure-solr",
            "text": "Add the solr config files to the solr webapp in tomcat. If you are setting up the search service, use the solr config\nfrom the search module.  $ cd apache-tomcat-7.0.5\n$ cp -R [opencast source]/modules/search-service-impl/src/main/resources/solr solr  Alternatively, if this is the solr index supporting the workflow service, copy those files instead:  $ cd apache-tomcat-7.0.5\n$ cp -R [opencast source]/modules/workflow-service-impl/src/main/resources/solr solr  Edit the dataDir setting in solr/conf/solrconfig.xml to specify the directory you want to use for the index files.",
            "title": "Configure solr"
        },
        {
            "location": "/modules/searchindex/#dependency-of-the-workflow-index",
            "text": "The index has a dependency on a Opencast class. The easiest way of getting rid of this dependency is providing a .jar\nfile with that class within a directory named lib in the solr folder (you may need to create it if it does not exist).\nThe .jar file can be the compiled solr bundle. Placing the jar in the main Tomcat lib directory does not\nwork.",
            "title": "Dependency of the workflow index"
        },
        {
            "location": "/modules/searchindex/#start-the-server",
            "text": "$ bin/startup.sh\nUsing CATALINA_BASE:   /Users/josh/Desktop/apache-tomcat-7.0.5\nUsing CATALINA_HOME:   /Users/josh/Desktop/apache-tomcat-7.0.5\nUsing CATALINA_TMPDIR: /Users/josh/Desktop/apache-tomcat-7.0.5/temp\nUsing JRE_HOME:        /System/Library/Frameworks/JavaVM.framework/Versions/CurrentJDK/Home  You should see that the solr server is running on http://localhost:8080/solr   You can use the admin screen to monitor the server or make ad-hoc queries:",
            "title": "Start the server"
        },
        {
            "location": "/modules/searchindex/#secure-the-solr-server",
            "text": "Just like with a relational database server, it is critical that you limit access to the solr server. Opencast's\ncommunication with solr servers is unauthenticated, so you must secure a firewall on the solr servers that accepts HTTP\nrequests only from Opencast servers. If these servers were publicly accessible, anyone could make changes to\nOpencast data from outside Opencast itself.",
            "title": "Secure the solr server"
        },
        {
            "location": "/modules/searchindex/#configure-opencast",
            "text": "Set the URL to this solr server in Opencast's custom.properties file:  org.opencastproject.search.solr.url=http://your.solr.server.edu:8080/solr/  If this solr server is supporting clustered workflow services:  org.opencastproject.workflow.solr.url==http://your.solr.server.edu:8080/solr/  It is important to understand that a solr server provides exactly one schema, and one schema only. If you want to\ncluster both the workflow service and the search service, you will need two separate solr servers. These solr servers\ncan run on the same machine, but each will needs its own servlet container and port.",
            "title": "Configure Opencast"
        },
        {
            "location": "/modules/stream-security/",
            "text": "Stream Security\n\n\nIntroduction\n\n\nSecurity usually is a challenging, technically aspects of any software system. However, diving into technical details\nbefore understanding the principles of the solution can lead to false assumptions about the level of security in place.\nTherefore, this section provides a high-level overview of Opencast's stream security functionality.\n\n\nContent Security in Opencast\n\n\nIn many settings, some or even all content published by an Opencast installation must not be accessible by everyone.\nInstead, access should be restricted to those users with corresponding permissions. So, if access control already\nensures that each user only has access to the recordings he or she is allowed to see, what does stream security add to\nthe mix?\n\n\nLooking more closely at what it means to serve recordings to a viewer reveals that a distinction needs to be made\nbetween:\n\n\n\n\nthe presentation of the video player, the recording metadata\n\n\nthe serving of the video streams, preview images etc. to that player.\n\n\n\n\nThe former is protected by the engage part of Opencast. The latter may be served by download and streaming servers.\nThose distribution servers are independent of Opencast and have no knowledge about the current user and its permissions\nwith regard to the requested video asset .\n\n\nTo summarize: Opencast is capable of assessing a recording\u2019s access control list and the current user\u2019s permissions to\ndecide if a user is allowed to access the recording\u2019s metadata and the player.  External download and streaming servers,\nserving the actual video files are not aware of these permissions. As a result, nothing prevents an authorized user from\npassing on the actual video and image URLs to the public, thereby circumventing the restrictions implied on the\npresentation layer earlier on.\n\n\nSecuring the Streams\n\n\nSince the download and streaming servers do not (and should not) have access to security related information about the\nuser, its roles nor its permissions with regard to the media files, there is no way to perform authorization checks the\nsame way Opencast is performing them while serving up recording metadata. The only way to decide if a given request\nshould be served or not is to leave authorization to Opencast and agree on a secure protocol that defines whether a\nrequest is meant to be granted by Opencast or not.\n\n\nStream security solves the problem exactly as described: Each request that is sent to any of the download or streaming\nservers must contain a validation policy, indicating for how long access should be granted and optionally even from\nwhich IP address. Signing of the policy ensures that potential changes to the policy will be detected. On the other end,\nthe server must be enabled to verify the signature and extract the policy to verify whether it should comply with the\nrequest or not.\n\n\nWhat is secured and what is not?\n\n\nEven with Stream security enabled, some loopholes exist where unauthorized viewers might be able to get access to\nprotected resources, even though for a limited time only. The following section describes in detail what is and what\nis not secured.\n\n\nURL hacking\n\n\nExecutive summary: Accessing a resource with an unsigned or incorrectly signed URL is impossible.\n\n\nResources distributed by Opencast are organized in a file structure that is built upon a resource\u2019s series identifier as\nwell as the identifier of the recording itself. Since those identifiers usually are based on\n\nUUIDs\n, guessing the URL is hard but not impossible. In\naddition, a malicious user might be getting hold of a valid identifier through network sniffing, social hacking or by\nother means.\n\n\nWith Stream Security enabled, a user cannot access that resource, since the URL for accessing the resource would either\nbe lacking the policy and signature completely or would contain a broken signature due to an identifier mismatch in the\npolicy.\n\n\nIt is important to note that, if stream security is enabled, all resources will be signed and protected, even ones that\ndo not have any access restrictions defined in their access control lists. Accessing resources with unsigned URLs will\nnot be possible.\n\n\nRevoking access rights\n\n\nExecutive summary: Access is revoked once the digital signature expires.\n\n\nIf a user has the rights to access a resource, it does not automatically mean that permission has been granted for a\nlifetime. After a signed URL\u2019s policy has expired, the URL must receive an updated policy and be signed again in order\nto provide continuous access to the corresponding resource, so in the case of revoked access rights, the user in\nquestion will be able to keep access to the resource as long as the initially signed url is valid. After that, Opencast\nwill not provide a signed URL anymore due to the change in permissions.\n\n\nOn the other hand, there is no way to revoke access to that resource for that particular user unless the URL expires.\nThe only way would be to completely remove the resource from the distribution server. It is therefore important to\nchoose reasonable expiration times for signed URLs.\n\n\nUnauthorized sharing of URLs\n\n\nExecutive summary: Leaked signed URLs are only accessible for the duration of the validity of the signature.\n\n\nA signed URL shared by an authorized user with a non-authorized third party will expire (as explained above). The\nexpiration time can be set as low as some seconds but will then require even authorized users to obtain newly signed\nURLs as they continue to access protected content (e.g. the user takes a quick break watching a recording by hitting\n\u201cpause\u201d, then hits \u201cplay\u201d again to resume). This risk can be lowered further by restricting a resource to a client\u2019s IP\naddress so that it can only be played by someone with the same IP.\n\n\nDownloading or ripping content\n\n\nExecutive summary: Content protected by stream security is not protected against unauthorized publication through\nauthorized users.\n\n\nSince stream security does not implement digital rights management (DRM), authorized users may download content while in\npossession of correctly signed URLs. When that content is republished on systems that are not under the control of the\noriginal owner (i.e. are not protected by stream security or any other means), it is publicly available.\n\n\nMost institutions will have a policy in place that legally prevents circumventing protection and sharing of protected\nmedia, and as a result, the above scenario will be taxed as piracy.\n\n\nTechnical Overview\n\n\nStream security consists of several components, and each of these components must be installed and configured properly,\notherwise the system may not behave as expected. This part of the documentation describes how each of the components\nneed to be installed and holds information on which configuration options are available.\n\n\nTerms\n\n\nFor the understanding of this document it is important to have the following terms clearly defined.\n\n\nPolicy\n\n\nA policy defines the timeframe and (optionally) from which addresses a specified resource may be accessed. In order to\nexchange the policy between system components, the involved components must agree on a serialization specification.\n\n\nSignature\n\n\nThe signature expresses the validity of a policy. As with the policy, the system\u2019s signature components, must follow a\npredefined signing algorithm. Only then is it possible to verify if the signature was issued for a specific policy, or\nif either the signature or the policy was modified.\n\n\nKey\n\n\nUsing keys is a common way to protect information that is being shared between two or more systems. In stream security,\nkeys are used to prevent signature forgery. A key consists of an identifier (ID) and a secret value. The keys need to be\nkept private, otherwise everyone can create signatures and thereby gain unlimited access to all resource protected by\nthat key.\n\n\nSigning Protocol\n\n\nThe combination of a policy specification and a signature algorithm forms the signing protocol, where the policy\ncontains the rules to be applied and the signature ensures that the rules remain unaltered. Components that implement\nthe same signing protocol are compatible and can be used in combination.\n\n\nComponents\n\n\nA typical signing infrastructure consists of two main components: a signing service and a verification component. While\nthe signing service is used to sign arbitrary URLs, the verification component is located on the distribution servers to\nprotect the resources and only serve requests that have been properly signed.\n\n\nAll signing providers and verification components developed by the Opencast community implement the Opencast signing\nprotocol as documented in the developer guide and are therefore compatible.\n\n\nURL Signing Service\n\n\nThe URL signing service is designed to support one or more signing implementations called signing providers. With this\nconcept, different signing protocols, and by virtue, different verification components are supported. The resource is\npresented to each signing provider in turn, where it is either signed or passed on. This process continues until a\nsignature is obtained.\n\n\nOut of the box, Opencast provides the following implementation:\n\n\n\n\nGeneric Signing Provider\n: This provider may be used in combination with HTTP servers. It appends the necessary\n  information (policy, signature and key id) to the URL.\n\n\n\n\nThe URL signing service makes it straightforward to provide additional implementations to handle third party\ndistribution servers URL signatures. This becomes important in situations where files are served by a server that is\ncurrently not supported or if files are served by a CDN that implements its own proprietary signing protocol.\n\n\nVerification components\n\n\nIn order to take advantage of the signed URLs, a verification component needs to reside on the distribution servers to\nverify the validity of the signature (i.e. check that the URL has not been altered after it was signed) and then grant\nor deny access to the resource, based on the policy associated with the URL.\n\n\nIn addition to these external verification components there is also an Opencast verification component called the\n\nUrlSigningFilter\n that is used to protect files that Opencast itself provides.\n\n\nVerification components have the option of strict or non-strict checking. Strict verification of resources means the\nentire URL will be considered when comparing the incoming request for a resource against the policy, including the\nscheme (http, https, etc.), hostname and port. If using non-strict checking, only the path to the resource will be\nconsidered. So if the request is for a resource at \nhttp://httpdserver:8080/the/full/path/video.mp4\n, only the\n\n/the/full/path/video.mp4\n part of the URL will be checked against the policy\u2019s path. This is useful when using a load\nbalancer so that the requested hostname does not have to match the actual hostname or if a video player is rewriting\nrequests, e.g. by inserting the port number.\n\n\nFurther Information\n\n\nFor further technical information like installation instructions, configuration guides, server plugins and the signing\nspecification, please have a look at these documents:\n\n\n\n\nStream Security Configuration & Testing\n\n\nThe Opencast Signing Protocol is defined in the subsection Stream Security in the modules section of the developer guide.",
            "title": "Stream Security"
        },
        {
            "location": "/modules/stream-security/#stream-security",
            "text": "",
            "title": "Stream Security"
        },
        {
            "location": "/modules/stream-security/#introduction",
            "text": "Security usually is a challenging, technically aspects of any software system. However, diving into technical details\nbefore understanding the principles of the solution can lead to false assumptions about the level of security in place.\nTherefore, this section provides a high-level overview of Opencast's stream security functionality.",
            "title": "Introduction"
        },
        {
            "location": "/modules/stream-security/#content-security-in-opencast",
            "text": "In many settings, some or even all content published by an Opencast installation must not be accessible by everyone.\nInstead, access should be restricted to those users with corresponding permissions. So, if access control already\nensures that each user only has access to the recordings he or she is allowed to see, what does stream security add to\nthe mix?  Looking more closely at what it means to serve recordings to a viewer reveals that a distinction needs to be made\nbetween:   the presentation of the video player, the recording metadata  the serving of the video streams, preview images etc. to that player.   The former is protected by the engage part of Opencast. The latter may be served by download and streaming servers.\nThose distribution servers are independent of Opencast and have no knowledge about the current user and its permissions\nwith regard to the requested video asset .  To summarize: Opencast is capable of assessing a recording\u2019s access control list and the current user\u2019s permissions to\ndecide if a user is allowed to access the recording\u2019s metadata and the player.  External download and streaming servers,\nserving the actual video files are not aware of these permissions. As a result, nothing prevents an authorized user from\npassing on the actual video and image URLs to the public, thereby circumventing the restrictions implied on the\npresentation layer earlier on.",
            "title": "Content Security in Opencast"
        },
        {
            "location": "/modules/stream-security/#securing-the-streams",
            "text": "Since the download and streaming servers do not (and should not) have access to security related information about the\nuser, its roles nor its permissions with regard to the media files, there is no way to perform authorization checks the\nsame way Opencast is performing them while serving up recording metadata. The only way to decide if a given request\nshould be served or not is to leave authorization to Opencast and agree on a secure protocol that defines whether a\nrequest is meant to be granted by Opencast or not.  Stream security solves the problem exactly as described: Each request that is sent to any of the download or streaming\nservers must contain a validation policy, indicating for how long access should be granted and optionally even from\nwhich IP address. Signing of the policy ensures that potential changes to the policy will be detected. On the other end,\nthe server must be enabled to verify the signature and extract the policy to verify whether it should comply with the\nrequest or not.",
            "title": "Securing the Streams"
        },
        {
            "location": "/modules/stream-security/#what-is-secured-and-what-is-not",
            "text": "Even with Stream security enabled, some loopholes exist where unauthorized viewers might be able to get access to\nprotected resources, even though for a limited time only. The following section describes in detail what is and what\nis not secured.",
            "title": "What is secured and what is not?"
        },
        {
            "location": "/modules/stream-security/#url-hacking",
            "text": "Executive summary: Accessing a resource with an unsigned or incorrectly signed URL is impossible.  Resources distributed by Opencast are organized in a file structure that is built upon a resource\u2019s series identifier as\nwell as the identifier of the recording itself. Since those identifiers usually are based on UUIDs , guessing the URL is hard but not impossible. In\naddition, a malicious user might be getting hold of a valid identifier through network sniffing, social hacking or by\nother means.  With Stream Security enabled, a user cannot access that resource, since the URL for accessing the resource would either\nbe lacking the policy and signature completely or would contain a broken signature due to an identifier mismatch in the\npolicy.  It is important to note that, if stream security is enabled, all resources will be signed and protected, even ones that\ndo not have any access restrictions defined in their access control lists. Accessing resources with unsigned URLs will\nnot be possible.",
            "title": "URL hacking"
        },
        {
            "location": "/modules/stream-security/#revoking-access-rights",
            "text": "Executive summary: Access is revoked once the digital signature expires.  If a user has the rights to access a resource, it does not automatically mean that permission has been granted for a\nlifetime. After a signed URL\u2019s policy has expired, the URL must receive an updated policy and be signed again in order\nto provide continuous access to the corresponding resource, so in the case of revoked access rights, the user in\nquestion will be able to keep access to the resource as long as the initially signed url is valid. After that, Opencast\nwill not provide a signed URL anymore due to the change in permissions.  On the other hand, there is no way to revoke access to that resource for that particular user unless the URL expires.\nThe only way would be to completely remove the resource from the distribution server. It is therefore important to\nchoose reasonable expiration times for signed URLs.",
            "title": "Revoking access rights"
        },
        {
            "location": "/modules/stream-security/#unauthorized-sharing-of-urls",
            "text": "Executive summary: Leaked signed URLs are only accessible for the duration of the validity of the signature.  A signed URL shared by an authorized user with a non-authorized third party will expire (as explained above). The\nexpiration time can be set as low as some seconds but will then require even authorized users to obtain newly signed\nURLs as they continue to access protected content (e.g. the user takes a quick break watching a recording by hitting\n\u201cpause\u201d, then hits \u201cplay\u201d again to resume). This risk can be lowered further by restricting a resource to a client\u2019s IP\naddress so that it can only be played by someone with the same IP.",
            "title": "Unauthorized sharing of URLs"
        },
        {
            "location": "/modules/stream-security/#downloading-or-ripping-content",
            "text": "Executive summary: Content protected by stream security is not protected against unauthorized publication through\nauthorized users.  Since stream security does not implement digital rights management (DRM), authorized users may download content while in\npossession of correctly signed URLs. When that content is republished on systems that are not under the control of the\noriginal owner (i.e. are not protected by stream security or any other means), it is publicly available.  Most institutions will have a policy in place that legally prevents circumventing protection and sharing of protected\nmedia, and as a result, the above scenario will be taxed as piracy.",
            "title": "Downloading or ripping content"
        },
        {
            "location": "/modules/stream-security/#technical-overview",
            "text": "Stream security consists of several components, and each of these components must be installed and configured properly,\notherwise the system may not behave as expected. This part of the documentation describes how each of the components\nneed to be installed and holds information on which configuration options are available.",
            "title": "Technical Overview"
        },
        {
            "location": "/modules/stream-security/#terms",
            "text": "For the understanding of this document it is important to have the following terms clearly defined.",
            "title": "Terms"
        },
        {
            "location": "/modules/stream-security/#policy",
            "text": "A policy defines the timeframe and (optionally) from which addresses a specified resource may be accessed. In order to\nexchange the policy between system components, the involved components must agree on a serialization specification.",
            "title": "Policy"
        },
        {
            "location": "/modules/stream-security/#signature",
            "text": "The signature expresses the validity of a policy. As with the policy, the system\u2019s signature components, must follow a\npredefined signing algorithm. Only then is it possible to verify if the signature was issued for a specific policy, or\nif either the signature or the policy was modified.",
            "title": "Signature"
        },
        {
            "location": "/modules/stream-security/#key",
            "text": "Using keys is a common way to protect information that is being shared between two or more systems. In stream security,\nkeys are used to prevent signature forgery. A key consists of an identifier (ID) and a secret value. The keys need to be\nkept private, otherwise everyone can create signatures and thereby gain unlimited access to all resource protected by\nthat key.",
            "title": "Key"
        },
        {
            "location": "/modules/stream-security/#signing-protocol",
            "text": "The combination of a policy specification and a signature algorithm forms the signing protocol, where the policy\ncontains the rules to be applied and the signature ensures that the rules remain unaltered. Components that implement\nthe same signing protocol are compatible and can be used in combination.",
            "title": "Signing Protocol"
        },
        {
            "location": "/modules/stream-security/#components",
            "text": "A typical signing infrastructure consists of two main components: a signing service and a verification component. While\nthe signing service is used to sign arbitrary URLs, the verification component is located on the distribution servers to\nprotect the resources and only serve requests that have been properly signed.  All signing providers and verification components developed by the Opencast community implement the Opencast signing\nprotocol as documented in the developer guide and are therefore compatible.",
            "title": "Components"
        },
        {
            "location": "/modules/stream-security/#url-signing-service",
            "text": "The URL signing service is designed to support one or more signing implementations called signing providers. With this\nconcept, different signing protocols, and by virtue, different verification components are supported. The resource is\npresented to each signing provider in turn, where it is either signed or passed on. This process continues until a\nsignature is obtained.  Out of the box, Opencast provides the following implementation:   Generic Signing Provider : This provider may be used in combination with HTTP servers. It appends the necessary\n  information (policy, signature and key id) to the URL.   The URL signing service makes it straightforward to provide additional implementations to handle third party\ndistribution servers URL signatures. This becomes important in situations where files are served by a server that is\ncurrently not supported or if files are served by a CDN that implements its own proprietary signing protocol.",
            "title": "URL Signing Service"
        },
        {
            "location": "/modules/stream-security/#verification-components",
            "text": "In order to take advantage of the signed URLs, a verification component needs to reside on the distribution servers to\nverify the validity of the signature (i.e. check that the URL has not been altered after it was signed) and then grant\nor deny access to the resource, based on the policy associated with the URL.  In addition to these external verification components there is also an Opencast verification component called the UrlSigningFilter  that is used to protect files that Opencast itself provides.  Verification components have the option of strict or non-strict checking. Strict verification of resources means the\nentire URL will be considered when comparing the incoming request for a resource against the policy, including the\nscheme (http, https, etc.), hostname and port. If using non-strict checking, only the path to the resource will be\nconsidered. So if the request is for a resource at  http://httpdserver:8080/the/full/path/video.mp4 , only the /the/full/path/video.mp4  part of the URL will be checked against the policy\u2019s path. This is useful when using a load\nbalancer so that the requested hostname does not have to match the actual hostname or if a video player is rewriting\nrequests, e.g. by inserting the port number.",
            "title": "Verification components"
        },
        {
            "location": "/modules/stream-security/#further-information",
            "text": "For further technical information like installation instructions, configuration guides, server plugins and the signing\nspecification, please have a look at these documents:   Stream Security Configuration & Testing  The Opencast Signing Protocol is defined in the subsection Stream Security in the modules section of the developer guide.",
            "title": "Further Information"
        },
        {
            "location": "/modules/textextraction/",
            "text": "Text Extraction Configuration\n\n\nHow the text extraction process works\n\n\nThe sequence of the Opencast services used during slide detection and text extraction is the following:\n\n\n-----> Segmentation -----> TextAnalyzerService ----------------->\n                              /             \\\n                             /               \\\n                   TextExtractor          DictionaryService\n                (OCR with Tesseract)   (Filter extracted texts)\n\n\n\nThe segmentation will define the frames which are passed to the text analyzer. For extraction, a frame from the end of a\nsegment is used to make sure that most of a slides text is visible.\n\n\nThe frame is then exported as image and passed to the text extraction service which calls an OCR engine to get the text\noutput. For this, the Tesseract OCR engine is used by default.\n\n\nAfter the text extraction is done, the analysis service will pass the recognized text to the dictionary service which\nmay filter it to remove messed up words, unknown words, single characters or other things depending on the actual\nimplementation and configuration.\n\n\nFinally, the extracted text is attached to the media package as MPEG 7 XML and the Opencast workflow continues.\n\n\nConfiguration\n\n\nThis section describes the configuration of all involved tools and services. In this guide, German is used as target\nlanguage but the configuration for other languages should be similar. If necessary, important differences will be\npointed out.\n\n\nOCR Engine: Tesseract\n\n\nTesseract is the default OCR engine used by Opencast. It will accept an image file and write the extracted text to an\noutput file. The command line arguments for this will be handled by Opencast. But apart from these mandatory ones, it is\npossible to pass additional arguments to Tesseract, defining the internally used dictionary, box files and the layout\nanalysis.\n\n\nFor example, if you want OCR for German content, you want to run something like this:\n\n\ntesseract in.tif out.txt -l deu -psm 3\n\n\n\n\n\nThe arguments \nin.tif\n and \nout.txt\n are automatically set by Opencast.\n\n\nThe argument \n-l\n specifies the language files used by Tesseract. \ndeu\n specifies the German language. Multiple\n  languages may be specified, separated by plus characters. Please make sure that you have installed the language packs\n  you want to use on every worker (E.g. \nyum install tesseract-langpack-deu\n).\n\n\nFinally \n-psm 3\n specifies the layout analysis for Tesseract. The value \n3\n means \nFully automatic page segmentation,\n  but no orientation and script detection\n which is actually the default. Hence in this case, the argument could simply\n  be omitted. If you know more about your input videos, you might want to use different options here (not likely).\n\n\n\n\nIn Opencast, you can modify this options in the \ncustom.properties\n file by setting the following option:\n\n\norg.opencastproject.textanalyzer.tesseract.options=-l deu -psm 3\n\n\n\nIt is highly recommended to configure Tesseract to use your local language. It will improve the recognition a lot and\nonly this will enable the recognition of special characters specific to your local language.\n\n\nEncoding (Image Preprocessing)\n\n\nThe text extraction works best if there is a high contrast between text and background and additionally, the text is not\ntoo thin. Ideally, this means that you have black and white images with a clear, bold font.\n\n\nAt this point, it is probably worth noting that despite what is often said and could also be found in the old\ndocumentation for Opencast, it does not matter for Tesseract if it is black text on a white background or if the colors\nare inverted (white on black). Because of the way Tesseract works, that does not matter.\n\n\nA lot of lecture slides are unfortunately not designed this way. Lecturers use colors, background images, etc. That is\nwhy, to get a better result, it is a good idea to do some image preprocessing steps. Some easy ones can be included\ndirectly into the image extraction step using FFmpeg.\n\n\nFor this, edit the \n/etc/opencast/encoding/opencast-images.properties\n and modify the command for the image\nextraction:\n\n\nprofile.text-analysis.http.ffmpeg.command = -ss #{time} -i #{in.video.path} \\\n  -filter:v boxblur=1:1,curves=all=0.4/0#{space}0.6/1 \\\n  -frames:v 1 -pix_fmt:v gray -r 1 #{out.dir}/#{out.name}#{out.suffix}\n\n\n\nThis profile will create a gray, high contrast image. The additional light blur will reduce or remove noise and thicken\nthe normal letters.\n\n\nThe kind of preprocessing you should use highly depends on the input material. Interesting filters to try out for your\nmaterial are among others the blur filters, the denoise filters, the curves filter and in some cases the color-channel\nmixer.\n\n\nDictionaryService (Filtering)\n\n\nThe filtering you want to do on the recognized texts highly depends on what you want to use the recognized texts for.\nFor searching, you might want a higher degree of filtering, for users you might also want to present text with slight\nerrors, for testing and debugging, you want no filtering at all.\n\n\nStarting with version 1.6, Opencast provides three different kinds of implementation for filtering which can be just\nswapped out at any time:\n\n\n\n\ndictionary-none\n\n\ndictionary-regexp (default)\n\n\ndictionary-hunspell\n\n\n\n\nNo Filtering (dictionary-none)\n\n\nThe \ndictionary-none\n module is the simplest one. It will just let the recognized texts pass through\nunmodified. There is no additional configuration needed or even possible. Of course, this is also the fastest one.\n\n\nUsing a Regular Expression (dictionary-regexp)\n\n\nStarting with 1.6, this is the default implementation for the DictionaryService. It is quite fast and easy to configure\nbut is limited in terms of filtering capabilities as it will not check if a recognized word actually makes sense.\n\n\nThe default expression for this module is \n\\w+\n which will let upper- and lowercase characters as well as digits pass\nthrough, but will block all other characters. For the German language, for example, this would mean that all special\ncharacters would be blocked as well. So you want to configure Opencast to let them pass as well.\n\n\nYou can do that by modifying the \npattern\n in\n\netc/org.opencastproject.dictionary.regexp.DictionaryServiceImpl.cfg\n:\n\n\nFor German, a suitable pattern could be:\n\n\npattern=[\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df][\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df]+[-.,:;!?]*\n\n\n\nThis expression will let all words pass which contain upper- and lowercase [a-z], digits and German special characters\nas well as punctuation at the end of a word. Additionally, it requires that the words are at least two characters long\nwhich will filter out most of the common noise.\n\n\nA similar pattern that could be used for Spanish would be:\n\n\npattern=[\u00bf\u00a1(]*[\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1][\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1]+[)-.,:;!?]*\n\n\n\nUsing a Spell Checker (dictionary-hunspell)\n\n\nLast, the \ndictionary-hunspell\n will check words based on a spell checker and a dictionary. As spell checker,\nthe tool \nhunspell\n is used which is one of the most common spell checkers on Linux and should be available from the\nsystem repositories for most common operating systems.\n\n\nFor the Hunspell based DictionaryService, there are two configuration options.  One is for the binary and one for the\narguments to use for filtering.\n\n\nBy default, Opencast will just call \nhunspell\n without an absolute path. This will work as long as hunspell is in the\nsystems path which should be the case unless you have built and installed it manually. In that case, the binary can be\nconfigured using the following option in the \ncustom.properties\n file:\n\n\norg.opencastproject.dictionary.hunspell.binary=/usr/bin/hunspell\n\n\n\nWhile most people will not need the binary path configuration, most people will need the filtering option which can be\nused for setting the languages. Configuration for this can be done using the following key in the \ncustom.properties\n\nfile:\n\n\norg.opencastproject.dictionary.hunspell.command=-d de_DE,en_GB,en_US -G\n\n\n\nNote that equivalent to the Tesseract configuration, again the necessary languages have to be installed in the system.\nOn RedHat based systems, for German, you would install the \nhunspell-de\n package from the system repositories.\n\n\nFor Hunspell, you can also create custom dictionaries or add custom words to the existing ones. This might be\ninteresting for technical terms.",
            "title": "Text Extraction"
        },
        {
            "location": "/modules/textextraction/#text-extraction-configuration",
            "text": "",
            "title": "Text Extraction Configuration"
        },
        {
            "location": "/modules/textextraction/#how-the-text-extraction-process-works",
            "text": "The sequence of the Opencast services used during slide detection and text extraction is the following:  -----> Segmentation -----> TextAnalyzerService ----------------->\n                              /             \\\n                             /               \\\n                   TextExtractor          DictionaryService\n                (OCR with Tesseract)   (Filter extracted texts)  The segmentation will define the frames which are passed to the text analyzer. For extraction, a frame from the end of a\nsegment is used to make sure that most of a slides text is visible.  The frame is then exported as image and passed to the text extraction service which calls an OCR engine to get the text\noutput. For this, the Tesseract OCR engine is used by default.  After the text extraction is done, the analysis service will pass the recognized text to the dictionary service which\nmay filter it to remove messed up words, unknown words, single characters or other things depending on the actual\nimplementation and configuration.  Finally, the extracted text is attached to the media package as MPEG 7 XML and the Opencast workflow continues.",
            "title": "How the text extraction process works"
        },
        {
            "location": "/modules/textextraction/#configuration",
            "text": "This section describes the configuration of all involved tools and services. In this guide, German is used as target\nlanguage but the configuration for other languages should be similar. If necessary, important differences will be\npointed out.",
            "title": "Configuration"
        },
        {
            "location": "/modules/textextraction/#ocr-engine-tesseract",
            "text": "Tesseract is the default OCR engine used by Opencast. It will accept an image file and write the extracted text to an\noutput file. The command line arguments for this will be handled by Opencast. But apart from these mandatory ones, it is\npossible to pass additional arguments to Tesseract, defining the internally used dictionary, box files and the layout\nanalysis.  For example, if you want OCR for German content, you want to run something like this:  tesseract in.tif out.txt -l deu -psm 3   The arguments  in.tif  and  out.txt  are automatically set by Opencast.  The argument  -l  specifies the language files used by Tesseract.  deu  specifies the German language. Multiple\n  languages may be specified, separated by plus characters. Please make sure that you have installed the language packs\n  you want to use on every worker (E.g.  yum install tesseract-langpack-deu ).  Finally  -psm 3  specifies the layout analysis for Tesseract. The value  3  means  Fully automatic page segmentation,\n  but no orientation and script detection  which is actually the default. Hence in this case, the argument could simply\n  be omitted. If you know more about your input videos, you might want to use different options here (not likely).   In Opencast, you can modify this options in the  custom.properties  file by setting the following option:  org.opencastproject.textanalyzer.tesseract.options=-l deu -psm 3  It is highly recommended to configure Tesseract to use your local language. It will improve the recognition a lot and\nonly this will enable the recognition of special characters specific to your local language.",
            "title": "OCR Engine: Tesseract"
        },
        {
            "location": "/modules/textextraction/#encoding-image-preprocessing",
            "text": "The text extraction works best if there is a high contrast between text and background and additionally, the text is not\ntoo thin. Ideally, this means that you have black and white images with a clear, bold font.  At this point, it is probably worth noting that despite what is often said and could also be found in the old\ndocumentation for Opencast, it does not matter for Tesseract if it is black text on a white background or if the colors\nare inverted (white on black). Because of the way Tesseract works, that does not matter.  A lot of lecture slides are unfortunately not designed this way. Lecturers use colors, background images, etc. That is\nwhy, to get a better result, it is a good idea to do some image preprocessing steps. Some easy ones can be included\ndirectly into the image extraction step using FFmpeg.  For this, edit the  /etc/opencast/encoding/opencast-images.properties  and modify the command for the image\nextraction:  profile.text-analysis.http.ffmpeg.command = -ss #{time} -i #{in.video.path} \\\n  -filter:v boxblur=1:1,curves=all=0.4/0#{space}0.6/1 \\\n  -frames:v 1 -pix_fmt:v gray -r 1 #{out.dir}/#{out.name}#{out.suffix}  This profile will create a gray, high contrast image. The additional light blur will reduce or remove noise and thicken\nthe normal letters.  The kind of preprocessing you should use highly depends on the input material. Interesting filters to try out for your\nmaterial are among others the blur filters, the denoise filters, the curves filter and in some cases the color-channel\nmixer.",
            "title": "Encoding (Image Preprocessing)"
        },
        {
            "location": "/modules/textextraction/#dictionaryservice-filtering",
            "text": "The filtering you want to do on the recognized texts highly depends on what you want to use the recognized texts for.\nFor searching, you might want a higher degree of filtering, for users you might also want to present text with slight\nerrors, for testing and debugging, you want no filtering at all.  Starting with version 1.6, Opencast provides three different kinds of implementation for filtering which can be just\nswapped out at any time:   dictionary-none  dictionary-regexp (default)  dictionary-hunspell",
            "title": "DictionaryService (Filtering)"
        },
        {
            "location": "/modules/textextraction/#no-filtering-dictionary-none",
            "text": "The  dictionary-none  module is the simplest one. It will just let the recognized texts pass through\nunmodified. There is no additional configuration needed or even possible. Of course, this is also the fastest one.",
            "title": "No Filtering (dictionary-none)"
        },
        {
            "location": "/modules/textextraction/#using-a-regular-expression-dictionary-regexp",
            "text": "Starting with 1.6, this is the default implementation for the DictionaryService. It is quite fast and easy to configure\nbut is limited in terms of filtering capabilities as it will not check if a recognized word actually makes sense.  The default expression for this module is  \\w+  which will let upper- and lowercase characters as well as digits pass\nthrough, but will block all other characters. For the German language, for example, this would mean that all special\ncharacters would be blocked as well. So you want to configure Opencast to let them pass as well.  You can do that by modifying the  pattern  in etc/org.opencastproject.dictionary.regexp.DictionaryServiceImpl.cfg :  For German, a suitable pattern could be:  pattern=[\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df][\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df]+[-.,:;!?]*  This expression will let all words pass which contain upper- and lowercase [a-z], digits and German special characters\nas well as punctuation at the end of a word. Additionally, it requires that the words are at least two characters long\nwhich will filter out most of the common noise.  A similar pattern that could be used for Spanish would be:  pattern=[\u00bf\u00a1(]*[\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1][\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1]+[)-.,:;!?]*",
            "title": "Using a Regular Expression (dictionary-regexp)"
        },
        {
            "location": "/modules/textextraction/#using-a-spell-checker-dictionary-hunspell",
            "text": "Last, the  dictionary-hunspell  will check words based on a spell checker and a dictionary. As spell checker,\nthe tool  hunspell  is used which is one of the most common spell checkers on Linux and should be available from the\nsystem repositories for most common operating systems.  For the Hunspell based DictionaryService, there are two configuration options.  One is for the binary and one for the\narguments to use for filtering.  By default, Opencast will just call  hunspell  without an absolute path. This will work as long as hunspell is in the\nsystems path which should be the case unless you have built and installed it manually. In that case, the binary can be\nconfigured using the following option in the  custom.properties  file:  org.opencastproject.dictionary.hunspell.binary=/usr/bin/hunspell  While most people will not need the binary path configuration, most people will need the filtering option which can be\nused for setting the languages. Configuration for this can be done using the following key in the  custom.properties \nfile:  org.opencastproject.dictionary.hunspell.command=-d de_DE,en_GB,en_US -G  Note that equivalent to the Tesseract configuration, again the necessary languages have to be installed in the system.\nOn RedHat based systems, for German, you would install the  hunspell-de  package from the system repositories.  For Hunspell, you can also create custom dictionaries or add custom words to the existing ones. This might be\ninteresting for technical terms.",
            "title": "Using a Spell Checker (dictionary-hunspell)"
        },
        {
            "location": "/modules/watsontranscripts/",
            "text": "Transcripts (Automated by IBM Watson)\n\n\nOverview\n\n\nThe IBMWatsonTranscriptionService invokes the IBM Watson Speech-to-Text service via REST API to translate audio to\n text.\n\n\nDuring the execution of an Opencast workflow, an audio file is extracted from one of the presenter videos and sent to\nthe IBM Watson Speech-to-Text service. When the results are received, they are converted to the desired caption format\nand attached to the media package.\n\n\nWorkflow 1 runs:\n\n\n\n\nAudio file created\n\n\nWatson Speech-to-Text job started\n\n\nWorkflow finishes\n\n\n\n\nTranslation finishes, callback with results is received, and workflow 2 is started.\n\n\nWorkflow 2 runs:\n\n\n\n\nFile with results is converted and attached to media package\n\n\nMedia package is republished with captions/transcripts\n\n\n\n\nIBM Watson Speech-to-Text service documentation, including which languages are currently supported, can be found\n \nhere\n.\n\n\nConfiguration\n\n\nStep 1: Get IBM Watson credentials\n\n\n\n\nCreate a 30-day trial acoount in IBM Bluemix\n\n\nGet service credentials\n\n\n\n\nStep 2: Configure IBMWatsonTranscriptionService\n\n\nEdit  \netc/org.opencastproject.transcription.ibmwatson.IBMWatsonTranscriptionService.cfg\n:\n\n\n\n\nSet \nenabled\n=true\n\n\nUse service credentials obtained above to set \nibm.watson.user\n and \nibm.watson.psw\n\n\nEnter the appropriate language model in \nibm.watson.model\n, if not using the default (\nen-US_BroadbandModel\n)\n\n\nIn \nworkflow\n, enter the workflow definition id of the workflow to be used to attach the generated\ntranscripts/captions\n\n\nEnter a \nnotification.email\n to get job failure notifications. If not entered, the email in\netc/custom.properties (org.opencastproject.admin.email) will be used. Configure the SmtpService.\nIf no email address specified in either \nnotification.email\n or \norg.opencastproject.admin.email\n,\nemail notifications will be disabled.\n\n\n\n\n# Change enabled to true to enable this service.\nenabled=true\n\n# User obtained when registering with the IBM Watson Speech-to_text service\nibm.watson.user=<SERVICE_USER>\n\n# Password obtained when registering with the IBM Watson Speech-to_text service\nibm.watson.password=<SERVICE_PSW>\n\n# Language model to be used. See the IBM Watson Speech-to-Text service documentation\n# for available models. If empty, the default will be used (\"en-US_BroadbandModel\").\n#ibm.watson.model=\n\n# Workflow to be executed when results are ready to be attached to media package.\n#workflow=attach-watson-transcription\n\n# Interval the workflow dispatcher runs to start workflows to attach transcripts to the media package\n# after the transcription job is completed.\n# (in seconds) Default is 1 minute.\n#workflow.dispatch.interval=60\n\n# How long it should wait to check jobs after their start date + track duration has passed.\n# The default is 10 minutes. This is only used if we didn't get a callback from the\n# ibm watson speech-to-text service.\n# (in seconds)\n#completion.check.buffer=600\n\n# How long to wait after a transcription is supposed to finish before marking the job as\n# canceled in the database. Default is 2 hours.\n# (in seconds)\n#max.processing.time=7200\n\n# How long to keep result files in the working file repository in days.\n# The default is 7 days.\n#cleanup.results.days=7\n\n# Email to send notifications of errors. If not entered, the value from\n# org.opencastproject.admin.email in custom.properties will be used.\n#notification.email=\n\n\n\n\nStep 3: Add encoding profile for extracting audio\n\n\nThe IBM Watson Speech-to-Text service has limitations on audio file size. Try using the encoding profile suggested in\netc/encoding/watson-audio.properties.\n\n\nStep 4: Add workflow operations and create new workflow\n\n\nAdd the following operations to your workflow. We suggest adding them after the media package is\npublished so that users can watch videos without having to wait for the transcription to finish, but it\ndepends on your use case. The only requirement is to take a snapshot of the media package so that\nthe second workflow can retrieve it from the Asset Manager to attach the caption/transcripts.\n\n\n<!-- Extract audio from one of the presenter videos -->\n\n<operation\n  id=\"compose\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Extract audio for transcript generation\">\n  <configurations>\n    <configuration key=\"source-tags\">engage-download</configuration>\n    <configuration key=\"target-flavor\">audio/ogg</configuration>\n    <!-- The target tag 'transcript' will be used in the next 'start-watson-transcription' operation -->\n    <configuration key=\"target-tags\">transcript</configuration>\n    <configuration key=\"encoding-profile\">audio-opus</configuration>\n    <!-- If there is more than one file that match the source-tags, use only the first one -->\n    <configuration key=\"process-first-match-only\">true</configuration>\n  </configurations>\n</operation>\n\n<!-- Start IBM Watson recognitions job -->\n\n<operation\n  id=\"start-watson-transcription\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Start IBM Watson transcription job\">\n  <configurations>\n    <!--  Skip this operation if flavor already exists. Used for cases when mp already has captions. -->\n    <configuration key=\"skip-if-flavor-exists\">captions/vtt+en</configuration>\n    <!-- Audio to be translated, produced in the previous compose operation -->\n    <configuration key=\"source-tag\">transcript</configuration>\n  </configurations>\n</operation>\n\n\n\n\n\nCreate a workflow that will add the generated caption/transcript to the media package and republish it.\nA sample one can be found in etc/workflows/attach-watson-transcripts.xml\n\n\nWorkflow Operations\n\n\n\n\nstart-watson-transcription\n\n\nattach-watson-transcription",
            "title": "Transcripts (IBM Watson)"
        },
        {
            "location": "/modules/watsontranscripts/#transcripts-automated-by-ibm-watson",
            "text": "",
            "title": "Transcripts (Automated by IBM Watson)"
        },
        {
            "location": "/modules/watsontranscripts/#overview",
            "text": "The IBMWatsonTranscriptionService invokes the IBM Watson Speech-to-Text service via REST API to translate audio to\n text.  During the execution of an Opencast workflow, an audio file is extracted from one of the presenter videos and sent to\nthe IBM Watson Speech-to-Text service. When the results are received, they are converted to the desired caption format\nand attached to the media package.  Workflow 1 runs:   Audio file created  Watson Speech-to-Text job started  Workflow finishes   Translation finishes, callback with results is received, and workflow 2 is started.  Workflow 2 runs:   File with results is converted and attached to media package  Media package is republished with captions/transcripts   IBM Watson Speech-to-Text service documentation, including which languages are currently supported, can be found\n  here .",
            "title": "Overview"
        },
        {
            "location": "/modules/watsontranscripts/#configuration",
            "text": "",
            "title": "Configuration"
        },
        {
            "location": "/modules/watsontranscripts/#step-1-get-ibm-watson-credentials",
            "text": "Create a 30-day trial acoount in IBM Bluemix  Get service credentials",
            "title": "Step 1: Get IBM Watson credentials"
        },
        {
            "location": "/modules/watsontranscripts/#step-2-configure-ibmwatsontranscriptionservice",
            "text": "Edit   etc/org.opencastproject.transcription.ibmwatson.IBMWatsonTranscriptionService.cfg :   Set  enabled =true  Use service credentials obtained above to set  ibm.watson.user  and  ibm.watson.psw  Enter the appropriate language model in  ibm.watson.model , if not using the default ( en-US_BroadbandModel )  In  workflow , enter the workflow definition id of the workflow to be used to attach the generated\ntranscripts/captions  Enter a  notification.email  to get job failure notifications. If not entered, the email in\netc/custom.properties (org.opencastproject.admin.email) will be used. Configure the SmtpService.\nIf no email address specified in either  notification.email  or  org.opencastproject.admin.email ,\nemail notifications will be disabled.   # Change enabled to true to enable this service.\nenabled=true\n\n# User obtained when registering with the IBM Watson Speech-to_text service\nibm.watson.user=<SERVICE_USER>\n\n# Password obtained when registering with the IBM Watson Speech-to_text service\nibm.watson.password=<SERVICE_PSW>\n\n# Language model to be used. See the IBM Watson Speech-to-Text service documentation\n# for available models. If empty, the default will be used (\"en-US_BroadbandModel\").\n#ibm.watson.model=\n\n# Workflow to be executed when results are ready to be attached to media package.\n#workflow=attach-watson-transcription\n\n# Interval the workflow dispatcher runs to start workflows to attach transcripts to the media package\n# after the transcription job is completed.\n# (in seconds) Default is 1 minute.\n#workflow.dispatch.interval=60\n\n# How long it should wait to check jobs after their start date + track duration has passed.\n# The default is 10 minutes. This is only used if we didn't get a callback from the\n# ibm watson speech-to-text service.\n# (in seconds)\n#completion.check.buffer=600\n\n# How long to wait after a transcription is supposed to finish before marking the job as\n# canceled in the database. Default is 2 hours.\n# (in seconds)\n#max.processing.time=7200\n\n# How long to keep result files in the working file repository in days.\n# The default is 7 days.\n#cleanup.results.days=7\n\n# Email to send notifications of errors. If not entered, the value from\n# org.opencastproject.admin.email in custom.properties will be used.\n#notification.email=",
            "title": "Step 2: Configure IBMWatsonTranscriptionService"
        },
        {
            "location": "/modules/watsontranscripts/#step-3-add-encoding-profile-for-extracting-audio",
            "text": "The IBM Watson Speech-to-Text service has limitations on audio file size. Try using the encoding profile suggested in\netc/encoding/watson-audio.properties.",
            "title": "Step 3: Add encoding profile for extracting audio"
        },
        {
            "location": "/modules/watsontranscripts/#step-4-add-workflow-operations-and-create-new-workflow",
            "text": "Add the following operations to your workflow. We suggest adding them after the media package is\npublished so that users can watch videos without having to wait for the transcription to finish, but it\ndepends on your use case. The only requirement is to take a snapshot of the media package so that\nthe second workflow can retrieve it from the Asset Manager to attach the caption/transcripts.  <!-- Extract audio from one of the presenter videos -->\n\n<operation\n  id=\"compose\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Extract audio for transcript generation\">\n  <configurations>\n    <configuration key=\"source-tags\">engage-download</configuration>\n    <configuration key=\"target-flavor\">audio/ogg</configuration>\n    <!-- The target tag 'transcript' will be used in the next 'start-watson-transcription' operation -->\n    <configuration key=\"target-tags\">transcript</configuration>\n    <configuration key=\"encoding-profile\">audio-opus</configuration>\n    <!-- If there is more than one file that match the source-tags, use only the first one -->\n    <configuration key=\"process-first-match-only\">true</configuration>\n  </configurations>\n</operation>\n\n<!-- Start IBM Watson recognitions job -->\n\n<operation\n  id=\"start-watson-transcription\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Start IBM Watson transcription job\">\n  <configurations>\n    <!--  Skip this operation if flavor already exists. Used for cases when mp already has captions. -->\n    <configuration key=\"skip-if-flavor-exists\">captions/vtt+en</configuration>\n    <!-- Audio to be translated, produced in the previous compose operation -->\n    <configuration key=\"source-tag\">transcript</configuration>\n  </configurations>\n</operation>  Create a workflow that will add the generated caption/transcript to the media package and republish it.\nA sample one can be found in etc/workflows/attach-watson-transcripts.xml",
            "title": "Step 4: Add workflow operations and create new workflow"
        },
        {
            "location": "/modules/watsontranscripts/#workflow-operations",
            "text": "start-watson-transcription  attach-watson-transcription",
            "title": "Workflow Operations"
        },
        {
            "location": "/modules/videoeditor.setup/",
            "text": "Video Editor: Setup\n\n\nSilence Detection Configuration\n\n\nThe settings regarding the sensitivity of the silence detection can be changed in\n\netc/org.opencastproject.silencedetection.impl.SilenceDetectionServiceImpl.cfg\n.\n\n\n\n\nsilence.pre.length\n\n\nDuration of silence that should be included at the beginning of  a new voice segment. This is to avoid that a cut\n  seems to sudden.\n\n\nDefault: 2000 (2s)\n\n\n\n\n\n\nsilence.threshold.db\n\n\nSilence threshold (e.g. -50dB for loud classrooms, -35dB for silent indoor location).\n\n\nDefault: -40dB\n\n\n\n\n\n\nsilence.min.length\n\n\nMinimum duration in milliseconds to detect a sequence as silence.\n\n\nDefault: 10000 (10s)\n\n\n\n\n\n\nvoice.min.length\n\n\nMinimum segment duration in milliseconds to start a new voice containing sequence after a silent sequence.\n\n\nDefault: 60000 (1min)\n\n\n\n\n\n\n\n\nVideo Editor Configuration\n\n\nThe FFmpeg properties for the Video Editor can be modified in\n\netc/org.opencastproject.videoeditor.impl.VideoEditorServiceImpl.cfg\n. Usually there should be no reason to touch this\nfile.",
            "title": "Setup"
        },
        {
            "location": "/modules/videoeditor.setup/#video-editor-setup",
            "text": "",
            "title": "Video Editor: Setup"
        },
        {
            "location": "/modules/videoeditor.setup/#silence-detection-configuration",
            "text": "The settings regarding the sensitivity of the silence detection can be changed in etc/org.opencastproject.silencedetection.impl.SilenceDetectionServiceImpl.cfg .   silence.pre.length  Duration of silence that should be included at the beginning of  a new voice segment. This is to avoid that a cut\n  seems to sudden.  Default: 2000 (2s)    silence.threshold.db  Silence threshold (e.g. -50dB for loud classrooms, -35dB for silent indoor location).  Default: -40dB    silence.min.length  Minimum duration in milliseconds to detect a sequence as silence.  Default: 10000 (10s)    voice.min.length  Minimum segment duration in milliseconds to start a new voice containing sequence after a silent sequence.  Default: 60000 (1min)",
            "title": "Silence Detection Configuration"
        },
        {
            "location": "/modules/videoeditor.setup/#video-editor-configuration",
            "text": "The FFmpeg properties for the Video Editor can be modified in etc/org.opencastproject.videoeditor.impl.VideoEditorServiceImpl.cfg . Usually there should be no reason to touch this\nfile.",
            "title": "Video Editor Configuration"
        },
        {
            "location": "/modules/videoeditor.architecture/",
            "text": "Video Editor: Architecture\n\n\nModules Of The Videoeditor\n\n\nThe Videoeditor consists of the following moduls. Additional to this there is a Workflow Operation Handler within the\nConductor module that provides the UI elements for the Video Editor.\n\n\n\n\nsilencedetection-api\n\n\nAPI for the silence detection\n\n\n\n\n\n\nsilencedetection-impl\n\n\nImplementation of the silence detection service\n\n\nProvides a SMIL file that can be used by the Video Editor UI or the Video Editor service to create a new cutted\n  file.\n\n\n\n\n\n\nsilencedetection-remote\n\n\nRemote implementation of the silence detection service to enable load balancing in a distributed setup.\n\n\n\n\n\n\nsmil-api\n\n\nAPI for the SMIL service\n\n\n\n\n\n\nsmil-impl\n\n\nThe SMIL service allows creation and manipulation of SMIL files. This is more or less a helper class to create\n  consistent SMIL files.\n\n\n\n\n\n\nvideoeditor-api\n\n\nThe API for the Video Editor which takes a SMIL file as an input to create a cutted version of the media files.\n\n\n\n\n\n\nvideoeditor-ffmpeg-impl\n\n\nThe Video Editor service creates new media files that will be cutted based on the information provided in a SMIL\n  file. In the current implementation GStreamer with the gnonlin module is used to process the files.\n\n\n\n\n\n\nvideoeditor-remote\n\n\nRemote implementation of the video editor service to enable load balancing in a distributed setup.\n\n\n\n\n\n\n\n\nSeveral other changes have been made on other Opencast modules to provide a better user experience for the video\neditor (i.e. byte-range request on the working-file-repository).\n\n\nEdit List Format\n\n\nThe video editor uses SMIL 3.0 as a standardized Data format for the edit lists (cutting information). Some conventions\nand namespace extensions have been made to make sure that Opencast is able to find the files.\n\n\n\n\nAs we usually have two (or more) parallel media files, these files are grouped in a \n<par>\n-element which forms a\n  segment that should be included in the resulting video.  This means the included \n<video>\n-files will be played in\n  parallel.\n\n\nThe clipBegin and clipEnd attributes a provided as milliseconds. Usually these should be identical for all \n<videos>\n\n  within a \n<par>\n.  For each segment a \n<par>\n is created.\n\n\nIn the result of the silence detection segments with silence are omitted within the SMIL files, so only segments\n  within the SMIL doc will be in the resulting video.\n\n\nThe segments within the SMIL file will be in the order they are written down. If the sequence of the segments is\n  changed, the sequence within the resulting video is changed too.\n\n\n\n\nExample SMIL file\n\n\n<smil xmlns=\"http://www.w3.org/ns/SMIL\" baseProfile=\"Language\" version=\"3.0\" xml:id=\"s-524c7815-4520-48e4-bb5e-94dcfdb3229f\">\n    <head xml:id=\"h-03b31c8d-68cf-49ea-8bae-d94abddf8f09\">\n        <meta name=\"track-duration\" content=\"6000841ms\" xml:id=\"meta-32069ddb-351d-4dca-a742-b9be490080f8\"/>\n        <paramGroup xml:id=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\">\n            <param value=\"9f373445-5f46-4bdd-8d93-dca5e1094c38\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-d509b427-b239-4c4b-985a-f8b4ea31bbfb\"/>\n            <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-411e0015-af0e-463c-898d-9a2bc594df46\"/>\n            <param value=\"presenter/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-5ea022cd-189d-420f-9cea-4f6775af285e\"/>\n        </paramGroup>\n        <paramGroup xml:id=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\">\n            <param value=\"9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-c3c427ad-ef8a-4a71-9b0c-9208dd8a6bed\"/>\n            <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-c15e1ed7-f773-456d-a007-fc237d9e0665\"/>\n            <param value=\"presentation/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-97d5b5ac-1258-4267-a013-dc3882d7e242\"/>\n        </paramGroup>\n    </head>\n    <body xml:id=\"b-c233c9ef-42d9-4f50-a1d2-29e3bbff003d\">\n        <par xml:id=\"par-7955133a-bcbe-40f8-87fd-47e78b3357c0\">\n            <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" paramGroup=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-61f5d0ee-dd36-4b1d-af3d-3f09f8807179\"/>\n            <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" paramGroup=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-c68260e7-fd0d-4df6-8696-cc475ab3b3f8\"/>\n        </par>\n    </body>\n</smil>\n\n\n\nWorkflow Operations\n\n\nWaveform Operation\n\n\nThe \nwaveform\n operation creates an image showing the temporal audio activity within the recording. This is be done\nwith a probably well known waveform (see example image).\n\n\n\n\nThe operation does not need an additional module, as it is not very work intensive to create such an image. The\noperation needs and audio-only file to create the image and it provides an PNG image.\n\n\nInput parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be\nused if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example).\n\n\nThe output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too.\n\n\nWaveform Operation Template\n\n\n<operation\n  id=\"waveform\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Generating waveform\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/audio</configuration>\n    <configuration key=\"target-flavor\">*/waveform</configuration>\n  </configurations>\n</operation>\n\n\n\nSilence Operation\n\n\nThe \nsilence\n operation performs a silence detection on an audio-only input file. The operation needs the silence\ndetection API and impl (or remote in a distributed system) modules to be installed to process the request.\n\n\nThe input parameters are source-flavors that takes one flavor/sub-type or multiple input flavors with the *-operator\nfollowed by the sub-type, and reference-tracks-flavour where the subtype of the media files that should be included in\nthe provided SMIL file will be set. The * should not be modified here. In most cases it is not important which\nreference-tracks-flavour is selected as long as all relevant flavors are available within this feature. \"preview\" is not\na bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\"\nwhere not all flavors may be available, as some recorders record all streams to one file and the tracks are separated\nafterwards. The editor operation afterwards will anyway try to select the best available quality.\n\n\nThe output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation.\nThe main flavor will be consistent and only the subtype will be replaced.\n\n\nThe output of this operation is a SMIL file (see the example above).\n\n\nSilence Operation Template\n\n\n<operation\n  id=\"silence\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Executing silence detection\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/audio</configuration>\n    <configuration key=\"smil-flavor-subtype\">smil</configuration>\n    <configuration key=\"reference-tracks-flavor\">*/preview</configuration>\n  </configurations>\n</operation>\n\n\n\nEditor Operation\n\n\nThe \neditor\n operation provides the UI for editing trim hold state and processes the edited files. This operation\nneeds the videoeditor API and impl (or remote on distributed systems) to be installed.\n\n\nThe input parameters are:\n\n\n\n\nsource-flavors: the subtype of all media files in the best available quality and in a codec that can be processed by\n   the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only\n   the subtype is important. All needed videos should be available within this flavor.\n\n\npreview-flavours: the subtype of the media files that should be used for the preview player. This is an HTML5 player\n   so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors.\n\n\nsmil-flavors: the smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil\n   will be favored, if this is not available the first in the list will be used.\n\n\nskipped-flavors: the flavor of the files that should be used if this workflow-operation is skipped.\n\n\n\n\nThe output parameters are:\n\n\n\n\ntarget-smil-flavor: only a unique flavor is allowed here, as this is the file that the editor UI writes and that will\n   be taken for processing the edited files afterwards.\n\n\ntarget-flavor-subtype: the flavor-subtype that will be used for all media files created in this operation.\n\n\n\n\nEditor Operation Template\n\n\n<operation\n  id=\"editor\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Waiting for user to review / video edit recording\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/work</configuration>\n    <configuration key=\"preview-flavors\">*/preview</configuration>\n    <configuration key=\"skipped-flavors\">*/preview</configuration>\n    <configuration key=\"smil-flavors\">*/smil</configuration>\n    <configuration key=\"target-smil-flavor\">episode/smil</configuration>\n    <configuration key=\"target-flavor-subtype\">trimmed</configuration>\n  </configurations>\n</operation>\n\n\n\nIncluding The Video Editor To The Workflow Definition File\n\n\nIncluding the Video Editor with the silence detection into the needs some changes in the default workflow. Several of\nthe steps here are inherited from the trim-operations and the workflow it was included too. We assume that you set\n${trimHold} variable like in the current workflow definitions with trimming.\n\n\n\n\nThe prepare-av operations has to be adopted. Gstreamer/gnonlin is kind of picky on the codec that it supports. So the\n   media file has to be re-encoded in the beginning of the workflow. The prepare-av encoding profiles (av.work and\n   mux-av.work) have been updated in the Video Editor branch for this. Within the prepare-av operation in the\n   workflow-definition XML-file rewriting the file should be forced:\n\n\n\n\nChanges in the workflow definition\n\n\n<configuration key=\"rewrite\">true</configuration>\n\n\n<configuration key=\"audio-muxing-source-flavors\">*/?,*/*</configuration>\n\n\n\n\n\n\nThe preview videos have to be created. These can be in H.264 (for Safari, IE, Chrome) or WebM (for Firefox, Opera or\n   Chrome) codec. Encoding profiles for WebM are provided in the video editor branch and are used in the examples. This\n   operation should be after the prepare-av operation.\n\n\nWorkflow operation to create WebM preview videos\n\n\n<operation\n  id=\"compose\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Encoding presenter (camera) video for videoeditor preview\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/preview</configuration>\n    <configuration key=\"encoding-profile\">webm-preview.http</configuration>\n  </configurations>\n</operation>\n\n\n\n\n\n\n\nAn audio-only file has to be composed for the waveform and silence operation. This operation should be after the\n   prepare-av operation.  Workflow operation to compose the audio-only file(s)\n\n\n<operation\n  id=\"compose\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Extracting audio for waveform generation\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/audio</configuration>\n    <configuration key=\"encoding-profile\">audio.wav</configuration>\n  </configurations>\n</operation>\n\n\n\n\n\n\n\nThe waveform operation should be included. See above for the XML-code for this operation. The audio-only file should\n   already be available.\n\n\n\n\nThe silence detection should be done. See above for the XML-code for this operation. The audio-only file should\n   already be available.\n\n\nAfter all previous operations have been done the editor can be included. See above for the XML-code for this\n   operation.\n\n\nYou may consider to tag the trimmed files for archiving. Then you should include this operation after the editor:\n\n\n\n\nTagging trimmed files for the archive\n\n\n    <operation\n      id=\"tag\"\n      description=\"Tagging media for archival\">\n      <configurations>\n        <configuration key=\"source-flavors\">*/trimmed</configuration>\n        <configuration key=\"target-tags\">+archive</configuration>\n      </configurations>\n    </operation>\n\nYou could check, if you want to archive the source media too, or remove the source-flavors from the previous tagging\noperations.\n\n\n\n\n\nThe rest of the workflow definition can be kept as it is, the input flavor subtype for the trimmed files in other\n   operations is \"/trimmed\" if you follow the naming in this example.\n\n\n\n\nThe default \ncompose-distribute-publish.xml\n workflow definition within the Video Editor branch has already been updated\nto include the editor instead of the trim-hold state. The trim operation is not overwritten with the video editor but\ncould still be used.",
            "title": "Architecture"
        },
        {
            "location": "/modules/videoeditor.architecture/#video-editor-architecture",
            "text": "",
            "title": "Video Editor: Architecture"
        },
        {
            "location": "/modules/videoeditor.architecture/#modules-of-the-videoeditor",
            "text": "The Videoeditor consists of the following moduls. Additional to this there is a Workflow Operation Handler within the\nConductor module that provides the UI elements for the Video Editor.   silencedetection-api  API for the silence detection    silencedetection-impl  Implementation of the silence detection service  Provides a SMIL file that can be used by the Video Editor UI or the Video Editor service to create a new cutted\n  file.    silencedetection-remote  Remote implementation of the silence detection service to enable load balancing in a distributed setup.    smil-api  API for the SMIL service    smil-impl  The SMIL service allows creation and manipulation of SMIL files. This is more or less a helper class to create\n  consistent SMIL files.    videoeditor-api  The API for the Video Editor which takes a SMIL file as an input to create a cutted version of the media files.    videoeditor-ffmpeg-impl  The Video Editor service creates new media files that will be cutted based on the information provided in a SMIL\n  file. In the current implementation GStreamer with the gnonlin module is used to process the files.    videoeditor-remote  Remote implementation of the video editor service to enable load balancing in a distributed setup.     Several other changes have been made on other Opencast modules to provide a better user experience for the video\neditor (i.e. byte-range request on the working-file-repository).",
            "title": "Modules Of The Videoeditor"
        },
        {
            "location": "/modules/videoeditor.architecture/#edit-list-format",
            "text": "The video editor uses SMIL 3.0 as a standardized Data format for the edit lists (cutting information). Some conventions\nand namespace extensions have been made to make sure that Opencast is able to find the files.   As we usually have two (or more) parallel media files, these files are grouped in a  <par> -element which forms a\n  segment that should be included in the resulting video.  This means the included  <video> -files will be played in\n  parallel.  The clipBegin and clipEnd attributes a provided as milliseconds. Usually these should be identical for all  <videos> \n  within a  <par> .  For each segment a  <par>  is created.  In the result of the silence detection segments with silence are omitted within the SMIL files, so only segments\n  within the SMIL doc will be in the resulting video.  The segments within the SMIL file will be in the order they are written down. If the sequence of the segments is\n  changed, the sequence within the resulting video is changed too.   Example SMIL file  <smil xmlns=\"http://www.w3.org/ns/SMIL\" baseProfile=\"Language\" version=\"3.0\" xml:id=\"s-524c7815-4520-48e4-bb5e-94dcfdb3229f\">\n    <head xml:id=\"h-03b31c8d-68cf-49ea-8bae-d94abddf8f09\">\n        <meta name=\"track-duration\" content=\"6000841ms\" xml:id=\"meta-32069ddb-351d-4dca-a742-b9be490080f8\"/>\n        <paramGroup xml:id=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\">\n            <param value=\"9f373445-5f46-4bdd-8d93-dca5e1094c38\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-d509b427-b239-4c4b-985a-f8b4ea31bbfb\"/>\n            <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-411e0015-af0e-463c-898d-9a2bc594df46\"/>\n            <param value=\"presenter/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-5ea022cd-189d-420f-9cea-4f6775af285e\"/>\n        </paramGroup>\n        <paramGroup xml:id=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\">\n            <param value=\"9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-c3c427ad-ef8a-4a71-9b0c-9208dd8a6bed\"/>\n            <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-c15e1ed7-f773-456d-a007-fc237d9e0665\"/>\n            <param value=\"presentation/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-97d5b5ac-1258-4267-a013-dc3882d7e242\"/>\n        </paramGroup>\n    </head>\n    <body xml:id=\"b-c233c9ef-42d9-4f50-a1d2-29e3bbff003d\">\n        <par xml:id=\"par-7955133a-bcbe-40f8-87fd-47e78b3357c0\">\n            <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" paramGroup=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-61f5d0ee-dd36-4b1d-af3d-3f09f8807179\"/>\n            <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" paramGroup=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-c68260e7-fd0d-4df6-8696-cc475ab3b3f8\"/>\n        </par>\n    </body>\n</smil>",
            "title": "Edit List Format"
        },
        {
            "location": "/modules/videoeditor.architecture/#workflow-operations",
            "text": "",
            "title": "Workflow Operations"
        },
        {
            "location": "/modules/videoeditor.architecture/#waveform-operation",
            "text": "The  waveform  operation creates an image showing the temporal audio activity within the recording. This is be done\nwith a probably well known waveform (see example image).   The operation does not need an additional module, as it is not very work intensive to create such an image. The\noperation needs and audio-only file to create the image and it provides an PNG image.  Input parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be\nused if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example).  The output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too.  Waveform Operation Template  <operation\n  id=\"waveform\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Generating waveform\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/audio</configuration>\n    <configuration key=\"target-flavor\">*/waveform</configuration>\n  </configurations>\n</operation>",
            "title": "Waveform Operation"
        },
        {
            "location": "/modules/videoeditor.architecture/#silence-operation",
            "text": "The  silence  operation performs a silence detection on an audio-only input file. The operation needs the silence\ndetection API and impl (or remote in a distributed system) modules to be installed to process the request.  The input parameters are source-flavors that takes one flavor/sub-type or multiple input flavors with the *-operator\nfollowed by the sub-type, and reference-tracks-flavour where the subtype of the media files that should be included in\nthe provided SMIL file will be set. The * should not be modified here. In most cases it is not important which\nreference-tracks-flavour is selected as long as all relevant flavors are available within this feature. \"preview\" is not\na bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\"\nwhere not all flavors may be available, as some recorders record all streams to one file and the tracks are separated\nafterwards. The editor operation afterwards will anyway try to select the best available quality.  The output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation.\nThe main flavor will be consistent and only the subtype will be replaced.  The output of this operation is a SMIL file (see the example above).  Silence Operation Template  <operation\n  id=\"silence\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Executing silence detection\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/audio</configuration>\n    <configuration key=\"smil-flavor-subtype\">smil</configuration>\n    <configuration key=\"reference-tracks-flavor\">*/preview</configuration>\n  </configurations>\n</operation>",
            "title": "Silence Operation"
        },
        {
            "location": "/modules/videoeditor.architecture/#editor-operation",
            "text": "The  editor  operation provides the UI for editing trim hold state and processes the edited files. This operation\nneeds the videoeditor API and impl (or remote on distributed systems) to be installed.  The input parameters are:   source-flavors: the subtype of all media files in the best available quality and in a codec that can be processed by\n   the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only\n   the subtype is important. All needed videos should be available within this flavor.  preview-flavours: the subtype of the media files that should be used for the preview player. This is an HTML5 player\n   so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors.  smil-flavors: the smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil\n   will be favored, if this is not available the first in the list will be used.  skipped-flavors: the flavor of the files that should be used if this workflow-operation is skipped.   The output parameters are:   target-smil-flavor: only a unique flavor is allowed here, as this is the file that the editor UI writes and that will\n   be taken for processing the edited files afterwards.  target-flavor-subtype: the flavor-subtype that will be used for all media files created in this operation.   Editor Operation Template  <operation\n  id=\"editor\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Waiting for user to review / video edit recording\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/work</configuration>\n    <configuration key=\"preview-flavors\">*/preview</configuration>\n    <configuration key=\"skipped-flavors\">*/preview</configuration>\n    <configuration key=\"smil-flavors\">*/smil</configuration>\n    <configuration key=\"target-smil-flavor\">episode/smil</configuration>\n    <configuration key=\"target-flavor-subtype\">trimmed</configuration>\n  </configurations>\n</operation>",
            "title": "Editor Operation"
        },
        {
            "location": "/modules/videoeditor.architecture/#including-the-video-editor-to-the-workflow-definition-file",
            "text": "Including the Video Editor with the silence detection into the needs some changes in the default workflow. Several of\nthe steps here are inherited from the trim-operations and the workflow it was included too. We assume that you set\n${trimHold} variable like in the current workflow definitions with trimming.   The prepare-av operations has to be adopted. Gstreamer/gnonlin is kind of picky on the codec that it supports. So the\n   media file has to be re-encoded in the beginning of the workflow. The prepare-av encoding profiles (av.work and\n   mux-av.work) have been updated in the Video Editor branch for this. Within the prepare-av operation in the\n   workflow-definition XML-file rewriting the file should be forced:   Changes in the workflow definition  <configuration key=\"rewrite\">true</configuration>  <configuration key=\"audio-muxing-source-flavors\">*/?,*/*</configuration>    The preview videos have to be created. These can be in H.264 (for Safari, IE, Chrome) or WebM (for Firefox, Opera or\n   Chrome) codec. Encoding profiles for WebM are provided in the video editor branch and are used in the examples. This\n   operation should be after the prepare-av operation.  Workflow operation to create WebM preview videos  <operation\n  id=\"compose\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Encoding presenter (camera) video for videoeditor preview\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/preview</configuration>\n    <configuration key=\"encoding-profile\">webm-preview.http</configuration>\n  </configurations>\n</operation>    An audio-only file has to be composed for the waveform and silence operation. This operation should be after the\n   prepare-av operation.  Workflow operation to compose the audio-only file(s)  <operation\n  id=\"compose\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Extracting audio for waveform generation\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/audio</configuration>\n    <configuration key=\"encoding-profile\">audio.wav</configuration>\n  </configurations>\n</operation>    The waveform operation should be included. See above for the XML-code for this operation. The audio-only file should\n   already be available.   The silence detection should be done. See above for the XML-code for this operation. The audio-only file should\n   already be available.  After all previous operations have been done the editor can be included. See above for the XML-code for this\n   operation.  You may consider to tag the trimmed files for archiving. Then you should include this operation after the editor:   Tagging trimmed files for the archive      <operation\n      id=\"tag\"\n      description=\"Tagging media for archival\">\n      <configurations>\n        <configuration key=\"source-flavors\">*/trimmed</configuration>\n        <configuration key=\"target-tags\">+archive</configuration>\n      </configurations>\n    </operation>\n\nYou could check, if you want to archive the source media too, or remove the source-flavors from the previous tagging\noperations.   The rest of the workflow definition can be kept as it is, the input flavor subtype for the trimmed files in other\n   operations is \"/trimmed\" if you follow the naming in this example.   The default  compose-distribute-publish.xml  workflow definition within the Video Editor branch has already been updated\nto include the editor instead of the trim-hold state. The trim operation is not overwritten with the video editor but\ncould still be used.",
            "title": "Including The Video Editor To The Workflow Definition File"
        },
        {
            "location": "/modules/videosegmentation/",
            "text": "Video Segmentation Configuration\n\n\nWhat is Video Segmentation\n\n\nVideo segmentation is a way of dividing a movie into meaningful segments. In the context of lecture capture,\nsegmentation is best applied to captured screen presentation, that the presenter goes through slide after slide.\n\n\nAs a result, the video segmentation returns the exact times of slide changes on the timeline, which allows for\nsophisticated ways for the learner to browse the lecture content, as shown in the slides section of the Opencast Player.\n\n\nHow the video segmentation process works\n\n\nFor detecting new scenes, Opencast uses the scene detection build into the FFmpeg select filter. The basic idea behind\nthis filter is to compare to consecutive frames and decide if the second frame belongs to a new scene based on the\ndifference.\n\n\nWhat can be optimized\n\n\nThe segmentation does not yield perfect results for all scenarios if always the same parameters for the FFmpeg filter\nare used. Especially for presentations that include live handwriting or small videos often way too many segments are\ncreated. In these special cases the difference between two consecutive frames is much higher than for normal\npresentation slides and these big differences happen very often, whereby many segments would be found.\nTo improve the resulting number of segments, different FFmpeg parameters are tried out and to prevent having segments\nthat are too short to be reasonably clickable, too short segments are filtered out.\n\n\nHow the Optimization works\n\n\nIn general the optimization repeats a cycle of calling the ffmpeg filter, merging too small segments and calculating a\nnew changes threshold until the segmentation is good enough.\n\n\nAdditional to calling the ffmpeg function there is a filter function that merges small segments to a bigger segment or\nsplits it to the surrounding segments if the resulting segment would be too small. This can be beneficial for example\nif a video is shown in a lecture, so that the video will be only one segment and not many short segments.\nThe stability threshold is used in the filter method to determine which segments are long enough and which should be\nmerged.\n\n\nFirst the segmentation is run with a stability threshold of 1 second and the initial changes threshold, that can be\nchanged in the options. If the segmentation or the filtered segmentation doesn't deviate more from the preferred number\nof segments than the maximum error allows, the optimization is done. If not, a new changes threshold, that should yield\nbetter results, is calculated and the segmentation is run again until the segmentation is good enough or until the\nmaximum number of cycles is reached.\n\n\nConfiguration\n\n\nThe value for the frame difference as well as the minimum length for a segment, the preferred number of segments, the\nmaximum error and the maximum number of cycles can be configured in\n\netc/org.opencastproject.videosegmenter.ffmpeg.VideoSegmenterServiceImpl.cfg\n.\n\n\nThe options that can be set are the minimum length of a segment (defaults to 60 sec).\n\n\nstabilitythreshold = 60\n\n\n\nThe percentage of pixels that may change between two frames without considering them different (defaults to 0.025).\n\n\nchangesthreshold = 0.025\n\n\n\nThe number of segments that the segmentation optimally should yield (defaults to 30).\n\n\nprefNumber = 30\n\n\n\nThe maximum error for the number of segments in percent. As soon as a segmentation with a lower error is achieved the\noptimization will be ended (defaults to 0.25).\n\n\nmaxError = 0.25\n\n\n\nThe maximum number of times the optimization will call the FFmpeg select filter (defaults to 3).\n\n\nmaxCycles = 3\n\n\n\nThe absolute maximum number of segments. If at the end of the optimization more segments than this are found, instead a\nuniform segmentation will be generated (defaults to 150).\n\n\nabsoluteMax = 150\n\n\n\nThe absolute minimum number of segments. If at the end of the optimization less segments than this are found, instead a\nuniform segmentation will be generated (defaults to 3).\n\n\nabsoluteMin = 3\n\n\n\nThis parameter controls whether the options prefNumber, absoluteMax and absoluteMin are interpreted as absolute\nsegment numbers or relative to track duration. If this is set to true, prefNumber, absoluteMax and absoluteMin will be\ninterpreted as number of segments per hour. (defaults to false)\n\n\ndurationDependent = false",
            "title": "Video Segmentation"
        },
        {
            "location": "/modules/videosegmentation/#video-segmentation-configuration",
            "text": "",
            "title": "Video Segmentation Configuration"
        },
        {
            "location": "/modules/videosegmentation/#what-is-video-segmentation",
            "text": "Video segmentation is a way of dividing a movie into meaningful segments. In the context of lecture capture,\nsegmentation is best applied to captured screen presentation, that the presenter goes through slide after slide.  As a result, the video segmentation returns the exact times of slide changes on the timeline, which allows for\nsophisticated ways for the learner to browse the lecture content, as shown in the slides section of the Opencast Player.",
            "title": "What is Video Segmentation"
        },
        {
            "location": "/modules/videosegmentation/#how-the-video-segmentation-process-works",
            "text": "For detecting new scenes, Opencast uses the scene detection build into the FFmpeg select filter. The basic idea behind\nthis filter is to compare to consecutive frames and decide if the second frame belongs to a new scene based on the\ndifference.",
            "title": "How the video segmentation process works"
        },
        {
            "location": "/modules/videosegmentation/#what-can-be-optimized",
            "text": "The segmentation does not yield perfect results for all scenarios if always the same parameters for the FFmpeg filter\nare used. Especially for presentations that include live handwriting or small videos often way too many segments are\ncreated. In these special cases the difference between two consecutive frames is much higher than for normal\npresentation slides and these big differences happen very often, whereby many segments would be found.\nTo improve the resulting number of segments, different FFmpeg parameters are tried out and to prevent having segments\nthat are too short to be reasonably clickable, too short segments are filtered out.",
            "title": "What can be optimized"
        },
        {
            "location": "/modules/videosegmentation/#how-the-optimization-works",
            "text": "In general the optimization repeats a cycle of calling the ffmpeg filter, merging too small segments and calculating a\nnew changes threshold until the segmentation is good enough.  Additional to calling the ffmpeg function there is a filter function that merges small segments to a bigger segment or\nsplits it to the surrounding segments if the resulting segment would be too small. This can be beneficial for example\nif a video is shown in a lecture, so that the video will be only one segment and not many short segments.\nThe stability threshold is used in the filter method to determine which segments are long enough and which should be\nmerged.  First the segmentation is run with a stability threshold of 1 second and the initial changes threshold, that can be\nchanged in the options. If the segmentation or the filtered segmentation doesn't deviate more from the preferred number\nof segments than the maximum error allows, the optimization is done. If not, a new changes threshold, that should yield\nbetter results, is calculated and the segmentation is run again until the segmentation is good enough or until the\nmaximum number of cycles is reached.",
            "title": "How the Optimization works"
        },
        {
            "location": "/modules/videosegmentation/#configuration",
            "text": "The value for the frame difference as well as the minimum length for a segment, the preferred number of segments, the\nmaximum error and the maximum number of cycles can be configured in etc/org.opencastproject.videosegmenter.ffmpeg.VideoSegmenterServiceImpl.cfg .  The options that can be set are the minimum length of a segment (defaults to 60 sec).  stabilitythreshold = 60  The percentage of pixels that may change between two frames without considering them different (defaults to 0.025).  changesthreshold = 0.025  The number of segments that the segmentation optimally should yield (defaults to 30).  prefNumber = 30  The maximum error for the number of segments in percent. As soon as a segmentation with a lower error is achieved the\noptimization will be ended (defaults to 0.25).  maxError = 0.25  The maximum number of times the optimization will call the FFmpeg select filter (defaults to 3).  maxCycles = 3  The absolute maximum number of segments. If at the end of the optimization more segments than this are found, instead a\nuniform segmentation will be generated (defaults to 150).  absoluteMax = 150  The absolute minimum number of segments. If at the end of the optimization less segments than this are found, instead a\nuniform segmentation will be generated (defaults to 3).  absoluteMin = 3  This parameter controls whether the options prefNumber, absoluteMax and absoluteMin are interpreted as absolute\nsegment numbers or relative to track duration. If this is set to true, prefNumber, absoluteMax and absoluteMin will be\ninterpreted as number of segments per hour. (defaults to false)  durationDependent = false",
            "title": "Configuration"
        },
        {
            "location": "/modules/waveform/",
            "text": "Waveform Service Configuration\n\n\nThe Waveform service generates waveform images from a audio/video file.\nThese waveform images are then shown in the Admin-UI video editor.\n\n\nService Configuration\n\n\nThe Waveform service configuration file \netc/org.opencastproject.waveform.ffmpeg.WaveformServiceImpl.cfg\n provides the\nfollowing options:\n\n\njob.load.waveform = 0.5\n\n\n\nWith this value you can define the load of waveform jobs, see \njob load\n\n\nwaveform.image.width.min = 5000\n\n\n\nThis will define the minimum width of the waveform image in pixels.\n\n\nwaveform.image.width.max = 20000\n\n\n\nThis will define the maximum width of the waveform image in pixels.\n\n\nwaveform.image.width.ppm = 200\n\n\n\nThis value defines the width of the waveform image in relation to the length of the audio/video file\n(in pixels per minute).\n\n\nwaveform.image.height = 500\n\n\n\nThis will define the height of the waveform image in pixels.\n\n\nwaveform.color = black\n\n\n\nThis value defines the color of the waveform. The value must be a RGB(A) hex code or one of the predefined values,\nsee \nFFMPEG Colors\n. You can define one color per audio channel\nseparated by a whitespace.\n\n\nwaveform.split.channels = false\n\n\n\nThis boolean value defines whether multiple audio channels should be mixed in one waveform (if \nfalse\n)\nor separated one next to each other (if \ntrue\n).\n\n\nwaveform.scale = lin\n\n\n\nThis value defines the scale of the waveform. You can chose between \nlin\n for linear or \nlog\n for logarithmic scale.",
            "title": "Waveform Service"
        },
        {
            "location": "/modules/waveform/#waveform-service-configuration",
            "text": "The Waveform service generates waveform images from a audio/video file.\nThese waveform images are then shown in the Admin-UI video editor.",
            "title": "Waveform Service Configuration"
        },
        {
            "location": "/modules/waveform/#service-configuration",
            "text": "The Waveform service configuration file  etc/org.opencastproject.waveform.ffmpeg.WaveformServiceImpl.cfg  provides the\nfollowing options:  job.load.waveform = 0.5  With this value you can define the load of waveform jobs, see  job load  waveform.image.width.min = 5000  This will define the minimum width of the waveform image in pixels.  waveform.image.width.max = 20000  This will define the maximum width of the waveform image in pixels.  waveform.image.width.ppm = 200  This value defines the width of the waveform image in relation to the length of the audio/video file\n(in pixels per minute).  waveform.image.height = 500  This will define the height of the waveform image in pixels.  waveform.color = black  This value defines the color of the waveform. The value must be a RGB(A) hex code or one of the predefined values,\nsee  FFMPEG Colors . You can define one color per audio channel\nseparated by a whitespace.  waveform.split.channels = false  This boolean value defines whether multiple audio channels should be mixed in one waveform (if  false )\nor separated one next to each other (if  true ).  waveform.scale = lin  This value defines the scale of the waveform. You can chose between  lin  for linear or  log  for logarithmic scale.",
            "title": "Service Configuration"
        },
        {
            "location": "/modules/adaptivestreaming-wowza/",
            "text": "Wowza Adaptive Streaming Distribution Service\n\n\nThis is an updated version of the \ndistribution-service-streaming\n module, that is not installed by default anymore.\n\n\nEven though the default \ndistribution-service-streaming\n module included in previous releases can also\nbe used in combination with Wowza Media Server (or any other streaming servers) to stream videos in the RTMP format,\nthis refactored version also offers access to\n\nWowza's adaptive streaming capabilities\n.\n\n\nThe \ndistribution-service-streaming-wowza\n module copies the media files to the Wowza application directory\nand generates a SMIL file containing the paths to those files, grouping those with the same flavor but different\nqualities. Then, for each configured streaming protocol, it generates the adequate entries in the MediaPackage and sets\nthe necessary URLs and MIME-Types automatically.\n\n\nThe protocols supported and the transport format they use are summarized below:\n\n\n\n\nRTMP(S)-based protocols (also supported by the default \ndistribution-service-streaming\n module)\n\n\nRTMP(S):\n Adobe Flash Streaming protocol. Requires the Adobe Flash Player to be installed in the client's browser.\n\n\n\n\n\n\nHTTP(S)-based protocols, corresponding to the modern (Adaptive) Streaming Formats\n\n\nHLS:\n (Live) Streaming from Apple\n\n\nHDS:\n Dynamic Streaming from Adobe\n\n\nDASH:\n MPEG-DASH Dynamic Adaptive Streaming\n\n\nSMOOTH:\n Microsoft's Smooth Streaming\n\n\n\n\n\n\n\n\nPlease note\n: Only the protocols RTMP, HLS and DASH (with and without SSL) have been thoroughly tested.\n\n\nRequirements\n\n\nA Wowza Streaming Engine version >= 4.0 is required. Please pay special attention to the instructions re.\ncrossdomain access.\n\n\nDirectory Structure\n\n\nThe structure how this module stores the SMIL and media files is important to understand how the Wowza server must be\nconfigured to properly work with Opencast.\n\n\nThis structure always follows the same pattern:\n\n\n${org.opencastproject.streaming.directory}/<organization-id>/<channel-id>/<mediapackage-id>/<element-id>/<filename>\n\n\n\n, where:\n\n\n\n\n${org.opencastproject.streaming.directory}\n is this module's root directory, as configured in Opencast's\n  configuration (see below)\n\n\n<organization-id>\n is the identifier for the current organization (by default \nmh-default-org\n)\n\n\n<channel-id>\n is the channel identifier. Normally, the Workflow Operation determines the value of this parameter;\n  for instance, the operation \npublish-engage\n calls the Streaming Service with a hardcoded value for this property\n  of \nengage-player\n\n\n<mediapackage-id>\n, \n<element-id>\n and \n<filename>\n are different for each MediaPackageElement that this module\n  distributes.\n\n\n\n\nThe organization ID is automatically assigned based on the server's DNS name\n(\nmore info\n). Each organization (or \ntenant\n) is\nindependent from the others defined in the system. For the media distribution, that means that each organization's\nmedia content is stored in separate directories, so the streaming applications should also be different, as we will see\nbelow.\n\n\nConfiguration\n\n\n\n\n\n\nEdit the file etc/org.opencastproject.streaming.wowza.StreamingDistributionService.cfg with your preferred\nconfiguration. The contents should be self-explanatory.\n\n\n\n\n\n\nEdit \n$KARAF/etc/custom.properties\n and adjust these values to match those of your scenario:\n\n\norg.opencastproject.streaming.url=rtmp(s)://<wowza-server>/<wowza-application>\norg.opencastproject.streaming.port=<port_number>\norg.opencastproject.adaptive-streaming.url=http(s)://<wowza-server>/<wowza-application>\norg.opencastproject.adaptive-streaming.port=<port_number>\norg.opencastproject.streaming.directory=/mnt/opencast-drive/content/streams\n\n\n\nThe port numbers are only necessary when non-standard ports are used for streaming and/or adaptive-streaming. In\nmost cases, it is safe to comment them out or simply not include those properties in the file.\n\n\n\n\n\n\nRestart your Opencast server.\n\n\n\n\n\n\nInstallation on the Wowza side\n\n\n\n\nPre-requirements\n\n\n\n\n\n\nDownload/Purchase the Wowza Streaming Engine from the \nWowza Homepage\n and install it\naccording to their manuals.\n\n\n\n\n\n\nThe shared drive indicated in the \norg.opencastproject.streaming.directory\n in the \ncustom.properties\n file in\nOpencast must also be mounted in the Wowza server. \nPlease note that mount points do not necessarily match!\n (e.g.\nthe path \n/mnt/opencast-drive-content-streams\n in the Opencast server might be mounted as \n/media/opencast-streams\n in\nthe Wowza server).\n\n\n\n\n\n\nDo not forget to open your firewall on ports 1935 (RTMP), 80 (HTTP, adaptive streaming) and, if you want to use SSL,\n443.\n\n\n\n\n\n\nYou will have set your login credentials during the setup of Wowza. You will need these for the web UI.\n\n\n\n\n\n\n\n\n\n\n\n\nOpen \nhttp://<wowza-server>:8088/enginemanager\n and log in\n\n\n\n\n\n\nSelect \"Application -> Add Application\" in the top menu\n\n\n\n\n\n\nSelect \"VOD Single Server\"\n\n\n\n\n\n\nEnter a name for the new application. You \nmust\n use the same application name you have configured\nin \n$KARAF/etc/custom.properties\n (for instance: \nopencast-engage\n)\n\n\n\n\n\n\nApplication Description\n: Feel free to add a description.\n\n\n\n\n\n\nPlayback Types\n: Enable your desired streaming protocols\n\n\n\n\n\n\nOptions\n: Disable the global CORS\n\n\n\n\n\n\nContent Directory\n: Mark the checkbox \nUse the following directory\n. The directory you should input is a\n    subdirectory of the path indicated in the property \norg.opencastproject.streaming.directory\n defined in the file\n    \n$KARAF/etc/custom.properties\n. That subdirectory's name is the organization's ID (\nmh_default_org\n by default).\n\n\nFor instance, if the \norg.opencastproject.streaming.directory\n is mounted in the Wowza Server as:\n\n\n/mnt/opencast-streams\n\n\n\nthen the \nContent Directory\n for the default organization would be:\n\n\n/mnt/opencast-streams/mh_default_org\n\n\n\nIn a multitenant Opencast setup, an organization with ID \nmy_organization\n should have the \nContent Directory\n\nset to:\n\n\n/mnt/opencast-streams/my_organization\n\n\n\n\n\n\n\nOptional Settings\n\n\nOpencast HTML5 Player is able to play videos from Wowza using adaptive streaming protocols. However, some browsers may\nexperiment problems due to crossdomain issues, which means that we need to instruct Wowza to include the right\n\nAllow-Origin\n headers in its HTTP requests.\n\n\nOn the other hand, you may experiment problems with the MPEG-DASH protocol, depending on the encoding of the video\nsources.\n\n\nAll this can be configured in the \"Options\" section of the Wowza application:\n\n\n\n\nClick on the tab \"Properties\" in your application\n\n\nIf you can't see the \"Properties\" tab, go to \"Users\" > \"Edit\" > \"Preferences\" and select \"Allow access to advanced\n  properties and features\"\n\n\n\n\n\n\nScroll down the page to \"Custom\"\n\n\nClick the \"Edit\" button\n\n\n\n\nAdd the following Properties\n\n\n\n\n\n\n\n\nPath\n\n\nName\n\n\nType\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/Root/Application/HTTPStreamer\n\n\ncupertinoUserHTTPHeaders\n\n\nString\n\n\n**\n\n\n\n\n\n\n/Root/Application/HTTPStreamer\n\n\nmpegdashUserHTTPHeaders\n\n\nString\n\n\n**\n\n\n\n\n\n\n/Root/Application/HTTPStreamer\n\n\nmpegdashAdjustCTTSForFirstKeyFrameToZero\n\n\nBoolean\n\n\ntrue\n\n\n\n\n\n\n\n\n\n\nDue to some limitations in Bitbucket's Markdown parser, we can write this value within a table because it\ncontains a \"pipe\" symbol (\"|\"). The correct value for this property is:\nAccess-Control-Allow-Origin: *|Access-Control-Allow-Methods:GET, HEAD, OPTIONS\n\n\n\n\n\n\n\n\n\n\n\nDo not forget to restart the application!\n\n\n\n\n\n\nPlayers and Formats\n\n\n\n\nTheodul\n: RTMP, HLS, DASH (over HTTP and HTTPS)\n\n\nPaella\n : RTMP, RTMPS, HLS, DASH (over HTTP and HTTPS)\n\n\n\n\nEncoding Profiles\n\n\nKeep in mind that you have to adapt your encoding profiles when you want generate the videos to distribute via HLS or\nDASH. Specifically, if the videos with different qualities are not keyframe-aligned, they may not play smoothly or not\nplay at all. You can find more information\n\nhere\n.\n\n\nLimitations\n\n\nThis module is able to correctly distribute new elements incrementally. That means that if some elements in a\nmediapackage are already distributed when another \nDistribute\n operation runs, the operation should run without errors.\nHowever, partial \nRetract\n operations are discouraged and cause the remaining elements to be no longer playable.\n\n\nThe recommended procedure to retract only some elements in a mediapackage is therefore:\n\n\n\n\nCompletely retract the mediapackage\n\n\nDistribute again only the desired elements\n\n\n\n\nThe effects of this limitation are small, because the \nretract-engage\n workflow operation always retracts the whole\nMediapackage and because partial retractions seem to have little to no practical application. These can however be\nperformed by calling the corresponding REST endpoints. In such cases, users are encouraged to use the recommended\nmethod above.",
            "title": "Wowza Adaptive Streaming Distribution Service"
        },
        {
            "location": "/modules/adaptivestreaming-wowza/#wowza-adaptive-streaming-distribution-service",
            "text": "This is an updated version of the  distribution-service-streaming  module, that is not installed by default anymore.  Even though the default  distribution-service-streaming  module included in previous releases can also\nbe used in combination with Wowza Media Server (or any other streaming servers) to stream videos in the RTMP format,\nthis refactored version also offers access to Wowza's adaptive streaming capabilities .  The  distribution-service-streaming-wowza  module copies the media files to the Wowza application directory\nand generates a SMIL file containing the paths to those files, grouping those with the same flavor but different\nqualities. Then, for each configured streaming protocol, it generates the adequate entries in the MediaPackage and sets\nthe necessary URLs and MIME-Types automatically.  The protocols supported and the transport format they use are summarized below:   RTMP(S)-based protocols (also supported by the default  distribution-service-streaming  module)  RTMP(S):  Adobe Flash Streaming protocol. Requires the Adobe Flash Player to be installed in the client's browser.    HTTP(S)-based protocols, corresponding to the modern (Adaptive) Streaming Formats  HLS:  (Live) Streaming from Apple  HDS:  Dynamic Streaming from Adobe  DASH:  MPEG-DASH Dynamic Adaptive Streaming  SMOOTH:  Microsoft's Smooth Streaming     Please note : Only the protocols RTMP, HLS and DASH (with and without SSL) have been thoroughly tested.",
            "title": "Wowza Adaptive Streaming Distribution Service"
        },
        {
            "location": "/modules/adaptivestreaming-wowza/#requirements",
            "text": "A Wowza Streaming Engine version >= 4.0 is required. Please pay special attention to the instructions re.\ncrossdomain access.",
            "title": "Requirements"
        },
        {
            "location": "/modules/adaptivestreaming-wowza/#directory-structure",
            "text": "The structure how this module stores the SMIL and media files is important to understand how the Wowza server must be\nconfigured to properly work with Opencast.  This structure always follows the same pattern:  ${org.opencastproject.streaming.directory}/<organization-id>/<channel-id>/<mediapackage-id>/<element-id>/<filename>  , where:   ${org.opencastproject.streaming.directory}  is this module's root directory, as configured in Opencast's\n  configuration (see below)  <organization-id>  is the identifier for the current organization (by default  mh-default-org )  <channel-id>  is the channel identifier. Normally, the Workflow Operation determines the value of this parameter;\n  for instance, the operation  publish-engage  calls the Streaming Service with a hardcoded value for this property\n  of  engage-player  <mediapackage-id> ,  <element-id>  and  <filename>  are different for each MediaPackageElement that this module\n  distributes.   The organization ID is automatically assigned based on the server's DNS name\n( more info ). Each organization (or  tenant ) is\nindependent from the others defined in the system. For the media distribution, that means that each organization's\nmedia content is stored in separate directories, so the streaming applications should also be different, as we will see\nbelow.",
            "title": "Directory Structure"
        },
        {
            "location": "/modules/adaptivestreaming-wowza/#configuration",
            "text": "Edit the file etc/org.opencastproject.streaming.wowza.StreamingDistributionService.cfg with your preferred\nconfiguration. The contents should be self-explanatory.    Edit  $KARAF/etc/custom.properties  and adjust these values to match those of your scenario:  org.opencastproject.streaming.url=rtmp(s)://<wowza-server>/<wowza-application>\norg.opencastproject.streaming.port=<port_number>\norg.opencastproject.adaptive-streaming.url=http(s)://<wowza-server>/<wowza-application>\norg.opencastproject.adaptive-streaming.port=<port_number>\norg.opencastproject.streaming.directory=/mnt/opencast-drive/content/streams  The port numbers are only necessary when non-standard ports are used for streaming and/or adaptive-streaming. In\nmost cases, it is safe to comment them out or simply not include those properties in the file.    Restart your Opencast server.",
            "title": "Configuration"
        },
        {
            "location": "/modules/adaptivestreaming-wowza/#installation-on-the-wowza-side",
            "text": "",
            "title": "Installation on the Wowza side"
        },
        {
            "location": "/modules/adaptivestreaming-wowza/#pre-requirements",
            "text": "Download/Purchase the Wowza Streaming Engine from the  Wowza Homepage  and install it\naccording to their manuals.    The shared drive indicated in the  org.opencastproject.streaming.directory  in the  custom.properties  file in\nOpencast must also be mounted in the Wowza server.  Please note that mount points do not necessarily match!  (e.g.\nthe path  /mnt/opencast-drive-content-streams  in the Opencast server might be mounted as  /media/opencast-streams  in\nthe Wowza server).    Do not forget to open your firewall on ports 1935 (RTMP), 80 (HTTP, adaptive streaming) and, if you want to use SSL,\n443.    You will have set your login credentials during the setup of Wowza. You will need these for the web UI.       Open  http://<wowza-server>:8088/enginemanager  and log in    Select \"Application -> Add Application\" in the top menu    Select \"VOD Single Server\"    Enter a name for the new application. You  must  use the same application name you have configured\nin  $KARAF/etc/custom.properties  (for instance:  opencast-engage )    Application Description : Feel free to add a description.    Playback Types : Enable your desired streaming protocols    Options : Disable the global CORS    Content Directory : Mark the checkbox  Use the following directory . The directory you should input is a\n    subdirectory of the path indicated in the property  org.opencastproject.streaming.directory  defined in the file\n     $KARAF/etc/custom.properties . That subdirectory's name is the organization's ID ( mh_default_org  by default).  For instance, if the  org.opencastproject.streaming.directory  is mounted in the Wowza Server as:  /mnt/opencast-streams  then the  Content Directory  for the default organization would be:  /mnt/opencast-streams/mh_default_org  In a multitenant Opencast setup, an organization with ID  my_organization  should have the  Content Directory \nset to:  /mnt/opencast-streams/my_organization",
            "title": "Pre-requirements"
        },
        {
            "location": "/modules/adaptivestreaming-wowza/#optional-settings",
            "text": "Opencast HTML5 Player is able to play videos from Wowza using adaptive streaming protocols. However, some browsers may\nexperiment problems due to crossdomain issues, which means that we need to instruct Wowza to include the right Allow-Origin  headers in its HTTP requests.  On the other hand, you may experiment problems with the MPEG-DASH protocol, depending on the encoding of the video\nsources.  All this can be configured in the \"Options\" section of the Wowza application:   Click on the tab \"Properties\" in your application  If you can't see the \"Properties\" tab, go to \"Users\" > \"Edit\" > \"Preferences\" and select \"Allow access to advanced\n  properties and features\"    Scroll down the page to \"Custom\"  Click the \"Edit\" button   Add the following Properties     Path  Name  Type  Value      /Root/Application/HTTPStreamer  cupertinoUserHTTPHeaders  String  **    /Root/Application/HTTPStreamer  mpegdashUserHTTPHeaders  String  **    /Root/Application/HTTPStreamer  mpegdashAdjustCTTSForFirstKeyFrameToZero  Boolean  true      Due to some limitations in Bitbucket's Markdown parser, we can write this value within a table because it\ncontains a \"pipe\" symbol (\"|\"). The correct value for this property is: Access-Control-Allow-Origin: *|Access-Control-Allow-Methods:GET, HEAD, OPTIONS      Do not forget to restart the application!",
            "title": "Optional Settings"
        },
        {
            "location": "/modules/adaptivestreaming-wowza/#players-and-formats",
            "text": "Theodul : RTMP, HLS, DASH (over HTTP and HTTPS)  Paella  : RTMP, RTMPS, HLS, DASH (over HTTP and HTTPS)",
            "title": "Players and Formats"
        },
        {
            "location": "/modules/adaptivestreaming-wowza/#encoding-profiles",
            "text": "Keep in mind that you have to adapt your encoding profiles when you want generate the videos to distribute via HLS or\nDASH. Specifically, if the videos with different qualities are not keyframe-aligned, they may not play smoothly or not\nplay at all. You can find more information here .",
            "title": "Encoding Profiles"
        },
        {
            "location": "/modules/adaptivestreaming-wowza/#limitations",
            "text": "This module is able to correctly distribute new elements incrementally. That means that if some elements in a\nmediapackage are already distributed when another  Distribute  operation runs, the operation should run without errors.\nHowever, partial  Retract  operations are discouraged and cause the remaining elements to be no longer playable.  The recommended procedure to retract only some elements in a mediapackage is therefore:   Completely retract the mediapackage  Distribute again only the desired elements   The effects of this limitation are small, because the  retract-engage  workflow operation always retracts the whole\nMediapackage and because partial retractions seem to have little to no practical application. These can however be\nperformed by calling the corresponding REST endpoints. In such cases, users are encouraged to use the recommended\nmethod above.",
            "title": "Limitations"
        },
        {
            "location": "/modules/youtubepublication/",
            "text": "YouTube Publication Configuration\n\n\nThis page documents the configuration for Opencast module \npublication-service-youtube-v3\n.\n\n\nBefore you start\n\n\nYou need to meet these requirements to make a YouTube Publication:\n\n\n\n\nGoogle Account\n\n\nYouTube Channel to make the publication\n\n\n\n\nGoogle Developers Configuration\n\n\nBelow is a summarized version of \nGoogle's quickstart page\n.  If these\ninstructions do not work for you, or are unclear please let us know - Google has a habit of changing its configuration\npages and we don't always notice!\n\n\nCreate new Google Project\n\n\n\n\nLogin to Google account\n\n\nNavigate to the \nGoogle Developers Console\n\n\nClick \nCreate Project\n and follow the instructions\n\n\nNavigate to the \nGoogle Credentials Console\n\n\nSelect \nOAuth constent screen\n\n\nConfigure the API Consent Screen, you will need to set the Product name\n\n\nSelect \nCredentials\n\n\nSelect \nCreate Credentials\n, specifically OAuth Client ID\n\n\nSelect \nOther\n application type\n\n\n\n\nSave Client ID in JSON Format\n\n\n\n\nDownload the client information in JSON format by clicking \nDownload JSON\n\n\nThis currently looks like an arrow pointing downwards on the rightmost portion of the client id row\n\n\n\n\n\n\nSave the JSON file to \n${karaf.etc}/youtube-v3/client-secrets-youtube-v3.json\n (Usually this is\n  \netc/youtube-v3/client-secrets-youtube-v3.json\n)\n\n\n\n\nEnable API\n\n\n\n\nNaviate to the \nGoogle API Dashboard\n\n\nClick \nEnable APIs and Services\n in the navigation pane\n\n\nUse the filter to find and enable \nYouTube Data API v3\n\n\n\n\nEnable the publication service\n\n\n\n\nIn \netc/org.opencastproject.publication.youtube.YouTubeV3PublicationServiceImpl.cfg\n set \norg.opencastproject.publication.youtube.enabled=true\n\n\nUpdate the category, keywords, default privacy, and default playlist variables as required\n\n\n\n\nYouTube configuration in Opencast\n\n\nWith the JSON file created and saved previously, you have to proceed as described:\n\n\n\n\n\n\nStart Opencast server (Restart Opencast in case was running)\n\n\nNote:\n Until this service is fully configured, Opencast will not start completely. In case you\nwant to abort the configuration, you only need to delete the JSON file and restart Opencast.\n\n\n\n\n\n\nIn the command line, enter the command to view the extended status of the Opencast service:\n\n\n# systemctl status opencast -l\n\n\n\nThis command will show parts of the Opencast logs in which you should see an URL that you have to copy to a browser.\n\n\n\n\n\n\nThe web page will ask for your Google account (you have to use the account with which you created the developer\n  project earlier) followed by access settings and settings for the channel you want to publish to.\n\n\n\n\n\n\nOnce you have accepted the access, you will receive an answer like:\n\n\nReceived verification code. Closing\u2026\n\n\n\n\n\n\n\nNow verify that Opencast has received the access key and that it has been saved in\n  \ndata/opencast/youtube-v3/data-store/store.\n\n\n\n\n\n\nRestart Opencast\n\n\n\n\n\n\nActivate YouTube publication in Opencast\n\n\nOpencast can now publish to YouTube. The last step is to activate this feature. For this you have to create a new\nworkflow or modify an existing one.\n\n\n\n\n\n\nOpen the workflows \netc/opencast/workflows/ng-schedule-and-upload.xml\n and \netc/opencast/workflows/ng-publish.xml\n\n\n\n\n\n\nIn the file, modify the \n<configuration_panel>\n and enable the YouTube option, like this:\n\n\n<input id=\"publishToYouTube\" name=\"publishToYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\"\n       disabled=\"disabled\" />\n\n\n\n\n\n\n\nbecomes\n\n\n    <input id=\"publishToYouTube\" name=\"publishToYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\"/>\n\n\n\n\n\n\n\nOpen the workflows \netc/opencast/workflows/ng-retract.xml\n\n\n\n\n\n\nIn the file, modify the \n<configuration_panel>\n and enable the YouTube option, like this:\n\n\n<input id=\"retractFromYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\" disabled=\"disabled\" />\n\n\n\n\n\n\n\nbecomes\n\n\n    <input id=\"retractFromYouTube\" type=\"checkbox\" checked=\"checked\" class=\"configField\" value=\"true\" />\n\n\n\nOpencast will detect the new workflow without restart, with that you can select the new workflow with the YouTube option\nenabled.",
            "title": "YouTube Publication"
        },
        {
            "location": "/modules/youtubepublication/#youtube-publication-configuration",
            "text": "This page documents the configuration for Opencast module  publication-service-youtube-v3 .",
            "title": "YouTube Publication Configuration"
        },
        {
            "location": "/modules/youtubepublication/#before-you-start",
            "text": "You need to meet these requirements to make a YouTube Publication:   Google Account  YouTube Channel to make the publication",
            "title": "Before you start"
        },
        {
            "location": "/modules/youtubepublication/#google-developers-configuration",
            "text": "Below is a summarized version of  Google's quickstart page .  If these\ninstructions do not work for you, or are unclear please let us know - Google has a habit of changing its configuration\npages and we don't always notice!",
            "title": "Google Developers Configuration"
        },
        {
            "location": "/modules/youtubepublication/#create-new-google-project",
            "text": "Login to Google account  Navigate to the  Google Developers Console  Click  Create Project  and follow the instructions  Navigate to the  Google Credentials Console  Select  OAuth constent screen  Configure the API Consent Screen, you will need to set the Product name  Select  Credentials  Select  Create Credentials , specifically OAuth Client ID  Select  Other  application type",
            "title": "Create new Google Project"
        },
        {
            "location": "/modules/youtubepublication/#save-client-id-in-json-format",
            "text": "Download the client information in JSON format by clicking  Download JSON  This currently looks like an arrow pointing downwards on the rightmost portion of the client id row    Save the JSON file to  ${karaf.etc}/youtube-v3/client-secrets-youtube-v3.json  (Usually this is\n   etc/youtube-v3/client-secrets-youtube-v3.json )",
            "title": "Save Client ID in JSON Format"
        },
        {
            "location": "/modules/youtubepublication/#enable-api",
            "text": "Naviate to the  Google API Dashboard  Click  Enable APIs and Services  in the navigation pane  Use the filter to find and enable  YouTube Data API v3",
            "title": "Enable API"
        },
        {
            "location": "/modules/youtubepublication/#enable-the-publication-service",
            "text": "In  etc/org.opencastproject.publication.youtube.YouTubeV3PublicationServiceImpl.cfg  set  org.opencastproject.publication.youtube.enabled=true  Update the category, keywords, default privacy, and default playlist variables as required",
            "title": "Enable the publication service"
        },
        {
            "location": "/modules/youtubepublication/#youtube-configuration-in-opencast",
            "text": "With the JSON file created and saved previously, you have to proceed as described:    Start Opencast server (Restart Opencast in case was running)  Note:  Until this service is fully configured, Opencast will not start completely. In case you\nwant to abort the configuration, you only need to delete the JSON file and restart Opencast.    In the command line, enter the command to view the extended status of the Opencast service:  # systemctl status opencast -l  This command will show parts of the Opencast logs in which you should see an URL that you have to copy to a browser.    The web page will ask for your Google account (you have to use the account with which you created the developer\n  project earlier) followed by access settings and settings for the channel you want to publish to.    Once you have accepted the access, you will receive an answer like:  Received verification code. Closing\u2026    Now verify that Opencast has received the access key and that it has been saved in\n   data/opencast/youtube-v3/data-store/store.    Restart Opencast",
            "title": "YouTube configuration in Opencast"
        },
        {
            "location": "/modules/youtubepublication/#activate-youtube-publication-in-opencast",
            "text": "Opencast can now publish to YouTube. The last step is to activate this feature. For this you have to create a new\nworkflow or modify an existing one.    Open the workflows  etc/opencast/workflows/ng-schedule-and-upload.xml  and  etc/opencast/workflows/ng-publish.xml    In the file, modify the  <configuration_panel>  and enable the YouTube option, like this:  <input id=\"publishToYouTube\" name=\"publishToYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\"\n       disabled=\"disabled\" />    becomes      <input id=\"publishToYouTube\" name=\"publishToYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\"/>    Open the workflows  etc/opencast/workflows/ng-retract.xml    In the file, modify the  <configuration_panel>  and enable the YouTube option, like this:  <input id=\"retractFromYouTube\" type=\"checkbox\" class=\"configField\" value=\"true\" disabled=\"disabled\" />    becomes      <input id=\"retractFromYouTube\" type=\"checkbox\" checked=\"checked\" class=\"configField\" value=\"true\" />  Opencast will detect the new workflow without restart, with that you can select the new workflow with the YouTube option\nenabled.",
            "title": "Activate YouTube publication in Opencast"
        },
        {
            "location": "/workflowoperationhandlers/",
            "text": "Workflow Operation Handler\n\n\nIntroduction\n\n\nWorkflows are the central element to define how a media package is being processed by the Opencast services. Their\ndefinitions consist of a list of workflow operations, which basically map a piece of configuration to Opencast code:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n    ....\n    <operation\n      id=\"tag\"\n      <configurations>\n        <configuration key=\"source-flavors\">presentation/trimmed</configuration>\n        <configuration key=\"target-flavor\">presentation/tagged</configuration>\n      </configurations>\n   </operation>\n   ...\n</definition>\n\n\n\nDefault Workflow Operations\n\n\nThe following table contains the workflow operations that are available in an out-of-the-box Opencast installation:\n\n\n\n\n\n\n\n\nOperation Handler\n\n\nDescription\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\nanalyze-audio\n\n\nAnalyze first audio stream\n\n\nDocumentation\n\n\n\n\n\n\nanalyze-tracks\n\n\nAnalyze tracks in media package\n\n\nDocumentation\n\n\n\n\n\n\nanimate\n\n\nCreate animated video sequence\n\n\nDocumentation\n\n\n\n\n\n\nasset-delete\n\n\nDeletes the current mediapackage from the Archive\n\n\nDocumentation\n\n\n\n\n\n\nattach-watson-transcription\n\n\nAttaches automated transcripts to mediapackage\n\n\nDocumentation\n\n\n\n\n\n\ncleanup\n\n\nCleanup the working file repository\n\n\nDocumentation\n\n\n\n\n\n\nclone\n\n\nClone media package elements to another flavor\n\n\nDocumentation\n\n\n\n\n\n\ncomment\n\n\nAdd, resolve or delete a comment\n\n\nDocumentation\n\n\n\n\n\n\ncompose\n\n\nEncode media files using FFmpeg\n\n\nDocumentation\n\n\n\n\n\n\ncomposite\n\n\nCompose two videos on one canvas.\n\n\nDocumentation\n\n\n\n\n\n\nconcat\n\n\nConcatenate multiple video tracks into one video track\n\n\nDocumentation\n\n\n\n\n\n\nconfigure-by-dcterm\n\n\nSet workflow parameter if dublincore term matches value\n\n\nDocumentation\n\n\n\n\n\n\ncopy\n\n\nCopy media package elements to target directory\n\n\nDocumentation\n\n\n\n\n\n\ncover-image\n\n\nGenerate a cover-image containing metadata\n\n\nDocumentation\n\n\n\n\n\n\ndefaults\n\n\nApplies default workflow configuration values\n\n\nDocumentation\n\n\n\n\n\n\ndemux\n\n\nDemuxes streams to multiple output files\n\n\nDocumentation\n\n\n\n\n\n\nduplicate-event\n\n\nCreate an event by cloning an existing one\n\n\nDocumentation\n\n\n\n\n\n\neditor\n\n\nWaiting for user to review, then cut video based on edit-list\n\n\nDocumentation\n\n\n\n\n\n\nencode\n\n\nEncode media files to differents formats in parallel\n\n\nDocumentation\n\n\n\n\n\n\nerror-resolution\n\n\nInternal operation to pause a workflow in error\n\n\nDocumentation\n\n\n\n\n\n\nexecute-many\n\n\nExecute a command for each matching element in a MediaPackage\n\n\nDocumentation\n\n\n\n\n\n\nexecute-once\n\n\nExecute a command for a MediaPackage\n\n\nDocumentation\n\n\n\n\n\n\nexport-wf-properties\n\n\nExport workflow properties\n\n\nDocumentation\n\n\n\n\n\n\nextract-text\n\n\nExtracting text from presentation segments\n\n\nDocumentation\n\n\n\n\n\n\nfailing\n\n\nOperations that always fails\n\n\nDocumentation\n\n\n\n\n\n\nhttp-notify\n\n\nNotifies an HTTP endpoint about the process of the workflow\n\n\nDocumentation\n\n\n\n\n\n\nimage\n\n\nExtract images from a video using FFmpeg\n\n\nDocumentation\n\n\n\n\n\n\nimage-convert\n\n\nConvert images using FFmpeg\n\n\nDocumentation\n\n\n\n\n\n\nimage-to-video\n\n\nCreate a video track from a source image\n\n\nDocumentation\n\n\n\n\n\n\nimport-wf-properties\n\n\nImport workflow properties\n\n\nDocumentation\n\n\n\n\n\n\nincident\n\n\nTesting incidents on a dummy job\n\n\nDocumentation\n\n\n\n\n\n\ninclude\n\n\nInclude workflow definition in current workflow\n\n\nDocumentation\n\n\n\n\n\n\ningest-download\n\n\nDownload files from external URL for ingest\n\n\nDocumentation\n\n\n\n\n\n\ninspect\n\n\nInspect the media (check if it is valid)\n\n\nDocumentation\n\n\n\n\n\n\nlog\n\n\nLog workflow status\n\n\nDocumentation\n\n\n\n\n\n\nmultiencode\n\n\nEncode to multiple profiles in one operation\n\n\nDocumentation\n\n\n\n\n\n\nnormalize-audio\n\n\nNormalize first audio stream\n\n\nDocumentation\n\n\n\n\n\n\npartial-import\n\n\nImport partial tracks and process according to a SMIL document\n\n\nDocumentation\n\n\n\n\n\n\npost-mediapackage\n\n\nSend mediapackage to remote service\n\n\nDocumentation\n\n\n\n\n\n\nprepare-av\n\n\nPreparing audio and video work versions\n\n\nDocumentation\n\n\n\n\n\n\nprobe-resolution\n\n\nSet workflow instance variables based on video resolution\n\n\nDocumentation\n\n\n\n\n\n\nprocess-smil\n\n\nEdit and Encode media defined by a SMIL file\n\n\nDocumentation\n\n\n\n\n\n\npublish-aws\n\n\nDistribute and publish media to Amazon S3 and Cloudfront\n\n\nDocumentation\n\n\n\n\n\n\npublish-configure\n\n\nDistribute and publish media to the configured publication\n\n\nDocumentation\n\n\n\n\n\n\npublish-engage\n\n\nDistribute and publish media to the engage player\n\n\nDocumentation\n\n\n\n\n\n\npublish-oaipmh\n\n\nDistribute and publish media to a OAI-PMH repository\n\n\nDocumentation\n\n\n\n\n\n\npublish-youtube\n\n\nDistribute and publish media to YouTube\n\n\nDocumentation\n\n\n\n\n\n\nrepublish-oaipmh\n\n\nUpdate media in a OAI-PMH repository\n\n\nDocumentation\n\n\n\n\n\n\nretract-aws\n\n\nRetracts media from AWS S3 and Cloudfront publication\n\n\nDocumentation\n\n\n\n\n\n\nretract-configure\n\n\nRetracts media from configured publication\n\n\nDocumentation\n\n\n\n\n\n\nretract-engage\n\n\nRetracts media from Opencast Media Module publication\n\n\nDocumentation\n\n\n\n\n\n\nretract-oaipmh\n\n\nRetracts media from a OAI-PMH repository\n\n\nDocumentation\n\n\n\n\n\n\nretract-youtube\n\n\nRetracts media from YouTube\n\n\nDocumentation\n\n\n\n\n\n\nsegment-video\n\n\nExtracting segments from presentation\n\n\nDocumentation\n\n\n\n\n\n\nsegmentpreviews\n\n\nExtract segment images from a video using FFmpeg\n\n\nDocumentation\n\n\n\n\n\n\nselect-streams\n\n\nSelect streams for further processing\n\n\nDocumentation\n\n\n\n\n\n\nsend-email\n\n\nSends email notifications at any part of a workflow\n\n\nDocumentation\n\n\n\n\n\n\nseries\n\n\nApply series to the mediapackage\n\n\nDocumentation\n\n\n\n\n\n\nsilence\n\n\nSilence detection on audio of the mediapackage\n\n\nDocumentation\n\n\n\n\n\n\nsnapshot\n\n\nArchive the current state of the mediapackage\n\n\nDocumentation\n\n\n\n\n\n\nstart-watson-transcription\n\n\nStarts automated transcription provided by IBM Watson\n\n\nDocumentation\n\n\n\n\n\n\nstart-workflow\n\n\nStart a new workflow for given media package ID\n\n\nDocumentation\n\n\n\n\n\n\ntag\n\n\nModify the tag sets of media package elements\n\n\nDocumentation\n\n\n\n\n\n\ntag-by-dcterm\n\n\nModify the tags if dublincore term matches value\n\n\nDocumentation\n\n\n\n\n\n\ntheme\n\n\nMake settings of themes available to processing\n\n\nDocumentation\n\n\n\n\n\n\ntimelinepreviews\n\n\nCreate a preview image stream from a given video track\n\n\nDocumentation\n\n\n\n\n\n\nwaveform\n\n\nCreate a waveform image of the audio of the mediapackage\n\n\nDocumentation\n\n\n\n\n\n\nzip\n\n\nCreate zipped archive of the current state of the mediapackage\n\n\nDocumentation",
            "title": "Overview"
        },
        {
            "location": "/workflowoperationhandlers/#workflow-operation-handler",
            "text": "",
            "title": "Workflow Operation Handler"
        },
        {
            "location": "/workflowoperationhandlers/#introduction",
            "text": "Workflows are the central element to define how a media package is being processed by the Opencast services. Their\ndefinitions consist of a list of workflow operations, which basically map a piece of configuration to Opencast code:  <definition xmlns=\"http://workflow.opencastproject.org\">\n    ....\n    <operation\n      id=\"tag\"\n      <configurations>\n        <configuration key=\"source-flavors\">presentation/trimmed</configuration>\n        <configuration key=\"target-flavor\">presentation/tagged</configuration>\n      </configurations>\n   </operation>\n   ...\n</definition>",
            "title": "Introduction"
        },
        {
            "location": "/workflowoperationhandlers/#default-workflow-operations",
            "text": "The following table contains the workflow operations that are available in an out-of-the-box Opencast installation:     Operation Handler  Description  Details      analyze-audio  Analyze first audio stream  Documentation    analyze-tracks  Analyze tracks in media package  Documentation    animate  Create animated video sequence  Documentation    asset-delete  Deletes the current mediapackage from the Archive  Documentation    attach-watson-transcription  Attaches automated transcripts to mediapackage  Documentation    cleanup  Cleanup the working file repository  Documentation    clone  Clone media package elements to another flavor  Documentation    comment  Add, resolve or delete a comment  Documentation    compose  Encode media files using FFmpeg  Documentation    composite  Compose two videos on one canvas.  Documentation    concat  Concatenate multiple video tracks into one video track  Documentation    configure-by-dcterm  Set workflow parameter if dublincore term matches value  Documentation    copy  Copy media package elements to target directory  Documentation    cover-image  Generate a cover-image containing metadata  Documentation    defaults  Applies default workflow configuration values  Documentation    demux  Demuxes streams to multiple output files  Documentation    duplicate-event  Create an event by cloning an existing one  Documentation    editor  Waiting for user to review, then cut video based on edit-list  Documentation    encode  Encode media files to differents formats in parallel  Documentation    error-resolution  Internal operation to pause a workflow in error  Documentation    execute-many  Execute a command for each matching element in a MediaPackage  Documentation    execute-once  Execute a command for a MediaPackage  Documentation    export-wf-properties  Export workflow properties  Documentation    extract-text  Extracting text from presentation segments  Documentation    failing  Operations that always fails  Documentation    http-notify  Notifies an HTTP endpoint about the process of the workflow  Documentation    image  Extract images from a video using FFmpeg  Documentation    image-convert  Convert images using FFmpeg  Documentation    image-to-video  Create a video track from a source image  Documentation    import-wf-properties  Import workflow properties  Documentation    incident  Testing incidents on a dummy job  Documentation    include  Include workflow definition in current workflow  Documentation    ingest-download  Download files from external URL for ingest  Documentation    inspect  Inspect the media (check if it is valid)  Documentation    log  Log workflow status  Documentation    multiencode  Encode to multiple profiles in one operation  Documentation    normalize-audio  Normalize first audio stream  Documentation    partial-import  Import partial tracks and process according to a SMIL document  Documentation    post-mediapackage  Send mediapackage to remote service  Documentation    prepare-av  Preparing audio and video work versions  Documentation    probe-resolution  Set workflow instance variables based on video resolution  Documentation    process-smil  Edit and Encode media defined by a SMIL file  Documentation    publish-aws  Distribute and publish media to Amazon S3 and Cloudfront  Documentation    publish-configure  Distribute and publish media to the configured publication  Documentation    publish-engage  Distribute and publish media to the engage player  Documentation    publish-oaipmh  Distribute and publish media to a OAI-PMH repository  Documentation    publish-youtube  Distribute and publish media to YouTube  Documentation    republish-oaipmh  Update media in a OAI-PMH repository  Documentation    retract-aws  Retracts media from AWS S3 and Cloudfront publication  Documentation    retract-configure  Retracts media from configured publication  Documentation    retract-engage  Retracts media from Opencast Media Module publication  Documentation    retract-oaipmh  Retracts media from a OAI-PMH repository  Documentation    retract-youtube  Retracts media from YouTube  Documentation    segment-video  Extracting segments from presentation  Documentation    segmentpreviews  Extract segment images from a video using FFmpeg  Documentation    select-streams  Select streams for further processing  Documentation    send-email  Sends email notifications at any part of a workflow  Documentation    series  Apply series to the mediapackage  Documentation    silence  Silence detection on audio of the mediapackage  Documentation    snapshot  Archive the current state of the mediapackage  Documentation    start-watson-transcription  Starts automated transcription provided by IBM Watson  Documentation    start-workflow  Start a new workflow for given media package ID  Documentation    tag  Modify the tag sets of media package elements  Documentation    tag-by-dcterm  Modify the tags if dublincore term matches value  Documentation    theme  Make settings of themes available to processing  Documentation    timelinepreviews  Create a preview image stream from a given video track  Documentation    waveform  Create a waveform image of the audio of the mediapackage  Documentation    zip  Create zipped archive of the current state of the mediapackage  Documentation",
            "title": "Default Workflow Operations"
        },
        {
            "location": "/workflowoperationhandlers/retry-strategies/",
            "text": "Retry Strategies\n\n\nAn operation can have a retry-strategy specified to define what will happen if the operation \nfails\n:\n\n\n\n\n\n\n\n\nStrategy\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nnone\n\n\nThis is the default. No action taken. If the operation fails, the behavior will depend on the fail-on-error parameter. If fail-on-error=\"true\", the workflow will fail. If fail-on-error=\"false\", the next operation will be executed.\n\n\n\n\n\n\nretry\n\n\nIf the operation fails, it will be re-tried until the number of attempts reaches max-attempts, which defaults to 2.\n\n\n\n\n\n\nhold\n\n\nIf the operation fails, the workflow will be paused, until the user takes an action. The user can choose to \nRetry\n the operation or \nAbort\n it. The user can retry the operation many times, until the number of attempts reaches max-attempts. If the user aborts the operation, the behavior will depend on the fail-on-error parameter as described above.\n\n\n\n\n\n\n\n\nExample 1\n: No retry\n\n\nIf the operation1 fails, the workflow will fail because fail-on-error=\"true\".\n\n\n<operation\n  id=\"operation1\"\n  retry-strategy=\"none\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Operation One\">\n</operation>\n\n\n\n\nExample 2\n: Automatic retry\n\n\nIf operation2 fails, it will be retried until it succeeds or until it has failed 5 times.\n\n\n<operation\n  id=\"operation2\"\n  retry-strategy=\"retry\"\n  max-attempts=\"5\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Operation Two\">\n</operation>\n\n\n\n\nExample 3\n: Manual retry\n\n\nIf operation3 fails, the user can choose between Retry or Abort. The user can manually retry the operation 4 times.\n\n\n<operation\n  id=\"operation3\"\n  retry-strategy=\"hold\"\n  max-attempts=\"5\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Operation Three\">\n</operation>",
            "title": "Retry Strategies"
        },
        {
            "location": "/workflowoperationhandlers/retry-strategies/#retry-strategies",
            "text": "An operation can have a retry-strategy specified to define what will happen if the operation  fails :     Strategy  Description      none  This is the default. No action taken. If the operation fails, the behavior will depend on the fail-on-error parameter. If fail-on-error=\"true\", the workflow will fail. If fail-on-error=\"false\", the next operation will be executed.    retry  If the operation fails, it will be re-tried until the number of attempts reaches max-attempts, which defaults to 2.    hold  If the operation fails, the workflow will be paused, until the user takes an action. The user can choose to  Retry  the operation or  Abort  it. The user can retry the operation many times, until the number of attempts reaches max-attempts. If the user aborts the operation, the behavior will depend on the fail-on-error parameter as described above.     Example 1 : No retry  If the operation1 fails, the workflow will fail because fail-on-error=\"true\".  <operation\n  id=\"operation1\"\n  retry-strategy=\"none\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Operation One\">\n</operation>  Example 2 : Automatic retry  If operation2 fails, it will be retried until it succeeds or until it has failed 5 times.  <operation\n  id=\"operation2\"\n  retry-strategy=\"retry\"\n  max-attempts=\"5\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Operation Two\">\n</operation>  Example 3 : Manual retry  If operation3 fails, the user can choose between Retry or Abort. The user can manually retry the operation 4 times.  <operation\n  id=\"operation3\"\n  retry-strategy=\"hold\"\n  max-attempts=\"5\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Operation Three\">\n</operation>",
            "title": "Retry Strategies"
        },
        {
            "location": "/workflowoperationhandlers/analyze-tracks-woh/",
            "text": "AnalyzeTracksWorkflowOperationHandler\n\n\nDescription\n\n\nThe AnalyzeTracksWorkflowOperationHandler analyzes specified tracks in the mediapackage and sets workflow instance\nvariables based on the tracks audio and video properties. These variables can then be used to control if workflow\noperations should be executed.\n\n\nNote that this operation should be preceded by the inspect workflow operation handler.\n\n\nFor all tracks matching the flavor specified by the mandatory configuration key \nsource-flavor\n, the following workflow\ninstance variables may be set:\n\n\n\n\n\n\n\n\nName\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nflavor\n_media\n\n\npresenter_source_media=true\n\n\nTrack with specific favor exists\n\n\n\n\n\n\nflavor\n_audio\n\n\npresenter_source_audio=true\n\n\nTrack contains at least one audio stream\n\n\n\n\n\n\nflavor\n_video\n\n\npresenter_source_video=true\n\n\nTrack contains at least one video stream\n\n\n\n\n\n\nflavor\n_resolution_x\n\n\npresenter_source_resolution_x=1280\n\n\nHorizontal resolution of the video stream\n\n\n\n\n\n\nflavor\n_resolution_y\n\n\npresenter_source_resolution_y=720\n\n\nVertical resolution of the video stream\n\n\n\n\n\n\nflavor\n_aspect\n\n\npresenter_source_aspect=4/3\n\n\nExact aspect ratio of the video stream\n\n\n\n\n\n\nflavor\n_aspect_snap\n\n\npresenter_source_aspect_snap=4/3\n\n\nNearest specified aspect ratio of the video\n\n\n\n\n\n\nflavor\n_framerate\n\n\npresenter_source_framerate=30.0\n\n\nFramerate of the video stream\n\n\n\n\n\n\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor*\n\n\npresentation/work\n\n\nThe \"flavor\" of the track to use as a source input\n\n\n\n\n\n\naspect-ratio\n\n\n4/3,16/9\n\n\nSnap to these aspect ratios if specified\n\n\n\n\n\n\nfail-no-tracks\n\n\nfalse\n\n\nFail if flavor matches no tracks (Default: false)\n\n\n\n\n\n\n\n\n* mandatory configuration key\n\n\nNote that if there are multiple video streams with one flavor, only the information from the last video stream are\ntaken.\n\n\nSnap to Aspect Ratio\n\n\nSnap-to-aspect can be used to deal with slightly off resolutions.  Given an SAR of 1, for example, a video with the\nresolution of 640x481 pixels has almost an aspect ration of 4/3, but is 1 pixel too wide. For special encoding options\nor cover generation, it would still be reasonable to use the 4/3 settings. If 4/3 is listed in the \naspect-ratio\n\noption, \n\u2026_aspect_snap\n would be set to 4/3.\n\n\nOperation Example\n\n\n<operation\n  id=\"analyze-tracks\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Analyze tracks in media package and set control variables\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/source</configuration>\n    <configuration key=\"aspect-ratio\">4/3,16/9</configuration>\n  </configurations>\n</operation>\n\n\n\nIf a video track with a resolution of 1280x720 and an included audio stream is passed to this operation as\n\npresentiation/source\n, the resulting variables would be:\n\n\npresentation_source_aspect=16/9\npresentation_source_aspect_snap=16/9\npresentation_source_audio=true\npresentation_source_media=true\npresentation_source_resolution_x=1280\npresentation_source_resolution_y=720\npresentation_source_video=true\npresentation_source_framerate=30.0",
            "title": "Analyze Tracks"
        },
        {
            "location": "/workflowoperationhandlers/analyze-tracks-woh/#analyzetracksworkflowoperationhandler",
            "text": "",
            "title": "AnalyzeTracksWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/analyze-tracks-woh/#description",
            "text": "The AnalyzeTracksWorkflowOperationHandler analyzes specified tracks in the mediapackage and sets workflow instance\nvariables based on the tracks audio and video properties. These variables can then be used to control if workflow\noperations should be executed.  Note that this operation should be preceded by the inspect workflow operation handler.  For all tracks matching the flavor specified by the mandatory configuration key  source-flavor , the following workflow\ninstance variables may be set:     Name  Example  Description      flavor _media  presenter_source_media=true  Track with specific favor exists    flavor _audio  presenter_source_audio=true  Track contains at least one audio stream    flavor _video  presenter_source_video=true  Track contains at least one video stream    flavor _resolution_x  presenter_source_resolution_x=1280  Horizontal resolution of the video stream    flavor _resolution_y  presenter_source_resolution_y=720  Vertical resolution of the video stream    flavor _aspect  presenter_source_aspect=4/3  Exact aspect ratio of the video stream    flavor _aspect_snap  presenter_source_aspect_snap=4/3  Nearest specified aspect ratio of the video    flavor _framerate  presenter_source_framerate=30.0  Framerate of the video stream",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/analyze-tracks-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      source-flavor*  presentation/work  The \"flavor\" of the track to use as a source input    aspect-ratio  4/3,16/9  Snap to these aspect ratios if specified    fail-no-tracks  false  Fail if flavor matches no tracks (Default: false)     * mandatory configuration key  Note that if there are multiple video streams with one flavor, only the information from the last video stream are\ntaken.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/analyze-tracks-woh/#snap-to-aspect-ratio",
            "text": "Snap-to-aspect can be used to deal with slightly off resolutions.  Given an SAR of 1, for example, a video with the\nresolution of 640x481 pixels has almost an aspect ration of 4/3, but is 1 pixel too wide. For special encoding options\nor cover generation, it would still be reasonable to use the 4/3 settings. If 4/3 is listed in the  aspect-ratio \noption,  \u2026_aspect_snap  would be set to 4/3.",
            "title": "Snap to Aspect Ratio"
        },
        {
            "location": "/workflowoperationhandlers/analyze-tracks-woh/#operation-example",
            "text": "<operation\n  id=\"analyze-tracks\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Analyze tracks in media package and set control variables\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/source</configuration>\n    <configuration key=\"aspect-ratio\">4/3,16/9</configuration>\n  </configurations>\n</operation>  If a video track with a resolution of 1280x720 and an included audio stream is passed to this operation as presentiation/source , the resulting variables would be:  presentation_source_aspect=16/9\npresentation_source_aspect_snap=16/9\npresentation_source_audio=true\npresentation_source_media=true\npresentation_source_resolution_x=1280\npresentation_source_resolution_y=720\npresentation_source_video=true\npresentation_source_framerate=30.0",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/",
            "text": "AnalyzeAudioWorkflowOperationHandler\n\n\nDescription\n\n\nThe AnalyzeAudioiWorkflowOperationHandler analyzes the first audio stream of a video or audio track through SoX\n(http://sox.sourceforge.net/) and writes the result back to the given track.\n\n\nThis workflow operation handler can be used with audio and/or video files. At least one audio stream must be available\notherwise nothing happens. Here are the internal steps done by the different inputs:\n\n\nUsed with Audio only file (forceTranscode is deactivated):\n\n\n\n\nAnalyze the given audio file with SoX\n\n\nWrite analyzed audio metadata back to the given track's mediapackage.\n\n\n\n\nUsed with Video file or with Audio only file with forceTranscode activated:\n\n\n\n\nExtract audio file encoded as FLAC audio and save it temporary in a collection\n\n\nAnalyze the previous encoded audio file with SoX\n\n\nWrite analyzed audio metadata back to the given track's mediapackage.\n\n\nDelete the temporary encoded FLAC audio file\n\n\n\n\nExample result track:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<track type=\"presentation/audio\" id=\"audio\">\n  <mimetype>video/x-flac</mimetype>\n  <tags />\n  <url>fooVideo.flac</url>\n  <checksum type=\"md5\">46cb2e9df2e73756b0d96c33b1aaf055</checksum>\n  <duration>65680</duration>\n  <audio id=\"audio-1\">\n    <device />\n    <encoder type=\"ADPCM\" />\n    <bitdepth>16</bitdepth>\n    <channels>2</channels>\n    <bitrate>62500.0</bitrate>\n    <peakleveldb>-30</peakleveldb> <!-- NEW -->\n    <rmsleveldb>-20</rmsleveldb> <!-- NEW -->\n    <rmspeakdb>-10</rmspeakdb> <!-- NEW -->\n  </audio>\n</track>\n\n\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"presentation/work,presenter/work\"\n\n\nThe \"flavors\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor\n\n\n\"presentation/work\"\n\n\nThe \"flavor\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags\n\n\n\"engage,atom,rss\"\n\n\nThe \"tag\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nforce-transcode\n\n\n\"true\" or \"false\"\n\n\nWhether to force transcoding the audio stream\n\n\n\n\n\n\n\n\n(This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format)\n\n\nFALSE\n\n\n\n\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"analyze-audio\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Analyze audio stream\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"force-transcode\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Analyze Audio"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#analyzeaudioworkflowoperationhandler",
            "text": "",
            "title": "AnalyzeAudioWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#description",
            "text": "The AnalyzeAudioiWorkflowOperationHandler analyzes the first audio stream of a video or audio track through SoX\n(http://sox.sourceforge.net/) and writes the result back to the given track.  This workflow operation handler can be used with audio and/or video files. At least one audio stream must be available\notherwise nothing happens. Here are the internal steps done by the different inputs:",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#used-with-audio-only-file-forcetranscode-is-deactivated",
            "text": "Analyze the given audio file with SoX  Write analyzed audio metadata back to the given track's mediapackage.",
            "title": "Used with Audio only file (forceTranscode is deactivated):"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#used-with-video-file-or-with-audio-only-file-with-forcetranscode-activated",
            "text": "Extract audio file encoded as FLAC audio and save it temporary in a collection  Analyze the previous encoded audio file with SoX  Write analyzed audio metadata back to the given track's mediapackage.  Delete the temporary encoded FLAC audio file   Example result track:  <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<track type=\"presentation/audio\" id=\"audio\">\n  <mimetype>video/x-flac</mimetype>\n  <tags />\n  <url>fooVideo.flac</url>\n  <checksum type=\"md5\">46cb2e9df2e73756b0d96c33b1aaf055</checksum>\n  <duration>65680</duration>\n  <audio id=\"audio-1\">\n    <device />\n    <encoder type=\"ADPCM\" />\n    <bitdepth>16</bitdepth>\n    <channels>2</channels>\n    <bitrate>62500.0</bitrate>\n    <peakleveldb>-30</peakleveldb> <!-- NEW -->\n    <rmsleveldb>-20</rmsleveldb> <!-- NEW -->\n    <rmspeakdb>-10</rmspeakdb> <!-- NEW -->\n  </audio>\n</track>",
            "title": "Used with Video file or with Audio only file with forceTranscode activated:"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  \"presentation/work,presenter/work\"  The \"flavors\" of the track to use as a source input  EMPTY    source-flavor  \"presentation/work\"  The \"flavor\" of the track to use as a source input  EMPTY    source-tags  \"engage,atom,rss\"  The \"tag\" of the track to use as a source input  EMPTY    force-transcode  \"true\" or \"false\"  Whether to force transcoding the audio stream     (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format)  FALSE",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#operation-example",
            "text": "<operation\n  id=\"analyze-audio\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Analyze audio stream\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"force-transcode\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/animate-woh/",
            "text": "Animate Workflow Operation\n\n\nID: \nanimate\n\n\nDescription\n\n\nThe animate operation can be used to generate an animated video clip using \nSynfig\n. It can\nautomatically including episode and series metadata (e.g. the title) into the animation. For example, this can be used\nto automatically generate custom intro videos.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nrequired\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nanimation-files\n\n\nyes\n\n\nThe source animation file to use\n\n\n\n\n\n\ntarget-flavor\n\n\nyes\n\n\nFlavor of the generated video\n\n\n\n\n\n\nwidth\n\n\nno\n\n\nWidth of the generated video\n\n\n\n\n\n\nheight\n\n\nno\n\n\nHeight of the generated video\n\n\n\n\n\n\nfps\n\n\nno\n\n\nFPS of the generated video\n\n\n\n\n\n\ncmd-args\n\n\nno\n\n\nCustom synfig arguments. Will override all arguments except input and output file\n\n\n\n\n\n\ntarget-tags\n\n\nno\n\n\nTags for the generated video\n\n\n\n\n\n\n\n\nSynfig Files\n\n\nSynfig animation files used for input must be saved uncompressed or the metadata replacement will not work. Uncompressed\nfiles usually have the file extension \n.sif\n and \nnot\n \n.sifz\n.\n\n\nMetadata Replacements\n\n\nYou can use all metadata fields present in the episode and series DublinCore catalogs of an event. In SynfigStudio, just\nuse placeholders of the following form:\n\n\n'{{' ['series' | 'episode'] '.' DC-FIELD '}}'\n\n\n\nHere are some common examples:\n\n\n\n\n{{episode.title}}\n\n\n{{episode.creator}}\n\n\n{{series.title}}\n\n\n\n\nOperation Examples\n\n\n<operation\n  id=\"animate\"\n  description=\"Create animated video clip\">\n  <configurations>\n    <configuration key=\"animation-file\">/path/to/animation.sif</configuration>\n    <configuration key=\"target-flavor\">presentation/intro</configuration>\n    <configuration key=\"target-tags\">archive</configuration>\n  </configurations>\n</operation>",
            "title": "Animate"
        },
        {
            "location": "/workflowoperationhandlers/animate-woh/#animate-workflow-operation",
            "text": "ID:  animate",
            "title": "Animate Workflow Operation"
        },
        {
            "location": "/workflowoperationhandlers/animate-woh/#description",
            "text": "The animate operation can be used to generate an animated video clip using  Synfig . It can\nautomatically including episode and series metadata (e.g. the title) into the animation. For example, this can be used\nto automatically generate custom intro videos.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/animate-woh/#parameter-table",
            "text": "configuration keys  required  description      animation-files  yes  The source animation file to use    target-flavor  yes  Flavor of the generated video    width  no  Width of the generated video    height  no  Height of the generated video    fps  no  FPS of the generated video    cmd-args  no  Custom synfig arguments. Will override all arguments except input and output file    target-tags  no  Tags for the generated video",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/animate-woh/#synfig-files",
            "text": "Synfig animation files used for input must be saved uncompressed or the metadata replacement will not work. Uncompressed\nfiles usually have the file extension  .sif  and  not   .sifz .",
            "title": "Synfig Files"
        },
        {
            "location": "/workflowoperationhandlers/animate-woh/#metadata-replacements",
            "text": "You can use all metadata fields present in the episode and series DublinCore catalogs of an event. In SynfigStudio, just\nuse placeholders of the following form:  '{{' ['series' | 'episode'] '.' DC-FIELD '}}'  Here are some common examples:   {{episode.title}}  {{episode.creator}}  {{series.title}}",
            "title": "Metadata Replacements"
        },
        {
            "location": "/workflowoperationhandlers/animate-woh/#operation-examples",
            "text": "<operation\n  id=\"animate\"\n  description=\"Create animated video clip\">\n  <configurations>\n    <configuration key=\"animation-file\">/path/to/animation.sif</configuration>\n    <configuration key=\"target-flavor\">presentation/intro</configuration>\n    <configuration key=\"target-tags\">archive</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Examples"
        },
        {
            "location": "/workflowoperationhandlers/snapshot-woh/",
            "text": "AssetManagerSnapshotWorkflowOperationHandler\n\n\nDescription\n\n\nThe snapshot operation allows you to take a new, versioned snapshot of a media package which is put into the asset\nmanager.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-tags\n\n\ntext\n\n\nComma separated list of tags. Specifies which media should be the source of a snapshop.\n\n\n\n\n\n\nsource-flavors\n\n\npresenter/source\n\n\nComma separated list of flavors. Specifies which media should be the source of a snapshot.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"snapshot\"\n  description=\"Archiving\">\n  <configurations>\n    <configuration key=\"source-tags\">archive</configuration>\n  </configurations>\n</operation>",
            "title": "Asset Snapshot"
        },
        {
            "location": "/workflowoperationhandlers/snapshot-woh/#assetmanagersnapshotworkflowoperationhandler",
            "text": "",
            "title": "AssetManagerSnapshotWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/snapshot-woh/#description",
            "text": "The snapshot operation allows you to take a new, versioned snapshot of a media package which is put into the asset\nmanager.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/snapshot-woh/#parameter-table",
            "text": "configuration keys  example  description      source-tags  text  Comma separated list of tags. Specifies which media should be the source of a snapshop.    source-flavors  presenter/source  Comma separated list of flavors. Specifies which media should be the source of a snapshot.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/snapshot-woh/#operation-example",
            "text": "<operation\n  id=\"snapshot\"\n  description=\"Archiving\">\n  <configurations>\n    <configuration key=\"source-tags\">archive</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/asset-delete-woh/",
            "text": "AssetManagerDeleteWorkflowOperationHandler\n\n\nDescription\n\n\nThe delete handler is responsible for deleting an episode, identified by the workflow\u2019s current media package, from the\nasset manager.\n\n\nThe handler does not take any parameters. The episode to delete is already identified by the media package.\n\n\nOperation Example\n\n\n<operation\n  id=\"asset-delete\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Delete from AssetManager\">\n</operation>",
            "title": "Asset Delete"
        },
        {
            "location": "/workflowoperationhandlers/asset-delete-woh/#assetmanagerdeleteworkflowoperationhandler",
            "text": "",
            "title": "AssetManagerDeleteWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/asset-delete-woh/#description",
            "text": "The delete handler is responsible for deleting an episode, identified by the workflow\u2019s current media package, from the\nasset manager.  The handler does not take any parameters. The episode to delete is already identified by the media package.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/asset-delete-woh/#operation-example",
            "text": "<operation\n  id=\"asset-delete\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Delete from AssetManager\">\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/attach-watson-transcription-woh/",
            "text": "Attach Watson Transcription\n\n\nDescription\n\n\nThe Attach Watson Transcription converts the results file received from the IBM Watson Speech-to-Text service in json\nformat, converts it to the desired caption format, and adds it to the media package.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\ndescription\n\n\ndefault value\n\n\nexample\n\n\n\n\n\n\n\n\n\n\ntranscription-job-id\n\n\nThis is filled out by the transcription service when starting the workflow.\n\n\nEMPTY\n\n\nShould always be \"${transcriptionJobId}\"\n\n\n\n\n\n\ntarget-flavor\n\n\nThe flavor of the caption/transcription file generated. Mandatory only if target-caption-format not informed.\n\n\ncaptions/\ntarget-caption-format\n+\nlanguage\n\n\ncaptions/vtt+en\n\n\n\n\n\n\ntarget-tag\n\n\nThe tag to apply to the caption/transcription file generated. Optional.\n\n\nEMPTY\n\n\narchive\n\n\n\n\n\n\ntarget-caption-format\n\n\nThe caption format to be generated. Optional. If not entered, the raw resulting file will be attached to the media package with the flavor \ntarget-flavor\n.\n\n\nEMPTY\n\n\nvtt\n\n\n\n\n\n\n\n\nExample\n\n\n<!-- Attach caption/transcript -->\n<operation id=\"attach-watson-transcription\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Attach captions/transcription\">\n  <configurations>\n    <!-- This is filled out by the transcription service when starting this workflow so just use this as is -->\n    <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration>\n    <configuration key=\"target-tag\">archive</configuration>\n    <!-- Caption generated will have the default flavor based on the target-caption-format and language e.g. captions/vtt+en -->\n    <configuration key=\"target-caption-format\">vtt</configuration>\n    <configuration key=\"target-tag\">engage-download</configuration>\n  </configurations>\n</operation>\n\n<!-- Merge caption/transcript to existing publication and republish -->\n<operation id=\"publish-engage\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Distribute and publish to engage server\">\n  <configurations>\n    <configuration key=\"download-source-tags\">engage-download</configuration>\n    <configuration key=\"strategy\">merge</configuration>\n    <configuration key=\"check-availability\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Attach Watson Transcription"
        },
        {
            "location": "/workflowoperationhandlers/attach-watson-transcription-woh/#attach-watson-transcription",
            "text": "",
            "title": "Attach Watson Transcription"
        },
        {
            "location": "/workflowoperationhandlers/attach-watson-transcription-woh/#description",
            "text": "The Attach Watson Transcription converts the results file received from the IBM Watson Speech-to-Text service in json\nformat, converts it to the desired caption format, and adds it to the media package.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/attach-watson-transcription-woh/#parameter-table",
            "text": "configuration keys  description  default value  example      transcription-job-id  This is filled out by the transcription service when starting the workflow.  EMPTY  Should always be \"${transcriptionJobId}\"    target-flavor  The flavor of the caption/transcription file generated. Mandatory only if target-caption-format not informed.  captions/ target-caption-format + language  captions/vtt+en    target-tag  The tag to apply to the caption/transcription file generated. Optional.  EMPTY  archive    target-caption-format  The caption format to be generated. Optional. If not entered, the raw resulting file will be attached to the media package with the flavor  target-flavor .  EMPTY  vtt",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/attach-watson-transcription-woh/#example",
            "text": "<!-- Attach caption/transcript -->\n<operation id=\"attach-watson-transcription\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Attach captions/transcription\">\n  <configurations>\n    <!-- This is filled out by the transcription service when starting this workflow so just use this as is -->\n    <configuration key=\"transcription-job-id\">${transcriptionJobId}</configuration>\n    <configuration key=\"target-tag\">archive</configuration>\n    <!-- Caption generated will have the default flavor based on the target-caption-format and language e.g. captions/vtt+en -->\n    <configuration key=\"target-caption-format\">vtt</configuration>\n    <configuration key=\"target-tag\">engage-download</configuration>\n  </configurations>\n</operation>\n\n<!-- Merge caption/transcript to existing publication and republish -->\n<operation id=\"publish-engage\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Distribute and publish to engage server\">\n  <configurations>\n    <configuration key=\"download-source-tags\">engage-download</configuration>\n    <configuration key=\"strategy\">merge</configuration>\n    <configuration key=\"check-availability\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Example"
        },
        {
            "location": "/workflowoperationhandlers/cleanup-woh/",
            "text": "CleanupWorkflowOperationHandler\n\n\nDescription\n\n\nThis operation removes all files from the workspace and the working file repository which belong to media package\nelements of the running workflow unless their flavor is matched by the value configured in \npreserve-flavors\n.  It is\nusually used as last workflow operation in a workflow to ensure that temporary processing artefacts are removed.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\npreserve-flavors\n\n\nsecurity/*\n\n\nComma-separated list of flavors to be preserved.\n\n\n\n\n\n\n\n\ndelete-external\n\n\ntrue\n\n\nIf files from external working file repositories should be deleted\n\n\nfalse\n\n\n\n\n\n\ndelay\n\n\n5\n\n\nSeconds to wait before removing files\n\n\n1\n\n\n\n\n\n\n\n\nNotes\n\n\n\n\nIf \ndelete-external\n is set to \ntrue\n, the externally referenced media package elements will be removed from its\n  source where the value of \npreserve-flavors\n does not match\n\n\nIf you have an shared working file repository setting \ndelete-external\n to \nfalse\n will speed up the cleanup process\n  while still removing all files.\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"cleanup\"\n  fail-on-error=\"false\"\n  description=\"Remove temporary processing artifacts\">\n  <configurations>\n    <configuration key=\"preserve-flavors\">security/*</configuration>\n    <configuration key=\"delete-external\">true</configuration>\n    <configuration key=\"delay\">5</configuration>\n  </configurations>\n</operation>",
            "title": "Cleanup"
        },
        {
            "location": "/workflowoperationhandlers/cleanup-woh/#cleanupworkflowoperationhandler",
            "text": "",
            "title": "CleanupWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/cleanup-woh/#description",
            "text": "This operation removes all files from the workspace and the working file repository which belong to media package\nelements of the running workflow unless their flavor is matched by the value configured in  preserve-flavors .  It is\nusually used as last workflow operation in a workflow to ensure that temporary processing artefacts are removed.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/cleanup-woh/#parameter-table",
            "text": "Configuration Key  Example  Description  Default      preserve-flavors  security/*  Comma-separated list of flavors to be preserved.     delete-external  true  If files from external working file repositories should be deleted  false    delay  5  Seconds to wait before removing files  1",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/cleanup-woh/#notes",
            "text": "If  delete-external  is set to  true , the externally referenced media package elements will be removed from its\n  source where the value of  preserve-flavors  does not match  If you have an shared working file repository setting  delete-external  to  false  will speed up the cleanup process\n  while still removing all files.",
            "title": "Notes"
        },
        {
            "location": "/workflowoperationhandlers/cleanup-woh/#operation-example",
            "text": "<operation\n  id=\"cleanup\"\n  fail-on-error=\"false\"\n  description=\"Remove temporary processing artifacts\">\n  <configurations>\n    <configuration key=\"preserve-flavors\">security/*</configuration>\n    <configuration key=\"delete-external\">true</configuration>\n    <configuration key=\"delay\">5</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/comment-woh/",
            "text": "CommentWorkflowOperationHandler\n\n\nDescription\n\n\nThe CommentWorkflowOperationHandler can be used to create, resolve or delete comments for events within workflows.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\naction\n\n\ncreate\n\n\nAction to be performed: create, resolve or delete. Default value is create.\n\n\n\n\n\n\nreason\n\n\nEVENTS.EVENTS.DETAILS.\nCOMMENTS.REASONS.CUTTING\n\n\nThe comment reason's i18n id. You can find the id in etc/listproviders/\nevent.comment.reasons.properties\n\n\n\n\n\n\ndescription\n\n\nRecording has not been cut yet.\n\n\nThe description text to add to the comment.\n\n\n\n\n\n\n\n\nNotes:\n\n\n\n\nreason and description must be provided for the \ncreate\n action.\n\n\ncreate\n will not create duplicate comments: if there is already a comment with the same reason and description,\n  a new comment will not be created.\n\n\nresolve\n and \ndelete\n will perform no action if no comment matches the provided parameters (reason, description,\n   or reason and description). If more than one comment matches the parameters, only the first matching comment will be\n   resolved or deleted.\n\n\n\n\nOperation Examples\n\n\nCreate a comment:\n\n\n<operation\n  id=\"comment\"\n  description=\"Mark the recording for cutting\">\n  <configurations>\n    <configuration key=\"action\">create</configuration>\n    <configuration key=\"reason\">EVENTS.EVENTS.DETAILS.COMMENTS.REASONS.CUTTING</configuration>\n    <configuration key=\"description\">Recording has not been cut yet.</configuration>\n  </configurations>\n</operation>\n\n\n\nResolve a comment:\n\n\n<operation\n  id=\"comment\"\n  description=\"Resolve the cutting flag\">\n  <configurations>\n    <configuration key=\"action\">resolve</configuration>\n    <configuration key=\"reason\">EVENTS.EVENTS.DETAILS.COMMENTS.REASONS.CUTTING</configuration>\n  </configurations>\n</operation>",
            "title": "Comment"
        },
        {
            "location": "/workflowoperationhandlers/comment-woh/#commentworkflowoperationhandler",
            "text": "",
            "title": "CommentWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/comment-woh/#description",
            "text": "The CommentWorkflowOperationHandler can be used to create, resolve or delete comments for events within workflows.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/comment-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      action  create  Action to be performed: create, resolve or delete. Default value is create.    reason  EVENTS.EVENTS.DETAILS. COMMENTS.REASONS.CUTTING  The comment reason's i18n id. You can find the id in etc/listproviders/ event.comment.reasons.properties    description  Recording has not been cut yet.  The description text to add to the comment.     Notes:   reason and description must be provided for the  create  action.  create  will not create duplicate comments: if there is already a comment with the same reason and description,\n  a new comment will not be created.  resolve  and  delete  will perform no action if no comment matches the provided parameters (reason, description,\n   or reason and description). If more than one comment matches the parameters, only the first matching comment will be\n   resolved or deleted.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/comment-woh/#operation-examples",
            "text": "Create a comment:  <operation\n  id=\"comment\"\n  description=\"Mark the recording for cutting\">\n  <configurations>\n    <configuration key=\"action\">create</configuration>\n    <configuration key=\"reason\">EVENTS.EVENTS.DETAILS.COMMENTS.REASONS.CUTTING</configuration>\n    <configuration key=\"description\">Recording has not been cut yet.</configuration>\n  </configurations>\n</operation>  Resolve a comment:  <operation\n  id=\"comment\"\n  description=\"Resolve the cutting flag\">\n  <configurations>\n    <configuration key=\"action\">resolve</configuration>\n    <configuration key=\"reason\">EVENTS.EVENTS.DETAILS.COMMENTS.REASONS.CUTTING</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Examples"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/",
            "text": "ComposeWorkflowHandler\n\n\nDescription\n\n\nThe ComposeWorkflowHandler is used to encode media files to different formats using FFmpeg.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/work\n\n\nWhich media should be encoded\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/delivery\n\n\nSpecifies the flavor of the new media\n\n\n\n\n\n\nsource-tags\n\n\nsometag\n\n\nTags of media to encode\n\n\n\n\n\n\ntarget-tags\n\n\nsometag\n\n\nSpecifies the tags of the new media\n\n\n\n\n\n\nencoding-profile\n\n\nwebm-hd\n\n\nSpecifies the encoding profile to use\n\n\n\n\n\n\ntags-and-flavors\n\n\ntrue\n\n\nWhen false (default), the operation selects input elements that have EITHER any of the source tags OR the source flavor. When true, the operation selects input elements that have BOTH the source-flavor AND any of the source tags\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n    id=\"compose\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encoding presenter (camera) video to Flash download\">\n    <configurations>\n        <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n        <configuration key=\"target-flavor\">presenter/delivery</configuration>\n        <configuration key=\"target-tags\">engage</configuration>\n        <configuration key=\"encoding-profile\">flash.http</configuration>\n    </configurations>\n</operation>",
            "title": "Compose"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/#composeworkflowhandler",
            "text": "",
            "title": "ComposeWorkflowHandler"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/#description",
            "text": "The ComposeWorkflowHandler is used to encode media files to different formats using FFmpeg.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/work  Which media should be encoded    target-flavor  presenter/delivery  Specifies the flavor of the new media    source-tags  sometag  Tags of media to encode    target-tags  sometag  Specifies the tags of the new media    encoding-profile  webm-hd  Specifies the encoding profile to use    tags-and-flavors  true  When false (default), the operation selects input elements that have EITHER any of the source tags OR the source flavor. When true, the operation selects input elements that have BOTH the source-flavor AND any of the source tags",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/#operation-example",
            "text": "<operation\n    id=\"compose\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encoding presenter (camera) video to Flash download\">\n    <configurations>\n        <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n        <configuration key=\"target-flavor\">presenter/delivery</configuration>\n        <configuration key=\"target-tags\">engage</configuration>\n        <configuration key=\"encoding-profile\">flash.http</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/",
            "text": "Composite Workflow Operation Handler\n\n\nDescription\n\n\nThe CompositeWorkflowOperationHandler is used to composite two videos (upper and lower) and an optional watermark into\none video, including encoding to different formats. The audio track is always taken from the lower video. Everything is\ndone using FFmpeg. The composition can be done in various layout formats e.g. side by side or picture in picture. The\nlayout has to be defined in JSON format and is described in section \"Layout Definition\". For some general information\nabout layouts see Opencast Composer Layout Module.\n\n\nThe internal ffmpeg command is using the following filters: scale for scaling the videos, pad for defining the output\ndimension including the background color, movie for adding additional videos and images and overlay for aligning the\nvideos and images to the output dimension. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide\n\n\nSample complex composite filter command\n\n\n-filter:v \"[in]scale=640:480,pad=1920:1080:20:20:black[lower];movie=test.mp4,scale=640:480[upper];movie=watermark.jpg[watermark];[lower][upper]overlay=200:200[video];[video][watermark]overlay=main_w-overlay_w-20:20[out]\" sidebyside.mp4\n\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nvalue type (EBNF)\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-tags-upper\n\n\nString , { \",\" , String }\n\n\ncomp,rss\n\n\nThe \"tag\" of the upper track to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor-upper\n\n\nMediaPackageElementFlavor\n\n\npresenter/trimmed\n\n\nThe \"flavor\" of the upper track to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags-lower\n\n\nString , { \",\" , String }\n\n\ncomp,rss\n\n\nThe \"tag\" of the lower track to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor-lower\n\n\nMediaPackageElementFlavor\n\n\npresenter/trimmed\n\n\nThe \"flavor\" of the lower track to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags-watermark\n\n\nString , { \",\" , String }\n\n\nbranding\n\n\nThe \"tag\" of the attachment image to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor-watermark\n\n\nMediaPackageElementFlavor\n\n\nimage/work\n\n\nThe \"flavor\" of the attachment image to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-url-watermark\n\n\nURL\n\n\nfile:///Users/me/logo.jpg\n\n\nThe \"URL\" of the fallback image to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\nString , { \",\" , String }\n\n\ncomposite,rss,atom,archive\n\n\nThe tags to apply to the compound video track.\n\n\nEMPTY\n\n\n\n\n\n\n* \ntarget-flavor\n\n\nMediaPackageElementFlavor\n\n\ncomposite/delivery\n\n\nThe flavor to apply to the compound video track.\n\n\nEMPTY\n\n\n\n\n\n\n* \nencoding-profile\n\n\nString\n\n\ncomposite\n\n\nThe encoding profile to use.\n\n\nEMPTY\n\n\n\n\n\n\n* \noutput-resolution\n\n\nwidth , \"x\" , height | lower | higher\n\n\n1920x1080\n\n\nThe resulting resolution of the compound video e.g. 1920x1080.\n\n\nEMPTY\n\n\n\n\n\n\noutput-background\n\n\nString\n\n\nred\n\n\nThe resulting background color of the compound video http://www.ffmpeg.org/ffmpeg-utils.html#Color.\n\n\nblack\n\n\n\n\n\n\nlayout\n\n\nname\n\n\nJson , \";\" , Json , [ \";\" , Json ]\n\n\nThe layout name to use or a semi-colon separated JSON layout definition (lower video, upper video, optional watermark). If a layout name is given than the corresponding layout-{name} key must be defined.\n\n\nEMPTY\n\n\n\n\n\n\nlayout-single\n\n\nname\n\n\nJson , \";\" , Json , [ \";\" , Json ]\n\n\nLayout to be used in case of one input video track (see \nlayout\n)\n\n\nEMPTY\n\n\n\n\n\n\nlayout-dual\n\n\nname\n\n\nJson , \";\" , Json , [ \";\" , Json ]\n\n\nLayout to be used in case of two input video tracks (see \nlayout\n). Defaults to value of \nlayout\n if not set.\n\n\nEMPTY\n\n\n\n\n\n\nlayout-{name}\n\n\nJson , \";\" , Json , [ \";\" , Json ]\n\n\nDefine semi-colon separated JSON layouts (lower video, upper video, optional watermark) to provide by name.\n\n\nEMPTY\n\n\n\n\n\n\n\n\n\n\n* \nmandatory\n\n\nNotes:\n\n\n\n\nAt least one of the configuration keys \nlayout\n, \nlayout-single\n, or \nlayout-multiple\n must be set\n\n\n\n\nOutput Resolution\n\n\nThe output resolution must be specified using the configuration key \noutput-resolution\n. The output resolution can be\neither explicitly specified (e.g. 1920x1080) or selected from the lower or upper input video (lower or higher).\nIn case that only a single input track is available, both part-lower and part-higher will refer to that\nsingle input track.\n\n\nLayout Definition\n\n\nThe layout definitions are provided as JSON. Each definition consist of the layout specifications for the lower and\nupper video and an optional specification for the watermark. The specifications have to be separated by comma.\n\n\nIt is always ensured that the media does not exceed the canvas. Offset and scaling is adjusted appropriately.\n\n\nA single layout is specified as follows:\n\n\n{\n  // How much of the canvas shall be covered. [0.0 - 1.0]\n  // 1.0 means that the media is scaled to cover the complete width of the canvas keeping the aspect ratio.\n  \"horizontalCoverage\": Double,\n  // The offset between the anchor points of the media and the canvas\n  \"anchorOffset\": {\n    // The anchor point of the media. [0.0 - 1.0]\n    // (0.0, 0.0) is the upper left corner, (1.0, 1.0) is the lower right corner.\n    // (0.5, 0.5) is the center.\n    \"referring\": {\n      \"left\": Double,\n      \"top\": Double\n    },\n    // The anchor point of the canvas.\n    \"reference\": {\n      \"left\": Double,\n      \"top\": Double\n    },\n    // The offset between the two anchor points.\n    \"offset\": {\n      \"y\": Integer,\n      \"x\": Integer\n    }\n  }\n}\n\n// Example.\n// The media is scaled to cover the whole width of the canvas and is placed in the upper left corner.\n{\n  \"horizontalCoverage\": 1.0,\n  \"anchorOffset\": {\n    \"referring\": {\n      \"left\": 0.0,\n      \"top\": 0.0\n    },\n    \"offset\": {\n      \"y\": 0,\n      \"x\": 0\n    },\n    \"reference\": {\n      \"left\": 0.0,\n      \"top\": 0.0\n    }\n  }\n}\n\n// Example.\n// The media is scaled to cover 20% of the width of the canvas and is placed in the lower right corner\n// with an offset of -10px on both x and y axis so that it does not touch the canvas' border.\n{\n  \"horizontalCoverage\": 0.2,\n  \"anchorOffset\": {\n    \"referring\": {\n      \"left\": 1.0,\n      \"top\": 1.0\n    },\n    \"offset\": {\n      \"y\": -10,\n      \"x\": -10\n    },\n    \"reference\": {\n      \"left\": 1.0,\n      \"top\": 1.0\n    }\n  }\n}\n\n\n\nOperation Example\n\n\n<operation\n  id=\"composite\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Composite\">\n  <configurations>\n    <configuration key=\"source-flavor-upper\">presentation/trimmed</configuration>\n    <configuration key=\"source-flavor-lower\">presenter/trimmed</configuration>\n    <configuration key=\"source-tags-upper\">comp,rss</configuration>\n    <configuration key=\"source-tags-lower\">comp,rss</configuration>\n    <configuration key=\"source-tags-watermark\">branding</configuration>\n    <configuration key=\"source-flavor-watermark\">image/work</configuration>\n    <configuration key=\"source-url-watermark\">file:///Users/me/logo.jpg</configuration>\n    <configuration key=\"encoding-profile\">composite</configuration>\n    <configuration key=\"target-tags\">composite,rss,atom,archive</configuration>\n    <configuration key=\"target-flavor\">composite/delivery</configuration>\n    <configuration key=\"output-resolution\">1920x1080</configuration>\n    <configuration key=\"output-background\">red</configuration>\n    <configuration key=\"layout\">topleft</configuration>\n    <configuration key=\"layout-topleft\">\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}};\n      {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":0.0,\"top\":0.0}}};\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":1.0,\"top\":0.0}}}\n    </configuration>\n    <configuration key=\"layout-topright\">\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}};\n      {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":0.0}}};\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":0.0,\"top\":0.0}}}\n    </configuration>\n  </configurations>\n</operation>",
            "title": "Composite"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#composite-workflow-operation-handler",
            "text": "",
            "title": "Composite Workflow Operation Handler"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#description",
            "text": "The CompositeWorkflowOperationHandler is used to composite two videos (upper and lower) and an optional watermark into\none video, including encoding to different formats. The audio track is always taken from the lower video. Everything is\ndone using FFmpeg. The composition can be done in various layout formats e.g. side by side or picture in picture. The\nlayout has to be defined in JSON format and is described in section \"Layout Definition\". For some general information\nabout layouts see Opencast Composer Layout Module.  The internal ffmpeg command is using the following filters: scale for scaling the videos, pad for defining the output\ndimension including the background color, movie for adding additional videos and images and overlay for aligning the\nvideos and images to the output dimension. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#sample-complex-composite-filter-command",
            "text": "-filter:v \"[in]scale=640:480,pad=1920:1080:20:20:black[lower];movie=test.mp4,scale=640:480[upper];movie=watermark.jpg[watermark];[lower][upper]overlay=200:200[video];[video][watermark]overlay=main_w-overlay_w-20:20[out]\" sidebyside.mp4",
            "title": "Sample complex composite filter command"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  value type (EBNF)  example  description  default value      source-tags-upper  String , { \",\" , String }  comp,rss  The \"tag\" of the upper track to use as a source input.  EMPTY    source-flavor-upper  MediaPackageElementFlavor  presenter/trimmed  The \"flavor\" of the upper track to use as a source input.  EMPTY    source-tags-lower  String , { \",\" , String }  comp,rss  The \"tag\" of the lower track to use as a source input.  EMPTY    source-flavor-lower  MediaPackageElementFlavor  presenter/trimmed  The \"flavor\" of the lower track to use as a source input.  EMPTY    source-tags-watermark  String , { \",\" , String }  branding  The \"tag\" of the attachment image to use as a source input.  EMPTY    source-flavor-watermark  MediaPackageElementFlavor  image/work  The \"flavor\" of the attachment image to use as a source input.  EMPTY    source-url-watermark  URL  file:///Users/me/logo.jpg  The \"URL\" of the fallback image to use as a source input.  EMPTY    target-tags  String , { \",\" , String }  composite,rss,atom,archive  The tags to apply to the compound video track.  EMPTY    *  target-flavor  MediaPackageElementFlavor  composite/delivery  The flavor to apply to the compound video track.  EMPTY    *  encoding-profile  String  composite  The encoding profile to use.  EMPTY    *  output-resolution  width , \"x\" , height | lower | higher  1920x1080  The resulting resolution of the compound video e.g. 1920x1080.  EMPTY    output-background  String  red  The resulting background color of the compound video http://www.ffmpeg.org/ffmpeg-utils.html#Color.  black    layout  name  Json , \";\" , Json , [ \";\" , Json ]  The layout name to use or a semi-colon separated JSON layout definition (lower video, upper video, optional watermark). If a layout name is given than the corresponding layout-{name} key must be defined.  EMPTY    layout-single  name  Json , \";\" , Json , [ \";\" , Json ]  Layout to be used in case of one input video track (see  layout )  EMPTY    layout-dual  name  Json , \";\" , Json , [ \";\" , Json ]  Layout to be used in case of two input video tracks (see  layout ). Defaults to value of  layout  if not set.  EMPTY    layout-{name}  Json , \";\" , Json , [ \";\" , Json ]  Define semi-colon separated JSON layouts (lower video, upper video, optional watermark) to provide by name.  EMPTY      *  mandatory  Notes:   At least one of the configuration keys  layout ,  layout-single , or  layout-multiple  must be set",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#output-resolution",
            "text": "The output resolution must be specified using the configuration key  output-resolution . The output resolution can be\neither explicitly specified (e.g. 1920x1080) or selected from the lower or upper input video (lower or higher).\nIn case that only a single input track is available, both part-lower and part-higher will refer to that\nsingle input track.",
            "title": "Output Resolution"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#layout-definition",
            "text": "The layout definitions are provided as JSON. Each definition consist of the layout specifications for the lower and\nupper video and an optional specification for the watermark. The specifications have to be separated by comma.  It is always ensured that the media does not exceed the canvas. Offset and scaling is adjusted appropriately.  A single layout is specified as follows:  {\n  // How much of the canvas shall be covered. [0.0 - 1.0]\n  // 1.0 means that the media is scaled to cover the complete width of the canvas keeping the aspect ratio.\n  \"horizontalCoverage\": Double,\n  // The offset between the anchor points of the media and the canvas\n  \"anchorOffset\": {\n    // The anchor point of the media. [0.0 - 1.0]\n    // (0.0, 0.0) is the upper left corner, (1.0, 1.0) is the lower right corner.\n    // (0.5, 0.5) is the center.\n    \"referring\": {\n      \"left\": Double,\n      \"top\": Double\n    },\n    // The anchor point of the canvas.\n    \"reference\": {\n      \"left\": Double,\n      \"top\": Double\n    },\n    // The offset between the two anchor points.\n    \"offset\": {\n      \"y\": Integer,\n      \"x\": Integer\n    }\n  }\n}\n\n// Example.\n// The media is scaled to cover the whole width of the canvas and is placed in the upper left corner.\n{\n  \"horizontalCoverage\": 1.0,\n  \"anchorOffset\": {\n    \"referring\": {\n      \"left\": 0.0,\n      \"top\": 0.0\n    },\n    \"offset\": {\n      \"y\": 0,\n      \"x\": 0\n    },\n    \"reference\": {\n      \"left\": 0.0,\n      \"top\": 0.0\n    }\n  }\n}\n\n// Example.\n// The media is scaled to cover 20% of the width of the canvas and is placed in the lower right corner\n// with an offset of -10px on both x and y axis so that it does not touch the canvas' border.\n{\n  \"horizontalCoverage\": 0.2,\n  \"anchorOffset\": {\n    \"referring\": {\n      \"left\": 1.0,\n      \"top\": 1.0\n    },\n    \"offset\": {\n      \"y\": -10,\n      \"x\": -10\n    },\n    \"reference\": {\n      \"left\": 1.0,\n      \"top\": 1.0\n    }\n  }\n}",
            "title": "Layout Definition"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#operation-example",
            "text": "<operation\n  id=\"composite\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Composite\">\n  <configurations>\n    <configuration key=\"source-flavor-upper\">presentation/trimmed</configuration>\n    <configuration key=\"source-flavor-lower\">presenter/trimmed</configuration>\n    <configuration key=\"source-tags-upper\">comp,rss</configuration>\n    <configuration key=\"source-tags-lower\">comp,rss</configuration>\n    <configuration key=\"source-tags-watermark\">branding</configuration>\n    <configuration key=\"source-flavor-watermark\">image/work</configuration>\n    <configuration key=\"source-url-watermark\">file:///Users/me/logo.jpg</configuration>\n    <configuration key=\"encoding-profile\">composite</configuration>\n    <configuration key=\"target-tags\">composite,rss,atom,archive</configuration>\n    <configuration key=\"target-flavor\">composite/delivery</configuration>\n    <configuration key=\"output-resolution\">1920x1080</configuration>\n    <configuration key=\"output-background\">red</configuration>\n    <configuration key=\"layout\">topleft</configuration>\n    <configuration key=\"layout-topleft\">\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}};\n      {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":0.0,\"top\":0.0}}};\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":1.0,\"top\":0.0}}}\n    </configuration>\n    <configuration key=\"layout-topright\">\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}};\n      {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":0.0}}};\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":0.0,\"top\":0.0}}}\n    </configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/",
            "text": "Concat Workflow Operation Handler\n\n\nThe \nconcat\n operation handler has been created to concatenate multiple video tracks into one video track.\n\n\nFor a concatenation of two video files to work, both files need to have the same format (timebase, resolution, codecs,\nframe rate, etc.). This workflow operation has two modes to deal with this restriction:\n\n\n\n\nA \ngeneral\n mode which re-encodes all input files, hence ensuring that this restriction is always met.\n\n\nA \nsame codec\n mode which assumes the restriction is already met and can hence concatenate the files much faster while\n  also being a lossless process. But it will fail or produce a weird output if if the restrictions are not met.\n\n\n\n\nGeneral Mode\n\n\nNo restriction on source tracks codecs\n\n\nThis will re-encode the videos first to the same format (framerate/timebase/codec, etc) before concatenation.\n\n\n\n\nThe internal FFmpeg command for re-encoding is using the following filters: fps, scale, pad and setdar for scaling all\nvideos to a similar size including letterboxing, aevalsrc for creating silent audio streams and of course the concat for\nthe actual concatenation step.\n\n\nThis requires an output-resolution and an optional output-framerate for the pre-concatenation encode.\n\n\nThe automatically generated FFmpeg filter for this process does look like this:\n\n\n-filter_complex '\n  [0:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[b];\n  [1:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[c];\n  [2:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[d];\n  aevalsrc=0::d=1[silent];\n  [b][0:a][c][silent][d][2:a]concat=n=3:v=1:a=1[v][a]' -map '[v]' -map '[a]'\n\n\n\nSame Codec Mode\n\n\nRequires the source tracks having the same format (same timebase/resolution/encoding, etc.)\n\n\nIf the \nsame-codec\n option is specified to use this mode, the sources files can be arranged into one container\nlosslessly without re-encoding first.  This is often the case if the tracks came from the same camera/recorder for\nexample.\n\n\nThis mode uses \nFFmpeg's concat demuxer\n, which puts all the video\ncontent into a single container without any re-encoding. The encoding profile then operates on the source in this\ncontainer. If \n-c copy\n is used in the encoding profile, the complete concatenation is lossless.\n\n\nThe FFmpeg command for this is is:\n\n\n-f concat -i videolist.txt\n\n\n\n\u2026where \nvideolist.txt\n contains a line in the form \nfile <path to video>\n for each source track.\n\n\nUsage\n\n\nThis operation is quite similar to the compose operation. The only difference is that the input properties are not only\nlimited to one \nsource-flavor\n and \nsource-tag\n. The operation supports multiple flavor and tags as input. To add\nmultiple sources, add different keys with the prefix \nsource-flavor-\n/\nsource-tag-\n and an incremental number starting\nwith 0. For example:\n\n\n\n\nsource-flavor-part-0\n\n\nsource-flavor-part-1\n\n\nsource-flavor-part-..\n\n\n\n\nAlternatively, using the \nsource-flavor-numbered-files\n option, the operation supports an undetermined number of\nordered input files.\n\n\nThis is useful when the number of input files cannot be known in advance, such as chunked output files from some\ncamera/recorders, and the names are ordered by number or timestamps and to be sorted lexicographically.\n\n\nFor example, the configuration could be \nsource-flavor-numbered-files: multipart/part+source\n and the ordered input\nfiles:\n\n\nvideo-201711201020.mp4\nvideo-201711201030.mp4\nvideo-201711201040.mp4\n\n\n\nNote that both methods of defining input files are mutually exclusive.\n\n\nConfiguration Keys\n\n\n\n\n\n\n\n\nKey\n\n\nRequired\n\n\nDescription\n\n\nDefault\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nsource-flavor-part-X\n\n\nfalse\n\n\nAn iterative list of part/flavor to use as input track.\n\n\nNULL\n\n\npresenter/trimmed\n\n\n\n\n\n\nsource-tag-part-X\n\n\nfalse\n\n\nAn iterative list of part/tag to use as input track.\n\n\nNULL\n\n\nsource-to-concate\n\n\n\n\n\n\nsource-flavor-part-X-mandatory\n\n\nfalse\n\n\nDefine the flavor part-X as optional for concatenation.\n\n\nfalse\n\n\ntrue\n\n\n\n\n\n\nsource-tag-part-X-mandatory\n\n\nfalse\n\n\nDefine the tag part-X as optional for concatenation.\n\n\nfalse\n\n\ntrue\n\n\n\n\n\n\nencoding-profile\n\n\ntrue\n\n\nEncoding profile to use for the concatenation.\n\n\nNULL\n\n\nconcat\n\n\n\n\n\n\ntarget-flavor\n\n\ntrue\n\n\nFlavor(s) to add to the output track.\n\n\nNULL\n\n\npresenter/concat\n\n\n\n\n\n\ntarget-tags\n\n\nfalse\n\n\nTag(s) to add to the output track\n\n\nNULL\n\n\nengage-download\n\n\n\n\n\n\noutput-resolution\n\n\ntrue\n\n\nOutput resolution in width, height or a source part\n\n\nNULL\n\n\n1900x1080\n, \npart-1\n\n\n\n\n\n\noutput-framerate\n\n\nfalse\n\n\nOutput frame rate in frames per second or a source part\n\n\n-1.0\n\n\n25\n, \n23.976\n, \npart-1\n\n\n\n\n\n\nsource-flavor-numbered-files\n\n\nfalse\n\n\nFiles of this flavor are ordered lexicographically to use as input track.\n\n\nNULL\n\n\nmultipart/sections\n\n\n\n\n\n\nsame-codec\n\n\nfalse\n\n\nAll source files have identical formats.\n\n\nfalse\n\n\ntrue\n\n\n\n\n\n\n\n\nExample\n\n\nExample of a concat operation in a workflow definition.\n\n\n<!-- Add intro and outro part to the presenter track -->\n<operation\n  id=\"concat\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Concatenate the presenter track and the intro/outro videos.\">\n  <configurations>\n    <configuration key=\"source-flavor-part-0\">intro/source</configuration>\n    <configuration key=\"source-flavor-part-1\">presenter/trimmed</configuration>\n    <configuration key=\"source-flavor-part-1-mandatory\">true</configuration>\n    <configuration key=\"source-flavor-part-2\">outro/source</configuration>\n    <configuration key=\"target-flavor\">presenter/concat</configuration>\n    <configuration key=\"target-tags\">engage-download,engage-streaming</configuration>\n    <configuration key=\"encoding-profile\">concat</configuration>\n    <configuration key=\"output-resolution\">1920x1080</configuration>\n    <configuration key=\"output-framerate\">part-1</configuration>\n  </configurations>\n</operation>\n\n\n\n\nExample of a lossless concat operation for videos with identical formats in a workflow definition.\n\n\n<!-- Concatenate chunked video from camera -->\n<operation\n  id=\"concat\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Concatenate the generated videos.\">\n  <configurations>\n    <configuration key=\"source-flavor-numbered-files\">multipart/chunkedsource</configuration>\n    <configuration key=\"target-flavor\">presenter/concat</configuration>\n    <configuration key=\"target-tags\">engage-download,engage-streaming</configuration>\n    <!-- do not encode before concatenation -->\n    <configuration key=\"same-codec\">true</configuration>\n    <configuration key=\"encoding-profile\">concat-samecodec</configuration>\n  </configurations>\n</operation>\n\n\n\n\nEncoding Profile\n\n\nThe encoding profile command must contain the #{concatCommand} parameter which will set all input and possibly filter\ncommands required for this operation:\n\n\nprofile.concat.ffmpeg.command = #{concatCommand} \\\n  \u2026 #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Concat"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#concat-workflow-operation-handler",
            "text": "The  concat  operation handler has been created to concatenate multiple video tracks into one video track.  For a concatenation of two video files to work, both files need to have the same format (timebase, resolution, codecs,\nframe rate, etc.). This workflow operation has two modes to deal with this restriction:   A  general  mode which re-encodes all input files, hence ensuring that this restriction is always met.  A  same codec  mode which assumes the restriction is already met and can hence concatenate the files much faster while\n  also being a lossless process. But it will fail or produce a weird output if if the restrictions are not met.",
            "title": "Concat Workflow Operation Handler"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#general-mode",
            "text": "No restriction on source tracks codecs  This will re-encode the videos first to the same format (framerate/timebase/codec, etc) before concatenation.   The internal FFmpeg command for re-encoding is using the following filters: fps, scale, pad and setdar for scaling all\nvideos to a similar size including letterboxing, aevalsrc for creating silent audio streams and of course the concat for\nthe actual concatenation step.  This requires an output-resolution and an optional output-framerate for the pre-concatenation encode.  The automatically generated FFmpeg filter for this process does look like this:  -filter_complex '\n  [0:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[b];\n  [1:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[c];\n  [2:v]fps=fps=25.0,scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[d];\n  aevalsrc=0::d=1[silent];\n  [b][0:a][c][silent][d][2:a]concat=n=3:v=1:a=1[v][a]' -map '[v]' -map '[a]'",
            "title": "General Mode"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#same-codec-mode",
            "text": "Requires the source tracks having the same format (same timebase/resolution/encoding, etc.)  If the  same-codec  option is specified to use this mode, the sources files can be arranged into one container\nlosslessly without re-encoding first.  This is often the case if the tracks came from the same camera/recorder for\nexample.  This mode uses  FFmpeg's concat demuxer , which puts all the video\ncontent into a single container without any re-encoding. The encoding profile then operates on the source in this\ncontainer. If  -c copy  is used in the encoding profile, the complete concatenation is lossless.  The FFmpeg command for this is is:  -f concat -i videolist.txt  \u2026where  videolist.txt  contains a line in the form  file <path to video>  for each source track.",
            "title": "Same Codec Mode"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#usage",
            "text": "This operation is quite similar to the compose operation. The only difference is that the input properties are not only\nlimited to one  source-flavor  and  source-tag . The operation supports multiple flavor and tags as input. To add\nmultiple sources, add different keys with the prefix  source-flavor- / source-tag-  and an incremental number starting\nwith 0. For example:   source-flavor-part-0  source-flavor-part-1  source-flavor-part-..   Alternatively, using the  source-flavor-numbered-files  option, the operation supports an undetermined number of\nordered input files.  This is useful when the number of input files cannot be known in advance, such as chunked output files from some\ncamera/recorders, and the names are ordered by number or timestamps and to be sorted lexicographically.  For example, the configuration could be  source-flavor-numbered-files: multipart/part+source  and the ordered input\nfiles:  video-201711201020.mp4\nvideo-201711201030.mp4\nvideo-201711201040.mp4  Note that both methods of defining input files are mutually exclusive.",
            "title": "Usage"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#configuration-keys",
            "text": "Key  Required  Description  Default  Example      source-flavor-part-X  false  An iterative list of part/flavor to use as input track.  NULL  presenter/trimmed    source-tag-part-X  false  An iterative list of part/tag to use as input track.  NULL  source-to-concate    source-flavor-part-X-mandatory  false  Define the flavor part-X as optional for concatenation.  false  true    source-tag-part-X-mandatory  false  Define the tag part-X as optional for concatenation.  false  true    encoding-profile  true  Encoding profile to use for the concatenation.  NULL  concat    target-flavor  true  Flavor(s) to add to the output track.  NULL  presenter/concat    target-tags  false  Tag(s) to add to the output track  NULL  engage-download    output-resolution  true  Output resolution in width, height or a source part  NULL  1900x1080 ,  part-1    output-framerate  false  Output frame rate in frames per second or a source part  -1.0  25 ,  23.976 ,  part-1    source-flavor-numbered-files  false  Files of this flavor are ordered lexicographically to use as input track.  NULL  multipart/sections    same-codec  false  All source files have identical formats.  false  true",
            "title": "Configuration Keys"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#example",
            "text": "Example of a concat operation in a workflow definition.  <!-- Add intro and outro part to the presenter track -->\n<operation\n  id=\"concat\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Concatenate the presenter track and the intro/outro videos.\">\n  <configurations>\n    <configuration key=\"source-flavor-part-0\">intro/source</configuration>\n    <configuration key=\"source-flavor-part-1\">presenter/trimmed</configuration>\n    <configuration key=\"source-flavor-part-1-mandatory\">true</configuration>\n    <configuration key=\"source-flavor-part-2\">outro/source</configuration>\n    <configuration key=\"target-flavor\">presenter/concat</configuration>\n    <configuration key=\"target-tags\">engage-download,engage-streaming</configuration>\n    <configuration key=\"encoding-profile\">concat</configuration>\n    <configuration key=\"output-resolution\">1920x1080</configuration>\n    <configuration key=\"output-framerate\">part-1</configuration>\n  </configurations>\n</operation>  Example of a lossless concat operation for videos with identical formats in a workflow definition.  <!-- Concatenate chunked video from camera -->\n<operation\n  id=\"concat\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Concatenate the generated videos.\">\n  <configurations>\n    <configuration key=\"source-flavor-numbered-files\">multipart/chunkedsource</configuration>\n    <configuration key=\"target-flavor\">presenter/concat</configuration>\n    <configuration key=\"target-tags\">engage-download,engage-streaming</configuration>\n    <!-- do not encode before concatenation -->\n    <configuration key=\"same-codec\">true</configuration>\n    <configuration key=\"encoding-profile\">concat-samecodec</configuration>\n  </configurations>\n</operation>",
            "title": "Example"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#encoding-profile",
            "text": "The encoding profile command must contain the #{concatCommand} parameter which will set all input and possibly filter\ncommands required for this operation:  profile.concat.ffmpeg.command = #{concatCommand} \\\n  \u2026 #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Encoding Profile"
        },
        {
            "location": "/workflowoperationhandlers/configure-by-dcterm-woh/",
            "text": "ConfigureByDCTermWorkflowOperationHandler\n\n\nDescription\n\n\nWith the ConfigureByDCTermWorkflowOperationHandler it's possible to create a workflow configuration property according\nto whether a Dublin Core term in a catalog has a specific value. So for example it's possible to control a workflow so\nthat it will publish before editing if a certain Dublin Core term has the specified value.\n\n\nIn combination with \nTagByDCTermWorkflowOperationHandler\n workflows can be controlled by the\nmetadata contained within the Dublin Core catalogs.\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\ndccatalog\n\n\n\"episode\" or \"series\"\n\n\nthe type of catalog in which to search for \ndcterm\n\n\nEMPTY\n\n\n\n\n\n\ndcterm\n\n\n\"creator\"\n\n\nthe name of the Dublin Core term which to check\n\n\nEMPTY\n\n\n\n\n\n\nmatch-value\n\n\n\"Joe Bloggs\"\n\n\nthe Dublin Core term value to check for\n\n\nEMPTY\n\n\n\n\n\n\ndefault-value\n\n\n\"Anon\"\n\n\nthe implied value if the dubincore term is not present in the catalog\n\n\nEMPTY\n\n\n\n\n\n\nconfigProperty\n\n\ntrue / false\n\n\na configuration property and the value it will be given if a match is found\n\n\nEMPTY\n\n\n\n\n\n\n\n\ndccatalog\n\n\nThe type of Dublin Core catalog in which to look for the \ndcterm\n. This will usually be \nepisode\n or \nseries\n.\n\n\ndcterm\n\n\nThe name of the Dublin Core term to look for in the \ndccatalog\n. This could be one of the terms set by Opencast or an\nadditional term adding to the catalog.\n\n\nmatch-value\n\n\nThe value of the \ndcterm\n which to match against. The comparison is case sensitive.\n\n\ndefault-value\n\n\nIf \ndefault-value\n is used when the \ndcterm\n is not found in the catalog. If not specified the operation will treat the\nmatch as false and not configure anything. If \ndefault-value\n is specified the operation will compare the \nmatch-value\n\nto the \ndefault-value\n and set the workflow property if they match. This allows an implied value to be explicitly and\nclearly defined. For example if you have mediapackages that were created before additional metadata was added to the\nepisode catalog you may want to imply that the \naudience\n term has a value of \nall-enrolled\n.\n\n\n\"configProperty\"\n\n\nSpecifies as the key the name of a new workflow configuration property and the boolean value to which it will be set if\nthe Dublin Core term matches the specified value.\n\n\nDue to the way a workflow evaluates operation \nif\n conditions as configuration properties are created, only new\nconfiguration properties can be used to modify the execution of subsequent operations. Also since an undefined property\nwill be evaluted as \nfalse\n in practice the only useful value which can set is \ntrue\n.  However operation \nif\n\nconditions can be negated though so it is possible to skip subsequent operations on matched \ndcterm\n  value.\n\n\nOperation Example\n\n\n<operation\n  id=\"configure-by-dcterm\"\n  fail-on-error=\"true\"\n  description=\"Configure publication channel by dcterm\">\n  <configurations>\n    <configuration key=\"dccatalog\">episode</configuration>\n    <configuration key=\"dcterm\">audience</configuration>\n    <configuration key=\"match-value\">private</configuration>\n    <configuration key=\"publishPrivate\">true</configuration>\n  </configurations>\n</operation>\n\n...\n\n<operation\n   id=\"publish-engage\"\n   if=\"${publishPrivate}\"\n   description=\"Publish to internal audience only\">\n   ...\n</operation>\n\n\n<operation\n   id=\"publish-youtube\"\n   if=\"NOT ${publishPrivate}\"\n   description=\"Publish to global audience\">\n   ...\n</operation>",
            "title": "Configure-By-DCTerm"
        },
        {
            "location": "/workflowoperationhandlers/configure-by-dcterm-woh/#configurebydctermworkflowoperationhandler",
            "text": "",
            "title": "ConfigureByDCTermWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/configure-by-dcterm-woh/#description",
            "text": "With the ConfigureByDCTermWorkflowOperationHandler it's possible to create a workflow configuration property according\nto whether a Dublin Core term in a catalog has a specific value. So for example it's possible to control a workflow so\nthat it will publish before editing if a certain Dublin Core term has the specified value.  In combination with  TagByDCTermWorkflowOperationHandler  workflows can be controlled by the\nmetadata contained within the Dublin Core catalogs.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/configure-by-dcterm-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  example  description  default value      dccatalog  \"episode\" or \"series\"  the type of catalog in which to search for  dcterm  EMPTY    dcterm  \"creator\"  the name of the Dublin Core term which to check  EMPTY    match-value  \"Joe Bloggs\"  the Dublin Core term value to check for  EMPTY    default-value  \"Anon\"  the implied value if the dubincore term is not present in the catalog  EMPTY    configProperty  true / false  a configuration property and the value it will be given if a match is found  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/configure-by-dcterm-woh/#dccatalog",
            "text": "The type of Dublin Core catalog in which to look for the  dcterm . This will usually be  episode  or  series .",
            "title": "dccatalog"
        },
        {
            "location": "/workflowoperationhandlers/configure-by-dcterm-woh/#dcterm",
            "text": "The name of the Dublin Core term to look for in the  dccatalog . This could be one of the terms set by Opencast or an\nadditional term adding to the catalog.",
            "title": "dcterm"
        },
        {
            "location": "/workflowoperationhandlers/configure-by-dcterm-woh/#match-value",
            "text": "The value of the  dcterm  which to match against. The comparison is case sensitive.",
            "title": "match-value"
        },
        {
            "location": "/workflowoperationhandlers/configure-by-dcterm-woh/#default-value",
            "text": "If  default-value  is used when the  dcterm  is not found in the catalog. If not specified the operation will treat the\nmatch as false and not configure anything. If  default-value  is specified the operation will compare the  match-value \nto the  default-value  and set the workflow property if they match. This allows an implied value to be explicitly and\nclearly defined. For example if you have mediapackages that were created before additional metadata was added to the\nepisode catalog you may want to imply that the  audience  term has a value of  all-enrolled .",
            "title": "default-value"
        },
        {
            "location": "/workflowoperationhandlers/configure-by-dcterm-woh/#configproperty",
            "text": "Specifies as the key the name of a new workflow configuration property and the boolean value to which it will be set if\nthe Dublin Core term matches the specified value.  Due to the way a workflow evaluates operation  if  conditions as configuration properties are created, only new\nconfiguration properties can be used to modify the execution of subsequent operations. Also since an undefined property\nwill be evaluted as  false  in practice the only useful value which can set is  true .  However operation  if \nconditions can be negated though so it is possible to skip subsequent operations on matched  dcterm   value.",
            "title": "\"configProperty\""
        },
        {
            "location": "/workflowoperationhandlers/configure-by-dcterm-woh/#operation-example",
            "text": "<operation\n  id=\"configure-by-dcterm\"\n  fail-on-error=\"true\"\n  description=\"Configure publication channel by dcterm\">\n  <configurations>\n    <configuration key=\"dccatalog\">episode</configuration>\n    <configuration key=\"dcterm\">audience</configuration>\n    <configuration key=\"match-value\">private</configuration>\n    <configuration key=\"publishPrivate\">true</configuration>\n  </configurations>\n</operation>\n\n...\n\n<operation\n   id=\"publish-engage\"\n   if=\"${publishPrivate}\"\n   description=\"Publish to internal audience only\">\n   ...\n</operation>\n\n\n<operation\n   id=\"publish-youtube\"\n   if=\"NOT ${publishPrivate}\"\n   description=\"Publish to global audience\">\n   ...\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/copy-woh/",
            "text": "CopyWorkflowOperationHandler\n\n\nDescription\n\n\nThe CopyWorkflowOperationHandler can be used to copy media package elements to a given target directory.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\npresenter/source\n\n\nComma-separated list of source-flavors\n\n\n\n\n\n\nsource-tags\n\n\narchive\n\n\nComma-separated list of source-tags\n\n\n\n\n\n\ntarget-directory*\n\n\n/mnt/mydisk\n\n\nThe directory where the file is copied to\n\n\n\n\n\n\ntarget-filename\n\n\ntest\n\n\nThe optional target filename. The file extension extract from the media package element URI will be appended\n\n\n\n\n\n\n\n\n* mandatory configuration key\n\n\nNotes:\n\n\n\n\nsource-flavors\n and \nsource-tags\n may be used both together to select media package elements based on both flavors\n  and tags\n\n\nIn case that neither \nsource-flavors\n nor \nsource-tags\n are specified, the operation will be skipped\n\n\nIn case no media package elements match \nsource-flavors\n and \nsource-tags\n, the operation will be skipped\n\n\n\n\nTarget Filenames\n\n\nIf \ntarget-filename\n is not specified, the filename for each media package element is extracted from the media package\nelement URI. If \ntarget-filename\n is specified, the filename is the result of appending the file extension (extracted\nfrom the media package element URI) to \ntarget-filename\n. In case the \nsource-flavors\n and \nsource-tags\n match mutliple\nmedia package elements, a sequentially increasing integer number (starting at 1) can be used within \ntarget-filename\n in\nJava string formatting manner to ensure unique filenames.\n\n\nOperation Example\n\n\n<operation id=\"copy\"\n         description=\"Copy sources to my disk\"\n         fail-on-error=\"true\"\n         exception-handler-workflow=\"partial-error\">\n<configurations>\n  <configuration key=\"source-flavors\">presenter/source, presentation/source</configuration>\n  <configuration key=\"target-directory\">/mnt/mydisk</configuration>\n</configurations>",
            "title": "Copy"
        },
        {
            "location": "/workflowoperationhandlers/copy-woh/#copyworkflowoperationhandler",
            "text": "",
            "title": "CopyWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/copy-woh/#description",
            "text": "The CopyWorkflowOperationHandler can be used to copy media package elements to a given target directory.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/copy-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      source-flavors  presenter/source  Comma-separated list of source-flavors    source-tags  archive  Comma-separated list of source-tags    target-directory*  /mnt/mydisk  The directory where the file is copied to    target-filename  test  The optional target filename. The file extension extract from the media package element URI will be appended     * mandatory configuration key  Notes:   source-flavors  and  source-tags  may be used both together to select media package elements based on both flavors\n  and tags  In case that neither  source-flavors  nor  source-tags  are specified, the operation will be skipped  In case no media package elements match  source-flavors  and  source-tags , the operation will be skipped",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/copy-woh/#target-filenames",
            "text": "If  target-filename  is not specified, the filename for each media package element is extracted from the media package\nelement URI. If  target-filename  is specified, the filename is the result of appending the file extension (extracted\nfrom the media package element URI) to  target-filename . In case the  source-flavors  and  source-tags  match mutliple\nmedia package elements, a sequentially increasing integer number (starting at 1) can be used within  target-filename  in\nJava string formatting manner to ensure unique filenames.",
            "title": "Target Filenames"
        },
        {
            "location": "/workflowoperationhandlers/copy-woh/#operation-example",
            "text": "<operation id=\"copy\"\n         description=\"Copy sources to my disk\"\n         fail-on-error=\"true\"\n         exception-handler-workflow=\"partial-error\">\n<configurations>\n  <configuration key=\"source-flavors\">presenter/source, presentation/source</configuration>\n  <configuration key=\"target-directory\">/mnt/mydisk</configuration>\n</configurations>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/clone-woh/",
            "text": "CloneWorkflowOperationHandler\n\n\nDescription\n\n\nThe CloneWorkflowOperationHandler can be used to clone media package elements.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/source\n\n\nThe source flavor(s) to clone\n\n\n\n\n\n\nsource-tags\n\n\narchive\n\n\nComma-separated list of source-tags\n\n\n\n\n\n\ntarget-flavor*\n\n\npresenter/target\n\n\nThe target flavor\n\n\n\n\n\n\n\n\n* mandatory configuration key\n\n\nNotes:\n\n\n\n\nsource-flavor\n and \nsource-tags\n may be used both together to select media package elements based on both flavors and\n  tags\n\n\nIf \nsource-flavor\n is not specified, all media package elements matching \nsource-tags\n will be selected\n\n\nIn case that neither \nsource-flavor\n nor \nsource-tags\n are specified, the operation will be skipped\n\n\nIn case no media package elements match \nsource-flavor\n and \nsource-tags\n, the operation will be skipped\n\n\n\n\nSource Flavor\n\n\nIf \nsource-flavor\n is specified as e.g. \n*/source\n, all matching media package elements will be cloned and have the new\nflavor \n/target\n.\n\n\nTarget Flavor\n\n\nIf \ntarget-flavor\n is specified as e.g. \n*/target\n, the target flavors will have the subtype \ntarget\n and the type from\nthe source If \ntarget-flavor\n is specified as e.g. \ntarget/*\n, the target flavors will have the type \ntarget\n and the\nsubtype from the source\n\n\nOperation Example\n\n\n    <operation\n            id=\"clone\"\n            fail-on-error=\"true\"\n            exception-handler-workflow=\"ng-partial-error\">\n            <configurations>\n                    <configuration key=\"source-flavor\">*/source</configuration>\n                    <configuration key=\"source-tags\">archive</configuration>\n                    <configuration key=\"target-flavor\">*/target</configuration>\n            </configurations>\n    </operation>",
            "title": "Clone"
        },
        {
            "location": "/workflowoperationhandlers/clone-woh/#cloneworkflowoperationhandler",
            "text": "",
            "title": "CloneWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/clone-woh/#description",
            "text": "The CloneWorkflowOperationHandler can be used to clone media package elements.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/clone-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      source-flavor  presenter/source  The source flavor(s) to clone    source-tags  archive  Comma-separated list of source-tags    target-flavor*  presenter/target  The target flavor     * mandatory configuration key  Notes:   source-flavor  and  source-tags  may be used both together to select media package elements based on both flavors and\n  tags  If  source-flavor  is not specified, all media package elements matching  source-tags  will be selected  In case that neither  source-flavor  nor  source-tags  are specified, the operation will be skipped  In case no media package elements match  source-flavor  and  source-tags , the operation will be skipped",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/clone-woh/#source-flavor",
            "text": "If  source-flavor  is specified as e.g.  */source , all matching media package elements will be cloned and have the new\nflavor  /target .",
            "title": "Source Flavor"
        },
        {
            "location": "/workflowoperationhandlers/clone-woh/#target-flavor",
            "text": "If  target-flavor  is specified as e.g.  */target , the target flavors will have the subtype  target  and the type from\nthe source If  target-flavor  is specified as e.g.  target/* , the target flavors will have the type  target  and the\nsubtype from the source",
            "title": "Target Flavor"
        },
        {
            "location": "/workflowoperationhandlers/clone-woh/#operation-example",
            "text": "<operation\n            id=\"clone\"\n            fail-on-error=\"true\"\n            exception-handler-workflow=\"ng-partial-error\">\n            <configurations>\n                    <configuration key=\"source-flavor\">*/source</configuration>\n                    <configuration key=\"source-tags\">archive</configuration>\n                    <configuration key=\"target-flavor\">*/target</configuration>\n            </configurations>\n    </operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/",
            "text": "CoverImageWorkflowOperationHandler\n\n\nDescription\n\n\nThe CoverImageWorkflowOperationHandler generates a cover image based on an XSLT transformation which results in an SVG\nimage that is rasterized as PNG as a last step.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nExample\n\n\nDefault Value\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nstylesheet *\n\n\nURL\n\n\nfile:///etc/opencast/branding/coverimage.xsl\n\n\n-\n\n\nFile URI to the XSL stylesheet used to generate the SVG image\n\n\n\n\n\n\nmetadata\n\n\nXML\n\n\nHello!\n\n\n-\n\n\nXML string which is passed to the XSL transformation. If parameter is not given, a default XML is handed to the transformation\n\n\n\n\n\n\nwidth *\n\n\nint\n\n\n1920\n\n\n-\n\n\nWidth of the resulting image\n\n\n\n\n\n\nheight *\n\n\nint\n\n\n1080\n\n\n-\n\n\nHeight of the resulting image\n\n\n\n\n\n\nposterimage-flavor\n\n\nFlavor\n\n\nimage/poster\n\n\n-\n\n\nFlavor of a poster image which may be used as a part of the cover image (e.g. as a background)\n\n\n\n\n\n\nposterimage\n\n\nURL\n\n\nhttp://flickr.com/posterimage.jpg\n\n\n-\n\n\nURL to a custom poster image instead of using one out of the media package\n\n\n\n\n\n\ntarget-flavor *\n\n\nFlavor\n\n\nimage/cover\n\n\n-\n\n\nFlavor of the resulting cover image\n\n\n\n\n\n\ntarget-tags\n\n\nString\n\n\narchive,download\n\n\n-\n\n\nComma separated list of tags to be applied to the resulting attachment.\n\n\n\n\n\n\n\n\nMetadata\n\n\nIf no metadata is passed by using the configuration key \nmetadata\n, the default metadata is passed to the cover image\nservice which looks like the following example:\n\n\n<?xml version=\"1.0\"?>\n<metadata>\n  <title>Puppy Love</title>\n  <date>2014-04-24T11:21:00</date>\n  <license>All rights reserved</license>\n  <description>Here is a description of the video</description>\n  <series>Superbowl Commercials</series>\n  <contributors>Budweiser</contributors>\n  <creators>Budweiser</creators>\n  <subjects>Commercial</subjects>\n</metadata>\n\n\n\nNote that the date is localized based on your servers Java Runtime language settings.\n\n\nStylesheet\n\n\nThe cover image service uses the Xalan XSLT 1.0 processor to transform an XML stylesheet to an SVG image.\n\n\nThe general structure of the stylesheet is expected to look like this:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n\n  <xsl:param name=\"width\" />\n  <xsl:param name=\"height\" />\n  <xsl:param name=\"posterimage\" />\n\n  <xsl:template match=\"/\">\n\n    <svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.1\">\n      <xsl:attribute name=\"width\">\n        <xsl:value-of select=\"$width\" />\n      </xsl:attribute>\n      <xsl:attribute name=\"height\">\n        <xsl:value-of select=\"$height\" />\n      </xsl:attribute>\n\n      <!-- Your SVG content -->\n\n  </xsl:template>\n\n</xsl:stylesheet>\n\n\n\nThe variables \nwidth\n, \nheight\n and \nposterimage\n will be set to the values of the respective configuration keys.\n\n\nAs a starting point for your own template you best take a look at file \netc/branding/coverimage.xsl\n.\n\n\nUsing XLST Extensions\n\n\nXalan is a powerful XSLT 1.0 processor that comes with a rich feature set. For example, it is possible to\nexecute JavaScript or Java code directly within the stylesheet.\n\n\nFor commonly used tasks it is simpler, however, to make use of available XSLT Extensions.\n\n\nOpencast Extensions\n\n\nThe package org.opencastproject.coverimage.impl.xsl provides classes supposed to be used within XSL stylesheets.\n\n\nTo make use of those classes, you need to reference the package from your XSL stylesheet:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"\n  xmlns:opencast=\"xalan://org.opencastproject.coverimage.impl.xsl\" exclude-result-prefixes=\"opencast\"\n  extension-element-prefixes=\"opencast\">\n</xsl:stylesheet>\n\n\n\nLater on, you can use methods of those classes as shown in the following example:\n\n\n<tspan class=\"title\" y=\"30%\" x=\"50%\">\n  <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 1, false())\" />\n</tspan>\n\n\n\nNote: In XSLT, use \ntrue()\n and \nfalse()\n for boolean literals (\ntrue\n and \nfalse\n won't work since those are not\nkeywords in XSLT)\n\n\nThe following classes are provided by the org.opencastproject.coverimage.impl.xsl package:\n\n\nclass XsltHelper\n\n\nString split(String text, int maxChars, int line, boolean isLastLine)\n\n\nThis method can be used to break strings over multiple lines and to abbreviate strings that are too using ellipsis.\n\n\n\n\n\n\n\n\nParameter\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntext\n\n\nInput string\n\n\n\n\n\n\nmaxChars\n\n\nMaximum number of characters per line\n\n\n\n\n\n\nline\n\n\nNumber of line\n\n\n\n\n\n\nisLastLine\n\n\nWhether \nline\n is the last line used to represent the \ntext\n\n\n\n\n\n\n\n\nExample\n\n\nTo use at most two lines (max. 30 characters per line) to represent a string \nmetadata/title\n and abbreviate the string\nif two lines aren't enough:\n\n\n<tspan class=\"title\" y=\"30%\" x=\"50%\">\n  <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 1, false())\" />\n</tspan>\n<tspan class=\"title\" dy=\"10%\" x=\"50%\">\n  <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 2, true())\" />\n</tspan>\n\n\n\nEXSLT Extensions\n\n\nXalan supports most of the XSLT extensions of the EXSLT community (see \n[1]\n). In doubt consult\n\n[2]\n for more information about Xalan's implementation of the\nEXSLT extensions.\n\n\nPlease find an example of how to use EXSLT extensions below:\n\n\n<xsl:stylesheet version=\"1.0\"\n  xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:dcterms=\"http://purl.org/dc/terms/\"\n  xmlns:date=\"http://exslt.org/dates-and-times\"\n  xmlns:opencast=\"xalan://org.opencastproject.coverimage.impl.xsl\" exclude-result-prefixes=\"date\"\n  extension-element-prefixes=\"date\">\n\n  <!-- [...] -->\n\n  <tspan class=\"presentationdate\" dy=\"12%\" x=\"50%\">\n    <xsl:value-of select=\"date:format-date(metadata/date, 'MMMMMMMMMM dd, YYYY, HH:mm:ss')\" />\n  </tspan>\n\n  <!-- [...] -->\n\n</xsl:stylesheet>\n\n\n\nIn this example, the function \nformat-date\n of the EXSLT dates-and-times functions library is used to format a date.\n\n\nOperation Example\n\n\nOperation example with metadata derived from events metadata:\n\n\n<operation\n  id=\"cover-image\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Create a cover image\">\n  <configurations>\n    <configuration key=\"stylesheet\">file://${karaf.etc}/branding/coverimage.xsl</configuration>\n    <configuration key=\"width\">1920</configuration>\n    <configuration key=\"height\">1080</configuration>\n    <configuration key=\"posterimage-flavor\">presenter/coverbackground</configuration>\n    <configuration key=\"target-flavor\">presenter/player+preview</configuration>\n    <configuration key=\"target-tags\">archive, engage-download</configuration>\n </configurations>\n</operation>\n\n\n\nOperation example with metadata provided in the operations configuration:\n\n\n<operation\n  id=\"cover-image\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Create a cover image\">\n  <configurations>\n    <configuration key=\"stylesheet\">file://${karaf.etc}/branding/coverimage.xsl</configuration>\n    <configuration key=\"metadata\">\n      <![CDATA[<meta><title>my custom title</title><special>very special</special></meta>]]>\n    </configuration>\n    <configuration key=\"width\">1920</configuration>\n    <configuration key=\"height\">1080</configuration>\n    <configuration key=\"posterimage-flavor\">presenter/player+preview</configuration>\n    <configuration key=\"target-flavor\">image/cover</configuration>\n </configurations>\n</operation>",
            "title": "Cover Image"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#coverimageworkflowoperationhandler",
            "text": "",
            "title": "CoverImageWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#description",
            "text": "The CoverImageWorkflowOperationHandler generates a cover image based on an XSLT transformation which results in an SVG\nimage that is rasterized as PNG as a last step.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#parameter-table",
            "text": "Name  Type  Example  Default Value  Description      stylesheet *  URL  file:///etc/opencast/branding/coverimage.xsl  -  File URI to the XSL stylesheet used to generate the SVG image    metadata  XML  Hello!  -  XML string which is passed to the XSL transformation. If parameter is not given, a default XML is handed to the transformation    width *  int  1920  -  Width of the resulting image    height *  int  1080  -  Height of the resulting image    posterimage-flavor  Flavor  image/poster  -  Flavor of a poster image which may be used as a part of the cover image (e.g. as a background)    posterimage  URL  http://flickr.com/posterimage.jpg  -  URL to a custom poster image instead of using one out of the media package    target-flavor *  Flavor  image/cover  -  Flavor of the resulting cover image    target-tags  String  archive,download  -  Comma separated list of tags to be applied to the resulting attachment.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#metadata",
            "text": "If no metadata is passed by using the configuration key  metadata , the default metadata is passed to the cover image\nservice which looks like the following example:  <?xml version=\"1.0\"?>\n<metadata>\n  <title>Puppy Love</title>\n  <date>2014-04-24T11:21:00</date>\n  <license>All rights reserved</license>\n  <description>Here is a description of the video</description>\n  <series>Superbowl Commercials</series>\n  <contributors>Budweiser</contributors>\n  <creators>Budweiser</creators>\n  <subjects>Commercial</subjects>\n</metadata>  Note that the date is localized based on your servers Java Runtime language settings.",
            "title": "Metadata"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#stylesheet",
            "text": "The cover image service uses the Xalan XSLT 1.0 processor to transform an XML stylesheet to an SVG image.  The general structure of the stylesheet is expected to look like this:  <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\">\n\n  <xsl:param name=\"width\" />\n  <xsl:param name=\"height\" />\n  <xsl:param name=\"posterimage\" />\n\n  <xsl:template match=\"/\">\n\n    <svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" version=\"1.1\">\n      <xsl:attribute name=\"width\">\n        <xsl:value-of select=\"$width\" />\n      </xsl:attribute>\n      <xsl:attribute name=\"height\">\n        <xsl:value-of select=\"$height\" />\n      </xsl:attribute>\n\n      <!-- Your SVG content -->\n\n  </xsl:template>\n\n</xsl:stylesheet>  The variables  width ,  height  and  posterimage  will be set to the values of the respective configuration keys.  As a starting point for your own template you best take a look at file  etc/branding/coverimage.xsl .",
            "title": "Stylesheet"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#using-xlst-extensions",
            "text": "Xalan is a powerful XSLT 1.0 processor that comes with a rich feature set. For example, it is possible to\nexecute JavaScript or Java code directly within the stylesheet.  For commonly used tasks it is simpler, however, to make use of available XSLT Extensions.",
            "title": "Using XLST Extensions"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#opencast-extensions",
            "text": "The package org.opencastproject.coverimage.impl.xsl provides classes supposed to be used within XSL stylesheets.  To make use of those classes, you need to reference the package from your XSL stylesheet:  <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<xsl:stylesheet version=\"1.0\" xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\"\n  xmlns:opencast=\"xalan://org.opencastproject.coverimage.impl.xsl\" exclude-result-prefixes=\"opencast\"\n  extension-element-prefixes=\"opencast\">\n</xsl:stylesheet>  Later on, you can use methods of those classes as shown in the following example:  <tspan class=\"title\" y=\"30%\" x=\"50%\">\n  <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 1, false())\" />\n</tspan>  Note: In XSLT, use  true()  and  false()  for boolean literals ( true  and  false  won't work since those are not\nkeywords in XSLT)  The following classes are provided by the org.opencastproject.coverimage.impl.xsl package:  class XsltHelper  String split(String text, int maxChars, int line, boolean isLastLine)  This method can be used to break strings over multiple lines and to abbreviate strings that are too using ellipsis.     Parameter  Description      text  Input string    maxChars  Maximum number of characters per line    line  Number of line    isLastLine  Whether  line  is the last line used to represent the  text     Example  To use at most two lines (max. 30 characters per line) to represent a string  metadata/title  and abbreviate the string\nif two lines aren't enough:  <tspan class=\"title\" y=\"30%\" x=\"50%\">\n  <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 1, false())\" />\n</tspan>\n<tspan class=\"title\" dy=\"10%\" x=\"50%\">\n  <xsl:value-of select=\"opencast:XsltHelper.split(metadata/title, 30, 2, true())\" />\n</tspan>",
            "title": "Opencast Extensions"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#exslt-extensions",
            "text": "Xalan supports most of the XSLT extensions of the EXSLT community (see  [1] ). In doubt consult [2]  for more information about Xalan's implementation of the\nEXSLT extensions.  Please find an example of how to use EXSLT extensions below:  <xsl:stylesheet version=\"1.0\"\n  xmlns:xsl=\"http://www.w3.org/1999/XSL/Transform\" xmlns:dcterms=\"http://purl.org/dc/terms/\"\n  xmlns:date=\"http://exslt.org/dates-and-times\"\n  xmlns:opencast=\"xalan://org.opencastproject.coverimage.impl.xsl\" exclude-result-prefixes=\"date\"\n  extension-element-prefixes=\"date\">\n\n  <!-- [...] -->\n\n  <tspan class=\"presentationdate\" dy=\"12%\" x=\"50%\">\n    <xsl:value-of select=\"date:format-date(metadata/date, 'MMMMMMMMMM dd, YYYY, HH:mm:ss')\" />\n  </tspan>\n\n  <!-- [...] -->\n\n</xsl:stylesheet>  In this example, the function  format-date  of the EXSLT dates-and-times functions library is used to format a date.",
            "title": "EXSLT Extensions"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#operation-example",
            "text": "Operation example with metadata derived from events metadata:  <operation\n  id=\"cover-image\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Create a cover image\">\n  <configurations>\n    <configuration key=\"stylesheet\">file://${karaf.etc}/branding/coverimage.xsl</configuration>\n    <configuration key=\"width\">1920</configuration>\n    <configuration key=\"height\">1080</configuration>\n    <configuration key=\"posterimage-flavor\">presenter/coverbackground</configuration>\n    <configuration key=\"target-flavor\">presenter/player+preview</configuration>\n    <configuration key=\"target-tags\">archive, engage-download</configuration>\n </configurations>\n</operation>  Operation example with metadata provided in the operations configuration:  <operation\n  id=\"cover-image\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Create a cover image\">\n  <configurations>\n    <configuration key=\"stylesheet\">file://${karaf.etc}/branding/coverimage.xsl</configuration>\n    <configuration key=\"metadata\">\n      <![CDATA[<meta><title>my custom title</title><special>very special</special></meta>]]>\n    </configuration>\n    <configuration key=\"width\">1920</configuration>\n    <configuration key=\"height\">1080</configuration>\n    <configuration key=\"posterimage-flavor\">presenter/player+preview</configuration>\n    <configuration key=\"target-flavor\">image/cover</configuration>\n </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/",
            "text": "DefaultsWorkflowOperation\n\n\nDescription\n\n\nThe DefaultsWorkflowOperationHandler is used to define default workflow configuration values that are in effect in cases\nwhere a workflow instance is started without the user interface being invoked, with the result that no configuration of\nthe workflow instance has taken place. The defaults specified by this handler will be applied for configuration keys\nthat have not been specified but won't overwrite existing values.\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nkey\n\n\nhello world\n\n\nThis would set the workflow configuration \"key\" to the value \"hello world\" if - and only if - the key is undefined.\n\n\n-\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"defaults\"\n  description=\"Applying default values\">\n  <configurations>\n    <configuration key=\"key\">hello world</configuration>\n  </configurations>\n</operation>",
            "title": "Defaults"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/#defaultsworkflowoperation",
            "text": "",
            "title": "DefaultsWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/#description",
            "text": "The DefaultsWorkflowOperationHandler is used to define default workflow configuration values that are in effect in cases\nwhere a workflow instance is started without the user interface being invoked, with the result that no configuration of\nthe workflow instance has taken place. The defaults specified by this handler will be applied for configuration keys\nthat have not been specified but won't overwrite existing values.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  example  description  default value      key  hello world  This would set the workflow configuration \"key\" to the value \"hello world\" if - and only if - the key is undefined.  -",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/#operation-example",
            "text": "<operation\n  id=\"defaults\"\n  description=\"Applying default values\">\n  <configurations>\n    <configuration key=\"key\">hello world</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/demux-woh/",
            "text": "Demux Workflow Operation\n\n\nDescription\n\n\nThe demux operation can be used to demux multiple streams (e.g. presenter and presentation) from one container and put\nthem into separate tracks. It uses a special encoding profile that has two outputs. It flavors the target media in the\norder listed in the encoding profile output.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\nmultitrack/source\n\n\nWhich media should be encoded\n\n\n\n\n\n\ntarget-tags\n\n\narchive,rss;rss\n\n\nSpecifies the tags of the new media\n\n\n\n\n\n\ntarget-flavors\n\n\npresenter/*,presentation/*\n\n\nSpecifies the flavors of the new media\n\n\n\n\n\n\nencoding-profile\n\n\ndemux\n\n\nSpecifies the encoding profile\n\n\n\n\n\n\n\n\nNote that \ntarget-tags\n can hold multiple sets of tags separated by \n;\n. Each set is applied to the matching set of\noutput files (same order). Target flavors are separated by \n,\n as usual. They are applied in order as well.\n\n\nOperation Example\n\n\n<operation\n  id=\"demux\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Extract presenter and presentation video from multitrack source\">\n  <configurations>\n    <configuration key=\"source-flavors\">multitrack/source</configuration>\n    <configuration key=\"target-flavors\">presenter/source,presentation/source</configuration>\n    <configuration key=\"target-tags\">archive</configuration>\n    <configuration key=\"encoding-profile\">demux</configuration>\n  </configurations>\n</operation>\n\n\n\n\nExample Profile\n\n\nprofile.demux.name = demux\nprofile.demux.input = visual\nprofile.demux.output = visual\nprofile.demux.suffix = .mp4\nprofile.demux.ffmpeg.command = -i #{in.video.path} -c copy \\\n  -map 0:a:0 -map 0:v:0 #{out.dir}/#{out.name}_presenter#{out.suffix} \\\n  -map 0:a:1 -map 0:v:1 #{out.dir}/#{out.name}_presentation#{out.suffix}",
            "title": "Demux"
        },
        {
            "location": "/workflowoperationhandlers/demux-woh/#demux-workflow-operation",
            "text": "",
            "title": "Demux Workflow Operation"
        },
        {
            "location": "/workflowoperationhandlers/demux-woh/#description",
            "text": "The demux operation can be used to demux multiple streams (e.g. presenter and presentation) from one container and put\nthem into separate tracks. It uses a special encoding profile that has two outputs. It flavors the target media in the\norder listed in the encoding profile output.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/demux-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      source-flavors  multitrack/source  Which media should be encoded    target-tags  archive,rss;rss  Specifies the tags of the new media    target-flavors  presenter/*,presentation/*  Specifies the flavors of the new media    encoding-profile  demux  Specifies the encoding profile     Note that  target-tags  can hold multiple sets of tags separated by  ; . Each set is applied to the matching set of\noutput files (same order). Target flavors are separated by  ,  as usual. They are applied in order as well.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/demux-woh/#operation-example",
            "text": "<operation\n  id=\"demux\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Extract presenter and presentation video from multitrack source\">\n  <configurations>\n    <configuration key=\"source-flavors\">multitrack/source</configuration>\n    <configuration key=\"target-flavors\">presenter/source,presentation/source</configuration>\n    <configuration key=\"target-tags\">archive</configuration>\n    <configuration key=\"encoding-profile\">demux</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/demux-woh/#example-profile",
            "text": "profile.demux.name = demux\nprofile.demux.input = visual\nprofile.demux.output = visual\nprofile.demux.suffix = .mp4\nprofile.demux.ffmpeg.command = -i #{in.video.path} -c copy \\\n  -map 0:a:0 -map 0:v:0 #{out.dir}/#{out.name}_presenter#{out.suffix} \\\n  -map 0:a:1 -map 0:v:1 #{out.dir}/#{out.name}_presentation#{out.suffix}",
            "title": "Example Profile"
        },
        {
            "location": "/workflowoperationhandlers/duplicate-event-woh/",
            "text": "Duplicate Event Workflow Operation\n\n\nId: duplicate-event\n\n\nDescription\n\n\nThe duplicate event operation can be used to duplicate an event by copying an existing one. The main use case are events,\nwhich contain a series of different presentations which were all recorded with just one recording. In order to create\nseperate events for each presentation, the original recording can be copied and each copy can be cut to only contain\none presentation. If the original event was already published, the duplicate won't be published right away. The user will\nhave to publish it manually when he is done editing it.\n\n\nFor each duplicated event the new media package ID is stored as a workflow property:\n\n\n\n\n\n\n\n\nName\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nduplicate_media_package_\nnumber\n_id\n\n\nduplicate_media_package_1_id=e72f2265-472a-49ae-bc04-8301d94b4b1a\n\n\nMedia package ID of the duplicated event\n\n\n\n\n\n\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\narchive\n\n\nCopy any mediapackage elements with one of these (comma separated) flavors.\n\n\n\n\n\n\nsource-tags\n\n\n*/*\n\n\nCopy any mediapackage elements with one of these (comma separated) tags.\n\n\n\n\n\n\ntarget-tags\n\n\n+copied\n\n\nApply these (comma separated) tags to any copied media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags.\n\n\n\n\n\n\nproperty-namespaces\n\n\norg.opencastproject.assetmanager.security\n\n\nCopy all asset manager properties of these (comma separated) namespaces.\n\n\n\n\n\n\ncopy-number-prefix\n\n\ncopy\n\n\nThe prefix used for the number of the copy which is appended to the title of the new event.\n\n\n\n\n\n\nnumber-of-events\n\n\n2\n\n\nHow many events to create.\n\n\n\n\n\n\nmax-number-of-events\n\n\n1000\n\n\nHow many events are allowed to be created at maximum.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"duplicate-event\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Duplicate event\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/*</configuration>\n    <configuration key=\"number-of-events\">${numberOfEvents}</configuration>\n    <configuration key=\"max-number-of-events\">1000</configuration>\n    <configuration key=\"target-tags\"></configuration>\n    <configuration key=\"property-namespaces\">\n      org.opencastproject.assetmanager.security\n    </configuration>\n    <configuration key=\"copy-number-prefix\">copy</configuration>\n  </configurations>\n</operation>",
            "title": "Duplicate Event"
        },
        {
            "location": "/workflowoperationhandlers/duplicate-event-woh/#duplicate-event-workflow-operation",
            "text": "Id: duplicate-event",
            "title": "Duplicate Event Workflow Operation"
        },
        {
            "location": "/workflowoperationhandlers/duplicate-event-woh/#description",
            "text": "The duplicate event operation can be used to duplicate an event by copying an existing one. The main use case are events,\nwhich contain a series of different presentations which were all recorded with just one recording. In order to create\nseperate events for each presentation, the original recording can be copied and each copy can be cut to only contain\none presentation. If the original event was already published, the duplicate won't be published right away. The user will\nhave to publish it manually when he is done editing it.  For each duplicated event the new media package ID is stored as a workflow property:     Name  Example  Description      duplicate_media_package_ number _id  duplicate_media_package_1_id=e72f2265-472a-49ae-bc04-8301d94b4b1a  Media package ID of the duplicated event",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/duplicate-event-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      source-flavors  archive  Copy any mediapackage elements with one of these (comma separated) flavors.    source-tags  */*  Copy any mediapackage elements with one of these (comma separated) tags.    target-tags  +copied  Apply these (comma separated) tags to any copied media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags.    property-namespaces  org.opencastproject.assetmanager.security  Copy all asset manager properties of these (comma separated) namespaces.    copy-number-prefix  copy  The prefix used for the number of the copy which is appended to the title of the new event.    number-of-events  2  How many events to create.    max-number-of-events  1000  How many events are allowed to be created at maximum.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/duplicate-event-woh/#operation-example",
            "text": "<operation\n  id=\"duplicate-event\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Duplicate event\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/*</configuration>\n    <configuration key=\"number-of-events\">${numberOfEvents}</configuration>\n    <configuration key=\"max-number-of-events\">1000</configuration>\n    <configuration key=\"target-tags\"></configuration>\n    <configuration key=\"property-namespaces\">\n      org.opencastproject.assetmanager.security\n    </configuration>\n    <configuration key=\"copy-number-prefix\">copy</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/",
            "text": "VideoEditorWorkflowOperationHandler\n\n\nDescription\n\n\nThe editor operation processes the edited files. This operation needs the videoeditor API and impl (or remote on\ndistributed systems) to be installed.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n*/work\n\n\nThe flavor(s) of all media files to process\n\n\n\n\n\n\nsmil-flavors\n\n\n*/smil\n\n\nThe flavor(s) of the SMIL file(s) to be used\n\n\n\n\n\n\nskipped-flavors\n\n\n*/work\n\n\nThe flavor(s) of all media files to be \"processed\" (cloned) if the editor operation is skipped\n\n\n\n\n\n\ntarget-flavor-subtype\n\n\ntrimmed\n\n\nThe flavor subtype to be applied to all resulting videos, e.g. for a value of \nbaz\n, a track with flavor \nfoo/bar\n will generate another track with flavor \nfoo/baz\n\n\n\n\n\n\ntarget-smil-flavor\n\n\nsmil/cutting\n\n\nthe flavor of the SMIL file containing the final video segments.\nShould be the same as the \nsmil.catalog.flavor\n property in \netc/org.opencastproject.adminui.cfg\n\n\n\n\n\n\nskip-if-not-trimmed\n\n\nfalse\n\n\n(Optional) if set to \ntrue\n, the track encoding will be skipped if no trimming points were defined (i.e. there is only one segment from the very beginning to the very end of the video). Defaults to \nfalse\n\n\n\n\n\n\nskip-processing\n\n\ntrue\n\n\nDo not do the actual encoding, just create the smil file and exit. This option is used with \nprocess-smil\n workflow operation, which will use the smil to run the encodings then. Default is false.\n\n\n\n\n\n\npreview_flavors\n\n\n*/preview\n\n\n(Legacy) Flavors used to preview the video in the editor.\nCurrently has no effect. Preview flavors are now configured in the file \netc/org.opencastproject.adminui.cfg\n\n\n\n\n\n\ninteractive\n\n\nfalse\n\n\n(Legacy) If \ntrue\n make the operation interactive, i.e. pause and wait for user input.\nDo not use. Interactive operations are deprecated in the current API.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"editor\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Waiting for user to review / video edit recording\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/work</configuration>\n    <configuration key=\"skipped-flavors\">*/work</configuration>\n    <configuration key=\"smil-flavors\">*/smil</configuration>\n    <configuration key=\"target-smil-flavor\">smil/cutting</configuration>\n    <configuration key=\"target-flavor-subtype\">trimmed</configuration>\n  </configurations>\n</operation>",
            "title": "Editor"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#videoeditorworkflowoperationhandler",
            "text": "",
            "title": "VideoEditorWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#description",
            "text": "The editor operation processes the edited files. This operation needs the videoeditor API and impl (or remote on\ndistributed systems) to be installed.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavors  */work  The flavor(s) of all media files to process    smil-flavors  */smil  The flavor(s) of the SMIL file(s) to be used    skipped-flavors  */work  The flavor(s) of all media files to be \"processed\" (cloned) if the editor operation is skipped    target-flavor-subtype  trimmed  The flavor subtype to be applied to all resulting videos, e.g. for a value of  baz , a track with flavor  foo/bar  will generate another track with flavor  foo/baz    target-smil-flavor  smil/cutting  the flavor of the SMIL file containing the final video segments. Should be the same as the  smil.catalog.flavor  property in  etc/org.opencastproject.adminui.cfg    skip-if-not-trimmed  false  (Optional) if set to  true , the track encoding will be skipped if no trimming points were defined (i.e. there is only one segment from the very beginning to the very end of the video). Defaults to  false    skip-processing  true  Do not do the actual encoding, just create the smil file and exit. This option is used with  process-smil  workflow operation, which will use the smil to run the encodings then. Default is false.    preview_flavors  */preview  (Legacy) Flavors used to preview the video in the editor. Currently has no effect. Preview flavors are now configured in the file  etc/org.opencastproject.adminui.cfg    interactive  false  (Legacy) If  true  make the operation interactive, i.e. pause and wait for user input. Do not use. Interactive operations are deprecated in the current API.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#operation-example",
            "text": "<operation\n  id=\"editor\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Waiting for user to review / video edit recording\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/work</configuration>\n    <configuration key=\"skipped-flavors\">*/work</configuration>\n    <configuration key=\"smil-flavors\">*/smil</configuration>\n    <configuration key=\"target-smil-flavor\">smil/cutting</configuration>\n    <configuration key=\"target-flavor-subtype\">trimmed</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/encode-woh/",
            "text": "Encode Workflow Operation Handler\n\n\n\n\nParallel FFmpeg encoding\n\n\n\n\nDescription\n\n\nThe encode workflow operation can be used to encode media files to different formats using \nFFmpeg\n.\n\n\nIts functionality is similar to the \ncompose workflow operation\n but can utilize the parallel encoding\ncapabilities of FFmpeg. This has the advantage that the source file needs to be read only once for several encodings,\nreducing the encoding time quite a lot. Additionally, this will let FFmpeg make better use of multiple CPU cores.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/work\n\n\nWhich media should be encoded\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/delivery\n\n\nSpecifies the flavor of the new media\n\n\n\n\n\n\nsource-tags\n\n\nsometag\n\n\nTags of media to encode\n\n\n\n\n\n\ntarget-tags\n\n\nsometag\n\n\nSpecifies the tags of the new media\n\n\n\n\n\n\nencoding-profile\n\n\nwebm-hd\n\n\nSpecifies the encoding profile to use\n\n\n\n\n\n\n\n\nAs explained in the \"Encoding Profile\" section, every media file created by an encode operation has its own named\nsuffix. The suffix name is defined in the encode profile definition. It will be added as a tag to the corresponding\ntrack in the media package. This is different from the \ntarget-tags\n workflow operation parameter, which will cause the\nspecified tag list to be added to every media file created by the operation.\n\n\nFor instance, let us take the example operation and encoding profile defined in this documentation. After a successful\nrun of the operation, the media package will contain four new tracks: the first one containing the new tags\n\nengage-download\n, \nengage-streaming\n and \nlow-quality\n; the second one containing the new tags \nengage-download\n,\n\nengage-streaming\n and \nmedium-quality\n; etc.\n\n\nOperation Example\n\n\n<operation\n  id=\"encode\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"encoding media files\">\n    <configurations>\n    <configuration key=\"source-flavor\">*/trimmed</configuration>\n    <configuration key=\"target-flavor\">*/delivery</configuration>\n    <configuration key=\"target-tags\">engage-download,engage-streaming</configuration>\n    <configuration key=\"encoding-profile\">parallel.http</configuration>\n  </configurations>\n</operation>\n\n\n\nEncoding Profile Example\n\n\nUnlike a regular compose operation, this operation can generate more than one output file and, therefore, more than one\nmedia package track elements. In order to distinguish these tracks, the encoding profile syntax for this operation\nallows different named suffix parameters in the form of \n<profile_name>.suffix.<suffix_name> = <suffix_value>\n.\n\n\nBecause file names are irrelevant for the workflow operations, each suffix name is added as a tag to the corresponding\nmedia package element. For instance, if a media file with a filename of \nmyfile.ext\n is processed with the encoding\nprofile in the example below, the first output file will be \nmyfile-low.mp4\n and the resulting media package element\nwill contain a tag with the value \nlow-quality\n; the second output file will be \nmyfile-medium.mp4\n and the resulting\nmedia package element will contain a tag with the value \nmedium-quality\n; and so on.\n\n\n# Distribution format definition for low quality presenter download\nprofile.parallel.http.name = parallel video encoding\nprofile.parallel.http.input = visual\nprofile.parallel.http.output = visual\nprofile.parallel.http.suffix.low-quality = -low.mp4\nprofile.parallel.http.suffix.medium-quality = -medium.mp4\nprofile.parallel.http.suffix.high-quality = -high.mp4\nprofile.parallel.http.suffix.hd-quality = -hd.mp4\nprofile.parallel.http.ffmpeg.command = -i #{in.video.path} \\\n  -c:v libx264 -filter:v yadif,scale=-2:288 -preset slower -crf 28 -r 25 -profile:v baseline -tune film -movflags faststart \\\n  -c:a aac -ar 22050 -ac 1 -ab 32k #{out.dir}/#{out.name}#{out.suffix.low-quality} \\\n  -c:v libx264 -filter:v yadif,scale=-2:360 -preset slower -crf 25 -r 25 -profile:v baseline -tune film -movflags faststart \\\n  -c:a aac -ar 22050 -ac 1 -ab 48k #{out.dir}/#{out.name}#{out.suffix.medium-quality} \\\n  -c:v libx264 -filter:v yadif,scale=-2:576 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film  -movflags faststart \\\n  -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.high-quality} \\\n  -c:v libx264 -filter:v yadif,scale=-2:720 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film  -movflags faststart \\\n  -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.hd-quality}",
            "title": "Encode"
        },
        {
            "location": "/workflowoperationhandlers/encode-woh/#encode-workflow-operation-handler",
            "text": "Parallel FFmpeg encoding",
            "title": "Encode Workflow Operation Handler"
        },
        {
            "location": "/workflowoperationhandlers/encode-woh/#description",
            "text": "The encode workflow operation can be used to encode media files to different formats using  FFmpeg .  Its functionality is similar to the  compose workflow operation  but can utilize the parallel encoding\ncapabilities of FFmpeg. This has the advantage that the source file needs to be read only once for several encodings,\nreducing the encoding time quite a lot. Additionally, this will let FFmpeg make better use of multiple CPU cores.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/encode-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/work  Which media should be encoded    target-flavor  presenter/delivery  Specifies the flavor of the new media    source-tags  sometag  Tags of media to encode    target-tags  sometag  Specifies the tags of the new media    encoding-profile  webm-hd  Specifies the encoding profile to use     As explained in the \"Encoding Profile\" section, every media file created by an encode operation has its own named\nsuffix. The suffix name is defined in the encode profile definition. It will be added as a tag to the corresponding\ntrack in the media package. This is different from the  target-tags  workflow operation parameter, which will cause the\nspecified tag list to be added to every media file created by the operation.  For instance, let us take the example operation and encoding profile defined in this documentation. After a successful\nrun of the operation, the media package will contain four new tracks: the first one containing the new tags engage-download ,  engage-streaming  and  low-quality ; the second one containing the new tags  engage-download , engage-streaming  and  medium-quality ; etc.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/encode-woh/#operation-example",
            "text": "<operation\n  id=\"encode\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"encoding media files\">\n    <configurations>\n    <configuration key=\"source-flavor\">*/trimmed</configuration>\n    <configuration key=\"target-flavor\">*/delivery</configuration>\n    <configuration key=\"target-tags\">engage-download,engage-streaming</configuration>\n    <configuration key=\"encoding-profile\">parallel.http</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/encode-woh/#encoding-profile-example",
            "text": "Unlike a regular compose operation, this operation can generate more than one output file and, therefore, more than one\nmedia package track elements. In order to distinguish these tracks, the encoding profile syntax for this operation\nallows different named suffix parameters in the form of  <profile_name>.suffix.<suffix_name> = <suffix_value> .  Because file names are irrelevant for the workflow operations, each suffix name is added as a tag to the corresponding\nmedia package element. For instance, if a media file with a filename of  myfile.ext  is processed with the encoding\nprofile in the example below, the first output file will be  myfile-low.mp4  and the resulting media package element\nwill contain a tag with the value  low-quality ; the second output file will be  myfile-medium.mp4  and the resulting\nmedia package element will contain a tag with the value  medium-quality ; and so on.  # Distribution format definition for low quality presenter download\nprofile.parallel.http.name = parallel video encoding\nprofile.parallel.http.input = visual\nprofile.parallel.http.output = visual\nprofile.parallel.http.suffix.low-quality = -low.mp4\nprofile.parallel.http.suffix.medium-quality = -medium.mp4\nprofile.parallel.http.suffix.high-quality = -high.mp4\nprofile.parallel.http.suffix.hd-quality = -hd.mp4\nprofile.parallel.http.ffmpeg.command = -i #{in.video.path} \\\n  -c:v libx264 -filter:v yadif,scale=-2:288 -preset slower -crf 28 -r 25 -profile:v baseline -tune film -movflags faststart \\\n  -c:a aac -ar 22050 -ac 1 -ab 32k #{out.dir}/#{out.name}#{out.suffix.low-quality} \\\n  -c:v libx264 -filter:v yadif,scale=-2:360 -preset slower -crf 25 -r 25 -profile:v baseline -tune film -movflags faststart \\\n  -c:a aac -ar 22050 -ac 1 -ab 48k #{out.dir}/#{out.name}#{out.suffix.medium-quality} \\\n  -c:v libx264 -filter:v yadif,scale=-2:576 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film  -movflags faststart \\\n  -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.high-quality} \\\n  -c:v libx264 -filter:v yadif,scale=-2:720 -preset medium -crf 23 -r 25 -pix_fmt yuv420p -tune film  -movflags faststart \\\n  -c:a aac -ar 44100 -ab 96k #{out.dir}/#{out.name}#{out.suffix.hd-quality}",
            "title": "Encoding Profile Example"
        },
        {
            "location": "/workflowoperationhandlers/error-resolution-woh/",
            "text": "Error Resolution Workflow Operation\n\n\nId: error-resolution\n\n\nDescription\n\n\nThe Error Resolution operation is an \ninternal\n operation inserted in the workflow by the Workflow Service\nwhen an operation that has retry-strategy=\"hold\" fails. This operations pauses the workflow so that\nthe user can retry or abort processing using the Admin UI.\n\n\nSee \nRetry Strategies\n for more details.",
            "title": "Error Resolution"
        },
        {
            "location": "/workflowoperationhandlers/error-resolution-woh/#error-resolution-workflow-operation",
            "text": "Id: error-resolution",
            "title": "Error Resolution Workflow Operation"
        },
        {
            "location": "/workflowoperationhandlers/error-resolution-woh/#description",
            "text": "The Error Resolution operation is an  internal  operation inserted in the workflow by the Workflow Service\nwhen an operation that has retry-strategy=\"hold\" fails. This operations pauses the workflow so that\nthe user can retry or abort processing using the Admin UI.  See  Retry Strategies  for more details.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/execute-once-woh/",
            "text": "Execute Once Workflow Operation\n\n\nThis operation handler runs a single command with multiple MediaPackage elements as arguments. The command\nmay be used to create a new mediapackage element, or to add configuration properties to the running workflow.\n\n\nTo run a command for each element in a MediaPackage, use the \nExecute Many\n operation.\n\n\nCommands run by this operation handler must first be included in the \ncommands.allowed\n list in the\n\nExecute Service\n configuration.\n\n\nParameter table\n\n\nAll parameters are empty by default if not specified. The special parameters \n#id\n, \n#flavor\n and \n#out\n are described\nin \nExecute Service: Parameter Substitution\n\n\n\n\n\n\n\n\nConfiguration keys\n\n\nExample\n\n\nDescription\n\n\nRequired?\n\n\n\n\n\n\n\n\n\n\nexec\n\n\nqtfaststart\n\n\nThe command to run\n\n\nYes\n\n\n\n\n\n\nparams\n\n\n-f -t 15 \n#{flavor(presentation/distribute)}\n #{out}\n\n\nThe arguments to the command. This string allows some placeholders for input and output MediaPackage elements (see Parameter Substitution)\n\n\nYes\n\n\n\n\n\n\nload\n\n\n1.5\n\n\nA floating point estimate of the load imposed on the node by this job\n\n\nNo\n\n\n\n\n\n\nset-workflow-properties\n\n\ntrue / false\n\n\nImport workflow properties from the output file\n\n\nNo\n\n\n\n\n\n\noutput-filename\n\n\noutfile.mp4\n\n\nSpecifies the name of the file created by the command (if any), without path information. Used as the last part of the #{out} parameter\n\n\nNo\n\n\n\n\n\n\nexpected-type\n\n\nTrack\n\n\nSpecifies the type of MediaPackage element produced by the command: Manifest, Timeline, Track, Catalog, Attachment, Publication, Other\n\n\nRequired if output- filename is present\n\n\n\n\n\n\ntarget-flavor\n\n\npresentation/processed\n\n\nSpecifies the flavor of the resulting Mediapackage element created by the command. If no new element is created, this parameter is ignored.\n\n\nRequired if output- filename is present\n\n\n\n\n\n\ntarget-tags\n\n\nexecservice, -trim\n\n\nList of tags that will be applied to the resulting Mediapackage element. Tags starting with \"-\" will be deleted from the element instead, if present. The resulting element may be the same as the input element.\n\n\nNo\n\n\n\n\n\n\n\n\nIf \nset-workflow-properties\n is true, the command should write a plain-text properties file to the location specified by\n\n#{out}\n in the key-value format supported by the \nJava\nProperties\n class, for example:\n\n\nkey1=value1\nkey2=value2\n\n\n\n\nOperation Examples\n\n\nRun a command which combines two tracks into a new track:\n\n\n<operation\n  id=\"execute-once\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Run command\">\n  <configurations>\n    <configuration key=\"exec\">ges-launch</configuration>\n    <configuration key=\"params\">-e #{flavor(presenter/source)} 0 5m14s #{flavor(presentation/source)} 0 14s</configuration>\n    <configuration key=\"output-filename\">result.avi</configuration>\n    <configuration key=\"target-flavor\">output/joined</configuration>\n    <configuration key=\"target-tags\">joined, -tojoin</configuration>\n    <configuration key=\"expected-type\">Track</configuration>\n  </configurations>\n</operation>\n\n\n\n\nRun a command which inspects a mediapackage and adds new configuration properties to the running workflow, leaving the\nmediapackage unchanged:\n\n\n<operation\n  id=\"execute-once\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Inspect media and update workflow properties\">\n  <configurations>\n    <configuration key=\"exec\">/usr/local/bin/oc-inspect.sh</configuration>\n    <configuration key=\"params\">#{out} #{id}</configuration>\n    <configuration key=\"set-workflow-properties\">true</configuration>\n    <configuration key=\"output-filename\">wf.properties</configuration>\n    <configuration key=\"expected-type\">Attachment</configuration>\n  </configurations>\n</operation>",
            "title": "Execute Once"
        },
        {
            "location": "/workflowoperationhandlers/execute-once-woh/#execute-once-workflow-operation",
            "text": "This operation handler runs a single command with multiple MediaPackage elements as arguments. The command\nmay be used to create a new mediapackage element, or to add configuration properties to the running workflow.  To run a command for each element in a MediaPackage, use the  Execute Many  operation.  Commands run by this operation handler must first be included in the  commands.allowed  list in the Execute Service  configuration.",
            "title": "Execute Once Workflow Operation"
        },
        {
            "location": "/workflowoperationhandlers/execute-once-woh/#parameter-table",
            "text": "All parameters are empty by default if not specified. The special parameters  #id ,  #flavor  and  #out  are described\nin  Execute Service: Parameter Substitution     Configuration keys  Example  Description  Required?      exec  qtfaststart  The command to run  Yes    params  -f -t 15  #{flavor(presentation/distribute)}  #{out}  The arguments to the command. This string allows some placeholders for input and output MediaPackage elements (see Parameter Substitution)  Yes    load  1.5  A floating point estimate of the load imposed on the node by this job  No    set-workflow-properties  true / false  Import workflow properties from the output file  No    output-filename  outfile.mp4  Specifies the name of the file created by the command (if any), without path information. Used as the last part of the #{out} parameter  No    expected-type  Track  Specifies the type of MediaPackage element produced by the command: Manifest, Timeline, Track, Catalog, Attachment, Publication, Other  Required if output- filename is present    target-flavor  presentation/processed  Specifies the flavor of the resulting Mediapackage element created by the command. If no new element is created, this parameter is ignored.  Required if output- filename is present    target-tags  execservice, -trim  List of tags that will be applied to the resulting Mediapackage element. Tags starting with \"-\" will be deleted from the element instead, if present. The resulting element may be the same as the input element.  No     If  set-workflow-properties  is true, the command should write a plain-text properties file to the location specified by #{out}  in the key-value format supported by the  Java\nProperties  class, for example:  key1=value1\nkey2=value2",
            "title": "Parameter table"
        },
        {
            "location": "/workflowoperationhandlers/execute-once-woh/#operation-examples",
            "text": "Run a command which combines two tracks into a new track:  <operation\n  id=\"execute-once\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Run command\">\n  <configurations>\n    <configuration key=\"exec\">ges-launch</configuration>\n    <configuration key=\"params\">-e #{flavor(presenter/source)} 0 5m14s #{flavor(presentation/source)} 0 14s</configuration>\n    <configuration key=\"output-filename\">result.avi</configuration>\n    <configuration key=\"target-flavor\">output/joined</configuration>\n    <configuration key=\"target-tags\">joined, -tojoin</configuration>\n    <configuration key=\"expected-type\">Track</configuration>\n  </configurations>\n</operation>  Run a command which inspects a mediapackage and adds new configuration properties to the running workflow, leaving the\nmediapackage unchanged:  <operation\n  id=\"execute-once\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Inspect media and update workflow properties\">\n  <configurations>\n    <configuration key=\"exec\">/usr/local/bin/oc-inspect.sh</configuration>\n    <configuration key=\"params\">#{out} #{id}</configuration>\n    <configuration key=\"set-workflow-properties\">true</configuration>\n    <configuration key=\"output-filename\">wf.properties</configuration>\n    <configuration key=\"expected-type\">Attachment</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Examples"
        },
        {
            "location": "/workflowoperationhandlers/execute-many-woh/",
            "text": "Execute Many Workflow Operation\n\n\nThis operation handler filters a set of MediaPackageElements that match certain input conditions and runs a command on\neach of them.\n\n\nTo run a command only once for the whole mediapackage, use the \nExecute Once\n operation.\n\n\nCommands run by this operation handler must first be included in the \ncommands.allowed\n list in the\n\nExecute Service\n configuration.\n\n\nParameter table\n\n\nAll parameters are empty by default if not specified. The special parameters \n#in\n and \n#out\n are described\nin \nExecute Service: Parameter Substitution\n\n\n\n\n\n\n\n\nConfiguration keys\n\n\nExample\n\n\nDescription\n\n\nRequired?\n\n\n\n\n\n\n\n\n\n\nexec\n\n\nqtfaststart\n\n\nThe command to run\n\n\nYes\n\n\n\n\n\n\nparams\n\n\n-f -t 15 #{in} #{out}\n\n\nThe arguments to the command. This string allows some placeholders for input and output MediaPackage elements (see Parameter Substitution)\n\n\nYes\n\n\n\n\n\n\nload\n\n\n1.5\n\n\nA floating point estimate of the load imposed on the node by this job\n\n\nNo\n\n\n\n\n\n\nsource-flavor\n\n\npresentation/source\n\n\nRun the command for any MediaPackage elements with this flavor. Elements must also match the source-tags condition, if present\n\n\nNo\n\n\n\n\n\n\nsource-tag\n\n\nrss, trim, -engage\n\n\nRun the command for any MediaPackage elements with one of these (comma- separated) tags. If any of them starts with '-', MediaPackage elements containing this tag will be excluded. Elements must also match the source-flavor condition, if present\n\n\nNo\n\n\n\n\n\n\noutput-filename\n\n\noutfile.mp4\n\n\nSpecifies the name of the file created by the command (if any), without path information. Used as the last part of the #{out} parameter\n\n\nNo\n\n\n\n\n\n\nexpected-type\n\n\nTrack\n\n\nSpecifies the type of MediaPackage element produced by the command: Manifest, Timeline, Track, Catalog, Attachment, Publication, Other\n\n\nRequired if output- filename is present\n\n\n\n\n\n\ntarget-flavor\n\n\npresentation/processed\n\n\nSpecifies the flavor of the resulting Mediapackage element created by the command\n\n\nRequired if output- filename is present\n\n\n\n\n\n\ntarget-tags\n\n\nexecservice, -trim\n\n\nList of tags that will be applied to the resulting Mediapackage element. Tags starting with \"-\" will be deleted from the element instead, if present. The resulting element may be the same as the input element\n\n\nNo\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"execute-many\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Run command\">\n  <configurations>\n    <configuration key=\"exec\">qt-faststart</configuration>\n    <configuration key=\"params\">-f #{in} #{out}</configuration>\n    <configuration key=\"source-flavor\">*/toprocess</configuration>\n    <configuration key=\"source-tags\">copy, -rss</configuration>\n    <configuration key=\"output-filename\">result.avi</configuration>\n    <configuration key=\"target-flavor\">output/processed</configuration>\n    <configuration key=\"target-tags\">copied, -copy</configuration>\n    <configuration key=\"expected-type\">Track</configuration>\n  </configurations>\n</operation>",
            "title": "Execute Many"
        },
        {
            "location": "/workflowoperationhandlers/execute-many-woh/#execute-many-workflow-operation",
            "text": "This operation handler filters a set of MediaPackageElements that match certain input conditions and runs a command on\neach of them.  To run a command only once for the whole mediapackage, use the  Execute Once  operation.  Commands run by this operation handler must first be included in the  commands.allowed  list in the Execute Service  configuration.",
            "title": "Execute Many Workflow Operation"
        },
        {
            "location": "/workflowoperationhandlers/execute-many-woh/#parameter-table",
            "text": "All parameters are empty by default if not specified. The special parameters  #in  and  #out  are described\nin  Execute Service: Parameter Substitution     Configuration keys  Example  Description  Required?      exec  qtfaststart  The command to run  Yes    params  -f -t 15 #{in} #{out}  The arguments to the command. This string allows some placeholders for input and output MediaPackage elements (see Parameter Substitution)  Yes    load  1.5  A floating point estimate of the load imposed on the node by this job  No    source-flavor  presentation/source  Run the command for any MediaPackage elements with this flavor. Elements must also match the source-tags condition, if present  No    source-tag  rss, trim, -engage  Run the command for any MediaPackage elements with one of these (comma- separated) tags. If any of them starts with '-', MediaPackage elements containing this tag will be excluded. Elements must also match the source-flavor condition, if present  No    output-filename  outfile.mp4  Specifies the name of the file created by the command (if any), without path information. Used as the last part of the #{out} parameter  No    expected-type  Track  Specifies the type of MediaPackage element produced by the command: Manifest, Timeline, Track, Catalog, Attachment, Publication, Other  Required if output- filename is present    target-flavor  presentation/processed  Specifies the flavor of the resulting Mediapackage element created by the command  Required if output- filename is present    target-tags  execservice, -trim  List of tags that will be applied to the resulting Mediapackage element. Tags starting with \"-\" will be deleted from the element instead, if present. The resulting element may be the same as the input element  No",
            "title": "Parameter table"
        },
        {
            "location": "/workflowoperationhandlers/execute-many-woh/#operation-example",
            "text": "<operation\n  id=\"execute-many\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Run command\">\n  <configurations>\n    <configuration key=\"exec\">qt-faststart</configuration>\n    <configuration key=\"params\">-f #{in} #{out}</configuration>\n    <configuration key=\"source-flavor\">*/toprocess</configuration>\n    <configuration key=\"source-tags\">copy, -rss</configuration>\n    <configuration key=\"output-filename\">result.avi</configuration>\n    <configuration key=\"target-flavor\">output/processed</configuration>\n    <configuration key=\"target-tags\">copied, -copy</configuration>\n    <configuration key=\"expected-type\">Track</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/export-wf-properties-woh/",
            "text": "ExportWfPropertiesWorkflowOperationHandler\n\n\nDescription\n\n\nThe ExportWfPropertiesWorkflowOperation can be used to export workflow properties to a Java properties file. Those\nproperties can later be imported using the \nImportWfPropertiesWorkflowOperation\n.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntarget-flavor*\n\n\nprocessing/defaults\n\n\nThe flavor to apply to the exported workflow properties\n\n\n\n\n\n\ntarget-tags\n\n\narchive\n\n\nThe tags to apply to the exported workflow properties\n\n\n\n\n\n\nkeys\n\n\nvariableName1, variableName2\n\n\nThe workflow property keys that need to be persisted. If the option is not specified, all defined properties should be persisted.\n\n\n\n\n\n\n\n\n* mandatory configuration key\n\n\nOperation Example\n\n\n<operation\n  id=\"export-wf-properties\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Export workflow settings to Java properties file\">\n  <configurations>\n    <configuration key=\"target-flavor\">processing/defaults</configuration>\n    <configuration key=\"target-tags\">archive</configuration>\n  </configurations>\n</operation>",
            "title": "Export Workflow Properties"
        },
        {
            "location": "/workflowoperationhandlers/export-wf-properties-woh/#exportwfpropertiesworkflowoperationhandler",
            "text": "",
            "title": "ExportWfPropertiesWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/export-wf-properties-woh/#description",
            "text": "The ExportWfPropertiesWorkflowOperation can be used to export workflow properties to a Java properties file. Those\nproperties can later be imported using the  ImportWfPropertiesWorkflowOperation .",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/export-wf-properties-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      target-flavor*  processing/defaults  The flavor to apply to the exported workflow properties    target-tags  archive  The tags to apply to the exported workflow properties    keys  variableName1, variableName2  The workflow property keys that need to be persisted. If the option is not specified, all defined properties should be persisted.     * mandatory configuration key",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/export-wf-properties-woh/#operation-example",
            "text": "<operation\n  id=\"export-wf-properties\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Export workflow settings to Java properties file\">\n  <configurations>\n    <configuration key=\"target-flavor\">processing/defaults</configuration>\n    <configuration key=\"target-tags\">archive</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/",
            "text": "ExtractTextWorkflowOperation\n\n\nDescription\n\n\nThe ExtractTextWorkflowOperation will try to extract test from a video using Tesseract OCR.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresentation/work\n\n\nSpecifies which media should be processed\n\n\n\n\n\n\nsource-tags\n\n\ntext\n\n\nSpecifies which media should be processed\n\n\n\n\n\n\ntarget-tags\n\n\nengage\n\n\nSpecifies the tags for the produces media\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"extract-text\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"error\"\n  description=\"Extracting text from presentation segments\">\n  <configurations>\n    <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n    <configuration key=\"source-tags\"></configuration>\n    <configuration key=\"target-tags\">engage,archive</configuration>\n  </configurations>\n</operation>",
            "title": "Extract Text"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/#extracttextworkflowoperation",
            "text": "",
            "title": "ExtractTextWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/#description",
            "text": "The ExtractTextWorkflowOperation will try to extract test from a video using Tesseract OCR.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presentation/work  Specifies which media should be processed    source-tags  text  Specifies which media should be processed    target-tags  engage  Specifies the tags for the produces media",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/#operation-example",
            "text": "<operation\n  id=\"extract-text\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"error\"\n  description=\"Extracting text from presentation segments\">\n  <configurations>\n    <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n    <configuration key=\"source-tags\"></configuration>\n    <configuration key=\"target-tags\">engage,archive</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/failing-woh/",
            "text": "Failing Workflow Operation\n\n\nId: failing\n\n\nDescription\n\n\nThe Failing operation will always fail and is supposed to be used for \ntesting purposes\n only.",
            "title": "Failing"
        },
        {
            "location": "/workflowoperationhandlers/failing-woh/#failing-workflow-operation",
            "text": "Id: failing",
            "title": "Failing Workflow Operation"
        },
        {
            "location": "/workflowoperationhandlers/failing-woh/#description",
            "text": "The Failing operation will always fail and is supposed to be used for  testing purposes  only.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/",
            "text": "HttpNotificationWorkflowOperation\n\n\nDescription\n\n\nOpencast can through this operation notify any HTTP endpoint about the process of the workflow.\n\n\nParameter Table A parameter that is always posted is the workflow instance identifier in the parameter named\n\n\nworkflowInstanceId\n containing the current workflow\u2019s identifier.\n\n\n\n\n\n\n\n\nKey\n\n\nRequired\n\n\nDescription\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nurl\n\n\ntrue\n\n\nThe target url to notify\n\n\nhttp://test.ch\n\n\n\n\n\n\nsubject\n\n\nfalse\n\n\nThe name of the event to notify from. The following events are planned: importing_started, imported, prepared, processing_started, published\n\n\nimporting_started\n\n\n\n\n\n\nmessage\n\n\nfalse\n\n\nData supporting the notification. Think of this as the body of an e-mail\n\n\ninternal::25\n\n\n\n\n\n\nmethod\n\n\nfalse\n\n\nSupported methods are \"put\", \"post\". If no method is specified, \"post\" is used by default\n\n\npost\n\n\n\n\n\n\nmax-retry\n\n\nfalse\n\n\nThe maximal number of notification attempts. The default value is 5\n\n\n5\n\n\n\n\n\n\ntimeout\n\n\nfalse\n\n\nThe timeout in seconds for the notification request: The default value is 10\n\n\n10\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"http-notify\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"error\"\n  description=\"Notify test\">\n  <configurations>\n    <configuration key=\"url\">http://www.test.ch</configuration>\n    <configuration key=\"subject\">importing-started</configuration>\n    <configuration key=\"message\">internal::25</configuration>\n    <configuration key=\"method\">put</configuration>\n    <configuration key=\"max-retry\">3</configuration>\n    <configuration key=\"timeout\">5</configuration>\n  </configurations>\n</operation>",
            "title": "HTTP Notify"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/#httpnotificationworkflowoperation",
            "text": "",
            "title": "HttpNotificationWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/#description",
            "text": "Opencast can through this operation notify any HTTP endpoint about the process of the workflow.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/#parameter-table-a-parameter-that-is-always-posted-is-the-workflow-instance-identifier-in-the-parameter-named",
            "text": "workflowInstanceId  containing the current workflow\u2019s identifier.     Key  Required  Description  Example      url  true  The target url to notify  http://test.ch    subject  false  The name of the event to notify from. The following events are planned: importing_started, imported, prepared, processing_started, published  importing_started    message  false  Data supporting the notification. Think of this as the body of an e-mail  internal::25    method  false  Supported methods are \"put\", \"post\". If no method is specified, \"post\" is used by default  post    max-retry  false  The maximal number of notification attempts. The default value is 5  5    timeout  false  The timeout in seconds for the notification request: The default value is 10  10",
            "title": "Parameter Table A parameter that is always posted is the workflow instance identifier in the parameter named"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/#operation-example",
            "text": "<operation\n  id=\"http-notify\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"error\"\n  description=\"Notify test\">\n  <configurations>\n    <configuration key=\"url\">http://www.test.ch</configuration>\n    <configuration key=\"subject\">importing-started</configuration>\n    <configuration key=\"message\">internal::25</configuration>\n    <configuration key=\"method\">put</configuration>\n    <configuration key=\"max-retry\">3</configuration>\n    <configuration key=\"timeout\">5</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/",
            "text": "ImageWorkflowOperation\n\n\nDescription\n\n\nThe ImageWorkflowOperation will extract still images from a video using FFmpeg and a list of given encoding profiles.\nBoth absolute and relative positions can be used.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/source\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\nsource-flavors\n\n\npresenter/source, presentation/source\n\n\nSpecifies a list of media which should be processed. In case a flavor has been specified in \nsource-flavor\n, it will be added to this list.\n\n\n\n\n\n\nsource-tags\n\n\nengage\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/work\n\n\nSpecifies the flavor the new files will get.\n\n\n\n\n\n\ntarget-tags\n\n\nengage\n\n\nSpecifies the tags the new files will get.\n\n\n\n\n\n\nencoding-profile\n\n\nsearch-cover.http\n\n\nComma-separated list of encoding profiles to use.\n\n\n\n\n\n\ntime\n\n\n1\n\n\nComma-separated list of time (in seconds or relative to source track duration) where the image should be taken.\n\n\n\n\n\n\ntarget-base-name-format-second\n\n\nthumbnail_%.0f%s\n\n\nUsed to control the target filenames for images extracted at absolute times. Mainly helpful when integrating third-party applications that prefer to use filename to distinguish individual images\n\n\n\n\n\n\ntarget-base-name-format-percent\n\n\nthumbnail_%.3f%s\n\n\nUsed to control the target filenames for images extracted at relative times. Mainly helpful when integrating third-party applications that prefer to use filename to distinguish individual images\n\n\n\n\n\n\nend-margin\n\n\n500\n\n\nSafety margin at the end of the track. Sometimes, image extraction is critical at the end of the file. Using \nend-margin\n ensures, that no images are being extracted near the end of the video file to avoid problems with defective inputs.\n(Default: 100)\n\n\n\n\n\n\n\n\nNotes:\n\n\n\n\nAbsolute and relative position may be mixed up in the configuration key \ntime\n\n\n\n\nOperation Example\n\n\nBasic\n\n\nExtract one image at position 1 second using the encoding profile \nsearch-cover.http\n.\n\n\n<operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encoding presenter (camera) to search result preview image\">\n      <configurations>\n            <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-flavor\">presenter/search+preview</configuration>\n            <configuration key=\"target-tags\">engage</configuration>\n            <configuration key=\"encoding-profile\">search-cover.http</configuration>\n            <configuration key=\"time\">1</configuration>\n      </configurations>\n</operation>\n\n\n\nAdvanced\n\n\nIn this example, we extract images at three relative positions (\n1%, 50%, 100%\n) from the presenter/trimmed track. For\neach position, we extract three images using three different encoding profiles (\nexample.encoding.profile.*\n). This\noperation therefore generates nine images in total. The target filenames will be formed based on the\n\ntarget-base-name-format-*\n configuration keys (prefix) and the configuration of the encoding profiles (file extension\nand possibly suffix).\n\n\n<operation id=\"image\"\n           description=\"Extract set of thumbnails\"\n           fail-on-error=\"true\"\n           exception-handler-workflow=\"partial-error\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n    <configuration key=\"target-flavor\">presenter/thumbnails</configuration>\n    <configuration key=\"target-base-name-format-second\">thumbnail_%.3f%s</configuration>\n    <configuration key=\"target-base-name-format-percent\">thumbnail_%.0f%s</configuration>\n    <configuration key=\"encoding-profile\"> example.encoding.profile.small, example.encoding.profile.medium, example.encoding.profile.large</configuration>\n    <configuration key=\"time\">1%, 50%, 100%</configuration>\n    <configuration key=\"end-margin\">1000</configuration>\n  </configurations>\n</operation>",
            "title": "Image"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#imageworkflowoperation",
            "text": "",
            "title": "ImageWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#description",
            "text": "The ImageWorkflowOperation will extract still images from a video using FFmpeg and a list of given encoding profiles.\nBoth absolute and relative positions can be used.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/source  Specifies which media should be processed.    source-flavors  presenter/source, presentation/source  Specifies a list of media which should be processed. In case a flavor has been specified in  source-flavor , it will be added to this list.    source-tags  engage  Specifies which media should be processed.    target-flavor  presenter/work  Specifies the flavor the new files will get.    target-tags  engage  Specifies the tags the new files will get.    encoding-profile  search-cover.http  Comma-separated list of encoding profiles to use.    time  1  Comma-separated list of time (in seconds or relative to source track duration) where the image should be taken.    target-base-name-format-second  thumbnail_%.0f%s  Used to control the target filenames for images extracted at absolute times. Mainly helpful when integrating third-party applications that prefer to use filename to distinguish individual images    target-base-name-format-percent  thumbnail_%.3f%s  Used to control the target filenames for images extracted at relative times. Mainly helpful when integrating third-party applications that prefer to use filename to distinguish individual images    end-margin  500  Safety margin at the end of the track. Sometimes, image extraction is critical at the end of the file. Using  end-margin  ensures, that no images are being extracted near the end of the video file to avoid problems with defective inputs. (Default: 100)     Notes:   Absolute and relative position may be mixed up in the configuration key  time",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#operation-example",
            "text": "",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#basic",
            "text": "Extract one image at position 1 second using the encoding profile  search-cover.http .  <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encoding presenter (camera) to search result preview image\">\n      <configurations>\n            <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-flavor\">presenter/search+preview</configuration>\n            <configuration key=\"target-tags\">engage</configuration>\n            <configuration key=\"encoding-profile\">search-cover.http</configuration>\n            <configuration key=\"time\">1</configuration>\n      </configurations>\n</operation>",
            "title": "Basic"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#advanced",
            "text": "In this example, we extract images at three relative positions ( 1%, 50%, 100% ) from the presenter/trimmed track. For\neach position, we extract three images using three different encoding profiles ( example.encoding.profile.* ). This\noperation therefore generates nine images in total. The target filenames will be formed based on the target-base-name-format-*  configuration keys (prefix) and the configuration of the encoding profiles (file extension\nand possibly suffix).  <operation id=\"image\"\n           description=\"Extract set of thumbnails\"\n           fail-on-error=\"true\"\n           exception-handler-workflow=\"partial-error\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n    <configuration key=\"target-flavor\">presenter/thumbnails</configuration>\n    <configuration key=\"target-base-name-format-second\">thumbnail_%.3f%s</configuration>\n    <configuration key=\"target-base-name-format-percent\">thumbnail_%.0f%s</configuration>\n    <configuration key=\"encoding-profile\"> example.encoding.profile.small, example.encoding.profile.medium, example.encoding.profile.large</configuration>\n    <configuration key=\"time\">1%, 50%, 100%</configuration>\n    <configuration key=\"end-margin\">1000</configuration>\n  </configurations>\n</operation>",
            "title": "Advanced"
        },
        {
            "location": "/workflowoperationhandlers/image-convert-woh/",
            "text": "Image-Convert Workflow Operation\n\n\nDescription\n\n\nThe Image-Convert workflow operation allows source images to be converted into target images with different encoding\nsettings. One example is the conversion of preview images into different formats.\n\n\nThis operation expects an attachment as input and creates one attachment as output.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-tags*\n\n\npreview+player,preview+search\n\n\nA comma separated lsit of source image(s) tags.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavors*\n\n\n*/image\n\n\nA comma separated list of source image(s) flavors.\n\n\nEMPTY\n\n\n\n\n\n\ntags-and-flavors\n\n\nfalse\n\n\nAn boolean value wether to select elements with tags and flavors (then set this option to true) or either tags or flavors (then set this option to false).\n\n\nfalse\n\n\n\n\n\n\ntarget-tags\n\n\n+preview-converted,-preview+player\n\n\nApply these (comma separated) tags to the output attachments. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor*\n\n\n*/image+converted\n\n\nApply these flavor to the output attachments.\n\n\nEMPTY\n\n\n\n\n\n\nencoding-profiles*\n\n\njpeg-player,jpeg-search\n\n\nA comma separated list of encoding profiles to be applied to each input image.\n\n\nEMPTY\n\n\n\n\n\n\n\n\n* mandatory configuration key\n\n\nNote: At least \nsource-tags\n or \nsource-flavors\n parameter must be set.\n\n\nOperation Example\n\n\nThis operation would convert all image attachments with flavor matches \n*/preview\n and tag \nplayer\n into two different\nformats described by the encoding profiles \npreview-regular.image\n and \npreview-small.image\n.\nThe produced image attachments will have an flavor with the subtype \npreview+player\n.\n\n\n<operation\n  id=\"image-convert\"\n  exception-handler-workflow=\"error\"\n  description=\"Resize images to fixed size\">\n  <configurations>\n    <configuration key=\"source-tags\">player</configuration>\n    <configuration key=\"source-flavors\">*/preview</configuration>\n    <configuration key=\"tags-and-flavors\">true</configuration>\n    <configuration key=\"target-tags\"></configuration>\n    <configuration key=\"target-flavor\">*/preview+player</configuration>\n    <configuration key=\"encoding-profiles\">preview-regular.image,preview-small.image</configuration>\n  </configurations>\n</operation>\n\n\n\nEncoding Profile Example\n\n\n# Player preview image regular size\nprofile.preview-regular.image.name = player preview image regular size\nprofile.preview-regular.image.input = image\nprofile.preview-regular.image.output = image\nprofile.preview-regular.image.suffix = -preview-regular.jpg\nprofile.preview-regular.image.mimetype = image/jpeg\nprofile.preview-regular.image.ffmpeg.command = -i #{in.video.path} -vf scale=480:-2 #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Image convert"
        },
        {
            "location": "/workflowoperationhandlers/image-convert-woh/#image-convert-workflow-operation",
            "text": "",
            "title": "Image-Convert Workflow Operation"
        },
        {
            "location": "/workflowoperationhandlers/image-convert-woh/#description",
            "text": "The Image-Convert workflow operation allows source images to be converted into target images with different encoding\nsettings. One example is the conversion of preview images into different formats.  This operation expects an attachment as input and creates one attachment as output.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/image-convert-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-tags*  preview+player,preview+search  A comma separated lsit of source image(s) tags.  EMPTY    source-flavors*  */image  A comma separated list of source image(s) flavors.  EMPTY    tags-and-flavors  false  An boolean value wether to select elements with tags and flavors (then set this option to true) or either tags or flavors (then set this option to false).  false    target-tags  +preview-converted,-preview+player  Apply these (comma separated) tags to the output attachments. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags.  EMPTY    target-flavor*  */image+converted  Apply these flavor to the output attachments.  EMPTY    encoding-profiles*  jpeg-player,jpeg-search  A comma separated list of encoding profiles to be applied to each input image.  EMPTY     * mandatory configuration key  Note: At least  source-tags  or  source-flavors  parameter must be set.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/image-convert-woh/#operation-example",
            "text": "This operation would convert all image attachments with flavor matches  */preview  and tag  player  into two different\nformats described by the encoding profiles  preview-regular.image  and  preview-small.image .\nThe produced image attachments will have an flavor with the subtype  preview+player .  <operation\n  id=\"image-convert\"\n  exception-handler-workflow=\"error\"\n  description=\"Resize images to fixed size\">\n  <configurations>\n    <configuration key=\"source-tags\">player</configuration>\n    <configuration key=\"source-flavors\">*/preview</configuration>\n    <configuration key=\"tags-and-flavors\">true</configuration>\n    <configuration key=\"target-tags\"></configuration>\n    <configuration key=\"target-flavor\">*/preview+player</configuration>\n    <configuration key=\"encoding-profiles\">preview-regular.image,preview-small.image</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/image-convert-woh/#encoding-profile-example",
            "text": "# Player preview image regular size\nprofile.preview-regular.image.name = player preview image regular size\nprofile.preview-regular.image.input = image\nprofile.preview-regular.image.output = image\nprofile.preview-regular.image.suffix = -preview-regular.jpg\nprofile.preview-regular.image.mimetype = image/jpeg\nprofile.preview-regular.image.ffmpeg.command = -i #{in.video.path} -vf scale=480:-2 #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Encoding Profile Example"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/",
            "text": "ImageToVideo Workflow Operation Handler\n\n\nDescription\n\n\nThe ImageToVideo Workflow Operation Handler allows to create a video track from a source image.\n\n\nParameters table\n\n\nTags and flavors can be used in combination. But combined they should match one image.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-tags\n*\n\n\nintro\n\n\nA comma separated list of tags of the input image\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor\n*\n\n\nintro/source\n\n\nThe \"flavor\" of the image to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\ncomposite,rss,atom,archive\n\n\nThe tags to apply to the output video track\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\nintro/work\n\n\nThe flavor to apply to the output video track\n\n\nEMPTY\n\n\n\n\n\n\nduration\n*\n\n\n5\n\n\nThe length of the output video in seconds.\n\n\nEMPTY\n\n\n\n\n\n\nprofile\n*\n\n\nimage-movie\n\n\nDefine the encoding-profile to use to create the output video. See example of profile below.\n\n\nEMPTY\n\n\n\n\n\n\n\n\n* \nmandatory\n\n\nOperation example\n\n\n<operation\n  id=\"image-to-video\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Composite\">\n  <configurations>\n    <configuration key=\"source-tags\">intro</configuration>\n    <configuration key=\"source-flavor\">intro/source</configuration>\n    <configuration key=\"target-tags\">intro-video</configuration>\n    <configuration key=\"target-flavor\">intro/video</configuration>\n    <configuration key=\"duration\">10</configuration>\n    <configuration key=\"profile\">image-movie</configuration>\n  </configurations>\n</operation>\n\n\n\n\nEncoding profile example\n\n\n# Image to video\nprofile.image-movie.name = image to video\nprofile.image-movie.input = image\nprofile.image-movie.output = visual\nprofile.image-movie.suffix = -image-video.mp4\nprofile.image-movie.ffmpeg.command = -loop 1 -i #{in.video.path} -c:v libx264 -r 25 -t #{time} -pix_fmt yuv420p #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Image to Video"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#imagetovideo-workflow-operation-handler",
            "text": "",
            "title": "ImageToVideo Workflow Operation Handler"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#description",
            "text": "The ImageToVideo Workflow Operation Handler allows to create a video track from a source image.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#parameters-table",
            "text": "Tags and flavors can be used in combination. But combined they should match one image.     configuration keys  example  description  default value      source-tags *  intro  A comma separated list of tags of the input image  EMPTY    source-flavor *  intro/source  The \"flavor\" of the image to use as a source input  EMPTY    target-tags  composite,rss,atom,archive  The tags to apply to the output video track  EMPTY    target-flavor  intro/work  The flavor to apply to the output video track  EMPTY    duration *  5  The length of the output video in seconds.  EMPTY    profile *  image-movie  Define the encoding-profile to use to create the output video. See example of profile below.  EMPTY     *  mandatory",
            "title": "Parameters table"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#operation-example",
            "text": "<operation\n  id=\"image-to-video\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Composite\">\n  <configurations>\n    <configuration key=\"source-tags\">intro</configuration>\n    <configuration key=\"source-flavor\">intro/source</configuration>\n    <configuration key=\"target-tags\">intro-video</configuration>\n    <configuration key=\"target-flavor\">intro/video</configuration>\n    <configuration key=\"duration\">10</configuration>\n    <configuration key=\"profile\">image-movie</configuration>\n  </configurations>\n</operation>",
            "title": "Operation example"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#encoding-profile-example",
            "text": "# Image to video\nprofile.image-movie.name = image to video\nprofile.image-movie.input = image\nprofile.image-movie.output = visual\nprofile.image-movie.suffix = -image-video.mp4\nprofile.image-movie.ffmpeg.command = -loop 1 -i #{in.video.path} -c:v libx264 -r 25 -t #{time} -pix_fmt yuv420p #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Encoding profile example"
        },
        {
            "location": "/workflowoperationhandlers/import-wf-properties-woh/",
            "text": "ImportWfPropertiesWorkflowOperationHandler\n\n\nDescription\n\n\nThe ImportWfPropertiesWorkflowOperationHandler loads workflow properties from a Java properties file and sets\nthe corresponding workflow instance variables so that the properties can be use to control workflow execution.\n\n\nIn case that no properties are found in \nsource-flavor\n, the workflow operation will just skip.\n\n\nNote that the \nExportWfPropertiesWorkflowOperationHandler\n can be used to export workflow\nproperties to a Java properties file.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor*\n\n\nprocessing/defaults\n\n\nFlavor of the attachment that contains the serialized workflow instance properties\n\n\n\n\n\n\nkeys\n\n\nvariableName1, variableName2\n\n\nThe workflow property keys to retrieve (comma separated list). If the option has not been specified, all keys will be retrieved\n\n\n\n\n\n\n\n\n* mandatory configuration key\n\n\nOperation Example\n\n\n<operation\n  id=\"import-wf-properties\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Load processing settings\">\n  <configurations>\n    <configuration key=\"source-flavor\">processing/defaults</configuration>\n  </configurations>\n</operation>",
            "title": "Import Workflow Properties"
        },
        {
            "location": "/workflowoperationhandlers/import-wf-properties-woh/#importwfpropertiesworkflowoperationhandler",
            "text": "",
            "title": "ImportWfPropertiesWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/import-wf-properties-woh/#description",
            "text": "The ImportWfPropertiesWorkflowOperationHandler loads workflow properties from a Java properties file and sets\nthe corresponding workflow instance variables so that the properties can be use to control workflow execution.  In case that no properties are found in  source-flavor , the workflow operation will just skip.  Note that the  ExportWfPropertiesWorkflowOperationHandler  can be used to export workflow\nproperties to a Java properties file.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/import-wf-properties-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      source-flavor*  processing/defaults  Flavor of the attachment that contains the serialized workflow instance properties    keys  variableName1, variableName2  The workflow property keys to retrieve (comma separated list). If the option has not been specified, all keys will be retrieved     * mandatory configuration key",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/import-wf-properties-woh/#operation-example",
            "text": "<operation\n  id=\"import-wf-properties\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Load processing settings\">\n  <configurations>\n    <configuration key=\"source-flavor\">processing/defaults</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/",
            "text": "IncidentCreatorWorkflowOperationHandler\n\n\nDescription\n\n\nThe IncidentCreatorWorkflowOperationHandler creates an incident on a dummy job used for integration testing.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\ncode\n\n\n2\n\n\nThe code number of the incident to produce.\n\n\n1\n\n\n\n\n\n\nseverity\n\n\nWARNING\n\n\nThe severity. See Incident.Severity enum.\n\n\nINFO\n\n\n\n\n\n\ndetails\n\n\n\"tagged,+rss\" / \"-rss,+tagged\"\n\n\nSome details: title=content;title=content;...\n\n\nEMPTY\n\n\n\n\n\n\nparams\n\n\n\"presentation/tagged\"\n\n\nSome params: key=value;key=value;...\n\n\nEMPTY\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"incident\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Provoke a job incident\">\n  <configurations>\n    <configuration key=\"code\">3</configuration>\n    <configuration key=\"severity\">INFO</configuration>\n    <configuration key=\"details\">exception=content;id=325</configuration>\n    <configuration key=\"params\">track=track-1;profile=full</configuration>\n  </configurations>\n</operation>",
            "title": "Incident"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/#incidentcreatorworkflowoperationhandler",
            "text": "",
            "title": "IncidentCreatorWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/#description",
            "text": "The IncidentCreatorWorkflowOperationHandler creates an incident on a dummy job used for integration testing.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      code  2  The code number of the incident to produce.  1    severity  WARNING  The severity. See Incident.Severity enum.  INFO    details  \"tagged,+rss\" / \"-rss,+tagged\"  Some details: title=content;title=content;...  EMPTY    params  \"presentation/tagged\"  Some params: key=value;key=value;...  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/#operation-example",
            "text": "<operation\n  id=\"incident\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Provoke a job incident\">\n  <configurations>\n    <configuration key=\"code\">3</configuration>\n    <configuration key=\"severity\">INFO</configuration>\n    <configuration key=\"details\">exception=content;id=325</configuration>\n    <configuration key=\"params\">track=track-1;profile=full</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/include-woh/",
            "text": "Include Workflow Operation\n\n\nId: include\n\n\nDescription\n\n\nThe Include operation can be used to add a workflow definition to the current workflow. This enables re-usable\nsequences of operations to be factored out and allows better structuring of complex workflows.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nworkflow-id\n\n\npartial-cleanup\n\n\nThe workflow definition id of the workflow to be included\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"include\"\n  description=\"Remove temporary processing artifacts\">\n  <configurations>\n    <configuration key=\"workflow-id\">partial-cleanup</configuration>\n  </configurations>\n</operation>",
            "title": "Include"
        },
        {
            "location": "/workflowoperationhandlers/include-woh/#include-workflow-operation",
            "text": "Id: include",
            "title": "Include Workflow Operation"
        },
        {
            "location": "/workflowoperationhandlers/include-woh/#description",
            "text": "The Include operation can be used to add a workflow definition to the current workflow. This enables re-usable\nsequences of operations to be factored out and allows better structuring of complex workflows.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/include-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      workflow-id  partial-cleanup  The workflow definition id of the workflow to be included",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/include-woh/#operation-example",
            "text": "<operation\n  id=\"include\"\n  description=\"Remove temporary processing artifacts\">\n  <configurations>\n    <configuration key=\"workflow-id\">partial-cleanup</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/",
            "text": "IngestDownloadWorkflowOperationHandler\n\n\nDescription\n\n\nWith the IngestDownloadWorkflowOperationHandler it's possible to initially download external URI's from mediapackage\nelements and store them to the working file repository. The external element URI's are then rewritten to the stored\nworking file repository URI.\n\n\nIn case of having external element URI's showing to a different Opencast working file repository, it's also possible to\ndelete them after downloading it by activating the \"delete-external\" option.\n\n\nThis operation is originally implemented to get rid of remaining files on ingest working file repositories.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\ndelete-external\n\n\n\"true\"\n\n\nWhether to try to delete external working file repository URIs.\n\n\nFALSE\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"ingest-download\"\n  fail-on-error=\"false\"\n  description=\"Downloads external artifacts to the working file repository\">\n  <configurations>\n    <configuration key=\"delete-external\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Ingest-Download"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/#ingestdownloadworkflowoperationhandler",
            "text": "",
            "title": "IngestDownloadWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/#description",
            "text": "With the IngestDownloadWorkflowOperationHandler it's possible to initially download external URI's from mediapackage\nelements and store them to the working file repository. The external element URI's are then rewritten to the stored\nworking file repository URI.  In case of having external element URI's showing to a different Opencast working file repository, it's also possible to\ndelete them after downloading it by activating the \"delete-external\" option.  This operation is originally implemented to get rid of remaining files on ingest working file repositories.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      delete-external  \"true\"  Whether to try to delete external working file repository URIs.  FALSE",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/#operation-example",
            "text": "<operation\n  id=\"ingest-download\"\n  fail-on-error=\"false\"\n  description=\"Downloads external artifacts to the working file repository\">\n  <configurations>\n    <configuration key=\"delete-external\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/",
            "text": "InspectWorkflowOperation\n\n\nDescription\n\n\nThe InspectWorkflowOperation is used to inspect all tracks of a media package. It tries to verify if they are valid\nmedia tracks.\nThe InspectWorkflowOperation will also set the duration and creation date of the dublincore/episode catalog\n(if available) to the media package duration and media package creation date.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nType\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\naccept-no-media\n\n\nBoolean\n\n\nWhether mediapackages with no media tracks should be accepted\n\n\nfalse\n\n\n\n\n\n\naccurate-frame-count\n\n\nBooelan\n\n\nWhether the media inspection service should determine the exact frame count\n\n\nfalse\n\n\n\n\n\n\noverwrite\n\n\nBoolean\n\n\nWhether to rewrite existing metadata\n\n\nfalse\n\n\n\n\n\n\n\n\nAccept No Media\n\n\nIf the configuration key \naccept-no-media\nis set to \nfalse\n, the operation will fail if the media package does not\ncontain any media tracks. If this behaviour is not appropriate, set \naccept-no-media\n to \ntrue\n.\n\n\nAccurate Frame Count\n\n\nThe media inspection service will provide the number of frames in case of video streams. Normally, this information is\nextracted from the media file header. In case of incorrect media file headers, this information might not be accurate.\nUsing the configuration key \naccurate-frame-count\n, the media inspection service can be forced to perform a full\ndecoding of the video stream. While this does result in an exact count of frames, this is expensive in terms of\ncomputation power.\n\n\nOverwrite\n\n\nThe inspection service will try to fill empty metadata fields. It will not overwrite any existing values except when\nyou specify the option \noverwrite\n as \ntrue\n.\n\n\nOperation Example\n\n\n<operation\n    id=\"inspect\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Inspecting mediapackage track elements\">\n    <configurations>\n        <configuration key=\"overwrite\">false</configuration>\n        <configuration key=\"accept-no-media\">false</configuration>\n        <configuration key=\"accurate-frame-count\">false</configuration>\n    </configurations>\n</operation>",
            "title": "Inspect"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#inspectworkflowoperation",
            "text": "",
            "title": "InspectWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#description",
            "text": "The InspectWorkflowOperation is used to inspect all tracks of a media package. It tries to verify if they are valid\nmedia tracks.\nThe InspectWorkflowOperation will also set the duration and creation date of the dublincore/episode catalog\n(if available) to the media package duration and media package creation date.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#parameter-table",
            "text": "Configuration Key  Type  Description  Default      accept-no-media  Boolean  Whether mediapackages with no media tracks should be accepted  false    accurate-frame-count  Booelan  Whether the media inspection service should determine the exact frame count  false    overwrite  Boolean  Whether to rewrite existing metadata  false",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#accept-no-media",
            "text": "If the configuration key  accept-no-media is set to  false , the operation will fail if the media package does not\ncontain any media tracks. If this behaviour is not appropriate, set  accept-no-media  to  true .",
            "title": "Accept No Media"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#accurate-frame-count",
            "text": "The media inspection service will provide the number of frames in case of video streams. Normally, this information is\nextracted from the media file header. In case of incorrect media file headers, this information might not be accurate.\nUsing the configuration key  accurate-frame-count , the media inspection service can be forced to perform a full\ndecoding of the video stream. While this does result in an exact count of frames, this is expensive in terms of\ncomputation power.",
            "title": "Accurate Frame Count"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#overwrite",
            "text": "The inspection service will try to fill empty metadata fields. It will not overwrite any existing values except when\nyou specify the option  overwrite  as  true .",
            "title": "Overwrite"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#operation-example",
            "text": "<operation\n    id=\"inspect\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Inspecting mediapackage track elements\">\n    <configurations>\n        <configuration key=\"overwrite\">false</configuration>\n        <configuration key=\"accept-no-media\">false</configuration>\n        <configuration key=\"accurate-frame-count\">false</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/log-woh/",
            "text": "LoggingWorkflowOperationHandler\n\n\nDescription\n\n\nThe LoggingWorkflowOperationHandler is primarily meant for testing and debugging purposes. It allows to log the current\nstate of of a workflow and/or its media package.\n\n\n\n\n\n\n\n\nName\n\n\nDefault\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ndirectory\n\n\n\n\nIf set, write the logs to this directory\n\n\n\n\n\n\nworkflowinstance-xml\n\n\nfalse\n\n\nLog the current state of the workflow as XML\n\n\n\n\n\n\nmediapackage-xml\n\n\nfalse\n\n\nLog the state of the current workflow's media package as XML\n\n\n\n\n\n\nmediapackage-json\n\n\ntrue\n\n\nLog the state of the current workflow's media package as JSON\n\n\n\n\n\n\n\n\nSetting any output configuration (\n*-xml\n and \n*-json\n options) will overwrite all defaults and only the formats\nexplicitly enabled will be logged.\n\n\nOperation Example\n\n\n<operation\n  id=\"log\"\n  description=\"Log to system logger\">\n</operation>\n\n\n\n\n<operation\n  id=\"log\"\n  description=\"Log to file\">\n  <configurations>\n    <configuration key=\"directory\">/tmp/logtest</configuration>\n  </configurations>\n</operation>",
            "title": "Log"
        },
        {
            "location": "/workflowoperationhandlers/log-woh/#loggingworkflowoperationhandler",
            "text": "",
            "title": "LoggingWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/log-woh/#description",
            "text": "The LoggingWorkflowOperationHandler is primarily meant for testing and debugging purposes. It allows to log the current\nstate of of a workflow and/or its media package.     Name  Default  Description      directory   If set, write the logs to this directory    workflowinstance-xml  false  Log the current state of the workflow as XML    mediapackage-xml  false  Log the state of the current workflow's media package as XML    mediapackage-json  true  Log the state of the current workflow's media package as JSON     Setting any output configuration ( *-xml  and  *-json  options) will overwrite all defaults and only the formats\nexplicitly enabled will be logged.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/log-woh/#operation-example",
            "text": "<operation\n  id=\"log\"\n  description=\"Log to system logger\">\n</operation>  <operation\n  id=\"log\"\n  description=\"Log to file\">\n  <configurations>\n    <configuration key=\"directory\">/tmp/logtest</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/notification/",
            "text": "Mattermost Notification\n\n\nDescription\n\n\nThe MattermostNotificationOperationHander sends a notification to a channel of Mattermost or similar applications,\nlike Slack, with the chosen parameters provided. It is useful to send such notifications when some operation(s) have\nbeen completed or some error has occurred in a workflow.\nThe notification message can be freely chosen. You can use different parameters which will be replaced with the\ncorresponding metadata of the current workflow instance (see List of parameters).\n\n\nList of configuration options\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\ndescription\n\n\ndefault\n\n\n\n\n\n\n\n\n\n\nurl\n\n\nURL of the mattermost webhook\n\n\nEMPTY\n\n\n\n\n\n\nmessage\n\n\nMessage that will be send\n\n\nEMPTY\n\n\n\n\n\n\nmethod\n\n\nHTTP method that will be used\n\n\npost\n\n\n\n\n\n\nmax-retry\n\n\nValue for the number of attempts for a request\n\n\n5\n\n\n\n\n\n\ntimeout\n\n\nMaximum time to wait for client to excecute a request\n\n\n10 * 1000\n\n\n\n\n\n\n\n\nExample for mattermost-notify operation\n\n\n  <operation\n      id=\"mattermost-notify\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Notify Mattermost about error\">\n      <configurations>\n        <configuration key=\"url\">insert-url-of-mattermost-webhook</configuration>\n        <configuration key=\"message\">Error at Workflow %i (%t) State: %s</configuration>\n        <configuration key=\"method\">post</configuration>\n        <configuration key=\"max-retry\">3</configuration>\n        <configuration key=\"timeout\">5</configuration>\n      </configurations>\n    </operation>\n\n\n\n\nList of parameters\n\n\nAll parameters (%\n) will be substituted with corresponding metadata of the current workflow instance.\n\n\n\n\n\n\n\n\nParameter\n\n\nMetadata\n\n\n\n\n\n\n\n\n\n\n%t\n\n\nTitle of workflow\n\n\n\n\n\n\n%i\n\n\nID of workflow\n\n\n\n\n\n\n%s\n\n\nState of workflow\n\n\n\n\n\n\n%o\n\n\nID of current workflow operation\n\n\n\n\n\n\n%I\n\n\nID of Mediapackage\n\n\n\n\n\n\n%T\n\n\nTitle of Mediapackage\n\n\n\n\n\n\n%C\n\n\nCreators of Mediapackage\n\n\n\n\n\n\n%c\n\n\nContributors of Mediapackage\n\n\n\n\n\n\n%D\n\n\nDate of Mediapackage\n\n\n\n\n\n\n%d\n\n\nDuration of Mediapackage\n\n\n\n\n\n\n%L\n\n\nLicense of Mediapackage\n\n\n\n\n\n\n%l\n\n\nLanguage of Mediapackage\n\n\n\n\n\n\n%S\n\n\nSeries-Title of Mediapackage",
            "title": "Mattermost Notification Module"
        },
        {
            "location": "/workflowoperationhandlers/notification/#mattermost-notification",
            "text": "",
            "title": "Mattermost Notification"
        },
        {
            "location": "/workflowoperationhandlers/notification/#description",
            "text": "The MattermostNotificationOperationHander sends a notification to a channel of Mattermost or similar applications,\nlike Slack, with the chosen parameters provided. It is useful to send such notifications when some operation(s) have\nbeen completed or some error has occurred in a workflow.\nThe notification message can be freely chosen. You can use different parameters which will be replaced with the\ncorresponding metadata of the current workflow instance (see List of parameters).",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/notification/#list-of-configuration-options",
            "text": "configuration keys  description  default      url  URL of the mattermost webhook  EMPTY    message  Message that will be send  EMPTY    method  HTTP method that will be used  post    max-retry  Value for the number of attempts for a request  5    timeout  Maximum time to wait for client to excecute a request  10 * 1000",
            "title": "List of configuration options"
        },
        {
            "location": "/workflowoperationhandlers/notification/#example-for-mattermost-notify-operation",
            "text": "<operation\n      id=\"mattermost-notify\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Notify Mattermost about error\">\n      <configurations>\n        <configuration key=\"url\">insert-url-of-mattermost-webhook</configuration>\n        <configuration key=\"message\">Error at Workflow %i (%t) State: %s</configuration>\n        <configuration key=\"method\">post</configuration>\n        <configuration key=\"max-retry\">3</configuration>\n        <configuration key=\"timeout\">5</configuration>\n      </configurations>\n    </operation>",
            "title": "Example for mattermost-notify operation"
        },
        {
            "location": "/workflowoperationhandlers/notification/#list-of-parameters",
            "text": "All parameters (% ) will be substituted with corresponding metadata of the current workflow instance.     Parameter  Metadata      %t  Title of workflow    %i  ID of workflow    %s  State of workflow    %o  ID of current workflow operation    %I  ID of Mediapackage    %T  Title of Mediapackage    %C  Creators of Mediapackage    %c  Contributors of Mediapackage    %D  Date of Mediapackage    %d  Duration of Mediapackage    %L  License of Mediapackage    %l  Language of Mediapackage    %S  Series-Title of Mediapackage",
            "title": "List of parameters"
        },
        {
            "location": "/workflowoperationhandlers/move-storage-woh/",
            "text": "MoveStorageOperationHandler\n\n\nDescription\n\n\nThe MoveStorageOperationHandler can be used to move files in the Asset Manager from one storage system to another.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntarget-storage*\n\n\nlocal-storage\n\n\nThe ID of the storage to move the files to\n\n\n\n\n\n\ntarget-version\n\n\n0\n\n\nThe (optional) snapshot version to move\n\n\n\n\n\n\n\n\n* mandatory configuration key\n\n\nNotes:\n\n\n\n\nOmitting \ntarget-version\n will move \nall\n current versions of the mediapackage to \ntarget-storage\n.  An example\n  usecase would be moving the raw input media to a cold(er) storage system after initial processing.\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"move-to-remote\"\n  description=\"Offloading to AWS S3\">\n  <configurations>\n    <configuration key=\"target-storage\">aws-s3</configuration>\n  </configurations>\n</operation>",
            "title": "Move Storage"
        },
        {
            "location": "/workflowoperationhandlers/move-storage-woh/#movestorageoperationhandler",
            "text": "",
            "title": "MoveStorageOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/move-storage-woh/#description",
            "text": "The MoveStorageOperationHandler can be used to move files in the Asset Manager from one storage system to another.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/move-storage-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      target-storage*  local-storage  The ID of the storage to move the files to    target-version  0  The (optional) snapshot version to move     * mandatory configuration key  Notes:   Omitting  target-version  will move  all  current versions of the mediapackage to  target-storage .  An example\n  usecase would be moving the raw input media to a cold(er) storage system after initial processing.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/move-storage-woh/#operation-example",
            "text": "<operation\n  id=\"move-to-remote\"\n  description=\"Offloading to AWS S3\">\n  <configurations>\n    <configuration key=\"target-storage\">aws-s3</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/multiencode-woh/",
            "text": "MultiencodeWorkflowHandler\n\n\nDescription\n\n\nThe MultiencodeWorkflowHandler is used to encode source media into multiple formats concurrently.\nThe source recording are selected by source-flavors AND source-tags.\nEach source media selector (eg presenter or presentation) can have an independent set of encoding profile ids\n(one for each target medium) and target tags.\nEncoding of each source medium runs as one ffmpeg command.\nThis operation will generate one multiencode operation per source medium,\nall of them running concurrently on the same or on different workers.\nIn addition, the target media can be optionally tagged with the encoding profile ids.\n\n\nConfiguration details\n\n\nThis workflow handles each source selector independently as a section.\nThe parameters for each configuration, such as flavors are separated positionally into sections by \"\n;\n\".\nThe use of the semi-colon is optional. If it is absent, there is only one section.\n\n\n<configuration key=\"source-flavors\">*/source</configuration>\n\n\n\n\n\n\nOne source selector means that all the matching recording will be processed the same way.\n\n\n\n\n\n<configuration key=\"source-flavors\">presenter/source;presentation/source</configuration>\n\n\n\n\n\n\nTwo different source selectors means that all the matching recordings in the first selector will be processed\naccording to the parameters in the first section and the all the matching recordings in the second selector will\nbe processed according to the parameters in next section.\n\n\n\n\nEach source selector can have only one corresponding section.\nIf there is only one section in one parameter, eg: target-flavors,\nbut multiple sections in another, eg: source-flavors,\nthen the sections are collapsed into one.\nFor example:\n\n\n<configuration key=\"target-flavors\">*/preview</configuration>\n\n\n\n\n\n\nAll targets are flavored the same way, using the example above, becomes \"presenter/preview\"\nand \"presentation/preview\"\n\n\n\n\n\nEach source selector can have its own set of target tags and flavors, defined as a comma delimited list.\nFor example:\n\n\n<configuration key=\"target-tags\">engage-streaming,rss,atom;engage-download,rss,atom</configuration>\n\n\n\n\n\n\nUsing the example above.\n\"presenter/preview\" is tagged with \"engage-streaming,rss,atom\".\n\"presentation/preview\" is tagged with \"engage-download,rss,atom\".\n\n\n\n\nWhen a configuration has the same number of sections as the source, then the configurations for the operation\nare taken from the corresponding sections.\n\n\nEach section runs independently as a parallel encoding job.\n\n\nFor example, if presenter/source is to encoded with \"mp4-low.http,mp4-medium.http\" and\npresentation/source is to be encoded with \"mp4-hd.http,mp4-hd.http\"\n\n\nThe target flavors are presenter/delivery and presentation/delivery and all are tagged \"rss, archive\".\nThe target flavors are additionally tagged with encoding profiles, so that they can selected individually.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\npresenter/source\n;\npresentation/source\n\n\nWhich media should be encoded\n\n\n\n\n\n\ntarget-flavors\n\n\n*/preview\n\n\nSpecifies the flavor of the new media\n\n\n\n\n\n\ntarget-tags\n\n\nrss,archive\n\n\nSpecifies the tags of the new media\n\n\n\n\n\n\nencoding-profiles\n\n\nmp4-low.http,mp4-medium.http\n;\nmp4-hd.http,mp4-hd.http\n\n\nEncoding profiles for each source flavor\n\n\n\n\n\n\ntag-with-profile\n\n\ntrue\n\n\ntarget media are tagged with coresponding encoding profile Id (false if omitted)\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n    id=\"multiencode\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encoding media to delivery formats\">\n    <configurations>\n        <configuration key=\"source-flavors\">presenter/work;presentation/work</configuration>\n        <configuration key=\"target-flavors\">*/delivery</configuration>\n        <configuration key=\"target-tags\">rss,archive</configuration>\n        <configuration key=\"encoding-profiles\">mp4-low.http;mp4-hd.http</configuration>\n        <configuration key=\"tag-with-profile\">true</configuration>\n    </configurations>\n</operation>\n\n\n\nNote: (Important)\n\n\nEach source flavor generates all the target formats in one ffmpeg call by incorporating relevant parts\nof the encoding profile commands.\n\n\n\n\n\n\nCare must be taken that no ffmpeg complex filters are used in the encoding profiles used for this workflow,\nas it can cause a conflict.\n\n\n\n\n\n\nEncoded target media are distinguished by the suffix, it is important that all the encoding profiles used have\ndistinct suffixes to use \"tag-with-profile\" configuration, for example:\n\n\n\n\n\n\nprofile.mp4-vga-medium.http.suffix = -vga-medium.mp4\nprofile.mp4-medium.http.suffix = -medium.mp4",
            "title": "Multiencode"
        },
        {
            "location": "/workflowoperationhandlers/multiencode-woh/#multiencodeworkflowhandler",
            "text": "",
            "title": "MultiencodeWorkflowHandler"
        },
        {
            "location": "/workflowoperationhandlers/multiencode-woh/#description",
            "text": "The MultiencodeWorkflowHandler is used to encode source media into multiple formats concurrently.\nThe source recording are selected by source-flavors AND source-tags.\nEach source media selector (eg presenter or presentation) can have an independent set of encoding profile ids\n(one for each target medium) and target tags.\nEncoding of each source medium runs as one ffmpeg command.\nThis operation will generate one multiencode operation per source medium,\nall of them running concurrently on the same or on different workers.\nIn addition, the target media can be optionally tagged with the encoding profile ids.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/multiencode-woh/#configuration-details",
            "text": "This workflow handles each source selector independently as a section.\nThe parameters for each configuration, such as flavors are separated positionally into sections by \" ; \".\nThe use of the semi-colon is optional. If it is absent, there is only one section.  <configuration key=\"source-flavors\">*/source</configuration>   One source selector means that all the matching recording will be processed the same way.   <configuration key=\"source-flavors\">presenter/source;presentation/source</configuration>   Two different source selectors means that all the matching recordings in the first selector will be processed\naccording to the parameters in the first section and the all the matching recordings in the second selector will\nbe processed according to the parameters in next section.   Each source selector can have only one corresponding section.\nIf there is only one section in one parameter, eg: target-flavors,\nbut multiple sections in another, eg: source-flavors,\nthen the sections are collapsed into one.\nFor example:  <configuration key=\"target-flavors\">*/preview</configuration>   All targets are flavored the same way, using the example above, becomes \"presenter/preview\"\nand \"presentation/preview\"   Each source selector can have its own set of target tags and flavors, defined as a comma delimited list.\nFor example:  <configuration key=\"target-tags\">engage-streaming,rss,atom;engage-download,rss,atom</configuration>   Using the example above.\n\"presenter/preview\" is tagged with \"engage-streaming,rss,atom\".\n\"presentation/preview\" is tagged with \"engage-download,rss,atom\".   When a configuration has the same number of sections as the source, then the configurations for the operation\nare taken from the corresponding sections.  Each section runs independently as a parallel encoding job.  For example, if presenter/source is to encoded with \"mp4-low.http,mp4-medium.http\" and\npresentation/source is to be encoded with \"mp4-hd.http,mp4-hd.http\"  The target flavors are presenter/delivery and presentation/delivery and all are tagged \"rss, archive\".\nThe target flavors are additionally tagged with encoding profiles, so that they can selected individually.",
            "title": "Configuration details"
        },
        {
            "location": "/workflowoperationhandlers/multiencode-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavors  presenter/source ; presentation/source  Which media should be encoded    target-flavors  */preview  Specifies the flavor of the new media    target-tags  rss,archive  Specifies the tags of the new media    encoding-profiles  mp4-low.http,mp4-medium.http ; mp4-hd.http,mp4-hd.http  Encoding profiles for each source flavor    tag-with-profile  true  target media are tagged with coresponding encoding profile Id (false if omitted)",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/multiencode-woh/#operation-example",
            "text": "<operation\n    id=\"multiencode\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encoding media to delivery formats\">\n    <configurations>\n        <configuration key=\"source-flavors\">presenter/work;presentation/work</configuration>\n        <configuration key=\"target-flavors\">*/delivery</configuration>\n        <configuration key=\"target-tags\">rss,archive</configuration>\n        <configuration key=\"encoding-profiles\">mp4-low.http;mp4-hd.http</configuration>\n        <configuration key=\"tag-with-profile\">true</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/multiencode-woh/#note-important",
            "text": "Each source flavor generates all the target formats in one ffmpeg call by incorporating relevant parts\nof the encoding profile commands.    Care must be taken that no ffmpeg complex filters are used in the encoding profiles used for this workflow,\nas it can cause a conflict.    Encoded target media are distinguished by the suffix, it is important that all the encoding profiles used have\ndistinct suffixes to use \"tag-with-profile\" configuration, for example:    profile.mp4-vga-medium.http.suffix = -vga-medium.mp4\nprofile.mp4-medium.http.suffix = -medium.mp4",
            "title": "Note: (Important)"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/",
            "text": "Audio Normalization Operation\n\n\nDescription\n\n\nThis operation normalizes the first audio stream of a video or audio track through \nSoX\n, it\ncreates a new track with a reference to the original track which can be flavored and tagged.  It can be used with audio\nand/or video files, at least one audio stream must be available otherwise nothing happens. Here are the internal steps\ndone by the different inputs:\n\n\nUsed with Audio only file (forceTranscode is deactivated):\n\n\n\n\nCheck if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.\n\n\nRun audio normalization with original audio file.\n\n\nReplace the normalized audio file with the original.\n\n\nWrite analyzed audio metadata to the track's mediapackage.\n\n\nDelete all used temporary files.\n\n\n\n\nUsed with Audio only file and forceTranscode activated:\n\n\n\n\nCheck if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.\n\n\n(forceTranscode step) Encode audio to FLAC. (Must be used when given audio file format is not supported by SoX)\n\n\nRun audio normalization with original audio file or encoded FLAC audio file.\n\n\n(forceTranscode step) Mux normalized audio file back to the original audio container by replacing it with the\n   original audio stream.\n\n\nWrite analyzed audio metadata to the track's mediapackage.\n\n\nDelete all used temporary files\n\n\n\n\nUsed with Video file:\n\n\n\n\nExtract audio file encoded as FLAC audio and save it temporary in a collection\n\n\nCheck if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.\n\n\nRun audio normalization with extracted audio file.\n\n\nMux normalized audio file back to the original video container by replacing it with original audio stream.\n\n\nWrite analyzed audio metadata to the track's mediapackage.\n\n\nDelete all used temporary files\n\n\n\n\nExample result track:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<track ref=\"track:track-2\" type=\"presenter/normalized\" id=\"70626874-17d2-480d-9d30-c10f0824961c\">\n  <mimetype>audio/x-flv</mimetype>\n  <tags>\n    <tag>norm</tag>\n  </tags>\n  <url>http://localhost:8080/files/mediapackage/8a510168-9102-425f-81e9-0943774dd229/70626874-17d2-480d-9d30-c10f0824961c/demo_slide_video_6min_buss.flv</url>\n  <checksum type=\"md5\">4e30d7d4305b0793f301816e796471db</checksum>\n  <duration>414407</duration>\n  <audio id=\"audio-1\">\n    <device/>\n    <encoder type=\"MPEG Audio\"/>\n    <bitdepth>16</bitdepth>\n    <channels>2</channels>\n    <bitrate>64000.0</bitrate>\n    <peakleveldb>-4.03</peakleveldb> <!-- NEW -->\n    <rmsleveldb>-30.54</rmsleveldb> <!-- NEW -->\n    <rmspeakdb>-10.85</rmspeakdb> <!-- NEW -->\n  </audio>\n</track>\n\n\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"presentation/work,presenter/work\"\n\n\nThe \"flavors\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor\n\n\n\"presentation/work\"\n\n\nThe \"flavor\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags\n\n\n\"engage,atom,rss\"\n\n\nThe \"tag\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\n\"presentation/normalized\"\n\n\nThe flavor to apply to the normalized file\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\n\"norm\"\n\n\nThe tags to apply to the normalized file\n\n\nEMPTY\n\n\n\n\n\n\ntarget-decibel\n*\n\n\n-30.4\n\n\nThe target RMS Level Decibel\n\n\nEMPTY\n\n\n\n\n\n\nforce-transcode\n\n\n\"true\" or \"false\"\n\n\nWhether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format)\n\n\nFALSE\n\n\n\n\n\n\n\n\n* \nrequired keys\n\n\nOperation Example\n\n\n<operation\n  id=\"normalize-audio\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Normalize audio stream\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/normalized</configuration>\n    <configuration key=\"target-tags\">norm</configuration>\n    <configuration key=\"target-decibel\">-30</configuration>\n    <configuration key=\"force-transcode\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Normalize Audio"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#audio-normalization-operation",
            "text": "",
            "title": "Audio Normalization Operation"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#description",
            "text": "This operation normalizes the first audio stream of a video or audio track through  SoX , it\ncreates a new track with a reference to the original track which can be flavored and tagged.  It can be used with audio\nand/or video files, at least one audio stream must be available otherwise nothing happens. Here are the internal steps\ndone by the different inputs:",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#used-with-audio-only-file-forcetranscode-is-deactivated",
            "text": "Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.  Run audio normalization with original audio file.  Replace the normalized audio file with the original.  Write analyzed audio metadata to the track's mediapackage.  Delete all used temporary files.",
            "title": "Used with Audio only file (forceTranscode is deactivated):"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#used-with-audio-only-file-and-forcetranscode-activated",
            "text": "Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.  (forceTranscode step) Encode audio to FLAC. (Must be used when given audio file format is not supported by SoX)  Run audio normalization with original audio file or encoded FLAC audio file.  (forceTranscode step) Mux normalized audio file back to the original audio container by replacing it with the\n   original audio stream.  Write analyzed audio metadata to the track's mediapackage.  Delete all used temporary files",
            "title": "Used with Audio only file and forceTranscode activated:"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#used-with-video-file",
            "text": "Extract audio file encoded as FLAC audio and save it temporary in a collection  Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.  Run audio normalization with extracted audio file.  Mux normalized audio file back to the original video container by replacing it with original audio stream.  Write analyzed audio metadata to the track's mediapackage.  Delete all used temporary files   Example result track:  <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<track ref=\"track:track-2\" type=\"presenter/normalized\" id=\"70626874-17d2-480d-9d30-c10f0824961c\">\n  <mimetype>audio/x-flv</mimetype>\n  <tags>\n    <tag>norm</tag>\n  </tags>\n  <url>http://localhost:8080/files/mediapackage/8a510168-9102-425f-81e9-0943774dd229/70626874-17d2-480d-9d30-c10f0824961c/demo_slide_video_6min_buss.flv</url>\n  <checksum type=\"md5\">4e30d7d4305b0793f301816e796471db</checksum>\n  <duration>414407</duration>\n  <audio id=\"audio-1\">\n    <device/>\n    <encoder type=\"MPEG Audio\"/>\n    <bitdepth>16</bitdepth>\n    <channels>2</channels>\n    <bitrate>64000.0</bitrate>\n    <peakleveldb>-4.03</peakleveldb> <!-- NEW -->\n    <rmsleveldb>-30.54</rmsleveldb> <!-- NEW -->\n    <rmspeakdb>-10.85</rmspeakdb> <!-- NEW -->\n  </audio>\n</track>",
            "title": "Used with Video file:"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  \"presentation/work,presenter/work\"  The \"flavors\" of the track to use as a source input  EMPTY    source-flavor  \"presentation/work\"  The \"flavor\" of the track to use as a source input  EMPTY    source-tags  \"engage,atom,rss\"  The \"tag\" of the track to use as a source input  EMPTY    target-flavor  \"presentation/normalized\"  The flavor to apply to the normalized file  EMPTY    target-tags  \"norm\"  The tags to apply to the normalized file  EMPTY    target-decibel *  -30.4  The target RMS Level Decibel  EMPTY    force-transcode  \"true\" or \"false\"  Whether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format)  FALSE     *  required keys",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#operation-example",
            "text": "<operation\n  id=\"normalize-audio\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Normalize audio stream\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/normalized</configuration>\n    <configuration key=\"target-tags\">norm</configuration>\n    <configuration key=\"target-decibel\">-30</configuration>\n    <configuration key=\"force-transcode\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/",
            "text": "PartialImportWorkflowOperation\n\n\nDescription\n\n\nThe PartialImportWorkflowOperation processes a set of audio and video files according to a SMIL document describing\ntheir relations. Its primary use is to post-process audio and video files ingested by capture agents using\n/ingest/addPartialTrack of the ingest endpoint.\n\n\nPrerequisite\n\n\nWhen using the PartialImportWorkflowOperation, it is recommended to perform a media inspection beforehand using the\nInspectWorkflowOperation with the option \naccurate-frame-count\n set to \ntrue\n. This ensures that\nthe PartialImportWorkflowOperation works correctly in case of media files with incorrect framecount in their header.\nNote that the use of \naccurate-frame-count\n will force the InspectWorkflowOperation to decode the complete video\nstream which makes the operation more expensive in terms of load.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\ntype\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-presenter-flavor\n\n\nMediaPackageElementFlavor\n\n\nThe flavor of tracks for the presenter video\n\n\n\n\n\n\n\n\nsource-presentation-flavor\n\n\nMediaPackageElementFlavor\n\n\nThe flavor of tracks for the presentation video\n\n\n\n\n\n\n\n\nsource-smil-flavor\n*\n\n\nMediaPackageElementFlavor\n\n\nThe flavor of the SMIL file describing how to build the targets.\nWhen using /ingest/addPartialTrack, the ingest service will create the SMIL file and add it to the media package as flavor \nsmil/source+partial\n\n\n\n\n\n\n\n\ntarget-presenter-flavor\n*\n\n\nMediaPackageElementFlavor\n\n\nThe flavor to be used for the target presentation track.\nBoth the type and subtype must not be \n*\n\n\n\n\n\n\n\n\ntarget-presentation-flavor\n*\n\n\nMediaPackageElementFlavor\n\n\nThe flavor to be used for the target presentation track.\nBoth the type nor subtype must not be \n*\n\n\n\n\n\n\n\n\nconcat-encoding-profile\n*\n\n\nString\n\n\nEncoding profile used for concatenating audio or video files\n\n\n\n\n\n\n\n\nconcat-output-framerate\n\n\nFloat\n\n\nThe optional output framerate for concatenated video files\n\n\n\n\n\n\n\n\ntrim-encoding-profile\n*\n\n\nString\n\n\nEncoding profile using for trimming tracks\n\n\n\n\n\n\n\n\nforce-encoding\n\n\nBoolean\n\n\nIf set to \ntrue\n, all generated target files will be encoded using the encoding profile \nforce-encoding-profile\n\n\nfalse\n\n\n\n\n\n\nforce-encoding-profile\n*\n\n\nString\n\n\nEncoding profile to be used when \nforce-encoding\n is set to \ntrue\n or a given target track has a file extension not included in \nrequired-extensions\n\n\n\n\n\n\n\n\nrequired-extensions\n\n\nString , { \",\" , String }\n\n\nComma-separated list of file extension names (case insensitive). All generated target files whose file extensions are not in this list will be encoded using the encoding profile \nforce-encoding-profile\n\n\n\"mp4\"\n\n\n\n\n\n\nenforce-divisible-by-two\n\n\nBoolean\n\n\nIf set, all video targets will have widths and heights divisible by two. This might be necessary depending since some encoder fail when encountering uneven widths or heights.\n\n\nfalse\n\n\n\n\n\n\n\n\n* \nrequired keys\n\n\nNote that it is allowed to set the configuration keys 'target-presenter-flavor' and 'target-presentation-flavor' to the\nsame value.\n\n\nOperation Example\n\n\nWhat exactly the PartialImportWorkflowOperation does is best described by example. In our example, a capture agent\nrecords three sources:\n\n\n\n\nPresenter camera (video only)\n\n\nPresenter microphone (audio only)\n\n\nPresentation (video only)\n\n\n\n\nWhile the capture agent internally triggers the recording for all sources at the same time, the actual recording of the\nindividual sources might not necessarily start at the exact same time, e.g. due to latency of the recording\ndevices.\n Also, while recording, a watch dog in our example capture agent recognizes that for whatever reason, the\nrecording of the sources had stopped and restarted again several times - resulting in multiple audio and/or video files\nper source.\n\n\nHere is a graphics showing how this example could look like:\n\n\n\n\nSo we have three tracks, but seven files:\n\n\n\n\nPresenter camera: 2 video-only files\n\n\nPresenter microphone: 2 audio-only files\n\n\nPresentation: 3 video-only files\n\n\n\n\nWe call that individual fragments of a track \npartial tracks\n.\n\n\nOur example capture agent can now use the addPartialTrack ingest facility to specify for each of the ingested files, at\nwhich time the content fits into the overall recording. The ingest service will automatically create the SMIL file\ndescribing how the files relate to each other and add it to the media package as flavor \nsmil/source+partial\n.\n\n\nIn our example, this SMIL file would like something like:\n\n\n  <?xml version=\"1.1\" encoding=\"UTF-8\"?>\n  <smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\">\n    <head/>\n    <body>\n      <par dur=\"93861ms\">\n        <seq>\n          <video begin=\"412ms\" dur=\"13440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/>\n          <video begin=\"15324ms\" dur=\"73440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/>\n          <audio begin=\"0ms\" dur=\"40861ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/>\n          <audio begin=\"43400ms\" dur=\"13861ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/>\n        </seq>\n        <seq>\n          <video begin=\"948ms\" dur=\"33440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/>\n          <video begin=\"35643ms\" dur=\"15430ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/>\n          <video begin=\"45448ms\" dur=\"25440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/>\n        </seq>\n      </par>\n    </body>\n  </smil>\n\n\n\nWhat we finally want, however, is a single presenter and a single presentation track that can be processed by Opencast\nworkflow operations. To achieve this, the PartialImportWorkflowOperation is used to post-process the files as described\nin the SMIL file:\n\n\n <operation id=\"partial-import\"\n           description=\"Post-processing raw audio and video files from capture agent\"\n           fail-on-error=\"true\"\n           exception-handler-workflow=\"partial-error\">\n  <configurations>\n    <configuration key=\"source-presenter-flavor\">presenter/source</configuration>\n    <configuration key=\"source-presentation-flavor\">presentation/source</configuration>\n    <configuration key=\"source-smil-flavor\">smil/source+partial</configuration>\n    <configuration key=\"target-presenter-flavor\">presenter/standard</configuration>\n    <configuration key=\"target-presentation-flavor\">presentation/standard</configuration>\n    <configuration key=\"concat-encoding-profile\">concat.work</configuration>\n    <configuration key=\"trim-encoding-profile\">trim.work</configuration>\n    <configuration key=\"force-encoding-profile\">editor.work</configuration>\n  </configurations>\n</operation>\n\n\n\nIn our example, the PartialImportWorkflowOperation will create the target flavors presenter/standard and\npresentation/standard as depicted below:\n\n\n\n\nThe green parts have been filled in by the PartialImportWorkflowOperation by either silence (audio) or pictures (video).\n\n\nTo achieve this, the PartialImportWorkflowOperation performs the following steps:\n\n\n\n\n\n\nExtend content at the beginning:\n If the first partial track of a given source and type (audio/video) does not\n   begin at position zero, content is added in front of it so that the corresponding target track will start at position\n   zero. For audio, silence is added. In case of video, the first frame of the first partial track is added.\n\n\n\n\n\n\nFilling the gaps:\n As you can see in our example, it is possible that content is missing within the actual tracks.\n   Those gaps are filled by adding silence (in case of audio) or adding the last frame of the previous partial track (in\n   case of video). In this step, content is also added at the end of the track in case its duration is less than the\n   overall duration of the recording.\n\n\n\n\n\n\nTrim the tracks:\n It is possible that processing the ingested files according to the SMIL file would result in\n   tracks that have a longer duration than the overall recording should. Therefore, all tracks are trimmed individually\n   to the target duration.\n\n\n\n\n\n\nMux audio tracks:\n To avoid the necessity to call further workflow operations just for audio muxing, the\n   PartialImportWorkflowOperation can perform audio muxing itself. In our example, it would mux the audio and video\n   track of the presenter into a single audio/video track.\n\n\n\n\n\n\nEnsure specific output formats:\n There may be situations where you want to ensure that the output of this\n   operations comes with a specific file format, e.g. \nMP4\n. The configuration keys \nforce-encoding\n and\n   \nrequired_extensions\n can be used to control the behavior of the PartialImportWorkflowOperation: In case the\n   \nforce-encoding\n is set to \ntrue\n, the target tracks will be re-encoded using the \nforce-encoding-profile\n. The\n   target tracks will also be re-encoded using that encoding profile in case its file extensions don't match the\n   \nrequired_extensions\n.\n\n\n\n\n\n\nSMIL File Structure\n\n\nThe PartialImportWorkflowOperation expects a specific subset of SMIL that is described in this section.\nThe overall structure of the SMIL file is shown by example below:\n\n\n  <?xml version=\"1.1\" encoding=\"UTF-8\"?>\n  <smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\">\n    <head/>\n    <body>\n      <par dur=\"15000ms\">\n        <seq>\n          <video begin=\"400ms\" dur=\"13000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/>\n          <video begin=\"15000ms\" dur=\"70000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/>\n          <audio begin=\"0ms\" dur=\"400ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/>\n          <audio begin=\"900ms\" dur=\"13000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/>\n        </seq>\n        <seq>\n          <video begin=\"900ms\" dur=\"30000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/>\n        </seq>\n      </par>\n    </body>\n  </smil>\n\n\n\nThe PartialImportWorkflowOperation can handle at most one \npar\n element that is used to describe to overall media\nduration using the attribute \ndur\n. The resulting tracks will be trimmed to this duration if necessary. In the example\nabove, the overall media duration is set to 15 seconds.\n\n\nThe \npar\n element has one or two sequence sub elements \nseq\n, each describing a track that is to be built from its\nsub elements - the partial tracks. Each sequence (\nseq\n) has at least one sub element. Sub elements can be either\n\nvideo\n elements, \naudio\n elements or both \nvideo\n and \naudio\n elements. Each of those sub elements requires the\nattributes \nbegin\n (position of partial track in milliseconds relative to start of overall media) and \ndur\n (duration of\npartial track in milliseconds) The \naudio\n elements are used to indicate that the media file referred to is an\naudio-only media file, whereas \nvideo\n elements can refer to either video-only or audio-video media files. The following\ncombinations result in a defined behavior:\n\n\nSupported Combinations of Video and Audio Elements\n\n\n\n\n\n\n\n\nvideo\n\n\naudio\n\n\nresulting track\n\n\n\n\n\n\n\n\n\n\naudio/video track\n\n\nn/a\n\n\naudio/video track\n\n\n\n\n\n\nvideo-only track\n\n\nn/a\n\n\nvideo-only track\n\n\n\n\n\n\nvideo-only track\n\n\naudio-only track\n\n\naudio/video track\n\n\n\n\n\n\nn/a\n\n\naudio-only track\n\n\naudio-only track\n\n\n\n\n\n\n\n\nAll other combinations of \nvideo\n and \naudio\n elements result in unspecified behavior of the\nPartialImportWorkflowOperation.\n\n\nOrder of Video and Audio Elements\n\n\nWithin a sequence (\nseq\n), the \nvideo\n elements most occur in ascending order considering the values of their attributes\n\nbegin\n. The same holds for \naudio\n elements. Note the \nvideo\n and \naudio\n elements are processed individually, so the\norder of occurrences of \nvideo\n and \naudio\n elements are independent from each other.\n\n\nImportant:\n The PartialImportWorkflowOperation will not process \nvideo\n or \naudio\n elements correctly if the order of\nappearance in the SMIL file is not correct.\n\n\nOverlapping Partial Tracks\n\n\nThe behavior of overlapping partial tracks is unspecified, i.e. for a given element \ne\n (\nvideo\n or \naudio\n), the value\nof \nbegin\n for the subsequent element \n(e+1)\n of the same type (\nvideo\n or \naudio\n) within the same sequence must be\nequal or greater than \ne.begin + e.dur\n, i.e. make sure that the following invariant holds: \n(e+1).begin >= e.begin +\ne.dur\n\n\nEncoding Profiles The PartialImportWorkflowOperation uses a number of encoding profiles to perform its processing.\n\n\nSome of the encoding profiles can be explicitly configured by the user, others are used implicitly in means of being\nhard-coded and are not supposed to be changed by the user.\n\n\nHard-coded Encoding Profiles\n\n\n\n\n\n\n\n\nencoding profile\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nimport.preview\n\n\nExtract the first frame of a given partial track\n\n\n\n\n\n\nimport.image-frame\n\n\nExtract the last frame of a given partial track. Note that this profile is used to extract the \nexactly\n last frame of a partial track - not just a frame close to the last one. To make this work for video files with headers that don't contain the exact frame count, set \naccurate_frame_count\n to \ntrue\n in  etc/org.opencastproject.inspection.ffmpeg.MediaInspectionServiceImpl.cfg\n\n\n\n\n\n\nimage-movie.work\n\n\nGenerate video partial tracks based on extracted images used to fill video gaps\n\n\n\n\n\n\nimport.silent\n\n\nGenerate silent audio tracks used to fill audio gaps\n\n\n\n\n\n\n\n\nConfigurable Encoding Profiles\n\n\n\n\n\n\n\n\nconfiguration key\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nconcat-encoding-profile\n\n\nUsed to concatenate partial tracks into tracks\n\n\n\n\n\n\ntrim-encoding-profile\n\n\nUsed to trim the resulting concatenated single tracks if necessary\n\n\n\n\n\n\nforce-encoding-profile\n\n\nUsed to re-encode target tracks in case the file extension of a given target track is not included in \nrequired-extensions\n or the configuration key \nforce-encoding\n is set to \ntrue",
            "title": "Partial Import"
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/#partialimportworkflowoperation",
            "text": "",
            "title": "PartialImportWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/#description",
            "text": "The PartialImportWorkflowOperation processes a set of audio and video files according to a SMIL document describing\ntheir relations. Its primary use is to post-process audio and video files ingested by capture agents using\n/ingest/addPartialTrack of the ingest endpoint.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/#prerequisite",
            "text": "When using the PartialImportWorkflowOperation, it is recommended to perform a media inspection beforehand using the\nInspectWorkflowOperation with the option  accurate-frame-count  set to  true . This ensures that\nthe PartialImportWorkflowOperation works correctly in case of media files with incorrect framecount in their header.\nNote that the use of  accurate-frame-count  will force the InspectWorkflowOperation to decode the complete video\nstream which makes the operation more expensive in terms of load.",
            "title": "Prerequisite"
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/#parameter-table",
            "text": "configuration keys  type  description  default value      source-presenter-flavor  MediaPackageElementFlavor  The flavor of tracks for the presenter video     source-presentation-flavor  MediaPackageElementFlavor  The flavor of tracks for the presentation video     source-smil-flavor *  MediaPackageElementFlavor  The flavor of the SMIL file describing how to build the targets. When using /ingest/addPartialTrack, the ingest service will create the SMIL file and add it to the media package as flavor  smil/source+partial     target-presenter-flavor *  MediaPackageElementFlavor  The flavor to be used for the target presentation track. Both the type and subtype must not be  *     target-presentation-flavor *  MediaPackageElementFlavor  The flavor to be used for the target presentation track. Both the type nor subtype must not be  *     concat-encoding-profile *  String  Encoding profile used for concatenating audio or video files     concat-output-framerate  Float  The optional output framerate for concatenated video files     trim-encoding-profile *  String  Encoding profile using for trimming tracks     force-encoding  Boolean  If set to  true , all generated target files will be encoded using the encoding profile  force-encoding-profile  false    force-encoding-profile *  String  Encoding profile to be used when  force-encoding  is set to  true  or a given target track has a file extension not included in  required-extensions     required-extensions  String , { \",\" , String }  Comma-separated list of file extension names (case insensitive). All generated target files whose file extensions are not in this list will be encoded using the encoding profile  force-encoding-profile  \"mp4\"    enforce-divisible-by-two  Boolean  If set, all video targets will have widths and heights divisible by two. This might be necessary depending since some encoder fail when encountering uneven widths or heights.  false     *  required keys  Note that it is allowed to set the configuration keys 'target-presenter-flavor' and 'target-presentation-flavor' to the\nsame value.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/#operation-example",
            "text": "What exactly the PartialImportWorkflowOperation does is best described by example. In our example, a capture agent\nrecords three sources:   Presenter camera (video only)  Presenter microphone (audio only)  Presentation (video only)   While the capture agent internally triggers the recording for all sources at the same time, the actual recording of the\nindividual sources might not necessarily start at the exact same time, e.g. due to latency of the recording\ndevices.  Also, while recording, a watch dog in our example capture agent recognizes that for whatever reason, the\nrecording of the sources had stopped and restarted again several times - resulting in multiple audio and/or video files\nper source.  Here is a graphics showing how this example could look like:   So we have three tracks, but seven files:   Presenter camera: 2 video-only files  Presenter microphone: 2 audio-only files  Presentation: 3 video-only files   We call that individual fragments of a track  partial tracks .  Our example capture agent can now use the addPartialTrack ingest facility to specify for each of the ingested files, at\nwhich time the content fits into the overall recording. The ingest service will automatically create the SMIL file\ndescribing how the files relate to each other and add it to the media package as flavor  smil/source+partial .  In our example, this SMIL file would like something like:    <?xml version=\"1.1\" encoding=\"UTF-8\"?>\n  <smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\">\n    <head/>\n    <body>\n      <par dur=\"93861ms\">\n        <seq>\n          <video begin=\"412ms\" dur=\"13440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/>\n          <video begin=\"15324ms\" dur=\"73440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/>\n          <audio begin=\"0ms\" dur=\"40861ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/>\n          <audio begin=\"43400ms\" dur=\"13861ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/>\n        </seq>\n        <seq>\n          <video begin=\"948ms\" dur=\"33440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/>\n          <video begin=\"35643ms\" dur=\"15430ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/>\n          <video begin=\"45448ms\" dur=\"25440ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/>\n        </seq>\n      </par>\n    </body>\n  </smil>  What we finally want, however, is a single presenter and a single presentation track that can be processed by Opencast\nworkflow operations. To achieve this, the PartialImportWorkflowOperation is used to post-process the files as described\nin the SMIL file:   <operation id=\"partial-import\"\n           description=\"Post-processing raw audio and video files from capture agent\"\n           fail-on-error=\"true\"\n           exception-handler-workflow=\"partial-error\">\n  <configurations>\n    <configuration key=\"source-presenter-flavor\">presenter/source</configuration>\n    <configuration key=\"source-presentation-flavor\">presentation/source</configuration>\n    <configuration key=\"source-smil-flavor\">smil/source+partial</configuration>\n    <configuration key=\"target-presenter-flavor\">presenter/standard</configuration>\n    <configuration key=\"target-presentation-flavor\">presentation/standard</configuration>\n    <configuration key=\"concat-encoding-profile\">concat.work</configuration>\n    <configuration key=\"trim-encoding-profile\">trim.work</configuration>\n    <configuration key=\"force-encoding-profile\">editor.work</configuration>\n  </configurations>\n</operation>  In our example, the PartialImportWorkflowOperation will create the target flavors presenter/standard and\npresentation/standard as depicted below:   The green parts have been filled in by the PartialImportWorkflowOperation by either silence (audio) or pictures (video).  To achieve this, the PartialImportWorkflowOperation performs the following steps:    Extend content at the beginning:  If the first partial track of a given source and type (audio/video) does not\n   begin at position zero, content is added in front of it so that the corresponding target track will start at position\n   zero. For audio, silence is added. In case of video, the first frame of the first partial track is added.    Filling the gaps:  As you can see in our example, it is possible that content is missing within the actual tracks.\n   Those gaps are filled by adding silence (in case of audio) or adding the last frame of the previous partial track (in\n   case of video). In this step, content is also added at the end of the track in case its duration is less than the\n   overall duration of the recording.    Trim the tracks:  It is possible that processing the ingested files according to the SMIL file would result in\n   tracks that have a longer duration than the overall recording should. Therefore, all tracks are trimmed individually\n   to the target duration.    Mux audio tracks:  To avoid the necessity to call further workflow operations just for audio muxing, the\n   PartialImportWorkflowOperation can perform audio muxing itself. In our example, it would mux the audio and video\n   track of the presenter into a single audio/video track.    Ensure specific output formats:  There may be situations where you want to ensure that the output of this\n   operations comes with a specific file format, e.g.  MP4 . The configuration keys  force-encoding  and\n    required_extensions  can be used to control the behavior of the PartialImportWorkflowOperation: In case the\n    force-encoding  is set to  true , the target tracks will be re-encoded using the  force-encoding-profile . The\n   target tracks will also be re-encoded using that encoding profile in case its file extensions don't match the\n    required_extensions .",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/#smil-file-structure",
            "text": "The PartialImportWorkflowOperation expects a specific subset of SMIL that is described in this section.\nThe overall structure of the SMIL file is shown by example below:    <?xml version=\"1.1\" encoding=\"UTF-8\"?>\n  <smil xmlns=\"http://www.w3.org/ns/SMIL\" version=\"3.0\">\n    <head/>\n    <body>\n      <par dur=\"15000ms\">\n        <seq>\n          <video begin=\"400ms\" dur=\"13000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/>\n          <video begin=\"15000ms\" dur=\"70000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/5133d85c-5813-4b54-8a43-0cce9ddc1c4a/video_file.mov\"/>\n          <audio begin=\"0ms\" dur=\"400ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/>\n          <audio begin=\"900ms\" dur=\"13000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/72a42596-e1d0-47a5-b9c8-60180b466954/audio_file.mov\"/>\n        </seq>\n        <seq>\n          <video begin=\"900ms\" dur=\"30000ms\" src=\"/files/mediapackage/7b56bf47-8065-4244-96a0-412a759ccc3f/bf5ea647-b99b-4ec3-a10c-29445fb01eca/video_file.mov\"/>\n        </seq>\n      </par>\n    </body>\n  </smil>  The PartialImportWorkflowOperation can handle at most one  par  element that is used to describe to overall media\nduration using the attribute  dur . The resulting tracks will be trimmed to this duration if necessary. In the example\nabove, the overall media duration is set to 15 seconds.  The  par  element has one or two sequence sub elements  seq , each describing a track that is to be built from its\nsub elements - the partial tracks. Each sequence ( seq ) has at least one sub element. Sub elements can be either video  elements,  audio  elements or both  video  and  audio  elements. Each of those sub elements requires the\nattributes  begin  (position of partial track in milliseconds relative to start of overall media) and  dur  (duration of\npartial track in milliseconds) The  audio  elements are used to indicate that the media file referred to is an\naudio-only media file, whereas  video  elements can refer to either video-only or audio-video media files. The following\ncombinations result in a defined behavior:",
            "title": "SMIL File Structure"
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/#supported-combinations-of-video-and-audio-elements",
            "text": "video  audio  resulting track      audio/video track  n/a  audio/video track    video-only track  n/a  video-only track    video-only track  audio-only track  audio/video track    n/a  audio-only track  audio-only track     All other combinations of  video  and  audio  elements result in unspecified behavior of the\nPartialImportWorkflowOperation.",
            "title": "Supported Combinations of Video and Audio Elements"
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/#order-of-video-and-audio-elements",
            "text": "Within a sequence ( seq ), the  video  elements most occur in ascending order considering the values of their attributes begin . The same holds for  audio  elements. Note the  video  and  audio  elements are processed individually, so the\norder of occurrences of  video  and  audio  elements are independent from each other.  Important:  The PartialImportWorkflowOperation will not process  video  or  audio  elements correctly if the order of\nappearance in the SMIL file is not correct.",
            "title": "Order of Video and Audio Elements"
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/#overlapping-partial-tracks",
            "text": "The behavior of overlapping partial tracks is unspecified, i.e. for a given element  e  ( video  or  audio ), the value\nof  begin  for the subsequent element  (e+1)  of the same type ( video  or  audio ) within the same sequence must be\nequal or greater than  e.begin + e.dur , i.e. make sure that the following invariant holds:  (e+1).begin >= e.begin +\ne.dur",
            "title": "Overlapping Partial Tracks"
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/#encoding-profiles-the-partialimportworkflowoperation-uses-a-number-of-encoding-profiles-to-perform-its-processing",
            "text": "Some of the encoding profiles can be explicitly configured by the user, others are used implicitly in means of being\nhard-coded and are not supposed to be changed by the user.",
            "title": "Encoding Profiles The PartialImportWorkflowOperation uses a number of encoding profiles to perform its processing."
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/#hard-coded-encoding-profiles",
            "text": "encoding profile  description      import.preview  Extract the first frame of a given partial track    import.image-frame  Extract the last frame of a given partial track. Note that this profile is used to extract the  exactly  last frame of a partial track - not just a frame close to the last one. To make this work for video files with headers that don't contain the exact frame count, set  accurate_frame_count  to  true  in  etc/org.opencastproject.inspection.ffmpeg.MediaInspectionServiceImpl.cfg    image-movie.work  Generate video partial tracks based on extracted images used to fill video gaps    import.silent  Generate silent audio tracks used to fill audio gaps",
            "title": "Hard-coded Encoding Profiles"
        },
        {
            "location": "/workflowoperationhandlers/partial-import-woh/#configurable-encoding-profiles",
            "text": "configuration key  description      concat-encoding-profile  Used to concatenate partial tracks into tracks    trim-encoding-profile  Used to trim the resulting concatenated single tracks if necessary    force-encoding-profile  Used to re-encode target tracks in case the file extension of a given target track is not included in  required-extensions  or the configuration key  force-encoding  is set to  true",
            "title": "Configurable Encoding Profiles"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/",
            "text": "PostMediapackageWorkflowHandler\n\n\nDescription\n\n\nThis Workflow Operation Handler can be used to send a POST request containing an XML/JSON representation of the\nMediapackage processed by the workflow to an external webservice. The service supports HTTP Basic and Digest\nAuthentication.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Keys\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nurl\n\n\nThe target url\n\n\n\n\n\n\nformat\n\n\nThe desired export format: \nxml\n or \njson\n\n\n\n\n\n\ndebug\n\n\nDisable this on a productive system. If enabled, request bodies etc. will be written to log. If disabled, only errors will be logged.\n\n\n\n\n\n\nmediapackage.type\n\n\nType of Mediapackage to send (possible values: \nworkflow\n, \nsearch\n; default: \nsearch\n)\n\n\n\n\n\n\nauth.enabled\n\n\nenable authentication (simple/digest will be detected automatically)\n\n\n\n\n\n\nauth.username\n\n\nusername for authentication\n\n\n\n\n\n\nauth.password\n\n\npassword for authentication\n\n\n\n\n\n\n+source_system\n\n\nfields with keys beginning with \n+\n will be added to the message body\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n    id=\"post-mediapackage\"\n    fail-on-error=\"false\"\n    exception-handler-workflow=\"error\"\n    description=\"Sending MediaPackage to Lernfunk3\">\n    <configurations>\n        <configuration key=\"url\">http://example.com:5000/</configuration>\n        <configuration key=\"format\">xml</configuration>\n        <configuration key=\"debug\">no</configuration>\n        <configuration key=\"mediapackage.type\">search</configuration>\n        <configuration key=\"auth.enabled\">yes</configuration>\n        <configuration key=\"auth.username\">exportuser</configuration>\n        <configuration key=\"auth.password\">secret</configuration>\n        <configuration key=\"+source_system\">video.example.com</configuration>\n    </configurations>\n</operation>",
            "title": "Post Media Package"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/#postmediapackageworkflowhandler",
            "text": "",
            "title": "PostMediapackageWorkflowHandler"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/#description",
            "text": "This Workflow Operation Handler can be used to send a POST request containing an XML/JSON representation of the\nMediapackage processed by the workflow to an external webservice. The service supports HTTP Basic and Digest\nAuthentication.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/#parameter-table",
            "text": "Configuration Keys  Description      url  The target url    format  The desired export format:  xml  or  json    debug  Disable this on a productive system. If enabled, request bodies etc. will be written to log. If disabled, only errors will be logged.    mediapackage.type  Type of Mediapackage to send (possible values:  workflow ,  search ; default:  search )    auth.enabled  enable authentication (simple/digest will be detected automatically)    auth.username  username for authentication    auth.password  password for authentication    +source_system  fields with keys beginning with  +  will be added to the message body",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/#operation-example",
            "text": "<operation\n    id=\"post-mediapackage\"\n    fail-on-error=\"false\"\n    exception-handler-workflow=\"error\"\n    description=\"Sending MediaPackage to Lernfunk3\">\n    <configurations>\n        <configuration key=\"url\">http://example.com:5000/</configuration>\n        <configuration key=\"format\">xml</configuration>\n        <configuration key=\"debug\">no</configuration>\n        <configuration key=\"mediapackage.type\">search</configuration>\n        <configuration key=\"auth.enabled\">yes</configuration>\n        <configuration key=\"auth.username\">exportuser</configuration>\n        <configuration key=\"auth.password\">secret</configuration>\n        <configuration key=\"+source_system\">video.example.com</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/",
            "text": "PrepareAVWorkflowOperation\n\n\nDescription\n\n\nThe PrepareAVWorkflowOperation works is like this:\n\n\nIf there are two tracks with the same flavor, and one of them contains a video stream only, while the other contains an\naudio stream only, the implementation will call the composer's \"mux\" method, with the result that the audio will be\nmuxed with the video, using the video's movie container.\n\n\nIf it there is one track with a certain flavor, the \"encode\" method is called which will rewrite (vs. encode) the file\nusing the same container and codec (-vcodec copy, -a codec copy), while the container format is determined by ffmpeg via\nthe file's extension. The reason for doing this is that many media files are in a poor state with regard to their\ncompatibility (most often, the stream's codec contains differing information from the container), so we are basically\nasking ffmepg to rewrite the whole thing, which will in many cases eliminate problems that would otherwhise occur later\nin the pipeline (encoding to flash, mjpeg etc.).\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/source\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/work\n\n\nSpecifies the flavor the new files will get.\n\n\n\n\n\n\nmux-encoding-profile\n\n\nmux-av.work\n\n\nThe encoding profile to use for media that needs to be muxed (default is 'mux-av.work')\n\n\n\n\n\n\naudio-video-encoding-profile\n\n\nav.work\n\n\nThe encoding profile to use for media that is audio-video already and needs to be re-encodend (default is av.work)\n\n\n\n\n\n\nvideo-encoding-profile\n\n\nvideo-only.work\n\n\nThe encoding profile to use for media that is only video and needs to be re-encodend (default is video-only.work)\n\n\n\n\n\n\naudio-encoding-profile\n\n\naudio-only.work\n\n\nThe encoding profile to use for media that is only audio and needs to be re-encodend (default is audio-only.work)\n\n\n\n\n\n\nrewrite\n\n\ntrue\n\n\nShould files be rewritten\n\n\n\n\n\n\naudio-muxing-source-flavors\n\n\npresentation/source,presentation/*,*/*\n\n\nIf there is no matching flavor to mux, search for a track with audio that can be muxed by going from left to right through this comma-separated list of source flavors\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"prepare-av\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Preparing presenter audio and video work versions\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/source</configuration>\n    <configuration key=\"target-flavor\">presenter/work</configuration>\n    <configuration key=\"rewrite\">false</configuration>\n    <configuration key=\"audio-muxing-source-flavors\">*/?,*/*</configuration>\n  </configurations>\n</operation>\n\n\n\nAudio Muxing\n\n\nThe PrepareAVWorkflowOperation can be used for audio muxing in case a matching source video track has no audio. Audio\nmuxing is performed as described below:\n\n\nIn case the \nsource-flavor\n matches to exactly two tracks whereas one track is a video-only track and the other is an\naudio-only track, those tracks will be merged into a single audio-video track.\n\n\nIf there is no such matching flavor to mux, additional audio muxing facilities can be controlled by the use of the\nconfiguration key \naudio-muxing-source-flavors\n. That configuration key contains a comma-separated list of flavors that\ndefines the search order of how to find an audio track.\n\n\nThe following two wildcard characters can be used in flavors in that list:\n\n\n\n\n'*' will match to any type or subtype\n\n\n'?' will match to the type or subtype of the matching \nsource-flavor\n\n\n\n\nNote: In case that a flavor used with \naudio-muxing-source-flavors\n matches to multiple tracks within the media package\nresulting in a list of matching tracks, the search order within that list is undefined, i.e. PrepareAVWorkflowOperation\nwill just pick any of those tracks that has audio.\n\n\nExample\n\n\n[...]\n<configuration key=\"source-flavor\">presenter/*</configuration>\n<configuration key=\"audio-muxing-source-flavors\">presenter-audio/?, presentation/?,presentation/*,?/audio,*/*</configuration>\n[...]\n\n\n\nLet's assume that exactly one video-only track of flavor presenter/source in the media package and another track of\nflavor audio/track that has audio.\n\n\nIn this example, the PrepareAVWorkflowOperation would perform the following steps:\n\n\n\n\nSearch tracks of flavor presenter-audio/source (presenter-audio/?)\n\n\nSearch tracks of flavor presentation/source (presentation/?)\n\n\nSearch tracks of flavor presentation/*\n\n\nSearch tracks of flavor presenter/audio (?/audio)\n\n\nSearch tracks of flavor */*",
            "title": "Prepare A/V"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#prepareavworkflowoperation",
            "text": "",
            "title": "PrepareAVWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#description",
            "text": "The PrepareAVWorkflowOperation works is like this:  If there are two tracks with the same flavor, and one of them contains a video stream only, while the other contains an\naudio stream only, the implementation will call the composer's \"mux\" method, with the result that the audio will be\nmuxed with the video, using the video's movie container.  If it there is one track with a certain flavor, the \"encode\" method is called which will rewrite (vs. encode) the file\nusing the same container and codec (-vcodec copy, -a codec copy), while the container format is determined by ffmpeg via\nthe file's extension. The reason for doing this is that many media files are in a poor state with regard to their\ncompatibility (most often, the stream's codec contains differing information from the container), so we are basically\nasking ffmepg to rewrite the whole thing, which will in many cases eliminate problems that would otherwhise occur later\nin the pipeline (encoding to flash, mjpeg etc.).",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/source  Specifies which media should be processed.    target-flavor  presenter/work  Specifies the flavor the new files will get.    mux-encoding-profile  mux-av.work  The encoding profile to use for media that needs to be muxed (default is 'mux-av.work')    audio-video-encoding-profile  av.work  The encoding profile to use for media that is audio-video already and needs to be re-encodend (default is av.work)    video-encoding-profile  video-only.work  The encoding profile to use for media that is only video and needs to be re-encodend (default is video-only.work)    audio-encoding-profile  audio-only.work  The encoding profile to use for media that is only audio and needs to be re-encodend (default is audio-only.work)    rewrite  true  Should files be rewritten    audio-muxing-source-flavors  presentation/source,presentation/*,*/*  If there is no matching flavor to mux, search for a track with audio that can be muxed by going from left to right through this comma-separated list of source flavors",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#operation-example",
            "text": "<operation\n  id=\"prepare-av\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Preparing presenter audio and video work versions\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/source</configuration>\n    <configuration key=\"target-flavor\">presenter/work</configuration>\n    <configuration key=\"rewrite\">false</configuration>\n    <configuration key=\"audio-muxing-source-flavors\">*/?,*/*</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#audio-muxing",
            "text": "The PrepareAVWorkflowOperation can be used for audio muxing in case a matching source video track has no audio. Audio\nmuxing is performed as described below:  In case the  source-flavor  matches to exactly two tracks whereas one track is a video-only track and the other is an\naudio-only track, those tracks will be merged into a single audio-video track.  If there is no such matching flavor to mux, additional audio muxing facilities can be controlled by the use of the\nconfiguration key  audio-muxing-source-flavors . That configuration key contains a comma-separated list of flavors that\ndefines the search order of how to find an audio track.  The following two wildcard characters can be used in flavors in that list:   '*' will match to any type or subtype  '?' will match to the type or subtype of the matching  source-flavor   Note: In case that a flavor used with  audio-muxing-source-flavors  matches to multiple tracks within the media package\nresulting in a list of matching tracks, the search order within that list is undefined, i.e. PrepareAVWorkflowOperation\nwill just pick any of those tracks that has audio.",
            "title": "Audio Muxing"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#example",
            "text": "[...]\n<configuration key=\"source-flavor\">presenter/*</configuration>\n<configuration key=\"audio-muxing-source-flavors\">presenter-audio/?, presentation/?,presentation/*,?/audio,*/*</configuration>\n[...]  Let's assume that exactly one video-only track of flavor presenter/source in the media package and another track of\nflavor audio/track that has audio.  In this example, the PrepareAVWorkflowOperation would perform the following steps:   Search tracks of flavor presenter-audio/source (presenter-audio/?)  Search tracks of flavor presentation/source (presentation/?)  Search tracks of flavor presentation/*  Search tracks of flavor presenter/audio (?/audio)  Search tracks of flavor */*",
            "title": "Example"
        },
        {
            "location": "/workflowoperationhandlers/probe-resolution-woh/",
            "text": "ProbeResolutionWorkflowOperationHandler\n\n\nDescription\n\n\nThe ProbeResolutionWorkflowOperationHandler analyzes specified tracks in the mediapackage and sets workflow instance\nvariables based on the video resolution and the mapping set-up.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor*\n\n\npresentation/work\n\n\nThe \"flavor\" of the track to use as a source input\n\n\n\n\n\n\nvar:VARNAME\n\n\n1280x720,1920x1080\n\n\nResolutions to variable mapping\n\n\n\n\n\n\nval:VARNAME\n\n\n16/9\n\n\nValue to set if resolution matches\n\n\n\n\n\n\n\n\n* mandatory configuration key\n\n\nThere can be an arbitrary number of variable parameters. They must be prefixed by \nvar:\n, followed by the variable name\nto set to true if the video has a resolution listed. The \nvar:\n prefix will not be part of the resulting variable name\nbut will be replaced with a representation of the tracks flavor.\n\n\nBy default, the variable will be set to \ntrue\n if the resolution matches. If a \nval:VARNAME\n configuration is present\nwhich matches a \nvar:VARNAME\n, the value from that configuration key will be used instead.\n\n\nNote that if there are multiple video streams with one flavor, only the information from the last video stream are\ntaken.\n\n\nOperation Example\n\n\n<operation\n  id=\"probe-resolution\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Set control variables based on video resolution\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/source</configuration>\n    <configuration key=\"var:aspect\">1280x720,1920x1080,2592x1080</configuration>\n    <configuration key=\"val:aspect\">16/9</configuration>\n    <configuration key=\"var:is_720\">1280x720</configuration>\n    <configuration key=\"var:is_1080\">1920x1080,2592x1080</configuration>\n  </configurations>\n</operation>\n\n\n\nIf a video track with a resolution of 1280x720 is passed to this operation as \npresentation/source\n, the resulting\nvariables would be:\n\n\npresentation_source_is_720=true\npresentation_source_aspect=16/9",
            "title": "Probe Resolution"
        },
        {
            "location": "/workflowoperationhandlers/probe-resolution-woh/#proberesolutionworkflowoperationhandler",
            "text": "",
            "title": "ProbeResolutionWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/probe-resolution-woh/#description",
            "text": "The ProbeResolutionWorkflowOperationHandler analyzes specified tracks in the mediapackage and sets workflow instance\nvariables based on the video resolution and the mapping set-up.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/probe-resolution-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      source-flavor*  presentation/work  The \"flavor\" of the track to use as a source input    var:VARNAME  1280x720,1920x1080  Resolutions to variable mapping    val:VARNAME  16/9  Value to set if resolution matches     * mandatory configuration key  There can be an arbitrary number of variable parameters. They must be prefixed by  var: , followed by the variable name\nto set to true if the video has a resolution listed. The  var:  prefix will not be part of the resulting variable name\nbut will be replaced with a representation of the tracks flavor.  By default, the variable will be set to  true  if the resolution matches. If a  val:VARNAME  configuration is present\nwhich matches a  var:VARNAME , the value from that configuration key will be used instead.  Note that if there are multiple video streams with one flavor, only the information from the last video stream are\ntaken.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/probe-resolution-woh/#operation-example",
            "text": "<operation\n  id=\"probe-resolution\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Set control variables based on video resolution\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/source</configuration>\n    <configuration key=\"var:aspect\">1280x720,1920x1080,2592x1080</configuration>\n    <configuration key=\"val:aspect\">16/9</configuration>\n    <configuration key=\"var:is_720\">1280x720</configuration>\n    <configuration key=\"var:is_1080\">1920x1080,2592x1080</configuration>\n  </configurations>\n</operation>  If a video track with a resolution of 1280x720 is passed to this operation as  presentation/source , the resulting\nvariables would be:  presentation_source_is_720=true\npresentation_source_aspect=16/9",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/process-smil-woh/",
            "text": "ProcessSmilWorkflowHandler\n\n\nDescription\n\n\nThe ProcessSmilWorkflowHandler is used to edit media files using descriptions from a SMIL file.\nThe SMIL file is typically generated by the editor or it can be constructed and uploaded.\nIt contains names of one or more source tracks and a list of selected clips defined by\nin/out points in ms in the source tracks.\nIt will concatenate all the clips from the source tracks according to the in/out points and encode the result into\nmultiple target videos using a list of encoding profiles.\nIn addition, the target videos are optionally tagged with the name of the encoding profiles.\n\n\nThe Video editor produces a SMIL file and by default will also encode one set of edited videos\ntargets as an intermediate format to be used to do segmentation and then used as source to generate multiple delivery\nformats.\nThis workflow operation is used to bypass the generation of the temporary targets and generate the delivery formats\ndirectly.\nSubsequent workflow operations can select the highest quality source medium by tags and flavors.\nThis operation saves the encoding time of one set of full length video and allows concurrent\nprocessing of multiple independent ffmpeg operations.\n\n\nTo use this operation with the editor, the following must be added to the \neditor\n workflow operation\nto bypass the video editor encoding,\n\n\n<configuration key=\"skip-processing\">true</configuration>\n\n\n\n\nConfiguration details\n\n\nCurrently, there is only one transition type, which is \"fade to black\".\nThe edited video will fade in from black with a fade-out/fade-in for each clip transition and a fade out at the end.\nThe transition duration is a 2 second fade, configured in org.opencastproject.composer.impl.ComposerServiceImpl.cfg.\nIn the future, each transition can be configurable as a SMIL element.\n\n\nThe SMIL file can use more than one source video, but the caller has to take care that the dimension of\nall the source videos are the same.\nThis workflow will generate one independent ffmpeg operation per SMIL paramgroup (based on source) regardless\nof the number of target outputs.\n\n\nThis workflow can handle each source flavor selector independently.\neg: Each source selector can have its own set of encoding profiles, target tags and flavors.\nThe parameters for each configuration, such as flavor are separated into sections by \"\n;\n\".\nE\nach source media selector can have its own sets of encoding profile ids (one for each target recording)\nand target tags,\nas well as its own set of target tags and flavors, defined as a comma delimited list.\n\n\nAs an example, using presenter/source and presentation/source as uploaded media.\neg:\n\n\n <configuration key=\"source-flavors\">*/source</configuration>\n\n\n\n\n\n\nOne source selector means that all the matching recording will be processed the same way.\n\n\n\n\n <configuration key=\"source-flavors\">presenter/source;presentation/source</configuration>\n\n\n\n\n\n\nTwo different source selectors separated by semicolons means that all the matching recordings in the\nfirst selector will be processed according to the parameters in the first\nsection and the all the\nmatching recordings in the second selector will be processed according to the parameters in next section\nof the other configuration values such as encoding profiles.\n\n\n\n\nEach source selector can have only one corresponding section in each set of values.\nThe use of the semi-colon is optional. If it is absent, there is only one section.\nIf there is only one source selector, but multiple sections in the parameters, then the sections are collapsed\ninto one and they will apply to all the source flavors in the source selector.\n\"N to N\" means that each section has its own processing configuration.\n\"1 to N\" or \"N to 1\" means that all the sections are processed the same way,\n but \"M to N\" where \"M <> N\" will result in an error.\n\n\neg:\n\n\n<configuration key=\"target-flavors\">*/preview</configuration>\n<configuration key=\"encoding-profiles\">mp4-low.http;mp4-vga-medium</configuration>\n\n\n\n\n\n\nAll targets are flavored the same way.\nUsing the example above,\nall media are encoded with \"mp4-low.http\" and \"mp4-vga-medium\" and\ntargets are flavored as \"presenter/preview\" and \"presentation/preview\"\n\n\n\n\n <configuration key=\"target-tags\">engage-streaming,rss,atom;engage-download,rss,atom</configuration>\n <configuration key=\"encoding-profiles\">mp4-medium.http;mp4-vga-medium</configuration>\n\n\n\n\n\n\nEach section is tagged individually. Using the example above,\npresenter/preview is encoded with \"mp4-medium.http\" and tagged with \"engage-streaming\" ,\"rss\" and \"atom\",\npresentation/preview is encoded with \"mp4-vga-medium\" and tagged with \"engage-download\",\"rss\" and \"atom\".\n\n\n\n\nIf presenter/work is to be encoded with \"mp4-low.http,mp4-medium.http\" and\npresentation/work is to be encoded with \"mp4-vga-medium,mp4-medium.http\",\nand the target media are flavored as \"presenter/delivery\" and \"presentation/delivery\" respectively,\nand all targets are tagged with \"engage\" and \"archive\" in addition to the names of the encoding profiles used.\n\n\nIt will look like the following.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsmil-flavor\n\n\nsmil/smil\n\n\nSpecifies the flavor of the new media\n\n\n\n\n\n\nsource-flavors\n\n\npresenter/work\n;\npresentation/work\n\n\nWhich media should be encoded\n\n\n\n\n\n\ntarget-flavors\n\n\n*/delivery\n\n\nSpecifies the flavor of the new media\n\n\n\n\n\n\ntarget-tags\n\n\nengage,archive\n\n\nSpecifies the tags of the new media\n\n\n\n\n\n\nencoding-profiles\n\n\nmp4-low.http,mp4-medium.http\n;\nmp4-vga-medium,mp4-medium.http\n\n\nProfiles for each source flavor\n\n\n\n\n\n\ntag-with-profile\n\n\ntrue (default to false)\n\n\ntarget medium are tagged with coresponding encoding profile Id\n\n\n\n\n\n\n\n\nOperation Example\n\n\nThe parameters in the table above will look like this as a workflow operation.\n\n\n<operation\n    id=\"process-smil\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encoding presenter (camera) video to Flash download\">\n    <configurations>\n        <configuration key=\"smil-flavor\">smil/cutting</configuration>\n        <configuration key=\"source-flavors\">presenter/work;presentation/work</configuration>\n        <configuration key=\"target-flavors\">*/delivery</configuration>\n        <configuration key=\"target-tags\">engage,archive</configuration>\n        <configuration key=\"encoding-profiles\">\n                mp4-low.http,mp4-medium.http*;*mp4-vga-medium,mp4-medium.http</configuration>\n        <configuration key=\"tag-with-profile\">true</configuration>\n    </configurations>\n</operation>\n\n\n\nNote:(Very Important)\n\n\nEach encoding section generates all the target media in one ffmpeg call by incorporating relevant parts\nof each encoding profile command using complex filters.\n\n\n\n\n\n\nCare must be taken that \nno complex filters\n are used in the encoding profiles used for this workflow,\nas it can cause a conflict and ffmpeg will fail.\nSimple filters (i.e.: -vf, -af , -filter:v, -filter:a) can be used.\n\n\n\n\n\n\nEncoded target recording are distinguished by the suffix, it is important that \nall the encoding profiles\nused have distinct suffixes\n or the target video tagging can be wrong, for example:\n\n\n\n\n\n\nprofile.mp4-vga-medium.http.suffix = -vga-medium.mp4\nprofile.mp4-medium.http.suffix = -medium.mp4\n\n\n\n\n\n\nIf using this to process SMIL files generated by the editor in the same workflow,\nbe sure to set the \"skip-processing\" key in the editor to true.",
            "title": "Process Smil"
        },
        {
            "location": "/workflowoperationhandlers/process-smil-woh/#processsmilworkflowhandler",
            "text": "",
            "title": "ProcessSmilWorkflowHandler"
        },
        {
            "location": "/workflowoperationhandlers/process-smil-woh/#description",
            "text": "The ProcessSmilWorkflowHandler is used to edit media files using descriptions from a SMIL file.\nThe SMIL file is typically generated by the editor or it can be constructed and uploaded.\nIt contains names of one or more source tracks and a list of selected clips defined by\nin/out points in ms in the source tracks.\nIt will concatenate all the clips from the source tracks according to the in/out points and encode the result into\nmultiple target videos using a list of encoding profiles.\nIn addition, the target videos are optionally tagged with the name of the encoding profiles.  The Video editor produces a SMIL file and by default will also encode one set of edited videos\ntargets as an intermediate format to be used to do segmentation and then used as source to generate multiple delivery\nformats.\nThis workflow operation is used to bypass the generation of the temporary targets and generate the delivery formats\ndirectly.\nSubsequent workflow operations can select the highest quality source medium by tags and flavors.\nThis operation saves the encoding time of one set of full length video and allows concurrent\nprocessing of multiple independent ffmpeg operations.  To use this operation with the editor, the following must be added to the  editor  workflow operation\nto bypass the video editor encoding,  <configuration key=\"skip-processing\">true</configuration>",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/process-smil-woh/#configuration-details",
            "text": "Currently, there is only one transition type, which is \"fade to black\".\nThe edited video will fade in from black with a fade-out/fade-in for each clip transition and a fade out at the end.\nThe transition duration is a 2 second fade, configured in org.opencastproject.composer.impl.ComposerServiceImpl.cfg.\nIn the future, each transition can be configurable as a SMIL element.  The SMIL file can use more than one source video, but the caller has to take care that the dimension of\nall the source videos are the same.\nThis workflow will generate one independent ffmpeg operation per SMIL paramgroup (based on source) regardless\nof the number of target outputs.  This workflow can handle each source flavor selector independently.\neg: Each source selector can have its own set of encoding profiles, target tags and flavors.\nThe parameters for each configuration, such as flavor are separated into sections by \" ; \".\nE\nach source media selector can have its own sets of encoding profile ids (one for each target recording)\nand target tags,\nas well as its own set of target tags and flavors, defined as a comma delimited list.  As an example, using presenter/source and presentation/source as uploaded media.\neg:   <configuration key=\"source-flavors\">*/source</configuration>   One source selector means that all the matching recording will be processed the same way.    <configuration key=\"source-flavors\">presenter/source;presentation/source</configuration>   Two different source selectors separated by semicolons means that all the matching recordings in the\nfirst selector will be processed according to the parameters in the first\nsection and the all the\nmatching recordings in the second selector will be processed according to the parameters in next section\nof the other configuration values such as encoding profiles.   Each source selector can have only one corresponding section in each set of values.\nThe use of the semi-colon is optional. If it is absent, there is only one section.\nIf there is only one source selector, but multiple sections in the parameters, then the sections are collapsed\ninto one and they will apply to all the source flavors in the source selector.\n\"N to N\" means that each section has its own processing configuration.\n\"1 to N\" or \"N to 1\" means that all the sections are processed the same way,\n but \"M to N\" where \"M <> N\" will result in an error.  eg:  <configuration key=\"target-flavors\">*/preview</configuration>\n<configuration key=\"encoding-profiles\">mp4-low.http;mp4-vga-medium</configuration>   All targets are flavored the same way.\nUsing the example above,\nall media are encoded with \"mp4-low.http\" and \"mp4-vga-medium\" and\ntargets are flavored as \"presenter/preview\" and \"presentation/preview\"    <configuration key=\"target-tags\">engage-streaming,rss,atom;engage-download,rss,atom</configuration>\n <configuration key=\"encoding-profiles\">mp4-medium.http;mp4-vga-medium</configuration>   Each section is tagged individually. Using the example above,\npresenter/preview is encoded with \"mp4-medium.http\" and tagged with \"engage-streaming\" ,\"rss\" and \"atom\",\npresentation/preview is encoded with \"mp4-vga-medium\" and tagged with \"engage-download\",\"rss\" and \"atom\".   If presenter/work is to be encoded with \"mp4-low.http,mp4-medium.http\" and\npresentation/work is to be encoded with \"mp4-vga-medium,mp4-medium.http\",\nand the target media are flavored as \"presenter/delivery\" and \"presentation/delivery\" respectively,\nand all targets are tagged with \"engage\" and \"archive\" in addition to the names of the encoding profiles used.  It will look like the following.",
            "title": "Configuration details"
        },
        {
            "location": "/workflowoperationhandlers/process-smil-woh/#parameter-table",
            "text": "configuration keys  example  description      smil-flavor  smil/smil  Specifies the flavor of the new media    source-flavors  presenter/work ; presentation/work  Which media should be encoded    target-flavors  */delivery  Specifies the flavor of the new media    target-tags  engage,archive  Specifies the tags of the new media    encoding-profiles  mp4-low.http,mp4-medium.http ; mp4-vga-medium,mp4-medium.http  Profiles for each source flavor    tag-with-profile  true (default to false)  target medium are tagged with coresponding encoding profile Id",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/process-smil-woh/#operation-example",
            "text": "The parameters in the table above will look like this as a workflow operation.  <operation\n    id=\"process-smil\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encoding presenter (camera) video to Flash download\">\n    <configurations>\n        <configuration key=\"smil-flavor\">smil/cutting</configuration>\n        <configuration key=\"source-flavors\">presenter/work;presentation/work</configuration>\n        <configuration key=\"target-flavors\">*/delivery</configuration>\n        <configuration key=\"target-tags\">engage,archive</configuration>\n        <configuration key=\"encoding-profiles\">\n                mp4-low.http,mp4-medium.http*;*mp4-vga-medium,mp4-medium.http</configuration>\n        <configuration key=\"tag-with-profile\">true</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/process-smil-woh/#notevery-important",
            "text": "Each encoding section generates all the target media in one ffmpeg call by incorporating relevant parts\nof each encoding profile command using complex filters.    Care must be taken that  no complex filters  are used in the encoding profiles used for this workflow,\nas it can cause a conflict and ffmpeg will fail.\nSimple filters (i.e.: -vf, -af , -filter:v, -filter:a) can be used.    Encoded target recording are distinguished by the suffix, it is important that  all the encoding profiles\nused have distinct suffixes  or the target video tagging can be wrong, for example:    profile.mp4-vga-medium.http.suffix = -vga-medium.mp4\nprofile.mp4-medium.http.suffix = -medium.mp4   If using this to process SMIL files generated by the editor in the same workflow,\nbe sure to set the \"skip-processing\" key in the editor to true.",
            "title": "Note:(Very Important)"
        },
        {
            "location": "/workflowoperationhandlers/publish-aws-woh/",
            "text": "PublishAWSS3WorkflowOperation\n\n\nDescription\n\n\nThe PublishAWSS3WorkflowOperation will publish your recording to the normal publication channel (ie, engage), but the\nmedia files will be hosted via AWS S3/Cloudfront.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\ncheck-availability\n\n\nCheck if the media if rechable\n\n\n\n\n\n\ndownload-source-flavors\n\n\nSpecifies which media should be published for download\n\n\n\n\n\n\ndownload-source-tags\n\n\nSpecifies which media should be published for download\n\n\n\n\n\n\ndownload-target-subflavors\n\n\nSubflavor to use for distributed material\n\n\n\n\n\n\ndownload-target-tags\n\n\nModify tags of published media\n\n\n\n\n\n\nstrategy\n\n\nIf there is no key, published media would be retracted before publishing\n\n\n\n\n\n\n\n\nmerge\n\n\n\n\n\n\n\n\nmerges new publication with existing publication\n\n\n\n\n\n\nstreaming-source-flavors\n\n\nSpecifies which media should be published to the streaming server\n\n\n\n\n\n\nstreaming-source-tags\n\n\nSpecifies which media should be published to the streaming server\n\n\n\n\n\n\nstreaming-tagret-tags\n\n\nModify tags of published media\n\n\n\n\n\n\nstreaming-target-subflavors\n\n\nSubflavor to use for distributed material\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"publish-aws\"\n  max-attempts=\"2\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Publishing to Amazon Web Services\">\n  <configurations>\n    <configuration key=\"download-source-flavors\">dublincore/*,security/*</configuration>\n    <configuration key=\"download-source-tags\">engage-download,atom,rss,mobile</configuration>\n    <configuration key=\"streaming-source-tags\">engage-streaming</configuration>\n    <configuration key=\"strategy\">merge</configuration>\n    <configuration key=\"check-availability\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Publish AWS"
        },
        {
            "location": "/workflowoperationhandlers/publish-aws-woh/#publishawss3workflowoperation",
            "text": "",
            "title": "PublishAWSS3WorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/publish-aws-woh/#description",
            "text": "The PublishAWSS3WorkflowOperation will publish your recording to the normal publication channel (ie, engage), but the\nmedia files will be hosted via AWS S3/Cloudfront.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/publish-aws-woh/#parameter-table",
            "text": "configuration keys  description      check-availability  Check if the media if rechable    download-source-flavors  Specifies which media should be published for download    download-source-tags  Specifies which media should be published for download    download-target-subflavors  Subflavor to use for distributed material    download-target-tags  Modify tags of published media    strategy  If there is no key, published media would be retracted before publishing     merge     merges new publication with existing publication    streaming-source-flavors  Specifies which media should be published to the streaming server    streaming-source-tags  Specifies which media should be published to the streaming server    streaming-tagret-tags  Modify tags of published media    streaming-target-subflavors  Subflavor to use for distributed material",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/publish-aws-woh/#operation-example",
            "text": "<operation\n  id=\"publish-aws\"\n  max-attempts=\"2\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Publishing to Amazon Web Services\">\n  <configurations>\n    <configuration key=\"download-source-flavors\">dublincore/*,security/*</configuration>\n    <configuration key=\"download-source-tags\">engage-download,atom,rss,mobile</configuration>\n    <configuration key=\"streaming-source-tags\">engage-streaming</configuration>\n    <configuration key=\"strategy\">merge</configuration>\n    <configuration key=\"check-availability\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/publish-configure-woh/",
            "text": "ConfigurablePublishWorkflowOperationHandler\n\n\nDescription\n\n\nThe \nConfigurablePublishWorkflowOperationHandler\n will distribute the given elements and create a publication element for\nit. By default it will retract all publications before publishing anew.\n\n\nParameter Table\n\n\nThese are the keys that are configured through the workflow definition. At least one media package element must match\nthe supplied \nsource-flavors\n or \nsource-tags\n or else the operation will not know what to publish. The \nchannel-id\n and\n\nurl-pattern\n are also mandatory.\n\n\n\n\n\n\n\n\nKey\n\n\nDescription\n\n\nExample\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\nchannel-id\n\n\nId of the channel to publish to\n\n\ninternal\n\n\n\n\n\n\n\n\nmimetype\n\n\nMime type of the published element\n\n\ntext/html\n\n\nType of last distributed element\n\n\n\n\n\n\nsource-flavors\n\n\nFlavors of the media package elements to publish\n\n\n*/trimmed\n\n\n\n\n\n\n\n\nsource-tags\n\n\nTags of the media package elements to publish\n\n\nengage\n\n\n\n\n\n\n\n\nurl-pattern\n\n\nPattern to create the URI for the published from\n\n\nftp://\u2026/${event_id}\n\n\n\n\n\n\n\n\nwith-published-elements\n\n\nUse the current contents of the media package instead of publishing elements to a channel\n\n\ntrue\n\n\n\n\n\n\n\n\ncheck-availability\n\n\nCheck if the media is reachable after publication\n\n\nfalse\n\n\nfalse\n\n\n\n\n\n\nstrategy\n\n\nStrategy for when there is already published material\n\n\nfail\n\n\nretract\n\n\n\n\n\n\nmode\n\n\nHow elements are distributed\n\n\nmixed\n\n\nbulk\n\n\n\n\n\n\n\n\nMode\n\n\nThe configuration key \nmode\n can be used to control how media package elements are being distributed:\n\n\n\n\n\n\n\n\nMode\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsingle\n\n\nFor each media package element, a job is created\n\n\n\n\n\n\nmixed\n\n\nOne job for all media package elements that are not tracks and one job per track\n\n\n\n\n\n\nbulk\n\n\nOne job for all media package elements\n\n\n\n\n\n\n\n\nThis allows you to choose a lot of jobs and parallelism (\nsingle\n), just one job and no parallelism (\nbulk\n)\nor something in between (\nmixed\n). The best choice depends on your setup.\n\n\nURL Pattern Variables\n\n\nThese are the variables available in the \nurl-pattern\n configuration. They will be replaced with the value during the\nexecution of the workflow operation.\n\n\n\n\n\n\n\n\nVariable\n\n\nDescription\n\n\nExample\n\n\n\n\n\n\n\n\n\n\n${element_uri}\n\n\nURI of the last media package element\n\n\nhttp://ex.com/files/mediap...xy.mp4\n\n\n\n\n\n\n${event_id}\n\n\nThe event (media package) identifier\n\n\n18633e04-1a3f-4bbb-a72a-99c15deba1b9\n\n\n\n\n\n\n${player_path}\n\n\nThe player path for the event\n\n\n/engage/theodul/ui/core.html?id=\n\n\n\n\n\n\n${publication_id}\n\n\nThe id of this publication.\n\n\n54f6c12d-8e68-4ec8-badf-cd045b33d01e\n\n\n\n\n\n\n${series_id}\n\n\nThe id of the series if available\n\n\n36f3c5d8-ad4d-4dab-beb1-1400ffab4a69\n\n\n\n\n\n\n\n\nPublication Channel Labels and Icons\n\n\nUsing this workflow operation, you can create arbitrary custom publication channels. Without further action, the\nadministrative user interface will label these channels \"Custom\". You can specify both a label and an icon for each\ncustom publication channels in the configuration files \netc/listproviders/publication.channel.labels.properties\n and\n\netc/listproviders/publication.channel.icons.properties\n.\n\n\nOperation Examples\n\n\nInternal Channel\n\n\n<operation\n  id=\"publish-configure\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Publish to internal channel\">\n  <configurations>\n    <configuration key=\"source-tags\">engage,atom,rss</configuration>\n    <configuration key=\"channel-id\">internal</configuration>\n    <configuration key=\"url-pattern\">http://localhost:8080/admin-ng/index.html#/events/events/${event_id}/tools/playback</configuration>\n  </configurations>\n</operation>\n\n\n\nExternal API\n\n\n<operation\n  id=\"publish-configure\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Publish to external api publication channel\">\n  <configurations>\n    <configuration key=\"channel-id\">api</configuration>\n    <configuration key=\"mimetype\">application/json</configuration>\n    <configuration key=\"source-tags\">engage-download,engage-streaming</configuration>\n    <configuration key=\"url-pattern\">http://api.oc.org/api/events/${event_id}</configuration>\n    <configuration key=\"check-availability\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Publish Configure"
        },
        {
            "location": "/workflowoperationhandlers/publish-configure-woh/#configurablepublishworkflowoperationhandler",
            "text": "",
            "title": "ConfigurablePublishWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/publish-configure-woh/#description",
            "text": "The  ConfigurablePublishWorkflowOperationHandler  will distribute the given elements and create a publication element for\nit. By default it will retract all publications before publishing anew.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/publish-configure-woh/#parameter-table",
            "text": "These are the keys that are configured through the workflow definition. At least one media package element must match\nthe supplied  source-flavors  or  source-tags  or else the operation will not know what to publish. The  channel-id  and url-pattern  are also mandatory.     Key  Description  Example  Default      channel-id  Id of the channel to publish to  internal     mimetype  Mime type of the published element  text/html  Type of last distributed element    source-flavors  Flavors of the media package elements to publish  */trimmed     source-tags  Tags of the media package elements to publish  engage     url-pattern  Pattern to create the URI for the published from  ftp://\u2026/${event_id}     with-published-elements  Use the current contents of the media package instead of publishing elements to a channel  true     check-availability  Check if the media is reachable after publication  false  false    strategy  Strategy for when there is already published material  fail  retract    mode  How elements are distributed  mixed  bulk",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/publish-configure-woh/#mode",
            "text": "The configuration key  mode  can be used to control how media package elements are being distributed:     Mode  Description      single  For each media package element, a job is created    mixed  One job for all media package elements that are not tracks and one job per track    bulk  One job for all media package elements     This allows you to choose a lot of jobs and parallelism ( single ), just one job and no parallelism ( bulk )\nor something in between ( mixed ). The best choice depends on your setup.",
            "title": "Mode"
        },
        {
            "location": "/workflowoperationhandlers/publish-configure-woh/#url-pattern-variables",
            "text": "These are the variables available in the  url-pattern  configuration. They will be replaced with the value during the\nexecution of the workflow operation.     Variable  Description  Example      ${element_uri}  URI of the last media package element  http://ex.com/files/mediap...xy.mp4    ${event_id}  The event (media package) identifier  18633e04-1a3f-4bbb-a72a-99c15deba1b9    ${player_path}  The player path for the event  /engage/theodul/ui/core.html?id=    ${publication_id}  The id of this publication.  54f6c12d-8e68-4ec8-badf-cd045b33d01e    ${series_id}  The id of the series if available  36f3c5d8-ad4d-4dab-beb1-1400ffab4a69",
            "title": "URL Pattern Variables"
        },
        {
            "location": "/workflowoperationhandlers/publish-configure-woh/#publication-channel-labels-and-icons",
            "text": "Using this workflow operation, you can create arbitrary custom publication channels. Without further action, the\nadministrative user interface will label these channels \"Custom\". You can specify both a label and an icon for each\ncustom publication channels in the configuration files  etc/listproviders/publication.channel.labels.properties  and etc/listproviders/publication.channel.icons.properties .",
            "title": "Publication Channel Labels and Icons"
        },
        {
            "location": "/workflowoperationhandlers/publish-configure-woh/#operation-examples",
            "text": "",
            "title": "Operation Examples"
        },
        {
            "location": "/workflowoperationhandlers/publish-configure-woh/#internal-channel",
            "text": "<operation\n  id=\"publish-configure\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Publish to internal channel\">\n  <configurations>\n    <configuration key=\"source-tags\">engage,atom,rss</configuration>\n    <configuration key=\"channel-id\">internal</configuration>\n    <configuration key=\"url-pattern\">http://localhost:8080/admin-ng/index.html#/events/events/${event_id}/tools/playback</configuration>\n  </configurations>\n</operation>",
            "title": "Internal Channel"
        },
        {
            "location": "/workflowoperationhandlers/publish-configure-woh/#external-api",
            "text": "<operation\n  id=\"publish-configure\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Publish to external api publication channel\">\n  <configurations>\n    <configuration key=\"channel-id\">api</configuration>\n    <configuration key=\"mimetype\">application/json</configuration>\n    <configuration key=\"source-tags\">engage-download,engage-streaming</configuration>\n    <configuration key=\"url-pattern\">http://api.oc.org/api/events/${event_id}</configuration>\n    <configuration key=\"check-availability\">true</configuration>\n  </configurations>\n</operation>",
            "title": "External API"
        },
        {
            "location": "/workflowoperationhandlers/publish-engage-woh/",
            "text": "PublishEngageWorkflowOperation\n\n\nDescription\n\n\nThe \nPublishEngageWorkflowOperation\n will bring your media to the engage distribution channels (streaming, progressive\ndownload, \u2026)\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\ncheck-availability\n\n\nCheck if the media if reachable\n\n\n\n\n\n\ndownload-source-flavors\n\n\nSpecifies which media should be published for download\n\n\n\n\n\n\ndownload-source-tags\n\n\nSpecifies which media should be published for download\n\n\n\n\n\n\ndownload-target-subflavors\n\n\nSubflavor to use for distributed material\n\n\n\n\n\n\ndownload-target-tags\n\n\nModify tags of published media\n\n\n\n\n\n\nstrategy\n\n\nIf there is no key, published media would be retracted before publishing\n\n\n\n\n\n\n\n\n<configuration key=\"strategy\">merge</configuration>\n\n\n\n\n\n\n\n\nmerges new publication with existing publication\n\n\n\n\n\n\nstreaming-source-flavors\n\n\nSpecifies which media should be published to the streaming server\n\n\n\n\n\n\nstreaming-source-tags\n\n\nSpecifies which media should be published to the streaming server\n\n\n\n\n\n\nstreaming-target-tags\n\n\nModify tags of published media\n\n\n\n\n\n\nstreaming-target-subflavors\n\n\nSubflavor to use for distributed material\n\n\n\n\n\n\nmerge-force-flavors\n\n\nFlavors of elements for which an update is enforced when mergeing catalogs.\n\n\n\n\n\n\n\n\nDefaults to \ndublincore/*,security/*\n.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n    id=\"publish-engage\"\n    max-attempts=\"2\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Distribute and publish to engage player\">\n    <configurations>\n        <configuration key=\"download-source-tags\">engage,atom,rss</configuration>\n        <configuration key=\"streaming-source-tags\">engage</configuration>\n        <configuration key=\"check-availability\">true</configuration>\n        <configuration key=\"strategy\">merge</configuration>\n    </configurations>\n</operation>",
            "title": "Publish Engage"
        },
        {
            "location": "/workflowoperationhandlers/publish-engage-woh/#publishengageworkflowoperation",
            "text": "",
            "title": "PublishEngageWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/publish-engage-woh/#description",
            "text": "The  PublishEngageWorkflowOperation  will bring your media to the engage distribution channels (streaming, progressive\ndownload, \u2026)",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/publish-engage-woh/#parameter-table",
            "text": "configuration keys  description      check-availability  Check if the media if reachable    download-source-flavors  Specifies which media should be published for download    download-source-tags  Specifies which media should be published for download    download-target-subflavors  Subflavor to use for distributed material    download-target-tags  Modify tags of published media    strategy  If there is no key, published media would be retracted before publishing     <configuration key=\"strategy\">merge</configuration>     merges new publication with existing publication    streaming-source-flavors  Specifies which media should be published to the streaming server    streaming-source-tags  Specifies which media should be published to the streaming server    streaming-target-tags  Modify tags of published media    streaming-target-subflavors  Subflavor to use for distributed material    merge-force-flavors  Flavors of elements for which an update is enforced when mergeing catalogs.     Defaults to  dublincore/*,security/* .",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/publish-engage-woh/#operation-example",
            "text": "<operation\n    id=\"publish-engage\"\n    max-attempts=\"2\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Distribute and publish to engage player\">\n    <configurations>\n        <configuration key=\"download-source-tags\">engage,atom,rss</configuration>\n        <configuration key=\"streaming-source-tags\">engage</configuration>\n        <configuration key=\"check-availability\">true</configuration>\n        <configuration key=\"strategy\">merge</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/publish-oaipmh-woh/",
            "text": "PublishOaiPmhWorkflowOperation\n\n\nDescription\n\n\nThe Publish OAI-PMH workflow operation exposes your media's metadata in a OAI-PMH repository for harvesting by OAI-PMH\naware applications.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Keys\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ndownload-flavors\n\n\nDistribute any mediapackage elements with one of these (comma separated) flavors to download\n\n\n\n\n\n\ndownload-tags\n\n\nDistribute any mediapackage elements with one of these (comma separated) tags to download\n\n\n\n\n\n\nstreaming-flavors\n\n\nDistribute any mediapackage elements with one of these (comma separated) flavors to streaming\n\n\n\n\n\n\nstreaming-tags\n\n\nDistribute any mediapackage elements with one of these (comma separated) tags to streaming\n\n\n\n\n\n\ncheck-availability\n\n\nCheck if the distributed download artifact is available at its URL (default: true)\n\n\n\n\n\n\nrepository\n\n\nThe name of the OAI-PMH repository where the media should be published to\n\n\n\n\n\n\nexternal-template\n\n\nThe optional URL template for URL the OAI-PMH publication element\n\n\n\n\n\n\nexternal-channel\n\n\nThe optional channel name for the OAI-PMH publication element\n\n\n\n\n\n\nexternal-mime-type\n\n\nThe optional mime type for the OAI-PMH publication element\n\n\n\n\n\n\n\n\nNote: The all or none of the configuration keys \nexternal-template\n, \nexternal-channel\n and \nexternal-mime-type\n must to\nbe set.\n\n\nCustomizing the OAI-PMH Publication Element\n\n\nIf the configuration keys \nexternal-template\n, \nexternal-channel\n and \nexternal-mime-type\n are not set, the publication\nelement will use the following default values:\n\n\n\n\n\n\n\n\nField\n\n\nDefault Value\n\n\n\n\n\n\n\n\n\n\nurl\n\n\nprop.org.opencastproject.oaipmh.server.hosturl + org.opencastproject.oaipmh.mountpoint + repository\n\n\n\n\n\n\nmime type\n\n\n\"text/xml\"\n\n\n\n\n\n\nchannel name\n\n\n\"oaipmh-\" + repository\n\n\n\n\n\n\n\n\nNote that \norg.opencastproject.oaipmh.server.hosturl\n is defined in\n\netc/org.opencastproject.organization-mh_default_org.cfg\n and \norg.opencastproject.oaipmh.mountpoint\n is defined in\n\ncustom.properties\n and defaults to \n/oaipmh\n.\n\n\nExample:\n\n\nhttp://localhost:8080/oaipmh/default\n\n\n\nThe OAI-PMH publication element can be customized by setting the configuration keys \nexternal-template\n,\n\nexternal-channel\n and \nexternal-mime-type\n.\n\n\nThe URL of the publication element can be set by using \nexternal-template\n. The following variables can be used in the\ntemplate:\n\n\n\n\n\n\n\n\nVariable Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nevent\n\n\nID of the event being published\n\n\n\n\n\n\nseries\n\n\nID of the series being published\n\n\n\n\n\n\n\n\nExample:\n\n\nhttps://www.externalURL.com/watch.html?series={series}&id={event}\n\n\n\nThe configuration key \nexternal-mime-type\n is used to set the mime type of the content return when accessing the\nURL of the publication element.\n\n\nThe configuration key 'external-channel' is used to set the name of the publication channel.\n\n\nOperation Example\n\n\n<operation\n    id=\"publish-oaipmh\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Publish event to the OAI-PMH repository\">\n    <configurations>\n        <configuration key=\"download-tags\">oaipmh-download</configuration>\n        <configuration key=\"streaming-tags\">oaipmh-streaming</configuration>\n        <configuration key=\"check-availability\">true</configuration>\n        <configuration key=\"repository\">default</configuration>\n    </configurations>\n</operation>",
            "title": "Publish OAI-PMH"
        },
        {
            "location": "/workflowoperationhandlers/publish-oaipmh-woh/#publishoaipmhworkflowoperation",
            "text": "",
            "title": "PublishOaiPmhWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/publish-oaipmh-woh/#description",
            "text": "The Publish OAI-PMH workflow operation exposes your media's metadata in a OAI-PMH repository for harvesting by OAI-PMH\naware applications.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/publish-oaipmh-woh/#parameter-table",
            "text": "Configuration Keys  Description      download-flavors  Distribute any mediapackage elements with one of these (comma separated) flavors to download    download-tags  Distribute any mediapackage elements with one of these (comma separated) tags to download    streaming-flavors  Distribute any mediapackage elements with one of these (comma separated) flavors to streaming    streaming-tags  Distribute any mediapackage elements with one of these (comma separated) tags to streaming    check-availability  Check if the distributed download artifact is available at its URL (default: true)    repository  The name of the OAI-PMH repository where the media should be published to    external-template  The optional URL template for URL the OAI-PMH publication element    external-channel  The optional channel name for the OAI-PMH publication element    external-mime-type  The optional mime type for the OAI-PMH publication element     Note: The all or none of the configuration keys  external-template ,  external-channel  and  external-mime-type  must to\nbe set.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/publish-oaipmh-woh/#customizing-the-oai-pmh-publication-element",
            "text": "If the configuration keys  external-template ,  external-channel  and  external-mime-type  are not set, the publication\nelement will use the following default values:     Field  Default Value      url  prop.org.opencastproject.oaipmh.server.hosturl + org.opencastproject.oaipmh.mountpoint + repository    mime type  \"text/xml\"    channel name  \"oaipmh-\" + repository     Note that  org.opencastproject.oaipmh.server.hosturl  is defined in etc/org.opencastproject.organization-mh_default_org.cfg  and  org.opencastproject.oaipmh.mountpoint  is defined in custom.properties  and defaults to  /oaipmh .  Example:  http://localhost:8080/oaipmh/default  The OAI-PMH publication element can be customized by setting the configuration keys  external-template , external-channel  and  external-mime-type .  The URL of the publication element can be set by using  external-template . The following variables can be used in the\ntemplate:     Variable Name  Description      event  ID of the event being published    series  ID of the series being published     Example:  https://www.externalURL.com/watch.html?series={series}&id={event}  The configuration key  external-mime-type  is used to set the mime type of the content return when accessing the\nURL of the publication element.  The configuration key 'external-channel' is used to set the name of the publication channel.",
            "title": "Customizing the OAI-PMH Publication Element"
        },
        {
            "location": "/workflowoperationhandlers/publish-oaipmh-woh/#operation-example",
            "text": "<operation\n    id=\"publish-oaipmh\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Publish event to the OAI-PMH repository\">\n    <configurations>\n        <configuration key=\"download-tags\">oaipmh-download</configuration>\n        <configuration key=\"streaming-tags\">oaipmh-streaming</configuration>\n        <configuration key=\"check-availability\">true</configuration>\n        <configuration key=\"repository\">default</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/publish-youtube-woh/",
            "text": "PublishYoutubeWorkflowOperation\n\n\nDescription\n\n\nThe PublishYoutubeWorkflowOperation publishes a single stream to YouTube.  This stream must meet YouTube's format\nrequirements, and may consist of audio and/or video.  If you want to publish both your presenter and presentation\nstreams we suggest using the \nComposite\n workflow operation handler to prepare a composite file\nwith both streams inside of it.  The default Opencast workflow prepares a video using this method.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\nThe flavors to publish to YouTube\n\n\n\n\n\n\nsource-tags\n\n\nThe tags to publish to YouTube\n\n\n\n\n\n\n\n\nOperation Example\n\n\n    <operation\n      id=\"publish-youtube\"\n      max-attempts=\"2\"\n      exception-handler-workflow=\"ng-partial-error\"\n      description=\"Publishing to YouTube\">\n      <configurations>\n        <configuration key=\"source-tags\">youtube</configuration>\n      </configurations>\n    </operation>",
            "title": "Publish YouTube"
        },
        {
            "location": "/workflowoperationhandlers/publish-youtube-woh/#publishyoutubeworkflowoperation",
            "text": "",
            "title": "PublishYoutubeWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/publish-youtube-woh/#description",
            "text": "The PublishYoutubeWorkflowOperation publishes a single stream to YouTube.  This stream must meet YouTube's format\nrequirements, and may consist of audio and/or video.  If you want to publish both your presenter and presentation\nstreams we suggest using the  Composite  workflow operation handler to prepare a composite file\nwith both streams inside of it.  The default Opencast workflow prepares a video using this method.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/publish-youtube-woh/#parameter-table",
            "text": "configuration keys  description      source-flavors  The flavors to publish to YouTube    source-tags  The tags to publish to YouTube",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/publish-youtube-woh/#operation-example",
            "text": "<operation\n      id=\"publish-youtube\"\n      max-attempts=\"2\"\n      exception-handler-workflow=\"ng-partial-error\"\n      description=\"Publishing to YouTube\">\n      <configurations>\n        <configuration key=\"source-tags\">youtube</configuration>\n      </configurations>\n    </operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/republish-oaipmh-woh/",
            "text": "RepublishOaiPmhWorkflowOperation\n\n\nDescription\n\n\nThe Republish OAI-PMH workflow operation will update metadata in your OAI-PMH repositories. In case that the media has\nnot been published before, this operation will skip. Otherwise all elements matching the flavors and tags will be replaced.\nIn case of missing elements in the media package, the published elements will be also removed.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Keys\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\nRepublish any media package elements with one of these (comma-separated) flavors\n\n\n\n\n\n\nsource-tags\n\n\nRepublish only media package elements that are tagged with one of these (comma-separated) tags\n\n\n\n\n\n\nrepository\n\n\nThe name of the OAI-PMH repository where the media should be updated\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"republish-oaipmh\"\n  description=\"Update recording metadata in default OAI-PMH repository\">\n  <configurations>\n    <configuration key=\"source-flavors\">dublincore/*,security/*</configuration>\n    <configuration key=\"repository\">default</configuration>\n  </configurations>\n</operation>",
            "title": "Republish OAI-PMH"
        },
        {
            "location": "/workflowoperationhandlers/republish-oaipmh-woh/#republishoaipmhworkflowoperation",
            "text": "",
            "title": "RepublishOaiPmhWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/republish-oaipmh-woh/#description",
            "text": "The Republish OAI-PMH workflow operation will update metadata in your OAI-PMH repositories. In case that the media has\nnot been published before, this operation will skip. Otherwise all elements matching the flavors and tags will be replaced.\nIn case of missing elements in the media package, the published elements will be also removed.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/republish-oaipmh-woh/#parameter-table",
            "text": "Configuration Keys  Description      source-flavors  Republish any media package elements with one of these (comma-separated) flavors    source-tags  Republish only media package elements that are tagged with one of these (comma-separated) tags    repository  The name of the OAI-PMH repository where the media should be updated",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/republish-oaipmh-woh/#operation-example",
            "text": "<operation\n  id=\"republish-oaipmh\"\n  description=\"Update recording metadata in default OAI-PMH repository\">\n  <configurations>\n    <configuration key=\"source-flavors\">dublincore/*,security/*</configuration>\n    <configuration key=\"repository\">default</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/retract-aws-woh/",
            "text": "RetractAWSWorkflowOperationHandler\n\n\nDescription\n\n\nThe RetractAWSWorkflowOperationHandler retracts the published elements from Amazon S3.\n\n\nThere are no configuration keys at this time.\n\n\nOperation Examples\n\n\nRetract\n\n\n<!-- Retract from AWS -->\n\n<operation\n  id=\"retract-aws\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Retract recording from AWS\">\n</operation>",
            "title": "Retract AWS S3 and Cloudfront"
        },
        {
            "location": "/workflowoperationhandlers/retract-aws-woh/#retractawsworkflowoperationhandler",
            "text": "",
            "title": "RetractAWSWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/retract-aws-woh/#description",
            "text": "The RetractAWSWorkflowOperationHandler retracts the published elements from Amazon S3.  There are no configuration keys at this time.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/retract-aws-woh/#operation-examples",
            "text": "",
            "title": "Operation Examples"
        },
        {
            "location": "/workflowoperationhandlers/retract-aws-woh/#retract",
            "text": "<!-- Retract from AWS -->\n\n<operation\n  id=\"retract-aws\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Retract recording from AWS\">\n</operation>",
            "title": "Retract"
        },
        {
            "location": "/workflowoperationhandlers/retract-engage-woh/",
            "text": "RetractEngageWorkflowOperationHandler\n\n\nDescription\n\n\nThe RetractEngageWorkflowOperationHandler retracts the published elements from the local Opencast Media Module.\n\n\nThere are no configuration keys at this time.\n\n\nOperation Examples\n\n\nRetract\n\n\n<!-- Retract from engage player -->\n\n<operation\n  id=\"retract-engage\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Retract recording from Engage\">\n</operation>",
            "title": "Retract Engage"
        },
        {
            "location": "/workflowoperationhandlers/retract-engage-woh/#retractengageworkflowoperationhandler",
            "text": "",
            "title": "RetractEngageWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/retract-engage-woh/#description",
            "text": "The RetractEngageWorkflowOperationHandler retracts the published elements from the local Opencast Media Module.  There are no configuration keys at this time.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/retract-engage-woh/#operation-examples",
            "text": "",
            "title": "Operation Examples"
        },
        {
            "location": "/workflowoperationhandlers/retract-engage-woh/#retract",
            "text": "<!-- Retract from engage player -->\n\n<operation\n  id=\"retract-engage\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Retract recording from Engage\">\n</operation>",
            "title": "Retract"
        },
        {
            "location": "/workflowoperationhandlers/retract-configure-woh/",
            "text": "ConfigurableRetractWorkflowOperationHandler\n\n\nDescription\n\n\nThe ConfigurableRetractWorkflowOperationHandler retracts the published elements from a configured publication.\n\n\nIf the elements have been added to the Publication using \"with-published-elements\", as in the case with the external\napi, they haven't actually been published so it is unnecessary to have a retract-configuration. Adding a retraction\nwon't cause any errors, it will just skip those elements.\n\n\nThere is only one configuration key \"channel-id\". This is the channel to remove the published elements from.\n\n\nOperation Examples\n\n\nRetract from Internal Channel\n\n\n<!-- Remove the internal publication if the mediapackage is being deleted. -->\n<operation\n  id=\"retract-configure\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Retract from internal publication channel\">\n  <configurations>\n    <configuration key=\"channel-id\">internal</configuration>\n  </configurations>\n</operation>\n\n\n\nRetract from External API\n\n\n<operation\n  id=\"retract-configure\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Retract from external api publication channel\">\n  <configurations>\n    <configuration key=\"channel-id\">api</configuration>\n  </configurations>\n</operation>",
            "title": "Retract Configure"
        },
        {
            "location": "/workflowoperationhandlers/retract-configure-woh/#configurableretractworkflowoperationhandler",
            "text": "",
            "title": "ConfigurableRetractWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/retract-configure-woh/#description",
            "text": "The ConfigurableRetractWorkflowOperationHandler retracts the published elements from a configured publication.  If the elements have been added to the Publication using \"with-published-elements\", as in the case with the external\napi, they haven't actually been published so it is unnecessary to have a retract-configuration. Adding a retraction\nwon't cause any errors, it will just skip those elements.  There is only one configuration key \"channel-id\". This is the channel to remove the published elements from.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/retract-configure-woh/#operation-examples",
            "text": "",
            "title": "Operation Examples"
        },
        {
            "location": "/workflowoperationhandlers/retract-configure-woh/#retract-from-internal-channel",
            "text": "<!-- Remove the internal publication if the mediapackage is being deleted. -->\n<operation\n  id=\"retract-configure\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Retract from internal publication channel\">\n  <configurations>\n    <configuration key=\"channel-id\">internal</configuration>\n  </configurations>\n</operation>",
            "title": "Retract from Internal Channel"
        },
        {
            "location": "/workflowoperationhandlers/retract-configure-woh/#retract-from-external-api",
            "text": "<operation\n  id=\"retract-configure\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Retract from external api publication channel\">\n  <configurations>\n    <configuration key=\"channel-id\">api</configuration>\n  </configurations>\n</operation>",
            "title": "Retract from External API"
        },
        {
            "location": "/workflowoperationhandlers/retract-oaipmh-woh/",
            "text": "RetractOaiPmhWorkflowOperation\n\n\nDescription\n\n\nThe Retract OAI-PMH workflow operation retracts the published elements from a OAI-PMH repository.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Keys\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nrepository\n\n\nThe name of the OAI-PMH repository where the media should be retracted from\n\n\n\n\n\n\n\n\nOperation Examples\n\n\n<operation\n    id=\"retract-oaipmh\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Retract event from the OAI-PMH repository\">\n    <configurations>\n        <configuration key=\"repository\">default</configuration>\n    </configurations>\n</operation>",
            "title": "Retract OAI-PMH"
        },
        {
            "location": "/workflowoperationhandlers/retract-oaipmh-woh/#retractoaipmhworkflowoperation",
            "text": "",
            "title": "RetractOaiPmhWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/retract-oaipmh-woh/#description",
            "text": "The Retract OAI-PMH workflow operation retracts the published elements from a OAI-PMH repository.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/retract-oaipmh-woh/#parameter-table",
            "text": "Configuration Keys  Description      repository  The name of the OAI-PMH repository where the media should be retracted from",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/retract-oaipmh-woh/#operation-examples",
            "text": "<operation\n    id=\"retract-oaipmh\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Retract event from the OAI-PMH repository\">\n    <configurations>\n        <configuration key=\"repository\">default</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Examples"
        },
        {
            "location": "/workflowoperationhandlers/retract-youtube-woh/",
            "text": "RetractYoutubeWorkflowOperation\n\n\nDescription\n\n\nThe RetractYoutubeWorkflowOperationHandler retracts the published elements from YouTube.\n\n\nThere are no configuration keys at this time.\n\n\nOperation Example\n\n\n    <operation\n      id=\"retract-youtube\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"ng-partial-error\"\n      description=\"Retract recording from YouTube\">\n    </operation>",
            "title": "Retract YouTube"
        },
        {
            "location": "/workflowoperationhandlers/retract-youtube-woh/#retractyoutubeworkflowoperation",
            "text": "",
            "title": "RetractYoutubeWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/retract-youtube-woh/#description",
            "text": "The RetractYoutubeWorkflowOperationHandler retracts the published elements from YouTube.  There are no configuration keys at this time.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/retract-youtube-woh/#operation-example",
            "text": "<operation\n      id=\"retract-youtube\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"ng-partial-error\"\n      description=\"Retract recording from YouTube\">\n    </operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/",
            "text": "SegmentpreviewsWorkflowOperation\n\n\nDescription\n\n\nThe SegmentpreviewsWorkflowOperation will extract still images from a video using FFmpeg, a given encoding profile and\nprevious discovered segments.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/source\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/work\n\n\nSpecifies the flavor the new files will get.\n\n\n\n\n\n\nsource-tags\n\n\nengage\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-tags\n\n\nengage\n\n\nSpecifies the tags the new files will get.\n\n\n\n\n\n\nencoding-profile\n\n\nsearch-cover.http\n\n\nThe encoding profile to use.\n\n\n\n\n\n\nreference-flavor\n\n\npresentation/work\n\n\nFlavor of the segments to use.\n\n\n\n\n\n\nreference-tags\n\n\nengage\n\n\nTags of the segments to use.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"segmentpreviews\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Encoding presentation (screen) to segment preview image\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-flavor\">presentation/segment+preview</configuration>\n            <configuration key=\"reference-flavor\">presentation/delivery</configuration>\n            <configuration key=\"reference-tags\">engage</configuration>\n            <configuration key=\"target-tags\">engage</configuration>\n            <configuration key=\"encoding-profile\">player-slides.http</configuration>\n      </configurations>\n</operation>",
            "title": "Segment Previews"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/#segmentpreviewsworkflowoperation",
            "text": "",
            "title": "SegmentpreviewsWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/#description",
            "text": "The SegmentpreviewsWorkflowOperation will extract still images from a video using FFmpeg, a given encoding profile and\nprevious discovered segments.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/source  Specifies which media should be processed.    target-flavor  presenter/work  Specifies the flavor the new files will get.    source-tags  engage  Specifies which media should be processed.    target-tags  engage  Specifies the tags the new files will get.    encoding-profile  search-cover.http  The encoding profile to use.    reference-flavor  presentation/work  Flavor of the segments to use.    reference-tags  engage  Tags of the segments to use.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/#operation-example",
            "text": "<operation\n      id=\"segmentpreviews\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Encoding presentation (screen) to segment preview image\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-flavor\">presentation/segment+preview</configuration>\n            <configuration key=\"reference-flavor\">presentation/delivery</configuration>\n            <configuration key=\"reference-tags\">engage</configuration>\n            <configuration key=\"target-tags\">engage</configuration>\n            <configuration key=\"encoding-profile\">player-slides.http</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/",
            "text": "SegmentVideoWorkflowOperation\n\n\nDescription\n\n\nThe SegmentVideoWorkflowOperation will try to identify and mark different segments of a video. A new segment is created\nwhen a major change in the video occurs. This might be the case for example if the video is a screenrecording and the\nslides which were shown change.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresentation/trimmed\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"segment-video\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Extracting segments from presentation\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n      </configurations>\n</operation>",
            "title": "Segment Video"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/#segmentvideoworkflowoperation",
            "text": "",
            "title": "SegmentVideoWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/#description",
            "text": "The SegmentVideoWorkflowOperation will try to identify and mark different segments of a video. A new segment is created\nwhen a major change in the video occurs. This might be the case for example if the video is a screenrecording and the\nslides which were shown change.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presentation/trimmed  Specifies which media should be processed.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/#operation-example",
            "text": "<operation\n      id=\"segment-video\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Extracting segments from presentation\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/select-streams-woh/",
            "text": "SelectStreamsWorkflowOperationHandler\n\n\nDescription\n\n\nThe SelectStreamsWorkflowOperationHandler can be used in case not all source streams should be processed. For example,\ngiven a recording with a presenter and a presentation track, the final recording to be published should only include the\nvideo stream of the presenter track and the audio stream of the presentation track.\n\n\nThe workflow operation will use workflow properties set by the Opencast video editor to determine which streams should be\nselected for further processing and add them to the media package based on \ntarget-flavor\n and \ntarget-tags\n.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor*\n\n\n*/source\n\n\nThe flavor of the track(s) to use as a source input\n\n\n\n\n\n\ntarget-flavor*\n\n\n*/work\n\n\nThe flavor of the target track(s)\n\n\n\n\n\n\ntarget-tags\n\n\ndownload\n\n\nThe tags applied to all target tracks\n\n\n\n\n\n\naudio-muxing\n\n\nforce\n\n\nMove single-audio media packages to a specific track (see below)\n\n\n\n\n\n\nforce-target\n\n\npresenter\n\n\nTarget track for the \nforce\n setting for \naudio-muxing\n\n\n\n\n\n\n\n\n* mandatory configuration key\n\n\nAudio Muxing\n\n\nThe optional \naudio-muxing\n parameter has three possible values: \nnone\n (same as omitting the option), \nforce\n and\n\nduplicate\n.\n\n\nnone\n\n\nIf \nnone\n is specified or the option is omitted, the audio stream is taken from the specified \nsource-flavor\n track and is\nedited according to the selections in video editor\u2019s \u201cTracks\u201d panel. The resulting tracks are stored in the\ncorresponding \ntarget-flavor\n and \ntarget-tags\n are applied.\n\n\nNote: If your editing results in a single video and single audio (track/stream) they will be muxed together even if\nthis option is set to \nnone\n.\n\n\nforce\n\n\nThe parameter value \nforce\n only applies to media packages that have exactly one non-hidden audio stream. For media\npackages without an audio stream or with more than one audio stream, the behavior is the same as if the parameter were\nomitted. The same applies to media packages for which there is only one audio stream, and it already belongs to the\ntrack with flavor type given by \nforce-target\n (or \npresenter\n if that parameter is omitted).\n\n\nIf, however, there is only one non-hidden audio stream and it does \nnot\n belong to the track given by \nforce-target\n,\nthen the WOH will \u201cmove\u201d the audio stream to this target track. Specifically, it will mux the video stream of\n\nforce-target\n with the audio stream it found. Then, it removes the audio stream from the original track.\n\n\nFor example, consider a media package with two tracks, \npresenter\n and \npresentation\n. Both of these tracks have\naudio components, however the \npresenter\n audio stream is hidden. This WOH will mux \npresentations\n's audio stream\nwith \npresenter\n's video, and remove the audio track from \npresentation\n's video.\n\n\nduplicate\n\n\nThe parameter value \nduplicate\n only applies to media packages that have exactly one non-hidden audio stream and no\nhidden video streams. For these media packages, the WOH will mux the audio stream it found to all video streams in\nthe media package. For media packages without an audio stream or with more than one audio stream, the behavior is\nthe same as if the parameter were omitted.\n\n\nOperation Example\n\n\n<operation\n  id=\"select-tracks\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Select tracks for further processing\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/source</configuration>\n    <configuration key=\"target-flavor\">*/work</configuration>\n    <configuration key=\"audio-muxing\">force</configuration>\n  </configurations>\n</operation>",
            "title": "Select Streams"
        },
        {
            "location": "/workflowoperationhandlers/select-streams-woh/#selectstreamsworkflowoperationhandler",
            "text": "",
            "title": "SelectStreamsWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/select-streams-woh/#description",
            "text": "The SelectStreamsWorkflowOperationHandler can be used in case not all source streams should be processed. For example,\ngiven a recording with a presenter and a presentation track, the final recording to be published should only include the\nvideo stream of the presenter track and the audio stream of the presentation track.  The workflow operation will use workflow properties set by the Opencast video editor to determine which streams should be\nselected for further processing and add them to the media package based on  target-flavor  and  target-tags .",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/select-streams-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      source-flavor*  */source  The flavor of the track(s) to use as a source input    target-flavor*  */work  The flavor of the target track(s)    target-tags  download  The tags applied to all target tracks    audio-muxing  force  Move single-audio media packages to a specific track (see below)    force-target  presenter  Target track for the  force  setting for  audio-muxing     * mandatory configuration key",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/select-streams-woh/#audio-muxing",
            "text": "The optional  audio-muxing  parameter has three possible values:  none  (same as omitting the option),  force  and duplicate .",
            "title": "Audio Muxing"
        },
        {
            "location": "/workflowoperationhandlers/select-streams-woh/#none",
            "text": "If  none  is specified or the option is omitted, the audio stream is taken from the specified  source-flavor  track and is\nedited according to the selections in video editor\u2019s \u201cTracks\u201d panel. The resulting tracks are stored in the\ncorresponding  target-flavor  and  target-tags  are applied.  Note: If your editing results in a single video and single audio (track/stream) they will be muxed together even if\nthis option is set to  none .",
            "title": "none"
        },
        {
            "location": "/workflowoperationhandlers/select-streams-woh/#force",
            "text": "The parameter value  force  only applies to media packages that have exactly one non-hidden audio stream. For media\npackages without an audio stream or with more than one audio stream, the behavior is the same as if the parameter were\nomitted. The same applies to media packages for which there is only one audio stream, and it already belongs to the\ntrack with flavor type given by  force-target  (or  presenter  if that parameter is omitted).  If, however, there is only one non-hidden audio stream and it does  not  belong to the track given by  force-target ,\nthen the WOH will \u201cmove\u201d the audio stream to this target track. Specifically, it will mux the video stream of force-target  with the audio stream it found. Then, it removes the audio stream from the original track.  For example, consider a media package with two tracks,  presenter  and  presentation . Both of these tracks have\naudio components, however the  presenter  audio stream is hidden. This WOH will mux  presentations 's audio stream\nwith  presenter 's video, and remove the audio track from  presentation 's video.",
            "title": "force"
        },
        {
            "location": "/workflowoperationhandlers/select-streams-woh/#duplicate",
            "text": "The parameter value  duplicate  only applies to media packages that have exactly one non-hidden audio stream and no\nhidden video streams. For these media packages, the WOH will mux the audio stream it found to all video streams in\nthe media package. For media packages without an audio stream or with more than one audio stream, the behavior is\nthe same as if the parameter were omitted.",
            "title": "duplicate"
        },
        {
            "location": "/workflowoperationhandlers/select-streams-woh/#operation-example",
            "text": "<operation\n  id=\"select-tracks\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Select tracks for further processing\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/source</configuration>\n    <configuration key=\"target-flavor\">*/work</configuration>\n    <configuration key=\"audio-muxing\">force</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/",
            "text": "EmailWorkflowOperation\n\n\nDescription\n\n\nThe EmailWorkflowOperationHandler invokes the SMTP Service to send an email with the parameters provided. It is useful\nto send email notifications when some operation(s) have been completed or some error(s) have occurred in a workflow.\n\n\nThe email body, if not specified by body or body-template-file, will consist of a single line of the form:\n\n<Recording Title> (<Mediapackage ID>)\n.\n\n\nFreemarker templates can be used in the following fields to allow replacement with values obtained from the workflow or\nmedia package: to, cc, bcc, subject, and body. If body-template-file is specified, the operation will use a Freemarker template\nfile located in \n<config_dir>/etc/email\n to generate the email body.\n\n\nUser names can be provided in \nto\n, \ncc\n, or \nbcc\n in lieu of email addresses so that the user directory is searched\nand that user's email address is used (see Example 5).\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\ndescription\n\n\ndefault value\n\n\nexample\n\n\n\n\n\n\n\n\n\n\nbody\n\n\nEmail body content.\nTakes precedence over body-template-file.\n\n\n<Recording Title> (<Mediapackage ID>)\n\n\nLecture 1 (4bf316fc-ea78-4903-b00e-9976b0912e4d)\n\n\n\n\n\n\nbody-template-file\n\n\nName of file that will be used as a template for the content of the email body.\n\n\nEMPTY\n\n\ntemplateName\n\n\n\n\n\n\nsubject\n\n\nEmail subject.\n\n\nEMPTY\n\n\nOperation has been completed\n\n\n\n\n\n\nto\n\n\nThe field \nto\n of the email\ni.e. the comma separated list of email accounts the email will be sent to.\n\n\nEMPTY\n\n\nemail-account@email-domain.org,second-account@second-domain.org\n\n\n\n\n\n\ncc\n\n\nThe field \ncc\n of the email\ni.e. the comma separated list of email accounts that will receive a carbon copy of the email.\n\n\nEMPTY\n\n\nemail-account@email-domain.org,second-account@second-domain.org\n\n\n\n\n\n\nbcc\n\n\nThe field \nbcc\n of the email\ni.e. the comma separated list of email accounts that will receive a blind carbon copy of the email.\n\n\nEMPTY\n\n\nemail-account@email-domain.org,second-account@second-domain.org\n\n\n\n\n\n\nuse-html\n\n\nFlag to indicate that the email content should be displayed as 'text/html'\n\n\nfalse\n\n\ntrue/false\n\n\n\n\n\n\n\n\nSome other email parameters can be customized in the SMTP Service configuration\n\n\nVariable Substitution\n\n\nThe template will have access to the media package, workflow instance (including its configuration properties and last\nfailed operation), catalogs, and any incidents. Fields should be tested for null/empty values before being used.\n\n\nMedia Package Information\n\n\nUse \n${mediaPackage.FIELD}\n\n\nExamples\n\n\n\n\n\n\n\n\nField\n\n\nHow To Get It\n\n\n\n\n\n\n\n\n\n\nmedia package id\n\n\n${mediaPackage.identifier}\n\n\n\n\n\n\nrecording title\n\n\n${mediaPackage.title}\n\n\n\n\n\n\nrecording date and time\n\n\n${mediaPackage.date?datetime?iso_utc} - See Freemarker manual for date manipulation \n(extract date only, time only, format, etc)\n\n\n\n\n\n\nseries title\n\n\n${mediaPackage.seriesTitle}\n\n\n\n\n\n\nseries id\n\n\n${mediaPackage.series}\n\n\n\n\n\n\n\n\nWorkflow Information\n\n\nUse \n${workflow.FIELD}\n\n\nExamples\n\n\n\n\n\n\n\n\nField\n\n\nHow To Get It\n\n\n\n\n\n\n\n\n\n\nworkflow id\n\n\n${workflow.id}\n\n\n\n\n\n\nworkflow name\n\n\n${workflow.template}\n\n\n\n\n\n\n\n\nWorkflow Configuration Properties\n\n\nUse \n${workflowConfig['PROPERTY']}\n\n\nLast Failed Operation\n\n\nOperation that caused the workflow to fail. Should be tested before accessing any of its fields:\n\n\n<#if failedOperation?has_content>Workflow failed in operation: ${failedOperation.template}</#if>\n\n\n\nIncidents\n\n\nIn your email template:\n\n\n<#if incident?has_content>\n  <#list incident as inc>\n    <#list inc.details as dets>${dets.b}</#list>\n  </#list>\n</#if>\n\n\n\n\nCatalog fields\n\n\nUse \n${catalogs['SUBTYPE']['FIELD']}\n\n\nExamples\n\n\n\n\n\n\n\n\nField\n\n\nHow To Get It\n\n\n\n\n\n\n\n\n\n\nepisode creator\n\n\n${catalogs['episode']['creator']}\n\n\n\n\n\n\nepisode title\n\n\n${catalogs['episode']['title']}\n\n\n\n\n\n\nseries creator\n\n\n${catalogs['series']['creator']}\n\n\n\n\n\n\nseries title\n\n\n${catalogs['series']['title']}\n\n\n\n\n\n\n\n\nExamples\n\n\nExample 1\n\n\nMedia package title in subject field, default email body.\n\n\n<operation\n  id=\"send-email\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"email-error\"\n  description=\"Sending email to user after media package is published\">\n  <configurations>\n    <configuration key=\"to\">email-account@email-domain.org</configuration>\n    <!-- This is going to be replaced with the media package title -->\n    <configuration key=\"subject\">${mediaPackage.title} has been published</configuration>\n    <!-- Neither body or body-template-file specified so default body <Recording Title> (<Mediapackage ID>)<br>is sent -->\n  </configurations>\n</operation>\n\n\n\n\nExample 2\n\n\nTo and subject are inline templates; the email body uses a template file named sample stored in\n\u2026/etc/email\n:\n\n\n<operation\n  id=\"send-email\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"email-error\"\n  description=\"Sending email to user before holding for edit\">\n  <configurations>\n    <!-- This is going to be replaced with the episode catalog publisher field, which in this example it is assumed\n    it contains a notification email address -->\n    <configuration key=\"to\">${catalogs['episode']['publisher']}</configuration>\n    <!-- This is going to be replaced with the episode catalog title field -->\n    <configuration key=\"subject\">${catalogs['episode']['title']} is ready for EDIT</configuration>\n    <!-- Email body is going to be built using the sample template found in <config_dir>/etc/email -->\n    <configuration key=\"body-template-file\">sample</configuration>\n  </configurations>\n</operation>\n\n\n\n\nTemplate: sample\n\n\nThe contents of the \n\u2026/etc/email/sample\n email template:\n\n\nEvent Details\n<#if catalogs['series']?has_content>\nSeries Title: ${catalogs['series']['title']}\nInstructor: ${catalogs['series']['contributor']}\n</#if>\nMedia Package Id: ${mediaPackage.identifier}\nTitle: ${mediaPackage.title}\nWorkflow Id: ${workflow.id}\nEvent Date: ${mediaPackage.date?datetime?iso_local}\n\n\n\n\nExample 3\n\n\nEmail address entered via admin UI as a workflow configuration parameter:\n\n\n<operation\n  id=\"send-email\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"email-error\"\n  description=\"Sends email\">\n  <configurations>\n    <configuration key=\"to\">${workflowConfig['emailAddress']}</configuration>\n    <configuration key=\"subject\">Media package has been published</configuration>\n    <configuration key=\"body-template-file\">sample</configuration>\n  </configurations>\n</operation>\n\n\n\n\nWorkflow Configuration Panel:\n\n\n<configuration_panel>\n<![CDATA[\n   <!-- Add after the other configuration fields (Holds, Archive, etc) -->\n   <fieldset>\n      <legend>Notification</legend>\n      <ul class=\"oc-ui-form-list\">\n        <li class=\"ui-helper-clearfix\">\n          <label class=\"scheduler-label\">\n            <span class=\"color-red\">* </span><span id=\"i18n_email_label\">Email Address</span>:\n          </label>\n          <span id=\"emailconfig\">\n            <input id=\"emailAddress\" name=\"emailAddress\" type=\"text\" class=\"configField\"\n                   value=\"my-email-account@my-email-domain.org\"/>\n          </span>\n        </li>\n      </ul>\n    </fieldset>\n\n    <script type=\"text/javascript\">\n\n      // Add email variable\n      var emailAddress = $('input#emailAddress');\n\n      // Register email configuration property\n      ocWorkflowPanel.registerComponents = function(components){\n        /* components with keys that begin with 'org.opencastproject.workflow.config' will be passed\n         * into the workflow. The component's nodeKey must match the components array key.\n         *\n         * Example:'org.opencastproject.workflow.config.myProperty' will be availible at ${my.property}\n         */\n        // After the other components (Hold, Archive, etc), add:\n        components['org.opencastproject.workflow.config.emailAddress'] = new ocAdmin.Component(\n          ['emailAddress'],\n          {key: 'org.opencastproject.workflow.config.emailAddress'},\n          {getValue: function(){ return this.fields.emailAddress.value;}\n          });\n\n          //etc...\n      }\n      ocWorkflowPanel.setComponentValues = function(values, components){\n        // After the other components (Hold, Archive, etc), add:\n        components['org.opencastproject.workflow.config.emailAddress'].setValue(\n          values['org.opencastproject.workflow.config.emailAddress']);\n      }\n    </script>\n]]>\n</configuration_panel>\n\n\n\n\nExample 4\n\n\nIn error handling workflow (email-error):\n\n\n<operation\n  id=\"send-email\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Sends email\">\n    <configurations>\n    <!-- Note that you can use variable substitution in to, subject, body\n         e.g. ${(catalogs['episode']['FIELD']!'root@localhost'}  -->\n    <configuration key=\"to\">root@localhost</configuration>\n    <configuration key=\"subject\">Failure processing a mediapackage</configuration>\n    <configuration key=\"body-template-file\">errorDetails</configuration>\n  </configurations>\n</operation>\n\n\n\n\nTemplate: errorDetails\n\n\nThe contents of the \n/etc/email/errorDetails email template:\n\n\nError Details\n\n<#if catalogs['series']?has_content>\nCourse: ${catalogs['series']['subject']!'series subject missing'}-${catalogs['series']['title']!'series title missing'}\nInstructor: ${catalogs['series']['contributor']!'instructor missing'}\n</#if>\nTitle: ${catalogs['episode']['title']!'title missing'}\nEvent Date: ${mediaPackage.date?datetime?iso_local}\n\n<#if failedOperation?has_content>\n  Workflow failed in operation: ${failedOperation.position}-${failedOperation.template}\n  Started: ${failedOperation.dateStarted?datetime?iso_local}\n  Ended: ${failedOperation.dateCompleted?datetime?iso_local}\n  Execution Host: ${failedOperation.executionHost}\n</#if>\n\nLogged incident of the error looks like this:\n\n<#if incident?has_content>\n  <#list incident as inc>\n    <#list inc.details as dets>${dets.b} </#list>\n  </#list>\n</#if>\n\n\n\n\nExample 5\n\n\nThe user name is stored in the episode dublin core \ncontributor\n field. There's a user \njharvard\n with email\n\njharvard@harvard.edu\n defined in the system. The message will be sent to \njharvard@harvard.edu\n:\n\n\n   <operation\n      id=\"send-email\"\n      fail-on-error=\"false\"\n      description=\"Notify user associated to this recording that it is ready to be trimmed\">\n      <configurations>\n        <configuration key=\"to\">${(catalogs['episode']['contributor'])}</configuration>\n        <configuration key=\"subject\">Recording is ready for EDIT</configuration>\n        <configuration key=\"body-template-file\">eventDetails</configuration>\n      </configurations>\n    </operation>\n\n\n\n\nEpisode Dublin Core\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<dublincore xmlns=\"http://www.opencastproject.org/xsd/1.0/dublincore/\"\n    xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n    <dcterms:contributor>jharvard</dcterms:contributor>\n    <dcterms:created>2018-05-01T16:14:00Z</dcterms:created>\n    <dcterms:extent xsi:type=\"dcterms:ISO8601\">PT17M1.933S</dcterms:extent>\n    <dcterms:isPartOf>20180229999</dcterms:isPartOf>\n    <dcterms:spatial>classroom-20</dcterms:spatial>\n    <dcterms:temporal>start=2018-05-01T16:14:00Z; end=2018-05-01T16:31:00Z;\n        scheme=W3C-DTF;</dcterms:temporal>\n    <dcterms:title>Test Lecture</dcterms:title>\n</dublincore>",
            "title": "Send Email"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#emailworkflowoperation",
            "text": "",
            "title": "EmailWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#description",
            "text": "The EmailWorkflowOperationHandler invokes the SMTP Service to send an email with the parameters provided. It is useful\nto send email notifications when some operation(s) have been completed or some error(s) have occurred in a workflow.  The email body, if not specified by body or body-template-file, will consist of a single line of the form: <Recording Title> (<Mediapackage ID>) .  Freemarker templates can be used in the following fields to allow replacement with values obtained from the workflow or\nmedia package: to, cc, bcc, subject, and body. If body-template-file is specified, the operation will use a Freemarker template\nfile located in  <config_dir>/etc/email  to generate the email body.  User names can be provided in  to ,  cc , or  bcc  in lieu of email addresses so that the user directory is searched\nand that user's email address is used (see Example 5).",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#parameter-table",
            "text": "configuration keys  description  default value  example      body  Email body content. Takes precedence over body-template-file.  <Recording Title> (<Mediapackage ID>)  Lecture 1 (4bf316fc-ea78-4903-b00e-9976b0912e4d)    body-template-file  Name of file that will be used as a template for the content of the email body.  EMPTY  templateName    subject  Email subject.  EMPTY  Operation has been completed    to  The field  to  of the email i.e. the comma separated list of email accounts the email will be sent to.  EMPTY  email-account@email-domain.org,second-account@second-domain.org    cc  The field  cc  of the email i.e. the comma separated list of email accounts that will receive a carbon copy of the email.  EMPTY  email-account@email-domain.org,second-account@second-domain.org    bcc  The field  bcc  of the email i.e. the comma separated list of email accounts that will receive a blind carbon copy of the email.  EMPTY  email-account@email-domain.org,second-account@second-domain.org    use-html  Flag to indicate that the email content should be displayed as 'text/html'  false  true/false     Some other email parameters can be customized in the SMTP Service configuration",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#variable-substitution",
            "text": "The template will have access to the media package, workflow instance (including its configuration properties and last\nfailed operation), catalogs, and any incidents. Fields should be tested for null/empty values before being used.",
            "title": "Variable Substitution"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#media-package-information",
            "text": "Use  ${mediaPackage.FIELD}",
            "title": "Media Package Information"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#examples",
            "text": "Field  How To Get It      media package id  ${mediaPackage.identifier}    recording title  ${mediaPackage.title}    recording date and time  ${mediaPackage.date?datetime?iso_utc} - See Freemarker manual for date manipulation  (extract date only, time only, format, etc)    series title  ${mediaPackage.seriesTitle}    series id  ${mediaPackage.series}",
            "title": "Examples"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#workflow-information",
            "text": "Use  ${workflow.FIELD}",
            "title": "Workflow Information"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#examples_1",
            "text": "Field  How To Get It      workflow id  ${workflow.id}    workflow name  ${workflow.template}",
            "title": "Examples"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#workflow-configuration-properties",
            "text": "Use  ${workflowConfig['PROPERTY']}",
            "title": "Workflow Configuration Properties"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#last-failed-operation",
            "text": "Operation that caused the workflow to fail. Should be tested before accessing any of its fields:  <#if failedOperation?has_content>Workflow failed in operation: ${failedOperation.template}</#if>",
            "title": "Last Failed Operation"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#incidents",
            "text": "In your email template:  <#if incident?has_content>\n  <#list incident as inc>\n    <#list inc.details as dets>${dets.b}</#list>\n  </#list>\n</#if>",
            "title": "Incidents"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#catalog-fields",
            "text": "Use  ${catalogs['SUBTYPE']['FIELD']}",
            "title": "Catalog fields"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#examples_2",
            "text": "Field  How To Get It      episode creator  ${catalogs['episode']['creator']}    episode title  ${catalogs['episode']['title']}    series creator  ${catalogs['series']['creator']}    series title  ${catalogs['series']['title']}",
            "title": "Examples"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#examples_3",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#example-1",
            "text": "Media package title in subject field, default email body.  <operation\n  id=\"send-email\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"email-error\"\n  description=\"Sending email to user after media package is published\">\n  <configurations>\n    <configuration key=\"to\">email-account@email-domain.org</configuration>\n    <!-- This is going to be replaced with the media package title -->\n    <configuration key=\"subject\">${mediaPackage.title} has been published</configuration>\n    <!-- Neither body or body-template-file specified so default body <Recording Title> (<Mediapackage ID>)<br>is sent -->\n  </configurations>\n</operation>",
            "title": "Example 1"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#example-2",
            "text": "To and subject are inline templates; the email body uses a template file named sample stored in \u2026/etc/email :  <operation\n  id=\"send-email\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"email-error\"\n  description=\"Sending email to user before holding for edit\">\n  <configurations>\n    <!-- This is going to be replaced with the episode catalog publisher field, which in this example it is assumed\n    it contains a notification email address -->\n    <configuration key=\"to\">${catalogs['episode']['publisher']}</configuration>\n    <!-- This is going to be replaced with the episode catalog title field -->\n    <configuration key=\"subject\">${catalogs['episode']['title']} is ready for EDIT</configuration>\n    <!-- Email body is going to be built using the sample template found in <config_dir>/etc/email -->\n    <configuration key=\"body-template-file\">sample</configuration>\n  </configurations>\n</operation>",
            "title": "Example 2"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#template-sample",
            "text": "The contents of the  \u2026/etc/email/sample  email template:  Event Details\n<#if catalogs['series']?has_content>\nSeries Title: ${catalogs['series']['title']}\nInstructor: ${catalogs['series']['contributor']}\n</#if>\nMedia Package Id: ${mediaPackage.identifier}\nTitle: ${mediaPackage.title}\nWorkflow Id: ${workflow.id}\nEvent Date: ${mediaPackage.date?datetime?iso_local}",
            "title": "Template: sample"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#example-3",
            "text": "Email address entered via admin UI as a workflow configuration parameter:  <operation\n  id=\"send-email\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"email-error\"\n  description=\"Sends email\">\n  <configurations>\n    <configuration key=\"to\">${workflowConfig['emailAddress']}</configuration>\n    <configuration key=\"subject\">Media package has been published</configuration>\n    <configuration key=\"body-template-file\">sample</configuration>\n  </configurations>\n</operation>  Workflow Configuration Panel:  <configuration_panel>\n<![CDATA[\n   <!-- Add after the other configuration fields (Holds, Archive, etc) -->\n   <fieldset>\n      <legend>Notification</legend>\n      <ul class=\"oc-ui-form-list\">\n        <li class=\"ui-helper-clearfix\">\n          <label class=\"scheduler-label\">\n            <span class=\"color-red\">* </span><span id=\"i18n_email_label\">Email Address</span>:\n          </label>\n          <span id=\"emailconfig\">\n            <input id=\"emailAddress\" name=\"emailAddress\" type=\"text\" class=\"configField\"\n                   value=\"my-email-account@my-email-domain.org\"/>\n          </span>\n        </li>\n      </ul>\n    </fieldset>\n\n    <script type=\"text/javascript\">\n\n      // Add email variable\n      var emailAddress = $('input#emailAddress');\n\n      // Register email configuration property\n      ocWorkflowPanel.registerComponents = function(components){\n        /* components with keys that begin with 'org.opencastproject.workflow.config' will be passed\n         * into the workflow. The component's nodeKey must match the components array key.\n         *\n         * Example:'org.opencastproject.workflow.config.myProperty' will be availible at ${my.property}\n         */\n        // After the other components (Hold, Archive, etc), add:\n        components['org.opencastproject.workflow.config.emailAddress'] = new ocAdmin.Component(\n          ['emailAddress'],\n          {key: 'org.opencastproject.workflow.config.emailAddress'},\n          {getValue: function(){ return this.fields.emailAddress.value;}\n          });\n\n          //etc...\n      }\n      ocWorkflowPanel.setComponentValues = function(values, components){\n        // After the other components (Hold, Archive, etc), add:\n        components['org.opencastproject.workflow.config.emailAddress'].setValue(\n          values['org.opencastproject.workflow.config.emailAddress']);\n      }\n    </script>\n]]>\n</configuration_panel>",
            "title": "Example 3"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#example-4",
            "text": "In error handling workflow (email-error):  <operation\n  id=\"send-email\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Sends email\">\n    <configurations>\n    <!-- Note that you can use variable substitution in to, subject, body\n         e.g. ${(catalogs['episode']['FIELD']!'root@localhost'}  -->\n    <configuration key=\"to\">root@localhost</configuration>\n    <configuration key=\"subject\">Failure processing a mediapackage</configuration>\n    <configuration key=\"body-template-file\">errorDetails</configuration>\n  </configurations>\n</operation>",
            "title": "Example 4"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#template-errordetails",
            "text": "The contents of the  /etc/email/errorDetails email template:  Error Details\n\n<#if catalogs['series']?has_content>\nCourse: ${catalogs['series']['subject']!'series subject missing'}-${catalogs['series']['title']!'series title missing'}\nInstructor: ${catalogs['series']['contributor']!'instructor missing'}\n</#if>\nTitle: ${catalogs['episode']['title']!'title missing'}\nEvent Date: ${mediaPackage.date?datetime?iso_local}\n\n<#if failedOperation?has_content>\n  Workflow failed in operation: ${failedOperation.position}-${failedOperation.template}\n  Started: ${failedOperation.dateStarted?datetime?iso_local}\n  Ended: ${failedOperation.dateCompleted?datetime?iso_local}\n  Execution Host: ${failedOperation.executionHost}\n</#if>\n\nLogged incident of the error looks like this:\n\n<#if incident?has_content>\n  <#list incident as inc>\n    <#list inc.details as dets>${dets.b} </#list>\n  </#list>\n</#if>",
            "title": "Template: errorDetails"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#example-5",
            "text": "The user name is stored in the episode dublin core  contributor  field. There's a user  jharvard  with email jharvard@harvard.edu  defined in the system. The message will be sent to  jharvard@harvard.edu :     <operation\n      id=\"send-email\"\n      fail-on-error=\"false\"\n      description=\"Notify user associated to this recording that it is ready to be trimmed\">\n      <configurations>\n        <configuration key=\"to\">${(catalogs['episode']['contributor'])}</configuration>\n        <configuration key=\"subject\">Recording is ready for EDIT</configuration>\n        <configuration key=\"body-template-file\">eventDetails</configuration>\n      </configurations>\n    </operation>",
            "title": "Example 5"
        },
        {
            "location": "/workflowoperationhandlers/send-email-woh/#episode-dublin-core",
            "text": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<dublincore xmlns=\"http://www.opencastproject.org/xsd/1.0/dublincore/\"\n    xmlns:dcterms=\"http://purl.org/dc/terms/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n    <dcterms:contributor>jharvard</dcterms:contributor>\n    <dcterms:created>2018-05-01T16:14:00Z</dcterms:created>\n    <dcterms:extent xsi:type=\"dcterms:ISO8601\">PT17M1.933S</dcterms:extent>\n    <dcterms:isPartOf>20180229999</dcterms:isPartOf>\n    <dcterms:spatial>classroom-20</dcterms:spatial>\n    <dcterms:temporal>start=2018-05-01T16:14:00Z; end=2018-05-01T16:31:00Z;\n        scheme=W3C-DTF;</dcterms:temporal>\n    <dcterms:title>Test Lecture</dcterms:title>\n</dublincore>",
            "title": "Episode Dublin Core"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/",
            "text": "SeriesWorkflowOperationHandler\n\n\nDescription\n\n\nThe SeriesWorkflowOperation will apply a series to the mediapackage.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nseries\n\n\n0d06537e-09d3-420c-8314-a21e45c5d032\n\n\nThe optional series identifier. If empty the current series of the medipackage will be taken.\n\n\n\n\n\n\n\n\nattach\n\n\ncreativecommons/*,dublincore/*\n\n\nThe flavors of the series catalogs to attach to the mediapackage.\n\n\n\n\n\n\n\n\napply-acl\n\n\ntrue\n\n\nWhether the ACL should be applied or not.\n\n\nfalse\n\n\n\n\n\n\ncopy-metadata\n\n\n{http://purl.org/dc/terms/}title, isPartOf\n\n\nA comma-separated list of metadata fields (possibly \"expanded\") to be transferred from the series catalog to the episode catalog if they do not exist in the latter.\n\n\n\n\n\n\n\n\ndefault-namespace\n\n\nhttp://purl.org/dc/elements/1.1/\n\n\nThe default namespace to use when the metadata fields in the \ncopy-metadata\n property are not fully \"expanded\".\n\n\nhttp://purl.org/dc/terms/\n (DublinCore Term namespace)\n\n\n\n\n\n\n\n\nAbout Expanded Names\n\n\nExpanded names are qualified XML terms where the prefix has been expanded to the full namespace it represents. For\nconvention, they are written as:\n\n\n{namespace}localname\n\n\n\n\u2026 where \nnamespace\n is the full namespace (not a prefix like in XML documents) and \nlocalname\n is the term itself.\n\n\nSome examples of expanded names are:\n\n\n\n\n{http://purl.org/dc/terms/}title\n\n\n{http://mediapackage.opencastproject.org}mediapackage\n\n\n{}term-with-an-empty-namespace\n\n\n\n\nThe value of the \ncopy-metadata\n may contain expanded and non-expanded names. In the latter case, the names will be\nexpanded using the provided namespace, if any, or the DublinCore namespace by default.\n\n\nPlease note that:\n\n\n\n\nAn empty namespace (such as in \n{}example\n) is still a namespace. That means that the default namespace will not be\n   substituted in this case and the term will be handled \"as-is\", i.e. with an empty namespace.\n\n\nMost of the terms used by Opencast belong to the DublinCore namespace, so using non-expanded names and the default\n   namespace should be sufficient. However, custom metadata fields may be in a different namespace which must be\n   explicitly specified.\n\n\n\n\nAllowed Namespaces\n\n\nFor technical reasons, namespaces need to be pre-registered in Opencast to be used. That is why only a defined set of\nnamespaces can be used in this operation. The allowed namespaces are:\n\n\n\n\nDublinCore Terms: \nhttp://purl.org/dc/terms/\n\n\nDublinCore Elements 1.1: \nhttp://purl.org/dc/elements/1.1/\n\n\nOpencast Properties: \nhttp://www.opencastproject.org/\n\n\n\n\nOperation Examples\n\n\n<operation\n  id=\"series\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Applying series to mediapackage\">\n  <configurations>\n    <configuration key=\"series\">0d06537e-09d3-420c-8314-a21e45c5d032</configuration>\n    <configuration key=\"attach\">*</configuration>\n    <configuration key=\"apply-acl\">true</configuration>\n  </configurations>\n</operation>\n\n\n\n\n<operation\n  id=\"series\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Applying series to mediapackage\">\n  <configurations>\n    <configuration key=\"attach\">*</configuration>\n    <configuration key=\"apply-acl\">false</configuration>\n    <configuration key=\"copy-metadata\">contributor, license</configuration>\n  </configurations>\n</operation>\n\n\n\n\n<operation\n  id=\"series\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Applying series to mediapackage\">\n  <configurations>\n    <configuration key=\"attach\">dublincore/*</configuration>\n    <configuration key=\"apply-acl\">false</configuration>\n    <configuration key=\"copy-metadata\">{http://purl.org/dc/terms/}contributor custom1 custom2</configuration>\n    <configuration key=\"default-namespace\">http://www.opencastproject.org/</configuration>\n  </configurations>\n</operation>",
            "title": "Series"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#seriesworkflowoperationhandler",
            "text": "",
            "title": "SeriesWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#description",
            "text": "The SeriesWorkflowOperation will apply a series to the mediapackage.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      series  0d06537e-09d3-420c-8314-a21e45c5d032  The optional series identifier. If empty the current series of the medipackage will be taken.     attach  creativecommons/*,dublincore/*  The flavors of the series catalogs to attach to the mediapackage.     apply-acl  true  Whether the ACL should be applied or not.  false    copy-metadata  {http://purl.org/dc/terms/}title, isPartOf  A comma-separated list of metadata fields (possibly \"expanded\") to be transferred from the series catalog to the episode catalog if they do not exist in the latter.     default-namespace  http://purl.org/dc/elements/1.1/  The default namespace to use when the metadata fields in the  copy-metadata  property are not fully \"expanded\".  http://purl.org/dc/terms/  (DublinCore Term namespace)",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#about-expanded-names",
            "text": "Expanded names are qualified XML terms where the prefix has been expanded to the full namespace it represents. For\nconvention, they are written as:  {namespace}localname  \u2026 where  namespace  is the full namespace (not a prefix like in XML documents) and  localname  is the term itself.  Some examples of expanded names are:   {http://purl.org/dc/terms/}title  {http://mediapackage.opencastproject.org}mediapackage  {}term-with-an-empty-namespace   The value of the  copy-metadata  may contain expanded and non-expanded names. In the latter case, the names will be\nexpanded using the provided namespace, if any, or the DublinCore namespace by default.  Please note that:   An empty namespace (such as in  {}example ) is still a namespace. That means that the default namespace will not be\n   substituted in this case and the term will be handled \"as-is\", i.e. with an empty namespace.  Most of the terms used by Opencast belong to the DublinCore namespace, so using non-expanded names and the default\n   namespace should be sufficient. However, custom metadata fields may be in a different namespace which must be\n   explicitly specified.",
            "title": "About Expanded Names"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#allowed-namespaces",
            "text": "For technical reasons, namespaces need to be pre-registered in Opencast to be used. That is why only a defined set of\nnamespaces can be used in this operation. The allowed namespaces are:   DublinCore Terms:  http://purl.org/dc/terms/  DublinCore Elements 1.1:  http://purl.org/dc/elements/1.1/  Opencast Properties:  http://www.opencastproject.org/",
            "title": "Allowed Namespaces"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#operation-examples",
            "text": "<operation\n  id=\"series\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Applying series to mediapackage\">\n  <configurations>\n    <configuration key=\"series\">0d06537e-09d3-420c-8314-a21e45c5d032</configuration>\n    <configuration key=\"attach\">*</configuration>\n    <configuration key=\"apply-acl\">true</configuration>\n  </configurations>\n</operation>  <operation\n  id=\"series\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Applying series to mediapackage\">\n  <configurations>\n    <configuration key=\"attach\">*</configuration>\n    <configuration key=\"apply-acl\">false</configuration>\n    <configuration key=\"copy-metadata\">contributor, license</configuration>\n  </configurations>\n</operation>  <operation\n  id=\"series\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Applying series to mediapackage\">\n  <configurations>\n    <configuration key=\"attach\">dublincore/*</configuration>\n    <configuration key=\"apply-acl\">false</configuration>\n    <configuration key=\"copy-metadata\">{http://purl.org/dc/terms/}contributor custom1 custom2</configuration>\n    <configuration key=\"default-namespace\">http://www.opencastproject.org/</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Examples"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/",
            "text": "SilenceDetectionWorkflowOperationHandler\n\n\nDescription\n\n\nThe silence operation performs a silence detection on an audio-only input file.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n*/audio\n\n\nThe input parameter source-flavors takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type\n\n\nEMPTY\n\n\n\n\n\n\nreference-tracks-flavour\n\n\n*/preview\n\n\nThe input parameter reference-tracks-flavour is the subtype of the media files that should be included in the provided SMIL file. The * should not be modified here. In most cases it is not important which reference-tracks-flavour is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality.\n\n\nEMPTY\n\n\n\n\n\n\nsmil-flavor-subtype\n\n\nsmil\n\n\nThe output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced.\n\n\nEMPTY\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"silence\"\n  description=\"Executing silence detection\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/audio</configuration>\n    <configuration key=\"smil-flavor-subtype\">smil</configuration>\n    <configuration key=\"reference-tracks-flavor\">*/preview</configuration>\n  </configurations>\n</operation>",
            "title": "Silence"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/#silencedetectionworkflowoperationhandler",
            "text": "",
            "title": "SilenceDetectionWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/#description",
            "text": "The silence operation performs a silence detection on an audio-only input file.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  */audio  The input parameter source-flavors takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type  EMPTY    reference-tracks-flavour  */preview  The input parameter reference-tracks-flavour is the subtype of the media files that should be included in the provided SMIL file. The * should not be modified here. In most cases it is not important which reference-tracks-flavour is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality.  EMPTY    smil-flavor-subtype  smil  The output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced.  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/#operation-example",
            "text": "<operation\n  id=\"silence\"\n  description=\"Executing silence detection\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/audio</configuration>\n    <configuration key=\"smil-flavor-subtype\">smil</configuration>\n    <configuration key=\"reference-tracks-flavor\">*/preview</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/start-watson-transcription-woh/",
            "text": "Start Watson Transcription\n\n\nDescription\n\n\nThe Start Watson Transcription invokes the IBM Watson Speech-to-Text service, passing an audio file to be translated to\ntext.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\ndescription\n\n\ndefault value\n\n\nexample\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\nThe flavor of the audio file to be sent for translation.\n\n\nEMPTY\n\n\npresenter/delivery\n\n\n\n\n\n\nsource-tag\n\n\nThe flavor of the audio file to be sent for translation.\n\n\nEMPTY\n\n\ntranscript-audio\n\n\n\n\n\n\nskip-if-flavor-exists\n\n\nIf this flavor already exists in the media package, skip this operation.\nTo be used when the media package already has a transcript file.\n\n\nfalse\n\n\ncaptions/vtt+en\n\n\n\n\n\n\n\n\nOne of source-flavor or source-tag must be specified.\n\n\nExample\n\n\n<!-- Extract audio from video in ogg/opus format -->\n\n<operation\n  id=\"compose\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Extract audio for transcript generation\">\n  <configurations>\n    <configuration key=\"source-tags\">engage-download</configuration>\n    <configuration key=\"target-flavor\">audio/ogg</configuration>\n    <configuration key=\"target-tags\">transcript</configuration>\n    <configuration key=\"encoding-profile\">audio-opus</configuration>\n    <!-- If there is more than one file that match the source-tags, use only the first one -->\n    <configuration key=\"process-first-match-only\">true</configuration>\n  </configurations>\n</operation>\n\n<!-- Start IBM Watson recognitions job -->\n\n<operation\n  id=\"start-watson-transcription\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Start IBM Watson transcription job\">\n  <configurations>\n    <!--  Skip this operation if flavor already exists. Used for cases when mp already has captions. -->\n    <configuration key=\"skip-if-flavor-exists\">captions/vtt+en</configuration>\n    <!-- Audio to be translated, produced in the previous compose operation -->\n    <configuration key=\"source-tag\">transcript</configuration>\n  </configurations>\n</operation>\n\n\n\n\nEncoding profile used in example above\n\n\nprofile.audio-opus.name = audio-opus\nprofile.audio-opus.input = stream\nprofile.audio-opus.output = audio\nprofile.audio-opus.suffix = -audio.opus\nprofile.audio-opus.ffmpeg.command = -i /#{in.video.path} -c:a libvorbis -ac 1 -ar 16k -b:a 64k #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Start Watson Transcription"
        },
        {
            "location": "/workflowoperationhandlers/start-watson-transcription-woh/#start-watson-transcription",
            "text": "",
            "title": "Start Watson Transcription"
        },
        {
            "location": "/workflowoperationhandlers/start-watson-transcription-woh/#description",
            "text": "The Start Watson Transcription invokes the IBM Watson Speech-to-Text service, passing an audio file to be translated to\ntext.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/start-watson-transcription-woh/#parameter-table",
            "text": "configuration keys  description  default value  example      source-flavor  The flavor of the audio file to be sent for translation.  EMPTY  presenter/delivery    source-tag  The flavor of the audio file to be sent for translation.  EMPTY  transcript-audio    skip-if-flavor-exists  If this flavor already exists in the media package, skip this operation. To be used when the media package already has a transcript file.  false  captions/vtt+en     One of source-flavor or source-tag must be specified.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/start-watson-transcription-woh/#example",
            "text": "<!-- Extract audio from video in ogg/opus format -->\n\n<operation\n  id=\"compose\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Extract audio for transcript generation\">\n  <configurations>\n    <configuration key=\"source-tags\">engage-download</configuration>\n    <configuration key=\"target-flavor\">audio/ogg</configuration>\n    <configuration key=\"target-tags\">transcript</configuration>\n    <configuration key=\"encoding-profile\">audio-opus</configuration>\n    <!-- If there is more than one file that match the source-tags, use only the first one -->\n    <configuration key=\"process-first-match-only\">true</configuration>\n  </configurations>\n</operation>\n\n<!-- Start IBM Watson recognitions job -->\n\n<operation\n  id=\"start-watson-transcription\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Start IBM Watson transcription job\">\n  <configurations>\n    <!--  Skip this operation if flavor already exists. Used for cases when mp already has captions. -->\n    <configuration key=\"skip-if-flavor-exists\">captions/vtt+en</configuration>\n    <!-- Audio to be translated, produced in the previous compose operation -->\n    <configuration key=\"source-tag\">transcript</configuration>\n  </configurations>\n</operation>",
            "title": "Example"
        },
        {
            "location": "/workflowoperationhandlers/start-watson-transcription-woh/#encoding-profile-used-in-example-above",
            "text": "profile.audio-opus.name = audio-opus\nprofile.audio-opus.input = stream\nprofile.audio-opus.output = audio\nprofile.audio-opus.suffix = -audio.opus\nprofile.audio-opus.ffmpeg.command = -i /#{in.video.path} -c:a libvorbis -ac 1 -ar 16k -b:a 64k #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Encoding profile used in example above"
        },
        {
            "location": "/workflowoperationhandlers/start-workflow-woh/",
            "text": "StartWorkflowWorkflowOperationHandler\n\n\nDescription\n\n\nThe StartWorkflowWorkflowOperationHandler can be used to start a new workflow for given media package and workflow definition.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Key\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nmedia-package*\n\n\ne72f2265-472a-49ae-bc04-8301d94b4b1a\n\n\nThe ID of the media package that should be used\n\n\n\n\n\n\nworkflow-definition*\n\n\nfast\n\n\nThe workflow definition that should be used\n\n\n\n\n\n\nconfigProperty\n\n\nabc / false\n\n\nWorkflow configuration property\n\n\n\n\n\n\n\n\n* mandatory configuration key\n\n\nOperation Example\n\n\n<operation id=\"start-workflow\">\n  <configurations>\n    <configuration key=\"workflow-definition\">fast</configuration>\n    <configuration key=\"media-package\">e72f2265-472a-49ae-bc04-8301d94b4b1a</configuration>\n    <configuration key=\"key\">value</configuration>\n    <configuration key=\"publish\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Start Workflow"
        },
        {
            "location": "/workflowoperationhandlers/start-workflow-woh/#startworkflowworkflowoperationhandler",
            "text": "",
            "title": "StartWorkflowWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/start-workflow-woh/#description",
            "text": "The StartWorkflowWorkflowOperationHandler can be used to start a new workflow for given media package and workflow definition.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/start-workflow-woh/#parameter-table",
            "text": "Configuration Key  Example  Description      media-package*  e72f2265-472a-49ae-bc04-8301d94b4b1a  The ID of the media package that should be used    workflow-definition*  fast  The workflow definition that should be used    configProperty  abc / false  Workflow configuration property     * mandatory configuration key",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/start-workflow-woh/#operation-example",
            "text": "<operation id=\"start-workflow\">\n  <configurations>\n    <configuration key=\"workflow-definition\">fast</configuration>\n    <configuration key=\"media-package\">e72f2265-472a-49ae-bc04-8301d94b4b1a</configuration>\n    <configuration key=\"key\">value</configuration>\n    <configuration key=\"publish\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/",
            "text": "TagWorkflowOperation\n\n\nDescription\n\n\nWith the TagWorkflowOperationHandler it's possible to select various media package elements and then modify their tag\nset and / or set their flavor.\n\n\nSo for example it's possible to pick up elements like the dublin core catalogs that have been added to the media package\nat the beginning of the workflow and tag them, so they can be picked up by operations later on.\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-tags\n\n\n\"engage,atom,rss,-publish\"\n\n\nTag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavors\n\n\n\"presentation/trimmed\"\n\n\nTag any media package elements with one of these (comma separated) flavors.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\n\"tagged,+rss\" / \"-rss,+tagged\"\n\n\nApply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\n\"presentation/tagged\"\n\n\nApply these flavor to any media package elements\n\n\nEMPTY\n\n\n\n\n\n\ncopy\n\n\n\"true\" or \"false\"\n\n\nIndicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise.\n\n\nFALSE\n\n\n\n\n\n\n\n\nTarget Tags Example\n\n\n\n\n\n\n\n\nTarget-Tags\n\n\nPreexisting Tags\n\n\nResulting Tags\n\n\n\n\n\n\n\n\n\n\nrss\n\n\nengage\n\n\nrss\n\n\n\n\n\n\n+rss\n\n\nengage\n\n\nengage,rss\n\n\n\n\n\n\n-rss\n\n\nengage,rss\n\n\nengage\n\n\n\n\n\n\ntagged,+rss\n\n\nengage\n\n\ntagged\n\n\n\n\n\n\n-rss,+tagged\n\n\nengage,rss\n\n\nengage,tagged\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"tag\"\n  max-attempts=\"2\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Tagging media package elements\">\n  <configurations>\n    <configuration key=\"source-tags\">engage,atom,publish</configuration>\n    <configuration key=\"source-flavors\">presentation/trimmed</configuration>\n    <configuration key=\"target-tags\">-atom,+rss</configuration>\n    <configuration key=\"target-flavor\">presentation/tagged</configuration>\n    <configuration key=\"copy\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Tag"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#tagworkflowoperation",
            "text": "",
            "title": "TagWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#description",
            "text": "With the TagWorkflowOperationHandler it's possible to select various media package elements and then modify their tag\nset and / or set their flavor.  So for example it's possible to pick up elements like the dublin core catalogs that have been added to the media package\nat the beginning of the workflow and tag them, so they can be picked up by operations later on.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  example  description  default value      source-tags  \"engage,atom,rss,-publish\"  Tag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded.  EMPTY    source-flavors  \"presentation/trimmed\"  Tag any media package elements with one of these (comma separated) flavors.  EMPTY    target-tags  \"tagged,+rss\" / \"-rss,+tagged\"  Apply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags.  EMPTY    target-flavor  \"presentation/tagged\"  Apply these flavor to any media package elements  EMPTY    copy  \"true\" or \"false\"  Indicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise.  FALSE",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#target-tags-example",
            "text": "Target-Tags  Preexisting Tags  Resulting Tags      rss  engage  rss    +rss  engage  engage,rss    -rss  engage,rss  engage    tagged,+rss  engage  tagged    -rss,+tagged  engage,rss  engage,tagged",
            "title": "Target Tags Example"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#operation-example",
            "text": "<operation\n  id=\"tag\"\n  max-attempts=\"2\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Tagging media package elements\">\n  <configurations>\n    <configuration key=\"source-tags\">engage,atom,publish</configuration>\n    <configuration key=\"source-flavors\">presentation/trimmed</configuration>\n    <configuration key=\"target-tags\">-atom,+rss</configuration>\n    <configuration key=\"target-flavor\">presentation/tagged</configuration>\n    <configuration key=\"copy\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/tag-by-dcterm-woh/",
            "text": "TagByDCTermWorkflowOperationHandler\n\n\nDescription\n\n\nWith the TagByDCTermWorkflowOperationHandler it's possible to select various media package elements and then modify\ntheir tag set and / or set their flavor according to whether a Dublin Core term in a catalog has a specific value.\n\n\nSo for example it's possible to pick elements like the Dublin Core catalogs that have been added to the media package\nat the beginning of the workflow and tag them, so they can be picked up by operations later on or even an application\nthat harvests the mediapackage from a publication channel.\n\n\nIn combination with \nConfigureByDCTermWorkflowOperationHandler\n workflows can be controlled\nby the metadata contained within the Dublin core catalogs.\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-tags\n\n\n\"engage,atom,rss,-publish\"\n\n\nTag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavors\n\n\n\"presentation/trimmed\"\n\n\nTag any media package elements with one of these (comma separated) flavors.\n\n\nEMPTY\n\n\n\n\n\n\ndccatalog\n\n\n\"episode\" or \"series\"\n\n\nthe type of catalog in which to search for dcterm\n\n\nEMPTY\n\n\n\n\n\n\ndcterm\n\n\n\"creator\"\n\n\nthe name of the Dublin Core term which to check\n\n\nEMPTY\n\n\n\n\n\n\nmatch-value\n\n\n\"Joe Bloggs\"\n\n\nthe Dublin Core term value to check for\n\n\nEMPTY\n\n\n\n\n\n\ndefault-value\"\n\n\n\"Anon\"\n\n\nthe implied value if the dubincore term is not present in the catalog\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\n\"tagged,+rss\" / \"-rss,+tagged\"\n\n\nApply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\n\"presentation/tagged\"\n\n\nApply these flavor to any media package elements\n\n\nEMPTY\n\n\n\n\n\n\ncopy\n\n\n\"true\" or \"false\"\n\n\nIndicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise.\n\n\nFALSE\n\n\n\n\n\n\n\n\nNote: see \nTagWorkflowOperationHandler\n for further explanation of the source/target-flavour/tags\n\n\ndccatalog\n\n\nThe type of Dublin Core catalog in which to look for the \ndcterm\n. This will usually be \nepisode\n or \nseries\n.\n\n\ndcterm\n\n\nThe name of the Dublin Core term to look for in the \ndccatalog\n. This could be one of the terms set by Opencast or an\nadditional term adding to the catalog.\n\n\nmatch-value\n\n\nThe value of the \ndcterm\n which to match against. The comparison is case sensitive.\n\n\ndefault-value\n\n\nIf \ndefault-value\n is used when the \ndcterm\n is not found in the catalog. If not specified the operation will treat the\nmatch as false and not tag anything. If \ndefault-value\n is specified the operation will compare the \nmatch-value\n to\nthe \ndefault-value\n and apply the tags if they match. This allows an implied value to be explicitly and clearly\ndefined. For example if you have mediapackages that were created before additional metadata was added to the episode\ncatalog you may want to imply that the \naudience\n term has a value of \nall-enrolled\n.\n\n\nOperation Example\n\n\n<operation\n  id=\"tag-by-dcterm\"\n  max-attempts=\"2\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Tagging media package elements according to dcterm\">\n  <configurations>\n    <configuration key=\"source-flavors\">dublincore/*,security/*</configuration>\n    <configuration key=\"dccatalog\">episode</configuration>\n    <configuration key=\"dcterm\">audience</configuration>\n    <configuration key=\"match-value\">learning-difficulties</configuration>\n    <configuration key=\"default-value\">all-enrolled</confiuration>\n    <configuration key=\"target-tags\">+publishBeforeEditing</configuration>\n  </configurations>\n</operation>",
            "title": "Tag-By-DCTerm"
        },
        {
            "location": "/workflowoperationhandlers/tag-by-dcterm-woh/#tagbydctermworkflowoperationhandler",
            "text": "",
            "title": "TagByDCTermWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/tag-by-dcterm-woh/#description",
            "text": "With the TagByDCTermWorkflowOperationHandler it's possible to select various media package elements and then modify\ntheir tag set and / or set their flavor according to whether a Dublin Core term in a catalog has a specific value.  So for example it's possible to pick elements like the Dublin Core catalogs that have been added to the media package\nat the beginning of the workflow and tag them, so they can be picked up by operations later on or even an application\nthat harvests the mediapackage from a publication channel.  In combination with  ConfigureByDCTermWorkflowOperationHandler  workflows can be controlled\nby the metadata contained within the Dublin core catalogs.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/tag-by-dcterm-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  example  description  default value      source-tags  \"engage,atom,rss,-publish\"  Tag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded.  EMPTY    source-flavors  \"presentation/trimmed\"  Tag any media package elements with one of these (comma separated) flavors.  EMPTY    dccatalog  \"episode\" or \"series\"  the type of catalog in which to search for dcterm  EMPTY    dcterm  \"creator\"  the name of the Dublin Core term which to check  EMPTY    match-value  \"Joe Bloggs\"  the Dublin Core term value to check for  EMPTY    default-value\"  \"Anon\"  the implied value if the dubincore term is not present in the catalog  EMPTY    target-tags  \"tagged,+rss\" / \"-rss,+tagged\"  Apply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags.  EMPTY    target-flavor  \"presentation/tagged\"  Apply these flavor to any media package elements  EMPTY    copy  \"true\" or \"false\"  Indicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise.  FALSE     Note: see  TagWorkflowOperationHandler  for further explanation of the source/target-flavour/tags",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/tag-by-dcterm-woh/#dccatalog",
            "text": "The type of Dublin Core catalog in which to look for the  dcterm . This will usually be  episode  or  series .",
            "title": "dccatalog"
        },
        {
            "location": "/workflowoperationhandlers/tag-by-dcterm-woh/#dcterm",
            "text": "The name of the Dublin Core term to look for in the  dccatalog . This could be one of the terms set by Opencast or an\nadditional term adding to the catalog.",
            "title": "dcterm"
        },
        {
            "location": "/workflowoperationhandlers/tag-by-dcterm-woh/#match-value",
            "text": "The value of the  dcterm  which to match against. The comparison is case sensitive.",
            "title": "match-value"
        },
        {
            "location": "/workflowoperationhandlers/tag-by-dcterm-woh/#default-value",
            "text": "If  default-value  is used when the  dcterm  is not found in the catalog. If not specified the operation will treat the\nmatch as false and not tag anything. If  default-value  is specified the operation will compare the  match-value  to\nthe  default-value  and apply the tags if they match. This allows an implied value to be explicitly and clearly\ndefined. For example if you have mediapackages that were created before additional metadata was added to the episode\ncatalog you may want to imply that the  audience  term has a value of  all-enrolled .",
            "title": "default-value"
        },
        {
            "location": "/workflowoperationhandlers/tag-by-dcterm-woh/#operation-example",
            "text": "<operation\n  id=\"tag-by-dcterm\"\n  max-attempts=\"2\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Tagging media package elements according to dcterm\">\n  <configurations>\n    <configuration key=\"source-flavors\">dublincore/*,security/*</configuration>\n    <configuration key=\"dccatalog\">episode</configuration>\n    <configuration key=\"dcterm\">audience</configuration>\n    <configuration key=\"match-value\">learning-difficulties</configuration>\n    <configuration key=\"default-value\">all-enrolled</confiuration>\n    <configuration key=\"target-tags\">+publishBeforeEditing</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/timelinepreviews-woh/",
            "text": "TimelinePreviewsWorkflowOperationHandler\n\n\nDescription\n\n\nThe timeline previews operation creates preview images for the given track that can be shown when hovering above the\ntimeline. It will generate the in \nimage-count\n specified number of preview images, that will all be saved in one large\nimage file. You can use the \nsource-flavor\n to specify for which video the preview images will be generated. In the\nengage player only the preview images of one video are shown (the first that is found), so to make sure the correct\npreview images are shown, better generate them only for one video.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n*/trimmed\n\n\nSpecifies which media should be processed. The *-operator can be used if the preview images should be created for all flavors with a certain subtype (like \"trimmed\" in the example) Hereby you can for example choose whether you want to create the timeline preview images from a presenter or a presentation video.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\n*/timeline+preview\n\n\nSpecifies the flavor the new files will get. This should use the *-operator if it was used in the source-flavor too. This flavor has to contain the words \"timeline\" and \"preview\" for the file to be found by the player.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\nengage-download\n\n\nSpecifies the tags the new files will get.\n\n\nEMPTY\n\n\n\n\n\n\nimage-count\n\n\n100\n\n\nSpecifies the number of generated timeline preview images. In the example 100 timeline preview images will be generated and stored in a 10x10 grid in the output image\n\n\n100\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"timelinepreviews\"\n  description=\"Creating presentation timeline preview images\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/trimmed</configuration>\n    <configuration key=\"target-flavor\">*/timeline+preview</configuration>\n    <configuration key=\"target-tags\">engage-download</configuration>\n    <configuration key=\"image-count\">100</configuration>\n  </configurations>\n</operation>",
            "title": "Timelinepreviews"
        },
        {
            "location": "/workflowoperationhandlers/timelinepreviews-woh/#timelinepreviewsworkflowoperationhandler",
            "text": "",
            "title": "TimelinePreviewsWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/timelinepreviews-woh/#description",
            "text": "The timeline previews operation creates preview images for the given track that can be shown when hovering above the\ntimeline. It will generate the in  image-count  specified number of preview images, that will all be saved in one large\nimage file. You can use the  source-flavor  to specify for which video the preview images will be generated. In the\nengage player only the preview images of one video are shown (the first that is found), so to make sure the correct\npreview images are shown, better generate them only for one video.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/timelinepreviews-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  */trimmed  Specifies which media should be processed. The *-operator can be used if the preview images should be created for all flavors with a certain subtype (like \"trimmed\" in the example) Hereby you can for example choose whether you want to create the timeline preview images from a presenter or a presentation video.  EMPTY    target-flavor  */timeline+preview  Specifies the flavor the new files will get. This should use the *-operator if it was used in the source-flavor too. This flavor has to contain the words \"timeline\" and \"preview\" for the file to be found by the player.  EMPTY    target-tags  engage-download  Specifies the tags the new files will get.  EMPTY    image-count  100  Specifies the number of generated timeline preview images. In the example 100 timeline preview images will be generated and stored in a 10x10 grid in the output image  100",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/timelinepreviews-woh/#operation-example",
            "text": "<operation\n  id=\"timelinepreviews\"\n  description=\"Creating presentation timeline preview images\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/trimmed</configuration>\n    <configuration key=\"target-flavor\">*/timeline+preview</configuration>\n    <configuration key=\"target-tags\">engage-download</configuration>\n    <configuration key=\"image-count\">100</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/theme-woh/",
            "text": "ThemeWorkflowOperationHandler\n\n\nDescription\n\n\nThe ThemeWorkflowOperation loads workflow properties and adds elements to the media package if available.\nThis information can be used within workflow definitions to actually implement themes.\n\n\nBumpers\n\n\nThe property \ntheme_bumper_active\n indicates whether the theme defines a bumper video. If true, the bumper video\nis added to the media package with the flavor \nbumper-flavor\n and/or tags \nbumper-tags\n.\n\n\nTrailers\n\n\nThe property \ntheme_trailer_active\n indicates whether the theme defines a trailer video. If true, the trailer video\nis added to the media package with the flavor \ntrailer-flavor\n and/or tags \ntrailer-tags\n.\n\n\nTitle Slide\n\n\nThe property \ntheme_title_slide_active\n indicates whether the theme defines a title slide. Additionally, the\nproperty \ntheme_title_slide_uploaded\n indicates whether the image needed as background for the generation\nof the title slide should be extracted from a video track or has been uploaded. In the later case,\nthe background image is added to the media package with the flavor \ntitle-slide-flavor\n and/or tags \ntitle-slide-tags\n.\n\n\nWatermark\n\n\nThe property \ntheme_watermark_active\n indicates whether the theme defines a watermark. If true, the watermark image\nis added to the media package with the flavor \nwatermark-flavor\n and/or tags \nwatermark-tags\n.\nAdditionally, a watermark layout compatible to the CompositeWorkflowOperation is added as property\n\nwatermark_layout_variable*.\n\n\nWorkflow Properties\n\n\nThe ThemeWorkflowOperation will set the following workflow properties:\n\n\n\n\n\n\n\n\nProperty Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntheme_active\n\n\ntrue if the theme has active settings, false or undefined otherwise\n\n\n\n\n\n\ntheme_bumper_active\n\n\ntrue if the theme has an active bumper video, false otherwise\n\n\n\n\n\n\ntheme_trailer_active\n\n\ntrue if the theme has an active trailer video, false otherwise\n\n\n\n\n\n\ntheme_title_slide_active\n\n\ntrue if the theme has an active title slide, false otherwise\n\n\n\n\n\n\ntheme_title_slide_uploaded\n\n\ntrue if the theme come with an uploaded title slide, false otherwise\n\n\n\n\n\n\ntheme_watermark_active\n\n\ntrue if the theme has an active watermark, false otherwise\n\n\n\n\n\n\n\n\nNote: The property \ntheme_active\n can be used to test whether a theme has any active settings, i.e.\nat least one of the properties \ntheme_*_active\n is true.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nConfiguration Keys\n\n\nExample\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n*bumper-flavor\n\n\nbranding/bumper\n\n\nFlavor of the bumper video\n\n\n\n\n\n\n*bumper-tags\n\n\nbumper\n\n\nTags of of the bumper video\n\n\n\n\n\n\n*trailer-flavor\n\n\nbranding/trailer\n\n\nFlavor of the trailer video\n\n\n\n\n\n\n*trailer-tags\n\n\ntrailer\n\n\nTags of the trailer video\n\n\n\n\n\n\n*title-slide-flavor\n\n\nbranding/titleslide\n\n\nFlavor of the title slide image\n\n\n\n\n\n\n*title-slide-tags\n\n\ntitleslide\n\n\nTags of the title slide image\n\n\n\n\n\n\n*watermark-flavor\n\n\nbranding/watermark\n\n\nFlavor of the watermark image\n\n\n\n\n\n\n*watermark-tags\n\n\nwatermark\n\n\nTags of the watermark image\n\n\n\n\n\n\n*watermark-layout-variable\n\n\ntheme_watermark_layout\n\n\nVariable that will hold the watermark layout\n\n\n\n\n\n\n\n\n* Mandatory configuration key (in case the feature is active)\n\n\nOperation Example\n\n\n<operation\n  id=\"theme\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Apply the theme\">\n  <configurations>\n    <configuration key=\"bumper-flavor\">branding/bumper</configuration>\n    <configuration key=\"bumper-tags\">archive</configuration>\n    <configuration key=\"trailer-flavor\">branding/trailer</configuration>\n    <configuration key=\"trailer-tags\">archive</configuration>\n    <configuration key=\"title-slide-flavor\">branding/titleslide</configuration>\n    <configuration key=\"title-slide-tags\">archive</configuration>\n    <configuration key=\"watermark-flavor\">branding/titleslide</configuration>\n    <configuration key=\"watermark-tags\">archive</configuration>\n    <configuration key=\"watermark-layout-variable\">theme_watermark_layout</configuration>\n  </configurations>\n</operation>",
            "title": "Theme"
        },
        {
            "location": "/workflowoperationhandlers/theme-woh/#themeworkflowoperationhandler",
            "text": "",
            "title": "ThemeWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/theme-woh/#description",
            "text": "The ThemeWorkflowOperation loads workflow properties and adds elements to the media package if available.\nThis information can be used within workflow definitions to actually implement themes.  Bumpers  The property  theme_bumper_active  indicates whether the theme defines a bumper video. If true, the bumper video\nis added to the media package with the flavor  bumper-flavor  and/or tags  bumper-tags .  Trailers  The property  theme_trailer_active  indicates whether the theme defines a trailer video. If true, the trailer video\nis added to the media package with the flavor  trailer-flavor  and/or tags  trailer-tags .  Title Slide  The property  theme_title_slide_active  indicates whether the theme defines a title slide. Additionally, the\nproperty  theme_title_slide_uploaded  indicates whether the image needed as background for the generation\nof the title slide should be extracted from a video track or has been uploaded. In the later case,\nthe background image is added to the media package with the flavor  title-slide-flavor  and/or tags  title-slide-tags .  Watermark  The property  theme_watermark_active  indicates whether the theme defines a watermark. If true, the watermark image\nis added to the media package with the flavor  watermark-flavor  and/or tags  watermark-tags .\nAdditionally, a watermark layout compatible to the CompositeWorkflowOperation is added as property watermark_layout_variable*.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/theme-woh/#workflow-properties",
            "text": "The ThemeWorkflowOperation will set the following workflow properties:     Property Name  Description      theme_active  true if the theme has active settings, false or undefined otherwise    theme_bumper_active  true if the theme has an active bumper video, false otherwise    theme_trailer_active  true if the theme has an active trailer video, false otherwise    theme_title_slide_active  true if the theme has an active title slide, false otherwise    theme_title_slide_uploaded  true if the theme come with an uploaded title slide, false otherwise    theme_watermark_active  true if the theme has an active watermark, false otherwise     Note: The property  theme_active  can be used to test whether a theme has any active settings, i.e.\nat least one of the properties  theme_*_active  is true.",
            "title": "Workflow Properties"
        },
        {
            "location": "/workflowoperationhandlers/theme-woh/#parameter-table",
            "text": "Configuration Keys  Example  Description      *bumper-flavor  branding/bumper  Flavor of the bumper video    *bumper-tags  bumper  Tags of of the bumper video    *trailer-flavor  branding/trailer  Flavor of the trailer video    *trailer-tags  trailer  Tags of the trailer video    *title-slide-flavor  branding/titleslide  Flavor of the title slide image    *title-slide-tags  titleslide  Tags of the title slide image    *watermark-flavor  branding/watermark  Flavor of the watermark image    *watermark-tags  watermark  Tags of the watermark image    *watermark-layout-variable  theme_watermark_layout  Variable that will hold the watermark layout     * Mandatory configuration key (in case the feature is active)",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/theme-woh/#operation-example",
            "text": "<operation\n  id=\"theme\"\n  exception-handler-workflow=\"partial-error\"\n  description=\"Apply the theme\">\n  <configurations>\n    <configuration key=\"bumper-flavor\">branding/bumper</configuration>\n    <configuration key=\"bumper-tags\">archive</configuration>\n    <configuration key=\"trailer-flavor\">branding/trailer</configuration>\n    <configuration key=\"trailer-tags\">archive</configuration>\n    <configuration key=\"title-slide-flavor\">branding/titleslide</configuration>\n    <configuration key=\"title-slide-tags\">archive</configuration>\n    <configuration key=\"watermark-flavor\">branding/titleslide</configuration>\n    <configuration key=\"watermark-tags\">archive</configuration>\n    <configuration key=\"watermark-layout-variable\">theme_watermark_layout</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/",
            "text": "WaveformWorkflowOperationHandler\n\n\nDescription\n\n\nThe waveform operation creates an image showing the temporal audio activity within the recording like this:\n\n\n\n\nThe implementation uses an ffmpeg filter that produces a waveform PNG image file from an audio/video file with at least\none audio channel.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n*/audio\n\n\nFlavor specifying tracks for which a waveform should be created\n\n\n\n\n\n\nsource-tags\n\n\nedit\n\n\nTags specifying tracks for which a waveform should be created\n\n\n\n\n\n\ntarget-flavor\n\n\n*/waveform\n\n\nFlavor used for the generated waveform\n\n\n\n\n\n\ntarget-tags\n\n\npreview\n\n\nComma-separated list of tags to be added to the waveform\n\n\n\n\n\n\n\n\nAdditional notes:\n\n\n\n\nAll media, that match either source-flavors or source tags will be processed.\n\n\nUsing a wildcard in the \ntarget-flavor\n will cause the main flavor of the input being used.\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"waveform\"\n  description=\"Generating waveform\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/audio</configuration>\n    <configuration key=\"target-flavor\">*/waveform</configuration>\n    <configuration key=\"target-tags\">preview</configuration>\n  </configurations>\n</operation>",
            "title": "Waveform"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/#waveformworkflowoperationhandler",
            "text": "",
            "title": "WaveformWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/#description",
            "text": "The waveform operation creates an image showing the temporal audio activity within the recording like this:   The implementation uses an ffmpeg filter that produces a waveform PNG image file from an audio/video file with at least\none audio channel.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/#parameter-table",
            "text": "configuration  example  description      source-flavors  */audio  Flavor specifying tracks for which a waveform should be created    source-tags  edit  Tags specifying tracks for which a waveform should be created    target-flavor  */waveform  Flavor used for the generated waveform    target-tags  preview  Comma-separated list of tags to be added to the waveform     Additional notes:   All media, that match either source-flavors or source tags will be processed.  Using a wildcard in the  target-flavor  will cause the main flavor of the input being used.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/#operation-example",
            "text": "<operation\n  id=\"waveform\"\n  description=\"Generating waveform\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/audio</configuration>\n    <configuration key=\"target-flavor\">*/waveform</configuration>\n    <configuration key=\"target-tags\">preview</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/",
            "text": "ZipWorkflowOperation\n\n\nDescription\n\n\nThe ZipWorkflowOperationHandler creates a zip archive including all elements of the current media package that are\nspecified in the operation configuration. It then adds the archive to the media package as an attachment with the given\nflavor and tags and by default stores the zip file in the working file repository's \"zip\" collection.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nzip-collection\n\n\nzips\n\n\nA comma separated list of flavors to preserve from deleting\n\n\nzip\n\n\n\n\n\n\ninclude-flavors\n\n\n*/source,dublincore/*\n\n\nWhich elements to include in the archive\n\n\n(all)\n\n\n\n\n\n\ntarget-flavor\n\n\narchive/zip\n\n\nThe flavor of the created attachment\n\n\narchive/zip\n\n\n\n\n\n\ntarget-tags\n\n\narchive\n\n\nThe tags to apply to the attachment\n\n\n\n\n\n\n\n\ncompression\n\n\ntrue\n\n\nWhether to compress the archive content\n\n\nflase\n\n\n\n\n\n\n\n\nAdditional notes:\n\n\n\n\nThe \ninclude-flavors\n configuration parameter accepts exact flavors like \npresenter/source\n as well as wildcard flavor\n  definitions like \n*/source\n.\n\n\nUsually, for media content, zip compression does not reduce the size of the archive very much but adds significant\n  processing time. That is why activating this is usually not recommended.\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"zip\"\n  description=\"Creating zipped recording archive\">\n  <configurations>\n    <configuration key=\"zip-collection\">failed.zips</configuration>\n    <configuration key=\"include-flavors\">*/source,dublincore/*</configuration>\n    <configuration key=\"target-flavor\">all/zip</configuration>\n    <configuration key=\"compression\">false</configuration>\n  </configurations>\n</operation>",
            "title": "Zip"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/#zipworkflowoperation",
            "text": "",
            "title": "ZipWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/#description",
            "text": "The ZipWorkflowOperationHandler creates a zip archive including all elements of the current media package that are\nspecified in the operation configuration. It then adds the archive to the media package as an attachment with the given\nflavor and tags and by default stores the zip file in the working file repository's \"zip\" collection.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/#parameter-table",
            "text": "configuration  example  description  default value      zip-collection  zips  A comma separated list of flavors to preserve from deleting  zip    include-flavors  */source,dublincore/*  Which elements to include in the archive  (all)    target-flavor  archive/zip  The flavor of the created attachment  archive/zip    target-tags  archive  The tags to apply to the attachment     compression  true  Whether to compress the archive content  flase     Additional notes:   The  include-flavors  configuration parameter accepts exact flavors like  presenter/source  as well as wildcard flavor\n  definitions like  */source .  Usually, for media content, zip compression does not reduce the size of the archive very much but adds significant\n  processing time. That is why activating this is usually not recommended.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/#operation-example",
            "text": "<operation\n  id=\"zip\"\n  description=\"Creating zipped recording archive\">\n  <configurations>\n    <configuration key=\"zip-collection\">failed.zips</configuration>\n    <configuration key=\"include-flavors\">*/source,dublincore/*</configuration>\n    <configuration key=\"target-flavor\">all/zip</configuration>\n    <configuration key=\"compression\">false</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        }
    ]
}