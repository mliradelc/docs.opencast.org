{
    "docs": [
        {
            "location": "/",
            "text": "Opencast Administration Guide\n\n\nWelcome to the Opencast Universe! Opencast is an open-source enterprise level lecture recording system. The core of the\nsystem delivers functionality for scheduling, media encoding, editing and content delivery. For lecture capture,\nOpencast provides capture agent software and third party appliances are available. An awesome community provides new\nfeatures and support.\n\n\nThe Software\n\n\nOpencast contains everything you need for scheduling captures, trimming, captioning, and conversion of output media to\nseveral formats and our engage components.  The core can be deployed on one (all-in-one deployment) or many (distributed\ndeployment) Linux servers so your Opencast installation can grow with the needs of your university.\n\n\nRelease Documentation\n\n\nThe Opencast Release Documentation is the official Opencast documentation for each release. It contains:\n\n\n\n\nRelease Notes\n\n\nInstallation Guides\n\n\nConfiguration Guides\n\n\nBasic Configuration\n\n\nDatabase Configuration\n\n\nWorkflow Configuration\n\n\nEncoding Configuration\n\n\nmore...\n\n\n\n\n\n\nModule Documentation\n\n\nMedia Module\n\n\nText Extraction\n\n\nVideo Segmentation\n\n\nYouTube Publication\n\n\nmore...\n\n\n\n\n\n\n\n\nFurther Documentation\n\n\nApart from these official documentation, further guides and tips can be found in the \nOpencast Adopter\nWiki\n, as well as on the mailing lists, the IRC channel and the regular meetings.",
            "title": "Home"
        },
        {
            "location": "/#opencast-administration-guide",
            "text": "Welcome to the Opencast Universe! Opencast is an open-source enterprise level lecture recording system. The core of the\nsystem delivers functionality for scheduling, media encoding, editing and content delivery. For lecture capture,\nOpencast provides capture agent software and third party appliances are available. An awesome community provides new\nfeatures and support.",
            "title": "Opencast Administration Guide"
        },
        {
            "location": "/#the-software",
            "text": "Opencast contains everything you need for scheduling captures, trimming, captioning, and conversion of output media to\nseveral formats and our engage components.  The core can be deployed on one (all-in-one deployment) or many (distributed\ndeployment) Linux servers so your Opencast installation can grow with the needs of your university.",
            "title": "The Software"
        },
        {
            "location": "/#release-documentation",
            "text": "The Opencast Release Documentation is the official Opencast documentation for each release. It contains:   Release Notes  Installation Guides  Configuration Guides  Basic Configuration  Database Configuration  Workflow Configuration  Encoding Configuration  more...    Module Documentation  Media Module  Text Extraction  Video Segmentation  YouTube Publication  more...",
            "title": "Release Documentation"
        },
        {
            "location": "/#further-documentation",
            "text": "Apart from these official documentation, further guides and tips can be found in the  Opencast Adopter\nWiki , as well as on the mailing lists, the IRC channel and the regular meetings.",
            "title": "Further Documentation"
        },
        {
            "location": "/release.notes/",
            "text": "Opencast 2.1: Release Notes\n\n\nA feature rich, flexible Opencast\n\n\nIn the spirit of moving forward from 2.0, Opencast 2.1 provides, amongst other features, a more stable and flexible\nbackend infrastructure courtesy of Karaf - \u201cthe next generation OSGI framework\u201d.\n\n\nThe new version provides a lot of User Interface (UI) improvements and fixes some Admin UI issues. It also provides\nadditional internationalization support, as well as a Dashboard that provides a quick overview of processing states.\n\n\nOpencast 2.1 also introduces a way to access the REST-endpoint documentation from within the Admin UI, which paves the\nway to allowing us to remove the legacy (1.x-style) Admin UI in upcoming versions. Although the legacy UI is still\nusable for some tasks, some areas feel broken and should be removed as the underlying logic has changed (in the\ntransition from Opencast 1.x to 2.x).\n\n\nNew Features and Improvements\n\n\n\n\n\n\nSwitch from Apache Felix to Apache Karaf\n - 2.1 sees the move from an OSGI runtime (Felix) to a flexible OSGI\n   Environment (Karaf). This is the most prominent feature in 2.1. It ensures that going forward Opencast will have a\n   solid, flexible backend infrastructure.\n\n\n\n\n\n\nAddition of a new \"Assets\" tab\n - The Event details has a new tab, \u201cAssets\u201d, that gives additional information\n   about all the media, meta-data catalogues and publications.\n\n\n\n\n\n\nNew service health endpoint\n - Monitoring tools like Nagios or New Relic can mostly be configured to check the\n   health status of the software. This service health endpoint provides the information to indicate to Monitoring tools\n   that Opencast works as it is supposed to.\n\n\n\n\n\n\nRewritten workspace\n - This is the first step to addressing NFS latency issues. In the past the following scenario\n   was observed: \u201cA file has been written to the workspace. The write call returns, then another service tries to access\n   the previously written file but gets a \"not found\" error. Then, some time later the file appears.\u201d This rewrite\n   ensures that all workspaces on all nodes are able to see a file after it is written.\n\n\n\n\n\n\nA dashboard for the new Admin UI\n - The dashboard shows the number of jobs for different filter sets. This only\n   works with the events module for now.\n\n\n\n\n\n\ni18n : Introduction of Chinese Translation to Opencast\n - The introduction of Chinese Traditional as a new\n   Translation brings Opencast to the position of being fully translated into 5 languages (English, French, German,\n   Spanish and Chinese). The Translation has also been moved to Crowdin which allows a greater Community to help with\n   the translation efforts, also enabling people who do not write source-code to contribute to the internationalization\n   of Opencast.\n\n\n\n\n\n\nImportant Administrative Notes\n\n\n\n\n\n\nApache Karaf\n : The move from Apache Felix to Apache Karaf resulted in some changes in the way Opencast is built\n   and run. The build infrastructure has changed, and the result is a simpler build. When you build opencast you now\n   just run maven with much fewer parameters i.e.\n\n\n`mvn clean install`\n\n\n\nThis creates all the files necessary to run Opencast either in an all-in-one or distributed setup. The outputs of\nthe build are now stored in the  \nbuild\n folder.\n\n\nThere you will find \n.tar.gz\n packages for:\n\n\n\n\n\n\n\n\nfilename\n\n\ninstallation\n\n\n\n\n\n\n\n\n\n\nopencast-dist-admin-2.1.2.tar.gz\n\n\nadmin node\n\n\n\n\n\n\nopencast-dist-ingest-2.1.2.tar.gz\n\n\ningest node\n\n\n\n\n\n\nopencast-dist-presentation-2.1.2.tar.gz\n\n\npresentation node\n\n\n\n\n\n\nopencast-dist-worker-2.1.2.tar.gz\n\n\nworker node\n\n\n\n\n\n\nopencast-dist-allinone-2.1.2.tar.gz\n\n\nall-in-one installation\n\n\n\n\n\n\n\n\nFor your convenience the all-in-one installation is automatically extracted to the \nbuild\n folder.\n\n\n\n\n\n\nNew Configuration File Structure\n :\n\n\n\n\nMain config is now \ncustom.properties\n this contains all the configuration keys that have previously been in\n  \nconfig.properties\n. There is still a \nconfig.properties\n file which is automatically generated during the build\n  process and should not be changed.\n\n\nRemember to adjust the bind address for public installations.\n\n\n\n\n\n\n\n\nNew start scripts\n :\n\n\n\n\nstart-opencast\n now runs an interactive shell by default.\n\n\nUse \nlog:tail\n to tail the logs.\n\n\n\n\n\n\n\n\nHow to Upgrade\n\n\nNote that backing up your Opencast instance before doing a major update is strongly recommended.\n\n\n\n\nCheck out/download Opencast 2.1\n\n\nStop your current Opencast instance\n\n\nBack up Opencast files and database (optional)\n\n\nRun the appropriate database upgrade script(s)\n\n\ndocs/upgrade/1.6_2.0.0\n -> \ndocs/upgrade/2.0.1_2.0.2\n\n\n\n\n\n\nReview the configuration changes and adjust your configuration accordingly\n\n\nUpdate the third party tools as documented\n\n\nBuild Opencast 2.1\n\n\nStart Opencast\n\n\n\n\nAdditional Notes About 2.1.2\n\n\nOpencast 2.1.2 is a bug fix release that fixes some security issues of Opencast 2.1.2 and \na couple of minor issues. It provides a resolution of the issue of Opencast hanging if ActiveMQ \nis not available and an additional assembly that creates an ingest-only server for the Opencast \nCluster. \n\n\nAdditional Notes About 2.1.1\n\n\nOpencast 2.1.1 is a bug fix release that fixes some major issues of Opencast 2.1.0. \nIn Opencast 2.1.0 the distributed setup had a problem with the worker-node not starting properly.\nThis is now fixed. \n\n\n\n\nOpencast 2.0: Release Notes\n\n\nOpencast Matterhorn becomes simply Opencast\n\n\nFor a long time Matterhorn was the one project of the Opencast community and it was hard to distinguish between the two\nnames. With the new major release and the move towards Apereo, the Board decided to harmonize the names and\ndrop the former codename \u201c\nMatterhorn\n\u201d. Hence, Matterhorn is dead, long live Opencast!\n\n\nNew Features\n\n\n\n\nNew administrative user interface\n \u2013\n   One of the most obvious changes in the new release is the new administrative user interface. It has been completely\n   rewritten from scratch, using up-to-date technologies and a cleaner design. For more details, have a look at the\n   \nOpencast Users Guide\n.\n\n\nNew Engage player\n \u2013\n   Opencast 2.0 now offers a HTML5 video player. Its user-interface is accessible: you can control the player with\n   keyboard-shortcuts, ARIA profiles support screen-readers and captions are supported.\n   The architecture is very modular in design so that new plugins can easily be created. HLS is now supported as a\n   streaming protocol but RTMP is still available through a Flash fallback.\n\n\nPlayer Architecture\n\n\nPlayer Configuration\n\n\n\n\n\n\nNew media module\n \u2013\n   The Media Module has been slightly updated. It offers a new tile design which adapts to different screen sizes,\n   from mobile devices to regular desktop resolutions.\n   Within the Media Module configuration an easy selection of various players has been implemented so that the\n   administrator can define the default player to be used.\n\n\nNew FFmpeg-based video editor backend\n \u2013\n   This change allows us to get rid of the GStreamer dependency.\n\n\nNew video segmenter\n \u2013\n   Opencast 2.0 comes with a new video segmenter based on the FFmpeg \nselect\n filter. It makes the process much faster\n   and (if configured properly) will even allow detection of scene changes in presenter videos.\n\n\nNew silence detector\n \u2013\n   As with the video segmenter, the silence detector has been replaced with an FFmpeg-based implementation.\n\n\nNew documentation\n \u2013\n   Until now, the Opencast documentation was confusing because it was split-up into several wikis and people never knew\n   where to look for a topic. All official documentation can now be found at\n   \nhttp://docs.opencast.org/\n. The documentation is also included in the source code, so\n   that it is connected with the current state of development.  Apart from the official documentation, two wikis still\n   exist. These are the \nOpencast Adopters Wiki\n (meant for users to share their guides)\n   and the \nOpencast Development Wiki\n (meant for storing working drafts).\n\n\n\n\nImportant Administrative Notes\n\n\n\n\nApache ActiveMQ\n \u2013\n   Since Opencast 2, the Apache ActiveMQ message broker is used to enable an asynchronous, fast and reliable data\n   exchange between back-end and user interface. It requires, however, to run ActiveMQ as external service, much like\n   running a separate database (e.g. MariaDB).\n\n\nNo GStreamer 0.10 dependency\n \u2013\n   For a long time, Opencast has used GStreamer 0.10 and the Java bindings for that version. This GStreamer version\n   has been deprecated for years and is slowly disappearing from all major operating systems. Upgrading GStreamer proved\n   nearly impossible since there are no Java bindings for the newer versions. Therefore, we decided to get rid of\n   GStreamer, mainly by replacing it with FFmpeg.\n\n\nHold State\n \u2013\n   The new admin UI does not support hold-states anymore.\n\n\n\n\nRemoved Components\n\n\n\n\nReference capture agent\n \u2013\n   For a long time, Opencast came with a reference capture agent, providing a free, open source software capture agent.\n   In the last years, however, it was mainly replaced by other capture agents. One reason for that was the fact that the\n   development of the reference capture agent itself has come to a halt due to lack of interest. That is why\n   it was decided to separate the capture agent code from the Opencast core and move it into its own project.\n\n\nGStreamer service\n \u2013\n   As outlined before, GStreamer 0.10 has been removed from Opencast 2.0. Many parts have been thus replaced. One\n   module that has not been replaced, but simply removed instead, is the GStreamer service, which provided a backend\n   for other modules to talk to the deprecated GStreamer version using the deprecated Java bindings.\n\n\n\n\nHow to Upgrade\n\n\nNote that backing up your Opencast instance before doing a major update is strongly recommended.\n\n\n\n\nCheck out/download Opencast 2.0\n\n\nStop your current Opencast instance\n\n\nBack up Opencast files and database (optional)\n\n\nRun the appropriate database upgrade script (\ndocs/upgrade/1.6_to_2.0\n)\n\n\nReview the configuration changes and adjust your configuration accordingly\n\n\nUpdate the third party tools as documented\n\n\nRebuild the search indexes\n\n\nDelete (or move) your search indices\n\n\n${org.opencastproject.storage.dir}/searchindex\n\n\n${org.opencastproject.storage.dir}/seriesindex\n\n\n${org.opencastproject.storage.dir}/schedulerindex\n\n\n\n\n\n\nThe indexes will be rebuild automatically when re-starting Opencast. Rebuilding the indices can take quite a while\n  depending on the number of recordings in your system.\n\n\n\n\n\n\nBuild Opencast 2.0\n\n\nStart Opencast",
            "title": "Release Notes"
        },
        {
            "location": "/release.notes/#opencast-21-release-notes",
            "text": "A feature rich, flexible Opencast  In the spirit of moving forward from 2.0, Opencast 2.1 provides, amongst other features, a more stable and flexible\nbackend infrastructure courtesy of Karaf - \u201cthe next generation OSGI framework\u201d.  The new version provides a lot of User Interface (UI) improvements and fixes some Admin UI issues. It also provides\nadditional internationalization support, as well as a Dashboard that provides a quick overview of processing states.  Opencast 2.1 also introduces a way to access the REST-endpoint documentation from within the Admin UI, which paves the\nway to allowing us to remove the legacy (1.x-style) Admin UI in upcoming versions. Although the legacy UI is still\nusable for some tasks, some areas feel broken and should be removed as the underlying logic has changed (in the\ntransition from Opencast 1.x to 2.x).",
            "title": "Opencast 2.1: Release Notes"
        },
        {
            "location": "/release.notes/#new-features-and-improvements",
            "text": "Switch from Apache Felix to Apache Karaf  - 2.1 sees the move from an OSGI runtime (Felix) to a flexible OSGI\n   Environment (Karaf). This is the most prominent feature in 2.1. It ensures that going forward Opencast will have a\n   solid, flexible backend infrastructure.    Addition of a new \"Assets\" tab  - The Event details has a new tab, \u201cAssets\u201d, that gives additional information\n   about all the media, meta-data catalogues and publications.    New service health endpoint  - Monitoring tools like Nagios or New Relic can mostly be configured to check the\n   health status of the software. This service health endpoint provides the information to indicate to Monitoring tools\n   that Opencast works as it is supposed to.    Rewritten workspace  - This is the first step to addressing NFS latency issues. In the past the following scenario\n   was observed: \u201cA file has been written to the workspace. The write call returns, then another service tries to access\n   the previously written file but gets a \"not found\" error. Then, some time later the file appears.\u201d This rewrite\n   ensures that all workspaces on all nodes are able to see a file after it is written.    A dashboard for the new Admin UI  - The dashboard shows the number of jobs for different filter sets. This only\n   works with the events module for now.    i18n : Introduction of Chinese Translation to Opencast  - The introduction of Chinese Traditional as a new\n   Translation brings Opencast to the position of being fully translated into 5 languages (English, French, German,\n   Spanish and Chinese). The Translation has also been moved to Crowdin which allows a greater Community to help with\n   the translation efforts, also enabling people who do not write source-code to contribute to the internationalization\n   of Opencast.",
            "title": "New Features and Improvements"
        },
        {
            "location": "/release.notes/#important-administrative-notes",
            "text": "Apache Karaf  : The move from Apache Felix to Apache Karaf resulted in some changes in the way Opencast is built\n   and run. The build infrastructure has changed, and the result is a simpler build. When you build opencast you now\n   just run maven with much fewer parameters i.e.  `mvn clean install`  This creates all the files necessary to run Opencast either in an all-in-one or distributed setup. The outputs of\nthe build are now stored in the   build  folder.  There you will find  .tar.gz  packages for:     filename  installation      opencast-dist-admin-2.1.2.tar.gz  admin node    opencast-dist-ingest-2.1.2.tar.gz  ingest node    opencast-dist-presentation-2.1.2.tar.gz  presentation node    opencast-dist-worker-2.1.2.tar.gz  worker node    opencast-dist-allinone-2.1.2.tar.gz  all-in-one installation     For your convenience the all-in-one installation is automatically extracted to the  build  folder.    New Configuration File Structure  :   Main config is now  custom.properties  this contains all the configuration keys that have previously been in\n   config.properties . There is still a  config.properties  file which is automatically generated during the build\n  process and should not be changed.  Remember to adjust the bind address for public installations.     New start scripts  :   start-opencast  now runs an interactive shell by default.  Use  log:tail  to tail the logs.",
            "title": "Important Administrative Notes"
        },
        {
            "location": "/release.notes/#how-to-upgrade",
            "text": "Note that backing up your Opencast instance before doing a major update is strongly recommended.   Check out/download Opencast 2.1  Stop your current Opencast instance  Back up Opencast files and database (optional)  Run the appropriate database upgrade script(s)  docs/upgrade/1.6_2.0.0  ->  docs/upgrade/2.0.1_2.0.2    Review the configuration changes and adjust your configuration accordingly  Update the third party tools as documented  Build Opencast 2.1  Start Opencast",
            "title": "How to Upgrade"
        },
        {
            "location": "/release.notes/#additional-notes-about-212",
            "text": "Opencast 2.1.2 is a bug fix release that fixes some security issues of Opencast 2.1.2 and \na couple of minor issues. It provides a resolution of the issue of Opencast hanging if ActiveMQ \nis not available and an additional assembly that creates an ingest-only server for the Opencast \nCluster.",
            "title": "Additional Notes About 2.1.2"
        },
        {
            "location": "/release.notes/#additional-notes-about-211",
            "text": "Opencast 2.1.1 is a bug fix release that fixes some major issues of Opencast 2.1.0. \nIn Opencast 2.1.0 the distributed setup had a problem with the worker-node not starting properly.\nThis is now fixed.",
            "title": "Additional Notes About 2.1.1"
        },
        {
            "location": "/release.notes/#opencast-20-release-notes",
            "text": "Opencast Matterhorn becomes simply Opencast  For a long time Matterhorn was the one project of the Opencast community and it was hard to distinguish between the two\nnames. With the new major release and the move towards Apereo, the Board decided to harmonize the names and\ndrop the former codename \u201c Matterhorn \u201d. Hence, Matterhorn is dead, long live Opencast!",
            "title": "Opencast 2.0: Release Notes"
        },
        {
            "location": "/release.notes/#new-features",
            "text": "New administrative user interface  \u2013\n   One of the most obvious changes in the new release is the new administrative user interface. It has been completely\n   rewritten from scratch, using up-to-date technologies and a cleaner design. For more details, have a look at the\n    Opencast Users Guide .  New Engage player  \u2013\n   Opencast 2.0 now offers a HTML5 video player. Its user-interface is accessible: you can control the player with\n   keyboard-shortcuts, ARIA profiles support screen-readers and captions are supported.\n   The architecture is very modular in design so that new plugins can easily be created. HLS is now supported as a\n   streaming protocol but RTMP is still available through a Flash fallback.  Player Architecture  Player Configuration    New media module  \u2013\n   The Media Module has been slightly updated. It offers a new tile design which adapts to different screen sizes,\n   from mobile devices to regular desktop resolutions.\n   Within the Media Module configuration an easy selection of various players has been implemented so that the\n   administrator can define the default player to be used.  New FFmpeg-based video editor backend  \u2013\n   This change allows us to get rid of the GStreamer dependency.  New video segmenter  \u2013\n   Opencast 2.0 comes with a new video segmenter based on the FFmpeg  select  filter. It makes the process much faster\n   and (if configured properly) will even allow detection of scene changes in presenter videos.  New silence detector  \u2013\n   As with the video segmenter, the silence detector has been replaced with an FFmpeg-based implementation.  New documentation  \u2013\n   Until now, the Opencast documentation was confusing because it was split-up into several wikis and people never knew\n   where to look for a topic. All official documentation can now be found at\n    http://docs.opencast.org/ . The documentation is also included in the source code, so\n   that it is connected with the current state of development.  Apart from the official documentation, two wikis still\n   exist. These are the  Opencast Adopters Wiki  (meant for users to share their guides)\n   and the  Opencast Development Wiki  (meant for storing working drafts).",
            "title": "New Features"
        },
        {
            "location": "/release.notes/#important-administrative-notes_1",
            "text": "Apache ActiveMQ  \u2013\n   Since Opencast 2, the Apache ActiveMQ message broker is used to enable an asynchronous, fast and reliable data\n   exchange between back-end and user interface. It requires, however, to run ActiveMQ as external service, much like\n   running a separate database (e.g. MariaDB).  No GStreamer 0.10 dependency  \u2013\n   For a long time, Opencast has used GStreamer 0.10 and the Java bindings for that version. This GStreamer version\n   has been deprecated for years and is slowly disappearing from all major operating systems. Upgrading GStreamer proved\n   nearly impossible since there are no Java bindings for the newer versions. Therefore, we decided to get rid of\n   GStreamer, mainly by replacing it with FFmpeg.  Hold State  \u2013\n   The new admin UI does not support hold-states anymore.",
            "title": "Important Administrative Notes"
        },
        {
            "location": "/release.notes/#removed-components",
            "text": "Reference capture agent  \u2013\n   For a long time, Opencast came with a reference capture agent, providing a free, open source software capture agent.\n   In the last years, however, it was mainly replaced by other capture agents. One reason for that was the fact that the\n   development of the reference capture agent itself has come to a halt due to lack of interest. That is why\n   it was decided to separate the capture agent code from the Opencast core and move it into its own project.  GStreamer service  \u2013\n   As outlined before, GStreamer 0.10 has been removed from Opencast 2.0. Many parts have been thus replaced. One\n   module that has not been replaced, but simply removed instead, is the GStreamer service, which provided a backend\n   for other modules to talk to the deprecated GStreamer version using the deprecated Java bindings.",
            "title": "Removed Components"
        },
        {
            "location": "/release.notes/#how-to-upgrade_1",
            "text": "Note that backing up your Opencast instance before doing a major update is strongly recommended.   Check out/download Opencast 2.0  Stop your current Opencast instance  Back up Opencast files and database (optional)  Run the appropriate database upgrade script ( docs/upgrade/1.6_to_2.0 )  Review the configuration changes and adjust your configuration accordingly  Update the third party tools as documented  Rebuild the search indexes  Delete (or move) your search indices  ${org.opencastproject.storage.dir}/searchindex  ${org.opencastproject.storage.dir}/seriesindex  ${org.opencastproject.storage.dir}/schedulerindex    The indexes will be rebuild automatically when re-starting Opencast. Rebuilding the indices can take quite a while\n  depending on the number of recordings in your system.    Build Opencast 2.0  Start Opencast",
            "title": "How to Upgrade"
        },
        {
            "location": "/installation/",
            "text": "Install Opencast\n\n\nInstallation from Source\n\n\nThese guides will help you to build Opencast, including all necessary third party tools. This method will most likely\nwork on all Unix-like systems.\n\n\n\n\nRedHat Enterprise Linux\n\n\nCentOS\n\n\nScientific Linux\n\n\nFedora\n\n\nDebian\n\n\nUbuntu\n\n\nMac OS X\n\n\n\n\nBuilding on most other Unix-like operating systems should be very much alike.\n\n\nInstallation from Repository\n\n\nThere is an RPM repository available for some operating systems. It provides packages containing pre-configured and\npre-built Opencast installations.\n\n\n\n\nRedHat Enterprise Linux\n\n\nCentOS\n\n\nScientific Linux\n\n\nFedora\n\n\n\n\nInstallation Across Multiple Servers\n\n\nFor production systems, it is recommended to install Opencast across multiple servers to separate the processing,\nmanagement and presentation layer, so that, for example, even if the processing layer is under full load, users can\nstill watch recordings unaffected since the presentation layer is running on a separate machine.\n\n\n\n\nInstallation Across Multiple Servers",
            "title": "Overview"
        },
        {
            "location": "/installation/#install-opencast",
            "text": "",
            "title": "Install Opencast"
        },
        {
            "location": "/installation/#installation-from-source",
            "text": "These guides will help you to build Opencast, including all necessary third party tools. This method will most likely\nwork on all Unix-like systems.   RedHat Enterprise Linux  CentOS  Scientific Linux  Fedora  Debian  Ubuntu  Mac OS X   Building on most other Unix-like operating systems should be very much alike.",
            "title": "Installation from Source"
        },
        {
            "location": "/installation/#installation-from-repository",
            "text": "There is an RPM repository available for some operating systems. It provides packages containing pre-configured and\npre-built Opencast installations.   RedHat Enterprise Linux  CentOS  Scientific Linux  Fedora",
            "title": "Installation from Repository"
        },
        {
            "location": "/installation/#installation-across-multiple-servers",
            "text": "For production systems, it is recommended to install Opencast across multiple servers to separate the processing,\nmanagement and presentation layer, so that, for example, even if the processing layer is under full load, users can\nstill watch recordings unaffected since the presentation layer is running on a separate machine.   Installation Across Multiple Servers",
            "title": "Installation Across Multiple Servers"
        },
        {
            "location": "/installation/multiple-servers/",
            "text": "Install Across Multiple Servers\n\n\nNote that this is not a comprehensive guide of all possible ways to install Opencast. It is more like a guide to good\npractices and presents what a lot of people are running.\n\n\nStep 1: Install Opencast\n\n\nOpencast consists of a large set of modules which together build the whole system. In a distributed set-up, different\nkinds of nodes are basically only defined by the existence or absence of specific modules.\n\n\nWhile it is possible to stick together a system module by module, opencast comes with a set of pre-defined distribution\nwhich can directly be built and installed. To build these distributions, you would compile Opencast just like it is\noutlined in the basic installation guides and will then find a set of different distributions, both as archive and in a\nseparate directory.\n\n\nTo list all distributions, run the following command after Opencast is built:\n\n\n% ls -1 build/*.tar.gz\nbuild/opencast-dist-admin-${version}.tar.gz\nbuild/opencast-dist-allinone-${version}.tar.gz\nbuild/opencast-dist-presentation-${version}.tar.gz\nbuild/opencast-dist-worker-${version}.tar.g\n...\n\n\n\nThe same distributions can be found in the packages provided in the Opencast RPM repository.  These packages will\nautomatically install all dependencies for a given node type. For example, to install an Opencast worker node, you would\ninstall the package \nopencast21-distribution-worker\n.\n\n\nThe following list describes possible set-ups:\n\n\nAll-In-One\n\n\nThis is the default set-up described in the basic installation guides. It works fine for testing purposes. It should\nusually not be used in production. It is not distributed but is listed here to have a comprehensive list of predefined\ndistributions.\n\n\nTwo-Server Set-up\n\n\nThis set-up is the minimum set-up recommended for productive use. It will separate the presentation layer from the\nadministrative and working layer. This means that even if one server is under heavy load while videos are processed, it\nwill not effect the distribution and users should still be able to watch videos smoothly. However, it might happen that\nunder heavy load the handling of the administrative user interface gets a bit rough.\n\n\nThree (or more) Server Set-up\n\n\nWhile in the last example we have created one combined node for both the administrative tools and the workers, in this\nexample we will split it into dedicated worker and admin nodes. Using this set-up it is easy to increase the systems\nperformance simply by adding further worker nodes to the system.\n\n\nStep 2: Set-Up NFS Server\n\n\nThough it is possible to have Opencast run without shared storage, it is still a good idea to do so, as hard links can\nbe used to link files instead of copying them and not everything has to be tunneled over HTTP.\n\n\nThus you should first set-up your NFS server. The best solution is certainly to have a dedicated storage server. For\nsmaller set-ups, however, it can also be put on one of the Opencast nodes, i.e. on the admin node.\n\n\nTo do this, you first have to install and enable the NFS server:\n\n\nyum install nfs-utils nfs-utils-lib\nchkconfig  --level 345 nfs on\nservice nfs start\n\n\n\nYou want to have one common user on all your systems, so that file permissions do not become an issue.. As preparation\nfor this it makes sense to manually create an \nopencast\n user and group with a common UID and GID:\n\n\ngroupadd -g 1234 opencast\nuseradd -g 1234 -u 1234 opencast\n\n\n\nIf the user and group id \n1234\n is already used, just pick another one but make sure to pick the same one on all your\nOpencast nodes.\n\n\nThen create the directory to be shared and set its ownership to the newly created users:\n\n\nmkdir -p /srv/opencast\nchown opencast:opencast /srv/opencast\n\n\n\nNext we actually share the storage dir. For this we need to edit the file \n/etc/exports\n and set:\n\n\n/srv/opencast  131.173.172.190(rw,sync,no_subtree_check)\n\n\n\nwith 131.173.172.190 being the IP address of the other machine that should get access. Finally we enable the share with:\n\n\nexportfs -a\n\n\n\nOf cause you have to open the necessary ports in your firewall configuration.  For iptables, appropriate rules could be\nfor example:\n\n\n-A INPUT -m state --state NEW -p tcp -m multiport --dport 111,892,2049,32803 -j ACCEPT\n-A INPUT -m state --state NEW -p udp -m multiport --dport 111,892,2049,32803 -j ACCEPT\n\n\n\nYou can set them by editing \n/etc/sysconfig/iptables\n and restarting the service afterwards.\n\n\nNow you have set-up your storage server. What is still left to do is to mount the network storage on all other servers\nof the Opencast clusters except the capture agents. To do that you need to edit the \n/etc/fstab\n on each server and add\nthe command to mount the network storage on startup:\n\n\nstorageserver.example.com:/srv/opencast /srv/opencast   nfs rw,hard,intr,rsize=32768,wsize=32768 0 0\n\n\n\nImportant:\n Do not use multiple NFS shares for different parts of the Opencast storage dir. Opencast will check if\nhard links are possible across in a distributed set-up, but the detection may fail if hard links are only possible\nbetween certain parts of the storage. This may lead to failures.\n\n\nImportant:\n Do not share the Karaf data directory. Doing so will cause Opencast to fail. Please share the storage\ndirectory only.\n\n\nStep 3: Set-Up the Database\n\n\nFirst make sure to follow the \nregular database set-up\n.\n\n\nDo not forget to set the user also for the remote servers and grant them the necessary rights. Additionally, you need to\nconfigure your firewall:\n\n\n-A INPUT -p tcp -s 131.173.172.190 --dport 3306 -m state --state NEW,ESTABLISHED -j ACCEPT\n\n\n\nStep 4: Set-Up ActiveMQ\n\n\nSince version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user\ninterface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the\nadmin node).\n\n\nActiveMQ 5.10 or above should work. ActiveMQ 5.6 will not work. Versions in between are untested.\n\n\nInstallation\n\n\n\n\nIf you use the Opencast RPM repository, simply install the \nactivemq-dist\n package.\n\n\nIf you are running RHEL, CentOS or Fedora you can use the \nActiveMQ-dist Copr RPM repository\n   \n\n\nYou can download binary distributions from the \nApache ActiveMQ website\n\n\n\n\nConfiguration\n\n\nWhat you basically need to do is to point all your Opencast nodes to your message broker. For more information about\nthe configuration, have a look at the \nMessage Broker Set-Up Guide\n.\n\n\nDo not forget that ActiveMQ uses TCP port 61616 (default configuration) for communication which you might have to allow\nin your firewall.\n\n\nStep 5: Configure Opencast\n\n\nYou did already set-up and configured your database and message broker in the last steps, but there is some more\nconfiguration you have to do. First of all you should follow the Basic Configuration guide which will tell you how to\nset the login credentials etc. After that continue with the following steps:\n\n\ncustom.properties\n\n\nSet the server URL to the public url of each server (admin URL on admin, worker URL on worker, engage URL on engage, \u2026).\nThis may either be this nodes IP address or preferable its domain name:\n\n\norg.opencastproject.server.url=http://<URL>:8080\n\n\n\nSet the location of the shared storage directory:\n\n\norg.opencastproject.storage.dir=/srv/opencast\n\n\n\nDefine that the file repository shall access all files locally:\n\n\norg.opencastproject.file.repo.url=${org.opencastproject.admin.ui.url}\n\n\n\norg.opencastproject.organization-mh_default_org.cfg\n\n\nSet the base URL of the server hosting the administrative tools. Again use a domain name instead of an IP address if\npossible:\n\n\norg.opencastproject.admin.ui.url=http://<ADMIN-URL>:8080\n\n\n\nSet the base URL of the server hosting the engage tools:\n\n\norg.opencastproject.engage.ui.url=http://<ENGAGE-URL>:8080\n\n\n\norg.opencastproject.serviceregistry.impl.ServiceRegistryJpaImpl.cfg\n\n\nTo ensure that jobs are not dispatched by non-admin nodes you may also want to set:\n\n\ndispatchinterval=0",
            "title": "Multiple Servers"
        },
        {
            "location": "/installation/multiple-servers/#install-across-multiple-servers",
            "text": "Note that this is not a comprehensive guide of all possible ways to install Opencast. It is more like a guide to good\npractices and presents what a lot of people are running.",
            "title": "Install Across Multiple Servers"
        },
        {
            "location": "/installation/multiple-servers/#step-1-install-opencast",
            "text": "Opencast consists of a large set of modules which together build the whole system. In a distributed set-up, different\nkinds of nodes are basically only defined by the existence or absence of specific modules.  While it is possible to stick together a system module by module, opencast comes with a set of pre-defined distribution\nwhich can directly be built and installed. To build these distributions, you would compile Opencast just like it is\noutlined in the basic installation guides and will then find a set of different distributions, both as archive and in a\nseparate directory.  To list all distributions, run the following command after Opencast is built:  % ls -1 build/*.tar.gz\nbuild/opencast-dist-admin-${version}.tar.gz\nbuild/opencast-dist-allinone-${version}.tar.gz\nbuild/opencast-dist-presentation-${version}.tar.gz\nbuild/opencast-dist-worker-${version}.tar.g\n...  The same distributions can be found in the packages provided in the Opencast RPM repository.  These packages will\nautomatically install all dependencies for a given node type. For example, to install an Opencast worker node, you would\ninstall the package  opencast21-distribution-worker .  The following list describes possible set-ups:",
            "title": "Step 1: Install Opencast"
        },
        {
            "location": "/installation/multiple-servers/#all-in-one",
            "text": "This is the default set-up described in the basic installation guides. It works fine for testing purposes. It should\nusually not be used in production. It is not distributed but is listed here to have a comprehensive list of predefined\ndistributions.",
            "title": "All-In-One"
        },
        {
            "location": "/installation/multiple-servers/#two-server-set-up",
            "text": "This set-up is the minimum set-up recommended for productive use. It will separate the presentation layer from the\nadministrative and working layer. This means that even if one server is under heavy load while videos are processed, it\nwill not effect the distribution and users should still be able to watch videos smoothly. However, it might happen that\nunder heavy load the handling of the administrative user interface gets a bit rough.",
            "title": "Two-Server Set-up"
        },
        {
            "location": "/installation/multiple-servers/#three-or-more-server-set-up",
            "text": "While in the last example we have created one combined node for both the administrative tools and the workers, in this\nexample we will split it into dedicated worker and admin nodes. Using this set-up it is easy to increase the systems\nperformance simply by adding further worker nodes to the system.",
            "title": "Three (or more) Server Set-up"
        },
        {
            "location": "/installation/multiple-servers/#step-2-set-up-nfs-server",
            "text": "Though it is possible to have Opencast run without shared storage, it is still a good idea to do so, as hard links can\nbe used to link files instead of copying them and not everything has to be tunneled over HTTP.  Thus you should first set-up your NFS server. The best solution is certainly to have a dedicated storage server. For\nsmaller set-ups, however, it can also be put on one of the Opencast nodes, i.e. on the admin node.  To do this, you first have to install and enable the NFS server:  yum install nfs-utils nfs-utils-lib\nchkconfig  --level 345 nfs on\nservice nfs start  You want to have one common user on all your systems, so that file permissions do not become an issue.. As preparation\nfor this it makes sense to manually create an  opencast  user and group with a common UID and GID:  groupadd -g 1234 opencast\nuseradd -g 1234 -u 1234 opencast  If the user and group id  1234  is already used, just pick another one but make sure to pick the same one on all your\nOpencast nodes.  Then create the directory to be shared and set its ownership to the newly created users:  mkdir -p /srv/opencast\nchown opencast:opencast /srv/opencast  Next we actually share the storage dir. For this we need to edit the file  /etc/exports  and set:  /srv/opencast  131.173.172.190(rw,sync,no_subtree_check)  with 131.173.172.190 being the IP address of the other machine that should get access. Finally we enable the share with:  exportfs -a  Of cause you have to open the necessary ports in your firewall configuration.  For iptables, appropriate rules could be\nfor example:  -A INPUT -m state --state NEW -p tcp -m multiport --dport 111,892,2049,32803 -j ACCEPT\n-A INPUT -m state --state NEW -p udp -m multiport --dport 111,892,2049,32803 -j ACCEPT  You can set them by editing  /etc/sysconfig/iptables  and restarting the service afterwards.  Now you have set-up your storage server. What is still left to do is to mount the network storage on all other servers\nof the Opencast clusters except the capture agents. To do that you need to edit the  /etc/fstab  on each server and add\nthe command to mount the network storage on startup:  storageserver.example.com:/srv/opencast /srv/opencast   nfs rw,hard,intr,rsize=32768,wsize=32768 0 0  Important:  Do not use multiple NFS shares for different parts of the Opencast storage dir. Opencast will check if\nhard links are possible across in a distributed set-up, but the detection may fail if hard links are only possible\nbetween certain parts of the storage. This may lead to failures.  Important:  Do not share the Karaf data directory. Doing so will cause Opencast to fail. Please share the storage\ndirectory only.",
            "title": "Step 2: Set-Up NFS Server"
        },
        {
            "location": "/installation/multiple-servers/#step-3-set-up-the-database",
            "text": "First make sure to follow the  regular database set-up .  Do not forget to set the user also for the remote servers and grant them the necessary rights. Additionally, you need to\nconfigure your firewall:  -A INPUT -p tcp -s 131.173.172.190 --dport 3306 -m state --state NEW,ESTABLISHED -j ACCEPT",
            "title": "Step 3: Set-Up the Database"
        },
        {
            "location": "/installation/multiple-servers/#step-4-set-up-activemq",
            "text": "Since version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user\ninterface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the\nadmin node).  ActiveMQ 5.10 or above should work. ActiveMQ 5.6 will not work. Versions in between are untested.",
            "title": "Step 4: Set-Up ActiveMQ"
        },
        {
            "location": "/installation/multiple-servers/#installation",
            "text": "If you use the Opencast RPM repository, simply install the  activemq-dist  package.  If you are running RHEL, CentOS or Fedora you can use the  ActiveMQ-dist Copr RPM repository\n     You can download binary distributions from the  Apache ActiveMQ website",
            "title": "Installation"
        },
        {
            "location": "/installation/multiple-servers/#configuration",
            "text": "What you basically need to do is to point all your Opencast nodes to your message broker. For more information about\nthe configuration, have a look at the  Message Broker Set-Up Guide .  Do not forget that ActiveMQ uses TCP port 61616 (default configuration) for communication which you might have to allow\nin your firewall.",
            "title": "Configuration"
        },
        {
            "location": "/installation/multiple-servers/#step-5-configure-opencast",
            "text": "You did already set-up and configured your database and message broker in the last steps, but there is some more\nconfiguration you have to do. First of all you should follow the Basic Configuration guide which will tell you how to\nset the login credentials etc. After that continue with the following steps:",
            "title": "Step 5: Configure Opencast"
        },
        {
            "location": "/installation/multiple-servers/#customproperties",
            "text": "Set the server URL to the public url of each server (admin URL on admin, worker URL on worker, engage URL on engage, \u2026).\nThis may either be this nodes IP address or preferable its domain name:  org.opencastproject.server.url=http://<URL>:8080  Set the location of the shared storage directory:  org.opencastproject.storage.dir=/srv/opencast  Define that the file repository shall access all files locally:  org.opencastproject.file.repo.url=${org.opencastproject.admin.ui.url}",
            "title": "custom.properties"
        },
        {
            "location": "/installation/multiple-servers/#orgopencastprojectorganization-mh_default_orgcfg",
            "text": "Set the base URL of the server hosting the administrative tools. Again use a domain name instead of an IP address if\npossible:  org.opencastproject.admin.ui.url=http://<ADMIN-URL>:8080  Set the base URL of the server hosting the engage tools:  org.opencastproject.engage.ui.url=http://<ENGAGE-URL>:8080",
            "title": "org.opencastproject.organization-mh_default_org.cfg"
        },
        {
            "location": "/installation/multiple-servers/#orgopencastprojectserviceregistryimplserviceregistryjpaimplcfg",
            "text": "To ensure that jobs are not dispatched by non-admin nodes you may also want to set:  dispatchinterval=0",
            "title": "org.opencastproject.serviceregistry.impl.ServiceRegistryJpaImpl.cfg"
        },
        {
            "location": "/installation/source-debian-ubuntu/",
            "text": "Install from Source (Debian, Ubuntu)\n\n\nThese instructions outline how to install an all in one Opencast system on Ubuntu 12.04 with LTS.\n\n\nPreparation\n\n\nCreate a dedicated Opencast user:\n\n\nuseradd -d /opt/opencast opencast\n\n\n\nGet Opencast source:\n\n\nYou can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git\nrepository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The\nprior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git.\n\n\nUsing the tarball:\n\n\nSelect the tarball for the version you want to install from the \nBitBucket downloads section\n\n.\n\n\n# Download desired tarball\ncurl -O https://bitbucket.org/opencast-community/matterhorn/...\ntar xf ....tar.gz\ncd opencast-community-...\n\n\n\nCloning the Git repository:\n\n\ngit clone https://bitbucket.org/opencast-community/matterhorn.git\ncd matterhorn\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version\n\n\n\nInstall Dependencies\n\n\nPlease make sure to install the following dependencies. Note that not all dependencies are in the system repositories.\n\n\nRequired:\n\n\nopenjdk-7-jdk or openjdk-8-jdk\nffmpeg >= 2.8\nmaven >= 3.1\n\n\n\nRequired (not necessarily on the same machine):\n\n\nActiveMQ >= 5.10 (older versions untested)\n\n\n\nRequired for text extraction (recommended):\n\n\ntesseract >= 3\n\n\n\nRequired for hunspell based text filtering (optional):\n\n\nhunspell >= 1.2.8\n\n\n\nRequired for audio normalization (optional):\n\n\nsox >= 14.4\n\n\n\nDependency Download\n\n\nPre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project\nwebsite:\n\n\n\n\nGet FFmpeg\n\n\nGet Apache Maven\n\n\nGet Apache ActiveMQ\n\n\n\n\nBuilding Opencast\n\n\nAutomatically build all Opencast modules and assemble distributions for different server types:\n\n\ncd opencast-dir\nmvn clean install\n\n\n\nDeploy all-in-one distribution:\n\n\ncd build/\nmv opencast-dist-allinone-*/ /opt/opencast\n\n\n\nMake sure everything belongs to the user \nopencast\n:\n\n\nsudo chown -R opencast:opencast /opt/opencast\n\n\n\nConfigure\n\n\nPlease follow the steps of the \nBasic Configuration guide\n. It will help you to set your\nhostname, login information, \u2026\n\n\nRunning Opencast\n\n\nTo start Opencast, run \n.../bin/start-opencast\n as user \nopencast\n:\n\n\nsudo -u opencast /opt/opencast/bin/start-opencast\n\n\n\nAs soon as Opencast is completely started, browse to \nhttp://localhost:8080\n to get to the\nadministration interface.\n\n\nRun Opencast as a service\n\n\nUsually, you do not want to run Opencast in interactive mode but as system service to make sure it is only running\nonce on a system and is started automatically.\n\n\nYou will find service files for Opencast in \ndocs/scripts/service/{opt,system}/\n.\n\n\nUsing Systemd\n\n\nMake sure the path to Opencast is set correctly:\n\n\nvim docs/scripts/service/opencast.service\n\n\n\nInstall the unit file:\n\n\ncp docs/scripts/service/opencast.service /usr/lib/systemd/system/\nsystemctl daemon-reload\n\n\n\nStart Opencast and make it run automatically:\n\n\nsystemctl start opencast.service\nsystemctl enable opencast.service\n\n\n\nUsing SysV-Init\n\n\n\n\nNote that this option is for compatibility to older systems. If you have the choice of either using the Systemd unit\nfile or the Init script, it is recommended to use the Systemd unit file.\n\n\n\n\nMake sure the path to Opencast is set correctly:\n\n\nvim docs/scripts/service/etc-init.d-opencast\n\n\n\n\n\n\n\nInstall init script:\n\n\ncp docs/scripts/service/etc-init.d-opencast /etc/init.d/opencast\n\n\n\n\n\n\n\nEnable service using \nchkconfig\n or \nupdate-rc.d\n\n\n\n\n\n\nStart Opencast using\n\n\nservice opencast start",
            "title": "Debian/Ubuntu"
        },
        {
            "location": "/installation/source-debian-ubuntu/#install-from-source-debian-ubuntu",
            "text": "These instructions outline how to install an all in one Opencast system on Ubuntu 12.04 with LTS.",
            "title": "Install from Source (Debian, Ubuntu)"
        },
        {
            "location": "/installation/source-debian-ubuntu/#preparation",
            "text": "Create a dedicated Opencast user:  useradd -d /opt/opencast opencast  Get Opencast source:  You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git\nrepository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The\nprior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git.  Using the tarball:  Select the tarball for the version you want to install from the  BitBucket downloads section .  # Download desired tarball\ncurl -O https://bitbucket.org/opencast-community/matterhorn/...\ntar xf ....tar.gz\ncd opencast-community-...  Cloning the Git repository:  git clone https://bitbucket.org/opencast-community/matterhorn.git\ncd matterhorn\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version",
            "title": "Preparation"
        },
        {
            "location": "/installation/source-debian-ubuntu/#install-dependencies",
            "text": "Please make sure to install the following dependencies. Note that not all dependencies are in the system repositories.  Required:  openjdk-7-jdk or openjdk-8-jdk\nffmpeg >= 2.8\nmaven >= 3.1  Required (not necessarily on the same machine):  ActiveMQ >= 5.10 (older versions untested)  Required for text extraction (recommended):  tesseract >= 3  Required for hunspell based text filtering (optional):  hunspell >= 1.2.8  Required for audio normalization (optional):  sox >= 14.4",
            "title": "Install Dependencies"
        },
        {
            "location": "/installation/source-debian-ubuntu/#dependency-download",
            "text": "Pre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project\nwebsite:   Get FFmpeg  Get Apache Maven  Get Apache ActiveMQ",
            "title": "Dependency Download"
        },
        {
            "location": "/installation/source-debian-ubuntu/#building-opencast",
            "text": "Automatically build all Opencast modules and assemble distributions for different server types:  cd opencast-dir\nmvn clean install  Deploy all-in-one distribution:  cd build/\nmv opencast-dist-allinone-*/ /opt/opencast  Make sure everything belongs to the user  opencast :  sudo chown -R opencast:opencast /opt/opencast",
            "title": "Building Opencast"
        },
        {
            "location": "/installation/source-debian-ubuntu/#configure",
            "text": "Please follow the steps of the  Basic Configuration guide . It will help you to set your\nhostname, login information, \u2026",
            "title": "Configure"
        },
        {
            "location": "/installation/source-debian-ubuntu/#running-opencast",
            "text": "To start Opencast, run  .../bin/start-opencast  as user  opencast :  sudo -u opencast /opt/opencast/bin/start-opencast  As soon as Opencast is completely started, browse to  http://localhost:8080  to get to the\nadministration interface.",
            "title": "Running Opencast"
        },
        {
            "location": "/installation/source-debian-ubuntu/#run-opencast-as-a-service",
            "text": "Usually, you do not want to run Opencast in interactive mode but as system service to make sure it is only running\nonce on a system and is started automatically.  You will find service files for Opencast in  docs/scripts/service/{opt,system}/ .",
            "title": "Run Opencast as a service"
        },
        {
            "location": "/installation/source-debian-ubuntu/#using-systemd",
            "text": "Make sure the path to Opencast is set correctly:  vim docs/scripts/service/opencast.service  Install the unit file:  cp docs/scripts/service/opencast.service /usr/lib/systemd/system/\nsystemctl daemon-reload  Start Opencast and make it run automatically:  systemctl start opencast.service\nsystemctl enable opencast.service",
            "title": "Using Systemd"
        },
        {
            "location": "/installation/source-debian-ubuntu/#using-sysv-init",
            "text": "Note that this option is for compatibility to older systems. If you have the choice of either using the Systemd unit\nfile or the Init script, it is recommended to use the Systemd unit file.   Make sure the path to Opencast is set correctly:  vim docs/scripts/service/etc-init.d-opencast    Install init script:  cp docs/scripts/service/etc-init.d-opencast /etc/init.d/opencast    Enable service using  chkconfig  or  update-rc.d    Start Opencast using  service opencast start",
            "title": "Using SysV-Init"
        },
        {
            "location": "/installation/source-rhel-sl-centos/",
            "text": "Install from Source (RedHat Enterprise Linux, CentOS, Scientific Linux, Fedora)\n\n\nPreparation\n\n\nCreate a dedicated Opencast user:\n\n\nuseradd -d /opt/opencast opencast\n\n\n\nGet Opencast source:\n\n\nYou can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git\nrepository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The\nprior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git.\n\n\nUsing the tarball:\n\n\nSelect the tarball for the version you want to install from the \nBitBucket downloads section\n\n.\n\n\n# Download desired tarball\ncurl -O https://bitbucket.org/opencast-community/matterhorn/...\ntar xf ....tar.gz\ncd opencast-community-...\n\n\n\nCloning the Git repository:\n\n\ngit clone https://bitbucket.org/opencast-community/matterhorn.git\ncd matterhorn\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version\n\n\n\nInstall Dependencies\n\n\nPlease make sure to install the following dependencies. Note that not all dependencies are in the system repositories.\n\n\nRequired:\n\n\njava-devel >= 1:1.7.0\nffmpeg >= 2.8\nmaven >= 3.1\n\n\n\nRequired (not necessarily on the same machine):\n\n\nActiveMQ >= 5.10 (older versions untested)\n\n\n\nRequired for text extraction (recommended):\n\n\ntesseract >= 3\n\n\n\nRequired for hunspell based text filtering (optional):\n\n\nhunspell >= 1.2.8\n\n\n\nRequired for audio normalization (optional):\n\n\nsox >= 14.4\n\n\n\nDependency Download\n\n\nPre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project\nwebsite:\n\n\n\n\nGet FFmpeg\n\n\nGet Apache Maven\n\n\nGet Apache ActiveMQ\n\n\n\n\nBuilding Opencast\n\n\nAutomatically build all Opencast modules and assemble distributions for different server types:\n\n\ncd opencast-dir\nmvn clean install\n\n\n\nDeploy all-in-one distribution:\n\n\ncd build/\nmv opencast-dist-allinone-*/ /opt/opencast\n\n\n\nMake sure everything belongs to the user \nopencast\n:\n\n\nsudo chown -R opencast:opencast /opt/opencast\n\n\n\nConfigure\n\n\nPlease follow the steps of the \nBasic Configuration guide\n. It will help you to set your\nhostname, login information, \u2026\n\n\nRunning Opencast\n\n\nTo start Opencast, run \n.../bin/start-opencast\n as user \nopencast\n:\n\n\nsudo -u opencast /opt/opencast/bin/start-opencast\n\n\n\nAs soon as Opencast is completely started, browse to \nhttp://localhost:8080\n to get to the\nadministration interface.\n\n\nRun Opencast as a service\n\n\nUsually, you do not want to run Opencast in interactive mode but as system service to make sure it is only running\nonce on a system and is started automatically.\n\n\nYou will find service files for Opencast in \ndocs/scripts/service/{opt,system}/\n.\n\n\nUsing Systemd\n\n\nMake sure the path to Opencast is set correctly:\n\n\nvim docs/scripts/service/opencast.service\n\n\n\nInstall the unit file:\n\n\ncp docs/scripts/service/opencast.service /usr/lib/systemd/system/\nsystemctl daemon-reload\n\n\n\nStart Opencast and make it run automatically:\n\n\nsystemctl start opencast.service\nsystemctl enable opencast.service\n\n\n\nUsing SysV-Init\n\n\n\n\nNote that this option is for compatibility to older systems. If you have the choice of either using the Systemd unit\nfile or the Init script, it is recommended to use the Systemd unit file.\n\n\n\n\nMake sure the path to Opencast is set correctly:\n\n\nvim docs/scripts/service/etc-init.d-opencast\n\n\n\n\n\n\n\nInstall init script:\n\n\ncp docs/scripts/service/etc-init.d-opencast /etc/init.d/opencast\n\n\n\n\n\n\n\nEnable service using \nchkconfig\n or \nupdate-rc.d\n\n\n\n\n\n\nStart Opencast using\n\n\nservice opencast start",
            "title": "RHEL/CentOS"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#install-from-source-redhat-enterprise-linux-centos-scientific-linux-fedora",
            "text": "",
            "title": "Install from Source (RedHat Enterprise Linux, CentOS, Scientific Linux, Fedora)"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#preparation",
            "text": "Create a dedicated Opencast user:  useradd -d /opt/opencast opencast  Get Opencast source:  You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git\nrepository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The\nprior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git.  Using the tarball:  Select the tarball for the version you want to install from the  BitBucket downloads section .  # Download desired tarball\ncurl -O https://bitbucket.org/opencast-community/matterhorn/...\ntar xf ....tar.gz\ncd opencast-community-...  Cloning the Git repository:  git clone https://bitbucket.org/opencast-community/matterhorn.git\ncd matterhorn\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version",
            "title": "Preparation"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#install-dependencies",
            "text": "Please make sure to install the following dependencies. Note that not all dependencies are in the system repositories.  Required:  java-devel >= 1:1.7.0\nffmpeg >= 2.8\nmaven >= 3.1  Required (not necessarily on the same machine):  ActiveMQ >= 5.10 (older versions untested)  Required for text extraction (recommended):  tesseract >= 3  Required for hunspell based text filtering (optional):  hunspell >= 1.2.8  Required for audio normalization (optional):  sox >= 14.4",
            "title": "Install Dependencies"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#dependency-download",
            "text": "Pre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project\nwebsite:   Get FFmpeg  Get Apache Maven  Get Apache ActiveMQ",
            "title": "Dependency Download"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#building-opencast",
            "text": "Automatically build all Opencast modules and assemble distributions for different server types:  cd opencast-dir\nmvn clean install  Deploy all-in-one distribution:  cd build/\nmv opencast-dist-allinone-*/ /opt/opencast  Make sure everything belongs to the user  opencast :  sudo chown -R opencast:opencast /opt/opencast",
            "title": "Building Opencast"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#configure",
            "text": "Please follow the steps of the  Basic Configuration guide . It will help you to set your\nhostname, login information, \u2026",
            "title": "Configure"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#running-opencast",
            "text": "To start Opencast, run  .../bin/start-opencast  as user  opencast :  sudo -u opencast /opt/opencast/bin/start-opencast  As soon as Opencast is completely started, browse to  http://localhost:8080  to get to the\nadministration interface.",
            "title": "Running Opencast"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#run-opencast-as-a-service",
            "text": "Usually, you do not want to run Opencast in interactive mode but as system service to make sure it is only running\nonce on a system and is started automatically.  You will find service files for Opencast in  docs/scripts/service/{opt,system}/ .",
            "title": "Run Opencast as a service"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#using-systemd",
            "text": "Make sure the path to Opencast is set correctly:  vim docs/scripts/service/opencast.service  Install the unit file:  cp docs/scripts/service/opencast.service /usr/lib/systemd/system/\nsystemctl daemon-reload  Start Opencast and make it run automatically:  systemctl start opencast.service\nsystemctl enable opencast.service",
            "title": "Using Systemd"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#using-sysv-init",
            "text": "Note that this option is for compatibility to older systems. If you have the choice of either using the Systemd unit\nfile or the Init script, it is recommended to use the Systemd unit file.   Make sure the path to Opencast is set correctly:  vim docs/scripts/service/etc-init.d-opencast    Install init script:  cp docs/scripts/service/etc-init.d-opencast /etc/init.d/opencast    Enable service using  chkconfig  or  update-rc.d    Start Opencast using  service opencast start",
            "title": "Using SysV-Init"
        },
        {
            "location": "/installation/source-macosx/",
            "text": "Install from Source (Mac OS X)\n\n\nThese instructions outline how to install an all in one Opencast system on the Mac OS X operating system.\nTested on OS X 10.9 Mavericks.\n\n\n\n\nThe installation on Mac OS X is not officially supported. Use this at your own risk.\n\n\n\n\nPreparation\n\n\nOpen a Terminal and switch to the directory, in which the Opencast installation should be placed, e.g. \n/opt/\n, \n~/develop/\n or whatever you prefer.\n\n\nGet Opencast source\n\n\nYou can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git repository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The prior option, the tarball download, needs less tools and you don't have to download nearly as much as with Git.\n\n\nCloning the Git repository:\n\n\ngit clone https://bitbucket.org/opencast-community/matterhorn.git\ncd matterhorn\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version\n\n\n\nUsing the tarball:\n\n\nSelect the tarball for the version you want to install from the \nBitBucket downloads section\n\n under the \"Tags\" tab and download it directly from there or with the curl command specified below.\n\n\n# Download desired tarball, replace [...] with the desired version\ncurl -O https://bitbucket.org/opencast-community/matterhorn/get/[...].tar.gz\ntar xf [...].tar.gz\n\n\n\nInstall Dependencies\n\n\nPlease make sure to install the following dependencies.\n\n\nRequired:\n\n\nXcode\njdk 7 or jdk 8 (recommended)\nffmpeg >= 2.8\nmaven >= 3.1\n\n\n\nRequired (not necessarily on the same machine):\n\n\nActiveMQ >= 5.10 (older versions untested)\n\n\n\nRequired for text extraction:\n\n\ntesseract >= 3\n\n\n\nRequired for hunspell based text filtering:\n\n\nhunspell >= 1.2.8\n\n\n\nRequired for audio normalization:\n\n\nsox >= 14.4 (with MP3, FLAC and OGG support)\n\n\n\nDependency Download\n\n\nYou can download Xcode in the Mac App Store. JDK 8 for OS X is available from \nOracle\n.\n\n\nUsing Homebrew\n\n\nHomebrew is a package manager for OS X. For installation instruction see \ntheir website\n.\n\n\nbrew install maven\nbrew install ffmpeg\nbrew install apache-activemq\n\nbrew install tesseract\nbrew install hunspell\nbrew install sox --with-lame --with-flac --with-libvorbis\n\n\n\nUsing pre-built binaries\n\n\nPre-built versions of most dependencies can be downloaded from the respective project website:\n\n\n\n\nGet Apache Maven\n\n\nGet FFmpeg\n\n\nGet Apache ActiveMQ\n\n\n\n\nBuilding Opencast\n\n\nSwitch to the opencast folder. If you downloaded the tarball, this is the folder you just unpacked (called something like \nopencast-community-matterhorn-[...]\n). If you chose to download via git, use \ncd matterhorn\n. You can proceed by building opencast (depending on the folder permissions, you might need to start the command with \nsudo\n):\n\n\nmvn clean install\n\n\n\n\n\nPlease be patient, as building Opencast for the first time will take quite long.\n\n\n\n\nConfigure\n\n\nPlease follow the steps of the \nBasic Configuration guide\n. It will help you to set your host name, login information, etc. Be aware that the config files now reside in the build folders for the desired distribution. For the allinone distribution, this would be \n/your/path/to/opencast/build/opencast-dist-allinone-[...]/etc/\n, again with \n[...]\n representing the selected version.\nAs specified in the guide, make sure you replace the default ActiveMQ configuration with the one provided in \ndocs/scripts/activemq/activemq.xml\n. If you installed ActiveMQ using homebrew, you can find the installation path with \nbrew info activemq\n.\n\n\nRunning Opencast\n\n\nMake sure you have ActiveMQ running (unless you're running it on a different machine). Then you can start Opencast using the start-opencast script:\n\n\nactivemq start\ncd /your/path/to/opencast/\ncd build/opencast-dist-allinone-[...]\n./bin/start-opencast",
            "title": "MacOS X"
        },
        {
            "location": "/installation/source-macosx/#install-from-source-mac-os-x",
            "text": "These instructions outline how to install an all in one Opencast system on the Mac OS X operating system.\nTested on OS X 10.9 Mavericks.   The installation on Mac OS X is not officially supported. Use this at your own risk.",
            "title": "Install from Source (Mac OS X)"
        },
        {
            "location": "/installation/source-macosx/#preparation",
            "text": "Open a Terminal and switch to the directory, in which the Opencast installation should be placed, e.g.  /opt/ ,  ~/develop/  or whatever you prefer.",
            "title": "Preparation"
        },
        {
            "location": "/installation/source-macosx/#get-opencast-source",
            "text": "You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git repository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The prior option, the tarball download, needs less tools and you don't have to download nearly as much as with Git.  Cloning the Git repository:  git clone https://bitbucket.org/opencast-community/matterhorn.git\ncd matterhorn\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version  Using the tarball:  Select the tarball for the version you want to install from the  BitBucket downloads section  under the \"Tags\" tab and download it directly from there or with the curl command specified below.  # Download desired tarball, replace [...] with the desired version\ncurl -O https://bitbucket.org/opencast-community/matterhorn/get/[...].tar.gz\ntar xf [...].tar.gz",
            "title": "Get Opencast source"
        },
        {
            "location": "/installation/source-macosx/#install-dependencies",
            "text": "Please make sure to install the following dependencies.  Required:  Xcode\njdk 7 or jdk 8 (recommended)\nffmpeg >= 2.8\nmaven >= 3.1  Required (not necessarily on the same machine):  ActiveMQ >= 5.10 (older versions untested)  Required for text extraction:  tesseract >= 3  Required for hunspell based text filtering:  hunspell >= 1.2.8  Required for audio normalization:  sox >= 14.4 (with MP3, FLAC and OGG support)",
            "title": "Install Dependencies"
        },
        {
            "location": "/installation/source-macosx/#dependency-download",
            "text": "You can download Xcode in the Mac App Store. JDK 8 for OS X is available from  Oracle .",
            "title": "Dependency Download"
        },
        {
            "location": "/installation/source-macosx/#using-homebrew",
            "text": "Homebrew is a package manager for OS X. For installation instruction see  their website .  brew install maven\nbrew install ffmpeg\nbrew install apache-activemq\n\nbrew install tesseract\nbrew install hunspell\nbrew install sox --with-lame --with-flac --with-libvorbis",
            "title": "Using Homebrew"
        },
        {
            "location": "/installation/source-macosx/#using-pre-built-binaries",
            "text": "Pre-built versions of most dependencies can be downloaded from the respective project website:   Get Apache Maven  Get FFmpeg  Get Apache ActiveMQ",
            "title": "Using pre-built binaries"
        },
        {
            "location": "/installation/source-macosx/#building-opencast",
            "text": "Switch to the opencast folder. If you downloaded the tarball, this is the folder you just unpacked (called something like  opencast-community-matterhorn-[...] ). If you chose to download via git, use  cd matterhorn . You can proceed by building opencast (depending on the folder permissions, you might need to start the command with  sudo ):  mvn clean install   Please be patient, as building Opencast for the first time will take quite long.",
            "title": "Building Opencast"
        },
        {
            "location": "/installation/source-macosx/#configure",
            "text": "Please follow the steps of the  Basic Configuration guide . It will help you to set your host name, login information, etc. Be aware that the config files now reside in the build folders for the desired distribution. For the allinone distribution, this would be  /your/path/to/opencast/build/opencast-dist-allinone-[...]/etc/ , again with  [...]  representing the selected version.\nAs specified in the guide, make sure you replace the default ActiveMQ configuration with the one provided in  docs/scripts/activemq/activemq.xml . If you installed ActiveMQ using homebrew, you can find the installation path with  brew info activemq .",
            "title": "Configure"
        },
        {
            "location": "/installation/source-macosx/#running-opencast",
            "text": "Make sure you have ActiveMQ running (unless you're running it on a different machine). Then you can start Opencast using the start-opencast script:  activemq start\ncd /your/path/to/opencast/\ncd build/opencast-dist-allinone-[...]\n./bin/start-opencast",
            "title": "Running Opencast"
        },
        {
            "location": "/installation/rpm-fedora/",
            "text": "Install from Repository (Fedora)\n\n\nThere is an RPM software repository available for RedHat-based Linux distributions provided by the University of\nOsnabr\u00fcck. This repository provides preconfigured Opencast installations, including all 3rd-Party-Tools. Using this\nmethod, you do not have to compile the software by yourself.\n\n\nIt may also be interesting for developers as all dependencies for Opencast usage, testing and development are provided\nby the RPM repository.\n\n\nSupported Versions\n\n\nFor Fedora usually the latest two versions are supported, meaning that the support is dependent on the status of the\nFedora release. For architectures, \nonly\n \nx86_64\n is supported. 32bit architectures are \nnot\n supported.\n\n\nRegistration\n\n\nBefore you can start you need to get an account for the repository. You will need the credentials that you get by mail\nafter the registration to successfully complete this manual. The placeholders \n[your_username]\n and \n[your_password]\n\nare used in this manual wherever the credentials are needed.\n\n\n\n\nhttp://repo.virtuos.uos.de\n\n\n\n\nActivate Repository\n\n\nFirst you have to install the necessary repositories so that your package manager can access them:\n\n\n\n\n\n\nAdd Opencast repository:\n\n\ncd /etc/yum.repos.d\ncurl -O http://repo.virtuos.uos.de/opencast-testing.repo \\\n  -d 'version=$releasever' -d os=fc \\\n  -u [your_username]:[your_password]\n\n\n\n\n\n\n\nAdd RPMfusion repository:\n\n\ndnf install --nogpgcheck \\\n  http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm \\\n  http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm\n\n\n\n\n\n\n\nInstall 3rd-party-tools\n\n\nThis step is optional and only recommended for those who want to build Opencast from source. If you install Opencast\nfrom the repository, all necessary dependencies will be installed automatically.\n\n\nYou can install all necessary 3rd-Party-Tools for Opencast like this:\n\n\ndnf install ffmpeg-recent tesseract hunspell sox\n\n\n\nInstall Apache ActiveMQ\n\n\nThe Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be\ninstalled on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the\nOpencast RPM repository as well and can be installed by running:\n\n\ndnf install activemq-dist\n\n\n\nA prepared configuration file for ActiveMQ can be found at \n/usr/share/opencast/docs/scripts/activemq/activemq.xml\n\n\nafter Opencast itself has been installed\n and should replace \n/etc/activemq/activemq.xml\n. For an all-in-one\ninstallation the following command should suffice:\n\n\ncp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml\n\n\n\nActiveMQ should be started \nprior to\n Opencast.\n\n\nMore information about how to properly set up ActiveMQ for Opencast can be found in the \nmessage broker configuration\ndocumentation\n.\n\n\nInstall Opencast\n\n\nFor this guide, \nopencast21-*\n is used as placeholder for the package name. It will install the latest version of the\nOpencast 2.1.x branch. If you want to install another version, please change the name accordingly.\n\n\nBasic Installation\n\n\nFor a basic installation (All-In-One) just run:\n\n\ndnf install opencast21-allinone\n\n\n\nThis will install the default distribution of Opencast and all its dependencies, including the 3rd-Party-Tools.\n\n\nNow you can start Opencast:\n\n\nsystemctl start opencast.service\n\n\n\nWhile Opencast is preconfigured, it is strongly recommended to follow at least the \nBasic Configuration\nguide\n. It will help you to set your hostname, login information, \u2026\n\n\nAdvanced Installation\n\n\nWhile the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might\nwant to have more control over your system and deploy it over several machines by choosing which parts of Opencast you\nwant to install. You can list all Opencast packages with:\n\n\ndnf search opencast\n\n\n\nStarting with Opencast 2.1, this will list all available Opencast distributions in the form\n\nopencast<version>-<dist-type>\n\n\nCurrent available distributions are:\n\n\n\n\nopencast21-allinone\n\n\nopencast21-admin\n\n\nopencast21-worker\n\n\nopencast21-presentation\n\n\n\n\nUninstall Opencast\n\n\nSometimes you want to uninstall Opencast. For example to do a clean reinstall. You can do that by executing:\n\n\ndnf remove opencast\n\n\n\nThis will not touch your created media files or modified configuration files.  If you want to remove them as well, you\nhave to to that by yourself.\n\n\n# Remove media files\nsudo rm -rf /srv/opencast\n\n# Remove local db, search index and working files\nsudo rm -rf /var/lib/opencast\n\n# Remove configuration files\nsudo rm -rf /etc/opencast\n\n# Remove system logfiles\nsudo rm -rf /var/log/opencast",
            "title": "Fedora"
        },
        {
            "location": "/installation/rpm-fedora/#install-from-repository-fedora",
            "text": "There is an RPM software repository available for RedHat-based Linux distributions provided by the University of\nOsnabr\u00fcck. This repository provides preconfigured Opencast installations, including all 3rd-Party-Tools. Using this\nmethod, you do not have to compile the software by yourself.  It may also be interesting for developers as all dependencies for Opencast usage, testing and development are provided\nby the RPM repository.",
            "title": "Install from Repository (Fedora)"
        },
        {
            "location": "/installation/rpm-fedora/#supported-versions",
            "text": "For Fedora usually the latest two versions are supported, meaning that the support is dependent on the status of the\nFedora release. For architectures,  only   x86_64  is supported. 32bit architectures are  not  supported.",
            "title": "Supported Versions"
        },
        {
            "location": "/installation/rpm-fedora/#registration",
            "text": "Before you can start you need to get an account for the repository. You will need the credentials that you get by mail\nafter the registration to successfully complete this manual. The placeholders  [your_username]  and  [your_password] \nare used in this manual wherever the credentials are needed.   http://repo.virtuos.uos.de",
            "title": "Registration"
        },
        {
            "location": "/installation/rpm-fedora/#activate-repository",
            "text": "First you have to install the necessary repositories so that your package manager can access them:    Add Opencast repository:  cd /etc/yum.repos.d\ncurl -O http://repo.virtuos.uos.de/opencast-testing.repo \\\n  -d 'version=$releasever' -d os=fc \\\n  -u [your_username]:[your_password]    Add RPMfusion repository:  dnf install --nogpgcheck \\\n  http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm \\\n  http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm",
            "title": "Activate Repository"
        },
        {
            "location": "/installation/rpm-fedora/#install-3rd-party-tools",
            "text": "This step is optional and only recommended for those who want to build Opencast from source. If you install Opencast\nfrom the repository, all necessary dependencies will be installed automatically.  You can install all necessary 3rd-Party-Tools for Opencast like this:  dnf install ffmpeg-recent tesseract hunspell sox",
            "title": "Install 3rd-party-tools"
        },
        {
            "location": "/installation/rpm-fedora/#install-apache-activemq",
            "text": "The Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be\ninstalled on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the\nOpencast RPM repository as well and can be installed by running:  dnf install activemq-dist  A prepared configuration file for ActiveMQ can be found at  /usr/share/opencast/docs/scripts/activemq/activemq.xml  after Opencast itself has been installed  and should replace  /etc/activemq/activemq.xml . For an all-in-one\ninstallation the following command should suffice:  cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml  ActiveMQ should be started  prior to  Opencast.  More information about how to properly set up ActiveMQ for Opencast can be found in the  message broker configuration\ndocumentation .",
            "title": "Install Apache ActiveMQ"
        },
        {
            "location": "/installation/rpm-fedora/#install-opencast",
            "text": "For this guide,  opencast21-*  is used as placeholder for the package name. It will install the latest version of the\nOpencast 2.1.x branch. If you want to install another version, please change the name accordingly.",
            "title": "Install Opencast"
        },
        {
            "location": "/installation/rpm-fedora/#basic-installation",
            "text": "For a basic installation (All-In-One) just run:  dnf install opencast21-allinone  This will install the default distribution of Opencast and all its dependencies, including the 3rd-Party-Tools.  Now you can start Opencast:  systemctl start opencast.service  While Opencast is preconfigured, it is strongly recommended to follow at least the  Basic Configuration\nguide . It will help you to set your hostname, login information, \u2026",
            "title": "Basic Installation"
        },
        {
            "location": "/installation/rpm-fedora/#advanced-installation",
            "text": "While the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might\nwant to have more control over your system and deploy it over several machines by choosing which parts of Opencast you\nwant to install. You can list all Opencast packages with:  dnf search opencast  Starting with Opencast 2.1, this will list all available Opencast distributions in the form opencast<version>-<dist-type>  Current available distributions are:   opencast21-allinone  opencast21-admin  opencast21-worker  opencast21-presentation",
            "title": "Advanced Installation"
        },
        {
            "location": "/installation/rpm-fedora/#uninstall-opencast",
            "text": "Sometimes you want to uninstall Opencast. For example to do a clean reinstall. You can do that by executing:  dnf remove opencast  This will not touch your created media files or modified configuration files.  If you want to remove them as well, you\nhave to to that by yourself.  # Remove media files\nsudo rm -rf /srv/opencast\n\n# Remove local db, search index and working files\nsudo rm -rf /var/lib/opencast\n\n# Remove configuration files\nsudo rm -rf /etc/opencast\n\n# Remove system logfiles\nsudo rm -rf /var/log/opencast",
            "title": "Uninstall Opencast"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/",
            "text": "Install from Repository (RedHat Enterprise Linux, CentOS, Scientific Linux)\n\n\nThere is an RPM software repository available for RedHat-based Linux distributions provided by the University of\nOsnabr\u00fcck. This repository provides preconfigured Opencast installations, including all 3rd-Party-Tools. Using this\nmethod, you do not have to compile the software by yourself.\n\n\nIt may also be interesting for developers as all dependencies for Opencast usage, testing and development are provided\nby the RPM repository.\n\n\nCurrently supported are are\n\n\n\n\nCentOS 6.x, 7.x (x86_64)\n\n\nRedHat Enterprise Linux 6.x, 7.x (x86_64)\n\n\nScientific Linux 6.x, 7.x (x86_64)\n\n\n\n\n\n\nOther architectures like i386, i686, arm, \u2026 are not supported!\n\n\n\n\nCentOS, SL, RHEL 7.x is recommended over 6.x.\n\n\nRegistration\n\n\nBefore you can start you need to get an account for the repository. You will need the credentials that you get by mail\nafter the registration to successfully complete this manual. The placeholders \n[your_username]\n and \n[your_password]\n\nare used in this manual wherever the credentials are needed.\n\n\n\n\nhttp://repo.virtuos.uos.de\n\n\n\n\nActivate Repository\n\n\nFirst you have to install the necessary repositories so that your package manager can access them:\n\n\n\n\n\n\nAdd Opencast repository:\n\n\ncd /etc/yum.repos.d\ncurl -O http://repo.virtuos.uos.de/opencast.repo \\\n   -d os=el -d version=7 \\\n   -u [YOUR_USERNAME]:[YOUR_PASSWORD]\n\n\n\nNote: For RHEL/CentOS/SL 6.x use \nversion=6\n\n\nIt might take some time after the final version is released before the RPMs are moved to the stable repository.\nBefore that, you can use \n.../opencast-testing.repo\n instead to get the latest version.\n\n\n\n\n\n\nAdd EPEL repository:\n\n\nyum install epel-release\n\n\n\n\n\n\nInstall 3rd-party-tools\n\n\nThis step is optional and only recommended for those who want to build Opencast from source. If you install Opencast\nfrom the repository, all necessary dependencies will be installed automatically.\n\n\nYou can install all necessary 3rd-Party-Tools for Opencast like this:\n\n\nyum install ffmpeg tesseract hunspell sox\n\n\n\nInstall Apache ActiveMQ\n\n\nThe Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be\ninstalled on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the\nOpencast RPM repository as well and can be installed by running:\n\n\nyum install activemq-dist\n\n\n\nA prepared configuration file for ActiveMQ can be found at \n/usr/share/opencast/docs/scripts/activemq/activemq.xml\n\n\nafter Opencast itself has been installed\n and should replace \n/etc/activemq/activemq.xml\n. For an all-in-one\ninstallation the following command should suffice:\n\n\ncp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml\n\n\n\nActiveMQ should be started \nprior to\n Opencast.\n\n\nMore information about how to properly set up ActiveMQ for Opencast can be found in the \nmessage broker configuration\ndocumentation\n.\n\n\nInstall Opencast\n\n\nFor this guide, \nopencast21-*\n is used as placeholder for the package name. It will install the latest version of the\nOpencast 2.1.x branch. If you want to install another version, please change the name accordingly.\n\n\nBasic Installation\n\n\nFor a basic installation (All-In-One) just run:\n\n\nyum install opencast21-allinone\n\n\n\nThis will install the default distribution of Opencast and all its dependencies, including the 3rd-Party-Tools.\n\n\nNow you can start Opencast:\n\n\n\n\n\n\nOn a SysV-init based system\n\n\nservice opencast start\n\n\n\n\n\n\nOn a Systemd based system\n\n\nsystemctl start opencast.service\n\n\n\n\n\n\nWhile Opencast is preconfigured, it is strongly recommended to follow at least the \nBasic Configuration\nguide\n. It will help you to set your hostname, login information, \u2026\n\n\nAdvanced Installation\n\n\nWhile the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might\nwant to have more control over your system and deploy it over several machines by choosing which parts of Opencast you\nwant to install. You can list all Opencast packages with:\n\n\ndnf search opencast\n\n\n\nStarting with Opencast 2.1, this will list all available Opencast distributions in the form\n\nopencast<version>-<dist-type>\n\n\nCurrent available distributions are:\n\n\n\n\nopencast21-allinone\n\n\nopencast21-admin\n\n\nopencast21-worker\n\n\nopencast21-presentation\n\n\n\n\nUninstall Opencast\n\n\nSometimes you want to uninstall Opencast. For example to do a clean reinstall. You can do that by executing:\n\n\nyum remove opencast\n\n\n\nThis will not touch your created media files or modified configuration files.  If you want to remove them as well, you\nhave to to that by yourself.\n\n\n# Remove media files\nsudo rm -rf /srv/opencast\n\n# Remove local db, search index and working files\nsudo rm -rf /var/lib/opencast\n\n# Remove configuration files\nsudo rm -rf /etc/opencast\n\n# Remove system logfiles\nsudo rm -rf /var/log/opencast",
            "title": "RHEL/CentOS"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#install-from-repository-redhat-enterprise-linux-centos-scientific-linux",
            "text": "There is an RPM software repository available for RedHat-based Linux distributions provided by the University of\nOsnabr\u00fcck. This repository provides preconfigured Opencast installations, including all 3rd-Party-Tools. Using this\nmethod, you do not have to compile the software by yourself.  It may also be interesting for developers as all dependencies for Opencast usage, testing and development are provided\nby the RPM repository.",
            "title": "Install from Repository (RedHat Enterprise Linux, CentOS, Scientific Linux)"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#currently-supported-are-are",
            "text": "CentOS 6.x, 7.x (x86_64)  RedHat Enterprise Linux 6.x, 7.x (x86_64)  Scientific Linux 6.x, 7.x (x86_64)    Other architectures like i386, i686, arm, \u2026 are not supported!   CentOS, SL, RHEL 7.x is recommended over 6.x.",
            "title": "Currently supported are are"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#registration",
            "text": "Before you can start you need to get an account for the repository. You will need the credentials that you get by mail\nafter the registration to successfully complete this manual. The placeholders  [your_username]  and  [your_password] \nare used in this manual wherever the credentials are needed.   http://repo.virtuos.uos.de",
            "title": "Registration"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#activate-repository",
            "text": "First you have to install the necessary repositories so that your package manager can access them:    Add Opencast repository:  cd /etc/yum.repos.d\ncurl -O http://repo.virtuos.uos.de/opencast.repo \\\n   -d os=el -d version=7 \\\n   -u [YOUR_USERNAME]:[YOUR_PASSWORD]  Note: For RHEL/CentOS/SL 6.x use  version=6  It might take some time after the final version is released before the RPMs are moved to the stable repository.\nBefore that, you can use  .../opencast-testing.repo  instead to get the latest version.    Add EPEL repository:  yum install epel-release",
            "title": "Activate Repository"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#install-3rd-party-tools",
            "text": "This step is optional and only recommended for those who want to build Opencast from source. If you install Opencast\nfrom the repository, all necessary dependencies will be installed automatically.  You can install all necessary 3rd-Party-Tools for Opencast like this:  yum install ffmpeg tesseract hunspell sox",
            "title": "Install 3rd-party-tools"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#install-apache-activemq",
            "text": "The Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be\ninstalled on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the\nOpencast RPM repository as well and can be installed by running:  yum install activemq-dist  A prepared configuration file for ActiveMQ can be found at  /usr/share/opencast/docs/scripts/activemq/activemq.xml  after Opencast itself has been installed  and should replace  /etc/activemq/activemq.xml . For an all-in-one\ninstallation the following command should suffice:  cp /usr/share/opencast/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml  ActiveMQ should be started  prior to  Opencast.  More information about how to properly set up ActiveMQ for Opencast can be found in the  message broker configuration\ndocumentation .",
            "title": "Install Apache ActiveMQ"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#install-opencast",
            "text": "For this guide,  opencast21-*  is used as placeholder for the package name. It will install the latest version of the\nOpencast 2.1.x branch. If you want to install another version, please change the name accordingly.",
            "title": "Install Opencast"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#basic-installation",
            "text": "For a basic installation (All-In-One) just run:  yum install opencast21-allinone  This will install the default distribution of Opencast and all its dependencies, including the 3rd-Party-Tools.  Now you can start Opencast:    On a SysV-init based system  service opencast start    On a Systemd based system  systemctl start opencast.service    While Opencast is preconfigured, it is strongly recommended to follow at least the  Basic Configuration\nguide . It will help you to set your hostname, login information, \u2026",
            "title": "Basic Installation"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#advanced-installation",
            "text": "While the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might\nwant to have more control over your system and deploy it over several machines by choosing which parts of Opencast you\nwant to install. You can list all Opencast packages with:  dnf search opencast  Starting with Opencast 2.1, this will list all available Opencast distributions in the form opencast<version>-<dist-type>  Current available distributions are:   opencast21-allinone  opencast21-admin  opencast21-worker  opencast21-presentation",
            "title": "Advanced Installation"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#uninstall-opencast",
            "text": "Sometimes you want to uninstall Opencast. For example to do a clean reinstall. You can do that by executing:  yum remove opencast  This will not touch your created media files or modified configuration files.  If you want to remove them as well, you\nhave to to that by yourself.  # Remove media files\nsudo rm -rf /srv/opencast\n\n# Remove local db, search index and working files\nsudo rm -rf /var/lib/opencast\n\n# Remove configuration files\nsudo rm -rf /etc/opencast\n\n# Remove system logfiles\nsudo rm -rf /var/log/opencast",
            "title": "Uninstall Opencast"
        },
        {
            "location": "/configuration/",
            "text": "Opencast Configuration Guides\n\n\nThese guides will help you to configure Opencast. If you are a first-time user, please make sure to at lease have a look\nat the \nbasic configuration guide\n.\n\n\nGeneral Configuration\n\n\n\n\nBasic Configuration\n\n\nDatabase Configuration\n\n\nEncoding Profile Configuration\n\n\nLogging and Privacy Configuration\n\n\nMessage Broker Configuration\n\n\nMulti Tenancy Configuration\n\n\nSecurity Configuration\n\n\nCAS Security Configuration\n\n\nLDAP Authentication and Authorization (without CAS)\n\n\n\n\n\n\nWorkflow Configuration\n\n\nWorkflow Operation Handler",
            "title": "Overview"
        },
        {
            "location": "/configuration/#opencast-configuration-guides",
            "text": "These guides will help you to configure Opencast. If you are a first-time user, please make sure to at lease have a look\nat the  basic configuration guide .",
            "title": "Opencast Configuration Guides"
        },
        {
            "location": "/configuration/#general-configuration",
            "text": "Basic Configuration  Database Configuration  Encoding Profile Configuration  Logging and Privacy Configuration  Message Broker Configuration  Multi Tenancy Configuration  Security Configuration  CAS Security Configuration  LDAP Authentication and Authorization (without CAS)    Workflow Configuration  Workflow Operation Handler",
            "title": "General Configuration"
        },
        {
            "location": "/configuration/basic/",
            "text": "Basic Configuration\n\n\nThis guide will help you to change the basic configuration settings which are required or at least strongly recommended\nfor each Opencast installation. This is basically what you should do, right after installing Opencast on your machine.\n\n\nAll settings are made to files, residing in the Opencast configuration directory. In most cases, that should be either\n\n/etc/opencast/custom.properties\n or \n/opt/opencast/etc/custom.properties\n. Edit the files, using the editor of your\nchoice, e.g.:\n\n\nvim /etc/opencast/custom.properties\n\n\n\nStep 1: Setting the Server URL\n\n\nBy default, only connections from the local machine are accepted by Opencast.  You want to change this if the system\nshould be accessible within a network.\n\n\nFirst, find the property \norg.opencastproject.server.url\n in your \ncustom.properties\n configuration file and set it to\nyour own domain name:\n\n\norg.opencastproject.server.url=http://example.com:8080\n\n\n\nNote:\n This value will be written to all generated mediapackages and thus cannot be changed easily for already\nprocessed media. At least not without an extra amount of work involving modifications to the database. That is why you\nshould think about this setting carefully.\n\n\nSecond, adjust the binding address in \ncustom.properties\n. The binding address can be set to \n0.0.0.0\n for general\nnetwork access. The property to modify is:\n\n\norg.ops4j.pax.web.listening.addresses=127.0.0.1\n\n\n\nStep 2: Setting the Login Details\n\n\nThere are two authentication methods for Opencast. HTTP Digest authentication and form-based authentication. Both\nmethods need a username and a password. Change the password for both! The important keys for this are:\n\n\n\n\norg.opencastproject.security.admin.user\n\n\nThe user for the administrative account. This is set to \nadmin\n by default.\n\n\n\n\n\n\norg.opencastproject.security.admin.pass\n\n\nThe password for the administrative account. This is set to \nopencast\n by default.\n\n\n\n\n\n\norg.opencastproject.security.digest.user\n\n\nThe user for the communication between Opencast nodes, as well as for capture agents. This is set to\n  \nopencast_system_account\n by default.\n\n\n\n\n\n\norg.opencastproject.security.digest.pass\n\n\nThe password for the communication between Opencast nodes and capture agents. This is set to \nCHANGE_ME\n by\n  default.\n\n\n\n\n\n\n\n\nNote:\n The digest credentials are also used for internal communication of Opencast servers. So these keys have to be\nset to the same value on each of you Opencast nodes (Core, Worker, Capture Agent, \u2026)\n\n\nStep 3: Setting up Apache ActiveMQ Message Broker\n\n\nSince version 2.0, Opencast requires a running Apache ActiveMQ instance with a specific configuration.  The message\nbroker is mostly run on the admin server of Opencast but can be run separately. It needs to be started before Opencast.\nFor more details about the setup, have a look at the \nApache ActiveMQ configuration guide\n.\n\n\nStep 4: Database Configuration\n\n\nOpencast uses an integrated HSQL database by default. While you will find it perfectly functional, it has certain\ndrawbacks:\n\n\n\n\nIt is rather slow\n\n\nIt cannot be used for distributed set-ups\n\n\nUpgrading Opencast with this database is not possible\n\n\n\n\nFor testing, it is totally fine to keep the internal database, but you are highly encouraged to switch to a stand-alone\ndatabase for productional use. For more information about database configuration, have a look at the \nDatabase\nConfiguration\n section.\n\n\nStep 4: Setting the Storage Directory (optional)\n\n\nEven though it is not important for all systems \u2013 on test setups you can probably omit this \u2013 you will often want to set\nthe storage directory. This directory is used to store all media, metadata, \u2026 Often, an NFS mount is used for this. You\ncan set the directory by changing \norg.opencastproject.storage.dir\n like:\n\n\norg.opencastproject.storage.dir=/media/mhdatamount",
            "title": "Basic"
        },
        {
            "location": "/configuration/basic/#basic-configuration",
            "text": "This guide will help you to change the basic configuration settings which are required or at least strongly recommended\nfor each Opencast installation. This is basically what you should do, right after installing Opencast on your machine.  All settings are made to files, residing in the Opencast configuration directory. In most cases, that should be either /etc/opencast/custom.properties  or  /opt/opencast/etc/custom.properties . Edit the files, using the editor of your\nchoice, e.g.:  vim /etc/opencast/custom.properties",
            "title": "Basic Configuration"
        },
        {
            "location": "/configuration/basic/#step-1-setting-the-server-url",
            "text": "By default, only connections from the local machine are accepted by Opencast.  You want to change this if the system\nshould be accessible within a network.  First, find the property  org.opencastproject.server.url  in your  custom.properties  configuration file and set it to\nyour own domain name:  org.opencastproject.server.url=http://example.com:8080  Note:  This value will be written to all generated mediapackages and thus cannot be changed easily for already\nprocessed media. At least not without an extra amount of work involving modifications to the database. That is why you\nshould think about this setting carefully.  Second, adjust the binding address in  custom.properties . The binding address can be set to  0.0.0.0  for general\nnetwork access. The property to modify is:  org.ops4j.pax.web.listening.addresses=127.0.0.1",
            "title": "Step 1: Setting the Server URL"
        },
        {
            "location": "/configuration/basic/#step-2-setting-the-login-details",
            "text": "There are two authentication methods for Opencast. HTTP Digest authentication and form-based authentication. Both\nmethods need a username and a password. Change the password for both! The important keys for this are:   org.opencastproject.security.admin.user  The user for the administrative account. This is set to  admin  by default.    org.opencastproject.security.admin.pass  The password for the administrative account. This is set to  opencast  by default.    org.opencastproject.security.digest.user  The user for the communication between Opencast nodes, as well as for capture agents. This is set to\n   opencast_system_account  by default.    org.opencastproject.security.digest.pass  The password for the communication between Opencast nodes and capture agents. This is set to  CHANGE_ME  by\n  default.     Note:  The digest credentials are also used for internal communication of Opencast servers. So these keys have to be\nset to the same value on each of you Opencast nodes (Core, Worker, Capture Agent, \u2026)",
            "title": "Step 2: Setting the Login Details"
        },
        {
            "location": "/configuration/basic/#step-3-setting-up-apache-activemq-message-broker",
            "text": "Since version 2.0, Opencast requires a running Apache ActiveMQ instance with a specific configuration.  The message\nbroker is mostly run on the admin server of Opencast but can be run separately. It needs to be started before Opencast.\nFor more details about the setup, have a look at the  Apache ActiveMQ configuration guide .",
            "title": "Step 3: Setting up Apache ActiveMQ Message Broker"
        },
        {
            "location": "/configuration/basic/#step-4-database-configuration",
            "text": "Opencast uses an integrated HSQL database by default. While you will find it perfectly functional, it has certain\ndrawbacks:   It is rather slow  It cannot be used for distributed set-ups  Upgrading Opencast with this database is not possible   For testing, it is totally fine to keep the internal database, but you are highly encouraged to switch to a stand-alone\ndatabase for productional use. For more information about database configuration, have a look at the  Database\nConfiguration  section.",
            "title": "Step 4: Database Configuration"
        },
        {
            "location": "/configuration/basic/#step-4-setting-the-storage-directory-optional",
            "text": "Even though it is not important for all systems \u2013 on test setups you can probably omit this \u2013 you will often want to set\nthe storage directory. This directory is used to store all media, metadata, \u2026 Often, an NFS mount is used for this. You\ncan set the directory by changing  org.opencastproject.storage.dir  like:  org.opencastproject.storage.dir=/media/mhdatamount",
            "title": "Step 4: Setting the Storage Directory (optional)"
        },
        {
            "location": "/configuration/database/",
            "text": "Database Configuration\n\n\nOpencast ships with embedded JDBC drivers for the H2 (HSQL), MySQL/MariaDB databases. The built in H2 databased is used\nby default and needs no configuration, but it is strongly recommended to use MySQL or MariaDB instead as there will be a\nhuge performance gain, especially if more data are in that database.\n\n\nNotice:\n For a distributed set-up of Opencast, you cannot use the internal H2 database.\n\n\nOther databases\n\n\nRunning Opencast with PostgreSQL should be possible and there is some community support for this. While it should work,\nthe support for this is unofficial and we cannot guarantee that every new feature is well tested on that platform.\n\n\nThe EclipseLink JPA implementation which is used in Opencast supports other databases as well and it should be\npossible to attach other database engines.\n\n\nSetting up MySQL/MariaDB\n\n\nRequirements\n\n\nBefore following this guide you should have:\n\n\n\n\nInstalled the Opencast Core System\n\n\nFollowed the \nBasic Configuration instructions\n\n\n\n\nStep 0: Set-up MySQL/MariaDB\n\n\nThis step is not Opencast specific and may be different for your needs (e.g.  if you want to have a dedicated database\nserver). It shall only be a guide for people with no experience setting up MySQL/MariaDB and to help them get things\nrunning.\n\n\nNotice:\n If your distribution still shipps MySQL instead of MariaDB, the installation should still be very much the\nsame. Only the names will of course change.\n\n\nFirst you have to install the MariaDB server. Usually you would do that by using the package management tool of you\ndistribution. On RedHat based systems (CentOS, Scientific Linux, \u2026) this should be:\n\n\nyum install mariadb mariadb-server\n\n\n\nAfter the installation you can start the server and set it up to start automatically after each reboot with the\nfollowing commands:\n\n\n# If you are using Systemd\nsystemctl start mariadb.service\nsystemctl enable mariadb.service\n# If you are using SysV-Init\nservice mariadb start\nchkconfig --level 345 mariadb on\n\n\n\nNow you have a MariaDB server running, but without a properly set up root account (no password, etc.) which might pose a\nsecurity risk. To create this initial configuration, there is a convenient tool that comes which MariaDB and which will\nhelp. You can launch this tool by executing (yes, it is still called mysql_\u2026):\n\n\nmysql_secure_installation\n\n\n\nIt will guide you through the steps of setting up a root account with password, etc.\n\n\nStep 1: Create a Opencast Database\n\n\nThe first step, if you have not already done this, is obviously to create a database for Opencast. You can use the\nfollowing SQL code to to that. For executing the SQL, use the MySQL/MariaDB client (run the mysql program from your\nshell) or use a graphical tool like phpMyAdmin. For now, we will use the MySQL shell client and the default\nadministrative (root) user. Launch the client with:\n\n\nmysql -u root -p\n\n\n\nYou will be asked for the password of the user root. After entering it, you will end up in the MySQL/MariaDB shell.\nNext, create a database called \nopencast\n by executing:\n\n\nCREATE DATABASE opencast CHARACTER SET utf8 COLLATE utf8_general_ci;\n\n\n\nThen create a user \nopencast\n with the password \nopencast_password\n and grant him all necessary rights:\n\n\nGRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP,INDEX ON opencast.*\n  TO 'opencast'@'localhost' IDENTIFIED BY 'opencast_password';\n\n\n\nNotice:\n Of cause you may use other names for user or database and should use a different password.\n\n\nOn Distributed Systems, additionally to \n'username'@'localhost'\n which would allow access from the local machine only,\nfor a distributed system you would also create a user like \n'username'@'10.0.1.%'\n and grant the necessary rights to\nthis user as well. The \n10.0.1.%\n specifies the IP range which gets access to the server with \n%\n being a wildcard for\nanything.  For more details on MySQL user creation have a look at MySQL Reference Manual :: 6.3.2 Adding User Accounts.\n\n\nFinally, leave the MySQL/MariaDB client shell and restart the database server to enable the user with:\n\n\nservice mysqld restart\n\n\n\nor if you have a systemd based system:\n\n\nsystemctl restart mariadb.service\n\n\n\nStep 2: Set up the Database Structure\n\n\nTo set up the database structure you can (and should!) use the Opencast ddl scripts. You can find the script either at\n\n/usr/share/opencast/docs/scripts/ddl/mysql5.sql\n or download it from BitBucket.\n\n\nSwitch to the directory that contains the mysql5.sql file and run the MySQL/MariaDB client with the user you created in\nthe previous step (\n-u opencast\n) and switch to the database you want to use (\nopencast\n):\n\n\nmysql -u opencast -p opencast\n\n\n\nRun the ddl script:\n\n\nmysql> source mysql5.sql;\n\n\n\nInstead of using the MySQL/MariaDB Client, you can, of cause, also use every other method for executing SQL code like\nphpMyAdmin or MySQL-Workbench\u2026\n\n\nStep 3: Configure Opencast\n\n\nThe following settings are made in the .../etc\n/custom.properties\n file (often \n/etc/opencast/custom.properties\n). Use\nthe editor of your choice to open it, e.g.:\n\n\nvim /etc/opencast/custom.properties\n\n\n\nNow change the following configuration keys:\n\n\norg.opencastproject.db.ddl.generation=false\n\n\n\nIf set to true, the database structure will be generated automatically. It works, but all database optimizations are\nlost. You should never do this, unless you need it for development purposes.\n\n\norg.opencastproject.db.vendor=MySQL\n\n\n\nTell Opencast that you use MySQL.\n\n\norg.opencastproject.db.jdbc.driver=com.mysql.jdbc.Driver\n\n\n\nTell Opencast to use the JDBC driver for MySQL.\n\n\norg.opencastproject.db.jdbc.url=jdbc:mysql://localhost/opencast\n\n\n\nTell Opencast where to find the database and the name of the database. Replace \u201clocalhost\u201d and \u201copencast\u201d if necessary.\n\n\norg.opencastproject.db.jdbc.user=opencast\n\n\n\nTell Opencast which username to use for accessing the database. This user need to have the rights to read from and\nwrite to the database.\n\n\norg.opencastproject.db.jdbc.pass=opencast_password\n\n\n\nTell Opencast which password to use for accessing the database. This must obviously fit the username.",
            "title": "Database"
        },
        {
            "location": "/configuration/database/#database-configuration",
            "text": "Opencast ships with embedded JDBC drivers for the H2 (HSQL), MySQL/MariaDB databases. The built in H2 databased is used\nby default and needs no configuration, but it is strongly recommended to use MySQL or MariaDB instead as there will be a\nhuge performance gain, especially if more data are in that database.  Notice:  For a distributed set-up of Opencast, you cannot use the internal H2 database.",
            "title": "Database Configuration"
        },
        {
            "location": "/configuration/database/#other-databases",
            "text": "Running Opencast with PostgreSQL should be possible and there is some community support for this. While it should work,\nthe support for this is unofficial and we cannot guarantee that every new feature is well tested on that platform.  The EclipseLink JPA implementation which is used in Opencast supports other databases as well and it should be\npossible to attach other database engines.",
            "title": "Other databases"
        },
        {
            "location": "/configuration/database/#setting-up-mysqlmariadb",
            "text": "",
            "title": "Setting up MySQL/MariaDB"
        },
        {
            "location": "/configuration/database/#requirements",
            "text": "Before following this guide you should have:   Installed the Opencast Core System  Followed the  Basic Configuration instructions",
            "title": "Requirements"
        },
        {
            "location": "/configuration/database/#step-0-set-up-mysqlmariadb",
            "text": "This step is not Opencast specific and may be different for your needs (e.g.  if you want to have a dedicated database\nserver). It shall only be a guide for people with no experience setting up MySQL/MariaDB and to help them get things\nrunning.  Notice:  If your distribution still shipps MySQL instead of MariaDB, the installation should still be very much the\nsame. Only the names will of course change.  First you have to install the MariaDB server. Usually you would do that by using the package management tool of you\ndistribution. On RedHat based systems (CentOS, Scientific Linux, \u2026) this should be:  yum install mariadb mariadb-server  After the installation you can start the server and set it up to start automatically after each reboot with the\nfollowing commands:  # If you are using Systemd\nsystemctl start mariadb.service\nsystemctl enable mariadb.service\n# If you are using SysV-Init\nservice mariadb start\nchkconfig --level 345 mariadb on  Now you have a MariaDB server running, but without a properly set up root account (no password, etc.) which might pose a\nsecurity risk. To create this initial configuration, there is a convenient tool that comes which MariaDB and which will\nhelp. You can launch this tool by executing (yes, it is still called mysql_\u2026):  mysql_secure_installation  It will guide you through the steps of setting up a root account with password, etc.",
            "title": "Step 0: Set-up MySQL/MariaDB"
        },
        {
            "location": "/configuration/database/#step-1-create-a-opencast-database",
            "text": "The first step, if you have not already done this, is obviously to create a database for Opencast. You can use the\nfollowing SQL code to to that. For executing the SQL, use the MySQL/MariaDB client (run the mysql program from your\nshell) or use a graphical tool like phpMyAdmin. For now, we will use the MySQL shell client and the default\nadministrative (root) user. Launch the client with:  mysql -u root -p  You will be asked for the password of the user root. After entering it, you will end up in the MySQL/MariaDB shell.\nNext, create a database called  opencast  by executing:  CREATE DATABASE opencast CHARACTER SET utf8 COLLATE utf8_general_ci;  Then create a user  opencast  with the password  opencast_password  and grant him all necessary rights:  GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP,INDEX ON opencast.*\n  TO 'opencast'@'localhost' IDENTIFIED BY 'opencast_password';  Notice:  Of cause you may use other names for user or database and should use a different password.  On Distributed Systems, additionally to  'username'@'localhost'  which would allow access from the local machine only,\nfor a distributed system you would also create a user like  'username'@'10.0.1.%'  and grant the necessary rights to\nthis user as well. The  10.0.1.%  specifies the IP range which gets access to the server with  %  being a wildcard for\nanything.  For more details on MySQL user creation have a look at MySQL Reference Manual :: 6.3.2 Adding User Accounts.  Finally, leave the MySQL/MariaDB client shell and restart the database server to enable the user with:  service mysqld restart  or if you have a systemd based system:  systemctl restart mariadb.service",
            "title": "Step 1: Create a Opencast Database"
        },
        {
            "location": "/configuration/database/#step-2-set-up-the-database-structure",
            "text": "To set up the database structure you can (and should!) use the Opencast ddl scripts. You can find the script either at /usr/share/opencast/docs/scripts/ddl/mysql5.sql  or download it from BitBucket.  Switch to the directory that contains the mysql5.sql file and run the MySQL/MariaDB client with the user you created in\nthe previous step ( -u opencast ) and switch to the database you want to use ( opencast ):  mysql -u opencast -p opencast  Run the ddl script:  mysql> source mysql5.sql;  Instead of using the MySQL/MariaDB Client, you can, of cause, also use every other method for executing SQL code like\nphpMyAdmin or MySQL-Workbench\u2026",
            "title": "Step 2: Set up the Database Structure"
        },
        {
            "location": "/configuration/database/#step-3-configure-opencast",
            "text": "The following settings are made in the .../etc /custom.properties  file (often  /etc/opencast/custom.properties ). Use\nthe editor of your choice to open it, e.g.:  vim /etc/opencast/custom.properties  Now change the following configuration keys:  org.opencastproject.db.ddl.generation=false  If set to true, the database structure will be generated automatically. It works, but all database optimizations are\nlost. You should never do this, unless you need it for development purposes.  org.opencastproject.db.vendor=MySQL  Tell Opencast that you use MySQL.  org.opencastproject.db.jdbc.driver=com.mysql.jdbc.Driver  Tell Opencast to use the JDBC driver for MySQL.  org.opencastproject.db.jdbc.url=jdbc:mysql://localhost/opencast  Tell Opencast where to find the database and the name of the database. Replace \u201clocalhost\u201d and \u201copencast\u201d if necessary.  org.opencastproject.db.jdbc.user=opencast  Tell Opencast which username to use for accessing the database. This user need to have the rights to read from and\nwrite to the database.  org.opencastproject.db.jdbc.pass=opencast_password  Tell Opencast which password to use for accessing the database. This must obviously fit the username.",
            "title": "Step 3: Configure Opencast"
        },
        {
            "location": "/configuration/message-broker/",
            "text": "Message Broker Configuration\n\n\nSince version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user\ninterface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the\nadmin node).\n\n\nRequired Version\n\n\n\n\nActiveMQ 5.10 or above should work.\n\n\nActiveMQ 5.6 will not work.\n\n\nVersions in between are untested.\n\n\n\n\nInstallation\n\n\n\n\nIf you use the Opencast RPM repository, simply install the \nactivemq-dist\n package.\n\n\nIf you are running RHEL, CentOS or Fedora you can use the \nActiveMQ-dist Copr RPM repository\n   \n\n\nYou can download binary distributions from the \nApache ActiveMQ website\n\n\n\n\nConfiguration\n\n\nWhat you need to do:\n\n\n\n\nSet-up required message queues for Opencast\n\n\nPoint all your Opencast nodes to your message broker.\n\n\n\n\nThe first task is easy. Opencast comes with a ActiveMQ configuration file, located at\n\ndocs/scripts/activemq/activemq.xml\n (RPM repo: \n/usr/share/opencast/docs/scripts/activemq/activemq.xml\n). This file\nwill give you a basic configuration with all queues set-up and accepting connections from all hosts over TCP port\n\n61616\n. Simply replacing the default ActiveMQ configuration, usually located at \n/etc/activemq/activemq.xml\n, with this\nfile will already give you a fully functional ActiveMQ set-up.\n\n\nThen configure the ActiveMQ connection in the \ncustom.properties\n. The default configuration points to a local\ninstallation of ActiveMQ:\n\n\nactivemq.broker.url = failover://tcp://example.opencast.org:61616\n\n\n\nSecurity\n\n\nActiveMQ can secure its message queues with user name and password access. This section will go through the steps of\nsetting up a configured username and password. On the \nActiveMQ security site\n\nthere are more details about using alternative authentication and authorization providers.\n\n\nCreate ActiveMQ Admin User\n\n\nFirst, you need to create a new user that will have access to the queues. This is configured in the \nusers.properties\n\nconfiguration file in the configuration directory for ActiveMQ. It is a list of the format \nusername = password\n so, for\nexample, we could create a new admin user with the following file contents:\n\n\nadmin=password\n\n\n\nCreate ActiveMQ Admin Group\n\n\nThe next step is to provide a group that will have our user in it and will secure access to the message queues. This is\nconfigured in the file \ngroups.properties\n in the configuration directory for ActiveMQ. It is a list of the format\n\ngroup = user1,user2,\u2026\n. For example:\n\n\ngroups=user1,user2,user3\n\n\n\nTo set-up our new user to be a part of the admins group:\n\n\nadmins=admin\n\n\n\nConfigure Users and Groups Configuration Files\n\n\nNext, we need to make sure that ActiveMQ is using our \nusers.properties\n and \ngroups.properties\n files to authenticate\nand authorize users. The \nlogin.config\n file should be in the ActivemQ configuration directory and contain:\n\n\nactivemq {\n    org.apache.activemq.jaas.PropertiesLoginModule required\n    org.apache.activemq.jaas.properties.user=\"users.properties\"\n    org.apache.activemq.jaas.properties.group=\"groups.properties\";\n};\n\n\n\nConfigure Message Broker Security\n\n\nThe final step to secure the ActiveMQ queues is to limit them with a group. This can be done by editing the\n\nactivemq.xml\n configuration file in the ActiveMQ configuration directory. Inside this configuration file, we need to\nadd some XML in between the tags:\n\n\n<broker></broker>\n\n\n\nWe will add the following plugin configuration:\n\n\n<plugins>\n    <jaasAuthenticationPlugin configuration=\"activemq\" />\n    <authorizationPlugin>\n        <map>\n            <authorizationMap>\n                <authorizationEntries>\n                    <authorizationEntry queue=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" />\n                    <authorizationEntry topic=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" />\n                    <authorizationEntry topic=\"ActiveMQ.Advisory.>\" read=\"admins\" write=\"admins\" admin=\"admins\"/>\n                </authorizationEntries>\n            </authorizationMap>\n        </map>\n    </authorizationPlugin>\n</plugins>\n\n\n\nThe \njaasAuthenticationPlugin\n configures the broker to use our \nlogin.config\n file to do the authentication.\n\n\n<jaasAuthenticationPlugin configuration=\"activemq\" />\n\n\n\nThe property:\n\n\nconfiguration=activemq\n\n\n\nneeds to match the name given for surrounding object in \nlogin.config\n i.e. activemq{};\n\n\nThe \nauthorizationEntry\n gives read, write and admin access to only those members in the group admins for queues and topics.\n\n\nConfigure Opencast to Connect with Username and Password to Message Broker\n\n\nNow that we have secured the queues, Opencast will complain that it is unable to connect, using the current username and\npassword. The username and password used above need to be added to the \ncustom.properties\n file of Opencast.  There are\ntwo properties to set:\n\n\nactivemq.broker.username=admin\nactivemq.broker.password=password\n\n\n\nFirewall\n\n\nDo not forget that ActiveMQ uses the TCP port 61616 (default configuration) for communication.  You probably want to\nallow communication over this port in your firewall on a distributed setup, or to explicitly forbid public access on an\nall-in-one installation.",
            "title": "Message Broker"
        },
        {
            "location": "/configuration/message-broker/#message-broker-configuration",
            "text": "Since version 2, Opencast requires an Apache ActiveMQ message broker as message relay for the administrative user\ninterface. ActiveMQ can either be set up to run on its own machine or on one of the existing Opencast nodes (usually the\nadmin node).",
            "title": "Message Broker Configuration"
        },
        {
            "location": "/configuration/message-broker/#required-version",
            "text": "ActiveMQ 5.10 or above should work.  ActiveMQ 5.6 will not work.  Versions in between are untested.",
            "title": "Required Version"
        },
        {
            "location": "/configuration/message-broker/#installation",
            "text": "If you use the Opencast RPM repository, simply install the  activemq-dist  package.  If you are running RHEL, CentOS or Fedora you can use the  ActiveMQ-dist Copr RPM repository\n     You can download binary distributions from the  Apache ActiveMQ website",
            "title": "Installation"
        },
        {
            "location": "/configuration/message-broker/#configuration",
            "text": "What you need to do:   Set-up required message queues for Opencast  Point all your Opencast nodes to your message broker.   The first task is easy. Opencast comes with a ActiveMQ configuration file, located at docs/scripts/activemq/activemq.xml  (RPM repo:  /usr/share/opencast/docs/scripts/activemq/activemq.xml ). This file\nwill give you a basic configuration with all queues set-up and accepting connections from all hosts over TCP port 61616 . Simply replacing the default ActiveMQ configuration, usually located at  /etc/activemq/activemq.xml , with this\nfile will already give you a fully functional ActiveMQ set-up.  Then configure the ActiveMQ connection in the  custom.properties . The default configuration points to a local\ninstallation of ActiveMQ:  activemq.broker.url = failover://tcp://example.opencast.org:61616",
            "title": "Configuration"
        },
        {
            "location": "/configuration/message-broker/#security",
            "text": "ActiveMQ can secure its message queues with user name and password access. This section will go through the steps of\nsetting up a configured username and password. On the  ActiveMQ security site \nthere are more details about using alternative authentication and authorization providers.",
            "title": "Security"
        },
        {
            "location": "/configuration/message-broker/#create-activemq-admin-user",
            "text": "First, you need to create a new user that will have access to the queues. This is configured in the  users.properties \nconfiguration file in the configuration directory for ActiveMQ. It is a list of the format  username = password  so, for\nexample, we could create a new admin user with the following file contents:  admin=password",
            "title": "Create ActiveMQ Admin User"
        },
        {
            "location": "/configuration/message-broker/#create-activemq-admin-group",
            "text": "The next step is to provide a group that will have our user in it and will secure access to the message queues. This is\nconfigured in the file  groups.properties  in the configuration directory for ActiveMQ. It is a list of the format group = user1,user2,\u2026 . For example:  groups=user1,user2,user3  To set-up our new user to be a part of the admins group:  admins=admin",
            "title": "Create ActiveMQ Admin Group"
        },
        {
            "location": "/configuration/message-broker/#configure-users-and-groups-configuration-files",
            "text": "Next, we need to make sure that ActiveMQ is using our  users.properties  and  groups.properties  files to authenticate\nand authorize users. The  login.config  file should be in the ActivemQ configuration directory and contain:  activemq {\n    org.apache.activemq.jaas.PropertiesLoginModule required\n    org.apache.activemq.jaas.properties.user=\"users.properties\"\n    org.apache.activemq.jaas.properties.group=\"groups.properties\";\n};",
            "title": "Configure Users and Groups Configuration Files"
        },
        {
            "location": "/configuration/message-broker/#configure-message-broker-security",
            "text": "The final step to secure the ActiveMQ queues is to limit them with a group. This can be done by editing the activemq.xml  configuration file in the ActiveMQ configuration directory. Inside this configuration file, we need to\nadd some XML in between the tags:  <broker></broker>  We will add the following plugin configuration:  <plugins>\n    <jaasAuthenticationPlugin configuration=\"activemq\" />\n    <authorizationPlugin>\n        <map>\n            <authorizationMap>\n                <authorizationEntries>\n                    <authorizationEntry queue=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" />\n                    <authorizationEntry topic=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" />\n                    <authorizationEntry topic=\"ActiveMQ.Advisory.>\" read=\"admins\" write=\"admins\" admin=\"admins\"/>\n                </authorizationEntries>\n            </authorizationMap>\n        </map>\n    </authorizationPlugin>\n</plugins>  The  jaasAuthenticationPlugin  configures the broker to use our  login.config  file to do the authentication.  <jaasAuthenticationPlugin configuration=\"activemq\" />  The property:  configuration=activemq  needs to match the name given for surrounding object in  login.config  i.e. activemq{};  The  authorizationEntry  gives read, write and admin access to only those members in the group admins for queues and topics.",
            "title": "Configure Message Broker Security"
        },
        {
            "location": "/configuration/message-broker/#configure-opencast-to-connect-with-username-and-password-to-message-broker",
            "text": "Now that we have secured the queues, Opencast will complain that it is unable to connect, using the current username and\npassword. The username and password used above need to be added to the  custom.properties  file of Opencast.  There are\ntwo properties to set:  activemq.broker.username=admin\nactivemq.broker.password=password",
            "title": "Configure Opencast to Connect with Username and Password to Message Broker"
        },
        {
            "location": "/configuration/message-broker/#firewall",
            "text": "Do not forget that ActiveMQ uses the TCP port 61616 (default configuration) for communication.  You probably want to\nallow communication over this port in your firewall on a distributed setup, or to explicitly forbid public access on an\nall-in-one installation.",
            "title": "Firewall"
        },
        {
            "location": "/configuration/encoding/",
            "text": "Encoding Profile Configuration\n\n\nA workflow defines which operations are applied to media ingested into Opencast and the order of these operations. An\noperation can be something general like \u201cencode this video\u201d. The encoding profiles then specify exactly how a media is\nancoded, which filters are applied, which codecs are used and in which container these will be stored, \u2026\n\n\nOpencast comes with a set of such profiles generating files for both online playback and download. These profiles are\nbuild to work for everyone, meaning that in most cases optimization can be done according to local needs. So modifying\nthese profiles or building new ones often makes sense. This document will help you modify or augment Opencast's\ndefault encoding profiles for audio, video and still images.\n\n\nDefault Profiles and Possible Settings\n\n\nThis section contains some notes about the default profiles, explaining some thoughts behind those profiles and pointing\nat things you might want to change depending on your local set-up.\n\n\nA/V-Muxing: From lossless to safe\n\n\nThe audio/video muxing (profile.mux-av.work) is applied if audio and video are send to Opencast separately. The basic\nidea behind this is, to combine these separate files into one file which can later be converted in one step.\n\n\nPossible settings:\n\n\n\n\nIf you get an audio and a video file separately, it is possivle to just copy the streams and put them together into a\n   new file. This is very fast (you only have to copy the streams) and most importantly, it is lossless, as no\n   re-encoding is done. The question is: What a/v container format can/should you use for such an operation.\n\n\nYou can try to use the video container the input video came in and just add the audio. This means that you will never\n   have an unexpected video container you don't know of. I.e. if you put an .mp4 video in, it still uses and .mp4\n   container after musing, etc. This might, however, lead to problems if you throw in an audio file that cannot be muxen\n   in the specific container format (i.e. you have a FLAC audio file and an FLV container). This is, what Opencast\n   does at the moment.\n\n\nTo circumvent the container problem, we could also use a container format which can hold almost everything (i.e. mkv)\n   regardless of the input. This would mean that MH can handle more combinations of a/v streams but you will always end\n   up with a Matroska file after muxing. Of cause you can then encode it to mp4, etc. later on.\n\n\n\n\nThe safest option for muxing is, of cause, to always re-encode the streams. It is far slower. It always means a quality\nloss. But it can handle everything FFmpeg can handle which (dependin on your FFmpeg configuration) is quite a lot.\n\n\nTrimming: Fast and lossless VS accurate\n\n\nThe profile trim.work is used after you send your recording to trim/hold and selected new start and end points. Here you\nhave basically two choices:\n\n\n\n\nAs you only want to cut the video, you don't have to re-encode all of it. You just split the stream and put it into a\n   new file. This is fast. This is lossless. But depending on the video format this might not be accurate. You can only\n   cut a stream at an I-frame (a frame holding the full image). Doing this, FFmpeg will cut the video at the nearest\n   I-frame before the selected position meaning that you might end up with a bit more video than you thought you would\n   get. You can minimize this by making sure that the input video has a high I-frame frequency (probably a good idea\n   anyway). This is what Opencast does at the moment.\n\n\nThe alternative is to cut between two I-frames. This is possible, but requires the video to be re-encoded completely.\n   This means that you will spend a lot of time on this process and will always loose quality.\n\n\n\n\nCreate an Encoding Profile\n\n\nThis section will help you to understand how you can modify an existing profile or create a completly new one.\n\n\nCreating a new encoding profile is a matter of creating a configuration file and placing it in the encoding profiles\nwatch folder.\n\n\nEncoding Profile Folder\n\n\nThe \n<config_dir>/encoding\n folder allows you to quickly augment Opencast's existing behavior, simply by modifying or\nadding new configuration files. The file names should follow the pattern \n*.properties\n.\n\n\nThe Encoding Profile\n\n\nEncoding profiles consist of a set of key-value pairs that conform to the following pattern:\n\n\nprofile.<name>.<context>.<property> = <value>\n\n\n\nFor example:\n\n\nprofile.flash.http.name = flash download\n\n\n\nAll profiles should have the following properties:\n\n\n.name\n.input  = [audio|visual|stream|image]\n.output = [audio|visual|stream|image]\n.suffix\n.mimetype\n.ffmpeg.command\n\n\n\nFor example:\n\n\n// My audio/video encoding profile\nprofile.my-av-profile.http.name           = my audio/video encoding profile\nprofile.my-av-profile.http.input          = visual\nprofile.my-av-profile.http.output         = visual\nprofile.my-av-profile.http.suffix         = -encoded.enc\nprofile.my-av-profile.http.mimetype       = video/x-enc\nprofile.my-av-profile.http.ffmpeg.command = -i #{in.video.path} -c:v venc -c:a aenc #{out.dir}/#{out.name}#{out.suffix}\n\n\n\nThe most important part of this profile is the \nffmpeg.command\n. This line specifies FFmpeg command line options using\n\n#{expression}\n for string replacement.\n\n\nFFmpeg\n\n\nTo create a new profile you have basically one task to do: Find an appropriate FFmpeg command line for whatever you want\nto do. For more information about FFmpeg, its options and how you can build FFmpeg with additional functionality have a\nlook at the \nOfficial FFmpeg Wiki\n. For trying out new encoding settings, just call FFmpeg\nfrom the command line.\n\n\nUsing a Profile\n\n\nOnce defined, use your encoding profile in your workflow by setting the encoding-profile property to the profiles name:\n\n\n<operation\n    id=\"compose\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encode presenter using my audio/video encoding profile\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/work</configuration>\n    <configuration key=\"target-flavor\">presenter/delivery</configuration>\n    <configuration key=\"target-tags\">rss, atom, captioning</configuration>\n    <configuration key=\"encoding-profile\">my-av-profile.http</configuration>\n  </configuration>\n</operation>\n\n\n\nHave a look at the Workflow Configuration section for more details about this.",
            "title": "Encoding"
        },
        {
            "location": "/configuration/encoding/#encoding-profile-configuration",
            "text": "A workflow defines which operations are applied to media ingested into Opencast and the order of these operations. An\noperation can be something general like \u201cencode this video\u201d. The encoding profiles then specify exactly how a media is\nancoded, which filters are applied, which codecs are used and in which container these will be stored, \u2026  Opencast comes with a set of such profiles generating files for both online playback and download. These profiles are\nbuild to work for everyone, meaning that in most cases optimization can be done according to local needs. So modifying\nthese profiles or building new ones often makes sense. This document will help you modify or augment Opencast's\ndefault encoding profiles for audio, video and still images.",
            "title": "Encoding Profile Configuration"
        },
        {
            "location": "/configuration/encoding/#default-profiles-and-possible-settings",
            "text": "This section contains some notes about the default profiles, explaining some thoughts behind those profiles and pointing\nat things you might want to change depending on your local set-up.",
            "title": "Default Profiles and Possible Settings"
        },
        {
            "location": "/configuration/encoding/#av-muxing-from-lossless-to-safe",
            "text": "The audio/video muxing (profile.mux-av.work) is applied if audio and video are send to Opencast separately. The basic\nidea behind this is, to combine these separate files into one file which can later be converted in one step.  Possible settings:   If you get an audio and a video file separately, it is possivle to just copy the streams and put them together into a\n   new file. This is very fast (you only have to copy the streams) and most importantly, it is lossless, as no\n   re-encoding is done. The question is: What a/v container format can/should you use for such an operation.  You can try to use the video container the input video came in and just add the audio. This means that you will never\n   have an unexpected video container you don't know of. I.e. if you put an .mp4 video in, it still uses and .mp4\n   container after musing, etc. This might, however, lead to problems if you throw in an audio file that cannot be muxen\n   in the specific container format (i.e. you have a FLAC audio file and an FLV container). This is, what Opencast\n   does at the moment.  To circumvent the container problem, we could also use a container format which can hold almost everything (i.e. mkv)\n   regardless of the input. This would mean that MH can handle more combinations of a/v streams but you will always end\n   up with a Matroska file after muxing. Of cause you can then encode it to mp4, etc. later on.   The safest option for muxing is, of cause, to always re-encode the streams. It is far slower. It always means a quality\nloss. But it can handle everything FFmpeg can handle which (dependin on your FFmpeg configuration) is quite a lot.",
            "title": "A/V-Muxing: From lossless to safe"
        },
        {
            "location": "/configuration/encoding/#trimming-fast-and-lossless-vs-accurate",
            "text": "The profile trim.work is used after you send your recording to trim/hold and selected new start and end points. Here you\nhave basically two choices:   As you only want to cut the video, you don't have to re-encode all of it. You just split the stream and put it into a\n   new file. This is fast. This is lossless. But depending on the video format this might not be accurate. You can only\n   cut a stream at an I-frame (a frame holding the full image). Doing this, FFmpeg will cut the video at the nearest\n   I-frame before the selected position meaning that you might end up with a bit more video than you thought you would\n   get. You can minimize this by making sure that the input video has a high I-frame frequency (probably a good idea\n   anyway). This is what Opencast does at the moment.  The alternative is to cut between two I-frames. This is possible, but requires the video to be re-encoded completely.\n   This means that you will spend a lot of time on this process and will always loose quality.",
            "title": "Trimming: Fast and lossless VS accurate"
        },
        {
            "location": "/configuration/encoding/#create-an-encoding-profile",
            "text": "This section will help you to understand how you can modify an existing profile or create a completly new one.  Creating a new encoding profile is a matter of creating a configuration file and placing it in the encoding profiles\nwatch folder.",
            "title": "Create an Encoding Profile"
        },
        {
            "location": "/configuration/encoding/#encoding-profile-folder",
            "text": "The  <config_dir>/encoding  folder allows you to quickly augment Opencast's existing behavior, simply by modifying or\nadding new configuration files. The file names should follow the pattern  *.properties .",
            "title": "Encoding Profile Folder"
        },
        {
            "location": "/configuration/encoding/#the-encoding-profile",
            "text": "Encoding profiles consist of a set of key-value pairs that conform to the following pattern:  profile.<name>.<context>.<property> = <value>  For example:  profile.flash.http.name = flash download  All profiles should have the following properties:  .name\n.input  = [audio|visual|stream|image]\n.output = [audio|visual|stream|image]\n.suffix\n.mimetype\n.ffmpeg.command  For example:  // My audio/video encoding profile\nprofile.my-av-profile.http.name           = my audio/video encoding profile\nprofile.my-av-profile.http.input          = visual\nprofile.my-av-profile.http.output         = visual\nprofile.my-av-profile.http.suffix         = -encoded.enc\nprofile.my-av-profile.http.mimetype       = video/x-enc\nprofile.my-av-profile.http.ffmpeg.command = -i #{in.video.path} -c:v venc -c:a aenc #{out.dir}/#{out.name}#{out.suffix}  The most important part of this profile is the  ffmpeg.command . This line specifies FFmpeg command line options using #{expression}  for string replacement.",
            "title": "The Encoding Profile"
        },
        {
            "location": "/configuration/encoding/#ffmpeg",
            "text": "To create a new profile you have basically one task to do: Find an appropriate FFmpeg command line for whatever you want\nto do. For more information about FFmpeg, its options and how you can build FFmpeg with additional functionality have a\nlook at the  Official FFmpeg Wiki . For trying out new encoding settings, just call FFmpeg\nfrom the command line.",
            "title": "FFmpeg"
        },
        {
            "location": "/configuration/encoding/#using-a-profile",
            "text": "Once defined, use your encoding profile in your workflow by setting the encoding-profile property to the profiles name:  <operation\n    id=\"compose\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encode presenter using my audio/video encoding profile\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/work</configuration>\n    <configuration key=\"target-flavor\">presenter/delivery</configuration>\n    <configuration key=\"target-tags\">rss, atom, captioning</configuration>\n    <configuration key=\"encoding-profile\">my-av-profile.http</configuration>\n  </configuration>\n</operation>  Have a look at the Workflow Configuration section for more details about this.",
            "title": "Using a Profile"
        },
        {
            "location": "/configuration/logging.and.privacy/",
            "text": "Logging and Privacy\n\n\nThe Opencast User-Tracking service stores user actions of the Opencast players in the database. This data is used for\nthe footprint feature of the player and for the optional analytics component.\n\n\n\n\nNote that enabling all of the logging option may result in legal problems depending on your contries privacy laws\nandthe type of service you are running.\n\n\n\n\nThe settings for logging user data can be found in:\n\n\n.../etc/org.opencastproject.usertracking.impl.UserTrackingServiceImpl.cfg\n\n\n\nLogging of user data can be controlled on two levels. First, logging can be generally activated or deactivated. Second,\nif it is activated, the data being logged can be defined.\n\n\norg.opencastproject.usertracking.detailedtrack\n defines if the user tracking JavaScript code is loaded and data about\nuser actions are being sent to and stored by Opencast. Deactivating this will effectively stop all logging. This may\neffect features like the footprints in the Opencast player.  Default: \ntrue\n.\n\n\nIf logging is still activated in general, the following keys may be used to define the kind of data that is being\nlogged. The keys have no effect if logging is turned off.\n\n\n\n\n\n\n\n\nKey\n\n\nData to be logged\n\n\nDefault value\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.usertracking.log.ip\n\n\nIP addresses\n\n\ntrue\n\n\n\n\n\n\norg.opencastproject.usertracking.log.user\n\n\nlogin names of users\n\n\ntrue\n\n\n\n\n\n\norg.opencastproject.usertracking.log.session\n\n\nBrowser session-IDs\n\n\ntrue\n\n\n\n\n\n\n\n\nIf you want to use the footprint feature but do not want to store any user specific data you can turn the logging of IP\naddresses, user names and session-IDs off.",
            "title": "Logging and Privacy"
        },
        {
            "location": "/configuration/logging.and.privacy/#logging-and-privacy",
            "text": "The Opencast User-Tracking service stores user actions of the Opencast players in the database. This data is used for\nthe footprint feature of the player and for the optional analytics component.   Note that enabling all of the logging option may result in legal problems depending on your contries privacy laws\nandthe type of service you are running.   The settings for logging user data can be found in:  .../etc/org.opencastproject.usertracking.impl.UserTrackingServiceImpl.cfg  Logging of user data can be controlled on two levels. First, logging can be generally activated or deactivated. Second,\nif it is activated, the data being logged can be defined.  org.opencastproject.usertracking.detailedtrack  defines if the user tracking JavaScript code is loaded and data about\nuser actions are being sent to and stored by Opencast. Deactivating this will effectively stop all logging. This may\neffect features like the footprints in the Opencast player.  Default:  true .  If logging is still activated in general, the following keys may be used to define the kind of data that is being\nlogged. The keys have no effect if logging is turned off.     Key  Data to be logged  Default value      org.opencastproject.usertracking.log.ip  IP addresses  true    org.opencastproject.usertracking.log.user  login names of users  true    org.opencastproject.usertracking.log.session  Browser session-IDs  true     If you want to use the footprint feature but do not want to store any user specific data you can turn the logging of IP\naddresses, user names and session-IDs off.",
            "title": "Logging and Privacy"
        },
        {
            "location": "/configuration/multi.tenancy/",
            "text": "Multi Tenancy Configuration\n\n\nIntroduction\n\n\nA single Opencast instance can handle mutliple tenants, each of which have their own recordings in the system.\nOpencast refers to tenants as \norganizations\n, and an HTTP request to the Opencast installation is mapped to an\norganization using the server name. Therefore, a Opencast instance will usually be set up with multiple DNS names\npointing to the same IP, for example:\n\n\n\n\ntenant1.matterhorn.edu\n\n\ntenant2.matterhorn.edu\n\n\n\n\nA tenant configuration thus consists mainly of the DNS name that is mapped to that tenant.\n\n\nDefault Setup\n\n\nOut of the box, Opencast has one tenant configured, called mh_default_org that is mapped to the server name\n\nlocalhost:8080\n. As long as there is one tenant configuration only, Opencast will map every request to that tenant\nregardless of the server name. As soon as a second tenant configuration is available, requests will be mapped to\norganizations using the server name, and an HTTP status code 404 will be returned for requests that hit the Opencast\nintallation that cannot be mapped to any organization.\n\n\nLimitations\n\n\nMulti tenancy in Opencast is working, however it is not fully finished. Certain objects are still shared amongst\norganizations, most notably workflow definitions, RSS/Atom feeds and encoding profiles.\n\n\nAdding A Tenant\n\n\nTo add a tenant to the installation, two things need to be put in place: a tenant configuration and a set of security\nrules. Assume that the new tenant is called \ntenant1\n and should be mapped to \ntenant1.myuniversity.edu\n.\n\n\nTenant Configuration\n\n\nCreate a file called org.opencastproject.organization-tenant1.cfg in the \netc/\n directory of your Opencast\ninstallation:\n\n\nid=tenant1\nname=Tenant 1\nserver=tenant1.myuniversity.edu\nport=8080\nadmin_role=ROLE_ADMIN\nanonymous_role=ROLE_ANONYMOUS\n\n# Admin and Presentation Server Urls\nprop.org.opencastproject.admin.ui.url=https://tenant1_admin.myuniversity.edu\nprop.org.opencastproject.engage.ui.url=https://tenant1_presentation.myuniversity.edu\n\n# Default properties for the user interface\nprop.logo_mediamodule=/img/MatterhornLogo_large.png\nprop.logo_player=/img/OpencastLogo.png\n\n# Define which parts of the admin ui should be visible\nprop.adminui.i18n_tab_episode.enable=false\nprop.adminui.i18n_tab_users.enable=false\n\n# Define which parts of the engage ui should be visible\nprop.engageui.link_download.enable=false\nprop.engageui.link_download.enable=false\n\n\n\nNote that if you are running Apache httpd with mod_proxy in front of the Opencast installation, the port number will be\n-1.\n\n\nSecurity Configuration\n\n\nCreate a file called tenant1.xml in /etc/security. This file specifies access rules for individual urls that specify\nwhich roles are needed in order to access a given url. In addition, it allows to define the directory services that are\nused to authenticate users. The file follows the standard ways on configuring Spring Security and you are free to add\nanything that can go into a Spring Security configuration.\n\n\nThe easiest way of creating that file is probably to create a copy of the already existing \nmh_default_org.xml\n.",
            "title": "Multi Tenancy"
        },
        {
            "location": "/configuration/multi.tenancy/#multi-tenancy-configuration",
            "text": "",
            "title": "Multi Tenancy Configuration"
        },
        {
            "location": "/configuration/multi.tenancy/#introduction",
            "text": "A single Opencast instance can handle mutliple tenants, each of which have their own recordings in the system.\nOpencast refers to tenants as  organizations , and an HTTP request to the Opencast installation is mapped to an\norganization using the server name. Therefore, a Opencast instance will usually be set up with multiple DNS names\npointing to the same IP, for example:   tenant1.matterhorn.edu  tenant2.matterhorn.edu   A tenant configuration thus consists mainly of the DNS name that is mapped to that tenant.",
            "title": "Introduction"
        },
        {
            "location": "/configuration/multi.tenancy/#default-setup",
            "text": "Out of the box, Opencast has one tenant configured, called mh_default_org that is mapped to the server name localhost:8080 . As long as there is one tenant configuration only, Opencast will map every request to that tenant\nregardless of the server name. As soon as a second tenant configuration is available, requests will be mapped to\norganizations using the server name, and an HTTP status code 404 will be returned for requests that hit the Opencast\nintallation that cannot be mapped to any organization.",
            "title": "Default Setup"
        },
        {
            "location": "/configuration/multi.tenancy/#limitations",
            "text": "Multi tenancy in Opencast is working, however it is not fully finished. Certain objects are still shared amongst\norganizations, most notably workflow definitions, RSS/Atom feeds and encoding profiles.",
            "title": "Limitations"
        },
        {
            "location": "/configuration/multi.tenancy/#adding-a-tenant",
            "text": "To add a tenant to the installation, two things need to be put in place: a tenant configuration and a set of security\nrules. Assume that the new tenant is called  tenant1  and should be mapped to  tenant1.myuniversity.edu .",
            "title": "Adding A Tenant"
        },
        {
            "location": "/configuration/multi.tenancy/#tenant-configuration",
            "text": "Create a file called org.opencastproject.organization-tenant1.cfg in the  etc/  directory of your Opencast\ninstallation:  id=tenant1\nname=Tenant 1\nserver=tenant1.myuniversity.edu\nport=8080\nadmin_role=ROLE_ADMIN\nanonymous_role=ROLE_ANONYMOUS\n\n# Admin and Presentation Server Urls\nprop.org.opencastproject.admin.ui.url=https://tenant1_admin.myuniversity.edu\nprop.org.opencastproject.engage.ui.url=https://tenant1_presentation.myuniversity.edu\n\n# Default properties for the user interface\nprop.logo_mediamodule=/img/MatterhornLogo_large.png\nprop.logo_player=/img/OpencastLogo.png\n\n# Define which parts of the admin ui should be visible\nprop.adminui.i18n_tab_episode.enable=false\nprop.adminui.i18n_tab_users.enable=false\n\n# Define which parts of the engage ui should be visible\nprop.engageui.link_download.enable=false\nprop.engageui.link_download.enable=false  Note that if you are running Apache httpd with mod_proxy in front of the Opencast installation, the port number will be\n-1.",
            "title": "Tenant Configuration"
        },
        {
            "location": "/configuration/multi.tenancy/#security-configuration",
            "text": "Create a file called tenant1.xml in /etc/security. This file specifies access rules for individual urls that specify\nwhich roles are needed in order to access a given url. In addition, it allows to define the directory services that are\nused to authenticate users. The file follows the standard ways on configuring Spring Security and you are free to add\nanything that can go into a Spring Security configuration.  The easiest way of creating that file is probably to create a copy of the already existing  mh_default_org.xml .",
            "title": "Security Configuration"
        },
        {
            "location": "/configuration/security/",
            "text": "Security Configuration\n\n\nThis document will help you configure the Opencast security policy.\n\n\nIntroduction\n\n\nOpencast service endpoints and user interfaces are secured by default using a set of servlet filters. The following\ndiagram illustrates the flow of an HTTP request and response through these filters.\n\n\n\n\nThe Spring Security filters used here are very powerful, but are also somewhat complicated. Please familiarize yourself\nwith the basic concepts and vocabulary described in the Spring Security documentation, then edit the xml files in\n\netc/security\n, as described below.\n\n\nConfigure Access\n\n\nTo configure access roles and URL patterns for a tenant, modify \n/etc/security/{{tenant_identifier.xml}}\n.  If you are\nnot hosting multiple tenants on your Opencast server or cluster, all configuration should be done in\n\nmh_default_org.xml\n.\n\n\nSome examples:\n\n\n<!-- Allow anonymous access to the welcome.html URLs -->\n<sec:intercept-url pattern='/welcome.html' access='ROLE_ANONYMOUS,ROLE_USER'/>\n\n<!-- Allow anonymous GET to the search service, but not POST or PUT -->\n<sec:intercept-url pattern='/search/**' method=\"GET\" access='ROLE_ANONYMOUS,ROLE_USER' />\n\n<!-- Allow users with the admin role to do anything -->\n<sec:intercept-url pattern='/**' access='ROLE_ADMIN'/>\n\n\n\nAuthentication Provider\n\n\nOpencast specifies an AuthenticationProvider by default, using a UserDetailService that is obtained from the OSGI\nservice registry.\n\n\nYou can use this simple provider as is, loading users into the \nmh_user\n and \nmh_role\n database tables, and specifying\nan administrative username and password in \ncustom.properties\n:\n\n\norg.opencastproject.security.digest.user=opencast_system_account\norg.opencastproject.security.digest.pass=CHANGE_ME\n\n\n\nThe set of user and role providers can be configured. If you do not want to keep users and passwords in Opencast's\ndatabase, you can replace the JpaUserAndRoleProvider with the LdapUserProvider by replacing the\nmatterhorn-userdirectory-jpa jar with the matterhorn-userdirectory-ldap jar.\n\n\nAdding Users to the Opencast Database\n\n\nAdditional users can be created by adding a username, organization and password hash to the \nmh_user\n table in the\nOpencast database. The default hash method is MD5 and the password must be salted with the username in curly braces.\n\n\nAt the moment, there is no graphical user interface for this task. It has to be done in the database.\n\n\nExample: Adding Garfield with the password 'monday' (in MySQL)\n\n\nINSERT INTO `opencast`.`mh_user` (`username`, `organization`, `password`) VALUES ('garfield', 'mh_default_org', MD5('monday{garfield}'));\n\n\n\nIn the next step roles for the newly created user can be added to the \nmh_role\n table. After that the created user and\nrole id can be added to the \nmh_user_role\n table. Here we set \nROLE_USER\n for Garfield:\n\n\nINSERT INTO `opencast`.`mh_role` (`organization`, `name`, `description`) VALUES ('mh_default_org', 'ROLE_USER', 'The user role');\nINSERT INTO `opencast`.`mh_user_role` (`user_id`, `role_id`) VALUES ('220', '221');\n\n\n\n Note that you must set the value of the organization field to the organization ID specified in one of the\n\n.../etc/org.opencast.organization-<organization_name>.cfg\n files. In a default installation this is\n\nmh_default_org\n.\n\n\nFurther Authentication Configuration\n\n\nConfigure Central Authentication Service (CAS)",
            "title": "General Security"
        },
        {
            "location": "/configuration/security/#security-configuration",
            "text": "This document will help you configure the Opencast security policy.",
            "title": "Security Configuration"
        },
        {
            "location": "/configuration/security/#introduction",
            "text": "Opencast service endpoints and user interfaces are secured by default using a set of servlet filters. The following\ndiagram illustrates the flow of an HTTP request and response through these filters.   The Spring Security filters used here are very powerful, but are also somewhat complicated. Please familiarize yourself\nwith the basic concepts and vocabulary described in the Spring Security documentation, then edit the xml files in etc/security , as described below.",
            "title": "Introduction"
        },
        {
            "location": "/configuration/security/#configure-access",
            "text": "To configure access roles and URL patterns for a tenant, modify  /etc/security/{{tenant_identifier.xml}} .  If you are\nnot hosting multiple tenants on your Opencast server or cluster, all configuration should be done in mh_default_org.xml .  Some examples:  <!-- Allow anonymous access to the welcome.html URLs -->\n<sec:intercept-url pattern='/welcome.html' access='ROLE_ANONYMOUS,ROLE_USER'/>\n\n<!-- Allow anonymous GET to the search service, but not POST or PUT -->\n<sec:intercept-url pattern='/search/**' method=\"GET\" access='ROLE_ANONYMOUS,ROLE_USER' />\n\n<!-- Allow users with the admin role to do anything -->\n<sec:intercept-url pattern='/**' access='ROLE_ADMIN'/>",
            "title": "Configure Access"
        },
        {
            "location": "/configuration/security/#authentication-provider",
            "text": "Opencast specifies an AuthenticationProvider by default, using a UserDetailService that is obtained from the OSGI\nservice registry.  You can use this simple provider as is, loading users into the  mh_user  and  mh_role  database tables, and specifying\nan administrative username and password in  custom.properties :  org.opencastproject.security.digest.user=opencast_system_account\norg.opencastproject.security.digest.pass=CHANGE_ME  The set of user and role providers can be configured. If you do not want to keep users and passwords in Opencast's\ndatabase, you can replace the JpaUserAndRoleProvider with the LdapUserProvider by replacing the\nmatterhorn-userdirectory-jpa jar with the matterhorn-userdirectory-ldap jar.",
            "title": "Authentication Provider"
        },
        {
            "location": "/configuration/security/#adding-users-to-the-opencast-database",
            "text": "Additional users can be created by adding a username, organization and password hash to the  mh_user  table in the\nOpencast database. The default hash method is MD5 and the password must be salted with the username in curly braces.  At the moment, there is no graphical user interface for this task. It has to be done in the database.  Example: Adding Garfield with the password 'monday' (in MySQL)  INSERT INTO `opencast`.`mh_user` (`username`, `organization`, `password`) VALUES ('garfield', 'mh_default_org', MD5('monday{garfield}'));  In the next step roles for the newly created user can be added to the  mh_role  table. After that the created user and\nrole id can be added to the  mh_user_role  table. Here we set  ROLE_USER  for Garfield:  INSERT INTO `opencast`.`mh_role` (`organization`, `name`, `description`) VALUES ('mh_default_org', 'ROLE_USER', 'The user role');\nINSERT INTO `opencast`.`mh_user_role` (`user_id`, `role_id`) VALUES ('220', '221');   Note that you must set the value of the organization field to the organization ID specified in one of the .../etc/org.opencast.organization-<organization_name>.cfg  files. In a default installation this is mh_default_org .",
            "title": "Adding Users to the Opencast Database"
        },
        {
            "location": "/configuration/security/#further-authentication-configuration",
            "text": "Configure Central Authentication Service (CAS)",
            "title": "Further Authentication Configuration"
        },
        {
            "location": "/configuration/security.cas/",
            "text": "Configure Central Authentication Service (CAS)\n\n\nCAS\n\n\nMany campuses use some kind of single sign on, such as JASIG's Central Authentication Service, or CAS. This guide\ndescribes how to integrate Opencast into such a system.\n\n\nStep 1\n\n\nFirst, install the optional CAS feature. Via the Karaf console, this can be done like this:\n\n\nfeature:install opencast-contrib-cas\n\n\n\nStep 2\n\n\nTo configure Opencast to use CAS, simply replace the default \nmh_default_org.xml\n with the contents of\n\nsecurity_sample_cas.xml\n, available in the Opencast source. You must modify several settings in the sample to point to\nyour CAS server:\n\n\n<bean id=\"casEntryPoint\" class=\"org.springframework.security.cas.web.CasAuthenticationEntryPoint\">\n  <property name=\"loginUrl\" value=\"https://auth-test.berkeley.edu/cas/login\"/>\n  <property name=\"serviceProperties\" ref=\"serviceProperties\"/>\n</bean>\n\n<bean id=\"casAuthenticationProvider\" class=\"org.springframework.security.cas.authentication.CasAuthenticationProvider\">\n  <property name=\"userDetailsService\" ref=\"userDetailsService\"/>\n  <property name=\"serviceProperties\" ref=\"serviceProperties\" />\n  <property name=\"ticketValidator\">\n    <bean class=\"org.jasig.cas.client.validation.Cas20ServiceTicketValidator\">\n      <constructor-arg index=\"0\" value=\"https://auth-test.berkeley.edu/cas\" />\n    </bean>\n  </property>\n  <property name=\"key\" value=\"cas\"/>\n</bean>\n\n\n\nYou will also need to set the public URL for your Opencast server:\n\n\n<bean id=\"serviceProperties\" class=\"org.springframework.security.cas.ServiceProperties\">\n  <property name=\"service\" value=\"http://localhost:8080/j_spring_cas_security_check\"/>\n  <property name=\"sendRenew\" value=\"false\"/>\n</bean>\n\n\n\nStep 3\n\n\nAssuming you are using Opencast version 1.4 and are using LDAP for user provisioning, you will need to build and deploy\nrelevant modules with:\n\n\nmvn clean install -Pdirectory-ldap,directory-cas,directory-openid -DdeployTo={your runtime server location here}\n\n\n\nIf not using LDAP, of course, you don't need the directory-ldap module but CAS alone will require deploying both the\ndirectory-cas and directory-openid modules.\n\n\nStep 4\n\n\nFinally, you will need to configure a UserProvider to look up users as identified by CAS, for example see:\n\n\nUniversity of Saskatchewan CAS and LDAP integration",
            "title": "Central Authentication Service (CAS)"
        },
        {
            "location": "/configuration/security.cas/#configure-central-authentication-service-cas",
            "text": "",
            "title": "Configure Central Authentication Service (CAS)"
        },
        {
            "location": "/configuration/security.cas/#cas",
            "text": "Many campuses use some kind of single sign on, such as JASIG's Central Authentication Service, or CAS. This guide\ndescribes how to integrate Opencast into such a system.",
            "title": "CAS"
        },
        {
            "location": "/configuration/security.cas/#step-1",
            "text": "First, install the optional CAS feature. Via the Karaf console, this can be done like this:  feature:install opencast-contrib-cas",
            "title": "Step 1"
        },
        {
            "location": "/configuration/security.cas/#step-2",
            "text": "To configure Opencast to use CAS, simply replace the default  mh_default_org.xml  with the contents of security_sample_cas.xml , available in the Opencast source. You must modify several settings in the sample to point to\nyour CAS server:  <bean id=\"casEntryPoint\" class=\"org.springframework.security.cas.web.CasAuthenticationEntryPoint\">\n  <property name=\"loginUrl\" value=\"https://auth-test.berkeley.edu/cas/login\"/>\n  <property name=\"serviceProperties\" ref=\"serviceProperties\"/>\n</bean>\n\n<bean id=\"casAuthenticationProvider\" class=\"org.springframework.security.cas.authentication.CasAuthenticationProvider\">\n  <property name=\"userDetailsService\" ref=\"userDetailsService\"/>\n  <property name=\"serviceProperties\" ref=\"serviceProperties\" />\n  <property name=\"ticketValidator\">\n    <bean class=\"org.jasig.cas.client.validation.Cas20ServiceTicketValidator\">\n      <constructor-arg index=\"0\" value=\"https://auth-test.berkeley.edu/cas\" />\n    </bean>\n  </property>\n  <property name=\"key\" value=\"cas\"/>\n</bean>  You will also need to set the public URL for your Opencast server:  <bean id=\"serviceProperties\" class=\"org.springframework.security.cas.ServiceProperties\">\n  <property name=\"service\" value=\"http://localhost:8080/j_spring_cas_security_check\"/>\n  <property name=\"sendRenew\" value=\"false\"/>\n</bean>",
            "title": "Step 2"
        },
        {
            "location": "/configuration/security.cas/#step-3",
            "text": "Assuming you are using Opencast version 1.4 and are using LDAP for user provisioning, you will need to build and deploy\nrelevant modules with:  mvn clean install -Pdirectory-ldap,directory-cas,directory-openid -DdeployTo={your runtime server location here}  If not using LDAP, of course, you don't need the directory-ldap module but CAS alone will require deploying both the\ndirectory-cas and directory-openid modules.",
            "title": "Step 3"
        },
        {
            "location": "/configuration/security.cas/#step-4",
            "text": "Finally, you will need to configure a UserProvider to look up users as identified by CAS, for example see:  University of Saskatchewan CAS and LDAP integration",
            "title": "Step 4"
        },
        {
            "location": "/configuration/security.ldap/",
            "text": "LDAP Authentication and Authorization (without CAS)\n\n\n\n\nThis page describes how to use only an LDAP server to authenticate users in Opencast. If you just want to use LDAP\n\n\nas an identity provider for another authentication mechanism, such as a CAS server, this guide does not apply to\n\n\nyou.\n\n\nYou may find the instructions to configure an LDAP-backed CAS server \nhere\n.\n\n\n\n\nAuthentication\n\n\nIn order to authenticate your Opencast users using an LDAP server, you must follow the following steps:\n\n\nStep 1\n\n\nIn a single-tenant deployment, your \nsecurity.xml\n file is under \nOPENCAST_HOME/security/mh_default_org.xml\n. In an\nRPM-based installation, it is located in \n/etc/opencast/security/mh_default_org.xml\n. You should make a backup copy of\nthe file and substitute it by the sample file named \nsecurity_sample_ldap.xml-example\n. In other words:\n\n\n$> cd etc/security\n$> mv mh_default_org.xml mh_default_org.xml.old\n$> cp security_sample_ldap.xml-example mh_default_org.xml\n\n\n\nThe sample file should be exactly the same as the default security file, except for the parts only relevant to the\nLDAP. If you have done custom modifications to your security file, make sure to incorporate them to the new file, too.\n\n\nStep 2\n\n\nAdd the necessary configuration values to the LDAP section of the new security file. The comments should be\nself-explanatory.\n\n\nThe first relevant section defines a context source. This contains the basic login information that enables Opencast to\nrequest user information to the LDAP server in order to authenticate them.\n\n\n<bean id=\"contextSource\"\n  class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\">\n  <!-- URL of the LDAP server -->\n  <constructor-arg value=\"ldap://myldapserver:myport\" />\n  <!-- \"Distinguished name\" for the unprivileged user -->\n  <!-- This user is merely to perform searches in the LDAP to find the users to login -->\n  <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" />\n  <!-- Password of the user above -->\n  <property name=\"password\" value=\"mypassword\" />\n</bean>\n\n\n\nThe next part tells the system how to search for users in the LDAP server:\n\n\n<constructor-arg>\n  <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\">\n    <constructor-arg ref=\"contextSource\" />\n    <property name=\"userDnPatterns\">\n      <list>\n        <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed -->\n        <value>uid={0},ou=Group,dc=my-institution,dc=country</value>\n      </list>\n    </property>\n    <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them -->\n    <!-- This property can be used together with the \"userDnPatterns\" above -->\n    <!--\n    <property name=\"userSearch\">\n      <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\">\n        < ! - - Base Dn from where the users will be searched for - - >\n        <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" />\n        < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - >\n        <constructor-arg index=\"1\" value=\"(uid={0})\" />\n        <constructor-arg ref=\"contextSource\" />\n      </bean>\n    </property>\n    -->\n  </bean>\n</constructor-arg>\n\n\n\nAs the previous snippet shows, there are two alternative ways to find users in your LDAP:\n\n\n\n\nUsing the property userDnPatterns:\n This property accepts a list of search patterns to match against the user's\nDN. The patterns will be tried in order until a match is found. The placeholder \n{0}\n can be used to represent the\nusername in such patterns.\n\n\nUsing a userSearch filter:\n With the previous approach, it is not possible to find users whose login name is not\npart of their DN. In such cases, you can use the userSearch property, that allows you to search the users based on a\nfilter. The filter requires three parameters:\n\n\nThe first parameter specifies the \"root node\" where the searches will start from.\n\n\nThe second one specifies the filter, where, again, the placeholder \n{0}\n will be substituted by the username\nduring the searches.\n\n\nThe third parameter should be the contextSource defined above.\n\n\n\n\n\n\n\n\nBoth methods are not mutually exclusive --i.e. both can be activated at the same time, even though only the first one\nis uncommented in the sample file because it is the most usual.\n\n\nAuthorization\n\n\nNow the system knows all the information necessary to authenticate users against the LDAP, but also need some\nauthorization information, to tell which services the user is allowed to use and which resources is allowed to see\nand/or modify.\n\n\nStep 1\n\n\nThe following snippet in the \nsecurity.xml\n file provides the necessary information to map LDAP attributes to roles\nduring authentication and in single-machine environments.\n\n\n<constructor-arg>\n  <!-- Get the authorities (roles) according to a certain attribute in the authenticated user -->\n  <bean class=\"org.opencastproject.kernel.userdirectory.LdapAttributeAuthoritiesPopulator\">\n    <constructor-arg>\n      <!-- List of attribute names in the user from which roles will be created -->\n      <!-- The specified attributes must meet few requirements:\n             * They may be single-valued or multivalued\n             * They may contain single roles or comma-separated role lists\n\n           The attributes read will be processed in the following way:\n             * Whitespace will converted to underscores (\"_\")\n             * Sequences of underscores (\"_\") will be collapsed into a single one.\n      -->\n      <list>\n        <value>attributeName1</value>\n        <value>attributeName2</value>\n      </list>\n    </constructor-arg>\n    <!-- Whether or not to make all the extracted roles uppercase. 'true' by default. -->\n    <!-- <property name=\"convertToUpperCase\" value=\"true\"/> -->\n\n    <!-- Define a prefix to be appended to every role extracted from the LDAP. -->\n    <!-- The convertToUpperCase property also affects the prefix -->\n    <!-- <property name=\"rolePrefix\" value=\"\"/> -->\n\n    <!-- Additional roles that will be added to those obtained from the attributes above -->\n    <!-- The convertToUpperCase and rolePrefix properties also affect the roles indicated here-->\n    <!-- <property name=\"additionalAuthorities\">\n      <set>\n        <value>additional_authority_1</value>\n        <value>additional_authority_2</value>\n      </set>\n    </property> -->\n  </bean>\n</constructor-arg>\n\n\n\nAs you can see, the sample file is quite self-explanatory: a list of attribute names is provided, each of which will\ncontain the roles this user will be assigned to. These attributes may be multivalued (i.e. they may appear several\ntimes in the user) and/or they may contain a comma-separated list of roles. The syntax of the roles found will be\nchecked so that they contain no whitespaces (they will be substituted by underscore characters  -\"_\"-) and all the\nresulting underscore sequences will be collapsed to a single character. The resulting roles will be converted to\nuppercase and finally assigned to the user.\n\n\nApart from the previous processing, a series of properties may be used to further customize the role syntax. In\nparticular, a prefix can be defined, which will be appended to every role obtained using the process described above.\nThe role capitalisation can also be disabled if desired.\n\n\nFinally, it is possible to define an additional set of roles that will be appended to the list obtained by inspecting\nthe LDAP according to the configuration. In other words, every user will have, at least, the roles defined in this\nlist. The roles will be processed in the same way as the roles obtained from the LDAP server.\n\n\nStep 2\n\n\n\n\nThis step is only necessary in Opencast deployments along multiple machines.\n\n\n\n\nEdit the file \netc/factories/org.opencastproject.userdirectory.ldap.properties\n and include the same authentication\nparameters as in the \nsecurity.xml\n file. The contents should be self-explanatory:\n\n\n# In order to configure one or more LDAP configurations, set the \"instances\" field to the correct value\n# and add the property keys by appending the respective number to it.\ninstances=0\n\n#\n# The property keys that can be used when setting up LDAP connections.  Be careful not to include spaces.\n#\nkeys=org.opencastproject.userdirectory.ldap.url,org.opencastproject.userdirectory.ldap.searchbase,\\\norg.opencastproject.userdirectory.ldap.searchfilter,org.opencastproject.userdirectory.ldap.cache.size,\\\n org.opencastproject.userdirectory.ldap.cache.expiration,org.opencastproject.userdirectory.ldap.roleattributes,\\\norg.opencastproject.userdirectory.ldap.org\n\n#\n# First sample configuration\n#\n\n# The URL to the LDAP server\n#org.opencastproject.userdirectory.ldap.url.1=ldap://ldap.berkeley.edu\n\n# The user and password used for LDAP authentication.  If left commented, the LDAP provider will use an anonymous bind.\n# If uncommenting these, add them to the keys at the bottom of this file.\n#org.opencastproject.userdirectory.ldap.userDn.1=\n#org.opencastproject.userdirectory.ldap.password.1=\n\n# The base path within LDAP to search for users\n#org.opencastproject.userdirectory.ldap.searchbase.1=ou=people,dc=berkeley,dc=edu\n\n# The search filter to use for identifying users by ID\n#org.opencastproject.userdirectory.ldap.searchfilter.1=(uid={0})\n\n# The maximum number of users to cache\n#org.opencastproject.userdirectory.ldap.cache.size.1=1000\n\n# The maximum number of minutes to cache a user\n#org.opencastproject.userdirectory.ldap.cache.expiration.1=5\n\n# The comma-separated list of attributes that will be translated into roles. Note that the attributes will be prefixed\n# with the string \"ROLE_\" and the attribute value will be transformed to upper case.\n#org.opencastproject.userdirectory.ldap.roleattributes.1=berkeleyEduAffiliations,departmentNumber\n\n# The organization for this provider\n#org.opencastproject.userdirectory.ldap.org.1=mh_default_org\n\n\n\nCombination with Existing authorization Mechanisms\n\n\nIn the default configuration included in the \nsecurity_sample_ldap.xml-example\n file, the LDAP is tried after the\nnormal authorization mechanisms (i.e. the database). This means that if a user is present in both the database and the\nLDAP, the database will take precedence. The order is determined by the order in which the authentication providers\nappear on the security file. The relevant snippet is this:\n\n\n<sec:authentication-manager alias=\"authenticationManager\">\n  <sec:authentication-provider user-service-ref=\"userDetailsService\">  # \\\n    <sec:password-encoder hash=\"md5\">                                  # |\n      <sec:salt-source user-property=\"username\" />                     # -> These lines must be moved as a block\n    </sec:password-encoder>                                            # |\n  </sec:authentication-provider>                                       # /\n  <sec:authentication-provider ref=\"ldapAuthProvider\" />               # The LDAP provider appears in the second position, therefore it is the second provider to consider\n</sec:authentication-manager>\n\n\n\nBy switching the position of the authentication providers, you will give them more or less priority.\n\n\nAdding more LDAP servers\n\n\nMore LDAP servers can be added to the configuration by including the LDAP-related sections as many times as necessary\nwith their corresponding configurations. All the defined authentication providers must be added to the providers list\nat the bottom of the file. Please see the example below:\n\n\n<bean id=\"contextSource\"\n  class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\">\n  <!-- URL of the LDAP server -->\n  <constructor-arg value=\"ldap://myldapserver:myport\" />\n  <!-- \"Distinguished name\" for the unprivileged user -->\n  <!-- This user is merely to perform searches in the LDAP to find the users to login -->\n  <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" />\n  <!-- Password of the user above -->\n  <property name=\"password\" value=\"mypassword\" />\n</bean>\n\n<bean id=\"ldapAuthProvider\"\n  class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\">\n  <constructor-arg>\n    <bean\n      class=\"org.springframework.security.ldap.authentication.BindAuthenticator\">\n      <constructor-arg ref=\"contextSource\" />\n      <property name=\"userDnPatterns\">\n        <list>\n          <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed -->\n          <value>uid={0},ou=Group,dc=my-institution,dc=country</value>\n        </list>\n     </property>\n     <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them -->\n     <!-- This property can be used together with the \"userDnPatterns\" above -->\n     <!--\n     <property name=\"userSearch\">\n       <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\">\n         < ! - - Base Dn from where the users will be searched for - - >\n         <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" />\n         < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - >\n         <constructor-arg index=\"1\" value=\"(uid={0})\" />\n         <constructor-arg ref=\"contextSource\" />\n       </bean>\n      </property>\n     -->\n    </bean>\n  </constructor-arg>\n  <!-- Defines how the user attributes are converted to authorities (roles) -->\n  <constructor-arg>\n    <!-- Get the authorities (roles) according to a certain attribute in the authenticated user -->\n    <bean class=\"org.opencastproject.kernel.userdirectory.LdapAttributeAuthoritiesPopulator\">\n      <constructor-arg>\n        <!-- List of attribute names in the user from which roles will be created -->\n        <!-- The specified attributes must meet few requirements:\n               * They may be single-valued or multivalued\n               * They may contain single roles or comma-separated role lists\n\n          The attributes read will be processed in the following way:\n               * Whitespace will converted to underscores (\"_\")\n               * Sequences of underscores (\"_\") will be collapsed into a single one.\n        -->\n        <list>\n          <value>attributeName1</value>\n          <value>attributeName2</value>\n        </list>\n      </constructor-arg>\n      <!-- Whether or not to make all the extracted roles uppercase. 'true' by default. -->\n      <!-- <property name=\"convertToUpperCase\" value=\"true\"/> -->\n\n      <!-- Define a prefix to be appended to every role extracted from the LDAP. -->\n      <!-- The convertToUpperCase property also affects the prefix -->\n      <!-- <property name=\"rolePrefix\" value=\"\"/> -->\n\n      <!-- Additional roles that will be added to those obtained from the attributes above -->\n      <!-- The convertToUpperCase and rolePrefix properties also affect the roles indicated here-->\n      <!-- <property name=\"additionalAuthorities\">\n        <set>\n          <value>additional_authority_1</value>\n          <value>additional_authority_2</value>\n        </set>\n      </property>\n      -->\n    </bean>\n  </constructor-arg>\n</bean>\n\n<!-- PLEASE NOTE: The ID below must be changed for each context source instance -->\n<bean id=\"contextSource2\"\n  class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\">\n  <constructor-arg value=\"ldap://myldapserver:myport\" />\n  <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" />\n  <property name=\"password\" value=\"mypassword\" />\n</bean>\n\n<!-- PLEASE NOTE: The ID below must be changed for each LDAP authentication provider instance -->\n<bean id=\"ldapAuthProvider2\"\n  class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\">\n  <constructor-arg>\n    <bean\n      class=\"org.springframework.security.ldap.authentication.BindAuthenticator\">\n      <!-- PLEASE NOTE: the ref below must match the corresponding context source ID -->\n      <constructor-arg ref=\"contextSource2\" />\n       <property name=\"userDnPatterns\">\n        <list>\n          <value>uid={0},ou=OtherGroup,dc=my-other-institution,dc=other-country</value>\n        </list>\n       </property>\n    <property name=\"userSearch\">\n      <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\">\n        <constructor-arg index=\"0\" value=\"ou=OtherGroup,dc=my-other-institution,dc=other-country\" />\n        <constructor-arg index=\"1\" value=\"(uid={0})\" />\n             <!-- PLEASE NOTE: the ref below must match the corresponding context source ID -->\n        <constructor-arg ref=\"contextSource2\" />\n         </bean>\n       </property>\n     </bean>\n  </constructor-arg>\n  <constructor-arg>\n    <bean class=\"org.opencastproject.kernel.userdirectory.LdapAttributeAuthoritiesPopulator\">\n      <constructor-arg>\n        <list>\n          <value>otherAttributeName1</value>\n          <value>otherAttributeName2</value>\n        </list>\n      </constructor-arg>\n   <property name=\"rolePrefix\" value=\"my_prefix_\"/>\n   <property name=\"additionalAuthorities\">\n     <set>\n       <value>default_role_1</value>\n       <value>default_role_2</value>\n     </set>\n   </property>\n    </bean>\n  </constructor-arg>\n</bean>\n\n<!-- [ ... SKIPPED LINES ... ] -->\n\n<sec:authentication-manager alias=\"authenticationManager\">\n  <sec:authentication-provider user-service-ref=\"userDetailsService\">\n    <sec:password-encoder hash=\"md5\">\n      <sec:salt-source user-property=\"username\" />\n    </sec:password-encoder>\n  </sec:authentication-provider>\n  <!-- PLEASE NOTE: In this example, the 2nd LDAP provider defined in the file has more priority that the first one -->\n  <sec:authentication-provider ref=\"ldapAuthProvider2\" />\n  <sec:authentication-provider ref=\"ldapAuthProvider\" />\n</sec:authentication-manager>\n\n\n\nIn multi-machine installations, remember to include the additional LDAP server(s) in the\n\netc/factories/org.opencastproject.userdirectory.ldap.properties\n file.",
            "title": "LDAP Authentication and Authorization (without CAS)"
        },
        {
            "location": "/configuration/security.ldap/#ldap-authentication-and-authorization-without-cas",
            "text": "This page describes how to use only an LDAP server to authenticate users in Opencast. If you just want to use LDAP  as an identity provider for another authentication mechanism, such as a CAS server, this guide does not apply to  you.  You may find the instructions to configure an LDAP-backed CAS server  here .",
            "title": "LDAP Authentication and Authorization (without CAS)"
        },
        {
            "location": "/configuration/security.ldap/#authentication",
            "text": "In order to authenticate your Opencast users using an LDAP server, you must follow the following steps:",
            "title": "Authentication"
        },
        {
            "location": "/configuration/security.ldap/#step-1",
            "text": "In a single-tenant deployment, your  security.xml  file is under  OPENCAST_HOME/security/mh_default_org.xml . In an\nRPM-based installation, it is located in  /etc/opencast/security/mh_default_org.xml . You should make a backup copy of\nthe file and substitute it by the sample file named  security_sample_ldap.xml-example . In other words:  $> cd etc/security\n$> mv mh_default_org.xml mh_default_org.xml.old\n$> cp security_sample_ldap.xml-example mh_default_org.xml  The sample file should be exactly the same as the default security file, except for the parts only relevant to the\nLDAP. If you have done custom modifications to your security file, make sure to incorporate them to the new file, too.",
            "title": "Step 1"
        },
        {
            "location": "/configuration/security.ldap/#step-2",
            "text": "Add the necessary configuration values to the LDAP section of the new security file. The comments should be\nself-explanatory.  The first relevant section defines a context source. This contains the basic login information that enables Opencast to\nrequest user information to the LDAP server in order to authenticate them.  <bean id=\"contextSource\"\n  class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\">\n  <!-- URL of the LDAP server -->\n  <constructor-arg value=\"ldap://myldapserver:myport\" />\n  <!-- \"Distinguished name\" for the unprivileged user -->\n  <!-- This user is merely to perform searches in the LDAP to find the users to login -->\n  <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" />\n  <!-- Password of the user above -->\n  <property name=\"password\" value=\"mypassword\" />\n</bean>  The next part tells the system how to search for users in the LDAP server:  <constructor-arg>\n  <bean class=\"org.springframework.security.ldap.authentication.BindAuthenticator\">\n    <constructor-arg ref=\"contextSource\" />\n    <property name=\"userDnPatterns\">\n      <list>\n        <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed -->\n        <value>uid={0},ou=Group,dc=my-institution,dc=country</value>\n      </list>\n    </property>\n    <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them -->\n    <!-- This property can be used together with the \"userDnPatterns\" above -->\n    <!--\n    <property name=\"userSearch\">\n      <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\">\n        < ! - - Base Dn from where the users will be searched for - - >\n        <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" />\n        < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - >\n        <constructor-arg index=\"1\" value=\"(uid={0})\" />\n        <constructor-arg ref=\"contextSource\" />\n      </bean>\n    </property>\n    -->\n  </bean>\n</constructor-arg>  As the previous snippet shows, there are two alternative ways to find users in your LDAP:   Using the property userDnPatterns:  This property accepts a list of search patterns to match against the user's\nDN. The patterns will be tried in order until a match is found. The placeholder  {0}  can be used to represent the\nusername in such patterns.  Using a userSearch filter:  With the previous approach, it is not possible to find users whose login name is not\npart of their DN. In such cases, you can use the userSearch property, that allows you to search the users based on a\nfilter. The filter requires three parameters:  The first parameter specifies the \"root node\" where the searches will start from.  The second one specifies the filter, where, again, the placeholder  {0}  will be substituted by the username\nduring the searches.  The third parameter should be the contextSource defined above.     Both methods are not mutually exclusive --i.e. both can be activated at the same time, even though only the first one\nis uncommented in the sample file because it is the most usual.",
            "title": "Step 2"
        },
        {
            "location": "/configuration/security.ldap/#authorization",
            "text": "Now the system knows all the information necessary to authenticate users against the LDAP, but also need some\nauthorization information, to tell which services the user is allowed to use and which resources is allowed to see\nand/or modify.",
            "title": "Authorization"
        },
        {
            "location": "/configuration/security.ldap/#step-1_1",
            "text": "The following snippet in the  security.xml  file provides the necessary information to map LDAP attributes to roles\nduring authentication and in single-machine environments.  <constructor-arg>\n  <!-- Get the authorities (roles) according to a certain attribute in the authenticated user -->\n  <bean class=\"org.opencastproject.kernel.userdirectory.LdapAttributeAuthoritiesPopulator\">\n    <constructor-arg>\n      <!-- List of attribute names in the user from which roles will be created -->\n      <!-- The specified attributes must meet few requirements:\n             * They may be single-valued or multivalued\n             * They may contain single roles or comma-separated role lists\n\n           The attributes read will be processed in the following way:\n             * Whitespace will converted to underscores (\"_\")\n             * Sequences of underscores (\"_\") will be collapsed into a single one.\n      -->\n      <list>\n        <value>attributeName1</value>\n        <value>attributeName2</value>\n      </list>\n    </constructor-arg>\n    <!-- Whether or not to make all the extracted roles uppercase. 'true' by default. -->\n    <!-- <property name=\"convertToUpperCase\" value=\"true\"/> -->\n\n    <!-- Define a prefix to be appended to every role extracted from the LDAP. -->\n    <!-- The convertToUpperCase property also affects the prefix -->\n    <!-- <property name=\"rolePrefix\" value=\"\"/> -->\n\n    <!-- Additional roles that will be added to those obtained from the attributes above -->\n    <!-- The convertToUpperCase and rolePrefix properties also affect the roles indicated here-->\n    <!-- <property name=\"additionalAuthorities\">\n      <set>\n        <value>additional_authority_1</value>\n        <value>additional_authority_2</value>\n      </set>\n    </property> -->\n  </bean>\n</constructor-arg>  As you can see, the sample file is quite self-explanatory: a list of attribute names is provided, each of which will\ncontain the roles this user will be assigned to. These attributes may be multivalued (i.e. they may appear several\ntimes in the user) and/or they may contain a comma-separated list of roles. The syntax of the roles found will be\nchecked so that they contain no whitespaces (they will be substituted by underscore characters  -\"_\"-) and all the\nresulting underscore sequences will be collapsed to a single character. The resulting roles will be converted to\nuppercase and finally assigned to the user.  Apart from the previous processing, a series of properties may be used to further customize the role syntax. In\nparticular, a prefix can be defined, which will be appended to every role obtained using the process described above.\nThe role capitalisation can also be disabled if desired.  Finally, it is possible to define an additional set of roles that will be appended to the list obtained by inspecting\nthe LDAP according to the configuration. In other words, every user will have, at least, the roles defined in this\nlist. The roles will be processed in the same way as the roles obtained from the LDAP server.",
            "title": "Step 1"
        },
        {
            "location": "/configuration/security.ldap/#step-2_1",
            "text": "This step is only necessary in Opencast deployments along multiple machines.   Edit the file  etc/factories/org.opencastproject.userdirectory.ldap.properties  and include the same authentication\nparameters as in the  security.xml  file. The contents should be self-explanatory:  # In order to configure one or more LDAP configurations, set the \"instances\" field to the correct value\n# and add the property keys by appending the respective number to it.\ninstances=0\n\n#\n# The property keys that can be used when setting up LDAP connections.  Be careful not to include spaces.\n#\nkeys=org.opencastproject.userdirectory.ldap.url,org.opencastproject.userdirectory.ldap.searchbase,\\\norg.opencastproject.userdirectory.ldap.searchfilter,org.opencastproject.userdirectory.ldap.cache.size,\\\n org.opencastproject.userdirectory.ldap.cache.expiration,org.opencastproject.userdirectory.ldap.roleattributes,\\\norg.opencastproject.userdirectory.ldap.org\n\n#\n# First sample configuration\n#\n\n# The URL to the LDAP server\n#org.opencastproject.userdirectory.ldap.url.1=ldap://ldap.berkeley.edu\n\n# The user and password used for LDAP authentication.  If left commented, the LDAP provider will use an anonymous bind.\n# If uncommenting these, add them to the keys at the bottom of this file.\n#org.opencastproject.userdirectory.ldap.userDn.1=\n#org.opencastproject.userdirectory.ldap.password.1=\n\n# The base path within LDAP to search for users\n#org.opencastproject.userdirectory.ldap.searchbase.1=ou=people,dc=berkeley,dc=edu\n\n# The search filter to use for identifying users by ID\n#org.opencastproject.userdirectory.ldap.searchfilter.1=(uid={0})\n\n# The maximum number of users to cache\n#org.opencastproject.userdirectory.ldap.cache.size.1=1000\n\n# The maximum number of minutes to cache a user\n#org.opencastproject.userdirectory.ldap.cache.expiration.1=5\n\n# The comma-separated list of attributes that will be translated into roles. Note that the attributes will be prefixed\n# with the string \"ROLE_\" and the attribute value will be transformed to upper case.\n#org.opencastproject.userdirectory.ldap.roleattributes.1=berkeleyEduAffiliations,departmentNumber\n\n# The organization for this provider\n#org.opencastproject.userdirectory.ldap.org.1=mh_default_org",
            "title": "Step 2"
        },
        {
            "location": "/configuration/security.ldap/#combination-with-existing-authorization-mechanisms",
            "text": "In the default configuration included in the  security_sample_ldap.xml-example  file, the LDAP is tried after the\nnormal authorization mechanisms (i.e. the database). This means that if a user is present in both the database and the\nLDAP, the database will take precedence. The order is determined by the order in which the authentication providers\nappear on the security file. The relevant snippet is this:  <sec:authentication-manager alias=\"authenticationManager\">\n  <sec:authentication-provider user-service-ref=\"userDetailsService\">  # \\\n    <sec:password-encoder hash=\"md5\">                                  # |\n      <sec:salt-source user-property=\"username\" />                     # -> These lines must be moved as a block\n    </sec:password-encoder>                                            # |\n  </sec:authentication-provider>                                       # /\n  <sec:authentication-provider ref=\"ldapAuthProvider\" />               # The LDAP provider appears in the second position, therefore it is the second provider to consider\n</sec:authentication-manager>  By switching the position of the authentication providers, you will give them more or less priority.",
            "title": "Combination with Existing authorization Mechanisms"
        },
        {
            "location": "/configuration/security.ldap/#adding-more-ldap-servers",
            "text": "More LDAP servers can be added to the configuration by including the LDAP-related sections as many times as necessary\nwith their corresponding configurations. All the defined authentication providers must be added to the providers list\nat the bottom of the file. Please see the example below:  <bean id=\"contextSource\"\n  class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\">\n  <!-- URL of the LDAP server -->\n  <constructor-arg value=\"ldap://myldapserver:myport\" />\n  <!-- \"Distinguished name\" for the unprivileged user -->\n  <!-- This user is merely to perform searches in the LDAP to find the users to login -->\n  <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" />\n  <!-- Password of the user above -->\n  <property name=\"password\" value=\"mypassword\" />\n</bean>\n\n<bean id=\"ldapAuthProvider\"\n  class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\">\n  <constructor-arg>\n    <bean\n      class=\"org.springframework.security.ldap.authentication.BindAuthenticator\">\n      <constructor-arg ref=\"contextSource\" />\n      <property name=\"userDnPatterns\">\n        <list>\n          <!-- Dn patterns to search for valid users. Multiple \"<value>\" tags are allowed -->\n          <value>uid={0},ou=Group,dc=my-institution,dc=country</value>\n        </list>\n     </property>\n     <!-- If your user IDs are not part of the user Dn's, you can use a search filter to find them -->\n     <!-- This property can be used together with the \"userDnPatterns\" above -->\n     <!--\n     <property name=\"userSearch\">\n       <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\">\n         < ! - - Base Dn from where the users will be searched for - - >\n         <constructor-arg index=\"0\" value=\"ou=GroupName,dc=my-institution,dc=country\" />\n         < ! - - Filter to located valid users. Use {0} as a placeholder for the login name - - >\n         <constructor-arg index=\"1\" value=\"(uid={0})\" />\n         <constructor-arg ref=\"contextSource\" />\n       </bean>\n      </property>\n     -->\n    </bean>\n  </constructor-arg>\n  <!-- Defines how the user attributes are converted to authorities (roles) -->\n  <constructor-arg>\n    <!-- Get the authorities (roles) according to a certain attribute in the authenticated user -->\n    <bean class=\"org.opencastproject.kernel.userdirectory.LdapAttributeAuthoritiesPopulator\">\n      <constructor-arg>\n        <!-- List of attribute names in the user from which roles will be created -->\n        <!-- The specified attributes must meet few requirements:\n               * They may be single-valued or multivalued\n               * They may contain single roles or comma-separated role lists\n\n          The attributes read will be processed in the following way:\n               * Whitespace will converted to underscores (\"_\")\n               * Sequences of underscores (\"_\") will be collapsed into a single one.\n        -->\n        <list>\n          <value>attributeName1</value>\n          <value>attributeName2</value>\n        </list>\n      </constructor-arg>\n      <!-- Whether or not to make all the extracted roles uppercase. 'true' by default. -->\n      <!-- <property name=\"convertToUpperCase\" value=\"true\"/> -->\n\n      <!-- Define a prefix to be appended to every role extracted from the LDAP. -->\n      <!-- The convertToUpperCase property also affects the prefix -->\n      <!-- <property name=\"rolePrefix\" value=\"\"/> -->\n\n      <!-- Additional roles that will be added to those obtained from the attributes above -->\n      <!-- The convertToUpperCase and rolePrefix properties also affect the roles indicated here-->\n      <!-- <property name=\"additionalAuthorities\">\n        <set>\n          <value>additional_authority_1</value>\n          <value>additional_authority_2</value>\n        </set>\n      </property>\n      -->\n    </bean>\n  </constructor-arg>\n</bean>\n\n<!-- PLEASE NOTE: The ID below must be changed for each context source instance -->\n<bean id=\"contextSource2\"\n  class=\"org.springframework.security.ldap.DefaultSpringSecurityContextSource\">\n  <constructor-arg value=\"ldap://myldapserver:myport\" />\n  <property name=\"userDn\" value=\"uid=user-id,ou=GroupName,dc=my-institution,dc=country\" />\n  <property name=\"password\" value=\"mypassword\" />\n</bean>\n\n<!-- PLEASE NOTE: The ID below must be changed for each LDAP authentication provider instance -->\n<bean id=\"ldapAuthProvider2\"\n  class=\"org.springframework.security.ldap.authentication.LdapAuthenticationProvider\">\n  <constructor-arg>\n    <bean\n      class=\"org.springframework.security.ldap.authentication.BindAuthenticator\">\n      <!-- PLEASE NOTE: the ref below must match the corresponding context source ID -->\n      <constructor-arg ref=\"contextSource2\" />\n       <property name=\"userDnPatterns\">\n        <list>\n          <value>uid={0},ou=OtherGroup,dc=my-other-institution,dc=other-country</value>\n        </list>\n       </property>\n    <property name=\"userSearch\">\n      <bean name=\"filterUserSearch\" class=\"org.springframework.security.ldap.search.FilterBasedLdapUserSearch\">\n        <constructor-arg index=\"0\" value=\"ou=OtherGroup,dc=my-other-institution,dc=other-country\" />\n        <constructor-arg index=\"1\" value=\"(uid={0})\" />\n             <!-- PLEASE NOTE: the ref below must match the corresponding context source ID -->\n        <constructor-arg ref=\"contextSource2\" />\n         </bean>\n       </property>\n     </bean>\n  </constructor-arg>\n  <constructor-arg>\n    <bean class=\"org.opencastproject.kernel.userdirectory.LdapAttributeAuthoritiesPopulator\">\n      <constructor-arg>\n        <list>\n          <value>otherAttributeName1</value>\n          <value>otherAttributeName2</value>\n        </list>\n      </constructor-arg>\n   <property name=\"rolePrefix\" value=\"my_prefix_\"/>\n   <property name=\"additionalAuthorities\">\n     <set>\n       <value>default_role_1</value>\n       <value>default_role_2</value>\n     </set>\n   </property>\n    </bean>\n  </constructor-arg>\n</bean>\n\n<!-- [ ... SKIPPED LINES ... ] -->\n\n<sec:authentication-manager alias=\"authenticationManager\">\n  <sec:authentication-provider user-service-ref=\"userDetailsService\">\n    <sec:password-encoder hash=\"md5\">\n      <sec:salt-source user-property=\"username\" />\n    </sec:password-encoder>\n  </sec:authentication-provider>\n  <!-- PLEASE NOTE: In this example, the 2nd LDAP provider defined in the file has more priority that the first one -->\n  <sec:authentication-provider ref=\"ldapAuthProvider2\" />\n  <sec:authentication-provider ref=\"ldapAuthProvider\" />\n</sec:authentication-manager>  In multi-machine installations, remember to include the additional LDAP server(s) in the etc/factories/org.opencastproject.userdirectory.ldap.properties  file.",
            "title": "Adding more LDAP servers"
        },
        {
            "location": "/configuration/workflow/",
            "text": "Create a Custom Workflow\n\n\nThis document will help you get started with creating your own Opencast workflows. For a list of available workflow\noperations, see:\n\n\n\n\nList of Workflow Operation Handler\n\n\n\n\nOverview\n\n\nA Opencast workflow is an ordered list of operations. There is no limit to the number of operations or their\nrepetition in a given workflow.\n\n\nWorkflow operations can be configured using configuration elements. The use of string replacement in configuration\nvalues allows workflows to dynamically adapt to a given input or user decision.\n\n\nDocument\n\n\nOpencast workflows are defined in XML.  The structure of a Opencast workflow looks like this:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  <id></id>\n  <title></title>\n  <tags></tags>\n  <description></description>\n\n  <!-- Operations -->\n  <operations>\n    <operation></operation>\n    ...\n  </operations>\n\n</definition>\n\n\n\nCreate a Workflow\n\n\nThis sections will walk you through creating a custom workflow, which will encode ingested tracks to defined output\nformat.\n\n\nEncoding Profiles\n\n\nFirst create or select the encoding profiles you want to use. For more details on this, have a look at the \nEncoding\nProfile Configuration Guide\n. For this guide we assume that we have an encoding profile \nmov-low.http\n\nwhich creates a distribution format definition for mp4 video and a \nfeed-cover.http\n encoding profile to create\nthumbnail images for the videos.\n\n\nDescribe the Workflow\n\n\nStart by naming the workflow and giving it a meaningful description:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  <id>example</id>\n  <title>Encode Mp4, Distribute and Publish</title>\n  <tags>\n    <!-- Tell the UI where to show this workflow -->\n    <tag>upload-ng</tag>\n    <tag>schedule-ng</tag>\n    <tag>archive</tag>\n  </tags>\n  <description>\n    Encode to Mp4 and thumbnail.\n    Distribute to local repository.\n    Publish to search index.\n  </description>\n\n  <!-- Operations -->\n  <operations></operations>\n\n</definition>\n\n\n\n\n\nThe \nid\n is used in several Opencast endpoints to identify and select this workflow. Make sure that this identifier is\n  unique among all endpoints in the system.\n\n\nThe \ntags\n define where the user interfaces may use these workflows. Useful tags are:\n\n\nupload-ng\n: Usable for uploaded media (new admin ui)\n\n\nschedule-ng\n: Usable for scheduled events (new admin ui)\n\n\narchive-ng\n: Usable for archived media (new admin ui)\n\n\neditor\n: Usable from the video editor\n\n\nupload\n: Usable for uploaded media (old admin ui)\n\n\nschedule\n: Usable for scheduled events (old admin ui)\n\n\narchive\n: Usable for archived media (old admin ui)\n\n\n\n\n\n\n\n\nInspect the Media\n\n\nThe first operation will be to inspect the media for technical metadata, such as format and length:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    <operation\n      id=\"inspect\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Inspect media package\">\n    </operation>\n\n  </operations>\n\n</definition>\n\n\n\nThe \nfail-on-error\n attribute is a boolean determining whether the workflow will throw an error to the\nexception-handler-workflow or simply proceed with the remaining operations.\n\n\nEncoding\n\n\nThe next operations will encode the media to the Mp4 format:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    ...\n\n    <!-- encode: mp4 -->\n    <operation\n      id=\"compose\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode camera to mp4\">\n      <configurations>\n        <configuration key=\"source-flavor\">presenter/source</configuration>\n        <configuration key=\"target-flavor\">presenter/delivery</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">mov-low.http</configuration>\n      </configurations>\n    </operation>\n\n    <operation\n      id=\"compose\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode screen to mp4\">\n      <configurations>\n        <configuration key=\"source-flavor\">presentation/source</configuration>\n        <configuration key=\"target-flavor\">presentation/delivery</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">mov-low.http</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>\n\n\n\n\n\nThe \ntarget-tags\n attribute causes the resulting media to be tagged. For example, this could be used to define these\n  media as input for other operations, using their \nsource-tags\n attribute.\n\n\nThe \nencoding-profile\n attribute refers to an encoding profile defined in \netc/encoding\n.\n\n\n\n\nEncode to Thumbnail\n\n\nThe next operations will create thumbnails from the media:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n  ...\n  <operations>\n    ...\n    <!-- encode: images -->\n    <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode camera to thumbnail\">\n      <configurations>\n        <configuration key=\"source-flavor\">presenter/source</configuration>\n        <configuration key=\"source-tags\"></configuration>\n        <configuration key=\"target-flavor\">cover/source</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">feed-cover.http</configuration>\n        <configuration key=\"time\">1</configuration>\n      </configurations>\n    </operation>\n\n    <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode screen to thumbnail\">\n      <configurations>\n        <configuration key=\"source-flavor\">presentation/source</configuration>\n        <configuration key=\"source-tags\"></configuration>\n        <configuration key=\"target-flavor\">cover/source</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">feed-cover.http</configuration>\n        <configuration key=\"time\">1</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>\n\n\n\n\n\nThe time attribute determines the approximate frame of the source media is used. The time unit is in seconds.\n\n\n\n\nDistribute the Media\n\n\nThe next operation copies the encoded media to the Opencast distribution channel:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n  ...\n  <operations>\n\n    <!-- distribute: local -->\n    <operation\n      id=\"publish-engage\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Distribute media to the local distribution channel\">\n      <configurations>\n        <configuration key=\"download-source-tags\">publish,rss,atom</configuration>\n        <configuration key=\"streaming-source-tags\"></configuration>\n        <configuration key=\"check-availability\">true</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>\n\n\n\n\n\nThe publish-engage operation uses all media tagged as \nrss\n or \natom\n as input.\n\n\n\n\nAccept User Input\n\n\nWorkflow definitions may optionally include variables to be replaced by user input. For instance, this may be used to\nselect optional parts of a workflow. To enable user control of individual workflow instances, the workflow definition\nmust:\n\n\n\n\nuse the \n${variable}\n notation in the workflow definition\n\n\ncontain a custom configuration panel.\n\n\n\n\nHere is an example of a configurable operation:\n\n\n<operation id=\"...\" if=\"${somevar}\">\n  ...\n</operation>\n\n\n\nOnce the operation is configured to accept a variable, we need to describe how to gather the value from the\nadministrative user. The \n<configuration_panel>\n element of a workflow definitions describes this user interface\nsnippet.  A simple configuration panel could look like this:\n\n\n<configuration_panel>\n  <![CDATA[\n    <input id=\"someaction\" name=\"someaction\" type=\"checkbox\" value=\"true\" />\n    <label for=\"someaction\">Execute some operation?</label>\n  ]]>\n</configuration_panel>\n\n\n\nThe checkbox in this \n<configuration_panel>\n will now be displayed in the administrative tools, and the user's selection\nwill be used to replace the \n${review.hold}\n variable in the workflow.\n\n\nThis input can also be sent by capture agents, using the ingest endpoints. Please note that capture agents usually do\nnot load the configuration panel. Hence defaults set in the user interface will not apply to ingests. To circumvent\nthis, the \ndefaults operation\n can be used.\n\n\nTest the Workflow\n\n\nThe easiest way to test a workflow is to just put it into the workflow folder where it will be picked up by Opencast\nautomatically and will be available in Opencast a few seconds later.",
            "title": "Workflow"
        },
        {
            "location": "/configuration/workflow/#create-a-custom-workflow",
            "text": "This document will help you get started with creating your own Opencast workflows. For a list of available workflow\noperations, see:   List of Workflow Operation Handler",
            "title": "Create a Custom Workflow"
        },
        {
            "location": "/configuration/workflow/#overview",
            "text": "A Opencast workflow is an ordered list of operations. There is no limit to the number of operations or their\nrepetition in a given workflow.  Workflow operations can be configured using configuration elements. The use of string replacement in configuration\nvalues allows workflows to dynamically adapt to a given input or user decision.",
            "title": "Overview"
        },
        {
            "location": "/configuration/workflow/#document",
            "text": "Opencast workflows are defined in XML.  The structure of a Opencast workflow looks like this:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  <id></id>\n  <title></title>\n  <tags></tags>\n  <description></description>\n\n  <!-- Operations -->\n  <operations>\n    <operation></operation>\n    ...\n  </operations>\n\n</definition>",
            "title": "Document"
        },
        {
            "location": "/configuration/workflow/#create-a-workflow",
            "text": "This sections will walk you through creating a custom workflow, which will encode ingested tracks to defined output\nformat.",
            "title": "Create a Workflow"
        },
        {
            "location": "/configuration/workflow/#encoding-profiles",
            "text": "First create or select the encoding profiles you want to use. For more details on this, have a look at the  Encoding\nProfile Configuration Guide . For this guide we assume that we have an encoding profile  mov-low.http \nwhich creates a distribution format definition for mp4 video and a  feed-cover.http  encoding profile to create\nthumbnail images for the videos.",
            "title": "Encoding Profiles"
        },
        {
            "location": "/configuration/workflow/#describe-the-workflow",
            "text": "Start by naming the workflow and giving it a meaningful description:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  <id>example</id>\n  <title>Encode Mp4, Distribute and Publish</title>\n  <tags>\n    <!-- Tell the UI where to show this workflow -->\n    <tag>upload-ng</tag>\n    <tag>schedule-ng</tag>\n    <tag>archive</tag>\n  </tags>\n  <description>\n    Encode to Mp4 and thumbnail.\n    Distribute to local repository.\n    Publish to search index.\n  </description>\n\n  <!-- Operations -->\n  <operations></operations>\n\n</definition>   The  id  is used in several Opencast endpoints to identify and select this workflow. Make sure that this identifier is\n  unique among all endpoints in the system.  The  tags  define where the user interfaces may use these workflows. Useful tags are:  upload-ng : Usable for uploaded media (new admin ui)  schedule-ng : Usable for scheduled events (new admin ui)  archive-ng : Usable for archived media (new admin ui)  editor : Usable from the video editor  upload : Usable for uploaded media (old admin ui)  schedule : Usable for scheduled events (old admin ui)  archive : Usable for archived media (old admin ui)",
            "title": "Describe the Workflow"
        },
        {
            "location": "/configuration/workflow/#inspect-the-media",
            "text": "The first operation will be to inspect the media for technical metadata, such as format and length:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    <operation\n      id=\"inspect\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Inspect media package\">\n    </operation>\n\n  </operations>\n\n</definition>  The  fail-on-error  attribute is a boolean determining whether the workflow will throw an error to the\nexception-handler-workflow or simply proceed with the remaining operations.",
            "title": "Inspect the Media"
        },
        {
            "location": "/configuration/workflow/#encoding",
            "text": "The next operations will encode the media to the Mp4 format:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    ...\n\n    <!-- encode: mp4 -->\n    <operation\n      id=\"compose\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode camera to mp4\">\n      <configurations>\n        <configuration key=\"source-flavor\">presenter/source</configuration>\n        <configuration key=\"target-flavor\">presenter/delivery</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">mov-low.http</configuration>\n      </configurations>\n    </operation>\n\n    <operation\n      id=\"compose\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode screen to mp4\">\n      <configurations>\n        <configuration key=\"source-flavor\">presentation/source</configuration>\n        <configuration key=\"target-flavor\">presentation/delivery</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">mov-low.http</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>   The  target-tags  attribute causes the resulting media to be tagged. For example, this could be used to define these\n  media as input for other operations, using their  source-tags  attribute.  The  encoding-profile  attribute refers to an encoding profile defined in  etc/encoding .",
            "title": "Encoding"
        },
        {
            "location": "/configuration/workflow/#encode-to-thumbnail",
            "text": "The next operations will create thumbnails from the media:  <definition xmlns=\"http://workflow.opencastproject.org\">\n  ...\n  <operations>\n    ...\n    <!-- encode: images -->\n    <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode camera to thumbnail\">\n      <configurations>\n        <configuration key=\"source-flavor\">presenter/source</configuration>\n        <configuration key=\"source-tags\"></configuration>\n        <configuration key=\"target-flavor\">cover/source</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">feed-cover.http</configuration>\n        <configuration key=\"time\">1</configuration>\n      </configurations>\n    </operation>\n\n    <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode screen to thumbnail\">\n      <configurations>\n        <configuration key=\"source-flavor\">presentation/source</configuration>\n        <configuration key=\"source-tags\"></configuration>\n        <configuration key=\"target-flavor\">cover/source</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">feed-cover.http</configuration>\n        <configuration key=\"time\">1</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>   The time attribute determines the approximate frame of the source media is used. The time unit is in seconds.",
            "title": "Encode to Thumbnail"
        },
        {
            "location": "/configuration/workflow/#distribute-the-media",
            "text": "The next operation copies the encoded media to the Opencast distribution channel:  <definition xmlns=\"http://workflow.opencastproject.org\">\n  ...\n  <operations>\n\n    <!-- distribute: local -->\n    <operation\n      id=\"publish-engage\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Distribute media to the local distribution channel\">\n      <configurations>\n        <configuration key=\"download-source-tags\">publish,rss,atom</configuration>\n        <configuration key=\"streaming-source-tags\"></configuration>\n        <configuration key=\"check-availability\">true</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>   The publish-engage operation uses all media tagged as  rss  or  atom  as input.",
            "title": "Distribute the Media"
        },
        {
            "location": "/configuration/workflow/#accept-user-input",
            "text": "Workflow definitions may optionally include variables to be replaced by user input. For instance, this may be used to\nselect optional parts of a workflow. To enable user control of individual workflow instances, the workflow definition\nmust:   use the  ${variable}  notation in the workflow definition  contain a custom configuration panel.   Here is an example of a configurable operation:  <operation id=\"...\" if=\"${somevar}\">\n  ...\n</operation>  Once the operation is configured to accept a variable, we need to describe how to gather the value from the\nadministrative user. The  <configuration_panel>  element of a workflow definitions describes this user interface\nsnippet.  A simple configuration panel could look like this:  <configuration_panel>\n  <![CDATA[\n    <input id=\"someaction\" name=\"someaction\" type=\"checkbox\" value=\"true\" />\n    <label for=\"someaction\">Execute some operation?</label>\n  ]]>\n</configuration_panel>  The checkbox in this  <configuration_panel>  will now be displayed in the administrative tools, and the user's selection\nwill be used to replace the  ${review.hold}  variable in the workflow.  This input can also be sent by capture agents, using the ingest endpoints. Please note that capture agents usually do\nnot load the configuration panel. Hence defaults set in the user interface will not apply to ingests. To circumvent\nthis, the  defaults operation  can be used.",
            "title": "Accept User Input"
        },
        {
            "location": "/configuration/workflow/#test-the-workflow",
            "text": "The easiest way to test a workflow is to just put it into the workflow folder where it will be picked up by Opencast\nautomatically and will be available in Opencast a few seconds later.",
            "title": "Test the Workflow"
        },
        {
            "location": "/modules/",
            "text": "Module Documentation\n\n\nThis is a documentation for modules included in Opencast that do not to be configured by default, but that allow some\ntweaking. For some modules some more in depth documentation is available too.\n\n\n\n\nMedia Module\n\n\nPlayer 2.0+\n\n\nConfiguration\n\n\nURL Parameter\n\n\nOptional Plugins\n\n\nDevelopment\n\n\nArchitecture\n\n\nCore Reference\n\n\nEvents\n\n\nPersistent local storage\n\n\nCreate a new Plugin\n\n\nTesting\n\n\n\n\n\n\nSearch Index\n\n\nText Extraction\n\n\nVideoeditor\n\n\nSetup\n\n\nManual\n\n\nArchitecture\n\n\n\n\n\n\nVideo Segmentation\n\n\nYouTube Publication",
            "title": "Overview"
        },
        {
            "location": "/modules/#module-documentation",
            "text": "This is a documentation for modules included in Opencast that do not to be configured by default, but that allow some\ntweaking. For some modules some more in depth documentation is available too.   Media Module  Player 2.0+  Configuration  URL Parameter  Optional Plugins  Development  Architecture  Core Reference  Events  Persistent local storage  Create a new Plugin  Testing    Search Index  Text Extraction  Videoeditor  Setup  Manual  Architecture    Video Segmentation  YouTube Publication",
            "title": "Module Documentation"
        },
        {
            "location": "/modules/mediamodule.configuration/",
            "text": "Media Module Configuration\n\n\nThe Media Module is the default overview of the distributed media files.\n\n\nThe configurations for the Media Module are done for each tenant. So the configuration keys are located in\n\n<opencast_home>/etc/org.opencastproject.organization-mh_default_org.cfg\n:\n\n\n\n\nprop.logo_mediamodule\n\n\nThis logo file will be displayed in the upper left of the Media Module page\n\n\nDefault: an Opencast logo\n\n\n\n\n\n\nprop.player\n\n\nThe player that should be use to play the videos.\n\n\nDefault: Opencast 2.0 (Theodul) player",
            "title": "Media Module"
        },
        {
            "location": "/modules/mediamodule.configuration/#media-module-configuration",
            "text": "The Media Module is the default overview of the distributed media files.  The configurations for the Media Module are done for each tenant. So the configuration keys are located in <opencast_home>/etc/org.opencastproject.organization-mh_default_org.cfg :   prop.logo_mediamodule  This logo file will be displayed in the upper left of the Media Module page  Default: an Opencast logo    prop.player  The player that should be use to play the videos.  Default: Opencast 2.0 (Theodul) player",
            "title": "Media Module Configuration"
        },
        {
            "location": "/modules/player.architecture/",
            "text": "Architecture\n\n\nOverview\n\n\nThe architecture of the theodul player has a plugin based structure based around a core. The core and the plugins have\nbeen realized as OSGi modules. Each plugin can be separately build.\n\n\nThe following figure shows the OSGi architecture of the player.\n\n\n\n\nAll Theodul OSGi modules are stored under:\n\n\nmodules/matterhorn-engage-theodul-*\n#Core module\nmodules/matterhorn-engage-theodul-api/\nmodules/matterhorn-engage-theodul-core/\n#A plugin module\nmodules/matterhorn-engage-theodul-plugin-*\nmodules/matterhorn-engage-theodul-plugin-tab-description/\n\n\n\nPlugin Manager\n\n\nThe main workflow is implemented by the core, which recognizes new plugins, collects information about the plugin type\nand resources, runs the JavaScript logic and inserts the first compiled templates into the HTML DOM.\n\n\nThe Plugin Manager Endpoint recognizes the OSGi modules. Each plugin has some information about its name and its\nresources. The Plugin Manager collects these information and publishes them via a REST endpoint. The following URL links\nto an example REST endpoint:\n\n\nhttp://localhost:8080/engage/theodul/manager/list.json\n\n\n\nThe documentation and test forms of the endpoint can be found on the Opencast start page. The following data in JSON\nshows an example list of plugins, which are used by the player and provided by the Plugin Manager Endpoint.\n\n\n{\n  \"pluginlist\":{\n    \"plugins\":[\n    {\n      \"name\":\"EngagePluginTabSlidetext\",\n      \"id\":\"6\",\n      \"description\":\"Simple implementation of a tab with the text of the slides\",\n      \"static-path\":\"6\\/static\"\n    },\n    {\n      \"name\":\"EngagePluginControlsMockup\",\n      \"id\":\"5\",\n      \"description\":\"Simple implementation of a control bar\",\n      \"static-path\":\"5\\/static\"\n    }]\n  }\n}\n\n\n\nNext to the Plugin Manager there is the Theodul Core module, which publishes the main HTML page, core.html.\n\n\nUI Core\n\n\nThe \ncore.html\n is the main entry point and starts the Javascript core logic. Following listing shows the directory\nstructure of core in the \nmatterhorn-engage-theodul-core OSGi\n module.\n\n\n|-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------spec\n\n\n\nAll Theodul JavaScript components are defined as a RequireJS module. The file \nengage_init.js\n is loaded firstly and\ncontains the configuration of RequireJS. This init script additionally loads the core module, which is defined in the\n\nengage_core.js\n.\n\n\nThe core module initializes the main HTML view. This view is realized as a BackboneJS view and is linked to a global\nBackbone model, which is stored in the model module in \nengage_model.js\n. The view is returned by the core module, so\nevery other module, which has a dependency to the core module, has a reference to the view (simply called \nEngage\n in\nthe plugins) and its functions. See the Core Reference for more information about the functions of the core view.\n\n\nPlugins\n\n\nPlugins in the Theodul player are developed and distributed in own OSGi modules. Every plugin has a special UI type. In\ndependency of this type the core injects the plugin to the right position of the player. The following plugin types are\npossible:\n\n\n\n\n\n\n\n\nPlugin Type\n\n\nDescription\n\n\nCharacteristics\n\n\nModule Name\n\n\nJS Plugin Type Name\n\n\nMaven Plugin Type Name\n\n\n\n\n\n\n\n\n\n\nControls\n\n\nImplements the main controls of the top of the player\n\n\nOnly one plugin per player possible.\n\n\nmatterhorn-engage-theodul-plugin-controls\n\n\nengage_controls\n\n\ncontrols\n\n\n\n\n\n\nTimeline\n\n\nTimeline information below the main controls.\n\n\nGood for processing time-based data like user tracking, slide previews or annotations.\n\n\nOptional plugin, more than one possible.  matterhorn-engage-theodul-plugin-timeline-\n\n\nengage_timeline\n\n\ntimeline\n\n\n\n\n\n\nVideodisplay\n\n\nImplementation of the video display.\n\n\nCurrently only one plugin per player possible, but in the future more video displays should be possible.\n\n\nmatterhorn-engage-theodul-plugin-video-\n\n\nengage_video\n\n\nvideo\n\n\n\n\n\n\nDescription/Label\n\n\nA plugin below the video display, good to show simple information about the video, like a title and the creator.\n\n\nOnly one plugin per player possible.\n\n\nmatterhorn-engage-theodul-plugin-description\n\n\nengage_description\n\n\ndescription\n\n\n\n\n\n\nTab\n\n\nShows a tab in the tab view at the bottom of the player.\n\n\nOptional plugin, more than one possible.\n\n\nmatterhorn-engage-theodul-plugin-tab-\n\n\nengage_tab\n\n\ntab\n\n\n\n\n\n\nCustom\n\n\nA custom plugin without a relationship to an UI element.\n\n\nGood for a custom REST endpoint, global data representation or to load custom JS code or libraries.\n\n\nOptional plugin, more than one possible.\n\n\nNo connection to a preserved UI element.\n\n\nmatterhorn-engage-theodul-plugin-custom-\n\n\n\n\n\n\n\n\nThe following listing shows the directory structure of a plugin module:\n\n\n|-src\n|---main\n|-----java\n|-------org\n|---------opencastproject\n|-----------engage\n|-------------theodul\n|---------------plugin\n|-----------------controls  #Simple Java class, and optional REST endpoint\n|-----resources\n|-------OSGI-INF            #OSGi information about the plugin\n|-------static              #web ressources, contains the main.js entry point of the plugin\n|---------images            #plugin ressources\n|---------js                #plugin js libs\n|-----------bootstrap\n|-----------jqueryui\n|---test                    #Jasmine test ressources\n|-----resources\n|-------js\n|---------engage            #Test Wrapper of the core\n|---------lib               #Required test libs\n|---------spec              #Jasmine test specs\n\n\n\nThe main JavaScript entry point of the plugin is main.js in the static folder. This contains the RequireJS module\ndefinition of the plugin and the main logic. All other plugin logic can be implemented as a RequireJS module and loaded\nin the main module. The main module should have a dependency to the core, the Engage object. With this object you have\naccess to main features of the core. See the Core Reference for more information about that.\n\n\nAfter the initialization process of the plugin, the plugin returns a plugin object with information about the plugin,\nlike the type, the name, the ui template etc. This object is used by the core to decide about the UI type/location of\nplugin. The Core Reference describes the plugin object, before and after it is being processed by the core.\n\n\nHave a look to the code of a plugin to get an impression about the plugin implementation.\n\n\nModel View Controller Support\n\n\nThe Theodul player supports MVC design patterns for each plugin based on methods and objects of the BackboneJS library.\nIt is not necessary to design a plugin in MVC style but it is highly recommended. An overview of the methods and objects\nof the BackboneJS library is listed on the official website of BackboneJS.\n\n\nEach plugin with a visual component has a reference to its view container and its template to fill the view container.\nHave a look at the Core Reference how to access the container and the template data. With this information the plugin\ncan create a Backbone view with a reference to the to div container and a render function to compile the template.\n\n\nThe next step is the creation of a model, which is being bound to the view. An usual way is to create a Backbone model,\nwhich is being passed by the view. In the initialization function of the view, the view binds the model change event to\nhis render function:\n\n\nBind the \"change\" event always to the render function of a view\n\n\n// bind the render function always to the view\n_.bindAll(this, \"render\");\n// listen for changes of the model and bind the render function to this\nthis.model.bind(\"change\", this.render);\n\n\n\nThe model can only be visible by the plugin itself or it can be added to the global Engage model of the core. Adding the\nmodel to the Engage model has the advantage, that on the one hand data can be used by other plugins and on the other\nhand it is able to listen to change- or add-events. So other plugins are able to listen to a change of data in another\nmodel and can react to it by e.g. re-render its view. This feature is e.g. used by the \"mhConnection\" custom plugin. The\nplugin receives data of Opencast endpoints and saves them to a model, which is being added to the Engage Model. Each\ntime the plugin gets newer endpoint data and updates its model's data, each plugin gets a notification and can re-render\nits view.\n\n\nA typical way to add a model to the Engage model is to add the model in the initialization function of the plugin after\nall other initializations. Here is an example of the video plugin:\n\n\nAdd a custom model to the Engage Model\n\n\nEngage.model.set(\"videoDataModel\", new VideoDataModel(videoDisplays, videoSources, duration));\n\n\n\nIn the same initialization function an event handler should be added to notice the addition of the model. Has the model\nsuccessfully been added, a view with this model and other data can be created:\n\n\nModel Event Handler\n\n\nEngage.model.on(\"change:videoDataModel\", function() {\n   new VideoDataView(this.get(\"videoDataModel\"), plugin.template, videojs_swf);\n});\n\n\n\nIf another plugin wants to use the defined \"videoDataModel\" model, it has to list it in its own initialization process:\n\n\nEngage.model.on(\"change:videoDataModel\", function() {\n   initCount -= 1;\n   if (initCount === 0) {\n      initPlugin();\n   }\n});\n\n\n\nHave a look at the full implementation of the VideoJS Plugin and the Controls Plugin to get an idea how the Backbone MVC\ndesign works. For completeness' sake, the \"Controller\" does not have an extra Object in the Backbone MVC design. The\n\"Controller\" is usually used as the render function in the view. This function can be very complex and should link to\nother functions, which are short and easy to be tested by the Jasmine Test Framework.",
            "title": "Architecture"
        },
        {
            "location": "/modules/player.architecture/#architecture",
            "text": "",
            "title": "Architecture"
        },
        {
            "location": "/modules/player.architecture/#overview",
            "text": "The architecture of the theodul player has a plugin based structure based around a core. The core and the plugins have\nbeen realized as OSGi modules. Each plugin can be separately build.  The following figure shows the OSGi architecture of the player.   All Theodul OSGi modules are stored under:  modules/matterhorn-engage-theodul-*\n#Core module\nmodules/matterhorn-engage-theodul-api/\nmodules/matterhorn-engage-theodul-core/\n#A plugin module\nmodules/matterhorn-engage-theodul-plugin-*\nmodules/matterhorn-engage-theodul-plugin-tab-description/",
            "title": "Overview"
        },
        {
            "location": "/modules/player.architecture/#plugin-manager",
            "text": "The main workflow is implemented by the core, which recognizes new plugins, collects information about the plugin type\nand resources, runs the JavaScript logic and inserts the first compiled templates into the HTML DOM.  The Plugin Manager Endpoint recognizes the OSGi modules. Each plugin has some information about its name and its\nresources. The Plugin Manager collects these information and publishes them via a REST endpoint. The following URL links\nto an example REST endpoint:  http://localhost:8080/engage/theodul/manager/list.json  The documentation and test forms of the endpoint can be found on the Opencast start page. The following data in JSON\nshows an example list of plugins, which are used by the player and provided by the Plugin Manager Endpoint.  {\n  \"pluginlist\":{\n    \"plugins\":[\n    {\n      \"name\":\"EngagePluginTabSlidetext\",\n      \"id\":\"6\",\n      \"description\":\"Simple implementation of a tab with the text of the slides\",\n      \"static-path\":\"6\\/static\"\n    },\n    {\n      \"name\":\"EngagePluginControlsMockup\",\n      \"id\":\"5\",\n      \"description\":\"Simple implementation of a control bar\",\n      \"static-path\":\"5\\/static\"\n    }]\n  }\n}  Next to the Plugin Manager there is the Theodul Core module, which publishes the main HTML page, core.html.",
            "title": "Plugin Manager"
        },
        {
            "location": "/modules/player.architecture/#ui-core",
            "text": "The  core.html  is the main entry point and starts the Javascript core logic. Following listing shows the directory\nstructure of core in the  matterhorn-engage-theodul-core OSGi  module.  |-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------spec  All Theodul JavaScript components are defined as a RequireJS module. The file  engage_init.js  is loaded firstly and\ncontains the configuration of RequireJS. This init script additionally loads the core module, which is defined in the engage_core.js .  The core module initializes the main HTML view. This view is realized as a BackboneJS view and is linked to a global\nBackbone model, which is stored in the model module in  engage_model.js . The view is returned by the core module, so\nevery other module, which has a dependency to the core module, has a reference to the view (simply called  Engage  in\nthe plugins) and its functions. See the Core Reference for more information about the functions of the core view.",
            "title": "UI Core"
        },
        {
            "location": "/modules/player.architecture/#plugins",
            "text": "Plugins in the Theodul player are developed and distributed in own OSGi modules. Every plugin has a special UI type. In\ndependency of this type the core injects the plugin to the right position of the player. The following plugin types are\npossible:     Plugin Type  Description  Characteristics  Module Name  JS Plugin Type Name  Maven Plugin Type Name      Controls  Implements the main controls of the top of the player  Only one plugin per player possible.  matterhorn-engage-theodul-plugin-controls  engage_controls  controls    Timeline  Timeline information below the main controls.  Good for processing time-based data like user tracking, slide previews or annotations.  Optional plugin, more than one possible.  matterhorn-engage-theodul-plugin-timeline-  engage_timeline  timeline    Videodisplay  Implementation of the video display.  Currently only one plugin per player possible, but in the future more video displays should be possible.  matterhorn-engage-theodul-plugin-video-  engage_video  video    Description/Label  A plugin below the video display, good to show simple information about the video, like a title and the creator.  Only one plugin per player possible.  matterhorn-engage-theodul-plugin-description  engage_description  description    Tab  Shows a tab in the tab view at the bottom of the player.  Optional plugin, more than one possible.  matterhorn-engage-theodul-plugin-tab-  engage_tab  tab    Custom  A custom plugin without a relationship to an UI element.  Good for a custom REST endpoint, global data representation or to load custom JS code or libraries.  Optional plugin, more than one possible.  No connection to a preserved UI element.  matterhorn-engage-theodul-plugin-custom-     The following listing shows the directory structure of a plugin module:  |-src\n|---main\n|-----java\n|-------org\n|---------opencastproject\n|-----------engage\n|-------------theodul\n|---------------plugin\n|-----------------controls  #Simple Java class, and optional REST endpoint\n|-----resources\n|-------OSGI-INF            #OSGi information about the plugin\n|-------static              #web ressources, contains the main.js entry point of the plugin\n|---------images            #plugin ressources\n|---------js                #plugin js libs\n|-----------bootstrap\n|-----------jqueryui\n|---test                    #Jasmine test ressources\n|-----resources\n|-------js\n|---------engage            #Test Wrapper of the core\n|---------lib               #Required test libs\n|---------spec              #Jasmine test specs  The main JavaScript entry point of the plugin is main.js in the static folder. This contains the RequireJS module\ndefinition of the plugin and the main logic. All other plugin logic can be implemented as a RequireJS module and loaded\nin the main module. The main module should have a dependency to the core, the Engage object. With this object you have\naccess to main features of the core. See the Core Reference for more information about that.  After the initialization process of the plugin, the plugin returns a plugin object with information about the plugin,\nlike the type, the name, the ui template etc. This object is used by the core to decide about the UI type/location of\nplugin. The Core Reference describes the plugin object, before and after it is being processed by the core.  Have a look to the code of a plugin to get an impression about the plugin implementation.",
            "title": "Plugins"
        },
        {
            "location": "/modules/player.architecture/#model-view-controller-support",
            "text": "The Theodul player supports MVC design patterns for each plugin based on methods and objects of the BackboneJS library.\nIt is not necessary to design a plugin in MVC style but it is highly recommended. An overview of the methods and objects\nof the BackboneJS library is listed on the official website of BackboneJS.  Each plugin with a visual component has a reference to its view container and its template to fill the view container.\nHave a look at the Core Reference how to access the container and the template data. With this information the plugin\ncan create a Backbone view with a reference to the to div container and a render function to compile the template.  The next step is the creation of a model, which is being bound to the view. An usual way is to create a Backbone model,\nwhich is being passed by the view. In the initialization function of the view, the view binds the model change event to\nhis render function:  Bind the \"change\" event always to the render function of a view  // bind the render function always to the view\n_.bindAll(this, \"render\");\n// listen for changes of the model and bind the render function to this\nthis.model.bind(\"change\", this.render);  The model can only be visible by the plugin itself or it can be added to the global Engage model of the core. Adding the\nmodel to the Engage model has the advantage, that on the one hand data can be used by other plugins and on the other\nhand it is able to listen to change- or add-events. So other plugins are able to listen to a change of data in another\nmodel and can react to it by e.g. re-render its view. This feature is e.g. used by the \"mhConnection\" custom plugin. The\nplugin receives data of Opencast endpoints and saves them to a model, which is being added to the Engage Model. Each\ntime the plugin gets newer endpoint data and updates its model's data, each plugin gets a notification and can re-render\nits view.  A typical way to add a model to the Engage model is to add the model in the initialization function of the plugin after\nall other initializations. Here is an example of the video plugin:",
            "title": "Model View Controller Support"
        },
        {
            "location": "/modules/player.architecture/#add-a-custom-model-to-the-engage-model",
            "text": "Engage.model.set(\"videoDataModel\", new VideoDataModel(videoDisplays, videoSources, duration));  In the same initialization function an event handler should be added to notice the addition of the model. Has the model\nsuccessfully been added, a view with this model and other data can be created:  Model Event Handler  Engage.model.on(\"change:videoDataModel\", function() {\n   new VideoDataView(this.get(\"videoDataModel\"), plugin.template, videojs_swf);\n});  If another plugin wants to use the defined \"videoDataModel\" model, it has to list it in its own initialization process:  Engage.model.on(\"change:videoDataModel\", function() {\n   initCount -= 1;\n   if (initCount === 0) {\n      initPlugin();\n   }\n});  Have a look at the full implementation of the VideoJS Plugin and the Controls Plugin to get an idea how the Backbone MVC\ndesign works. For completeness' sake, the \"Controller\" does not have an extra Object in the Backbone MVC design. The\n\"Controller\" is usually used as the render function in the view. This function can be very complex and should link to\nother functions, which are short and easy to be tested by the Jasmine Test Framework.",
            "title": "Add a custom model to the Engage Model"
        },
        {
            "location": "/modules/player.configuration/",
            "text": "Theodul Pass Player - Configuration\n\n\nThe Theodul Pass Player is the new default player from Opencast 2.0 onwards.  The old engage player from 1.x is still\navailable.\n\n\nThe configurations for the player are done for each tenant. So the configuration keys are located in\n\n.../etc/org.opencastproject.organization-mh_default_org.cfg\n.\n\n\nSelect the Opencast 2.0 Player\n\n\nTo activate the player set:\n\n\nprop.player=/engage/theodul/ui/core.html\n\n\n\nConfiguration\n\n\nLogo\n\n\nThe logo in the top right can easily be replaced by changing the path or URL for logo small.\n\n\nprop.logo_player=/engage/ui/img/mh_logos/OpencastLogo.png\n\n\n\nOptions:\n\n\n\n\nAny URL or local path to a PNG, GIF, JPG image. Default displayed hight in the browser 36px.\n\n\n\n\nPosition of the controls\n\n\nThe basic controls for the player can be placed over or under the video display.\n\n\nprop.player.positioncontrols=bottom\n\n\n\nOptions:\n\n\n\n\ntop\n\n\nbottom\n\n\n\n\nMain video flavor\n\n\nThe default flavor of the master video (the video on the \"left side\" in the video display). This source also provides\nthe audio. You can change this to every falvor that your installation might provide. If no mastervideotype was selected,\nor the mastervideotype is not available the videos are taken in their sequence within the mediapackage.\n\n\nprop.player.mastervideotype=presenter/delivery\n\n\n\nOptions (default flavors):\n\n\n\n\npresenter/delivery\n\n\npresentation/delivery\n\n\n\n\nShow Embed links\n\n\nThe player can show a dialog with links to the current video that can be embeded into other websites. This function can\nbe disabled\n\n\nprop.show_embed_links=true\n\n\n\nOptions:\n\n\n\n\ntrue\n\n\nfalse\n\n\n\n\nLink to Media Module\n\n\nIf you don't want to use the Opencast Media Module the link within the player back to the overview of the recordings can\nbe disabled:\n\n\nprop.link_mediamodule=true\n\n\n\nOptions:\n\n\n\n\ntrue\n\n\nfalse\n\n\n\n\nKeyboard Shortcuts\n\n\nThe keyboard shortcuts in the player can be customized:\n\n\nprop.player.shortcut.playPause=space\nprop.player.shortcut.seekRight=right\nprop.player.shortcut.seekLeft=left\nprop.player.shortcut.playbackrateIncrease=mod+9\nprop.player.shortcut.playbackrateDecrease=mod+8\nprop.player.shortcut.muteToggle=m\nprop.player.shortcut.volUp=9\nprop.player.shortcut.volDown=8\nprop.player.shortcut.fullscreenEnable=mod+enter\nprop.player.shortcut.fullscreenCancel=escape\nprop.player.shortcut.jumpToBegin=backspace\nprop.player.shortcut.prevChapter=pagedown\nprop.player.shortcut.nextChapter=pageup",
            "title": "Configuration"
        },
        {
            "location": "/modules/player.configuration/#theodul-pass-player-configuration",
            "text": "The Theodul Pass Player is the new default player from Opencast 2.0 onwards.  The old engage player from 1.x is still\navailable.  The configurations for the player are done for each tenant. So the configuration keys are located in .../etc/org.opencastproject.organization-mh_default_org.cfg .",
            "title": "Theodul Pass Player - Configuration"
        },
        {
            "location": "/modules/player.configuration/#select-the-opencast-20-player",
            "text": "To activate the player set:  prop.player=/engage/theodul/ui/core.html",
            "title": "Select the Opencast 2.0 Player"
        },
        {
            "location": "/modules/player.configuration/#configuration",
            "text": "",
            "title": "Configuration"
        },
        {
            "location": "/modules/player.configuration/#logo",
            "text": "The logo in the top right can easily be replaced by changing the path or URL for logo small.  prop.logo_player=/engage/ui/img/mh_logos/OpencastLogo.png  Options:   Any URL or local path to a PNG, GIF, JPG image. Default displayed hight in the browser 36px.",
            "title": "Logo"
        },
        {
            "location": "/modules/player.configuration/#position-of-the-controls",
            "text": "The basic controls for the player can be placed over or under the video display.  prop.player.positioncontrols=bottom  Options:   top  bottom",
            "title": "Position of the controls"
        },
        {
            "location": "/modules/player.configuration/#main-video-flavor",
            "text": "The default flavor of the master video (the video on the \"left side\" in the video display). This source also provides\nthe audio. You can change this to every falvor that your installation might provide. If no mastervideotype was selected,\nor the mastervideotype is not available the videos are taken in their sequence within the mediapackage.  prop.player.mastervideotype=presenter/delivery  Options (default flavors):   presenter/delivery  presentation/delivery",
            "title": "Main video flavor"
        },
        {
            "location": "/modules/player.configuration/#show-embed-links",
            "text": "The player can show a dialog with links to the current video that can be embeded into other websites. This function can\nbe disabled  prop.show_embed_links=true  Options:   true  false",
            "title": "Show Embed links"
        },
        {
            "location": "/modules/player.configuration/#link-to-media-module",
            "text": "If you don't want to use the Opencast Media Module the link within the player back to the overview of the recordings can\nbe disabled:  prop.link_mediamodule=true  Options:   true  false",
            "title": "Link to Media Module"
        },
        {
            "location": "/modules/player.configuration/#keyboard-shortcuts",
            "text": "The keyboard shortcuts in the player can be customized:  prop.player.shortcut.playPause=space\nprop.player.shortcut.seekRight=right\nprop.player.shortcut.seekLeft=left\nprop.player.shortcut.playbackrateIncrease=mod+9\nprop.player.shortcut.playbackrateDecrease=mod+8\nprop.player.shortcut.muteToggle=m\nprop.player.shortcut.volUp=9\nprop.player.shortcut.volDown=8\nprop.player.shortcut.fullscreenEnable=mod+enter\nprop.player.shortcut.fullscreenCancel=escape\nprop.player.shortcut.jumpToBegin=backspace\nprop.player.shortcut.prevChapter=pagedown\nprop.player.shortcut.nextChapter=pageup",
            "title": "Keyboard Shortcuts"
        },
        {
            "location": "/modules/player.core.reference/",
            "text": "Core Reference\n\n\nEngage Core\n\n\nRequireJS Path\n\n\n'engage/engage_core'\n\n\n\nInherited object functions of the BackboneJS view, see http://backbonejs.org/#View\n\n\nAdded object functions and properties:\n\n\n\n\n\n\n\n\nName\n\n\nParameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nlog(value):void\n\n\nvalue:String\n\n\nfunction\n\n\nfunction to log via the core cross browser\n\n\n\n\n\n\nEvent:EngageEvent\n\n\nnone\n\n\nproperty\n\n\nReturns the EngageEvent object prototype, the see EngageEvent Object for more information\n\n\n\n\n\n\ntrigger(event):void\n\n\nevent:EngageEvent\n\n\nfunction\n\n\ntriggers an EngageEvent\n\n\n\n\n\n\non(event, handler, context):void\n\n\nevent:EngageEvent, handler:function, context:object\n\n\nfunction\n\n\ninstall an event handler on a EngageEvent\n\n\n\n\n\n\nmodel:EngageModel\n\n\nnone\n\n\nproperty\n\n\nReturns the singleton engage model for this session, see EngageModel for more information's\n\n\n\n\n\n\ngetPluginPath(pluginName):String\n\n\npluginName:String\n\n\nfunction\n\n\nReturns the absolute path of a plugin by name.\n\n\n\n\n\n\n\n\nEngageEvent Object\n\n\n\n\n\n\n\n\nName\n\n\nParamters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nEngageEvent(name, description, type)\n\n\nname:String, description:String, type:String\n\n\nconstructor\n\n\nCreate a new unbound EngageEvent, with a name, description and a type. For Example: var myEvent = new EngageEvent('play', 'plays the video', 'trigger')\n\n\n\n\n\n\ngetName:String\n\n\nnone\n\n\nfunction\n\n\nGets the name\n\n\n\n\n\n\ngetDescription:String\n\n\nnone\n\n\nfunction\n\n\nGets the description\n\n\n\n\n\n\ngetType:String\n\n\nnone\n\n\nfunction\n\n\nGets the Type, can be a \"handler\", \"trigger\" or \"both\"\n\n\n\n\n\n\ntoString:String\n\n\nnone\n\n\nfunction\n\n\nBuild a string that describes the event\n\n\n\n\n\n\n\n\nEngage Model\n\n\nInherited object functions of the BackboneJS model, see http://backbonejs.org/#Model, how to use BackboneJS models. This model is a global singleton object and can be used by each plugin to add new models which can be used by another plugin again.\n\n\nNo special functions are added, but the model is filled with some default data. This default data can be used by each plugin, which has a reference to the EngageModel.\n\n\n\n\n\n\n\n\nProperty Name\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\npluginsInfo\n\n\nBackbone Model\n\n\nContains Information's of each plugin\n\n\n\n\n\n\npluginModels\n\n\nBackbone Collection\n\n\nContains the plugin models\n\n\n\n\n\n\nurlParameters\n\n\nObject\n\n\nContains the data of the URL parameters.\n\n\n\n\n\n\n\n\nPlugin Object\n\n\nEach plugin \nmust\n create and return a object with some properties which are set by the plugin itself. It is recommend to keep a reference to the object because some properties are set by the core after the plugin is processed.\n\n\n\n\n\n\n\n\nProperty Name\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nname\n\n\nString\n\n\nName of the plugin, e.g. \"Engage Controls\". \nThis property is set by the plugin.\n\n\n\n\n\n\ntype\n\n\nString\n\n\nType of the plugin, e.g. \"engage_controls\", see the plugin table in Architecture for the other plugin types. \nThis property is set by the plugin.\n\n\n\n\n\n\nversion\n\n\nString\n\n\nVersion of plugin. \nThis property is set by the plugin.\n\n\n\n\n\n\nstyles\n\n\nArray of Strings\n\n\nArray of the paths of css files relative to the static folder of each plugin . \nThis property is set by the plugin.\n\n\n\n\n\n\ntemplate\n\n\nString\n\n\nBefore the plugin object is returned by the plugin logic, the template property contains the path to the template relative to the static folder. \nThe path property is set first by the plugin\n. After the plugin object is returned and the Theodul core processed the plugin, the template property is filled with the real template data and can be used to re-render the view.\n\n\n\n\n\n\ncontainer\n\n\nString\n\n\nContains the ID of the HTML div container, which contains the rendered template. This can be used to re-render the view. \nThis property is set by the core.\n\n\n\n\n\n\npluginPath\n\n\nString\n\n\nContains the absolute path of the plugin.  \nThis property is set by the core.\n\n\n\n\n\n\nevents\n\n\nObject\n\n\nContains all events which are used of this plugin. Each handled and each triggered event.",
            "title": "Core Reference"
        },
        {
            "location": "/modules/player.core.reference/#core-reference",
            "text": "",
            "title": "Core Reference"
        },
        {
            "location": "/modules/player.core.reference/#engage-core",
            "text": "RequireJS Path  'engage/engage_core'  Inherited object functions of the BackboneJS view, see http://backbonejs.org/#View  Added object functions and properties:     Name  Parameters  Type  Description      log(value):void  value:String  function  function to log via the core cross browser    Event:EngageEvent  none  property  Returns the EngageEvent object prototype, the see EngageEvent Object for more information    trigger(event):void  event:EngageEvent  function  triggers an EngageEvent    on(event, handler, context):void  event:EngageEvent, handler:function, context:object  function  install an event handler on a EngageEvent    model:EngageModel  none  property  Returns the singleton engage model for this session, see EngageModel for more information's    getPluginPath(pluginName):String  pluginName:String  function  Returns the absolute path of a plugin by name.",
            "title": "Engage Core"
        },
        {
            "location": "/modules/player.core.reference/#engageevent-object",
            "text": "Name  Paramters  Type  Description      EngageEvent(name, description, type)  name:String, description:String, type:String  constructor  Create a new unbound EngageEvent, with a name, description and a type. For Example: var myEvent = new EngageEvent('play', 'plays the video', 'trigger')    getName:String  none  function  Gets the name    getDescription:String  none  function  Gets the description    getType:String  none  function  Gets the Type, can be a \"handler\", \"trigger\" or \"both\"    toString:String  none  function  Build a string that describes the event",
            "title": "EngageEvent Object"
        },
        {
            "location": "/modules/player.core.reference/#engage-model",
            "text": "Inherited object functions of the BackboneJS model, see http://backbonejs.org/#Model, how to use BackboneJS models. This model is a global singleton object and can be used by each plugin to add new models which can be used by another plugin again.  No special functions are added, but the model is filled with some default data. This default data can be used by each plugin, which has a reference to the EngageModel.     Property Name  Type  Description      pluginsInfo  Backbone Model  Contains Information's of each plugin    pluginModels  Backbone Collection  Contains the plugin models    urlParameters  Object  Contains the data of the URL parameters.",
            "title": "Engage Model"
        },
        {
            "location": "/modules/player.core.reference/#plugin-object",
            "text": "Each plugin  must  create and return a object with some properties which are set by the plugin itself. It is recommend to keep a reference to the object because some properties are set by the core after the plugin is processed.     Property Name  Type  Description      name  String  Name of the plugin, e.g. \"Engage Controls\".  This property is set by the plugin.    type  String  Type of the plugin, e.g. \"engage_controls\", see the plugin table in Architecture for the other plugin types.  This property is set by the plugin.    version  String  Version of plugin.  This property is set by the plugin.    styles  Array of Strings  Array of the paths of css files relative to the static folder of each plugin .  This property is set by the plugin.    template  String  Before the plugin object is returned by the plugin logic, the template property contains the path to the template relative to the static folder.  The path property is set first by the plugin . After the plugin object is returned and the Theodul core processed the plugin, the template property is filled with the real template data and can be used to re-render the view.    container  String  Contains the ID of the HTML div container, which contains the rendered template. This can be used to re-render the view.  This property is set by the core.    pluginPath  String  Contains the absolute path of the plugin.   This property is set by the core.    events  Object  Contains all events which are used of this plugin. Each handled and each triggered event.",
            "title": "Plugin Object"
        },
        {
            "location": "/modules/player.events/",
            "text": "Theodul Pass Player - Events\n\n\nA Theodul Pass Player plugin can trigger and/or subscribe to events.\n\n\nAn event is defined in the events section of the plugin and looks like this:\n\n\nNAME: new Engage.Event(\"MODULE:NAME\", \"DESCRIPTION\", \"OPTION\")\n\n\n\nThe event has the event name \"MODULE:NAME\", the description DESCRIPTION and one of the options \"trigger\", \"handler\" or \"both\" as OPTION. When the plugin just triggers the event, the option is \"trigger\", when it just handles the events the option is \"handler\" and when it does both - trigger and handle it - the option is \"both\".\n\n\nAn event can be triggered via\n\n\nEngage.trigger(plugin.events.NAME.getName(), [parameter(s)]);\n\n\n\nand can be subscribed to via\n\n\nEngage.on(plugin.events.NAME.getName(), function () {});\n\n\n\nThe following list contains all events of the Core + of all official plugins, sorted alphabetically after \"Event name\" for version 1.0 of Feb 12, 2015.\n\n\nCurrently official plugins are\n\n\n\n\nControls\n\n\nMHConnection\n\n\nNotifications\n\n\nUsertracking\n\n\nDescription\n\n\nDescription (Tab)\n\n\nSlide text (Tab)\n\n\nShortcuts (Tab)\n\n\nTimeline statistics\n\n\nVideodisplay\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEvent name\n\n\nAdditional parameters\n\n\nDescription\n\n\nTriggered in\n\n\nHandled in\n\n\n\n\n\n\n\n\n\n\ncoreInit\n\n\nCore:init\n\n\n\n\n\n\nCore\n\n\n\n\n\n\n\n\nplugin_load_done\n\n\nCore:plugin_load_done\n\n\n\n\n\n\nCore\n\n\nCore, Controls, MHConnection, Notifications, Usertracking, Description, Description (Tab), Slide text (Tab), Shortcuts (Tab), Timeline statistics, Videodisplay\n\n\n\n\n\n\ntimelineplugin_closed\n\n\nEngage:timelineplugin_closed\n\n\nNote: No \"Engage Event\", just use as string, example: Engage.on(\"Engage:timelineplugin_closed\", function() {});\n\n\nwhen the timeline plugin container closed\n\n\nCore\n\n\n\n\n\n\n\n\ntimelineplugin_opened\n\n\nEngage:timelineplugin_opened\n\n\nNote: No \"Engage Event\", just use as string, example: Engage.on(\"Engage:timelineplugin_opened\", function() {});\n\n\nwhen the timeline plugin container opened\n\n\nCore\n\n\nTimeline statistics\n\n\n\n\n\n\ngetMediaInfo\n\n\nMhConnection:getMediaInfo\n\n\n\n\n\n\n\n\nMHConnection\n\n\n\n\n\n\ngetMediaPackage\n\n\nMhConnection:getMediaPackage\n\n\n\n\n\n\n\n\nMHConnection\n\n\n\n\n\n\nmediaPackageModelError\n\n\nMhConnection:mediaPackageModelError\n\n\n\n\n\n\nMHConnection\n\n\nCore, Controls, Notifications, Usertracking, Description, Description (Tab), Slide text (Tab), Shortcuts (Tab), Timeline statistics, Videodisplay\n\n\n\n\n\n\ncustomError\n\n\nNotification:customError\n\n\nmsg: The message to display\n\n\nan error occurred\n\n\nCore, Controls, Videodisplay\n\n\nNotifications\n\n\n\n\n\n\ncustomNotification\n\n\nNotification:customNotification\n\n\nmsg: The message to display\n\n\na custom message\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\ncustomOKMessage\n\n\nNotification:customOKMessage\n\n\nmsg: The message to display\n\n\na custom message with an OK button\n\n\nControls\n\n\nNotifications\n\n\n\n\n\n\ncustomSuccess\n\n\nNotification:customSuccess\n\n\nmsg: The message to display\n\n\na custom success message\n\n\nCore, Controls\n\n\nNotifications\n\n\n\n\n\n\nsegmentMouseout\n\n\nSegment:mouseOut\n\n\nno: Segment number\n\n\nthe mouse is off a segment\n\n\nControls, Slide text (Tab)\n\n\nControls, Slide text (Tab)\n\n\n\n\n\n\nsegmentMouseover\n\n\nSegment:mouseOver\n\n\nno: Segment number\n\n\nthe mouse is over a segment\n\n\nControls, Slide text (Tab)\n\n\nControls, Slide text (Tab)\n\n\n\n\n\n\nsliderMousein\n\n\nSlider:mouseIn\n\n\n\n\nthe mouse entered the slider\n\n\nControls\n\n\n\n\n\n\n\n\nsliderMouseout\n\n\nSlider:mouseOut\n\n\n\n\nthe mouse is off the slider\n\n\nControls\n\n\n\n\n\n\n\n\nsliderMousemove\n\n\nSlider:mouseMoved\n\n\ntimeInMs: The time on the hovered position in ms\n\n\nthe mouse is moving over the slider\n\n\nControls\n\n\n\n\n\n\n\n\nsliderStart\n\n\nSlider:start\n\n\n\n\nslider started\n\n\nControls\n\n\n\n\n\n\n\n\nsliderStop\n\n\nSlider:stop\n\n\ntime: The time the slider stopped at\n\n\nslider stopped\n\n\nControls\n\n\nVideodisplay\n\n\n\n\n\n\naspectRatioSet\n\n\nVideo:aspectRatioSet\n\n\nas: (array) as[0] = width, as[1] = height, as[2] = aspect ratio in %\n\n\nthe aspect ratio has been calculated\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\naudioCodecNotSupported\n\n\nVideo:audioCodecNotSupported\n\n\n\n\nwhen the audio codec seems not to be supported by the browser\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\nautoplay\n\n\nVideo:autoplay\n\n\n\n\nautoplay the video\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nbufferedAndAutoplaying\n\n\nVideo:bufferedAndAutoplaying\n\n\n\n\nbuffering successful, was playing, autoplaying now\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\nbufferedButNotAutoplaying\n\n\nVideo:bufferedButNotAutoplaying\n\n\n\n\nbuffering successful, was not playing, not autoplaying now\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\nbuffering\n\n\nVideo:buffering\n\n\n\n\nvideo is buffering\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\nended\n\n\nVideo:ended\n\n\ntriggeredByMaster: Whether or not the event has been triggered by master\n\n\nvideo ended\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\nfullscreenCancel\n\n\nVideo:fullscreenCancel\n\n\n\n\ncancel fullscreen\n\n\nControls, Videodisplay\n\n\nVideodisplay\n\n\n\n\n\n\nfullscreenChange\n\n\nVideo:fullscreenChange\n\n\n\n\na fullscreen change happened\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\nfullscreenEnable\n\n\nVideo:fullscreenEnable\n\n\n\n\nenable fullscreen\n\n\nControls, Core\n\n\nControls, Videodisplay\n\n\n\n\n\n\nisAudioOnly\n\n\nVideo:isAudioOnly\n\n\naudio: true if audio only, false else\n\n\nwhether it's audio only or not\n\n\nVideodisplay\n\n\nControls, Notifications\n\n\n\n\n\n\ninitialSeek\n\n\nVideo:initialSeek\n\n\ntime: The time to seek to\n\n\nSeeks initially after all plugins have been loaded after a short delay\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nmute\n\n\nVideo:mute\n\n\n\n\nmute\n\n\nVideodisplay\n\n\nVideodisplay\n\n\n\n\n\n\nmuteToggle\n\n\nVideo:muteToggle\n\n\n\n\ntoggle mute and unmute\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nnextChapter\n\n\nVideo:nextChapter\n\n\n\n\nCore\n\n\n\n\n\n\n\n\n\n\nnumberOfVideodisplaysSet\n\n\nVideo:numberOfVideodisplaysSet\n\n\nno: Number of videodisplays\n\n\nthe number of videodisplays has been set\n\n\nVideodisplay\n\n\n\n\n\n\n\n\npause\n\n\nVideo:pause\n\n\ntriggeredByMaster: Whether or not the event has been triggered by master\n\n\npauses the video\n\n\n\n\n\n\n\n\n\n\nCore, Controls, Videodisplay\n\n\nControls, Videodisplay\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplay\n\n\nVideo:play\n\n\ntriggeredByMaster: Whether or not the event has been triggered by master\n\n\nplays the video\n\n\nCore, Controls, Videodisplay\n\n\nControls,Videodisplay\n\n\n\n\n\n\nplayPause\n\n\nVideo:playPause\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\npreviousChapter\n\n\nVideo:previousChapter\n\n\n\n\n\n\nCore\n\n\n\n\n\n\n\n\nplaybackRateChanged\n\n\nVideo:playbackRateChanged\n\n\nrate: The video playback rate (0.0-x, default: 1.0)\n\n\nThe video playback rate changed\n\n\nControls\n\n\nControls, Videodisplay\n\n\n\n\n\n\nplaybackRateIncrease\n\n\nVideo:playbackRateIncrease\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nplaybackRateDecrease\n\n\nVideo:playbackRateDecrease\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nplayerLoaded\n\n\nVideo:playerLoaded\n\n\n\n\nplayer loaded successfully\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nready\n\n\nVideo:ready\n\n\n\n\nall videos loaded successfully\n\n\nVideodisplay\n\n\nControls, Notifications\n\n\n\n\n\n\nseek\n\n\nVideo:seek\n\n\ntime: Current time in seconds  seek video to a given position in seconds\n\n\nCore, Controls, Slide text (Tab)\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nseekLeft\n\n\nVideo:seekLeft\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nseekRight\n\n\nVideo:seekRight\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nsynchronizing\n\n\nVideo:synchronizing\n\n\n\n\nsynchronizing videos with the master video\n\n\nVideodisplay\n\n\n\n\n\n\n\n\ntimeupdate\n\n\nVideo:timeupdate\n\n\ntime: Current time in seconds, triggeredByMaster: Whether or not the event has been triggered by master\n\n\na timeupdate happened\n\n\nVideodisplay\n\n\nControls, Usertracking\n\n\n\n\n\n\nqualitySet\n\n\nVideo:qualitySet\n\n\nquality: the quality that has been set a video quality has been set\n\n\nControls\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nunmute\n\n\nVideo:unmute\n\n\n\n\nunmute\n\n\nControls\n\n\nControls\n\n\n\n\n\n\nusingFlash\n\n\nVideo:usingFlash\n\n\nflash: true if flash is being used, false else\n\n\nflash is being used\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\nvideoFormatsFound\n\n\nVideo:videoFormatsFound\n\n\nformat: array of video formats if different video formats (qualities) have been found\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\n\n\nvolumechange\n\n\nVideo:volumechange\n\n\nvol: Current volume (0 is off (muted), 1.0 is all the way up, 0.5 is half way)\n\n\na volume change happened\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nvolumeDown\n\n\nVideo:volumeDown\n\n\n\n\n\n\nCore\n\n\nControls\n\n\n\n\n\n\nvolumeGet\n\n\nVideo:volumeGet\n\n\ncallback: A callback function with the current volume as a parameter\n\n\nget the volume\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nvolumeSet\n\n\nVideo:volumeSet\n\n\npercentAsDecimal: Volume to set (0 is off (muted), 1.0 is all the way up, 0.5 is half way)\n\n\nset the volume\n\n\nControls\n\n\nControls, Videodisplay\n\n\n\n\n\n\nvolumeUp\n\n\nVideo:volumeUp\n\n\n\n\n\n\nCore\n\n\nControls",
            "title": "Events"
        },
        {
            "location": "/modules/player.events/#theodul-pass-player-events",
            "text": "A Theodul Pass Player plugin can trigger and/or subscribe to events.  An event is defined in the events section of the plugin and looks like this:  NAME: new Engage.Event(\"MODULE:NAME\", \"DESCRIPTION\", \"OPTION\")  The event has the event name \"MODULE:NAME\", the description DESCRIPTION and one of the options \"trigger\", \"handler\" or \"both\" as OPTION. When the plugin just triggers the event, the option is \"trigger\", when it just handles the events the option is \"handler\" and when it does both - trigger and handle it - the option is \"both\".  An event can be triggered via  Engage.trigger(plugin.events.NAME.getName(), [parameter(s)]);  and can be subscribed to via  Engage.on(plugin.events.NAME.getName(), function () {});  The following list contains all events of the Core + of all official plugins, sorted alphabetically after \"Event name\" for version 1.0 of Feb 12, 2015.  Currently official plugins are   Controls  MHConnection  Notifications  Usertracking  Description  Description (Tab)  Slide text (Tab)  Shortcuts (Tab)  Timeline statistics  Videodisplay      Name  Event name  Additional parameters  Description  Triggered in  Handled in      coreInit  Core:init    Core     plugin_load_done  Core:plugin_load_done    Core  Core, Controls, MHConnection, Notifications, Usertracking, Description, Description (Tab), Slide text (Tab), Shortcuts (Tab), Timeline statistics, Videodisplay    timelineplugin_closed  Engage:timelineplugin_closed  Note: No \"Engage Event\", just use as string, example: Engage.on(\"Engage:timelineplugin_closed\", function() {});  when the timeline plugin container closed  Core     timelineplugin_opened  Engage:timelineplugin_opened  Note: No \"Engage Event\", just use as string, example: Engage.on(\"Engage:timelineplugin_opened\", function() {});  when the timeline plugin container opened  Core  Timeline statistics    getMediaInfo  MhConnection:getMediaInfo     MHConnection    getMediaPackage  MhConnection:getMediaPackage     MHConnection    mediaPackageModelError  MhConnection:mediaPackageModelError    MHConnection  Core, Controls, Notifications, Usertracking, Description, Description (Tab), Slide text (Tab), Shortcuts (Tab), Timeline statistics, Videodisplay    customError  Notification:customError  msg: The message to display  an error occurred  Core, Controls, Videodisplay  Notifications    customNotification  Notification:customNotification  msg: The message to display  a custom message  Videodisplay  Notifications    customOKMessage  Notification:customOKMessage  msg: The message to display  a custom message with an OK button  Controls  Notifications    customSuccess  Notification:customSuccess  msg: The message to display  a custom success message  Core, Controls  Notifications    segmentMouseout  Segment:mouseOut  no: Segment number  the mouse is off a segment  Controls, Slide text (Tab)  Controls, Slide text (Tab)    segmentMouseover  Segment:mouseOver  no: Segment number  the mouse is over a segment  Controls, Slide text (Tab)  Controls, Slide text (Tab)    sliderMousein  Slider:mouseIn   the mouse entered the slider  Controls     sliderMouseout  Slider:mouseOut   the mouse is off the slider  Controls     sliderMousemove  Slider:mouseMoved  timeInMs: The time on the hovered position in ms  the mouse is moving over the slider  Controls     sliderStart  Slider:start   slider started  Controls     sliderStop  Slider:stop  time: The time the slider stopped at  slider stopped  Controls  Videodisplay    aspectRatioSet  Video:aspectRatioSet  as: (array) as[0] = width, as[1] = height, as[2] = aspect ratio in %  the aspect ratio has been calculated  Videodisplay  Controls    audioCodecNotSupported  Video:audioCodecNotSupported   when the audio codec seems not to be supported by the browser  Videodisplay  Notifications    autoplay  Video:autoplay   autoplay the video  Core  Videodisplay    bufferedAndAutoplaying  Video:bufferedAndAutoplaying   buffering successful, was playing, autoplaying now  Videodisplay  Notifications    bufferedButNotAutoplaying  Video:bufferedButNotAutoplaying   buffering successful, was not playing, not autoplaying now  Videodisplay  Notifications    buffering  Video:buffering   video is buffering  Videodisplay  Notifications    ended  Video:ended  triggeredByMaster: Whether or not the event has been triggered by master  video ended  Videodisplay  Controls    fullscreenCancel  Video:fullscreenCancel   cancel fullscreen  Controls, Videodisplay  Videodisplay    fullscreenChange  Video:fullscreenChange   a fullscreen change happened  Videodisplay  Controls    fullscreenEnable  Video:fullscreenEnable   enable fullscreen  Controls, Core  Controls, Videodisplay    isAudioOnly  Video:isAudioOnly  audio: true if audio only, false else  whether it's audio only or not  Videodisplay  Controls, Notifications    initialSeek  Video:initialSeek  time: The time to seek to  Seeks initially after all plugins have been loaded after a short delay  Core  Videodisplay    mute  Video:mute   mute  Videodisplay  Videodisplay    muteToggle  Video:muteToggle   toggle mute and unmute  Core  Videodisplay    nextChapter  Video:nextChapter   Core      numberOfVideodisplaysSet  Video:numberOfVideodisplaysSet  no: Number of videodisplays  the number of videodisplays has been set  Videodisplay     pause  Video:pause  triggeredByMaster: Whether or not the event has been triggered by master  pauses the video      Core, Controls, Videodisplay  Controls, Videodisplay        play  Video:play  triggeredByMaster: Whether or not the event has been triggered by master  plays the video  Core, Controls, Videodisplay  Controls,Videodisplay    playPause  Video:playPause    Core  Videodisplay    previousChapter  Video:previousChapter    Core     playbackRateChanged  Video:playbackRateChanged  rate: The video playback rate (0.0-x, default: 1.0)  The video playback rate changed  Controls  Controls, Videodisplay    playbackRateIncrease  Video:playbackRateIncrease    Core  Videodisplay    playbackRateDecrease  Video:playbackRateDecrease    Core  Videodisplay    playerLoaded  Video:playerLoaded   player loaded successfully  Videodisplay     ready  Video:ready   all videos loaded successfully  Videodisplay  Controls, Notifications    seek  Video:seek  time: Current time in seconds  seek video to a given position in seconds  Core, Controls, Slide text (Tab)  Videodisplay     seekLeft  Video:seekLeft    Core  Videodisplay    seekRight  Video:seekRight    Core  Videodisplay    synchronizing  Video:synchronizing   synchronizing videos with the master video  Videodisplay     timeupdate  Video:timeupdate  time: Current time in seconds, triggeredByMaster: Whether or not the event has been triggered by master  a timeupdate happened  Videodisplay  Controls, Usertracking    qualitySet  Video:qualitySet  quality: the quality that has been set a video quality has been set  Controls  Videodisplay     unmute  Video:unmute   unmute  Controls  Controls    usingFlash  Video:usingFlash  flash: true if flash is being used, false else  flash is being used  Videodisplay  Controls    videoFormatsFound  Video:videoFormatsFound  format: array of video formats if different video formats (qualities) have been found  Videodisplay  Controls     volumechange  Video:volumechange  vol: Current volume (0 is off (muted), 1.0 is all the way up, 0.5 is half way)  a volume change happened  Videodisplay     volumeDown  Video:volumeDown    Core  Controls    volumeGet  Video:volumeGet  callback: A callback function with the current volume as a parameter  get the volume  Videodisplay     volumeSet  Video:volumeSet  percentAsDecimal: Volume to set (0 is off (muted), 1.0 is all the way up, 0.5 is half way)  set the volume  Controls  Controls, Videodisplay    volumeUp  Video:volumeUp    Core  Controls",
            "title": "Theodul Pass Player - Events"
        },
        {
            "location": "/modules/player.storage/",
            "text": "How to store data in the browser persistently\n\n\nThe Theodul Pass Player uses basil.js for storing persistent data such as the volume and the playback rate.\n\n\nBasil.js unifies localstorage, cookies and session storage and provides an easy-to-use JavaScript API.\n\n\nExample Usage\n\n\nIn your plugin you just have to require the basil lib which is being distributed globally:\n\n\ndefine([..., \"basil\", ...], function(..., Basil, ...) {\n    ...\n}\n\n\n\nAfter that basil needs to be set up:\n\n\nvar basilOptions = {\n    namespace: 'mhStorage'\n};\nBasil = new window.Basil(basilOptions);\n\n\n\nThe default plugins have \"mhStorage\" as their namespace, feel free to set your own. The default storage is the localstorage; if the localstorage is not available, a cookie is being used and so on.\n\n\nAfter setting up basil, the usage is straightforward:\n\n\nBasil.set(\"someKey\", \"someValue); // set a value\nBasil.get(\"someKey\"); // get a value",
            "title": "Storage"
        },
        {
            "location": "/modules/player.storage/#how-to-store-data-in-the-browser-persistently",
            "text": "The Theodul Pass Player uses basil.js for storing persistent data such as the volume and the playback rate.  Basil.js unifies localstorage, cookies and session storage and provides an easy-to-use JavaScript API.",
            "title": "How to store data in the browser persistently"
        },
        {
            "location": "/modules/player.storage/#example-usage",
            "text": "In your plugin you just have to require the basil lib which is being distributed globally:  define([..., \"basil\", ...], function(..., Basil, ...) {\n    ...\n}  After that basil needs to be set up:  var basilOptions = {\n    namespace: 'mhStorage'\n};\nBasil = new window.Basil(basilOptions);  The default plugins have \"mhStorage\" as their namespace, feel free to set your own. The default storage is the localstorage; if the localstorage is not available, a cookie is being used and so on.  After setting up basil, the usage is straightforward:  Basil.set(\"someKey\", \"someValue); // set a value\nBasil.get(\"someKey\"); // get a value",
            "title": "Example Usage"
        },
        {
            "location": "/modules/player.plugins/",
            "text": "Non-standard plugins\n\n\nThis page lists non-standard (3rd-party) plugins for the Player in Opencast version 2.x (Theodul Pass Player).\n\n\nTo add one of the plugins to an existing installation, the normal approach is the following:\n\n\n\n\nDownload the jar file of the plugin\n\n\nCopy it into the Opencast \"/lib\" folder\n\n\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nAuthor\n\n\nLicense\n\n\nDownload\n\n\n\n\n\n\n\n\n\n\nDownload\n\n\nLists the available the video and audio sources in a tab.\n\n\nHenning Str\u00fcber, Denis Meyer\n\n\nGNU LGPL v2 or v3\n\n\nhttps://bitbucket.org/CallToPower/theodul-download-plugin\n\n\n\n\n\n\nSnow Showcase\n\n\nLet it snow in the player!\n\n\nDenis Meyer\n\n\nGNU LGPL v2 or v3\n\n\nhttps://bitbucket.org/CallToPower/theodul-snowshowcase-plugin",
            "title": "Plugins"
        },
        {
            "location": "/modules/player.plugins/#non-standard-plugins",
            "text": "This page lists non-standard (3rd-party) plugins for the Player in Opencast version 2.x (Theodul Pass Player).  To add one of the plugins to an existing installation, the normal approach is the following:   Download the jar file of the plugin  Copy it into the Opencast \"/lib\" folder      Name  Description  Author  License  Download      Download  Lists the available the video and audio sources in a tab.  Henning Str\u00fcber, Denis Meyer  GNU LGPL v2 or v3  https://bitbucket.org/CallToPower/theodul-download-plugin    Snow Showcase  Let it snow in the player!  Denis Meyer  GNU LGPL v2 or v3  https://bitbucket.org/CallToPower/theodul-snowshowcase-plugin",
            "title": "Non-standard plugins"
        },
        {
            "location": "/modules/player.plugin.development/",
            "text": "How To Create A New Plugin\n\n\nPlugin Archetype\n\n\nThe \nMaven Archetype Plugin\n provides a convenient mechanism\nfor automatically generating projects. Project templates are called Archetypes and they are basically maven artifacts of\na special kind of packaging, \u2018maven-archetype\u2019.\n\n\nWith the Theodul Plugin Archetype you can create a new plugin project in no time and start writing the plugin\u2019s business\nlogic right away, without caring about the POM or SCR component declarations.\n\n\nInstallation\n\n\nThe Theodul Plugin Archetype is included in the Opencast source code (Theodul Player branch) in the modules directory.\nTo make the artifact available on your system you need to install it like any other atrifacts. In the Opencast source\ndirectory type:\n\n\n> cd modules/matterhorn-engage-theodul-plugin-archetype\n> mvn install\n\n\n\nAfter successful build and installation the archetype is available in your system.\n\n\nGenerating a new plugin\n\n\nTo generate a new plugin project simply go to the modules directory inside the Opencast source directory and type:\n\n\n> mvn archetype:generate -DarchetypeGroupId=org.opencastproject -DarchetypeArtifactId=matterhorn-theodul-plugin\n\n\n\nProvided the archetype is installed maven will now ask you for the properties configuration for the new project:\n\n\n[INFO] Generating project in Interactive mode\n[INFO] Archetype [org.opencastproject:matterhorn-theodul-plugin:1.5-SNAPSHOT] found in catalog local\nDefine value for property 'groupId': : org.opencastproject\nDefine value for property 'artifactId': : matterhorn-engage-theodul-plugin-test\nDefine value for property 'version': 1.0-SNAPSHOT: : 1.5-SNAPSHOT\nDefine value for property 'package': org.opencastproject: : org.opencastproject.engage.theodul.plugin.custom.test\nDefine value for property 'plugin_description': : A test plugin\nDefine value for property 'plugin_name': : testName \nDefine value for property 'plugin_type': : custom\nDefine value for property 'plugin_version': : 0.1\nDefine value for property 'plugin_rest': : false\nConfirm properties configuration:\ngroupId: org.opencastproject\nartifactId: matterhorn-engage-theodul-plugin-test\nversion: 1.5-SNAPSHOT\npackage: org.opencastproject.engage.theodul.plugin.test\nplugin_description: A test plugin\nplugin_name: test\nplugin_rest: true\n Y: : y\n[INFO] ----------------------------------------------------------------------------\n[INFO] Using following parameters for creating project from Archetype: matterhorn-theodul-plugin:1.5-SNAPSHOT\n[INFO] ----------------------------------------------------------------------------\n[INFO] Parameter: groupId, Value: org.opencastproject\n[INFO] Parameter: artifactId, Value: matterhorn-engage-theodul-plugin-test\n[INFO] Parameter: version, Value: 1.5-SNAPSHOT\n[INFO] Parameter: package, Value: org.opencastproject.engage.theodul.plugin.test\n[INFO] Parameter: packageInPathFormat, Value: org/opencastproject/engage/theodul/plugin/test\n[INFO] Parameter: package, Value: org.opencastproject.engage.theodul.plugin.test\n[INFO] Parameter: version, Value: 1.5-SNAPSHOT\n[INFO] Parameter: plugin_description, Value: A test plugin\n[INFO] Parameter: plugin_name, Value: test\n[INFO] Parameter: groupId, Value: org.opencastproject\n[INFO] Parameter: plugin_rest, Value: true\n[INFO] Parameter: artifactId, Value: matterhorn-engage-theodul-plugin-test\n[INFO] project created from Archetype in dir: /home/wulff/code/UOS/plugin-archetype/test/matterhorn-engage-theodul-plugin-test\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 3:39.195s\n[INFO] Finished at: Thu Jan 23 15:48:37 CET 2014\n[INFO] Final Memory: 15M/308M\n[INFO] ------------------------------------------------------------------------\n\n\n\nThere you go, the newly created plugin project is waiting to be filled with life in the directory that is named after\nthe atrifactId you entered before.\n\n\nProject Properties\n\n\nIn addition to the above explanation, here is a description of the properties you have to specify when generating a new\nproject with the Theodul Plugin Archetype:\n\n\ngroupId\n\n\nMaven group ID. For the Opencast developers this is\n\n\norg.opencastproject\n\n\n\nartifactId\n\n\nMaven artifact ID. Name by which your project is identified as an artifact by maven. Think of it as the project name. It\nwill also be used as the name for your projects root directory. During the course of the Theodul project the following\nnaming scheme came up:\n\n\nmatterhorn-engage-theodul-plugin-<plugin type>-<plugin name>\n\n\n\nversion\n\n\nThe project version. For Opencast developers: simply put in the version of the Opencast source tree your are working\non.\n\n\npackage\n\n\nThe Java package in which the source for the back end part of your plugin will live. The following scheme is used by the\nTheodul developers:\n\n\norg.opencastproject.engage.theodul.plugin.<plugin type>.<plugin name>\n\n\n\nplugin_version\n\n\nThe version of the plugin itself. This is not to be confused with the maven project version which will, for instance, be\nupdated when the Opencast version changes.\n\n\nplugin_type\n\n\nThe type of the plugin to be created. See https://opencast.jira.com/wiki/display/MH/Architecture\nPossible types are: custom, controls, timeline, video, description, tab\n\n\nplugin_name\n\n\nThe name by which your plugin will be registered by the plugin manager when running.\n\n\nplugin_description\n\n\n(optional) A short description of the plugin. The description will be provided by the \nplugin list endpoint\n\n together with the other plugin data.\n\n\nplugin_rest\n\n\n(boolean) Whether or not the plugin should provide a Opencast Rest endpoint. If set to true, the Java class that makes\nup the back end part of your plugin will be augmented with the annotations necessary to work as a Rest endpoint provider\nin Opencast. Also an example endpoint (GET:sayHello) will be generated.\n\n\nExample Plugin\n\n\nHave a look at the \nsnow showcase example plugin (custom)\n.\n\n\nDebugging\n\n\nTo display debug information in the developer console, add the following parameters to the URL:\n\n\nDisplay debug information\n\n\n&debug=true\n\n\n\nDisplay event debug information\n\n\n&debugEvents=true",
            "title": "Plugin Development"
        },
        {
            "location": "/modules/player.plugin.development/#how-to-create-a-new-plugin",
            "text": "",
            "title": "How To Create A New Plugin"
        },
        {
            "location": "/modules/player.plugin.development/#plugin-archetype",
            "text": "The  Maven Archetype Plugin  provides a convenient mechanism\nfor automatically generating projects. Project templates are called Archetypes and they are basically maven artifacts of\na special kind of packaging, \u2018maven-archetype\u2019.  With the Theodul Plugin Archetype you can create a new plugin project in no time and start writing the plugin\u2019s business\nlogic right away, without caring about the POM or SCR component declarations.",
            "title": "Plugin Archetype"
        },
        {
            "location": "/modules/player.plugin.development/#installation",
            "text": "The Theodul Plugin Archetype is included in the Opencast source code (Theodul Player branch) in the modules directory.\nTo make the artifact available on your system you need to install it like any other atrifacts. In the Opencast source\ndirectory type:  > cd modules/matterhorn-engage-theodul-plugin-archetype\n> mvn install  After successful build and installation the archetype is available in your system.",
            "title": "Installation"
        },
        {
            "location": "/modules/player.plugin.development/#generating-a-new-plugin",
            "text": "To generate a new plugin project simply go to the modules directory inside the Opencast source directory and type:  > mvn archetype:generate -DarchetypeGroupId=org.opencastproject -DarchetypeArtifactId=matterhorn-theodul-plugin  Provided the archetype is installed maven will now ask you for the properties configuration for the new project:  [INFO] Generating project in Interactive mode\n[INFO] Archetype [org.opencastproject:matterhorn-theodul-plugin:1.5-SNAPSHOT] found in catalog local\nDefine value for property 'groupId': : org.opencastproject\nDefine value for property 'artifactId': : matterhorn-engage-theodul-plugin-test\nDefine value for property 'version': 1.0-SNAPSHOT: : 1.5-SNAPSHOT\nDefine value for property 'package': org.opencastproject: : org.opencastproject.engage.theodul.plugin.custom.test\nDefine value for property 'plugin_description': : A test plugin\nDefine value for property 'plugin_name': : testName \nDefine value for property 'plugin_type': : custom\nDefine value for property 'plugin_version': : 0.1\nDefine value for property 'plugin_rest': : false\nConfirm properties configuration:\ngroupId: org.opencastproject\nartifactId: matterhorn-engage-theodul-plugin-test\nversion: 1.5-SNAPSHOT\npackage: org.opencastproject.engage.theodul.plugin.test\nplugin_description: A test plugin\nplugin_name: test\nplugin_rest: true\n Y: : y\n[INFO] ----------------------------------------------------------------------------\n[INFO] Using following parameters for creating project from Archetype: matterhorn-theodul-plugin:1.5-SNAPSHOT\n[INFO] ----------------------------------------------------------------------------\n[INFO] Parameter: groupId, Value: org.opencastproject\n[INFO] Parameter: artifactId, Value: matterhorn-engage-theodul-plugin-test\n[INFO] Parameter: version, Value: 1.5-SNAPSHOT\n[INFO] Parameter: package, Value: org.opencastproject.engage.theodul.plugin.test\n[INFO] Parameter: packageInPathFormat, Value: org/opencastproject/engage/theodul/plugin/test\n[INFO] Parameter: package, Value: org.opencastproject.engage.theodul.plugin.test\n[INFO] Parameter: version, Value: 1.5-SNAPSHOT\n[INFO] Parameter: plugin_description, Value: A test plugin\n[INFO] Parameter: plugin_name, Value: test\n[INFO] Parameter: groupId, Value: org.opencastproject\n[INFO] Parameter: plugin_rest, Value: true\n[INFO] Parameter: artifactId, Value: matterhorn-engage-theodul-plugin-test\n[INFO] project created from Archetype in dir: /home/wulff/code/UOS/plugin-archetype/test/matterhorn-engage-theodul-plugin-test\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 3:39.195s\n[INFO] Finished at: Thu Jan 23 15:48:37 CET 2014\n[INFO] Final Memory: 15M/308M\n[INFO] ------------------------------------------------------------------------  There you go, the newly created plugin project is waiting to be filled with life in the directory that is named after\nthe atrifactId you entered before.",
            "title": "Generating a new plugin"
        },
        {
            "location": "/modules/player.plugin.development/#project-properties",
            "text": "In addition to the above explanation, here is a description of the properties you have to specify when generating a new\nproject with the Theodul Plugin Archetype:",
            "title": "Project Properties"
        },
        {
            "location": "/modules/player.plugin.development/#groupid",
            "text": "Maven group ID. For the Opencast developers this is  org.opencastproject",
            "title": "groupId"
        },
        {
            "location": "/modules/player.plugin.development/#artifactid",
            "text": "Maven artifact ID. Name by which your project is identified as an artifact by maven. Think of it as the project name. It\nwill also be used as the name for your projects root directory. During the course of the Theodul project the following\nnaming scheme came up:  matterhorn-engage-theodul-plugin-<plugin type>-<plugin name>",
            "title": "artifactId"
        },
        {
            "location": "/modules/player.plugin.development/#version",
            "text": "The project version. For Opencast developers: simply put in the version of the Opencast source tree your are working\non.",
            "title": "version"
        },
        {
            "location": "/modules/player.plugin.development/#package",
            "text": "The Java package in which the source for the back end part of your plugin will live. The following scheme is used by the\nTheodul developers:  org.opencastproject.engage.theodul.plugin.<plugin type>.<plugin name>",
            "title": "package"
        },
        {
            "location": "/modules/player.plugin.development/#plugin_version",
            "text": "The version of the plugin itself. This is not to be confused with the maven project version which will, for instance, be\nupdated when the Opencast version changes.",
            "title": "plugin_version"
        },
        {
            "location": "/modules/player.plugin.development/#plugin_type",
            "text": "The type of the plugin to be created. See https://opencast.jira.com/wiki/display/MH/Architecture\nPossible types are: custom, controls, timeline, video, description, tab",
            "title": "plugin_type"
        },
        {
            "location": "/modules/player.plugin.development/#plugin_name",
            "text": "The name by which your plugin will be registered by the plugin manager when running.",
            "title": "plugin_name"
        },
        {
            "location": "/modules/player.plugin.development/#plugin_description",
            "text": "(optional) A short description of the plugin. The description will be provided by the  plugin list endpoint  together with the other plugin data.",
            "title": "plugin_description"
        },
        {
            "location": "/modules/player.plugin.development/#plugin_rest",
            "text": "(boolean) Whether or not the plugin should provide a Opencast Rest endpoint. If set to true, the Java class that makes\nup the back end part of your plugin will be augmented with the annotations necessary to work as a Rest endpoint provider\nin Opencast. Also an example endpoint (GET:sayHello) will be generated.",
            "title": "plugin_rest"
        },
        {
            "location": "/modules/player.plugin.development/#example-plugin",
            "text": "Have a look at the  snow showcase example plugin (custom) .",
            "title": "Example Plugin"
        },
        {
            "location": "/modules/player.plugin.development/#debugging",
            "text": "To display debug information in the developer console, add the following parameters to the URL:  Display debug information  &debug=true  Display event debug information  &debugEvents=true",
            "title": "Debugging"
        },
        {
            "location": "/modules/player.testing/",
            "text": "How To Test With Phantom.js and Jasmine\n\n\nIntegration Of Jasmine Into The Build Process (Maven)\n\n\nJasmine\n is integrated with the \njasmine-maven-plugin\n into the maven build process. Therefore only the pom.xml file will be enhanced by the following code, which specifies the \njasmine-maven-plugin\n as plugin for the build process. The configuration of the jasmine-maven-plugin is also done in this file. The meaning of every configuration parameter can be looked up on the jasmine-maven-plugin project page under this \nlink\n. The following configuration uses a the specRunnerTemplate  REQUIRE_JS in order to function properly with \nRequireJS\n. Further information about spec runner templates can be found \nhere\n. On the next build the needed dependencies will be automatically resolved just like it is in the nature of maven.\n\n\npom.xml\n\n\n<build>\n<plugins>\n    ...\n      <plugin>\n        <groupId>com.github.searls</groupId>\n        <artifactId>jasmine-maven-plugin</artifactId>\n        <version>1.3.1.2</version>\n        <executions>\n          <execution>\n            <goals>\n              <goal>test</goal>\n            </goals>\n          </execution>\n        </executions>\n        <configuration>\n          <preloadSources>\n            <source>${project.basedir}/src/test/resources/js/lib/require.js</source>\n          </preloadSources>\n          <jsSrcDir>${project.basedir}/src/main/resources/static</jsSrcDir>\n          <sourceIncludes>\n            <include>**/*.js</include>\n            <include>**/*.coffee</include>\n          </sourceIncludes>\n          <jsTestSrcDir>${project.basedir}/src/test/resources/js/spec</jsTestSrcDir>\n          <specIncludes>\n            <include>**/spec_helper.js</include>\n            <include>**/*.js</include>\n            <include>**/*.coffee</include>\n          </specIncludes>\n          <specRunnerTemplate>REQUIRE_JS</specRunnerTemplate>\n          <format>progress</format>\n        </configuration>\n      </plugin>\n  </plugins>\n</build>\n\n\n\nTesting The Engage Core\n\n\nThis chapter gives an overview over the directory structure used for testing the theodul engage core module, the configuration for the specs in the \nspec_helper.js\n and how to write specs for the core.\n\n\nDirectory Structure\n\n\nThe test relevant files are located in the \nsrc/test/resources/ui/js/spec\n tree. Files that filename ends on \n_spec.js\n are considered as files with executable tests. The \nspec_helper.js\n in configured in the \npom.xml\n for the initial setup.\n\n\nDirectory Structure Testing Engage Core\n\n\n|-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------spec    #Tests the *_spec.js and the helper file spec_helper.js\n\n\n\nSpec Helper\n\n\nThe file \nspec_helper.js\n takes over the configuration of RequireJS which is usually done by the engage_init.js. The paths differ slighty from the player has at runtime.\n\n\nspec_helper for engage_core module\n\n\n/*global requirejs*/\nrequirejs.config({\n  baseUrl: 'src/js/lib',\n  paths: {\n    require: 'require',\n    jquery: 'jquery',\n    underscore: 'underscore',\n    backbone: 'backbone',\n    engage: '../engage',\n    plugins: '../engage/plugin/*/static'\n  },\n  shim: {\n    'backbone': {\n      //script dependencies\n      deps: ['underscore', 'jquery'],\n      //global variable\n      exports: 'Backbone'\n    },\n    'underscore': {\n      //global variable\n      exports: '_'\n    }\n  }\n});\nvar PLUGIN_MANAGER_PATH = '/engage/theodul/manager/list.json';\nvar PLUGIN_PATH = '/engage/theodul/plugin/';\n\n\n\nWriting Specs\n\n\nTODO\n\n\nTesting Engage Plugins\n\n\nThis chapter gives an overview over the directory structure used for testing a theodul engage plugin module, the configuration for the specs in the spec_helper.js and how to write specs for a plugin.\n\n\nDirectory Structure\n\n\nThe test relevant files are located in the \nsrc/test/resources/ui/js/spec\n tree. Files that filename ends on \n_spec.js\n are considered as files with executable tests. The \nspec_helper.js\n in configured in the \npom.xml\n for the initial setup. In the directory \ntest/resources/ui/js/engage\n is a mockup of the theodul engage core module in order to be able to test the plugin module independent. The directory \ntest/resources/ui/js/lib\n provides the libraries which are provides by the engage core module at runtime of the player, as well to be able to test the plugin module independently.\n\n\nDirectory Structure Testing Plugins\n\n\n|-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------engage  #Mockup of the engage_core.js and engage_model.js\n|-----------lib     #Libraries that are used and provided by the core (A copy of the lib directory in the engage core module)\n|-----------spec    #Tests the *_spec.js and the helper file spec_helper.js\n\n\n\nSpec Helper\n\n\nThe file \nspec_helper.js\n takes over the configuration of RequireJS which is usually done by the engage_init.js. The paths differ slighty from the player uses at runtime.\n\n\n/*global requirejs*/\nrequirejs.config({\n  baseUrl: 'src/',\n  paths: {\n    require: 'test/resources/js/lib/require',\n    jquery: 'test/resources/js/lib/jquery',\n    underscore: 'test/resources/js/lib/underscore',\n    backbone: 'test/resources/js/lib/backbone',\n    engage: 'test/resources/js/engage'\n  },\n  shim: {\n    'backbone': {\n      //script dependencies\n      deps: ['underscore', 'jquery'],\n      //global variable\n      exports: 'Backbone'\n    },\n    'underscore': {\n      //global variable\n      exports: '_'\n    }\n  }\n});\n\n\n\nWriting Specs\n\n\nTODO\n\n\nRunning The Tests\n\n\nNow you can start the build process and the jasmine specs will be executed. Each . stands for a successful test. F stands for a failure and will stop the build process like it is specified in the configuration. The example output shows a manipulated version of the tests for the theodul engage core in order to illustrate a failing test. Normally all three tests should succeed at this point.\n\n\nTesting on build\n\n\nmvn install -DdeployTo=${FELIX_HOME}\n    // some output before\n    [INFO]\n    -------------------------------------------------------\n     J A S M I N E   S P E C S\n    -------------------------------------------------------\n    [INFO]\n    F..\n\n    1 failure:\n\n      1.) EngageCore it should have a model <<< FAILURE!\n\n        * Expected { cid : 'c3', ... _pending : false } not to be defined.\n\n    Results: 3 specs, 1 failures\n    // some output before\n\n\n\nThe jasmine-maven-plugin can also be executed manually and show the result in a browser. This can be achieved by the following command:\n\n\nManual testing\n\n\nmvn jasmine:bdd\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Building matterhorn-engage-theodul-core 1.5-SNAPSHOT\n    [INFO] ------------------------------------------------------------------------\n    [INFO]\n    [INFO] --- jasmine-maven-plugin:1.3.1.2:bdd (default-cli) @ matterhorn-engage-theodul-core ---\n    2014-01-28 14:33:30.722:INFO:oejs.Server:jetty-8.1.10.v20130312\n    2014-01-28 14:33:30.746:INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:8234\n    [INFO]\n\n    Server started--it's time to spec some JavaScript! You can run your specs as you develop by visiting this URL in a web browser:\n\n    http://localhost:8234\n\n    The server will monitor these two directories for scripts that you add, remove, and change:\n\n    source directory: src/main/resources/ui\n\n    spec directory: src/test/resources/ui/js/spec\n\n    Just leave this process running as you test-drive your code, refreshing your browser window to re-run your specs.\n    You can kill the server with Ctrl-C when you're done.\n\n\n\nIn a browser you should see an output like it is shown on the next screenshot.",
            "title": "Testing"
        },
        {
            "location": "/modules/player.testing/#how-to-test-with-phantomjs-and-jasmine",
            "text": "",
            "title": "How To Test With Phantom.js and Jasmine"
        },
        {
            "location": "/modules/player.testing/#integration-of-jasmine-into-the-build-process-maven",
            "text": "Jasmine  is integrated with the  jasmine-maven-plugin  into the maven build process. Therefore only the pom.xml file will be enhanced by the following code, which specifies the  jasmine-maven-plugin  as plugin for the build process. The configuration of the jasmine-maven-plugin is also done in this file. The meaning of every configuration parameter can be looked up on the jasmine-maven-plugin project page under this  link . The following configuration uses a the specRunnerTemplate  REQUIRE_JS in order to function properly with  RequireJS . Further information about spec runner templates can be found  here . On the next build the needed dependencies will be automatically resolved just like it is in the nature of maven.  pom.xml  <build>\n<plugins>\n    ...\n      <plugin>\n        <groupId>com.github.searls</groupId>\n        <artifactId>jasmine-maven-plugin</artifactId>\n        <version>1.3.1.2</version>\n        <executions>\n          <execution>\n            <goals>\n              <goal>test</goal>\n            </goals>\n          </execution>\n        </executions>\n        <configuration>\n          <preloadSources>\n            <source>${project.basedir}/src/test/resources/js/lib/require.js</source>\n          </preloadSources>\n          <jsSrcDir>${project.basedir}/src/main/resources/static</jsSrcDir>\n          <sourceIncludes>\n            <include>**/*.js</include>\n            <include>**/*.coffee</include>\n          </sourceIncludes>\n          <jsTestSrcDir>${project.basedir}/src/test/resources/js/spec</jsTestSrcDir>\n          <specIncludes>\n            <include>**/spec_helper.js</include>\n            <include>**/*.js</include>\n            <include>**/*.coffee</include>\n          </specIncludes>\n          <specRunnerTemplate>REQUIRE_JS</specRunnerTemplate>\n          <format>progress</format>\n        </configuration>\n      </plugin>\n  </plugins>\n</build>",
            "title": "Integration Of Jasmine Into The Build Process (Maven)"
        },
        {
            "location": "/modules/player.testing/#testing-the-engage-core",
            "text": "This chapter gives an overview over the directory structure used for testing the theodul engage core module, the configuration for the specs in the  spec_helper.js  and how to write specs for the core.",
            "title": "Testing The Engage Core"
        },
        {
            "location": "/modules/player.testing/#directory-structure",
            "text": "The test relevant files are located in the  src/test/resources/ui/js/spec  tree. Files that filename ends on  _spec.js  are considered as files with executable tests. The  spec_helper.js  in configured in the  pom.xml  for the initial setup.  Directory Structure Testing Engage Core  |-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------spec    #Tests the *_spec.js and the helper file spec_helper.js",
            "title": "Directory Structure"
        },
        {
            "location": "/modules/player.testing/#spec-helper",
            "text": "The file  spec_helper.js  takes over the configuration of RequireJS which is usually done by the engage_init.js. The paths differ slighty from the player has at runtime.  spec_helper for engage_core module  /*global requirejs*/\nrequirejs.config({\n  baseUrl: 'src/js/lib',\n  paths: {\n    require: 'require',\n    jquery: 'jquery',\n    underscore: 'underscore',\n    backbone: 'backbone',\n    engage: '../engage',\n    plugins: '../engage/plugin/*/static'\n  },\n  shim: {\n    'backbone': {\n      //script dependencies\n      deps: ['underscore', 'jquery'],\n      //global variable\n      exports: 'Backbone'\n    },\n    'underscore': {\n      //global variable\n      exports: '_'\n    }\n  }\n});\nvar PLUGIN_MANAGER_PATH = '/engage/theodul/manager/list.json';\nvar PLUGIN_PATH = '/engage/theodul/plugin/';",
            "title": "Spec Helper"
        },
        {
            "location": "/modules/player.testing/#writing-specs",
            "text": "TODO",
            "title": "Writing Specs"
        },
        {
            "location": "/modules/player.testing/#testing-engage-plugins",
            "text": "This chapter gives an overview over the directory structure used for testing a theodul engage plugin module, the configuration for the specs in the spec_helper.js and how to write specs for a plugin.",
            "title": "Testing Engage Plugins"
        },
        {
            "location": "/modules/player.testing/#directory-structure_1",
            "text": "The test relevant files are located in the  src/test/resources/ui/js/spec  tree. Files that filename ends on  _spec.js  are considered as files with executable tests. The  spec_helper.js  in configured in the  pom.xml  for the initial setup. In the directory  test/resources/ui/js/engage  is a mockup of the theodul engage core module in order to be able to test the plugin module independent. The directory  test/resources/ui/js/lib  provides the libraries which are provides by the engage core module at runtime of the player, as well to be able to test the plugin module independently.  Directory Structure Testing Plugins  |-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------engage  #Mockup of the engage_core.js and engage_model.js\n|-----------lib     #Libraries that are used and provided by the core (A copy of the lib directory in the engage core module)\n|-----------spec    #Tests the *_spec.js and the helper file spec_helper.js",
            "title": "Directory Structure"
        },
        {
            "location": "/modules/player.testing/#spec-helper_1",
            "text": "The file  spec_helper.js  takes over the configuration of RequireJS which is usually done by the engage_init.js. The paths differ slighty from the player uses at runtime.  /*global requirejs*/\nrequirejs.config({\n  baseUrl: 'src/',\n  paths: {\n    require: 'test/resources/js/lib/require',\n    jquery: 'test/resources/js/lib/jquery',\n    underscore: 'test/resources/js/lib/underscore',\n    backbone: 'test/resources/js/lib/backbone',\n    engage: 'test/resources/js/engage'\n  },\n  shim: {\n    'backbone': {\n      //script dependencies\n      deps: ['underscore', 'jquery'],\n      //global variable\n      exports: 'Backbone'\n    },\n    'underscore': {\n      //global variable\n      exports: '_'\n    }\n  }\n});",
            "title": "Spec Helper"
        },
        {
            "location": "/modules/player.testing/#writing-specs_1",
            "text": "TODO",
            "title": "Writing Specs"
        },
        {
            "location": "/modules/player.testing/#running-the-tests",
            "text": "Now you can start the build process and the jasmine specs will be executed. Each . stands for a successful test. F stands for a failure and will stop the build process like it is specified in the configuration. The example output shows a manipulated version of the tests for the theodul engage core in order to illustrate a failing test. Normally all three tests should succeed at this point.  Testing on build  mvn install -DdeployTo=${FELIX_HOME}\n    // some output before\n    [INFO]\n    -------------------------------------------------------\n     J A S M I N E   S P E C S\n    -------------------------------------------------------\n    [INFO]\n    F..\n\n    1 failure:\n\n      1.) EngageCore it should have a model <<< FAILURE!\n\n        * Expected { cid : 'c3', ... _pending : false } not to be defined.\n\n    Results: 3 specs, 1 failures\n    // some output before  The jasmine-maven-plugin can also be executed manually and show the result in a browser. This can be achieved by the following command:  Manual testing  mvn jasmine:bdd\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Building matterhorn-engage-theodul-core 1.5-SNAPSHOT\n    [INFO] ------------------------------------------------------------------------\n    [INFO]\n    [INFO] --- jasmine-maven-plugin:1.3.1.2:bdd (default-cli) @ matterhorn-engage-theodul-core ---\n    2014-01-28 14:33:30.722:INFO:oejs.Server:jetty-8.1.10.v20130312\n    2014-01-28 14:33:30.746:INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:8234\n    [INFO]\n\n    Server started--it's time to spec some JavaScript! You can run your specs as you develop by visiting this URL in a web browser:\n\n    http://localhost:8234\n\n    The server will monitor these two directories for scripts that you add, remove, and change:\n\n    source directory: src/main/resources/ui\n\n    spec directory: src/test/resources/ui/js/spec\n\n    Just leave this process running as you test-drive your code, refreshing your browser window to re-run your specs.\n    You can kill the server with Ctrl-C when you're done.  In a browser you should see an output like it is shown on the next screenshot.",
            "title": "Running The Tests"
        },
        {
            "location": "/modules/player.configuration/",
            "text": "Theodul Pass Player - Configuration\n\n\nThe Theodul Pass Player is the new default player from Opencast 2.0 onwards.  The old engage player from 1.x is still\navailable.\n\n\nThe configurations for the player are done for each tenant. So the configuration keys are located in\n\n.../etc/org.opencastproject.organization-mh_default_org.cfg\n.\n\n\nSelect the Opencast 2.0 Player\n\n\nTo activate the player set:\n\n\nprop.player=/engage/theodul/ui/core.html\n\n\n\nConfiguration\n\n\nLogo\n\n\nThe logo in the top right can easily be replaced by changing the path or URL for logo small.\n\n\nprop.logo_player=/engage/ui/img/mh_logos/OpencastLogo.png\n\n\n\nOptions:\n\n\n\n\nAny URL or local path to a PNG, GIF, JPG image. Default displayed hight in the browser 36px.\n\n\n\n\nPosition of the controls\n\n\nThe basic controls for the player can be placed over or under the video display.\n\n\nprop.player.positioncontrols=bottom\n\n\n\nOptions:\n\n\n\n\ntop\n\n\nbottom\n\n\n\n\nMain video flavor\n\n\nThe default flavor of the master video (the video on the \"left side\" in the video display). This source also provides\nthe audio. You can change this to every falvor that your installation might provide. If no mastervideotype was selected,\nor the mastervideotype is not available the videos are taken in their sequence within the mediapackage.\n\n\nprop.player.mastervideotype=presenter/delivery\n\n\n\nOptions (default flavors):\n\n\n\n\npresenter/delivery\n\n\npresentation/delivery\n\n\n\n\nShow Embed links\n\n\nThe player can show a dialog with links to the current video that can be embeded into other websites. This function can\nbe disabled\n\n\nprop.show_embed_links=true\n\n\n\nOptions:\n\n\n\n\ntrue\n\n\nfalse\n\n\n\n\nLink to Media Module\n\n\nIf you don't want to use the Opencast Media Module the link within the player back to the overview of the recordings can\nbe disabled:\n\n\nprop.link_mediamodule=true\n\n\n\nOptions:\n\n\n\n\ntrue\n\n\nfalse\n\n\n\n\nKeyboard Shortcuts\n\n\nThe keyboard shortcuts in the player can be customized:\n\n\nprop.player.shortcut.playPause=space\nprop.player.shortcut.seekRight=right\nprop.player.shortcut.seekLeft=left\nprop.player.shortcut.playbackrateIncrease=mod+9\nprop.player.shortcut.playbackrateDecrease=mod+8\nprop.player.shortcut.muteToggle=m\nprop.player.shortcut.volUp=9\nprop.player.shortcut.volDown=8\nprop.player.shortcut.fullscreenEnable=mod+enter\nprop.player.shortcut.fullscreenCancel=escape\nprop.player.shortcut.jumpToBegin=backspace\nprop.player.shortcut.prevChapter=pagedown\nprop.player.shortcut.nextChapter=pageup",
            "title": "Configuration"
        },
        {
            "location": "/modules/player.configuration/#theodul-pass-player-configuration",
            "text": "The Theodul Pass Player is the new default player from Opencast 2.0 onwards.  The old engage player from 1.x is still\navailable.  The configurations for the player are done for each tenant. So the configuration keys are located in .../etc/org.opencastproject.organization-mh_default_org.cfg .",
            "title": "Theodul Pass Player - Configuration"
        },
        {
            "location": "/modules/player.configuration/#select-the-opencast-20-player",
            "text": "To activate the player set:  prop.player=/engage/theodul/ui/core.html",
            "title": "Select the Opencast 2.0 Player"
        },
        {
            "location": "/modules/player.configuration/#configuration",
            "text": "",
            "title": "Configuration"
        },
        {
            "location": "/modules/player.configuration/#logo",
            "text": "The logo in the top right can easily be replaced by changing the path or URL for logo small.  prop.logo_player=/engage/ui/img/mh_logos/OpencastLogo.png  Options:   Any URL or local path to a PNG, GIF, JPG image. Default displayed hight in the browser 36px.",
            "title": "Logo"
        },
        {
            "location": "/modules/player.configuration/#position-of-the-controls",
            "text": "The basic controls for the player can be placed over or under the video display.  prop.player.positioncontrols=bottom  Options:   top  bottom",
            "title": "Position of the controls"
        },
        {
            "location": "/modules/player.configuration/#main-video-flavor",
            "text": "The default flavor of the master video (the video on the \"left side\" in the video display). This source also provides\nthe audio. You can change this to every falvor that your installation might provide. If no mastervideotype was selected,\nor the mastervideotype is not available the videos are taken in their sequence within the mediapackage.  prop.player.mastervideotype=presenter/delivery  Options (default flavors):   presenter/delivery  presentation/delivery",
            "title": "Main video flavor"
        },
        {
            "location": "/modules/player.configuration/#show-embed-links",
            "text": "The player can show a dialog with links to the current video that can be embeded into other websites. This function can\nbe disabled  prop.show_embed_links=true  Options:   true  false",
            "title": "Show Embed links"
        },
        {
            "location": "/modules/player.configuration/#link-to-media-module",
            "text": "If you don't want to use the Opencast Media Module the link within the player back to the overview of the recordings can\nbe disabled:  prop.link_mediamodule=true  Options:   true  false",
            "title": "Link to Media Module"
        },
        {
            "location": "/modules/player.configuration/#keyboard-shortcuts",
            "text": "The keyboard shortcuts in the player can be customized:  prop.player.shortcut.playPause=space\nprop.player.shortcut.seekRight=right\nprop.player.shortcut.seekLeft=left\nprop.player.shortcut.playbackrateIncrease=mod+9\nprop.player.shortcut.playbackrateDecrease=mod+8\nprop.player.shortcut.muteToggle=m\nprop.player.shortcut.volUp=9\nprop.player.shortcut.volDown=8\nprop.player.shortcut.fullscreenEnable=mod+enter\nprop.player.shortcut.fullscreenCancel=escape\nprop.player.shortcut.jumpToBegin=backspace\nprop.player.shortcut.prevChapter=pagedown\nprop.player.shortcut.nextChapter=pageup",
            "title": "Keyboard Shortcuts"
        },
        {
            "location": "/modules/player.url.parameter/",
            "text": "Theodul Pass Player - URL Parameters\n\n\nURL Parameters\n\n\n\n\ntime\n\n\nPossible values\n\n\nMinutes (with value \nX\n) and seconds (with value \nY\n)\n\n\nXmYs\n\n\nYsXm\n\n\nXmY\n\n\n\n\n\n\nMinutes (with value \nX\n) only\n\n\nXm\n\n\n\n\n\n\nSeconds (with value \nY\n) only\n\n\nYs\n\n\nY\n\n\n\n\n\n\nDefault value\n\n\n-\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nSeeks intially automatically to a specified time\n\n\nautomatically plays the video from the specified time on\n\n\n\n\n\n\n\n\n\n\nautoplay\n\n\nPossible values\n\n\ntrue\n\n\nfalse\n\n\n\n\n\n\nDefault value\n\n\nfalse\n\n\n\n\n\n\nDescription\n\n\nAutomatically starts playing the video after a short delay\n\n\n\n\n\n\n\n\n\n\nquality\n\n\nPossible values\n\n\nlow\n\n\nmedium\n\n\nhigh\n\n\n\n\n\n\nDefault value\n\n\nmedium\n\n\n\n\n\n\nDescription\n\n\nSets a video quality if the video has been encoded in multiple\n  qualities\n\n\n\n\n\n\n\n\n\n\nmode\n\n\nPossible values\n\n\ndesktop\n\n\nembed\n\n\nmobile\n\n\n\n\n\n\nDefault value\n\n\ndesktop\n\n\n\n\n\n\nDescription\n\n\nSets the player mode manually\n\n\n\n\n\n\n\n\n\n\nbrowser\n\n\nPossible values\n\n\nall\n\n\ndefault\n\n\n\n\n\n\nDefault value\n\n\ndefault\n\n\n\n\n\n\nDescription\n\n\nIf your browser is not supported, try the new player with this flag activated\n  overwrites filtering for supported browsers with parameter set to \nall\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nhttp://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&time=3m30s\n\n\n\nDeveloper URL Parameters\n\n\n\n\ndebug\n\n\nPossible values\n\n\ntrue\n\n\nfalse\n\n\n\n\n\n\nDefault value\n\n\nfalse\n\n\n\n\n\n\nDescription\n\n\nprints debug output to the developer console\n\n\n\n\n\n\n\n\n\n\ndebugEvents\n\n\nPossible values\n\n\ntrue\n\n\nfalse\n\n\n\n\n\n\nDefault value\n\n\nfalse\n\n\n\n\n\n\nDescription\n\n\nPrints debug output to the developer console when an event occurs\n\n\n\n\n\n\n\n\n\n\nformat\n\n\nPossible Values\n\n\nhls\n: Apple HTTP Live Streaming\n\n\ndash\n: MPEG DASH\n\n\nrtmp\n: Adobe RTMP (Flash)\n\n\nmp4\n: MP4 videos (no streaming)\n\n\nwebm\n: WebM videos (no streaming)\n\n\naudio\n: audio only (no streaming)\n\n\ndefault\n: reset to defaults\n\n\n\n\n\n\nDefault value\n\n\ndefault\n\n\n\n\n\n\nDescription\n\n\nsets the preferred (streaming) format\n\n\nif not available, the defaults will be selected\n\n\nthe value is permanently stored for the browser in the local storage\n\n\n\n\n\n\n\n\n\n\n\n\nExample\n\n\nhttp://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&debug=true&debugEvents=true",
            "title": "URL Parameters"
        },
        {
            "location": "/modules/player.url.parameter/#theodul-pass-player-url-parameters",
            "text": "",
            "title": "Theodul Pass Player - URL Parameters"
        },
        {
            "location": "/modules/player.url.parameter/#url-parameters",
            "text": "time  Possible values  Minutes (with value  X ) and seconds (with value  Y )  XmYs  YsXm  XmY    Minutes (with value  X ) only  Xm    Seconds (with value  Y ) only  Ys  Y    Default value  -      Description  Seeks intially automatically to a specified time  automatically plays the video from the specified time on      autoplay  Possible values  true  false    Default value  false    Description  Automatically starts playing the video after a short delay      quality  Possible values  low  medium  high    Default value  medium    Description  Sets a video quality if the video has been encoded in multiple\n  qualities      mode  Possible values  desktop  embed  mobile    Default value  desktop    Description  Sets the player mode manually      browser  Possible values  all  default    Default value  default    Description  If your browser is not supported, try the new player with this flag activated\n  overwrites filtering for supported browsers with parameter set to  all",
            "title": "URL Parameters"
        },
        {
            "location": "/modules/player.url.parameter/#example",
            "text": "http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&time=3m30s",
            "title": "Example"
        },
        {
            "location": "/modules/player.url.parameter/#developer-url-parameters",
            "text": "debug  Possible values  true  false    Default value  false    Description  prints debug output to the developer console      debugEvents  Possible values  true  false    Default value  false    Description  Prints debug output to the developer console when an event occurs      format  Possible Values  hls : Apple HTTP Live Streaming  dash : MPEG DASH  rtmp : Adobe RTMP (Flash)  mp4 : MP4 videos (no streaming)  webm : WebM videos (no streaming)  audio : audio only (no streaming)  default : reset to defaults    Default value  default    Description  sets the preferred (streaming) format  if not available, the defaults will be selected  the value is permanently stored for the browser in the local storage",
            "title": "Developer URL Parameters"
        },
        {
            "location": "/modules/player.url.parameter/#example_1",
            "text": "http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&debug=true&debugEvents=true",
            "title": "Example"
        },
        {
            "location": "/modules/searchindex/",
            "text": "Search Index Configuration\n\n\nOpencast has Solr included by default. This guide is only needed, if you want to run Solr on a separate server.\n\n\nThe software versions in these instructions are not the only versions that will work, they are just the version tested\nwhen this document was written.  Newer versions of both Tomcat and Solr are highly recommended.\n\n\nIntroduction\n\n\nOpencast services use filesystem, relational database, and/or search indexes to store and retrieve information. In\norder to cluster services across multiple servers, we must provide shared storage solutions for each of these\ntechnologies. We do this with NFS or ZFS for filesystems, JDBC for relational databases, and solr for search indexes. If\nyou plan on clustering either the workflow service or the search service, you must configure Opencast to use remote\nsolr servers as described below, otherwise no further action is required.\n\n\nObtaining the software\n\n\nSolr runs in any modern servlet environment such as Apache Tomcat 7. Download and unpack Tomcat.\n\n\n$ curl -O http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.5-beta/bin/apache-tomcat-7.0.5.zip\n$ unzip apache-tomcat-7.0.5.zip\n\n\n\nDownload solr from the closest mirror and unpack the zip file. Make sure the permissions are set properly (the zip file\ndoesn't retain proper unix permissions)\n\n\n$ curl -O http://archive.apache.org/dist/lucene/solr/1.4.1/apache-solr-1.4.1.zip\n$ unzip apache-solr-1.4.1.zip\n$ chmod 755 apache-tomcat-7.0.5/bin/*\n\n\n\nDeploy solr to tomcat\n\n\nCopy the solr example war file to tomcat's webapps directory and expand the war file.\n\n\n$ unzip apache-solr-1.4.1/example/webapps/solr.war -d apache-tomcat-7.0.5/webapps/solr/\n\n\n\nConfigure solr\n\n\nAdd the solr config files to the solr webapp in tomcat. If you are setting up the search service, use the solr config\nfrom the search module.\n\n\n$ cd apache-tomcat-7.0.5\n$ cp -R [opencast source]/modules/matterhorn-search-service-impl/src/main/resources/solr solr\n\n\n\nAlternatively, if this is the solr index supporting the workflow service, copy those files instead:\n\n\n$ cd apache-tomcat-7.0.5\n$ cp -R [opencast source]/modules/matterhorn-workflow-service-impl/src/main/resources/solr solr\n\n\n\nEdit the dataDir setting in solr/conf/solrconfig.xml to specify the directory you want to use for the index files.\n\n\nDependency of the workflow index\n\n\nThe index has a dependency on a Opencast class. The easiest way of getting rid of this dependency is providing a .jar\nfile with that class within a directory named lib in the solr folder (you may need to create it if it does not exist).\nThe .jar file can be the compiled matterhorn-solr bundle. Placing the jar in the main Tomcat lib directory does not\nwork.\n\n\nStart the server\n\n\n$ bin/startup.sh\nUsing CATALINA_BASE:   /Users/josh/Desktop/apache-tomcat-7.0.5\nUsing CATALINA_HOME:   /Users/josh/Desktop/apache-tomcat-7.0.5\nUsing CATALINA_TMPDIR: /Users/josh/Desktop/apache-tomcat-7.0.5/temp\nUsing JRE_HOME:        /System/Library/Frameworks/JavaVM.framework/Versions/CurrentJDK/Home\n\n\n\nYou should see that the solr server is running on http://localhost:8080/solr\n\n\n\n\nYou can use the admin screen to monitor the server or make ad-hoc queries:\n\n\n\n\n\n\nSecure the solr server\n\n\nJust like with a relational database server, it is critical that you limit access to the solr server. Opencast's\ncommunication with solr servers is unauthenticated, so you must secure a firewall on the solr servers that accepts HTTP\nrequests only from Opencast servers. If these servers were publicly accessible, anyone could make changes to\nOpencast data from outside Opencast itself.\n\n\nConfigure Opencast\n\n\nSet the URL to this solr server in Opencast's custom.properties file:\n\n\norg.opencastproject.search.solr.url=http://your.solr.server.edu:8080/solr/\n\n\n\nIf this solr server is supporting clustered workflow services:\n\n\norg.opencastproject.workflow.solr.url==http://your.solr.server.edu:8080/solr/\n\n\n\nIt is important to understand that a solr server provides exactly one schema, and one schema only. If you want to\ncluster both the workflow service and the search service, you will need two separate solr servers. These solr servers\ncan run on the same machine, but each will needs its own servlet container and port.",
            "title": "Search Index"
        },
        {
            "location": "/modules/searchindex/#search-index-configuration",
            "text": "Opencast has Solr included by default. This guide is only needed, if you want to run Solr on a separate server.  The software versions in these instructions are not the only versions that will work, they are just the version tested\nwhen this document was written.  Newer versions of both Tomcat and Solr are highly recommended.",
            "title": "Search Index Configuration"
        },
        {
            "location": "/modules/searchindex/#introduction",
            "text": "Opencast services use filesystem, relational database, and/or search indexes to store and retrieve information. In\norder to cluster services across multiple servers, we must provide shared storage solutions for each of these\ntechnologies. We do this with NFS or ZFS for filesystems, JDBC for relational databases, and solr for search indexes. If\nyou plan on clustering either the workflow service or the search service, you must configure Opencast to use remote\nsolr servers as described below, otherwise no further action is required.",
            "title": "Introduction"
        },
        {
            "location": "/modules/searchindex/#obtaining-the-software",
            "text": "Solr runs in any modern servlet environment such as Apache Tomcat 7. Download and unpack Tomcat.  $ curl -O http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.5-beta/bin/apache-tomcat-7.0.5.zip\n$ unzip apache-tomcat-7.0.5.zip  Download solr from the closest mirror and unpack the zip file. Make sure the permissions are set properly (the zip file\ndoesn't retain proper unix permissions)  $ curl -O http://archive.apache.org/dist/lucene/solr/1.4.1/apache-solr-1.4.1.zip\n$ unzip apache-solr-1.4.1.zip\n$ chmod 755 apache-tomcat-7.0.5/bin/*",
            "title": "Obtaining the software"
        },
        {
            "location": "/modules/searchindex/#deploy-solr-to-tomcat",
            "text": "Copy the solr example war file to tomcat's webapps directory and expand the war file.  $ unzip apache-solr-1.4.1/example/webapps/solr.war -d apache-tomcat-7.0.5/webapps/solr/",
            "title": "Deploy solr to tomcat"
        },
        {
            "location": "/modules/searchindex/#configure-solr",
            "text": "Add the solr config files to the solr webapp in tomcat. If you are setting up the search service, use the solr config\nfrom the search module.  $ cd apache-tomcat-7.0.5\n$ cp -R [opencast source]/modules/matterhorn-search-service-impl/src/main/resources/solr solr  Alternatively, if this is the solr index supporting the workflow service, copy those files instead:  $ cd apache-tomcat-7.0.5\n$ cp -R [opencast source]/modules/matterhorn-workflow-service-impl/src/main/resources/solr solr  Edit the dataDir setting in solr/conf/solrconfig.xml to specify the directory you want to use for the index files.",
            "title": "Configure solr"
        },
        {
            "location": "/modules/searchindex/#dependency-of-the-workflow-index",
            "text": "The index has a dependency on a Opencast class. The easiest way of getting rid of this dependency is providing a .jar\nfile with that class within a directory named lib in the solr folder (you may need to create it if it does not exist).\nThe .jar file can be the compiled matterhorn-solr bundle. Placing the jar in the main Tomcat lib directory does not\nwork.",
            "title": "Dependency of the workflow index"
        },
        {
            "location": "/modules/searchindex/#start-the-server",
            "text": "$ bin/startup.sh\nUsing CATALINA_BASE:   /Users/josh/Desktop/apache-tomcat-7.0.5\nUsing CATALINA_HOME:   /Users/josh/Desktop/apache-tomcat-7.0.5\nUsing CATALINA_TMPDIR: /Users/josh/Desktop/apache-tomcat-7.0.5/temp\nUsing JRE_HOME:        /System/Library/Frameworks/JavaVM.framework/Versions/CurrentJDK/Home  You should see that the solr server is running on http://localhost:8080/solr   You can use the admin screen to monitor the server or make ad-hoc queries:",
            "title": "Start the server"
        },
        {
            "location": "/modules/searchindex/#secure-the-solr-server",
            "text": "Just like with a relational database server, it is critical that you limit access to the solr server. Opencast's\ncommunication with solr servers is unauthenticated, so you must secure a firewall on the solr servers that accepts HTTP\nrequests only from Opencast servers. If these servers were publicly accessible, anyone could make changes to\nOpencast data from outside Opencast itself.",
            "title": "Secure the solr server"
        },
        {
            "location": "/modules/searchindex/#configure-opencast",
            "text": "Set the URL to this solr server in Opencast's custom.properties file:  org.opencastproject.search.solr.url=http://your.solr.server.edu:8080/solr/  If this solr server is supporting clustered workflow services:  org.opencastproject.workflow.solr.url==http://your.solr.server.edu:8080/solr/  It is important to understand that a solr server provides exactly one schema, and one schema only. If you want to\ncluster both the workflow service and the search service, you will need two separate solr servers. These solr servers\ncan run on the same machine, but each will needs its own servlet container and port.",
            "title": "Configure Opencast"
        },
        {
            "location": "/modules/textextraction/",
            "text": "Text Extraction Configuration\n\n\nHow the text extraction process works\n\n\nThe sequence of the Opencast services used during slide detection and text extraction is the following:\n\n\n-----> Segmentation -----> TextAnalyzerService ----------------->\n                              /             \\\n                             /               \\\n                   TextExtractor          DictionaryService\n                (OCR with Tesseract)   (Filter extracted texts)\n\n\n\nThe segmentation will define the frames which are passed to the text analyzer. For extraction a frame from the end of a\nsegment is used to make sure that most of a slides text is visible.\n\n\nThe frame is then exported as TIFF image and passed to the text extraction service which calles an OCR engine to get the\ntext output. For this, the Tesseract OCR engine is used by default.\n\n\nAfter the text extraction is done, the analysis service will pass the recognized text to the dictionary service which\nmay filter it to remove messed up words, unknown words, single characters or other things depending on the actual\nimplementation and configuration.\n\n\nFinally, the the extracted text is attached to the Mediapackage as MPEG 7 XML and the Opencast workflow continues.\n\n\nConfiguration\n\n\nThis section describes the configuration of all involved tools and services. As this guide the configuration is for the\nGerman language but the configuration for other languages should be equivalent and if not obvious, the differences will\nbe pointed out.\n\n\nOCR Engine: Tesseract\n\n\nTesseract is the default OCR engine used by Opencast. It will accept an image file and write the extracted text to an\noutput file. The command line arguments for this will be handles by Opencast. But apart from this, it is possible to\npass additional arguments to tesseract defining the internally used dictionary, box files and the layout analysis.\n\n\nFor example, for OCR on slides with German language, you want to run something like this:\n\n\ntesseract in.tif out.txt -l deu -psm 3\n\n\n\n\n\nThe arguments \nin.tif\n and \nout.txt\n are automatically set by Opencast.\n\n\nThe argument \n-l deu\n will specify the language files used by tesseract.  This time \ndeu\n is used for German\n   language. Multiple languages may be specified, separated by plus characters. Please make sure that you have\n   installed the language pack you want to use. Using yum, this can be done by running something like \nyum install\n   tesseract-langpack-deu\n.\n\n\nFinally \n-psm 3\n will specify the layout analysis tesseract will do. The value \n3\n means \nFully automatic page\n   segmentation, but no orientation and script detection\n which is actually the default. Hence in this case, the\n   argument could simply be omitted. If you know more about this input videos, you might want to use different options\n   here (not likely).\n\n\n\n\nIn Opencast you can modify this options in the custom.properties file setting the following option:\n\n\norg.opencastproject.textanalyzer.tesseract.options=-l deu -psm 3\n\n\n\nIt is highly recommended to configure Tesseract to use your local language. It will improve the recognition a lot and\nonly this will enable the recognition of special characters specific to your local language.\n\n\nEncoding (Image Preprocessing)\n\n\nThe text extraction works best if there is a high contrast between text and background and additionally, the text is not\ntoo thin. Ideally, this means that you have black and white images.\n\n\nAt this point it is probably worth noting that despite what is often said and could also be found in the documentation\nfor Opencast, it does not matter for Tesseract if it is black text on a white background or if the colors are inverted\n(white on black). Because of the way Tesseract works, that does not matter.\n\n\nA lot of lecture slides are unfortunately not designed this way. Lecturers use colors, background images, etc. That is\nwhy, to get a better result, it is a good idea to do some image preprocessing steps. Some easy ones can be included\ndirectly into the image extraction step using FFmpeg.\n\n\nFor this, edit the \n/etc/opencast/encoding/opencast-images.properties\n and modify the command for the image\nextraction:\n\n\nprofile.text-analysis.http.ffmpeg.command = -ss #{time} -i #{in.video.path}\n    -filter:v boxblur=1:1,curves=all=0.4/0#{space}0.6/1\n   -frames:v 1 -pix_fmt:v gray -r 1 #{out.dir}/#{out.name}#{out.suffix}\n\n\n\nThis profile would, for example, create a gray, high contrast image. The additional light blur will reduce or remove\nnoise and thicken the normal letters.\n\n\nThe kind of preprocessing you should use highly depends on the input material. Interesting filters to try out for your\nmaterial are among others the blur filters, the denoise filters, the curves filter and in some cases the color-channel\nmixer.\n\n\nDictionaryService (Filtering)\n\n\nThe filtering you want to do on the recognized texts highly depends on what you want to use the recognized texts for.\nFor searching, you might want a higher degree of filtering, for users you might also want to present text with slight\nerrors, for testing and debugging, you want no filtering at all.\n\n\nStarting with version 1.6, Opencast provides three different kinds of implementation for filtering which can be just\nswapped out at any time:\n\n\n\n\nmatterhorn-dictionary-none\n\n\nmatterhorn-dictionary-regexp (default)\n\n\nmatterhorn-dictionary-hunspell\n\n\n\n\nNo Filtering (matterhorn-dictionary-none)\n\n\nThe \nmatterhorn-dictionary-none\n module is the simplest one. It will just let the recognized texts pass through\nunmodified. There is no additional configuration needed or even possible. Of course, this is also the fastest one.\n\n\nUsing a Regular Expression (matterhorn-dictionary-regexp)\n\n\nStarting with 1.6, this is the default implementation for the DictionaryService. It is quite fast and easy to configure,\nbut is limited in terms of filtering capabilities as it will in most cases not check it a word makes sense or even if it\nmakes sense in this context.\n\n\nThe default expression for this module is \n\\w+\n which will let upper- and lowercase characters as well as digits pass\nthrough, but will block all other characters. For the German language for example, this would mean that all special\ncharacters would be blocked as well. So you want to configure Opencast to let them pass as well.\n\n\nYou can do that by modifying the \npattern\n in\n\netc/org.opencastproject.dictionary.regexp.DictionaryServiceImpl.cfg\n:\n\n\nFor German, a suitable pattern could be:\n\n\npattern=[\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df][\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df]+[-.,:;!?]*\n\n\n\nThis will for example let all words pass which contain upper- and lowercase [a-z], digits and German special characters\nas well as punctuation at the end of a words. Additionally, it is required that the words are at least two characters\nlong which will filter out most of the common noise.\n\n\nA similar pattern that could be used for Spanish would be:\n\n\npattern=[\u00bf\u00a1(]*[\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1][\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1]+[)-.,:;!?]*\n\n\n\nUsing a Spell Checker (matterhorn-dictionary-hunspell)\n\n\nLast, the \nmatterhorn-dictionary-hunspell\n will check words based on a spell checker and a dictionary. As spell checker,\nthe tool \nhunspell\n is used which is one of the most common spell checkers on Linux and should be available from the\nsystem repositories for most common operating systems.\n\n\nFor the Hunspell based DictionaryService, there are two configuration options.  One is for the binary and one for the\narguments to use for filtering.\n\n\nBy default Opencast will just call \nhunspell\n without an absolute path. This will work as long as hunspell is in the\nsystems path which should be the case unless you have built and installed it manually. In that case, the binary can be\nconfigured using the following option in the \ncustom.properties\n file:\n\n\norg.opencastproject.dictionary.hunspell.binary=/usr/bin/hunspell\n\n\n\nWhile most people wont need the binary path configuration, most people will need the filtering option which can be used\nfor setting the languages.  Configuration for this can be done using the following key in the \ncustom.properties\n file:\n\n\norg.opencastproject.dictionary.hunspell.command=-d de_DE,en_GB,en_US -G\n\n\n\nNote that equivalent to the tesseract configuration, again the necessary languages have to be installed in the system.\nFor German, you would on RedHat based systems for example install the \nhunspell-de\n package from the system\nrepositories.\n\n\nFor Hunspell, you can also create custom dictionaries or add custom words to the existing ones. This might be\ninteresting for technical terms.\n\n\nGetting Opencast with Specific Implementations\n\n\nBuilding Opencast from Source\n\n\nStarting with 1.6, a default build of Opencast will build Opencast with text extraction and the RegExp based\nDictionaryService implementation. But replacing this with another implementation is not difficult. There is an\nalternatives profile in that main pom.xml which can be used, but it is probably easier, to build the desired module\ndirectly.\n\n\nAs an example, lets say that you want to replace the default RegExp based DictionaryService with the Hunspell based one.\nFirst of all, you would simply build Opencast the same way you always do running:\n\n\nmvn clean install -Ddeplayto=/some/path/\n\n\n\nThis means that you would end up with all Opencast modules in the directory:\n\n\n/some/path/lib/opencast/\n\n\n\nThis includes the \nmatterhorn-dictionary-regexp-X.Y.Z.jar\n which we want to replace. Thus you can simply delete the file\nrunning:\n\n\nrm /some/path/lib/opencast/matterhorn-dictionary-regexp-*.jar\n\n\n\nNow switch to the \nmodules/matterhorn-dictionary-hunspell\n subdirectory of your Opencast source code and run:\n\n\nmvn clean install -Ddeplayto=/some/path/\n\n\n\nThis will build the curremt module only and will put the resulting JAR file in the target directory where all your other\nJARs already are.\n\n\nApart from the configuration descriped above, you are now ready to go.\n\n\nInstalling Specific Implementations from the RPM Repository\n\n\nIf you do not have an advanced knowledge of the structure of Opencast and the way RPM packages work, what you want to\ndo is basically the same thing you would so when building Opencast from source: First install a default installation,\nthen replace the module we want to replace.\n\n\nThus we start by installing Opencast the way we always do by running:\n\n\nyum install opencast...\n\n\n\nThis will install Opencast with all its dependencies, including all necessary modules (especially the RegExp based\nDictionaryService). As we don't want this particular module, we will just remove it again by running:\n\n\nyum remove opencast...-module-dictionary-regexp\n\n\n\nYou will notice that yum wants to remove a profile and distribution package as well. Do not worry about that, that is\nthe way it should work. The profile and distribution packages do nothing except for making sure that a given set of\nmodule-packages are installed. As you removed one, this set is not given anymore and yum will remove these metapackages\nas well.\n\n\nSo we now have a system with one missing module: The DictionaryService implementation. For this we now choose another\none and install it using:\n\n\nyum install opencast...-module-dictionary-hunspell\n\n\n\nThat is it.",
            "title": "Text Extraction"
        },
        {
            "location": "/modules/textextraction/#text-extraction-configuration",
            "text": "",
            "title": "Text Extraction Configuration"
        },
        {
            "location": "/modules/textextraction/#how-the-text-extraction-process-works",
            "text": "The sequence of the Opencast services used during slide detection and text extraction is the following:  -----> Segmentation -----> TextAnalyzerService ----------------->\n                              /             \\\n                             /               \\\n                   TextExtractor          DictionaryService\n                (OCR with Tesseract)   (Filter extracted texts)  The segmentation will define the frames which are passed to the text analyzer. For extraction a frame from the end of a\nsegment is used to make sure that most of a slides text is visible.  The frame is then exported as TIFF image and passed to the text extraction service which calles an OCR engine to get the\ntext output. For this, the Tesseract OCR engine is used by default.  After the text extraction is done, the analysis service will pass the recognized text to the dictionary service which\nmay filter it to remove messed up words, unknown words, single characters or other things depending on the actual\nimplementation and configuration.  Finally, the the extracted text is attached to the Mediapackage as MPEG 7 XML and the Opencast workflow continues.",
            "title": "How the text extraction process works"
        },
        {
            "location": "/modules/textextraction/#configuration",
            "text": "This section describes the configuration of all involved tools and services. As this guide the configuration is for the\nGerman language but the configuration for other languages should be equivalent and if not obvious, the differences will\nbe pointed out.",
            "title": "Configuration"
        },
        {
            "location": "/modules/textextraction/#ocr-engine-tesseract",
            "text": "Tesseract is the default OCR engine used by Opencast. It will accept an image file and write the extracted text to an\noutput file. The command line arguments for this will be handles by Opencast. But apart from this, it is possible to\npass additional arguments to tesseract defining the internally used dictionary, box files and the layout analysis.  For example, for OCR on slides with German language, you want to run something like this:  tesseract in.tif out.txt -l deu -psm 3   The arguments  in.tif  and  out.txt  are automatically set by Opencast.  The argument  -l deu  will specify the language files used by tesseract.  This time  deu  is used for German\n   language. Multiple languages may be specified, separated by plus characters. Please make sure that you have\n   installed the language pack you want to use. Using yum, this can be done by running something like  yum install\n   tesseract-langpack-deu .  Finally  -psm 3  will specify the layout analysis tesseract will do. The value  3  means  Fully automatic page\n   segmentation, but no orientation and script detection  which is actually the default. Hence in this case, the\n   argument could simply be omitted. If you know more about this input videos, you might want to use different options\n   here (not likely).   In Opencast you can modify this options in the custom.properties file setting the following option:  org.opencastproject.textanalyzer.tesseract.options=-l deu -psm 3  It is highly recommended to configure Tesseract to use your local language. It will improve the recognition a lot and\nonly this will enable the recognition of special characters specific to your local language.",
            "title": "OCR Engine: Tesseract"
        },
        {
            "location": "/modules/textextraction/#encoding-image-preprocessing",
            "text": "The text extraction works best if there is a high contrast between text and background and additionally, the text is not\ntoo thin. Ideally, this means that you have black and white images.  At this point it is probably worth noting that despite what is often said and could also be found in the documentation\nfor Opencast, it does not matter for Tesseract if it is black text on a white background or if the colors are inverted\n(white on black). Because of the way Tesseract works, that does not matter.  A lot of lecture slides are unfortunately not designed this way. Lecturers use colors, background images, etc. That is\nwhy, to get a better result, it is a good idea to do some image preprocessing steps. Some easy ones can be included\ndirectly into the image extraction step using FFmpeg.  For this, edit the  /etc/opencast/encoding/opencast-images.properties  and modify the command for the image\nextraction:  profile.text-analysis.http.ffmpeg.command = -ss #{time} -i #{in.video.path}\n    -filter:v boxblur=1:1,curves=all=0.4/0#{space}0.6/1\n   -frames:v 1 -pix_fmt:v gray -r 1 #{out.dir}/#{out.name}#{out.suffix}  This profile would, for example, create a gray, high contrast image. The additional light blur will reduce or remove\nnoise and thicken the normal letters.  The kind of preprocessing you should use highly depends on the input material. Interesting filters to try out for your\nmaterial are among others the blur filters, the denoise filters, the curves filter and in some cases the color-channel\nmixer.",
            "title": "Encoding (Image Preprocessing)"
        },
        {
            "location": "/modules/textextraction/#dictionaryservice-filtering",
            "text": "The filtering you want to do on the recognized texts highly depends on what you want to use the recognized texts for.\nFor searching, you might want a higher degree of filtering, for users you might also want to present text with slight\nerrors, for testing and debugging, you want no filtering at all.  Starting with version 1.6, Opencast provides three different kinds of implementation for filtering which can be just\nswapped out at any time:   matterhorn-dictionary-none  matterhorn-dictionary-regexp (default)  matterhorn-dictionary-hunspell",
            "title": "DictionaryService (Filtering)"
        },
        {
            "location": "/modules/textextraction/#no-filtering-matterhorn-dictionary-none",
            "text": "The  matterhorn-dictionary-none  module is the simplest one. It will just let the recognized texts pass through\nunmodified. There is no additional configuration needed or even possible. Of course, this is also the fastest one.",
            "title": "No Filtering (matterhorn-dictionary-none)"
        },
        {
            "location": "/modules/textextraction/#using-a-regular-expression-matterhorn-dictionary-regexp",
            "text": "Starting with 1.6, this is the default implementation for the DictionaryService. It is quite fast and easy to configure,\nbut is limited in terms of filtering capabilities as it will in most cases not check it a word makes sense or even if it\nmakes sense in this context.  The default expression for this module is  \\w+  which will let upper- and lowercase characters as well as digits pass\nthrough, but will block all other characters. For the German language for example, this would mean that all special\ncharacters would be blocked as well. So you want to configure Opencast to let them pass as well.  You can do that by modifying the  pattern  in etc/org.opencastproject.dictionary.regexp.DictionaryServiceImpl.cfg :  For German, a suitable pattern could be:  pattern=[\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df][\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df]+[-.,:;!?]*  This will for example let all words pass which contain upper- and lowercase [a-z], digits and German special characters\nas well as punctuation at the end of a words. Additionally, it is required that the words are at least two characters\nlong which will filter out most of the common noise.  A similar pattern that could be used for Spanish would be:  pattern=[\u00bf\u00a1(]*[\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1][\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1]+[)-.,:;!?]*",
            "title": "Using a Regular Expression (matterhorn-dictionary-regexp)"
        },
        {
            "location": "/modules/textextraction/#using-a-spell-checker-matterhorn-dictionary-hunspell",
            "text": "Last, the  matterhorn-dictionary-hunspell  will check words based on a spell checker and a dictionary. As spell checker,\nthe tool  hunspell  is used which is one of the most common spell checkers on Linux and should be available from the\nsystem repositories for most common operating systems.  For the Hunspell based DictionaryService, there are two configuration options.  One is for the binary and one for the\narguments to use for filtering.  By default Opencast will just call  hunspell  without an absolute path. This will work as long as hunspell is in the\nsystems path which should be the case unless you have built and installed it manually. In that case, the binary can be\nconfigured using the following option in the  custom.properties  file:  org.opencastproject.dictionary.hunspell.binary=/usr/bin/hunspell  While most people wont need the binary path configuration, most people will need the filtering option which can be used\nfor setting the languages.  Configuration for this can be done using the following key in the  custom.properties  file:  org.opencastproject.dictionary.hunspell.command=-d de_DE,en_GB,en_US -G  Note that equivalent to the tesseract configuration, again the necessary languages have to be installed in the system.\nFor German, you would on RedHat based systems for example install the  hunspell-de  package from the system\nrepositories.  For Hunspell, you can also create custom dictionaries or add custom words to the existing ones. This might be\ninteresting for technical terms.",
            "title": "Using a Spell Checker (matterhorn-dictionary-hunspell)"
        },
        {
            "location": "/modules/textextraction/#getting-opencast-with-specific-implementations",
            "text": "",
            "title": "Getting Opencast with Specific Implementations"
        },
        {
            "location": "/modules/textextraction/#building-opencast-from-source",
            "text": "Starting with 1.6, a default build of Opencast will build Opencast with text extraction and the RegExp based\nDictionaryService implementation. But replacing this with another implementation is not difficult. There is an\nalternatives profile in that main pom.xml which can be used, but it is probably easier, to build the desired module\ndirectly.  As an example, lets say that you want to replace the default RegExp based DictionaryService with the Hunspell based one.\nFirst of all, you would simply build Opencast the same way you always do running:  mvn clean install -Ddeplayto=/some/path/  This means that you would end up with all Opencast modules in the directory:  /some/path/lib/opencast/  This includes the  matterhorn-dictionary-regexp-X.Y.Z.jar  which we want to replace. Thus you can simply delete the file\nrunning:  rm /some/path/lib/opencast/matterhorn-dictionary-regexp-*.jar  Now switch to the  modules/matterhorn-dictionary-hunspell  subdirectory of your Opencast source code and run:  mvn clean install -Ddeplayto=/some/path/  This will build the curremt module only and will put the resulting JAR file in the target directory where all your other\nJARs already are.  Apart from the configuration descriped above, you are now ready to go.",
            "title": "Building Opencast from Source"
        },
        {
            "location": "/modules/textextraction/#installing-specific-implementations-from-the-rpm-repository",
            "text": "If you do not have an advanced knowledge of the structure of Opencast and the way RPM packages work, what you want to\ndo is basically the same thing you would so when building Opencast from source: First install a default installation,\nthen replace the module we want to replace.  Thus we start by installing Opencast the way we always do by running:  yum install opencast...  This will install Opencast with all its dependencies, including all necessary modules (especially the RegExp based\nDictionaryService). As we don't want this particular module, we will just remove it again by running:  yum remove opencast...-module-dictionary-regexp  You will notice that yum wants to remove a profile and distribution package as well. Do not worry about that, that is\nthe way it should work. The profile and distribution packages do nothing except for making sure that a given set of\nmodule-packages are installed. As you removed one, this set is not given anymore and yum will remove these metapackages\nas well.  So we now have a system with one missing module: The DictionaryService implementation. For this we now choose another\none and install it using:  yum install opencast...-module-dictionary-hunspell  That is it.",
            "title": "Installing Specific Implementations from the RPM Repository"
        },
        {
            "location": "/modules/videoeditor.manual/",
            "text": "Video editor: Manual\n\n\nBrowser compatibility: This editor was designed and tested for Firefox and Google Chrome. It should work with Safari\nin principle but is not extensively tested.\n\n\nOverview\n\n\n\n\nPlayer Buttons\n\n\n\n\n\n\nPlay/Pause\n\n\nPlays or pauses the video\n\n\n\n\n\n\nPrevious Marker\n\n\nJumps to the previous chapter beginning\n\n\n\n\n\n\nPrevious Frame\n\n\nSeeks one frame backwards\n\n\n\n\n\n\nSplit at current time\n\n\nInserts a new marker at the current position in the video\n\n\n\n\n\n\nPlay at current playhead with pre roll and post roll excluding removed items\n\n\nPlays the currently selected segment with a certain amount of time before and after it, deleted segments being excluded\n\n\n\n\n\n\nNext Frame\n\n\nSeeks one frame forward\n\n\n\n\n\n\nNext Marker\n\n\nJumps to the next chapter beginning\n\n\n\n\n\n\n\n\nSegment Overview\n\n\nThere are two colors to display the different states of the segment:\n\n\n\n\nRed\n\n\nThe segment is marked as \"remove\"\n\n\nThe segment will be cut out in the following processing\n\n\n\n\n\n\nGreen\n\n\nThe segment is marked as \"keep\"\n\n\nThe segment will be kept in the following processing\n\n\nThe segment is currently selected\n\n\n\n\n\n\nWhite\n\n\nThe segment is as \"keep\"\n\n\nThe segment will be kept in the following processing\n\n\nThe segment is currently not selected\n\n\n\n\n\n\n\n\nOn the one hand the segments are being displayed directly beneath the player above the waveform display:\n\n\n\n\nOn the other hand there is a segment list:\n\n\n\n\n\n\nClear segment list\n\n\nClears the segment list, removes all segments\n\n\n\n\n\n\nRe-add the item\n\n\nRe-adds the removed item (marks it as \"keep\") to not remove the item on processing\n\n\n\n\n\n\nRemove this item\n\n\nRemoves the item (marks it as \"remove\") to remove the item on processing\n\n\n\n\n\n\nSet start time of the segment\n\n\nSets a new start time of the segment\n\n\n\n\n\n\nSet end time of the segment\n\n\nSets a new end time of the segment\n\n\n\n\n\n\n\n\nZooming The Waveform\n\n\nFor more easy and precise cutting the waveform can be zoomed in via the zoom scrubber:\n\n\n\n\nWhen zoomed in you can click directly into the waveform to seek exactly to the time you clicked:\n\n\n\n\n\n\nZoom in the waveform:\n    \n\n\n\n\n\n\nClick at a point you want to seek to:\n    \n\n\n\n\n\n\nThe player seeks exactly to the time you wanted to seek to:\n    \n\n\n\n\n\n\nShortcuts\n\n\nMany shortcuts are mapped for nearly every operation:",
            "title": "Overview"
        },
        {
            "location": "/modules/videoeditor.manual/#video-editor-manual",
            "text": "Browser compatibility: This editor was designed and tested for Firefox and Google Chrome. It should work with Safari\nin principle but is not extensively tested.",
            "title": "Video editor: Manual"
        },
        {
            "location": "/modules/videoeditor.manual/#overview",
            "text": "",
            "title": "Overview"
        },
        {
            "location": "/modules/videoeditor.manual/#player-buttons",
            "text": "Play/Pause  Plays or pauses the video    Previous Marker  Jumps to the previous chapter beginning    Previous Frame  Seeks one frame backwards    Split at current time  Inserts a new marker at the current position in the video    Play at current playhead with pre roll and post roll excluding removed items  Plays the currently selected segment with a certain amount of time before and after it, deleted segments being excluded    Next Frame  Seeks one frame forward    Next Marker  Jumps to the next chapter beginning",
            "title": "Player Buttons"
        },
        {
            "location": "/modules/videoeditor.manual/#segment-overview",
            "text": "There are two colors to display the different states of the segment:   Red  The segment is marked as \"remove\"  The segment will be cut out in the following processing    Green  The segment is marked as \"keep\"  The segment will be kept in the following processing  The segment is currently selected    White  The segment is as \"keep\"  The segment will be kept in the following processing  The segment is currently not selected     On the one hand the segments are being displayed directly beneath the player above the waveform display:   On the other hand there is a segment list:    Clear segment list  Clears the segment list, removes all segments    Re-add the item  Re-adds the removed item (marks it as \"keep\") to not remove the item on processing    Remove this item  Removes the item (marks it as \"remove\") to remove the item on processing    Set start time of the segment  Sets a new start time of the segment    Set end time of the segment  Sets a new end time of the segment",
            "title": "Segment Overview"
        },
        {
            "location": "/modules/videoeditor.manual/#zooming-the-waveform",
            "text": "For more easy and precise cutting the waveform can be zoomed in via the zoom scrubber:   When zoomed in you can click directly into the waveform to seek exactly to the time you clicked:    Zoom in the waveform:\n        Click at a point you want to seek to:\n        The player seeks exactly to the time you wanted to seek to:",
            "title": "Zooming The Waveform"
        },
        {
            "location": "/modules/videoeditor.manual/#shortcuts",
            "text": "Many shortcuts are mapped for nearly every operation:",
            "title": "Shortcuts"
        },
        {
            "location": "/modules/videoeditor.setup/",
            "text": "Video Editor: Setup\n\n\nUser Interface Configuration\n\n\nCurrently there are two config file parameters for UI options.\n\n\nThe config file can be found at \netc/org.opencastproject.organization-mh_default_org.cfg\n.\n\n\n\n\nprop.adminui.prePostRoll\n\n\nChange the duration of the pre and post roll (in seconds)\n\n\n\n\n\n\nprop.adminui.minSegmentLength\n\n\nChange the minimum required segment length (in seconds)\n\n\n\n\n\n\n\n\nSilence Detection Configuration\n\n\nThe settings regarding the sensitivity of the silence detection can be changed in\n\netc/org.opencastproject.silencedetection.impl.SilenceDetectionServiceImpl.cfg\n.\n\n\n\n\nsilence.pre.length\n\n\nDuration of silence that should be included at the beginning of  a new voice segment. This is to avoid that a cut\n  seems to sudden.\n\n\nDefault: 2000 (2s)\n\n\n\n\n\n\nsilence.threshold.db\n\n\nSilence threshold (e.g. -50dB for loud classrooms, -35dB for silent indoor location).\n\n\nDefault: -40dB\n\n\n\n\n\n\nsilence.min.length\n\n\nMinimum duration in milliseconds to detect a sequence as silence.\n\n\nDefault: 10000 (10s)\n\n\n\n\n\n\nvoice.min.length\n\n\nMinimum segment duration in milliseconds to start a new voice containing sequence after a silent sequence.\n\n\nDefault: 60000 (1min)\n\n\n\n\n\n\n\n\nVideo Editor Configuration\n\n\nThe FFmpeg properties for the Video Editor can be modified in\n\netc/org.opencastproject.videoeditor.impl.VideoEditorServiceImpl.cfg\n. Usually there should be no reason to touch this\nfile.",
            "title": "Setup"
        },
        {
            "location": "/modules/videoeditor.setup/#video-editor-setup",
            "text": "",
            "title": "Video Editor: Setup"
        },
        {
            "location": "/modules/videoeditor.setup/#user-interface-configuration",
            "text": "Currently there are two config file parameters for UI options.  The config file can be found at  etc/org.opencastproject.organization-mh_default_org.cfg .   prop.adminui.prePostRoll  Change the duration of the pre and post roll (in seconds)    prop.adminui.minSegmentLength  Change the minimum required segment length (in seconds)",
            "title": "User Interface Configuration"
        },
        {
            "location": "/modules/videoeditor.setup/#silence-detection-configuration",
            "text": "The settings regarding the sensitivity of the silence detection can be changed in etc/org.opencastproject.silencedetection.impl.SilenceDetectionServiceImpl.cfg .   silence.pre.length  Duration of silence that should be included at the beginning of  a new voice segment. This is to avoid that a cut\n  seems to sudden.  Default: 2000 (2s)    silence.threshold.db  Silence threshold (e.g. -50dB for loud classrooms, -35dB for silent indoor location).  Default: -40dB    silence.min.length  Minimum duration in milliseconds to detect a sequence as silence.  Default: 10000 (10s)    voice.min.length  Minimum segment duration in milliseconds to start a new voice containing sequence after a silent sequence.  Default: 60000 (1min)",
            "title": "Silence Detection Configuration"
        },
        {
            "location": "/modules/videoeditor.setup/#video-editor-configuration",
            "text": "The FFmpeg properties for the Video Editor can be modified in etc/org.opencastproject.videoeditor.impl.VideoEditorServiceImpl.cfg . Usually there should be no reason to touch this\nfile.",
            "title": "Video Editor Configuration"
        },
        {
            "location": "/modules/videoeditor.architecture/",
            "text": "Video Editor: Architecture\n\n\nModules Of The Videoeditor\n\n\nThe Videoeditor consists of the following moduls. Additional to this there is a Workflow Operation Handler within the\nConductor module that provides the UI elements for the Video Editor.\n\n\n\n\nmatterhorn-silencedetection-api\n\n\nAPI for the silence detection\n\n\n\n\n\n\nmatterhorn-silencedetection-impl\n\n\nImplementation of the silence detection service\n\n\nProvides a SMIL file that can be used by the Video Editor UI or the Video Editor service to create a new cutted\n  file.\n\n\n\n\n\n\nmatterhorn-silencedetection-remote\n\n\nRemote implementation of the silence detection service to enable load balancing in a distributed setup.\n\n\n\n\n\n\nmatterhorn-smil-api\n\n\nAPI for the SMIL service\n\n\n\n\n\n\nmatterhorn-smil-impl\n\n\nThe SMIL service allows creation and manipulation of SMIL files. This is more or less a helper class to create\n  consistent SMIL files.\n\n\n\n\n\n\nmatterhorn-videoeditor-api\n\n\nThe API for the Video Editor which takes a SMIL file as an input to create a cutted version of the media files.\n\n\n\n\n\n\nmatterhorn-videoeditor-impl\n\n\nThe Video Editor service creates new media files that will be cutted based on the information provided in a SMIL\n  file. In the current implementation GStreamer with the gnonlin module is used to process the files.\n\n\n\n\n\n\nmatterhorn-videoeditor-remote\n\n\nRemote implementation of the video editor service to enable load balancing in a distributed setup.\n\n\n\n\n\n\n\n\nSeveral other changes have been made on other Opencast modules to provide a better user experience for the video\neditor (i.e. byte-range request on the working-file-repository).\n\n\nEdit List Format\n\n\nThe video editor uses SMIL 3.0 as a standardized Data format for the edit lists (cutting information). Some conventions\nand namespace extensions have been made to make sure that Opencast is able to find the files.\n\n\n\n\nAs we usually have two (or more) parallel media files, these files are grouped in a \n<par>\n-element which forms a\n   segment that should be included in the resulting video.  This means the included \n<video>\n-files will be played in\n   parallel.\n\n\nThe clipBegin and clipEnd attributes a provided as milliseconds. Usually these should be identical for all \n<videos>\n\n   within a \n<par>\n.  For each segment a \n<par>\n is created.\n\n\nIn the result of the silence detection segments with silence are omitted within the SMIL files, so only segments\n   within the SMIL doc will be in the resulting video.\n\n\nThe segments within the SMIL file will be in the order they are written down. If the sequence of the segments is\n   changed, the sequence within the resulting video is changed too.\n\n\n\n\nExample SMIL file\n\n\n<smil xmlns=\"http://www.w3.org/ns/SMIL\" baseProfile=\"Language\" version=\"3.0\" xml:id=\"s-524c7815-4520-48e4-bb5e-94dcfdb3229f\">\n    <head xml:id=\"h-03b31c8d-68cf-49ea-8bae-d94abddf8f09\">\n        <meta name=\"track-duration\" content=\"6000841ms\" xml:id=\"meta-32069ddb-351d-4dca-a742-b9be490080f8\"/>\n        <paramGroup xml:id=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\">\n            <param value=\"9f373445-5f46-4bdd-8d93-dca5e1094c38\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-d509b427-b239-4c4b-985a-f8b4ea31bbfb\"/>\n            <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-411e0015-af0e-463c-898d-9a2bc594df46\"/>\n            <param value=\"presenter/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-5ea022cd-189d-420f-9cea-4f6775af285e\"/>\n        </paramGroup>\n        <paramGroup xml:id=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\">\n            <param value=\"9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-c3c427ad-ef8a-4a71-9b0c-9208dd8a6bed\"/>\n            <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-c15e1ed7-f773-456d-a007-fc237d9e0665\"/>\n            <param value=\"presentation/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-97d5b5ac-1258-4267-a013-dc3882d7e242\"/>\n        </paramGroup>\n    </head>\n    <body xml:id=\"b-c233c9ef-42d9-4f50-a1d2-29e3bbff003d\">\n        <par xml:id=\"par-7955133a-bcbe-40f8-87fd-47e78b3357c0\">\n            <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" paramGroup=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-61f5d0ee-dd36-4b1d-af3d-3f09f8807179\"/>\n            <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" paramGroup=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-c68260e7-fd0d-4df6-8696-cc475ab3b3f8\"/>\n        </par>\n    </body>\n</smil>\n\n\n\nWorkflow Operations\n\n\nWaveform Operation\n\n\nThe \nwaveform\n operation creates an image showing the temporal audio activity within the recording. This is be done\nwith a probably well known waveform (see example image).\n\n\n\n\nThe operation does not need an additional module, as it is not very work intensive to create such an image. The\noperation needs and audio-only file to create the image and it provides an PNG image.\n\n\nInput parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be\nused if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example).\n\n\nThe output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too.\n\n\nWaveform Operation Template\n\n\n<operation\n  id=\"waveform\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Generating waveform\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/audio</configuration>\n    <configuration key=\"target-flavor\">*/waveform</configuration>\n  </configurations>\n</operation>\n\n\n\nSilence Operation\n\n\nThe \nsilence\n operation performs a silence detection on an audio-only input file. The operation needs the silence\ndetection API and impl (or remote in a distributed system) modules to be installed to process the request.\n\n\nThe input parameters are source-flavors that takes one flavor/sub-type or multiple input flavors with the *-operator\nfollowed by the sub-type, and reference-tracks-flavour where the subtype of the media files that should be included in\nthe provided SMIL file will be set. The * should not be modified here. In most cases it is not important which\nreference-tracks-flavour is selected as long as all relevant flavors are available within this feature. \"preview\" is not\na bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\"\nwhere not all flavors may be available, as some recorders record all streams to one file and the tracks are separated\nafterwards. The editor operation afterwards will anyway try to select the best available quality.\n\n\nThe output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation.\nThe main flavor will be consistent and only the subtype will be replaced.\n\n\nThe output of this operation is a SMIL file (see the example above).\n\n\nSilence Operation Template\n\n\n<operation\n  id=\"silence\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Executing silence detection\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/audio</configuration>\n    <configuration key=\"smil-flavor-subtype\">smil</configuration>\n    <configuration key=\"reference-tracks-flavor\">*/preview</configuration>\n  </configurations>\n</operation>\n\n\n\nEditor Operation\n\n\nThe \neditor\n operation provides the UI for editing trim hold state and processes the edited files. This operation\nneeds the videoeditor API and impl (or remote on distributed systems) to be installed.\n\n\nThe input parameters are:\n\n\n\n\nsource-flavors: the subtype of all media files in the best available quality and in a codec that can be processed by\n   the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only\n   the subtype is important. All needed videos should be available within this flavor.\n\n\npreview-flavours: the subtype of the media files that should be used for the preview player. This is an HTML5 player\n   so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors.\n\n\nsmil-flavors: the smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil\n   will be favored, if this is not available the first in the list will be used.\n\n\nskipped-flavors: the flavor of the files that should be used if this workflow-operation is skipped.\n\n\n\n\nThe output parameters are:\n\n\n\n\ntarget-smil-flavor: only a unique flavor is allowed here, as this is the file that the editor UI writes and that will\n   be taken for processing the edited files afterwards.\n\n\ntarget-flavor-subtype: the flavor-subtype that will be used for all media files created in this operation.\n\n\n\n\nEditor Operation Template\n\n\n<operation\n  id=\"editor\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Waiting for user to review / video edit recording\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/work</configuration>\n    <configuration key=\"preview-flavors\">*/preview</configuration>\n    <configuration key=\"skipped-flavors\">*/preview</configuration>\n    <configuration key=\"smil-flavors\">*/smil</configuration>\n    <configuration key=\"target-smil-flavor\">episode/smil</configuration>\n    <configuration key=\"target-flavor-subtype\">trimmed</configuration>\n  </configurations>\n</operation>\n\n\n\nIncluding The Video Editor To The Workflow Definition File\n\n\nIncluding the Video Editor with the silence detection into the needs some changes in the default workflow. Several of\nthe steps here are inherited from the trim-operations and the workflow it was included too. We assume that you set\n${trimHold} variable like in the current workflow definitions with trimming.\n\n\n\n\nThe prepare-av operations has to be adopted. Gstreamer/gnonlin is kind of picky on the codec that it supports. So the\n   media file has to be re-encoded in the beginning of the workflow. The prepare-av encoding profiles (av.work and\n   mux-av.work) have been updated in the Video Editor branch for this. Within the prepare-av operation in the\n   workflow-definition XML-file rewriting the file should be forced:\n\n\n\n\nChanges in the workflow definition\n\n\n<configuration key=\"rewrite\">true</configuration>\n\n\n<configuration key=\"promiscuous-audio-muxing\">true</configuration>\n\n\n\n\n\n\nThe preview videos have to be created. These can be in H.264 (for Safari, IE, Chrome) or WebM (for Firefox, Opera or\n   Chrome) codec. Encoding profiles for WebM are provided in the video editor branch and are used in the examples. This\n   operation should be after the prepare-av operation.\n\n\nWorkflow operation to create WebM preview videos\n\n\n<operation\n  id=\"compose\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Encoding presenter (camera) video for videoeditor preview\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/preview</configuration>\n    <configuration key=\"encoding-profile\">webm-preview.http</configuration>\n  </configurations>\n</operation>\n\n\n\n\n\n\n\nAn audio-only file has to be composed for the waveform and silence operation. This operation should be after the\n   prepare-av operation.  Workflow operation to compose the audio-only file(s)\n\n\n<operation\n  id=\"compose\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Extracting audio for waveform generation\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/audio</configuration>\n    <configuration key=\"encoding-profile\">audio.wav</configuration>\n  </configurations>\n</operation>\n\n\n\n\n\n\n\nThe waveform operation should be included. See above for the XML-code for this operation. The audio-only file should already be available.\n\n\n\n\nThe silence detection should be done. See above for the XML-code for this operation. The audio-only file should already be available.\n\n\nAfter all previous operations have been done the editor can be included. See above for the XML-code for this operation.\n\n\nYou may consider to tag the trimmed files for archiving. Then you should include this operation after the editor:\n\n\n\n\nTagging trimmed files for the archive\n\n\n    <operation\n      id=\"tag\"\n      description=\"Tagging media for archival\">\n      <configurations>\n        <configuration key=\"source-flavors\">*/trimmed</configuration>\n        <configuration key=\"target-tags\">+archive</configuration>\n      </configurations>\n    </operation>\n\nYou could check, if you want to archive the source media too, or remove the source-flavors from the previous tagging operations.\n\n\n\n\n\nThe rest of the workflow definition can be kept as it is, the input flavor subtype for the trimmed files in other\n   operations is \"/trimmed\" if you follow the naming in this example.\n\n\n\n\nThe default \ncompose-distribute-publish.xml\n workflow definition within the Video Editor branch has already been updated\nto include the editor instead of the trim-hold state. The trim operation is not overwritten with the video editor but\ncould still be used.",
            "title": "Architecture"
        },
        {
            "location": "/modules/videoeditor.architecture/#video-editor-architecture",
            "text": "",
            "title": "Video Editor: Architecture"
        },
        {
            "location": "/modules/videoeditor.architecture/#modules-of-the-videoeditor",
            "text": "The Videoeditor consists of the following moduls. Additional to this there is a Workflow Operation Handler within the\nConductor module that provides the UI elements for the Video Editor.   matterhorn-silencedetection-api  API for the silence detection    matterhorn-silencedetection-impl  Implementation of the silence detection service  Provides a SMIL file that can be used by the Video Editor UI or the Video Editor service to create a new cutted\n  file.    matterhorn-silencedetection-remote  Remote implementation of the silence detection service to enable load balancing in a distributed setup.    matterhorn-smil-api  API for the SMIL service    matterhorn-smil-impl  The SMIL service allows creation and manipulation of SMIL files. This is more or less a helper class to create\n  consistent SMIL files.    matterhorn-videoeditor-api  The API for the Video Editor which takes a SMIL file as an input to create a cutted version of the media files.    matterhorn-videoeditor-impl  The Video Editor service creates new media files that will be cutted based on the information provided in a SMIL\n  file. In the current implementation GStreamer with the gnonlin module is used to process the files.    matterhorn-videoeditor-remote  Remote implementation of the video editor service to enable load balancing in a distributed setup.     Several other changes have been made on other Opencast modules to provide a better user experience for the video\neditor (i.e. byte-range request on the working-file-repository).",
            "title": "Modules Of The Videoeditor"
        },
        {
            "location": "/modules/videoeditor.architecture/#edit-list-format",
            "text": "The video editor uses SMIL 3.0 as a standardized Data format for the edit lists (cutting information). Some conventions\nand namespace extensions have been made to make sure that Opencast is able to find the files.   As we usually have two (or more) parallel media files, these files are grouped in a  <par> -element which forms a\n   segment that should be included in the resulting video.  This means the included  <video> -files will be played in\n   parallel.  The clipBegin and clipEnd attributes a provided as milliseconds. Usually these should be identical for all  <videos> \n   within a  <par> .  For each segment a  <par>  is created.  In the result of the silence detection segments with silence are omitted within the SMIL files, so only segments\n   within the SMIL doc will be in the resulting video.  The segments within the SMIL file will be in the order they are written down. If the sequence of the segments is\n   changed, the sequence within the resulting video is changed too.   Example SMIL file  <smil xmlns=\"http://www.w3.org/ns/SMIL\" baseProfile=\"Language\" version=\"3.0\" xml:id=\"s-524c7815-4520-48e4-bb5e-94dcfdb3229f\">\n    <head xml:id=\"h-03b31c8d-68cf-49ea-8bae-d94abddf8f09\">\n        <meta name=\"track-duration\" content=\"6000841ms\" xml:id=\"meta-32069ddb-351d-4dca-a742-b9be490080f8\"/>\n        <paramGroup xml:id=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\">\n            <param value=\"9f373445-5f46-4bdd-8d93-dca5e1094c38\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-d509b427-b239-4c4b-985a-f8b4ea31bbfb\"/>\n            <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-411e0015-af0e-463c-898d-9a2bc594df46\"/>\n            <param value=\"presenter/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-5ea022cd-189d-420f-9cea-4f6775af285e\"/>\n        </paramGroup>\n        <paramGroup xml:id=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\">\n            <param value=\"9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-c3c427ad-ef8a-4a71-9b0c-9208dd8a6bed\"/>\n            <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-c15e1ed7-f773-456d-a007-fc237d9e0665\"/>\n            <param value=\"presentation/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-97d5b5ac-1258-4267-a013-dc3882d7e242\"/>\n        </paramGroup>\n    </head>\n    <body xml:id=\"b-c233c9ef-42d9-4f50-a1d2-29e3bbff003d\">\n        <par xml:id=\"par-7955133a-bcbe-40f8-87fd-47e78b3357c0\">\n            <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" paramGroup=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-61f5d0ee-dd36-4b1d-af3d-3f09f8807179\"/>\n            <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" paramGroup=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-c68260e7-fd0d-4df6-8696-cc475ab3b3f8\"/>\n        </par>\n    </body>\n</smil>",
            "title": "Edit List Format"
        },
        {
            "location": "/modules/videoeditor.architecture/#workflow-operations",
            "text": "",
            "title": "Workflow Operations"
        },
        {
            "location": "/modules/videoeditor.architecture/#waveform-operation",
            "text": "The  waveform  operation creates an image showing the temporal audio activity within the recording. This is be done\nwith a probably well known waveform (see example image).   The operation does not need an additional module, as it is not very work intensive to create such an image. The\noperation needs and audio-only file to create the image and it provides an PNG image.  Input parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be\nused if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example).  The output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too.  Waveform Operation Template  <operation\n  id=\"waveform\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Generating waveform\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/audio</configuration>\n    <configuration key=\"target-flavor\">*/waveform</configuration>\n  </configurations>\n</operation>",
            "title": "Waveform Operation"
        },
        {
            "location": "/modules/videoeditor.architecture/#silence-operation",
            "text": "The  silence  operation performs a silence detection on an audio-only input file. The operation needs the silence\ndetection API and impl (or remote in a distributed system) modules to be installed to process the request.  The input parameters are source-flavors that takes one flavor/sub-type or multiple input flavors with the *-operator\nfollowed by the sub-type, and reference-tracks-flavour where the subtype of the media files that should be included in\nthe provided SMIL file will be set. The * should not be modified here. In most cases it is not important which\nreference-tracks-flavour is selected as long as all relevant flavors are available within this feature. \"preview\" is not\na bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\"\nwhere not all flavors may be available, as some recorders record all streams to one file and the tracks are separated\nafterwards. The editor operation afterwards will anyway try to select the best available quality.  The output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation.\nThe main flavor will be consistent and only the subtype will be replaced.  The output of this operation is a SMIL file (see the example above).  Silence Operation Template  <operation\n  id=\"silence\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Executing silence detection\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/audio</configuration>\n    <configuration key=\"smil-flavor-subtype\">smil</configuration>\n    <configuration key=\"reference-tracks-flavor\">*/preview</configuration>\n  </configurations>\n</operation>",
            "title": "Silence Operation"
        },
        {
            "location": "/modules/videoeditor.architecture/#editor-operation",
            "text": "The  editor  operation provides the UI for editing trim hold state and processes the edited files. This operation\nneeds the videoeditor API and impl (or remote on distributed systems) to be installed.  The input parameters are:   source-flavors: the subtype of all media files in the best available quality and in a codec that can be processed by\n   the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only\n   the subtype is important. All needed videos should be available within this flavor.  preview-flavours: the subtype of the media files that should be used for the preview player. This is an HTML5 player\n   so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors.  smil-flavors: the smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil\n   will be favored, if this is not available the first in the list will be used.  skipped-flavors: the flavor of the files that should be used if this workflow-operation is skipped.   The output parameters are:   target-smil-flavor: only a unique flavor is allowed here, as this is the file that the editor UI writes and that will\n   be taken for processing the edited files afterwards.  target-flavor-subtype: the flavor-subtype that will be used for all media files created in this operation.   Editor Operation Template  <operation\n  id=\"editor\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Waiting for user to review / video edit recording\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/work</configuration>\n    <configuration key=\"preview-flavors\">*/preview</configuration>\n    <configuration key=\"skipped-flavors\">*/preview</configuration>\n    <configuration key=\"smil-flavors\">*/smil</configuration>\n    <configuration key=\"target-smil-flavor\">episode/smil</configuration>\n    <configuration key=\"target-flavor-subtype\">trimmed</configuration>\n  </configurations>\n</operation>",
            "title": "Editor Operation"
        },
        {
            "location": "/modules/videoeditor.architecture/#including-the-video-editor-to-the-workflow-definition-file",
            "text": "Including the Video Editor with the silence detection into the needs some changes in the default workflow. Several of\nthe steps here are inherited from the trim-operations and the workflow it was included too. We assume that you set\n${trimHold} variable like in the current workflow definitions with trimming.   The prepare-av operations has to be adopted. Gstreamer/gnonlin is kind of picky on the codec that it supports. So the\n   media file has to be re-encoded in the beginning of the workflow. The prepare-av encoding profiles (av.work and\n   mux-av.work) have been updated in the Video Editor branch for this. Within the prepare-av operation in the\n   workflow-definition XML-file rewriting the file should be forced:   Changes in the workflow definition  <configuration key=\"rewrite\">true</configuration>  <configuration key=\"promiscuous-audio-muxing\">true</configuration>    The preview videos have to be created. These can be in H.264 (for Safari, IE, Chrome) or WebM (for Firefox, Opera or\n   Chrome) codec. Encoding profiles for WebM are provided in the video editor branch and are used in the examples. This\n   operation should be after the prepare-av operation.  Workflow operation to create WebM preview videos  <operation\n  id=\"compose\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Encoding presenter (camera) video for videoeditor preview\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/preview</configuration>\n    <configuration key=\"encoding-profile\">webm-preview.http</configuration>\n  </configurations>\n</operation>    An audio-only file has to be composed for the waveform and silence operation. This operation should be after the\n   prepare-av operation.  Workflow operation to compose the audio-only file(s)  <operation\n  id=\"compose\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Extracting audio for waveform generation\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/audio</configuration>\n    <configuration key=\"encoding-profile\">audio.wav</configuration>\n  </configurations>\n</operation>    The waveform operation should be included. See above for the XML-code for this operation. The audio-only file should already be available.   The silence detection should be done. See above for the XML-code for this operation. The audio-only file should already be available.  After all previous operations have been done the editor can be included. See above for the XML-code for this operation.  You may consider to tag the trimmed files for archiving. Then you should include this operation after the editor:   Tagging trimmed files for the archive      <operation\n      id=\"tag\"\n      description=\"Tagging media for archival\">\n      <configurations>\n        <configuration key=\"source-flavors\">*/trimmed</configuration>\n        <configuration key=\"target-tags\">+archive</configuration>\n      </configurations>\n    </operation>\n\nYou could check, if you want to archive the source media too, or remove the source-flavors from the previous tagging operations.   The rest of the workflow definition can be kept as it is, the input flavor subtype for the trimmed files in other\n   operations is \"/trimmed\" if you follow the naming in this example.   The default  compose-distribute-publish.xml  workflow definition within the Video Editor branch has already been updated\nto include the editor instead of the trim-hold state. The trim operation is not overwritten with the video editor but\ncould still be used.",
            "title": "Including The Video Editor To The Workflow Definition File"
        },
        {
            "location": "/modules/videosegmentation/",
            "text": "Video Segmentation Configuration\n\n\nWhat is Video Segmentation\n\n\nVideo segmentation is a way of dividing a movie into meaningful segments. In the context of lecture capture,\nsegmentation is best applied to captured screen presentation, that the presenter goes through slide after slide.\n\n\nAs a result, video segmentation returns the exact timepoints of slide changes on the timeline, which allows for\nsophisticated ways for the learner to browse the lecture content, as shown in the slides section of the Opencast Player.\n\n\nHow the video segmentation process works\n\n\nFor detecting new scenes, Opencast uses the scene detection build into the FFmpeg select filter. The basic idea behind\nthis filter is to compare to consecutive frames and decide if the second frame belongs to a new scene based on the\ndifference.\n\n\nConfiguration\n\n\nThe value for the frame difference as well as the minimum length for a segment can be configured in\n\netc/org.opencastproject.videosegmenter.ffmpeg.VideoSegmenterServiceImpl.cfg\n.\n\n\nThe two options that can be set are the minimum length of a segment (defaults to 5 sec).\n\n\nstabilitythreshold = 5\n\n\n\nThe percentage of pixels that may change between tow frames without considering them different (defaults to 0.05).\n\n\nchangesthreshold = 0.05",
            "title": "Video Segmentation"
        },
        {
            "location": "/modules/videosegmentation/#video-segmentation-configuration",
            "text": "",
            "title": "Video Segmentation Configuration"
        },
        {
            "location": "/modules/videosegmentation/#what-is-video-segmentation",
            "text": "Video segmentation is a way of dividing a movie into meaningful segments. In the context of lecture capture,\nsegmentation is best applied to captured screen presentation, that the presenter goes through slide after slide.  As a result, video segmentation returns the exact timepoints of slide changes on the timeline, which allows for\nsophisticated ways for the learner to browse the lecture content, as shown in the slides section of the Opencast Player.",
            "title": "What is Video Segmentation"
        },
        {
            "location": "/modules/videosegmentation/#how-the-video-segmentation-process-works",
            "text": "For detecting new scenes, Opencast uses the scene detection build into the FFmpeg select filter. The basic idea behind\nthis filter is to compare to consecutive frames and decide if the second frame belongs to a new scene based on the\ndifference.",
            "title": "How the video segmentation process works"
        },
        {
            "location": "/modules/videosegmentation/#configuration",
            "text": "The value for the frame difference as well as the minimum length for a segment can be configured in etc/org.opencastproject.videosegmenter.ffmpeg.VideoSegmenterServiceImpl.cfg .  The two options that can be set are the minimum length of a segment (defaults to 5 sec).  stabilitythreshold = 5  The percentage of pixels that may change between tow frames without considering them different (defaults to 0.05).  changesthreshold = 0.05",
            "title": "Configuration"
        },
        {
            "location": "/modules/youtubepublication/",
            "text": "YouTube Publication Configuration\n\n\nThis page documents the configuration for Opencast module \nmatterhorn-publication-service-youtube-v3\n.\n\n\nCreate new Google Project\n\n\n\n\nLogin to Google account\n\n\nNavigate to the \nGoogle Developers Console\n\n\nClick \nCreate Project\n and follow the instructions\n\n\nOn your new projects page, choose \nAPIs & auth\n then \nConsent screen\n in the navigation pane\n\n\nSet the \nPRODUCT NAME\n and the \nEMAIL ADDRESS\n\n\n\n\nEnable API\n\n\n\n\nChoose \nAPIs\n in the navigation pane\n\n\nUse the filter to find and enable \nYouTube Data API v3\n\n\n\n\nRegister an Application\n\n\n\n\nChoose \nCredentials\n in the navigation pane\n\n\nClick \nCreate new Client ID\n for OAuth\n\n\nChoose \nInstalled application\n for the application type and \nOther\n for the installed application type\n\n\nAccept with \nCreate Client ID\n\n\n\n\nSave Client ID in JSON Format\n\n\n\n\nDownload the client information in JSON format by clicking \nDownload JSON\n\n\nSave the JSON file to \n${karaf.etc}/youtube-v3/client-secrets-youtube-v3.json\n (Usually this is\n  \netc/youtube-v3/client-secrets-youtube-v3.json\n)\n\n\n\n\nGenerate OAuth Tokens\n\n\n\n\nStart Opencast\n\n\nFollow the request URL appearing in the Opencast logs and click \nAccept\n\n\nThe resulting website will say \nReceived verification code. Closing...\n\n\n\n\nThe generated token is saved at \n${org.opencastproject.storage.dir}/youtube-v3/data-store/store\n (Usually this is\n\nwork/opencast/youtube-v3/data-store/store\n).  If the file is not found or invalid a new request URL will be generated.\nBoth paths for the JSON file and the token file can be altered in the service properties file at\n\netc/services/org.opencastproject.publication.  youtube.YouTubePublicationServiceImpl.properties",
            "title": "YouTube Publication"
        },
        {
            "location": "/modules/youtubepublication/#youtube-publication-configuration",
            "text": "This page documents the configuration for Opencast module  matterhorn-publication-service-youtube-v3 .",
            "title": "YouTube Publication Configuration"
        },
        {
            "location": "/modules/youtubepublication/#create-new-google-project",
            "text": "Login to Google account  Navigate to the  Google Developers Console  Click  Create Project  and follow the instructions  On your new projects page, choose  APIs & auth  then  Consent screen  in the navigation pane  Set the  PRODUCT NAME  and the  EMAIL ADDRESS",
            "title": "Create new Google Project"
        },
        {
            "location": "/modules/youtubepublication/#enable-api",
            "text": "Choose  APIs  in the navigation pane  Use the filter to find and enable  YouTube Data API v3",
            "title": "Enable API"
        },
        {
            "location": "/modules/youtubepublication/#register-an-application",
            "text": "Choose  Credentials  in the navigation pane  Click  Create new Client ID  for OAuth  Choose  Installed application  for the application type and  Other  for the installed application type  Accept with  Create Client ID",
            "title": "Register an Application"
        },
        {
            "location": "/modules/youtubepublication/#save-client-id-in-json-format",
            "text": "Download the client information in JSON format by clicking  Download JSON  Save the JSON file to  ${karaf.etc}/youtube-v3/client-secrets-youtube-v3.json  (Usually this is\n   etc/youtube-v3/client-secrets-youtube-v3.json )",
            "title": "Save Client ID in JSON Format"
        },
        {
            "location": "/modules/youtubepublication/#generate-oauth-tokens",
            "text": "Start Opencast  Follow the request URL appearing in the Opencast logs and click  Accept  The resulting website will say  Received verification code. Closing...   The generated token is saved at  ${org.opencastproject.storage.dir}/youtube-v3/data-store/store  (Usually this is work/opencast/youtube-v3/data-store/store ).  If the file is not found or invalid a new request URL will be generated.\nBoth paths for the JSON file and the token file can be altered in the service properties file at etc/services/org.opencastproject.publication.  youtube.YouTubePublicationServiceImpl.properties",
            "title": "Generate OAuth Tokens"
        },
        {
            "location": "/workflowoperationhandlers/",
            "text": "Workflow Operation Handler\n\n\nIntroduction\n\n\nWorkflows are the central element to define how a media package is being processed by the Opencast services. Their\ndefinitions consist of a list of workflow operations, which basically map a piece of configuration to Opencast code:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n    ....\n    <operation\n      id=\"tag\"\n      <configurations>\n        <configuration key=\"source-flavors\">presentation/trimmed</configuration>\n        <configuration key=\"target-flavor\">presentation/tagged</configuration>\n      </configurations>\n   </operation>\n   ...\n</definition>\n\n\n\nDefault Workflow Operations\n\n\nThe following table contains the workflow operations that are available in an out-of-the-box Opencast installation:\n\n\n\n\n\n\n\n\nOperation Handler\n\n\nDescription\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\nanalyze-audio\n\n\nAnalyze first audio stream\n\n\nDocumentation\n\n\n\n\n\n\nappend\n\n\nHold for user to select workflow to continue with\n\n\nDocumentation\n\n\n\n\n\n\narchive\n\n\nArchive the current state of the mediapackage\n\n\nDocumentation\n\n\n\n\n\n\ncaption\n\n\nWaiting for user to upload captions\n\n\nDocumentation\n\n\n\n\n\n\ncleanup\n\n\nCleanup the working file repository\n\n\n\n\n\n\n\n\ncompose\n\n\nEncode media files using FFmpeg\n\n\nDocumentation\n\n\n\n\n\n\ncomposite\n\n\nCompose two videos on one canvas.\n\n\nDocumentation\n\n\n\n\n\n\nconcat\n\n\nConcatenate multiple video tracks into one video track\n\n\nDocumentation\n\n\n\n\n\n\ndefaults\n\n\nApplies default workflow configuration values\n\n\nDocumentation\n\n\n\n\n\n\neditor\n\n\nWaiting for user to review, then cut video based on edit-list\n\n\nDocumentation\n\n\n\n\n\n\nemail\n\n\nSends email notifications at any part of a workflow\n\n\nDocumentation\n\n\n\n\n\n\nextract-text\n\n\nExtracting text from presentation segments\n\n\nDocumentation\n\n\n\n\n\n\nhttp-notify\n\n\nNotifies an HTTP endpoint about the process of the workflow\n\n\nDocumentation\n\n\n\n\n\n\nimage\n\n\nExtract images from a video using FFmpeg\n\n\nDocumentation\n\n\n\n\n\n\nimage-to-video\n\n\nCreate a video track from a source image\n\n\nDocumentation\n\n\n\n\n\n\nincident\n\n\nTesting incidents on a dummy job\n\n\nDocumentation\n\n\n\n\n\n\ningest-download\n\n\nDownload files from external URL for ingest\n\n\nDocumentation\n\n\n\n\n\n\ninspect\n\n\nInspect the media (check if it is valid)\n\n\nDocumentation\n\n\n\n\n\n\nnormalize-audio\n\n\nNormalize first audio stream\n\n\nDocumentation\n\n\n\n\n\n\npost-mediapackage\n\n\nSend mediapackage to remote service\n\n\nDocumentation\n\n\n\n\n\n\nprepare-av\n\n\nPreparing audio and video work versions\n\n\nDocumentation\n\n\n\n\n\n\npublish-engage\n\n\nDistribute and publish media to the engage player\n\n\nDocumentation\n\n\n\n\n\n\nrepublish\n\n\nRepublishes elements to search\n\n\nDocumentation\n\n\n\n\n\n\nsegment-video\n\n\nExtracting segments from presentation\n\n\nDocumentation\n\n\n\n\n\n\nsegmentpreviews\n\n\nExtract segment images from a video using FFmpeg\n\n\nDocumentation\n\n\n\n\n\n\nseries\n\n\nApply series to the mediapackage\n\n\nDocumentation\n\n\n\n\n\n\nsilence\n\n\nSilence detection on audio of the mediapackage\n\n\nDocumentation\n\n\n\n\n\n\ntag\n\n\nModify the tag sets of media package elements\n\n\nDocumentation\n\n\n\n\n\n\ntrim\n\n\nWaiting for user to review, then trim the recording\n\n\nDocumentation\n\n\n\n\n\n\nwaveform\n\n\nCreate a waveform image of the audio of the mediapackage\n\n\nDocumentation\n\n\n\n\n\n\nzip\n\n\nCreate zipped archive of the current state of the mediapackage\n\n\nDocumentation",
            "title": "Overview"
        },
        {
            "location": "/workflowoperationhandlers/#workflow-operation-handler",
            "text": "",
            "title": "Workflow Operation Handler"
        },
        {
            "location": "/workflowoperationhandlers/#introduction",
            "text": "Workflows are the central element to define how a media package is being processed by the Opencast services. Their\ndefinitions consist of a list of workflow operations, which basically map a piece of configuration to Opencast code:  <definition xmlns=\"http://workflow.opencastproject.org\">\n    ....\n    <operation\n      id=\"tag\"\n      <configurations>\n        <configuration key=\"source-flavors\">presentation/trimmed</configuration>\n        <configuration key=\"target-flavor\">presentation/tagged</configuration>\n      </configurations>\n   </operation>\n   ...\n</definition>",
            "title": "Introduction"
        },
        {
            "location": "/workflowoperationhandlers/#default-workflow-operations",
            "text": "The following table contains the workflow operations that are available in an out-of-the-box Opencast installation:     Operation Handler  Description  Details      analyze-audio  Analyze first audio stream  Documentation    append  Hold for user to select workflow to continue with  Documentation    archive  Archive the current state of the mediapackage  Documentation    caption  Waiting for user to upload captions  Documentation    cleanup  Cleanup the working file repository     compose  Encode media files using FFmpeg  Documentation    composite  Compose two videos on one canvas.  Documentation    concat  Concatenate multiple video tracks into one video track  Documentation    defaults  Applies default workflow configuration values  Documentation    editor  Waiting for user to review, then cut video based on edit-list  Documentation    email  Sends email notifications at any part of a workflow  Documentation    extract-text  Extracting text from presentation segments  Documentation    http-notify  Notifies an HTTP endpoint about the process of the workflow  Documentation    image  Extract images from a video using FFmpeg  Documentation    image-to-video  Create a video track from a source image  Documentation    incident  Testing incidents on a dummy job  Documentation    ingest-download  Download files from external URL for ingest  Documentation    inspect  Inspect the media (check if it is valid)  Documentation    normalize-audio  Normalize first audio stream  Documentation    post-mediapackage  Send mediapackage to remote service  Documentation    prepare-av  Preparing audio and video work versions  Documentation    publish-engage  Distribute and publish media to the engage player  Documentation    republish  Republishes elements to search  Documentation    segment-video  Extracting segments from presentation  Documentation    segmentpreviews  Extract segment images from a video using FFmpeg  Documentation    series  Apply series to the mediapackage  Documentation    silence  Silence detection on audio of the mediapackage  Documentation    tag  Modify the tag sets of media package elements  Documentation    trim  Waiting for user to review, then trim the recording  Documentation    waveform  Create a waveform image of the audio of the mediapackage  Documentation    zip  Create zipped archive of the current state of the mediapackage  Documentation",
            "title": "Default Workflow Operations"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/",
            "text": "AnalyzeAudioWorkflowOperationHandler\n\n\nDescription\n\n\nThe AnalyzeAudioiWorkflowOperationHandler analyzes the first audio stream of a video or audio track through SoX (http://sox.sourceforge.net/) and writes the result back to the given track.\n\n\nThis workflow operation handler can be used with audio and/or video files. At least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs:\n\n\nUsed with Audio only file (forceTranscode is deactivated):\n\n\n\n\nAnalyze the given audio file with SoX\n\n\nWrite analyzed audio metadata back to the given track's mediapackage.\n\n\n\n\nUsed with Video file or with Audio only file with forceTranscode activated:\n\n\n\n\nExtract audio file encoded as FLAC audio and save it temporary in a collection\n\n\nAnalyze the previous encoded audio file with SoX\n\n\nWrite analyzed audio metadata back to the given track's mediapackage.\n\n\nDelete the temporary encoded FLAC audio file\n\n\n\n\nExample result track:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<track type=\"presentation/audio\" id=\"audio\">\n    <mimetype>video/x-flac</mimetype>\n    <tags />\n    <url>fooVideo.flac</url>\n    <checksum type=\"md5\">46cb2e9df2e73756b0d96c33b1aaf055</checksum>\n    <duration>65680</duration>\n    <audio id=\"audio-1\">\n        <device />\n        <encoder type=\"ADPCM\" />\n        <bitdepth>16</bitdepth>\n        <channels>2</channels>\n        <bitrate>62500.0</bitrate>\n        <peakleveldb>-30</peakleveldb> <!-- NEW -->\n        <rmsleveldb>-20</rmsleveldb> <!-- NEW -->\n        <rmspeakdb>-10</rmspeakdb> <!-- NEW -->\n    </audio>\n</track>\n\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"presentation/work,presenter/work\"\n\n\nThe \"flavors\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor\n\n\n\"presentation/work\"\n\n\nThe \"flavor\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags\n\n\n\"engage,atom,rss\"\n\n\nThe \"tag\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nforce-transcode\n\n\n\"true\" or \"false\"\n\n\nWhether to force transcoding the audio stream\n\n\n\n\n\n\n\n\n(This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format)\n\n\nFALSE\n\n\n\n\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"analyze-audio\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Analyze audio stream\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"force-transcode\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Analyze Audio"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#analyzeaudioworkflowoperationhandler",
            "text": "",
            "title": "AnalyzeAudioWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#description",
            "text": "The AnalyzeAudioiWorkflowOperationHandler analyzes the first audio stream of a video or audio track through SoX (http://sox.sourceforge.net/) and writes the result back to the given track.  This workflow operation handler can be used with audio and/or video files. At least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs:",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#used-with-audio-only-file-forcetranscode-is-deactivated",
            "text": "Analyze the given audio file with SoX  Write analyzed audio metadata back to the given track's mediapackage.",
            "title": "Used with Audio only file (forceTranscode is deactivated):"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#used-with-video-file-or-with-audio-only-file-with-forcetranscode-activated",
            "text": "Extract audio file encoded as FLAC audio and save it temporary in a collection  Analyze the previous encoded audio file with SoX  Write analyzed audio metadata back to the given track's mediapackage.  Delete the temporary encoded FLAC audio file   Example result track:  <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<track type=\"presentation/audio\" id=\"audio\">\n    <mimetype>video/x-flac</mimetype>\n    <tags />\n    <url>fooVideo.flac</url>\n    <checksum type=\"md5\">46cb2e9df2e73756b0d96c33b1aaf055</checksum>\n    <duration>65680</duration>\n    <audio id=\"audio-1\">\n        <device />\n        <encoder type=\"ADPCM\" />\n        <bitdepth>16</bitdepth>\n        <channels>2</channels>\n        <bitrate>62500.0</bitrate>\n        <peakleveldb>-30</peakleveldb> <!-- NEW -->\n        <rmsleveldb>-20</rmsleveldb> <!-- NEW -->\n        <rmspeakdb>-10</rmspeakdb> <!-- NEW -->\n    </audio>\n</track>",
            "title": "Used with Video file or with Audio only file with forceTranscode activated:"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  \"presentation/work,presenter/work\"  The \"flavors\" of the track to use as a source input  EMPTY    source-flavor  \"presentation/work\"  The \"flavor\" of the track to use as a source input  EMPTY    source-tags  \"engage,atom,rss\"  The \"tag\" of the track to use as a source input  EMPTY    force-transcode  \"true\" or \"false\"  Whether to force transcoding the audio stream     (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format)  FALSE",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#operation-example",
            "text": "<operation\n  id=\"analyze-audio\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Analyze audio stream\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"force-transcode\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/append-woh/",
            "text": "AppendWorkflowHandler\n\n\n\n\nThis operations has been deprecated with opencast 2.0\n\n\n\n\nDescription\n\n\nThe AppendWorkflowOperation can be used to select additional workflows which should be appended to the current one. This\nbasically means that it can be used to build a workflow selection workflow, making it possible to select workflows after\nthe media was ingested.\n\n\nOperation Example\n\n\nthis example shows a complete workflow selection workflow:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<definition xmlns=\"http://workflow.opencastproject.org\">\n  <id>default</id>\n  <description>Puts mediapackages on hold</description>\n  <operations>\n    <operation\n      id=\"append\"\n      fail-on-error=\"true\"\n      description=\"Hold for workflow selection\">\n    </operation>\n  </operations>\n</definition>",
            "title": "Append"
        },
        {
            "location": "/workflowoperationhandlers/append-woh/#appendworkflowhandler",
            "text": "This operations has been deprecated with opencast 2.0",
            "title": "AppendWorkflowHandler"
        },
        {
            "location": "/workflowoperationhandlers/append-woh/#description",
            "text": "The AppendWorkflowOperation can be used to select additional workflows which should be appended to the current one. This\nbasically means that it can be used to build a workflow selection workflow, making it possible to select workflows after\nthe media was ingested.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/append-woh/#operation-example",
            "text": "this example shows a complete workflow selection workflow:  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<definition xmlns=\"http://workflow.opencastproject.org\">\n  <id>default</id>\n  <description>Puts mediapackages on hold</description>\n  <operations>\n    <operation\n      id=\"append\"\n      fail-on-error=\"true\"\n      description=\"Hold for workflow selection\">\n    </operation>\n  </operations>\n</definition>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/archive-woh/",
            "text": "ArchiveWorkflowHandler\n\n\nDescription\n\n\nThe ArchiveWorkflowHandler will archive the current state of the mediapackage.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-tags\n\n\ntext\n\n\nSpecifies which media should be archived.\n\n\n\n\n\n\nsource-flavors\n\n\npresenter/source\n\n\nFlavors that should be archived, separated by \",\"\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      if=\"${archiveOp}\"\n      id=\"archive\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Archiving\">\n      <configurations>\n            <configuration key=\"source-tags\">archive</configuration>\n      </configurations>\n</operation>",
            "title": "Archive"
        },
        {
            "location": "/workflowoperationhandlers/archive-woh/#archiveworkflowhandler",
            "text": "",
            "title": "ArchiveWorkflowHandler"
        },
        {
            "location": "/workflowoperationhandlers/archive-woh/#description",
            "text": "The ArchiveWorkflowHandler will archive the current state of the mediapackage.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/archive-woh/#parameter-table",
            "text": "configuration keys  example  description      source-tags  text  Specifies which media should be archived.    source-flavors  presenter/source  Flavors that should be archived, separated by \",\"",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/archive-woh/#operation-example",
            "text": "<operation\n      if=\"${archiveOp}\"\n      id=\"archive\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Archiving\">\n      <configurations>\n            <configuration key=\"source-tags\">archive</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/caption-woh/",
            "text": "CaptionWorkflowOperation\n\n\nDescription\n\n\nTheCaptionWorkflowOperation waits for user to upload caption files which will be added to the media.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\ntarget-tags\n\n\nengage\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"caption\"\n      if=\"${captionHold}\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Waiting for user to upload captions\">\n      <configurations>\n            <configuration key=\"target-tags\">engage,archive</configuration>\n      </configurations>\n</operation>",
            "title": "Caption"
        },
        {
            "location": "/workflowoperationhandlers/caption-woh/#captionworkflowoperation",
            "text": "",
            "title": "CaptionWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/caption-woh/#description",
            "text": "TheCaptionWorkflowOperation waits for user to upload caption files which will be added to the media.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/caption-woh/#parameter-table",
            "text": "configuration keys  example  description      target-tags  engage  Specifies which media should be processed.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/caption-woh/#operation-example",
            "text": "<operation\n      id=\"caption\"\n      if=\"${captionHold}\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Waiting for user to upload captions\">\n      <configurations>\n            <configuration key=\"target-tags\">engage,archive</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/",
            "text": "ComposeWorkflowHandler\n\n\nDescription\n\n\nThe ComposeWorkflowHandler is used to encode media files to different formats using FFmpeg.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/work\n\n\nWhich media should be encoded\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/delivery\n\n\nSpecifies the flavor of the new media\n\n\n\n\n\n\nsource-tags\n\n\nsometag\n\n\nTags of media to encode\n\n\n\n\n\n\ntarget-tags\n\n\nsometag\n\n\nSpecifies the tags of the new media\n\n\n\n\n\n\nencoding-profile   webm-hd\n\n\nSpecifies the encoding profile to use\n\n\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n    id=\"compose\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encoding presenter (camera) video to Flash download\">\n    <configurations>\n        <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n        <configuration key=\"target-flavor\">presenter/delivery</configuration>\n        <configuration key=\"target-tags\">engage</configuration>\n        <configuration key=\"encoding-profile\">flash.http</configuration>\n    </configurations>\n</operation>",
            "title": "Compose"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/#composeworkflowhandler",
            "text": "",
            "title": "ComposeWorkflowHandler"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/#description",
            "text": "The ComposeWorkflowHandler is used to encode media files to different formats using FFmpeg.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/work  Which media should be encoded    target-flavor  presenter/delivery  Specifies the flavor of the new media    source-tags  sometag  Tags of media to encode    target-tags  sometag  Specifies the tags of the new media    encoding-profile   webm-hd  Specifies the encoding profile to use",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/#operation-example",
            "text": "<operation\n    id=\"compose\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encoding presenter (camera) video to Flash download\">\n    <configurations>\n        <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n        <configuration key=\"target-flavor\">presenter/delivery</configuration>\n        <configuration key=\"target-tags\">engage</configuration>\n        <configuration key=\"encoding-profile\">flash.http</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/",
            "text": "Composite workflow Operation Handler\n\n\nDescription\n\n\nThe CompositeWorkflowOperationHandler is used to composite two videos (upper and lower) and an optionally watermark into\none video, including encoding to different formats. The audio track is always taken from the lower video. Everything is\ndone using FFmpeg. The composition can be done in various layout formats e.g. side by side or picture in picture. The\nlayout has to be defined in JSON format and is described in section \"Layout Definition\". For some general information\nabout layouts see Opencast Composer Layout Module.\n\n\nThe internal ffmpeg command is using the following filters: scale for scaling the videos, pad for defining the output\ndimension including the background color, movie for adding additional videos and images and overlay for aligning the\nvideos and images to the output dimension. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide\n\n\nSample complex composite filter command\n\n\n-filter:v \"[in]scale=640:480,pad=1920:1080:20:20:black[lower];movie=test.mp4,scale=640:480[upper];movie=watermark.jpg[watermark];[lower][upper]overlay=200:200[video];[video][watermark]overlay=main_w-overlay_w-20:20[out]\" sidebyside.mp4\n\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nvalue type (EBNF)\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-tags-upper\n\n\nString , { \",\" , String }\n\n\ncomp,rss\n\n\nThe \"tag\" of the upper track to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor-upper\n\n\nMediaPackageElementFlavor\n\n\npresenter/trimmed\n\n\nThe \"flavor\" of the upper track to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags-lower\n\n\nString , { \",\" , String }\n\n\ncomp,rss\n\n\nThe \"tag\" of the lower track to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor-lower\n\n\nMediaPackageElementFlavor\n\n\npresenter/trimmed\n\n\nThe \"flavor\" of the lower track to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags-watermark\n\n\nString , { \",\" , String }\n\n\nbranding\n\n\nThe \"tag\" of the attachment image to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor-watermark\n\n\nMediaPackageElementFlavor\n\n\nimage/work\n\n\nThe \"flavor\" of the attachment image to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-url-watermark\n\n\nURL\n\n\nfile:///Users/me/logo.jpg\n\n\nThe \"URL\" of the fallback image to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\nString , { \",\" , String }\n\n\ncomposite,rss,atom,archive\n\n\nThe tags to apply to the compound video track.\n\n\nEMPTY\n\n\n\n\n\n\n* \ntarget-flavor\n\n\nMediaPackageElementFlavor\n\n\ncomposite/delivery\n\n\nThe flavor to apply to the compound video track.\n\n\nEMPTY\n\n\n\n\n\n\n* \nencoding-profile\n\n\nString\n\n\ncomposite\n\n\nThe encoding profile to use.\n\n\nEMPTY\n\n\n\n\n\n\n* \noutput-resolution\n\n\nwidth , \"x\" , height\n\n\n1900x1080\n\n\nThe resulting resolution of the compound video e.g. 1900x1080.\n\n\nEMPTY\n\n\n\n\n\n\noutput-background\n\n\nString\n\n\nred\n\n\nThe resulting background color of the compound video http://www.ffmpeg.org/ffmpeg-utils.html#Color.\n\n\nblack\n\n\n\n\n\n\n* \nlayout\n\n\nname\n\n\nJson , \";\" , Json , [ \";\" , Json ]\n\n\ntopleft\n\n\nThe layout name to use or a semi-colon separated JSON layout definition (lower video, upper video, optional watermark). If a layout name is given than the corresponding layout-{name} key must be defined.\n\n\n\n\n\n\nlayout-{name}\n\n\nJson , \";\" , Json , [ \";\" , Json ]\n\n\nDefine semi-colon separated JSON layouts (lower video, upper video, optional watermark) to provide by name.\n\n\nEMPTY\n\n\n\n\n\n\n\n\n\n\n* \nmandatory\n\n\nLayout Definition\n\n\nThe layout definitions are provided as JSON. Each definition consist of the layout specifications for the lower and\nupper video and an optional specification for the watermark. The specifications have to be separated by comma.\n\n\nIt is always ensured that the media does not exceed the canvas. Offset and scaling is adjusted appropriately.\n\n\nA single layout is specified as follows:\n\n\n{\n  // How much of the canvas shall be covered. [0.0 - 1.0]\n  // 1.0 means that the media is scaled to cover the complete width of the canvas keeping the aspect ratio.\n  \"horizontalCoverage\": Double,\n  // The offset between the anchor points of the media and the canvas\n  \"anchorOffset\": {\n    // The anchor point of the media. [0.0 - 1.0]\n    // (0.0, 0.0) is the upper left corner, (1.0, 1.0) is the lower right corner.\n    // (0.5, 0.5) is the center.\n    \"referring\": {\n      \"left\": Double,\n      \"top\": Double\n    },\n    // The anchor point of the canvas.\n    \"reference\": {\n      \"left\": Double,\n      \"top\": Double\n    },\n    // The offset between the two anchor points.\n    \"offset\": {\n      \"y\": Integer,\n      \"x\": Integer\n    }\n  }\n}\n\n// Example.\n// The media is scaled to cover the whole width of the canvas and is placed in the upper left corner.\n{\n  \"horizontalCoverage\": 1.0,\n  \"anchorOffset\": {\n    \"referring\": {\n      \"left\": 0.0,\n      \"top\": 0.0\n    },\n    \"offset\": {\n      \"y\": 0,\n      \"x\": 0\n    },\n    \"reference\": {\n      \"left\": 0.0,\n      \"top\": 0.0\n    }\n  }\n}\n\n// Example.\n// The media is scaled to cover 20% of the width of the canvas and is placed in the lower right corner\n// with an offset of -10px on both x and y axis so that it does not touch the canvas' border.\n{\n  \"horizontalCoverage\": 0.2,\n  \"anchorOffset\": {\n    \"referring\": {\n      \"left\": 1.0,\n      \"top\": 1.0\n    },\n    \"offset\": {\n      \"y\": -10,\n      \"x\": -10\n    },\n    \"reference\": {\n      \"left\": 1.0,\n      \"top\": 1.0\n    }\n  }\n}\n\n\n\nOperation Example\n\n\n<operation\n  id=\"composite\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Composite\">\n  <configurations>\n    <configuration key=\"source-flavor-upper\">presentation/trimmed</configuration>\n    <configuration key=\"source-flavor-lower\">presenter/trimmed</configuration>\n    <configuration key=\"source-tags-upper\">comp,rss</configuration>\n    <configuration key=\"source-tags-lower\">comp,rss</configuration>\n    <configuration key=\"source-tags-watermark\">branding</configuration>\n    <configuration key=\"source-flavor-watermark\">image/work</configuration>\n    <configuration key=\"source-url-watermark\">file:///Users/me/logo.jpg</configuration>\n    <configuration key=\"encoding-profile\">composite</configuration>\n    <configuration key=\"target-tags\">composite,rss,atom,archive</configuration>\n    <configuration key=\"target-flavor\">composite/delivery</configuration>\n    <configuration key=\"output-resolution\">1900x1080</configuration>\n    <configuration key=\"output-background\">red</configuration>\n    <configuration key=\"layout\">topleft</configuration>\n    <configuration key=\"layout-topleft\">\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}};\n      {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":0.0,\"top\":0.0}}};\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":1.0,\"top\":0.0}}}\n    </configuration>\n    <configuration key=\"layout-topright\">\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}};\n      {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":0.0}}};\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":0.0,\"top\":0.0}}}\n    </configuration>\n  </configurations>\n</operation>",
            "title": "Composite"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#composite-workflow-operation-handler",
            "text": "",
            "title": "Composite workflow Operation Handler"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#description",
            "text": "The CompositeWorkflowOperationHandler is used to composite two videos (upper and lower) and an optionally watermark into\none video, including encoding to different formats. The audio track is always taken from the lower video. Everything is\ndone using FFmpeg. The composition can be done in various layout formats e.g. side by side or picture in picture. The\nlayout has to be defined in JSON format and is described in section \"Layout Definition\". For some general information\nabout layouts see Opencast Composer Layout Module.  The internal ffmpeg command is using the following filters: scale for scaling the videos, pad for defining the output\ndimension including the background color, movie for adding additional videos and images and overlay for aligning the\nvideos and images to the output dimension. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#sample-complex-composite-filter-command",
            "text": "-filter:v \"[in]scale=640:480,pad=1920:1080:20:20:black[lower];movie=test.mp4,scale=640:480[upper];movie=watermark.jpg[watermark];[lower][upper]overlay=200:200[video];[video][watermark]overlay=main_w-overlay_w-20:20[out]\" sidebyside.mp4",
            "title": "Sample complex composite filter command"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  value type (EBNF)  example  description  default value      source-tags-upper  String , { \",\" , String }  comp,rss  The \"tag\" of the upper track to use as a source input.  EMPTY    source-flavor-upper  MediaPackageElementFlavor  presenter/trimmed  The \"flavor\" of the upper track to use as a source input.  EMPTY    source-tags-lower  String , { \",\" , String }  comp,rss  The \"tag\" of the lower track to use as a source input.  EMPTY    source-flavor-lower  MediaPackageElementFlavor  presenter/trimmed  The \"flavor\" of the lower track to use as a source input.  EMPTY    source-tags-watermark  String , { \",\" , String }  branding  The \"tag\" of the attachment image to use as a source input.  EMPTY    source-flavor-watermark  MediaPackageElementFlavor  image/work  The \"flavor\" of the attachment image to use as a source input.  EMPTY    source-url-watermark  URL  file:///Users/me/logo.jpg  The \"URL\" of the fallback image to use as a source input.  EMPTY    target-tags  String , { \",\" , String }  composite,rss,atom,archive  The tags to apply to the compound video track.  EMPTY    *  target-flavor  MediaPackageElementFlavor  composite/delivery  The flavor to apply to the compound video track.  EMPTY    *  encoding-profile  String  composite  The encoding profile to use.  EMPTY    *  output-resolution  width , \"x\" , height  1900x1080  The resulting resolution of the compound video e.g. 1900x1080.  EMPTY    output-background  String  red  The resulting background color of the compound video http://www.ffmpeg.org/ffmpeg-utils.html#Color.  black    *  layout  name  Json , \";\" , Json , [ \";\" , Json ]  topleft  The layout name to use or a semi-colon separated JSON layout definition (lower video, upper video, optional watermark). If a layout name is given than the corresponding layout-{name} key must be defined.    layout-{name}  Json , \";\" , Json , [ \";\" , Json ]  Define semi-colon separated JSON layouts (lower video, upper video, optional watermark) to provide by name.  EMPTY      *  mandatory",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#layout-definition",
            "text": "The layout definitions are provided as JSON. Each definition consist of the layout specifications for the lower and\nupper video and an optional specification for the watermark. The specifications have to be separated by comma.  It is always ensured that the media does not exceed the canvas. Offset and scaling is adjusted appropriately.  A single layout is specified as follows:  {\n  // How much of the canvas shall be covered. [0.0 - 1.0]\n  // 1.0 means that the media is scaled to cover the complete width of the canvas keeping the aspect ratio.\n  \"horizontalCoverage\": Double,\n  // The offset between the anchor points of the media and the canvas\n  \"anchorOffset\": {\n    // The anchor point of the media. [0.0 - 1.0]\n    // (0.0, 0.0) is the upper left corner, (1.0, 1.0) is the lower right corner.\n    // (0.5, 0.5) is the center.\n    \"referring\": {\n      \"left\": Double,\n      \"top\": Double\n    },\n    // The anchor point of the canvas.\n    \"reference\": {\n      \"left\": Double,\n      \"top\": Double\n    },\n    // The offset between the two anchor points.\n    \"offset\": {\n      \"y\": Integer,\n      \"x\": Integer\n    }\n  }\n}\n\n// Example.\n// The media is scaled to cover the whole width of the canvas and is placed in the upper left corner.\n{\n  \"horizontalCoverage\": 1.0,\n  \"anchorOffset\": {\n    \"referring\": {\n      \"left\": 0.0,\n      \"top\": 0.0\n    },\n    \"offset\": {\n      \"y\": 0,\n      \"x\": 0\n    },\n    \"reference\": {\n      \"left\": 0.0,\n      \"top\": 0.0\n    }\n  }\n}\n\n// Example.\n// The media is scaled to cover 20% of the width of the canvas and is placed in the lower right corner\n// with an offset of -10px on both x and y axis so that it does not touch the canvas' border.\n{\n  \"horizontalCoverage\": 0.2,\n  \"anchorOffset\": {\n    \"referring\": {\n      \"left\": 1.0,\n      \"top\": 1.0\n    },\n    \"offset\": {\n      \"y\": -10,\n      \"x\": -10\n    },\n    \"reference\": {\n      \"left\": 1.0,\n      \"top\": 1.0\n    }\n  }\n}",
            "title": "Layout Definition"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#operation-example",
            "text": "<operation\n  id=\"composite\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Composite\">\n  <configurations>\n    <configuration key=\"source-flavor-upper\">presentation/trimmed</configuration>\n    <configuration key=\"source-flavor-lower\">presenter/trimmed</configuration>\n    <configuration key=\"source-tags-upper\">comp,rss</configuration>\n    <configuration key=\"source-tags-lower\">comp,rss</configuration>\n    <configuration key=\"source-tags-watermark\">branding</configuration>\n    <configuration key=\"source-flavor-watermark\">image/work</configuration>\n    <configuration key=\"source-url-watermark\">file:///Users/me/logo.jpg</configuration>\n    <configuration key=\"encoding-profile\">composite</configuration>\n    <configuration key=\"target-tags\">composite,rss,atom,archive</configuration>\n    <configuration key=\"target-flavor\">composite/delivery</configuration>\n    <configuration key=\"output-resolution\">1900x1080</configuration>\n    <configuration key=\"output-background\">red</configuration>\n    <configuration key=\"layout\">topleft</configuration>\n    <configuration key=\"layout-topleft\">\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}};\n      {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":0.0,\"top\":0.0}}};\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":1.0,\"top\":0.0}}}\n    </configuration>\n    <configuration key=\"layout-topright\">\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}};\n      {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":0.0}}};\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":0.0,\"top\":0.0}}}\n    </configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/",
            "text": "Concat workflow operation handler\n\n\n FFMPEG 1.1 is required for the encoding profile related to this operation! \n\n\nOverview\n\n\nThe \"concat\" operation handler has been created to concatenate multiple video tracks into one video track. The concatenation process uses the ffmpeg scale filter which is always re-encoding the videos, this means the resulting video has most likely a loss of quality.\n\n\n\n\nThe internal ffmpeg command is using the following filters:  scale, pad and setdar for scaling all videos to a similar size including letterboxing, aevalsrc for creating silent audio streams and of course the concat for the actual concatenation step. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide\n\n\nSample complex concat filter command\n\n\n-filter_complex \"[0:v]scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[b];[1:v]scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[c];[2:v]scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[d];aevalsrc=0::d=1[silent];[b][0:a][c][silent][d][2:a]concat=n=3:v=1:a=1[v][a]\" -map '[v]' -map '[a]'\n\n\n\nUsage\n\n\nThis operation is quite similar to the compose operation. The only difference is that the input properties are not only limited to one \"source-flavor\" and \"source-tag\". The operation supports multiple flavor and tags as input.  To add multiple source, add different key with the prefix \"source-flavor-\"/\"source-tag-\" and an incremental number starting with 0. For example:\n\n\n\n\nsource-flavor-0\n\n\nsource-flavor-1\n\n\nsource-flavor-..\n\n\n\n\nConfiguration keys\n\n\n\n\n\n\n\n\nKey\n\n\nRequired\n\n\nDescription\n\n\nDefault Value\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nsource-flavor-part-X\n\n\nfalse\n\n\nAn iterative list of part/flavor to use as input track.\n\n\nNULL\n\n\n\n\n\n\n\n\npresenter/trimmed\n\n\nsource-tag-part-X\n\n\nfalse\n\n\nAn iterative list of part/tag to use as input track.\n\n\nNULL\n\n\n\n\n\n\nsource-to-concate\n\n\nsource-flavor-part-X-mandatory\n\n\nfalse\n\n\nDefine the flavor part-X as an optional track for concatenation.\n\n\nfalse\n\n\n\n\n\n\nsource-tag-part-X-mandatory\n\n\nfalse\n\n\nDefine the tag part-X as an optional track for concatenation.\n\n\nfalse\n\n\ntrue\n\n\n\n\n\n\nencoding-profile\n\n\ntrue\n\n\nDefine the encoding-profile to use for the concatenation operation. See example of profile below.\n\n\nNULL\n\n\nconcat\n\n\n\n\n\n\ntarget-flavor\n\n\ntrue\n\n\nDefine the flavor(s) to add to the output track.\n\n\nNULL\n\n\npresenter/concat\n\n\n\n\n\n\ntarget-tags\n\n\nfalse\n\n\nDefine the tag(s) to add to the output track\n\n\nNULL\n\n\nengage-download\n\n\n\n\n\n\noutput-resolution\n\n\ntrue\n\n\nDefine the output resolution in width, height or take it from one of the given parts\n\n\nNULL\n\n\n1900x1080, part-1\n\n\n\n\n\n\n\n\nExample\n\n\nExample of an concat operation in a workflow definition.\n\n\n<!-- Add intro and outro part to the presenter track -->\n<operation\n  id=\"concat\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Concatenate the presenter track and the intro/outro videos.\">\n  <configurations>\n    <configuration key=\"source-flavor-part-0\">intro/source</configuration>\n    <configuration key=\"source-flavor-part-1\">presenter/trimmed</configuration>\n    <configuration key=\"source-flavor-part-1-mandatory\">true</configuration>\n    <configuration key=\"source-flavor-part-2\">outro/source</configuration>\n    <configuration key=\"target-flavor\">presenter/concat</configuration>\n    <configuration key=\"target-tags\">engage-download,engage-streaming</configuration>\n    <configuration key=\"encoding-profile\">concat</configuration>\n    <configuration key=\"output-resolution\">1920x1080</configuration>\n  </configurations>\n</operation>\n\n\n\nEncoding profile\n\n\nThe encoding profile command must contain the the #{concatCommand} parameter.\n\n\n# Concat\nprofile.concat.name = concat\nprofile.concat.input = visual\nprofile.concat.output = visual\nprofile.concat.suffix = -concatenated.mp4\nprofile.concat.mimetype = video/mp4\nprofile.concat.ffmpeg.command = #{concatCommand} -acodec libfaac -b:a 128k -vcodec mpeg4 -b:v 1200k\n-flags +aic+mv4 #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Concat"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#concat-workflow-operation-handler",
            "text": "FFMPEG 1.1 is required for the encoding profile related to this operation!",
            "title": "Concat workflow operation handler"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#overview",
            "text": "The \"concat\" operation handler has been created to concatenate multiple video tracks into one video track. The concatenation process uses the ffmpeg scale filter which is always re-encoding the videos, this means the resulting video has most likely a loss of quality.   The internal ffmpeg command is using the following filters:  scale, pad and setdar for scaling all videos to a similar size including letterboxing, aevalsrc for creating silent audio streams and of course the concat for the actual concatenation step. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide",
            "title": "Overview"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#sample-complex-concat-filter-command",
            "text": "-filter_complex \"[0:v]scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[b];[1:v]scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[c];[2:v]scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[d];aevalsrc=0::d=1[silent];[b][0:a][c][silent][d][2:a]concat=n=3:v=1:a=1[v][a]\" -map '[v]' -map '[a]'",
            "title": "Sample complex concat filter command"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#usage",
            "text": "This operation is quite similar to the compose operation. The only difference is that the input properties are not only limited to one \"source-flavor\" and \"source-tag\". The operation supports multiple flavor and tags as input.  To add multiple source, add different key with the prefix \"source-flavor-\"/\"source-tag-\" and an incremental number starting with 0. For example:   source-flavor-0  source-flavor-1  source-flavor-..",
            "title": "Usage"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#configuration-keys",
            "text": "Key  Required  Description  Default Value  Example      source-flavor-part-X  false  An iterative list of part/flavor to use as input track.  NULL     presenter/trimmed  source-tag-part-X  false  An iterative list of part/tag to use as input track.  NULL    source-to-concate  source-flavor-part-X-mandatory  false  Define the flavor part-X as an optional track for concatenation.  false    source-tag-part-X-mandatory  false  Define the tag part-X as an optional track for concatenation.  false  true    encoding-profile  true  Define the encoding-profile to use for the concatenation operation. See example of profile below.  NULL  concat    target-flavor  true  Define the flavor(s) to add to the output track.  NULL  presenter/concat    target-tags  false  Define the tag(s) to add to the output track  NULL  engage-download    output-resolution  true  Define the output resolution in width, height or take it from one of the given parts  NULL  1900x1080, part-1",
            "title": "Configuration keys"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#example",
            "text": "Example of an concat operation in a workflow definition.  <!-- Add intro and outro part to the presenter track -->\n<operation\n  id=\"concat\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Concatenate the presenter track and the intro/outro videos.\">\n  <configurations>\n    <configuration key=\"source-flavor-part-0\">intro/source</configuration>\n    <configuration key=\"source-flavor-part-1\">presenter/trimmed</configuration>\n    <configuration key=\"source-flavor-part-1-mandatory\">true</configuration>\n    <configuration key=\"source-flavor-part-2\">outro/source</configuration>\n    <configuration key=\"target-flavor\">presenter/concat</configuration>\n    <configuration key=\"target-tags\">engage-download,engage-streaming</configuration>\n    <configuration key=\"encoding-profile\">concat</configuration>\n    <configuration key=\"output-resolution\">1920x1080</configuration>\n  </configurations>\n</operation>",
            "title": "Example"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#encoding-profile",
            "text": "The encoding profile command must contain the the #{concatCommand} parameter.  # Concat\nprofile.concat.name = concat\nprofile.concat.input = visual\nprofile.concat.output = visual\nprofile.concat.suffix = -concatenated.mp4\nprofile.concat.mimetype = video/mp4\nprofile.concat.ffmpeg.command = #{concatCommand} -acodec libfaac -b:a 128k -vcodec mpeg4 -b:v 1200k\n-flags +aic+mv4 #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Encoding profile"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/",
            "text": "CoverImageWorkflowOperationHandler\n\n\nDescription\n\n\nThe CoverImageWorkflowOperationHandler generates a cover image based on an XSLT transformation which results in an SVG\nimage that is rasterized as PNG as a last step.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nName\n\n\nType\n\n\nExample\n\n\nDefault Value\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nstylesheet *\n\n\nURL\n\n\nfile:///etc/opencast/branding/coverimage.xsl\n\n\n-\n\n\nFile URI to the XSL stylesheet used to generate the SVG image\n\n\n\n\n\n\nmetadata\n\n\nXML\n\n\nHello!\n\n\n-\n\n\nXML string which is passed to the XSL transformation. If parameter is not given, a default XML is handed to the transformation\n\n\n\n\n\n\nwidth *\n\n\nint\n\n\n1920\n\n\n-\n\n\nWidth of the resulting image\n\n\n\n\n\n\nheight *\n\n\nint\n\n\n1080\n\n\n-\n\n\nHeight of the resulting image\n\n\n\n\n\n\nposterimage-flavor\n\n\nFlavor\n\n\nimage/poster\n\n\n-\n\n\nFlavor of a poster image which may be used as a part of the cover image (e.g. as a background)\n\n\n\n\n\n\nposterimage\n\n\nURL\n\n\nhttp://flickr.com/posterimage.jpg\n\n\n-\n\n\nURL to a custom poster image instead of using one out of the media package\n\n\n\n\n\n\ntarget-flavor *\n\n\nFlavor\n\n\nimage/cover\n\n\n-\n\n\nFlavor of the resulting cover image\n\n\n\n\n\n\ntarget-tags\n\n\nString\n\n\narchive,download\n\n\n-\n\n\nComma separated list of tags to be applied to the resulting attachment.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"cover-image\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Create a cover image\">\n  <configurations>\n    <configuration key=\"stylesheet\">file:///etc/opencast/branding/coverimage/opencast-default.xsl</configuration>\n    <configuration key=\"metadata\"><![CDATA[<meta><title>my custom title</title><special>very special</special></meta>]]></configuration>\n    <configuration key=\"width\">1920</configuration>\n    <configuration key=\"height\">1080</configuration>\n    <configuration key=\"posterimage-flavor\">presenter/player+preview</configuration>\n    <configuration key=\"target-flavor\">image/cover</configuration>\n </configurations>\n</operation>\n\n\n\nTemplate\n\n\nAs a starting point for your own template you best take a look at file /coverimage/default-template.xsl in the resources\nof the bundle opencast-conductor. The metadata XML, which is passed to the cover image service in case you don't pass\nyour own, looks like the following example:\n\n\n<?xml version=\"1.0\"?>\n<metadata>\n  <title>Puppy Love</title>\n  <date>2014-03-24T11:21:00Z</date>\n  <license>All rights reserved</license>\n  <series>Superbowl Commercials</series>\n  <contributors>Budweiser</contributors>\n  <creators>Budweiser</creators>\n  <subjects>Commercial</subjects>\n</metadata>",
            "title": "Cover Image"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#coverimageworkflowoperationhandler",
            "text": "",
            "title": "CoverImageWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#description",
            "text": "The CoverImageWorkflowOperationHandler generates a cover image based on an XSLT transformation which results in an SVG\nimage that is rasterized as PNG as a last step.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#parameter-table",
            "text": "Name  Type  Example  Default Value  Description      stylesheet *  URL  file:///etc/opencast/branding/coverimage.xsl  -  File URI to the XSL stylesheet used to generate the SVG image    metadata  XML  Hello!  -  XML string which is passed to the XSL transformation. If parameter is not given, a default XML is handed to the transformation    width *  int  1920  -  Width of the resulting image    height *  int  1080  -  Height of the resulting image    posterimage-flavor  Flavor  image/poster  -  Flavor of a poster image which may be used as a part of the cover image (e.g. as a background)    posterimage  URL  http://flickr.com/posterimage.jpg  -  URL to a custom poster image instead of using one out of the media package    target-flavor *  Flavor  image/cover  -  Flavor of the resulting cover image    target-tags  String  archive,download  -  Comma separated list of tags to be applied to the resulting attachment.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#operation-example",
            "text": "<operation\n  id=\"cover-image\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Create a cover image\">\n  <configurations>\n    <configuration key=\"stylesheet\">file:///etc/opencast/branding/coverimage/opencast-default.xsl</configuration>\n    <configuration key=\"metadata\"><![CDATA[<meta><title>my custom title</title><special>very special</special></meta>]]></configuration>\n    <configuration key=\"width\">1920</configuration>\n    <configuration key=\"height\">1080</configuration>\n    <configuration key=\"posterimage-flavor\">presenter/player+preview</configuration>\n    <configuration key=\"target-flavor\">image/cover</configuration>\n </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/coverimage-woh/#template",
            "text": "As a starting point for your own template you best take a look at file /coverimage/default-template.xsl in the resources\nof the bundle opencast-conductor. The metadata XML, which is passed to the cover image service in case you don't pass\nyour own, looks like the following example:  <?xml version=\"1.0\"?>\n<metadata>\n  <title>Puppy Love</title>\n  <date>2014-03-24T11:21:00Z</date>\n  <license>All rights reserved</license>\n  <series>Superbowl Commercials</series>\n  <contributors>Budweiser</contributors>\n  <creators>Budweiser</creators>\n  <subjects>Commercial</subjects>\n</metadata>",
            "title": "Template"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/",
            "text": "DefaultsWorkflowOperation\n\n\nDescription\n\n\nThe DefaultsWorkflowOperationHandler is used to define default workflow configuration values that are in effect in cases where a workflow instance is started without the user interface being invoked, with the result that no configuration of the workflow instance has taken place. The defaults specified by this handler will be applied for configuration keys that have not been specified but won't overwrite existing values.\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nkey\n\n\nhello world\n\n\nThis would set the workflow configuration \"key\" to the value \"hello world\" if - and only if - the key is undefined.\n\n\n-\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"defaults\"\n  description=\"Applying default values\">\n  <configurations>\n    <configuration key=\"key\">hello world</configuration>\n  </configurations>\n</operation>",
            "title": "Defaults"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/#defaultsworkflowoperation",
            "text": "",
            "title": "DefaultsWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/#description",
            "text": "The DefaultsWorkflowOperationHandler is used to define default workflow configuration values that are in effect in cases where a workflow instance is started without the user interface being invoked, with the result that no configuration of the workflow instance has taken place. The defaults specified by this handler will be applied for configuration keys that have not been specified but won't overwrite existing values.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  example  description  default value      key  hello world  This would set the workflow configuration \"key\" to the value \"hello world\" if - and only if - the key is undefined.  -",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/#operation-example",
            "text": "<operation\n  id=\"defaults\"\n  description=\"Applying default values\">\n  <configurations>\n    <configuration key=\"key\">hello world</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/",
            "text": "VideoEditorWorkflowOperationHandler\n\n\nDescription\n\n\nThe editor operation provides the UI for editing trim hold state and processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"*/work\"\n\n\nthe subtype of all media files in the best available quality and in a codec that can be processed by the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only the subtype is important. All needed videos should be available within this flavor\n\n\nEMPTY\n\n\n\n\n\n\npreview-flavors\n\n\n\"*/preview\"\n\n\nthe subtype of the media files that should be used for the preview player. This is an HTML5 player so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors.\n\n\nEMPTY\n\n\n\n\n\n\nsmil-flavors\n\n\n\"*/smil\"\n\n\nthe smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil will be favored, if this is not available the first in the list will be used.\n\n\nEMPTY\n\n\n\n\n\n\nskipped-flavors\n\n\n\"*/work\"\n\n\nthe subtype of all media files that should be used in the following processing, if the editor operation was skipped\n\n\nEMPTY\n\n\n\n\n\n\n\n\nVideo Editor UI\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"editor\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Waiting for user to review / video edit recording\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/work</configuration>\n    <configuration key=\"preview-flavors\">*/preview</configuration>\n    <configuration key=\"skipped-flavors\">*/work</configuration>\n    <configuration key=\"smil-flavors\">*/smil</configuration>\n    <configuration key=\"target-smil-flavor\">episode/smil</configuration>\n    <configuration key=\"target-flavor-subtype\">trimmed</configuration>\n  </configurations>\n</operation>",
            "title": "Editor"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#videoeditorworkflowoperationhandler",
            "text": "",
            "title": "VideoEditorWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#description",
            "text": "The editor operation provides the UI for editing trim hold state and processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  \"*/work\"  the subtype of all media files in the best available quality and in a codec that can be processed by the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only the subtype is important. All needed videos should be available within this flavor  EMPTY    preview-flavors  \"*/preview\"  the subtype of the media files that should be used for the preview player. This is an HTML5 player so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors.  EMPTY    smil-flavors  \"*/smil\"  the smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil will be favored, if this is not available the first in the list will be used.  EMPTY    skipped-flavors  \"*/work\"  the subtype of all media files that should be used in the following processing, if the editor operation was skipped  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#video-editor-ui",
            "text": "",
            "title": "Video Editor UI"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#operation-example",
            "text": "<operation\n  id=\"editor\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Waiting for user to review / video edit recording\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/work</configuration>\n    <configuration key=\"preview-flavors\">*/preview</configuration>\n    <configuration key=\"skipped-flavors\">*/work</configuration>\n    <configuration key=\"smil-flavors\">*/smil</configuration>\n    <configuration key=\"target-smil-flavor\">episode/smil</configuration>\n    <configuration key=\"target-flavor-subtype\">trimmed</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/email-woh/",
            "text": "EmailWorkflowOperation\n\n\nDescription\n\n\nThe EmailWorkflowOperationHandler queries the SMTP Service to send an email with the provided parameters. It is useful to send email notifications that some operation(s) have been completed or that some error(s) occurred in a workflow.\nThe mail body consists of a single line of the form: \n (\n).\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nto\n\n\n\"my-email-account@my-email-domain.org\"\n\n\nIt specifies the field \"to\" of the email, i.e. the email account the email will be sent to.\n\n\nEMPTY\n\n\n\n\n\n\nsubject\n\n\nOperation has been completed\n\n\nSpecifies the mail subject\n\n\nEMPTY\n\n\n\n\n\n\n\n\nSome other email parameters can be customized in the SMTP Service configuration\n\n\nOperation Example\n\n\n<operation\n    id=\"send-email\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Sends email\">\n    <configurations>\n        <configuration key=\"to\">root@localhost</configuration>\n        <configuration key=\"subject\">Failure processing a mediapackage</configuration>\n    </configurations>\n</operation>",
            "title": "Email"
        },
        {
            "location": "/workflowoperationhandlers/email-woh/#emailworkflowoperation",
            "text": "",
            "title": "EmailWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/email-woh/#description",
            "text": "The EmailWorkflowOperationHandler queries the SMTP Service to send an email with the provided parameters. It is useful to send email notifications that some operation(s) have been completed or that some error(s) occurred in a workflow.\nThe mail body consists of a single line of the form:   ( ).",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/email-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      to  \"my-email-account@my-email-domain.org\"  It specifies the field \"to\" of the email, i.e. the email account the email will be sent to.  EMPTY    subject  Operation has been completed  Specifies the mail subject  EMPTY     Some other email parameters can be customized in the SMTP Service configuration",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/email-woh/#operation-example",
            "text": "<operation\n    id=\"send-email\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Sends email\">\n    <configurations>\n        <configuration key=\"to\">root@localhost</configuration>\n        <configuration key=\"subject\">Failure processing a mediapackage</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/",
            "text": "ExtractTextWorkflowOperation\n\n\nDescription\n\n\nThe ExtractTextWorkflowOperation will try to extract test from a video using Tesseract OCR.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresentation/work\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\nsource-tags\n\n\ntext\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-tags\n\n\nengage\n\n\nSpecifies the tags for the produces media.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"extract-text\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Extracting text from presentation segments\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-tags\">engage,archive</configuration>\n      </configurations>\n</operation>",
            "title": "Extract Text"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/#extracttextworkflowoperation",
            "text": "",
            "title": "ExtractTextWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/#description",
            "text": "The ExtractTextWorkflowOperation will try to extract test from a video using Tesseract OCR.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presentation/work  Specifies which media should be processed.    source-tags  text  Specifies which media should be processed.    target-tags  engage  Specifies the tags for the produces media.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/#operation-example",
            "text": "<operation\n      id=\"extract-text\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Extracting text from presentation segments\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-tags\">engage,archive</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/",
            "text": "HttpNotificationWorkflowOperation\n\n\nDescription\n\n\nOpencast can through this operation notify any HTTP endpoint about the process of the workflow.\n\n\nParameter Table\n\n\nA parameter that is always posted is the workflow instance identifier in the parameter named \nworkflowInstanceId\n containing the current workflow\u2019s identifier.\n\n\n\n\n\n\n\n\nKey\n\n\nRequired\n\n\nDescription\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nurl\n\n\ntrue\n\n\nThe target url to notify\n\n\nhttp://test.ch\n\n\n\n\n\n\nsubject\n\n\nfalse\n\n\nThe name of the event to notify from. The following events are planned: importing_started, imported, prepared, processing_started, published\n\n\nimporting_started\n\n\n\n\n\n\nmessage\n\n\nfalse\n\n\nData supporting the notification. Think of this as the body of an e-mail\n\n\ninternal::25\n\n\n\n\n\n\nmethod\n\n\nfalse\n\n\nSupported methods are \"put\", \"post\". If no method is specified, \"post\" is used by default\n\n\npost\n\n\n\n\n\n\nmax-retry\n\n\nfalse\n\n\nThe maximal number of notification attempts. The default value is 5\n\n\n5\n\n\n\n\n\n\ntimeout\n\n\nfalse\n\n\nThe timeout in seconds for the notification request: The default value is 10\n\n\n10\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"http-notify\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"error\"\n  description=\"Notify test\">\n  <configurations>\n    <configuration key=\"url\">http://www.test.ch</configuration>\n    <configuration key=\"subject\">importing-started</configuration>\n    <configuration key=\u201cmessage\u201d>internal::25</configuration>\n    <configuration key=\u201cmethod\u201d>put</configuration>\n    <configuration key=\"max-retry\">3</configuration>\n    <configuration key=\"timeout\">5</configuration>\n  </configurations>\n</operation>",
            "title": "HTTP Notify"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/#httpnotificationworkflowoperation",
            "text": "",
            "title": "HttpNotificationWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/#description",
            "text": "Opencast can through this operation notify any HTTP endpoint about the process of the workflow.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/#parameter-table",
            "text": "A parameter that is always posted is the workflow instance identifier in the parameter named  workflowInstanceId  containing the current workflow\u2019s identifier.     Key  Required  Description  Example      url  true  The target url to notify  http://test.ch    subject  false  The name of the event to notify from. The following events are planned: importing_started, imported, prepared, processing_started, published  importing_started    message  false  Data supporting the notification. Think of this as the body of an e-mail  internal::25    method  false  Supported methods are \"put\", \"post\". If no method is specified, \"post\" is used by default  post    max-retry  false  The maximal number of notification attempts. The default value is 5  5    timeout  false  The timeout in seconds for the notification request: The default value is 10  10",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/#operation-example",
            "text": "<operation\n  id=\"http-notify\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"error\"\n  description=\"Notify test\">\n  <configurations>\n    <configuration key=\"url\">http://www.test.ch</configuration>\n    <configuration key=\"subject\">importing-started</configuration>\n    <configuration key=\u201cmessage\u201d>internal::25</configuration>\n    <configuration key=\u201cmethod\u201d>put</configuration>\n    <configuration key=\"max-retry\">3</configuration>\n    <configuration key=\"timeout\">5</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/",
            "text": "ImageWorkflowOperation\n\n\nDescription\n\n\nThe ImageWorkflowOperation will extract a still image from a video using FFmpeg and a given encoding profile.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/source\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/work\n\n\nSpecifies the flavor the new files will get.\n\n\n\n\n\n\nsource-tags\n\n\nengage\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-tags\n\n\nengage\n\n\nSpecifies the tags the new files will get.\n\n\n\n\n\n\nencoding-profile\n\n\nsearch-cover.http\n\n\nThe encoding profile to use.\n\n\n\n\n\n\ntime\n\n\n1\n\n\nTime in seconds where the image should be taken.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encoding presenter (camera) to search result preview image\">\n      <configurations>\n            <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-flavor\">presenter/search+preview</configuration>\n            <configuration key=\"target-tags\">engage</configuration>\n            <configuration key=\"encoding-profile\">search-cover.http</configuration>\n            <configuration key=\"time\">1</configuration>\n      </configurations>\n</operation>",
            "title": "Image"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#imageworkflowoperation",
            "text": "",
            "title": "ImageWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#description",
            "text": "The ImageWorkflowOperation will extract a still image from a video using FFmpeg and a given encoding profile.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/source  Specifies which media should be processed.    target-flavor  presenter/work  Specifies the flavor the new files will get.    source-tags  engage  Specifies which media should be processed.    target-tags  engage  Specifies the tags the new files will get.    encoding-profile  search-cover.http  The encoding profile to use.    time  1  Time in seconds where the image should be taken.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#operation-example",
            "text": "<operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encoding presenter (camera) to search result preview image\">\n      <configurations>\n            <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-flavor\">presenter/search+preview</configuration>\n            <configuration key=\"target-tags\">engage</configuration>\n            <configuration key=\"encoding-profile\">search-cover.http</configuration>\n            <configuration key=\"time\">1</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/",
            "text": "ImageToVideo Workflow Operation Handler\n\n\nDescription\n\n\nThe ImageToVideo Workflow Operation Handler allows to create a video track from a source image.\n\n\nParameters table\n\n\nTags and flavors can be used in combination. But combined they should match one image.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-tag\n*\n\n\nintro/source\n\n\nThe \"tag\" of the image to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor\n*\n\n\nintro\n\n\nThe \"flavor\" of the image to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\ncomposite,rss,atom,archive\n\n\nThe tags to apply to the output video track\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\nintro/work\n\n\nThe flavor to apply to the output video track\n\n\nEMPTY\n\n\n\n\n\n\nduration\n*\n\n\n5\n\n\nThe length of the output video in seconds.\n\n\nEMPTY\n\n\n\n\n\n\nprofile\n*\n\n\nimage-movie\n\n\nDefine the encoding-profile to use to create the output video. See example of profile below.\n\n\nEMPTY\n\n\n\n\n\n\n\n\n* \nmandatory\n\n\nOperation example\n\n\n<operation\n  id=\"image-to-video\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Composite\">\n  <configurations>\n    <configuration key=\"source-tag\">presentation/trimmed</configuration>\n    <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n    <configuration key=\"target-tags\">comp</configuration>\n    <configuration key=\"target-flavor\">intro/work</configuration>\n    <configuration key=\"duration\">10</configuration>\n<configuration key=\"profile\">image-movie</configuration>\n  </configurations>\n</operation>\n\n\n\nEncoding profile example\n\n\n# Image to video\nprofile.image-movie.name = image to video\nprofile.image-movie.input = image\nprofile.image-movie.output = visual\nprofile.image-movie.suffix = -image-video.mp4\nprofile.image-movie.mimetype = video/mp4\nprofile.image-movie.ffmpeg.command = -loop 1 -i #{in.video.path} -c:v libx264 -r 25 -t #{time} -pix_fmt yuv420p #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Image to Video"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#imagetovideo-workflow-operation-handler",
            "text": "",
            "title": "ImageToVideo Workflow Operation Handler"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#description",
            "text": "The ImageToVideo Workflow Operation Handler allows to create a video track from a source image.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#parameters-table",
            "text": "Tags and flavors can be used in combination. But combined they should match one image.     configuration keys  example  description  default value      source-tag *  intro/source  The \"tag\" of the image to use as a source input  EMPTY    source-flavor *  intro  The \"flavor\" of the image to use as a source input  EMPTY    target-tags  composite,rss,atom,archive  The tags to apply to the output video track  EMPTY    target-flavor  intro/work  The flavor to apply to the output video track  EMPTY    duration *  5  The length of the output video in seconds.  EMPTY    profile *  image-movie  Define the encoding-profile to use to create the output video. See example of profile below.  EMPTY     *  mandatory",
            "title": "Parameters table"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#operation-example",
            "text": "<operation\n  id=\"image-to-video\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Composite\">\n  <configurations>\n    <configuration key=\"source-tag\">presentation/trimmed</configuration>\n    <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n    <configuration key=\"target-tags\">comp</configuration>\n    <configuration key=\"target-flavor\">intro/work</configuration>\n    <configuration key=\"duration\">10</configuration>\n<configuration key=\"profile\">image-movie</configuration>\n  </configurations>\n</operation>",
            "title": "Operation example"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#encoding-profile-example",
            "text": "# Image to video\nprofile.image-movie.name = image to video\nprofile.image-movie.input = image\nprofile.image-movie.output = visual\nprofile.image-movie.suffix = -image-video.mp4\nprofile.image-movie.mimetype = video/mp4\nprofile.image-movie.ffmpeg.command = -loop 1 -i #{in.video.path} -c:v libx264 -r 25 -t #{time} -pix_fmt yuv420p #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Encoding profile example"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/",
            "text": "IncidentCreatorWorkflowOperationHandler\n\n\nDescription\n\n\nThe IncidentCreatorWorkflowOperationHandler creates an incident on a dummy job used for integration testing.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\ncode\n\n\n2\n\n\nThe code number of the incident to produce.\n\n\n1\n\n\n\n\n\n\nseverity\n\n\nWARNING\n\n\nThe severity. See Incident.Severity enum.\n\n\nINFO\n\n\n\n\n\n\ndetails\n\n\n\"tagged,+rss\" / \"-rss,+tagged\"\n\n\nSome details: title=content;title=content;...\n\n\nEMPTY\n\n\n\n\n\n\nparams\n\n\n\"presentation/tagged\"\n\n\nSome params: key=value;key=value;...\n\n\nEMPTY\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"incident\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Provoke a job incident\">\n  <configurations>\n    <configuration key=\"code\">3</configuration>\n    <configuration key=\"severity\">INFO</configuration>\n    <configuration key=\"details\">exception=content;id=325</configuration>\n    <configuration key=\"params\">track=track-1;profile=full</configuration>\n  </configurations>\n</operation>",
            "title": "Incident"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/#incidentcreatorworkflowoperationhandler",
            "text": "",
            "title": "IncidentCreatorWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/#description",
            "text": "The IncidentCreatorWorkflowOperationHandler creates an incident on a dummy job used for integration testing.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      code  2  The code number of the incident to produce.  1    severity  WARNING  The severity. See Incident.Severity enum.  INFO    details  \"tagged,+rss\" / \"-rss,+tagged\"  Some details: title=content;title=content;...  EMPTY    params  \"presentation/tagged\"  Some params: key=value;key=value;...  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/#operation-example",
            "text": "<operation\n  id=\"incident\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Provoke a job incident\">\n  <configurations>\n    <configuration key=\"code\">3</configuration>\n    <configuration key=\"severity\">INFO</configuration>\n    <configuration key=\"details\">exception=content;id=325</configuration>\n    <configuration key=\"params\">track=track-1;profile=full</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/",
            "text": "IngestDownloadWorkflowOperationHandler\n\n\nDescription\n\n\nWith the IngestDownloadWorkflowOperationHandler it's possible to initially download external URI's from mediapackage\nelements and store them to the working file repository. The external element URI's are then rewritten to the stored\nworking file repository URI.\n\n\nIn case of having external element URI's showing to a different Opencast working file repository, it's also possible to\ndelete them after downloading it by activating the \"delete-external\" option.\n\n\nThis operation is originally implemented to get rid of remaining files on ingest working file repositories.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\ndelete-external\n\n\n\"true\"\n\n\nWhether to try to delete external working file repository URIs.\n\n\nFALSE\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"ingest-download\"\n  fail-on-error=\"false\"\n  description=\"Downloads external artifacts to the working file repository\">\n  <configurations>\n    <configuration key=\"delete-external\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Ingest-Download"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/#ingestdownloadworkflowoperationhandler",
            "text": "",
            "title": "IngestDownloadWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/#description",
            "text": "With the IngestDownloadWorkflowOperationHandler it's possible to initially download external URI's from mediapackage\nelements and store them to the working file repository. The external element URI's are then rewritten to the stored\nworking file repository URI.  In case of having external element URI's showing to a different Opencast working file repository, it's also possible to\ndelete them after downloading it by activating the \"delete-external\" option.  This operation is originally implemented to get rid of remaining files on ingest working file repositories.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      delete-external  \"true\"  Whether to try to delete external working file repository URIs.  FALSE",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/#operation-example",
            "text": "<operation\n  id=\"ingest-download\"\n  fail-on-error=\"false\"\n  description=\"Downloads external artifacts to the working file repository\">\n  <configurations>\n    <configuration key=\"delete-external\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/",
            "text": "InspectWorkflowOperation\n\n\nDescription\n\n\nThe InspectWorkflowOperation is used to inspect all tracks of a media package. It tries to verify if they are valid media tracks.\n\n\nOperation Example\n\n\n<operation\n    id=\"inspect\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Inspecting the media package\">\n</operation>",
            "title": "Inspect"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#inspectworkflowoperation",
            "text": "",
            "title": "InspectWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#description",
            "text": "The InspectWorkflowOperation is used to inspect all tracks of a media package. It tries to verify if they are valid media tracks.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#operation-example",
            "text": "<operation\n    id=\"inspect\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Inspecting the media package\">\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/",
            "text": "NormalizeAudioWorkflowOperationHandler\n\n\nDescription\n\n\nThe NormalizeAudioiWorkflowOperationHandler normalizes the first audio stream of a video or audio track through SoX (http://sox.sourceforge.net/), it creates a new track with a reference to the original track which can be flavored and tagged.\nThis workflow operation handler can be used with audio and/or video files, at least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs:\n\n\nUsed with Audio only file (forceTranscode is deactivated):\n\n\n\n\nCheck if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.\n\n\nRun audio normalization with original audio file.\n\n\nReplace the normalized audio file with the original.\n\n\nWrite analyzed audio metadata to the track's mediapackage.\n\n\nDelete all used temporary files\n\n\n\n\nUsed with Audio only file and forceTranscode activated:\n\n\n\n\nCheck if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.\n\n\n(forceTranscode step) Encode audio to FLAC. (Must be used when given audio file format is not supported by SoX)\n\n\nRun audio normalization with original audio file or encoded FLAC audio file.\n\n\n(forceTranscode step) Mux normalized audio file back to the original audio container by replacing it with the original audio stream.\n\n\nWrite analyzed audio metadata to the track's mediapackage.\n\n\nDelete all used temporary files\n\n\n\n\nUsed with Video file:\n\n\n\n\nExtract audio file encoded as FLAC audio and save it temporary in a collection\n\n\nCheck if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.\n\n\nRun audio normalization with extracted audio file.\n\n\nMux normalized audio file back to the original video container by replacing it with original audio stream.\n\n\nWrite analyzed audio metadata to the track's mediapackage.\n\n\nDelete all used temporary files\n\n\n\n\nExample result track:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<track ref=\"track:track-2\" type=\"presenter/normalized\" id=\"70626874-17d2-480d-9d30-c10f0824961c\">\n    <mimetype>audio/x-flv</mimetype>\n    <tags>\n        <tag>norm</tag>\n    </tags>\n    <url>http://localhost:8080/files/mediapackage/8a510168-9102-425f-81e9-0943774dd229/70626874-17d2-480d-9d30-c10f0824961c/demo_slide_video_6min_buss.flv</url>\n    <checksum type=\"md5\">4e30d7d4305b0793f301816e796471db</checksum>\n    <duration>414407</duration>\n    <audio id=\"audio-1\">\n        <device/>\n        <encoder type=\"MPEG Audio\"/>\n        <bitdepth>16</bitdepth>\n        <channels>2</channels>\n        <bitrate>64000.0</bitrate>\n        <peakleveldb>-4.03</peakleveldb> <!-- NEW -->\n        <rmsleveldb>-30.54</rmsleveldb> <!-- NEW -->\n        <rmspeakdb>-10.85</rmspeakdb> <!-- NEW -->\n    </audio>\n</track>\n\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"presentation/work,presenter/work\"\n\n\nThe \"flavors\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor\n\n\n\"presentation/work\"\n\n\nThe \"flavor\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags\n\n\n\"engage,atom,rss\"\n\n\nThe \"tag\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\n\"presentation/normalized\"\n\n\nThe flavor to apply to the normalized file\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\n\"norm\"\n\n\nThe tags to apply to the normalized file\n\n\nEMPTY\n\n\n\n\n\n\ntarget-decibel\n*\n\n\n-30.4\n\n\nThe target RMS Level Decibel\n\n\nEMPTY\n\n\n\n\n\n\nforce-transcode\n\n\n\"true\" or \"false\"\n\n\nWhether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format)\n\n\nFALSE\n\n\n\n\n\n\n\n\n* \nrequired keys\n\n\nOperation Example\n\n\n<operation\n  id=\"normalize-audio\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Normalize audio stream\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/normalized</configuration>\n    <configuration key=\"target-tags\">norm</configuration>\n    <configuration key=\"target-decibel\">-30</configuration>\n    <configuration key=\"force-transcode\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Normalize Audio"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#normalizeaudioworkflowoperationhandler",
            "text": "",
            "title": "NormalizeAudioWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#description",
            "text": "The NormalizeAudioiWorkflowOperationHandler normalizes the first audio stream of a video or audio track through SoX (http://sox.sourceforge.net/), it creates a new track with a reference to the original track which can be flavored and tagged.\nThis workflow operation handler can be used with audio and/or video files, at least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs:",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#used-with-audio-only-file-forcetranscode-is-deactivated",
            "text": "Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.  Run audio normalization with original audio file.  Replace the normalized audio file with the original.  Write analyzed audio metadata to the track's mediapackage.  Delete all used temporary files",
            "title": "Used with Audio only file (forceTranscode is deactivated):"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#used-with-audio-only-file-and-forcetranscode-activated",
            "text": "Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.  (forceTranscode step) Encode audio to FLAC. (Must be used when given audio file format is not supported by SoX)  Run audio normalization with original audio file or encoded FLAC audio file.  (forceTranscode step) Mux normalized audio file back to the original audio container by replacing it with the original audio stream.  Write analyzed audio metadata to the track's mediapackage.  Delete all used temporary files",
            "title": "Used with Audio only file and forceTranscode activated:"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#used-with-video-file",
            "text": "Extract audio file encoded as FLAC audio and save it temporary in a collection  Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.  Run audio normalization with extracted audio file.  Mux normalized audio file back to the original video container by replacing it with original audio stream.  Write analyzed audio metadata to the track's mediapackage.  Delete all used temporary files   Example result track:  <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<track ref=\"track:track-2\" type=\"presenter/normalized\" id=\"70626874-17d2-480d-9d30-c10f0824961c\">\n    <mimetype>audio/x-flv</mimetype>\n    <tags>\n        <tag>norm</tag>\n    </tags>\n    <url>http://localhost:8080/files/mediapackage/8a510168-9102-425f-81e9-0943774dd229/70626874-17d2-480d-9d30-c10f0824961c/demo_slide_video_6min_buss.flv</url>\n    <checksum type=\"md5\">4e30d7d4305b0793f301816e796471db</checksum>\n    <duration>414407</duration>\n    <audio id=\"audio-1\">\n        <device/>\n        <encoder type=\"MPEG Audio\"/>\n        <bitdepth>16</bitdepth>\n        <channels>2</channels>\n        <bitrate>64000.0</bitrate>\n        <peakleveldb>-4.03</peakleveldb> <!-- NEW -->\n        <rmsleveldb>-30.54</rmsleveldb> <!-- NEW -->\n        <rmspeakdb>-10.85</rmspeakdb> <!-- NEW -->\n    </audio>\n</track>",
            "title": "Used with Video file:"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  \"presentation/work,presenter/work\"  The \"flavors\" of the track to use as a source input  EMPTY    source-flavor  \"presentation/work\"  The \"flavor\" of the track to use as a source input  EMPTY    source-tags  \"engage,atom,rss\"  The \"tag\" of the track to use as a source input  EMPTY    target-flavor  \"presentation/normalized\"  The flavor to apply to the normalized file  EMPTY    target-tags  \"norm\"  The tags to apply to the normalized file  EMPTY    target-decibel *  -30.4  The target RMS Level Decibel  EMPTY    force-transcode  \"true\" or \"false\"  Whether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format)  FALSE     *  required keys",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#operation-example",
            "text": "<operation\n  id=\"normalize-audio\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Normalize audio stream\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/normalized</configuration>\n    <configuration key=\"target-tags\">norm</configuration>\n    <configuration key=\"target-decibel\">-30</configuration>\n    <configuration key=\"force-transcode\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/",
            "text": "PostMediapackageWorkflowHandler\n\n\nDescription\n\n\nThis Workflow Operation Handler can be used to send a POST request containing an XML/JSON representation of the Mediapackage processed by the workflow to an external webservice. The service supports HTTP Basic and Digest Authentication.\n\n\nOptions\n\n\n<!--\n    This operation will send a POST request containing the Mediapackage to an\n    external webservice.\n-->\n<operation\n    id=\"post-mediapackage\"\n    fail-on-error=\"false\"\n    exception-handler-workflow=\"error\"\n    description=\"Sending MediaPackage to Lernfunk3\">\n    <configurations>\n        <!-- target url -->\n        <configuration key=\"url\">http://example.com:5000/</configuration>\n        <!-- export format: xml or json -->\n        <configuration key=\"format\">xml</configuration>\n        <!--\n            Disable this on a productive system. If enabled, request bodies\n            etc. will be written to log. If disabled, only errors will be\n            logged.\n        -->\n        <configuration key=\"debug\">no</configuration>\n        <!-- Type of Mediapackage to send (possible values: workflow, search; default: search) -->\n        <configuration key=\"mediapackage.type\">search</configuration>\n        <!-- enable authentication (simple/digest will be detected automatically) -->\n        <configuration key=\"auth.enabled\">yes</configuration>\n        <!-- username for authentication -->\n        <configuration key=\"auth.username\">exportuser</configuration>\n        <!-- password for authentication -->\n        <configuration key=\"auth.password\">secret</configuration>\n        <!-- fields with keys beginning with + will be added to the message body -->\n        <configuration key=\"+source_system\">video.example.com</configuration>\n    </configurations>\n</operation>",
            "title": "Post Media Package"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/#postmediapackageworkflowhandler",
            "text": "",
            "title": "PostMediapackageWorkflowHandler"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/#description",
            "text": "This Workflow Operation Handler can be used to send a POST request containing an XML/JSON representation of the Mediapackage processed by the workflow to an external webservice. The service supports HTTP Basic and Digest Authentication.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/#options",
            "text": "<!--\n    This operation will send a POST request containing the Mediapackage to an\n    external webservice.\n-->\n<operation\n    id=\"post-mediapackage\"\n    fail-on-error=\"false\"\n    exception-handler-workflow=\"error\"\n    description=\"Sending MediaPackage to Lernfunk3\">\n    <configurations>\n        <!-- target url -->\n        <configuration key=\"url\">http://example.com:5000/</configuration>\n        <!-- export format: xml or json -->\n        <configuration key=\"format\">xml</configuration>\n        <!--\n            Disable this on a productive system. If enabled, request bodies\n            etc. will be written to log. If disabled, only errors will be\n            logged.\n        -->\n        <configuration key=\"debug\">no</configuration>\n        <!-- Type of Mediapackage to send (possible values: workflow, search; default: search) -->\n        <configuration key=\"mediapackage.type\">search</configuration>\n        <!-- enable authentication (simple/digest will be detected automatically) -->\n        <configuration key=\"auth.enabled\">yes</configuration>\n        <!-- username for authentication -->\n        <configuration key=\"auth.username\">exportuser</configuration>\n        <!-- password for authentication -->\n        <configuration key=\"auth.password\">secret</configuration>\n        <!-- fields with keys beginning with + will be added to the message body -->\n        <configuration key=\"+source_system\">video.example.com</configuration>\n    </configurations>\n</operation>",
            "title": "Options"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/",
            "text": "PrepareAVWorkflowOperation\n\n\nDescription\n\n\nThe PrepareAVWorkflowOperation works is like this: \n\n\nIf there are two tracks with the same flavor, and one of them contains a video stream only, while the other contains an audio stream only, the implementation will call the composer's \"mux\" method, with the result that the audio will be muxed with the video, using the video's movie container. \n\n\nIf it there is one track with a certain flavor, the \"encode\" method is called which will rewrite (vs. encode) the file using the same container and codec (-vcodec copy, -a codec copy), while the container format is determined by ffmpeg via the file's extension. The reason for doing this is that many media files are in a poor state with regard to their compatibility (most often, the stream's codec contains differing information from the container), so we are basically asking ffmepg to rewrite the whole thing, which will in many cases eliminate problems that would otherwhise occur later in the pipeline (encoding to flash, mjpeg etc.). \n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/source\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/work\n\n\nSpecifies the flavor the new files will get.\n\n\n\n\n\n\nmux-encoding-profile\n\n\nmux-av.work\n\n\nThe encoding profile to use for media that needs to be muxed (default is 'mux-av.work')\n\n\n\n\n\n\naudio-video-encoding-profile\n\n\nav.work\n\n\nThe encoding profile to use for media that is audio-video already and needs to be re-encodend (default is av.work)\n\n\n\n\n\n\nvideo-encoding-profile\n\n\nvideo-only.work\n\n\nThe encoding profile to use for media that is only video and needs to be re-encodend (default is video-only.work)\n\n\n\n\n\n\naudio-encoding-profile\n\n\naudio-only.work\n\n\nThe encoding profile to use for media that is only audio and needs to be re-encodend (default is audio-only.work)\n\n\n\n\n\n\nrewrite\n\n\ntrue\n\n\nShould files be rewritten\n\n\n\n\n\n\npromiscuous-audio-muxing\n\n\ntrue\n\n\nIf there is no matching flavor to mux, try other flavors as well\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"prepare-av\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Preparing presenter audio and video work versions\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/source</configuration>\n    <configuration key=\"target-flavor\">presenter/work</configuration>\n    <configuration key=\"rewrite\">false</configuration>\n    <configuration key=\"promiscuous-audio-muxing\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Prepare A/V"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#prepareavworkflowoperation",
            "text": "",
            "title": "PrepareAVWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#description",
            "text": "The PrepareAVWorkflowOperation works is like this:   If there are two tracks with the same flavor, and one of them contains a video stream only, while the other contains an audio stream only, the implementation will call the composer's \"mux\" method, with the result that the audio will be muxed with the video, using the video's movie container.   If it there is one track with a certain flavor, the \"encode\" method is called which will rewrite (vs. encode) the file using the same container and codec (-vcodec copy, -a codec copy), while the container format is determined by ffmpeg via the file's extension. The reason for doing this is that many media files are in a poor state with regard to their compatibility (most often, the stream's codec contains differing information from the container), so we are basically asking ffmepg to rewrite the whole thing, which will in many cases eliminate problems that would otherwhise occur later in the pipeline (encoding to flash, mjpeg etc.).",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/source  Specifies which media should be processed.    target-flavor  presenter/work  Specifies the flavor the new files will get.    mux-encoding-profile  mux-av.work  The encoding profile to use for media that needs to be muxed (default is 'mux-av.work')    audio-video-encoding-profile  av.work  The encoding profile to use for media that is audio-video already and needs to be re-encodend (default is av.work)    video-encoding-profile  video-only.work  The encoding profile to use for media that is only video and needs to be re-encodend (default is video-only.work)    audio-encoding-profile  audio-only.work  The encoding profile to use for media that is only audio and needs to be re-encodend (default is audio-only.work)    rewrite  true  Should files be rewritten    promiscuous-audio-muxing  true  If there is no matching flavor to mux, try other flavors as well",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#operation-example",
            "text": "<operation\n  id=\"prepare-av\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Preparing presenter audio and video work versions\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/source</configuration>\n    <configuration key=\"target-flavor\">presenter/work</configuration>\n    <configuration key=\"rewrite\">false</configuration>\n    <configuration key=\"promiscuous-audio-muxing\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/publishengage-woh/",
            "text": "PublishEngageWorkflowOperation\n\n\nDescription\n\n\nThe PublishEngageWorkflowOperation will bring your media to the engage distribution channels (streaming, progressive download, \u2026)\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\ncheck-availability\n\n\nCheck if the media if rechable\n\n\n\n\n\n\ndownload-source-flavors\n\n\nSpecifies which media should be published for download\n\n\n\n\n\n\ndownload-source-tags\n\n\nSpecifies which media should be published for download\n\n\n\n\n\n\ndownload-target-subflavors\n\n\nSubflavor to use for distributed material\n\n\n\n\n\n\ndownload-target-tags\n\n\nModify tags of published media\n\n\n\n\n\n\nmerge-only\n\n\nMerge with existing published data. Skip if nothing had been published before\n\n\n\n\n\n\nstreaming-source-flavors\n\n\nSpecifies which media should be published to the streaming server\n\n\n\n\n\n\nstreaming-source-tags\n\n\nSpecifies which media should be published to the streaming server\n\n\n\n\n\n\nstreaming-tagret-tags\n\n\nModify tags of published media\n\n\n\n\n\n\nstreaming-target-szbflavors\n\n\nSubflavor to use for distributed material\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n    id=\"publish-engage\"\n    max-attempts=\"2\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Distribute and publish to engage player\">\n    <configurations>\n        <configuration key=\"download-source-tags\">engage,atom,rss</configuration>\n        <configuration key=\"streaming-source-tags\">engage</configuration>\n        <configuration key=\"check-availability\">true</configuration>\n    </configurations>\n</operation>",
            "title": "Publish Engage"
        },
        {
            "location": "/workflowoperationhandlers/publishengage-woh/#publishengageworkflowoperation",
            "text": "",
            "title": "PublishEngageWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/publishengage-woh/#description",
            "text": "The PublishEngageWorkflowOperation will bring your media to the engage distribution channels (streaming, progressive download, \u2026)",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/publishengage-woh/#parameter-table",
            "text": "configuration keys  description      check-availability  Check if the media if rechable    download-source-flavors  Specifies which media should be published for download    download-source-tags  Specifies which media should be published for download    download-target-subflavors  Subflavor to use for distributed material    download-target-tags  Modify tags of published media    merge-only  Merge with existing published data. Skip if nothing had been published before    streaming-source-flavors  Specifies which media should be published to the streaming server    streaming-source-tags  Specifies which media should be published to the streaming server    streaming-tagret-tags  Modify tags of published media    streaming-target-szbflavors  Subflavor to use for distributed material",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/publishengage-woh/#operation-example",
            "text": "<operation\n    id=\"publish-engage\"\n    max-attempts=\"2\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Distribute and publish to engage player\">\n    <configurations>\n        <configuration key=\"download-source-tags\">engage,atom,rss</configuration>\n        <configuration key=\"streaming-source-tags\">engage</configuration>\n        <configuration key=\"check-availability\">true</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/republish-woh/",
            "text": "RepublishWorkflowOperation\n\n\nDescription\n\n\nThe republish workflow operation handler will take a mediapackage from the archive and republish just its metadata. This is achieved by publishing the archived elements as specified in the \"source-flavor\" option and merging them with what had been published to search before. Alternatively, \"merge\" can be set to false which will result in the operation replacing what is in search.\n\n\nThis way one is able to use the archive's mediapackage editor to make changes to a recording's metadata and then use the \"republish\" workflow operation to publish the updated metadata to the search index. Note that you would want to distribute the catalogs to download before publishing because the search service will try to download them.\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"dublincore/episode\"\n\n\nSelect all media package elements with any of these (comma separated) flavors. If no source flavor is specified, all archived elements will be republished, including tracks and attachments.\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags\n\n\n\"engage, publish\"\n\n\nOnly select media package elements that are tagged with any of these (comma separated) tags.\n\n\nEMPTY\n\n\n\n\n\n\nmerge\n\n\n\"true\" or \"false\"\n\n\nIndicates whether the republished mediapackage elements should be merged with what has been published to search so far. If set to \"true\", mediapackage elements that are selected (by means of flavor and tags) will replace what is in search. If set to \"false\", the mediapackage in search will be replaced completely.\n\n\ntrue\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"republish\"\n  max-attempts=\"2\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Republishing metadata\">\n  <configurations>\n    <configuration key=\"source-flavors\">dublincore/*</configuration>    <configuration key=\"source-tags\">engage,atom</configuration>\n    <configuration key=\"merge\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Republish"
        },
        {
            "location": "/workflowoperationhandlers/republish-woh/#republishworkflowoperation",
            "text": "",
            "title": "RepublishWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/republish-woh/#description",
            "text": "The republish workflow operation handler will take a mediapackage from the archive and republish just its metadata. This is achieved by publishing the archived elements as specified in the \"source-flavor\" option and merging them with what had been published to search before. Alternatively, \"merge\" can be set to false which will result in the operation replacing what is in search.  This way one is able to use the archive's mediapackage editor to make changes to a recording's metadata and then use the \"republish\" workflow operation to publish the updated metadata to the search index. Note that you would want to distribute the catalogs to download before publishing because the search service will try to download them.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/republish-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  example  description  default value      source-flavors  \"dublincore/episode\"  Select all media package elements with any of these (comma separated) flavors. If no source flavor is specified, all archived elements will be republished, including tracks and attachments.  EMPTY    source-tags  \"engage, publish\"  Only select media package elements that are tagged with any of these (comma separated) tags.  EMPTY    merge  \"true\" or \"false\"  Indicates whether the republished mediapackage elements should be merged with what has been published to search so far. If set to \"true\", mediapackage elements that are selected (by means of flavor and tags) will replace what is in search. If set to \"false\", the mediapackage in search will be replaced completely.  true",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/republish-woh/#operation-example",
            "text": "<operation\n  id=\"republish\"\n  max-attempts=\"2\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Republishing metadata\">\n  <configurations>\n    <configuration key=\"source-flavors\">dublincore/*</configuration>    <configuration key=\"source-tags\">engage,atom</configuration>\n    <configuration key=\"merge\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/",
            "text": "SegmentpreviewsWorkflowOperation\n\n\nDescription\n\n\nThe SegmentpreviewsWorkflowOperation will extract still images from a video using FFmpeg, a given encoding profile and previous discovered segments.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/source\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/work\n\n\nSpecifies the flavor the new files will get.\n\n\n\n\n\n\nsource-tags\n\n\nengage\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-tags\n\n\nengage\n\n\nSpecifies the tags the new files will get.\n\n\n\n\n\n\nencoding-profile\n\n\nsearch-cover.http\n\n\nThe encoding profile to use.\n\n\n\n\n\n\nreference-flavor\n\n\npresentation/work\n\n\nFlavor of the segments to use.\n\n\n\n\n\n\nreference-tags\n\n\nengage\n\n\nTags of the segments to use.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"segmentpreviews\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Encoding presentation (screen) to segment preview image\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-flavor\">presentation/segment+preview</configuration>\n            <configuration key=\"reference-flavor\">presentation/delivery</configuration>\n            <configuration key=\"reference-tags\">engage</configuration>\n            <configuration key=\"target-tags\">engage</configuration>\n            <configuration key=\"encoding-profile\">player-slides.http</configuration>\n      </configurations>\n</operation>",
            "title": "Segment Previews"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/#segmentpreviewsworkflowoperation",
            "text": "",
            "title": "SegmentpreviewsWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/#description",
            "text": "The SegmentpreviewsWorkflowOperation will extract still images from a video using FFmpeg, a given encoding profile and previous discovered segments.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/source  Specifies which media should be processed.    target-flavor  presenter/work  Specifies the flavor the new files will get.    source-tags  engage  Specifies which media should be processed.    target-tags  engage  Specifies the tags the new files will get.    encoding-profile  search-cover.http  The encoding profile to use.    reference-flavor  presentation/work  Flavor of the segments to use.    reference-tags  engage  Tags of the segments to use.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/#operation-example",
            "text": "<operation\n      id=\"segmentpreviews\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Encoding presentation (screen) to segment preview image\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-flavor\">presentation/segment+preview</configuration>\n            <configuration key=\"reference-flavor\">presentation/delivery</configuration>\n            <configuration key=\"reference-tags\">engage</configuration>\n            <configuration key=\"target-tags\">engage</configuration>\n            <configuration key=\"encoding-profile\">player-slides.http</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/",
            "text": "SegmentVideoWorkflowOperation\n\n\nDescription\n\n\nThe SegmentVideoWorkflowOperation will try to identify and mark different segments of a video. A new segment is created when a major change in the video occurs. This might be the case for example if the video is a screenrecording and the slides which were shown change.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresentation/trimmed\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"segment-video\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Extracting segments from presentation\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n      </configurations>\n</operation>",
            "title": "Segment Video"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/#segmentvideoworkflowoperation",
            "text": "",
            "title": "SegmentVideoWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/#description",
            "text": "The SegmentVideoWorkflowOperation will try to identify and mark different segments of a video. A new segment is created when a major change in the video occurs. This might be the case for example if the video is a screenrecording and the slides which were shown change.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presentation/trimmed  Specifies which media should be processed.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/#operation-example",
            "text": "<operation\n      id=\"segment-video\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Extracting segments from presentation\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/",
            "text": "SeriesWorkflowOperationHandler\n\n\nDescription\n\n\nThe SeriesWorkflowOperation will apply a series to the mediapackage.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nseries\n\n\n\"0d06537e-09d3-420c-8314-a21e45c5d032\"\n\n\nThe optional series identifier. If empty the current series of the medipackage will be taken.\n\n\nEMPTY\n\n\n\n\n\n\nattach\n\n\n\"creativecommons/*,dublincore/*\"\n\n\nThe flavors of the series catalogs to attach to the mediapackage.\n\n\nEMPTY\n\n\n\n\n\n\napply-acl\n\n\n\"true\"|\"false\"\n\n\nWhether the ACL should be applied or not.\n\n\n\"false\"\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"series\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Applying series to mediapackage\">\n      <configurations>\n        <configuration key=\"series\">0d06537e-09d3-420c-8314-a21e45c5d032</configuration>\n        <configuration key=\"attach\">*</configuration>\n        <configuration key=\"apply-acl\">true</configuration>\n      </configurations>\n</operation>",
            "title": "Series"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#seriesworkflowoperationhandler",
            "text": "",
            "title": "SeriesWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#description",
            "text": "The SeriesWorkflowOperation will apply a series to the mediapackage.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      series  \"0d06537e-09d3-420c-8314-a21e45c5d032\"  The optional series identifier. If empty the current series of the medipackage will be taken.  EMPTY    attach  \"creativecommons/*,dublincore/*\"  The flavors of the series catalogs to attach to the mediapackage.  EMPTY    apply-acl  \"true\"|\"false\"  Whether the ACL should be applied or not.  \"false\"",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#operation-example",
            "text": "<operation\n      id=\"series\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Applying series to mediapackage\">\n      <configurations>\n        <configuration key=\"series\">0d06537e-09d3-420c-8314-a21e45c5d032</configuration>\n        <configuration key=\"attach\">*</configuration>\n        <configuration key=\"apply-acl\">true</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/",
            "text": "SilenceDetectionWorkflowOperationHandler\n\n\nDescription\n\n\nThe \nsilence\n operation performs a silence detection on an audio-only input file. The operation needs the silence detection API and impl (or remote in a distributed system) modules to be installed to process the request.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"*/audio\"\n\n\nThe input parameter source-flavors takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type\n\n\nEMPTY\n\n\n\n\n\n\nreference-tracks-flavour\n\n\n\"*/preview\"\n\n\nThe input parameter reference-tracks-flavour is the subtype of the media files that should be included in the provided SMIL file. The * should not be modified here. In most cases it is not important which reference-tracks-flavour is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality.\n\n\nEMPTY\n\n\n\n\n\n\nsmil-flavor-subtype\n\n\n\"smil\"\n\n\nThe output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced.\n\n\nEMPTY\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"silence\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Executing silence detection\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/audio</configuration>\n    <configuration key=\"smil-flavor-subtype\">smil</configuration>\n    <configuration key=\"reference-tracks-flavor\">*/preview</configuration>\n  </configurations>\n</operation>",
            "title": "Silence"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/#silencedetectionworkflowoperationhandler",
            "text": "",
            "title": "SilenceDetectionWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/#description",
            "text": "The  silence  operation performs a silence detection on an audio-only input file. The operation needs the silence detection API and impl (or remote in a distributed system) modules to be installed to process the request.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  \"*/audio\"  The input parameter source-flavors takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type  EMPTY    reference-tracks-flavour  \"*/preview\"  The input parameter reference-tracks-flavour is the subtype of the media files that should be included in the provided SMIL file. The * should not be modified here. In most cases it is not important which reference-tracks-flavour is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality.  EMPTY    smil-flavor-subtype  \"smil\"  The output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced.  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/#operation-example",
            "text": "<operation\n  id=\"silence\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Executing silence detection\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/audio</configuration>\n    <configuration key=\"smil-flavor-subtype\">smil</configuration>\n    <configuration key=\"reference-tracks-flavor\">*/preview</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/",
            "text": "TagWorkflowOperation\n\n\nDescription\n\n\nWith the TagWorkflowOperationHandler it's possible to select various media package elements and then modify their tag set and / or set their flavor.\n\n\nSo for example it's possible to pick up elements like the dublin core catalogs that have been added to the media package at the beginning of the workflow and tag them, so they can be picked up by operations later on.\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-tags\n\n\n\"engage,atom,rss,-publish\"\n\n\nTag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavors\n\n\n\"presentation/trimmed\"\n\n\nTag any media package elements with one of these (comma separated) flavors.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\n\"tagged,+rss\" / \"-rss,+tagged\"\n\n\nApply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\n\"presentation/tagged\"\n\n\nApply these flavor to any media package elements\n\n\nEMPTY\n\n\n\n\n\n\ncopy\n\n\n\"true\" or \"false\"\n\n\nIndicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise.\n\n\nFALSE\n\n\n\n\n\n\n\n\nTarget Tags Example\n\n\n\n\n\n\n\n\nTarget-Tags\n\n\nPreexisting Tags\n\n\nResulting Tags\n\n\n\n\n\n\n\n\n\n\nrss\n\n\nengage\n\n\nrss\n\n\n\n\n\n\n+rss\n\n\nengage\n\n\nengage,rss\n\n\n\n\n\n\n-rss\n\n\nengage,rss\n\n\nengage\n\n\n\n\n\n\ntagged,+rss\n\n\nengage\n\n\ntagged\n\n\n\n\n\n\n-rss,+tagged\n\n\nengage,rss\n\n\nengage,tagged\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"tag\"\n  max-attempts=\"2\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Tagging media package elements\">\n  <configurations>\n    <configuration key=\"source-tags\">engage,atom,-publish</configuration>\n    <configuration key=\"source-flavors\">presentation/trimmed</configuration>\n    <configuration key=\"target-tags\">-atom,+rss</configuration>\n    <configuration key=\"target-flavor\">presentation/tagged</configuration>\n    <configuration key=\"copy\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Tag"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#tagworkflowoperation",
            "text": "",
            "title": "TagWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#description",
            "text": "With the TagWorkflowOperationHandler it's possible to select various media package elements and then modify their tag set and / or set their flavor.  So for example it's possible to pick up elements like the dublin core catalogs that have been added to the media package at the beginning of the workflow and tag them, so they can be picked up by operations later on.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  example  description  default value      source-tags  \"engage,atom,rss,-publish\"  Tag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded.  EMPTY    source-flavors  \"presentation/trimmed\"  Tag any media package elements with one of these (comma separated) flavors.  EMPTY    target-tags  \"tagged,+rss\" / \"-rss,+tagged\"  Apply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags.  EMPTY    target-flavor  \"presentation/tagged\"  Apply these flavor to any media package elements  EMPTY    copy  \"true\" or \"false\"  Indicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise.  FALSE",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#target-tags-example",
            "text": "Target-Tags  Preexisting Tags  Resulting Tags      rss  engage  rss    +rss  engage  engage,rss    -rss  engage,rss  engage    tagged,+rss  engage  tagged    -rss,+tagged  engage,rss  engage,tagged",
            "title": "Target Tags Example"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#operation-example",
            "text": "<operation\n  id=\"tag\"\n  max-attempts=\"2\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Tagging media package elements\">\n  <configurations>\n    <configuration key=\"source-tags\">engage,atom,-publish</configuration>\n    <configuration key=\"source-flavors\">presentation/trimmed</configuration>\n    <configuration key=\"target-tags\">-atom,+rss</configuration>\n    <configuration key=\"target-flavor\">presentation/tagged</configuration>\n    <configuration key=\"copy\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/",
            "text": "TrimWorkflowOperationHandler\n\n\nDescription\n\n\nThe TrimWorkflowOperationHandler makes it possible to remove the undesired parts of the media at the beginning and the\nend of the recordings.\n\n\nThis operation UI also allows users to select/deselect tracks for being further processed and distributed (e.g. one\ncould remove the presenter track if its quality does not meet the required standards). The recording metadata fields\n(e.g. title, presenter, series, etc.) may be also be edited in the UI provided.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nduration-threshold\n\n\n\"100\"\n\n\nIf the trimming \"out point\" is beyond a certain track's duration, this parameter specifies the maximum allowed difference between them (in milliseconds).\n\n\n0\n\n\n\n\n\n\nencoding-profile\n\n\n\"trim.master\"\n\n\nThe encoding profile used to encode the trimmed tracks.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavors\n\n\n\"presentation/trimmed\"\n\n\nIndicates the flavor(s) that will be trimmed by this operation..\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor-subtype\n\n\n\"master\"\n\n\nThe flavors of the elements created after the trim will be modified by changing the second half of the flavor with the value of this parameter. E.g., if it is set to \"trimmed\", a source track's flavor \"presenter/work\" would become \"presenter/trimmed\".\n\n\nEMPTY\n\n\n\n\n\n\n\n\nDuration Threshold Tag\n\n\nThe \"duration-threshold\" parameter  accepts a threshold value in milliseconds. It is meant to deal with length\ndifferences between the tracks in a mediapackage (which in theory should have the same length). Since all the tracks in\nthe mediapackage are trimmed at the same time points, the trimming point may be within a certain track's duration, but\noutside another. If the difference between the trim point and the track length is shorter than the threshold, then the\noutpoint is adjusted to the length of the track, for that track only. For instance, if the trim point is at 5'31'' but\none of the tracks is 5'30'' long, with a threshold of 2000 (2 seconds), the shorter track will be trimmed to 5'30\ninstead, thus not failing. In the end, when some tracks are longer and others slightly shorter than the trim point, you\nwill end up with a set of tracks that are trimmed either at the exact point or not shorter than \n milliseconds\n\n\nThe parameter is currently in the default workflow, but commented. The threshold is 0 by default, i.e. no difference\nbetween the trim outpoint and the track length is allowed.\n\n\nCapture UI\n\n\n\n\nOperation Example\n\n\n<operation\n id=\"trim\"\n retry-strategy=\"hold\"\n fail-on-error=\"true\"\n exception-handler-workflow=\"error\"\n description=\"trimming and master generation\">\n  <configurations>\n    <configuration key=\"duration-threshold\">1000</configuration>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor-subtype\">master</configuration>\n    <configuration key=\"encoding-profile\">trim.master</configuration>\n  </configurations>\n</operation>",
            "title": "Trim"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/#trimworkflowoperationhandler",
            "text": "",
            "title": "TrimWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/#description",
            "text": "The TrimWorkflowOperationHandler makes it possible to remove the undesired parts of the media at the beginning and the\nend of the recordings.  This operation UI also allows users to select/deselect tracks for being further processed and distributed (e.g. one\ncould remove the presenter track if its quality does not meet the required standards). The recording metadata fields\n(e.g. title, presenter, series, etc.) may be also be edited in the UI provided.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      duration-threshold  \"100\"  If the trimming \"out point\" is beyond a certain track's duration, this parameter specifies the maximum allowed difference between them (in milliseconds).  0    encoding-profile  \"trim.master\"  The encoding profile used to encode the trimmed tracks.  EMPTY    source-flavors  \"presentation/trimmed\"  Indicates the flavor(s) that will be trimmed by this operation..  EMPTY    target-flavor-subtype  \"master\"  The flavors of the elements created after the trim will be modified by changing the second half of the flavor with the value of this parameter. E.g., if it is set to \"trimmed\", a source track's flavor \"presenter/work\" would become \"presenter/trimmed\".  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/#duration-threshold-tag",
            "text": "The \"duration-threshold\" parameter  accepts a threshold value in milliseconds. It is meant to deal with length\ndifferences between the tracks in a mediapackage (which in theory should have the same length). Since all the tracks in\nthe mediapackage are trimmed at the same time points, the trimming point may be within a certain track's duration, but\noutside another. If the difference between the trim point and the track length is shorter than the threshold, then the\noutpoint is adjusted to the length of the track, for that track only. For instance, if the trim point is at 5'31'' but\none of the tracks is 5'30'' long, with a threshold of 2000 (2 seconds), the shorter track will be trimmed to 5'30\ninstead, thus not failing. In the end, when some tracks are longer and others slightly shorter than the trim point, you\nwill end up with a set of tracks that are trimmed either at the exact point or not shorter than   milliseconds  The parameter is currently in the default workflow, but commented. The threshold is 0 by default, i.e. no difference\nbetween the trim outpoint and the track length is allowed.",
            "title": "Duration Threshold Tag"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/#capture-ui",
            "text": "",
            "title": "Capture UI"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/#operation-example",
            "text": "<operation\n id=\"trim\"\n retry-strategy=\"hold\"\n fail-on-error=\"true\"\n exception-handler-workflow=\"error\"\n description=\"trimming and master generation\">\n  <configurations>\n    <configuration key=\"duration-threshold\">1000</configuration>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor-subtype\">master</configuration>\n    <configuration key=\"encoding-profile\">trim.master</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/",
            "text": "WaveformWorkflowOperationHandler\n\n\nDescription\n\n\nThe waveform operation creates an image showing the temporal audio activity within the recording. This is be done with a probably well known waveform (see example image).\n\n\nThe operation does not need an additional module, as it is not very work intensive to create such an image. The operation needs and audio-only file to create the image and it provides an PNG image.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"*/audio\"\n\n\nInput parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be used if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example).\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\n\"*/waveform\"\n\n\nThe output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too.\n\n\nEMPTY\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"waveform\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Generating waveform\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/audio</configuration>\n    <configuration key=\"target-flavor\">*/waveform</configuration>\n  </configurations>\n</operation>",
            "title": "Waveform"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/#waveformworkflowoperationhandler",
            "text": "",
            "title": "WaveformWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/#description",
            "text": "The waveform operation creates an image showing the temporal audio activity within the recording. This is be done with a probably well known waveform (see example image). \nThe operation does not need an additional module, as it is not very work intensive to create such an image. The operation needs and audio-only file to create the image and it provides an PNG image.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  \"*/audio\"  Input parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be used if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example).  EMPTY    target-flavor  \"*/waveform\"  The output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too.  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/#operation-example",
            "text": "<operation\n  id=\"waveform\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Generating waveform\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/audio</configuration>\n    <configuration key=\"target-flavor\">*/waveform</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/",
            "text": "ZipWorkflowOperation\n\n\nDescription\n\n\nThe ZipWorkflowOperationHandler creates a zip archive including all elements of the current mediapackage that are specified in the operation configuration. It then adds the archive to the mediapackage as an attachment with the given flavor and tags and by default stores the zip file in the working file repository's \"zip\" collection.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nzip-collection\n\n\nzips\n\n\nA comma separated list of flavors to preserve from deleting.\n\n\nzip\n\n\n\n\n\n\ninclude-flavors\n\n\n\"\n/source,dublincore/\n\"\n\n\nWhich elements to include in the archive. This configuration parameter accepts exact flavors like \"presenter/source\" as well as wildcard flavor definitions like \"*/source\".\n\n\n(all)\n\n\n\n\n\n\ntarget-flavor\n\n\n\"archive/zip\"\n\n\nThe flavor of the created attachment.\n\n\narchive/zip\n\n\n\n\n\n\ntarget-tags\n\n\n\"archive\"\n\n\nThe tags to apply to the attachment.\n\n\n-\n\n\n\n\n\n\ncompression\n\n\n\"true\"\n\n\nWhether to compress the archive content. Usually, for media content this doesn't reduce size of the archive by a lot but adds significant processing time by the compression.\n\n\nFALSE\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n    id=\"zip\"\n    description=\"Creating zipped recording archive\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"cleanup\">\n    <configurations>\n      <configuration key=\"zip-collection\">failed.zips</configuration>\n      <configuration key=\"include-flavors\">*/source,dublincore/*</configuration>\n      <configuration key=\"target-flavor\">all/zip</configuration>\n      <configuration key=\"compression\">false</configuration>\n    </configurations>\n</operation>",
            "title": "Zip"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/#zipworkflowoperation",
            "text": "",
            "title": "ZipWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/#description",
            "text": "The ZipWorkflowOperationHandler creates a zip archive including all elements of the current mediapackage that are specified in the operation configuration. It then adds the archive to the mediapackage as an attachment with the given flavor and tags and by default stores the zip file in the working file repository's \"zip\" collection.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      zip-collection  zips  A comma separated list of flavors to preserve from deleting.  zip    include-flavors  \" /source,dublincore/ \"  Which elements to include in the archive. This configuration parameter accepts exact flavors like \"presenter/source\" as well as wildcard flavor definitions like \"*/source\".  (all)    target-flavor  \"archive/zip\"  The flavor of the created attachment.  archive/zip    target-tags  \"archive\"  The tags to apply to the attachment.  -    compression  \"true\"  Whether to compress the archive content. Usually, for media content this doesn't reduce size of the archive by a lot but adds significant processing time by the compression.  FALSE",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/#operation-example",
            "text": "<operation\n    id=\"zip\"\n    description=\"Creating zipped recording archive\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"cleanup\">\n    <configurations>\n      <configuration key=\"zip-collection\">failed.zips</configuration>\n      <configuration key=\"include-flavors\">*/source,dublincore/*</configuration>\n      <configuration key=\"target-flavor\">all/zip</configuration>\n      <configuration key=\"compression\">false</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        }
    ]
}