{
    "docs": [
        {
            "location": "/",
            "text": "Opencast Development Guides\n\n\nThese guides will help you if you want to participate in Opencast development.\n\n\n\n\nDevelopment Process\n\n\nCommitters\n\n\nDecision Making\n\n\nProposal Log\n\n\nQA Coordinator\n\n\nRelease Manager\n\n\nCommitters\n\n\nReviewing, Merging and Declining Pull Requests\n\n\nSecurity Issues\n\n\nLicenses and Legal Matters\n\n\nLocalization\n\n\nGovernance\n\n\nDevelopment Environment\n\n\nDocker\n\n\n\n\n\n\nPackaging Guidelines\n\n\nModules\n\n\nAdministrative User Interface\n\n\nDevelopment\n\n\nStyle Guide\n\n\n\n\n\n\nCapture Agent\n\n\nStream Security\n\n\n\u2026\n\n\n\n\n\n\nExternal API\n\n\nProject Infrastructure\n\n\nMaven Repository",
            "title": "Home"
        },
        {
            "location": "/#opencast-development-guides",
            "text": "These guides will help you if you want to participate in Opencast development.   Development Process  Committers  Decision Making  Proposal Log  QA Coordinator  Release Manager  Committers  Reviewing, Merging and Declining Pull Requests  Security Issues  Licenses and Legal Matters  Localization  Governance  Development Environment  Docker    Packaging Guidelines  Modules  Administrative User Interface  Development  Style Guide    Capture Agent  Stream Security  \u2026    External API  Project Infrastructure  Maven Repository",
            "title": "Opencast Development Guides"
        },
        {
            "location": "/development-process/",
            "text": "Development Process\n\n\nThis document defines rules and recommendations for Opencast development. In particular, it defines how patches can be\ncontributed, how they are merged and how releases are done.\n\n\nIf this document does not answer all of your questions, here is how you can get further help:\n\n\n\n\nAsk on the \nOpencast Development List\n\n\nChat with developers on \nIRC (#opencast on Freenode)\n\n\nJoin our weekly technical meeting (see lists or IRC)\n\n\n\n\nContributing Code\n\n\nOpencast sources can be found on \nGitHub\n and some of its ancillary projects\non \nBitBucket\n. The easiest way to contribute code to the project\nis by creating a pull request against the project's official repository. More details about the structure\nof this repository are explained later in this guide.\n\n\nJira and GitHub\n\n\n\n\n\n\nOpencast uses \nJira\n for tracking issues. Each pull request should be accompanied by a\n   ticket in Jira. The issue identifier should also be used in the title of the pull request and the commits. E.g.:\n   \nMH-12345, Fixing Something Somewhere\n. Creating a Jira ticket is usually the first step when fixing something.\n\n\n\n\n\n\nOpencast uses \nGitHub\n for code hosting.\n   Please \nfork\n\n   the \nofficial repository\n on GitHub\n   to \ncreate pull requests\n from your repository\n   which will show up on the project's list of open pull requests.\n\n\n\n\n\n\nAll open pull requests are listed on the \nOpencast Pull Request Filter\n. It might\n   take a couple of minutes for a new pull request to show up.\n\n\n\n\n\n\nBugfix vs Feature\n\n\nOpencast distinguishes between bug fix and feature pull requests.\n\n\n\n\n\n\nFeatures are \nonly\n allowed to be merged into \ndevelop\n, which will let them automatically become part of the next\n   major/minor release, given that the release branch for the next release has not been cut yet. If possible, please\n   name branches containing features according to the pattern \nf/MH-XXXXX-short-description\n, where MH-XXXXX is the\n   relevant Jira ticket.\n\n\n\n\n\n\nBug fixes can be merged both into \ndevelop\n and into release branches. If possible, please name branches containing\n   bug fixes according to the pattern \nt/MH-XXXXX-short-description\n, where MH-XXXXX is the relevant Jira ticket.\n\n\n\n\n\n\nReviews\n\n\nBefore a patch is merged, it needs to be reviewed by a committer. The reviewer makes sure that the patch merges\nwithout conflicts, that it works as expected and that it does not break anything else.\n\n\nIf the reviewer discovers any kind of issue, he should comment on the pull request in GitHub, so that the author can\nfix the problem.\n\n\nFor more details about the review and merge process, have a look at \nReviewing, Merging and Declining Pull\nRequests\n.\n\n\nPull Request Guidelines\n\n\nWhen reviewing a pull request, it is always easier if the reviewer knows what the ticket is about, and has a rough idea\nof what work has been done.  To this end, there are a few expectations for all pull requests:\n\n\n\n\nFor each pull request a JIRA ticket should be created\n\n\nThe JIRA ticket and JIRA ticket title should be the pull request title\n\n\nThe pull request description should contain a summary of the work done, along with reasoning for any major change\n\n\nThe JIRA ticket should contain the same information\n\n\nFor feature pull requests, accompanying documentation should be included\n\n\nIt is encouraged, but not required that the pull request have a clean commit history\n\n\nIn the case of major user interface changes, it is good practice to include screenshots of the affect sections of\n   the interface\n\n\nIf you add or modify any external libraries ensure that those additions and modifications are also applied to the\n   NOTICES file\n\n\nAny actions that would be required for a version upgrade (e.g: from 3.x to 4.x) must be documented in\n   docs/guides/admin/docs/upgrade.md\n\n\nThe commands \nmvn clean install\n, \nmvn javadoc:javadoc javadoc:aggregate\n, and \nmvn site\n should all succeed\n\n\nThe licenses of any external libraries used in the pull request comply with the \nlicensing rules\n both\n   in terms of the license itself as well as its listing in NOTICES\n\n\n\n\nWhile a committer may accept a patch even if it does not meet these expectations, it is encouraged that anyone filing\na pull request ensures that they meet these expectations.\n\n\nGit Repository Branching Model\n\n\nWhile the Opencast repository and branching model is inspired by\n\nGitFlow\n, there have been some distinct changes to how release\nbranches are used and releases are tagged. The purpose of this is mainly to support multiple, simultaneous versions and\nmaintenance releases.\n\n\nSwift overview:\n\n\n\n\nThe \ndevelop\n branch represents the latest state of development. Features may be merged into this branch and into\n   this branch only. Release branches are branched off from \ndevelop\n. It is basically the preparation for the next big\n   release at all times.\n\n\nThe release branches are named \nr/<a>.<b>.x\n (e.g. \nr/1.6.x\n). They are the latest state of development for a\n   specific release. Only bug fixes and no features may be added to these branches. All beta versions, release\n   candidates and final releases are made from these branches. The branch lives on as long as there may be additional\n   maintenance releases for a given version.\n\n\nGit tags are created to indicate official releases. These may be:\n\n\nx.y.z-betaX\n marks a beta release. This is usually a version which may still have bugs but is good enough for\n  testing, so that further issues or bugs can be identified before an actual release.\n\n\nx.y.z-rcX\n marks a release candidate. This is a version that seems to be ready to be released as a final\n  version. It will become the final version if testing does not reveal any severe issues.\n\n\nx.y.z\n marks a final release.\n\n\n\n\n\n\n\n\nTo get a closer look at the branching model, let us consider a simple example with a single release:\n\n\ndevelop ---*----*----*------*------- ... -----------*-->\n            \\       /      /                       /\n    r/1.6.x  *-----*------*-------------*---------*----- ... ---*-->\n                           \\             \\         \\             \\\n                1.6.0-beta1 *   1.6.0-rc1 *   1.6.0 *       1.6.1 *\n\n\n\nAs described above, \ndevelop\n is the branch used for preparing the next version. At some point marked in the release\nschedule, the release branch is cut from \ndevelop\n. This action also marks the feature freeze for such Opencast version,\ni.e. the moment when no new features will be included in that specific version. This is because all the new features\nmust be merged only into the \ndevelop\n branch; therefore, the release branches (such as \nr/1.6.x\n in our example) can\nonly contain features that were merged before the branch was forked off. Any features merged after the creation of the\nrelease branch can only make it into the next release, but not into this one.\n\n\nAfter the release branch is cut, the development on the \ndevelop\n branch may continue as before. Features can (and\nshould) be merged without waiting for the next version to be released. Thus, the creation of a release branch also marks\nthe beginning of the development for the next version.\n\n\nIn contrast to that, only bug fixes may be merged into the release branch. At this point, the code contained in this\nbranch should be tested, so that bugs can be identified and fixed. The release manager can tag different beta versions\nduring the QA process (such as \n1.6.0-beta1\n) to mark the code evolution as bug fixes are merged. Once the branch status\nseems to be stable enough to be released, a release candidate (RC) is tagged and tested (\n1.6.0-rc1\n). New RCs can be\ntagged as long as new issues are found and fixed. When no severe issues are found, the final release is tagged.\n\n\nDuring the whole process the release manager will regularly merge back the release branch into \ndevelop\n or, if\nexistent, the next active release branch so that bug fixes from the release branch will automatically become part of the\nnext Opencast versions and finally \ndevelop\n, without having to create additional pull requests. For example, a pull\nrequest may be merged into \nr/3.x\n, \nr/3.x\n will then be merged into \ndevelop\n or, if it already exists, \nr/4.x\n and\nfrom there into \ndevelop\n. That way patches bubble through all newer versions and finally end up in \ndevelop\n.\n\n\nThe releases themselves are not part of the release branch. Instead, the release manager branches off, makes the\nnecessary changes to the pom files (and possibly the UI) and creates a separately tagged commit.\n\n\nFinally, after a release is done, more bug fixes may be added to the release branch. The release manager should identify\nif there are enough commits to be put into a maintenance release.\n\n\nEven after an Opencast version has been released, more bugs may be found and fixes for them merged into the release\nbranch. When the release manager considers that the number or importance of such bug fixes is sufficient, he may decide\nto create a new maintenance release. The version \n1.6.1\n above is an example of that.\n\n\nRelease Process\n\n\nAs indicated above, the release cycle of a new Opencast version starts when a release branch is cut. The new features\nmerged into \ndevelop\n afterwards will be part of the next version, but not the one just cut.\n\n\nThis is why the position of release manager for the next Opencast version should be assigned at this point. The current\nrelease manager should therefore ask for volunteers in the mailing lists. For more details about the rights and\nresponsibilities of a release manager, please have a look at the \nRelease Manager Guide\n.\n\n\nPreparations\n\n\nThe first phase of the release consists of adding new features and defining the release schedule. It is the duty of the\nrelease manager to orchestrate this. This does not necessarily mean that release managers merge or review pull requests,\nbut that they talk to developers and ensure the merge process is driven forward.\n\n\nRelease Schedule\n\n\nReleases should happen twice a year, usually within a time span of 9.5 months between the cut of the previous release\nbranch and the final release. The release manager should create a release schedule as soon as possible, identifying when\nthe release branch is cut and when the final release will happen. Additionally, he should coordinate with the QA manager\nto identify phases for internal and public testing.\n\n\nUsually, a release schedule will look like this:\n\n\n\n\n\n\n\n\nDate\n\n\nWhat is happening\n\n\n\n\n\n\n\n\n\n\nApril 6th\n\n\nFeature Freeze \n(release branch is cut)\n\n\n\n\n\n\nApril 6th - 24th\n\n\nInternal QA and bug fixing phase\n\n\n\n\n\n\n\u00a0 \nApril 11th - 17th\n\n\nReview Test Cases \n(handles by a dedicated team)\n\n\n\n\n\n\n\u00a0 \nApril 18th - 24th\n\n\nDocumentation Review\n\n\n\n\n\n\nApril 25th - May 15th\n\n\nPublic QA phase\n\n\n\n\n\n\nMay 15th - June 1st\n\n\nAdditional bug fixing phase\n\n\n\n\n\n\n\u00a0 \nMay 25th - June 1st\n\n\nTranslation week \n(encourage translators to do their work)\n\n\n\n\n\n\nJune 2nd - June 12th\n\n\nFinal QA phase \n(checking release readiness)\n\n\n\n\n\n\nJune 15th\n\n\nFinal Release\n\n\n\n\n\n\n\n\nRelease Branch\n\n\nThe release branch is created from \ndevelop\n. The release branch is named \nr/A.B.x\n (e.g. \nr/2.1.x\n) to indicate that it\nis the origin of all releases with the major and minor version of \nA.B\n. The creation of the release branch marks the\nfeature freeze for a given version, as no more features can be merged into a release branch.\n\n\nTo ensure that all fixes that go into the release branch will become part of \ndevelop\n (and thus part of the next version\nof Opencast) with a minimum amount of work, the release manager will merge the release branch into \ndevelop\n on a\nregular basis. He may request assistance from certain developers in case of merge conflicts. This process continues until\nthe next release branch is cut.\n\n\nTags\n\n\nGit tags are used to mark explicit Opencast versions or releases. Here is how a release should look like in the history:\n\n\nr/A.B.x  ------------(A)---->\n                       \\\n           A.B.0-beta1 (B)\n\n\n\nTo create a version based on a given state of the release branch (commit A), the release manager will branch off from\nthis commit, make the necessary version changes to all \npom.xml\n files and to the UI and create a commit and a \nsigned\n\ngit tag on this commit. He would then push the commit and the tag (not the branch) to the community repository.\n\n\nFor more details about how to create a release, have a look at the \nRelease Manager Guide\n.\n\n\nBeta Versions/Release Candidates\n\n\nA beta release (\nA.B.C-betaX\n) should be cut before the public QA phase. It indicates a specific version of Opencast for\nusers to test. It is expected to still have bugs. Beta releases should continue until all bugs with a severity of\n\nBlocker\n have been fixed.\n\n\nIf the code seems to be ready for a release, a \nrelease candidate\n (\nA.B.C-rcX\n) should be cut for final testing. The\ncommit from which a release candidate is created is expected to become the final release if no severe bugs are found.\n\n\nFinal Release\n\n\nOnce a release candidate seems to be stable during the QA phase (no issues left marked as \nBlocker\n), the release manager\nwill propose this release candidate to become the final release. If the proposal is approved (i.e. no serious bugs are\nfound before the proposal deadline is met), the final release is then created from the same commit the\nrelease candidate was cut from.\n\n\nMaintenance Releases\n\n\nAfter a final release, additional issues may show up. These issues may be fixed on the ongoing release branch and at\nsome point released as maintenance release.\n\n\nThere is usually no release schedule for maintenance releases. It is up to the release manager to decide when it is\nworthwhile to create a maintenance release with the fixes for bugs affecting a given release. He would then announce his\nintention to create such a release, cut a release candidate and, should no severe issues with this candidate show up, cut\nthe maintenance release.\n\n\nQuality Assurance\n\n\nAs any piece of software, Opencast may contain bugs. It is the duty of the whole community to identify these bugs,\nreport them and possibly fix them to improve Opencast as product.\n\n\nAdditionally, before releasing a new version of Opencast, the current release manager and quality assurance manager will\ncoordinate test phases dedicated to new releases in order to identify possible problems ahead of time. The whole\ncommunity will be requested to participate in this testing.\n\n\nReporting Bugs\n\n\nIf you identify any bugs, please report them! To do that, register yourself in the \nOpencast\nJira\n and create a new ticket. Please describe in detail how to reproduce the problem and\nespecially set the \nAffects Version\n and \"Fix Version\", where \nFix Version\n should be the next Opencast release.\n\n\nIf in doubt of any items in the ticket, please assign it for review to either the current release manager or to the\nquality assurance manager. They will check the issue fields and adjust \nfix version\n, \nseverity\n, etc. if necessary.\n\n\nSecurity Issues\n\n\nIf you discover a problem that has severe implications for system security, please do not publish this information on\nlist. Instead, send a report of the problem to \nsecurity@opencast.org\n. The message will be forwarded to the private\ncommitters list, where the issue will be discussed. Once a patch for the problem is ready, a security notice will be\nreleased along with it.\n\n\nUnit Tests\n\n\nAll Opencast modules should have built-in unit tests to check that they are actually doing what they are supposed to do\nand that code patches do not break the existing functionality. These tests are automatically run whenever the project is\nbuilt. If building repeatedly fails due to test failures, then something is most likely wrong. Please report this as a\nsevere bug.\n\n\nUser Tests\n\n\nBefore each major release, the release and quality assurance managers will ask the whole community to participate in\nthe execution of a set of manual tests. These tests are designed to check that important functionalities of Opencast\nwork as expected even if users are in slightly different environments or choose different methods to achieve a certain\ngoal.\n\n\nSuch a call for participation will usually be raised both on the lists, the technical and the adopters meeting.  If it\nis possible for you to participate, please do so. Identifying possible problems early will immensely benefit the release\nprocess.\n\n\nTest Server\n\n\nSome institutions provide public testing infrastructure for Opencast. Use them to try out the most recent development\nversion of Opencast. They are meant for testing. Do not fear to break them.  If you manage to do it, please contact the\nQA manager or send a notice to the list.\n\n\nRemember that they are usually not running a stable version of Opencast but the latest development release (beta version\nor release candidate) instead. If you discover any bugs on these systems, please take a minute to report them.",
            "title": "Development"
        },
        {
            "location": "/development-process/#development-process",
            "text": "This document defines rules and recommendations for Opencast development. In particular, it defines how patches can be\ncontributed, how they are merged and how releases are done.  If this document does not answer all of your questions, here is how you can get further help:   Ask on the  Opencast Development List  Chat with developers on  IRC (#opencast on Freenode)  Join our weekly technical meeting (see lists or IRC)",
            "title": "Development Process"
        },
        {
            "location": "/development-process/#contributing-code",
            "text": "Opencast sources can be found on  GitHub  and some of its ancillary projects\non  BitBucket . The easiest way to contribute code to the project\nis by creating a pull request against the project's official repository. More details about the structure\nof this repository are explained later in this guide.",
            "title": "Contributing Code"
        },
        {
            "location": "/development-process/#jira-and-github",
            "text": "Opencast uses  Jira  for tracking issues. Each pull request should be accompanied by a\n   ticket in Jira. The issue identifier should also be used in the title of the pull request and the commits. E.g.:\n    MH-12345, Fixing Something Somewhere . Creating a Jira ticket is usually the first step when fixing something.    Opencast uses  GitHub  for code hosting.\n   Please  fork \n   the  official repository  on GitHub\n   to  create pull requests  from your repository\n   which will show up on the project's list of open pull requests.    All open pull requests are listed on the  Opencast Pull Request Filter . It might\n   take a couple of minutes for a new pull request to show up.",
            "title": "Jira and GitHub"
        },
        {
            "location": "/development-process/#bugfix-vs-feature",
            "text": "Opencast distinguishes between bug fix and feature pull requests.    Features are  only  allowed to be merged into  develop , which will let them automatically become part of the next\n   major/minor release, given that the release branch for the next release has not been cut yet. If possible, please\n   name branches containing features according to the pattern  f/MH-XXXXX-short-description , where MH-XXXXX is the\n   relevant Jira ticket.    Bug fixes can be merged both into  develop  and into release branches. If possible, please name branches containing\n   bug fixes according to the pattern  t/MH-XXXXX-short-description , where MH-XXXXX is the relevant Jira ticket.",
            "title": "Bugfix vs Feature"
        },
        {
            "location": "/development-process/#reviews",
            "text": "Before a patch is merged, it needs to be reviewed by a committer. The reviewer makes sure that the patch merges\nwithout conflicts, that it works as expected and that it does not break anything else.  If the reviewer discovers any kind of issue, he should comment on the pull request in GitHub, so that the author can\nfix the problem.  For more details about the review and merge process, have a look at  Reviewing, Merging and Declining Pull\nRequests .",
            "title": "Reviews"
        },
        {
            "location": "/development-process/#pull-request-guidelines",
            "text": "When reviewing a pull request, it is always easier if the reviewer knows what the ticket is about, and has a rough idea\nof what work has been done.  To this end, there are a few expectations for all pull requests:   For each pull request a JIRA ticket should be created  The JIRA ticket and JIRA ticket title should be the pull request title  The pull request description should contain a summary of the work done, along with reasoning for any major change  The JIRA ticket should contain the same information  For feature pull requests, accompanying documentation should be included  It is encouraged, but not required that the pull request have a clean commit history  In the case of major user interface changes, it is good practice to include screenshots of the affect sections of\n   the interface  If you add or modify any external libraries ensure that those additions and modifications are also applied to the\n   NOTICES file  Any actions that would be required for a version upgrade (e.g: from 3.x to 4.x) must be documented in\n   docs/guides/admin/docs/upgrade.md  The commands  mvn clean install ,  mvn javadoc:javadoc javadoc:aggregate , and  mvn site  should all succeed  The licenses of any external libraries used in the pull request comply with the  licensing rules  both\n   in terms of the license itself as well as its listing in NOTICES   While a committer may accept a patch even if it does not meet these expectations, it is encouraged that anyone filing\na pull request ensures that they meet these expectations.",
            "title": "Pull Request Guidelines"
        },
        {
            "location": "/development-process/#git-repository-branching-model",
            "text": "While the Opencast repository and branching model is inspired by GitFlow , there have been some distinct changes to how release\nbranches are used and releases are tagged. The purpose of this is mainly to support multiple, simultaneous versions and\nmaintenance releases.  Swift overview:   The  develop  branch represents the latest state of development. Features may be merged into this branch and into\n   this branch only. Release branches are branched off from  develop . It is basically the preparation for the next big\n   release at all times.  The release branches are named  r/<a>.<b>.x  (e.g.  r/1.6.x ). They are the latest state of development for a\n   specific release. Only bug fixes and no features may be added to these branches. All beta versions, release\n   candidates and final releases are made from these branches. The branch lives on as long as there may be additional\n   maintenance releases for a given version.  Git tags are created to indicate official releases. These may be:  x.y.z-betaX  marks a beta release. This is usually a version which may still have bugs but is good enough for\n  testing, so that further issues or bugs can be identified before an actual release.  x.y.z-rcX  marks a release candidate. This is a version that seems to be ready to be released as a final\n  version. It will become the final version if testing does not reveal any severe issues.  x.y.z  marks a final release.     To get a closer look at the branching model, let us consider a simple example with a single release:  develop ---*----*----*------*------- ... -----------*-->\n            \\       /      /                       /\n    r/1.6.x  *-----*------*-------------*---------*----- ... ---*-->\n                           \\             \\         \\             \\\n                1.6.0-beta1 *   1.6.0-rc1 *   1.6.0 *       1.6.1 *  As described above,  develop  is the branch used for preparing the next version. At some point marked in the release\nschedule, the release branch is cut from  develop . This action also marks the feature freeze for such Opencast version,\ni.e. the moment when no new features will be included in that specific version. This is because all the new features\nmust be merged only into the  develop  branch; therefore, the release branches (such as  r/1.6.x  in our example) can\nonly contain features that were merged before the branch was forked off. Any features merged after the creation of the\nrelease branch can only make it into the next release, but not into this one.  After the release branch is cut, the development on the  develop  branch may continue as before. Features can (and\nshould) be merged without waiting for the next version to be released. Thus, the creation of a release branch also marks\nthe beginning of the development for the next version.  In contrast to that, only bug fixes may be merged into the release branch. At this point, the code contained in this\nbranch should be tested, so that bugs can be identified and fixed. The release manager can tag different beta versions\nduring the QA process (such as  1.6.0-beta1 ) to mark the code evolution as bug fixes are merged. Once the branch status\nseems to be stable enough to be released, a release candidate (RC) is tagged and tested ( 1.6.0-rc1 ). New RCs can be\ntagged as long as new issues are found and fixed. When no severe issues are found, the final release is tagged.  During the whole process the release manager will regularly merge back the release branch into  develop  or, if\nexistent, the next active release branch so that bug fixes from the release branch will automatically become part of the\nnext Opencast versions and finally  develop , without having to create additional pull requests. For example, a pull\nrequest may be merged into  r/3.x ,  r/3.x  will then be merged into  develop  or, if it already exists,  r/4.x  and\nfrom there into  develop . That way patches bubble through all newer versions and finally end up in  develop .  The releases themselves are not part of the release branch. Instead, the release manager branches off, makes the\nnecessary changes to the pom files (and possibly the UI) and creates a separately tagged commit.  Finally, after a release is done, more bug fixes may be added to the release branch. The release manager should identify\nif there are enough commits to be put into a maintenance release.  Even after an Opencast version has been released, more bugs may be found and fixes for them merged into the release\nbranch. When the release manager considers that the number or importance of such bug fixes is sufficient, he may decide\nto create a new maintenance release. The version  1.6.1  above is an example of that.",
            "title": "Git Repository Branching Model"
        },
        {
            "location": "/development-process/#release-process",
            "text": "As indicated above, the release cycle of a new Opencast version starts when a release branch is cut. The new features\nmerged into  develop  afterwards will be part of the next version, but not the one just cut.  This is why the position of release manager for the next Opencast version should be assigned at this point. The current\nrelease manager should therefore ask for volunteers in the mailing lists. For more details about the rights and\nresponsibilities of a release manager, please have a look at the  Release Manager Guide .",
            "title": "Release Process"
        },
        {
            "location": "/development-process/#preparations",
            "text": "The first phase of the release consists of adding new features and defining the release schedule. It is the duty of the\nrelease manager to orchestrate this. This does not necessarily mean that release managers merge or review pull requests,\nbut that they talk to developers and ensure the merge process is driven forward.",
            "title": "Preparations"
        },
        {
            "location": "/development-process/#release-schedule",
            "text": "Releases should happen twice a year, usually within a time span of 9.5 months between the cut of the previous release\nbranch and the final release. The release manager should create a release schedule as soon as possible, identifying when\nthe release branch is cut and when the final release will happen. Additionally, he should coordinate with the QA manager\nto identify phases for internal and public testing.  Usually, a release schedule will look like this:     Date  What is happening      April 6th  Feature Freeze  (release branch is cut)    April 6th - 24th  Internal QA and bug fixing phase    \u00a0  April 11th - 17th  Review Test Cases  (handles by a dedicated team)    \u00a0  April 18th - 24th  Documentation Review    April 25th - May 15th  Public QA phase    May 15th - June 1st  Additional bug fixing phase    \u00a0  May 25th - June 1st  Translation week  (encourage translators to do their work)    June 2nd - June 12th  Final QA phase  (checking release readiness)    June 15th  Final Release",
            "title": "Release Schedule"
        },
        {
            "location": "/development-process/#release-branch",
            "text": "The release branch is created from  develop . The release branch is named  r/A.B.x  (e.g.  r/2.1.x ) to indicate that it\nis the origin of all releases with the major and minor version of  A.B . The creation of the release branch marks the\nfeature freeze for a given version, as no more features can be merged into a release branch.  To ensure that all fixes that go into the release branch will become part of  develop  (and thus part of the next version\nof Opencast) with a minimum amount of work, the release manager will merge the release branch into  develop  on a\nregular basis. He may request assistance from certain developers in case of merge conflicts. This process continues until\nthe next release branch is cut.",
            "title": "Release Branch"
        },
        {
            "location": "/development-process/#tags",
            "text": "Git tags are used to mark explicit Opencast versions or releases. Here is how a release should look like in the history:  r/A.B.x  ------------(A)---->\n                       \\\n           A.B.0-beta1 (B)  To create a version based on a given state of the release branch (commit A), the release manager will branch off from\nthis commit, make the necessary version changes to all  pom.xml  files and to the UI and create a commit and a  signed \ngit tag on this commit. He would then push the commit and the tag (not the branch) to the community repository.  For more details about how to create a release, have a look at the  Release Manager Guide .",
            "title": "Tags"
        },
        {
            "location": "/development-process/#beta-versionsrelease-candidates",
            "text": "A beta release ( A.B.C-betaX ) should be cut before the public QA phase. It indicates a specific version of Opencast for\nusers to test. It is expected to still have bugs. Beta releases should continue until all bugs with a severity of Blocker  have been fixed.  If the code seems to be ready for a release, a  release candidate  ( A.B.C-rcX ) should be cut for final testing. The\ncommit from which a release candidate is created is expected to become the final release if no severe bugs are found.",
            "title": "Beta Versions/Release Candidates"
        },
        {
            "location": "/development-process/#final-release",
            "text": "Once a release candidate seems to be stable during the QA phase (no issues left marked as  Blocker ), the release manager\nwill propose this release candidate to become the final release. If the proposal is approved (i.e. no serious bugs are\nfound before the proposal deadline is met), the final release is then created from the same commit the\nrelease candidate was cut from.",
            "title": "Final Release"
        },
        {
            "location": "/development-process/#maintenance-releases",
            "text": "After a final release, additional issues may show up. These issues may be fixed on the ongoing release branch and at\nsome point released as maintenance release.  There is usually no release schedule for maintenance releases. It is up to the release manager to decide when it is\nworthwhile to create a maintenance release with the fixes for bugs affecting a given release. He would then announce his\nintention to create such a release, cut a release candidate and, should no severe issues with this candidate show up, cut\nthe maintenance release.",
            "title": "Maintenance Releases"
        },
        {
            "location": "/development-process/#quality-assurance",
            "text": "As any piece of software, Opencast may contain bugs. It is the duty of the whole community to identify these bugs,\nreport them and possibly fix them to improve Opencast as product.  Additionally, before releasing a new version of Opencast, the current release manager and quality assurance manager will\ncoordinate test phases dedicated to new releases in order to identify possible problems ahead of time. The whole\ncommunity will be requested to participate in this testing.",
            "title": "Quality Assurance"
        },
        {
            "location": "/development-process/#reporting-bugs",
            "text": "If you identify any bugs, please report them! To do that, register yourself in the  Opencast\nJira  and create a new ticket. Please describe in detail how to reproduce the problem and\nespecially set the  Affects Version  and \"Fix Version\", where  Fix Version  should be the next Opencast release.  If in doubt of any items in the ticket, please assign it for review to either the current release manager or to the\nquality assurance manager. They will check the issue fields and adjust  fix version ,  severity , etc. if necessary.",
            "title": "Reporting Bugs"
        },
        {
            "location": "/development-process/#security-issues",
            "text": "If you discover a problem that has severe implications for system security, please do not publish this information on\nlist. Instead, send a report of the problem to  security@opencast.org . The message will be forwarded to the private\ncommitters list, where the issue will be discussed. Once a patch for the problem is ready, a security notice will be\nreleased along with it.",
            "title": "Security Issues"
        },
        {
            "location": "/development-process/#unit-tests",
            "text": "All Opencast modules should have built-in unit tests to check that they are actually doing what they are supposed to do\nand that code patches do not break the existing functionality. These tests are automatically run whenever the project is\nbuilt. If building repeatedly fails due to test failures, then something is most likely wrong. Please report this as a\nsevere bug.",
            "title": "Unit Tests"
        },
        {
            "location": "/development-process/#user-tests",
            "text": "Before each major release, the release and quality assurance managers will ask the whole community to participate in\nthe execution of a set of manual tests. These tests are designed to check that important functionalities of Opencast\nwork as expected even if users are in slightly different environments or choose different methods to achieve a certain\ngoal.  Such a call for participation will usually be raised both on the lists, the technical and the adopters meeting.  If it\nis possible for you to participate, please do so. Identifying possible problems early will immensely benefit the release\nprocess.",
            "title": "User Tests"
        },
        {
            "location": "/development-process/#test-server",
            "text": "Some institutions provide public testing infrastructure for Opencast. Use them to try out the most recent development\nversion of Opencast. They are meant for testing. Do not fear to break them.  If you manage to do it, please contact the\nQA manager or send a notice to the list.  Remember that they are usually not running a stable version of Opencast but the latest development release (beta version\nor release candidate) instead. If you discover any bugs on these systems, please take a minute to report them.",
            "title": "Test Server"
        },
        {
            "location": "/reviewing-and-merging/",
            "text": "Reviewing, Merging and Declining Pull Requests\n\n\nBefore a patch is merged into an official branch, it needs to be reviewed by a committer. During a\nreview, the reviewer tries to make sure that the patch merges without conflicts, that it works as expected and that\nit does not break anything else.\n\n\nIf the reviewer discovers any kind of issue, he should leave a comment in the pull request view of GitHub and let the\ncontributor fix the problem. Reviewer and contributor should work together to fix any problem with the pull requests\nbefore it is ready to go into the codebase.\n\n\nReviewing Rules\n\n\n\n\nReviews and merges need to be done by committers.\n\n\nReviewers should come from a different institution than the contributor.\n\n\nPull requests for bug fixes or documentation may be reviewed and merged out of order.\n\n\nFeature pull requests have to be merged in order unless their contributor or reviewer decide to temporarily skip it.\n   Such a decision has to be justified by the existence of unresolved issues in that particular pull request.\n\n\nThere is a so-called \u201cmerge ticket\u201d in Jira for \ndevelop\n and for each release branch. Committers must not merge code\n   into these branches unless they are the assignee of the corresponding ticket.\n\n\nBy default, the merge ticket for \ndevelop\n should be always assigned to the reviewer of the next feature pull request\n   to be merged.\n\n\nThe merge ticket for \ndevelop\n, can be temporarily taken by anyone for merging a bug fix after coordinating this with\n   the current assignee of the ticket\n\n\nNo features can be merged in the release branches, so the merge tickets corresponding to a release branch will be\n   unassigned by default. Reviewers merging bug fixes must assign the ticket to themselves before doing so, and then\n   leave it unassigned after finishing.\n\n\nThe release ticket should not be unassigned for longer than 72 hours in which case the release manager should assign\n   it to the reviewer of the next pull request in line.\n\n\nAfter taking up a review (or being assigned to one), a basic review has to be done within the following 14 days for a\n   bug fix or 21 days for a feature. A basic review means that either some issues should be pointed out or the pull\n   request should be approved.\n\n\nNo pull request shall be without a reviewer for more than 14 days. If no committer is willing to take up the review\n   on their own, the review will be assigned.\n\n\nAny committer may merge an arbitrary set of \napproved\n pull requests, even if he is not the official reviewer, given\n   that:\n\n\nThe committer sends an announcement to the development list 24 hours in advance, including a list of the pull\n  requests to be merged and no other committer objects to that.\n\n\nThe committer checks that all the patches are working (which basically means to review the patch set as a whole).\n\n\n\n\n\n\nA reviewer may decline a pull request if issues were pointed out but were neither fixed nor discussed for more than\n   14 days. It is generally suggested to try to contact the contributor before declining the pull request and to\n   additionally bring the problem up at the technical meeting.\n\n\n\n\nReviewing a Pull Request\n\n\nThere is no list of things you are required to do as reviewer of a pull request. Our primary goals in doing reviews for\nall pull requests are to ensure that:\n\n\n\n\nThere are no bugs in the pull request\n\n\nThe feature works as advertised\n\n\nIt does not break any other features\n\n\n\n\n\n\nThere are no obvious legal problems\n\n\nLicenses seem to be fine\n\n\nLicenses are added to the \nNOTICES\n file\n\n\n\n\n\n\nFeature documentation is in place\n\n\nAn upgrade path exists (usually relevant for database changes)\n\n\n\n\nThe exact review process heavily depends on the type, size and purpose of the pull request. For example, it does not\nmake sense to run the unit or integration tests for pull requests containing documentation only. Instead, reviewers\nshould run \nmkdocs\n to build the documentation.\n\n\nHere are some things a reviewer should usually do:\n\n\n\n\nCheck if code looks sensible (e.g. no nonsensical files, no obvious formatting errors, no large binary files, \u2026)\n\n\nPerform the merge locally to make sure there are no conflicts\n\n\nBuild Opencast with the \n-P dev,dist\n flag (build all modules) and tests enabled (default). If you have some more time\n   (e.g. lunch break), clear your local Maven repository (usually \n~/.m2\n) before starting the build process\n\n\nLocally run Opencast to make sure it still works after the merge\n\n\nMake sure the issue has been fixed (as described in the pull request and/or the Jira ticket) or the feature does\n   what it is supposed to\n\n\nCheck and build the documentation",
            "title": "Reviewing, Merging and Declining Pull Requests"
        },
        {
            "location": "/reviewing-and-merging/#reviewing-merging-and-declining-pull-requests",
            "text": "Before a patch is merged into an official branch, it needs to be reviewed by a committer. During a\nreview, the reviewer tries to make sure that the patch merges without conflicts, that it works as expected and that\nit does not break anything else.  If the reviewer discovers any kind of issue, he should leave a comment in the pull request view of GitHub and let the\ncontributor fix the problem. Reviewer and contributor should work together to fix any problem with the pull requests\nbefore it is ready to go into the codebase.",
            "title": "Reviewing, Merging and Declining Pull Requests"
        },
        {
            "location": "/reviewing-and-merging/#reviewing-rules",
            "text": "Reviews and merges need to be done by committers.  Reviewers should come from a different institution than the contributor.  Pull requests for bug fixes or documentation may be reviewed and merged out of order.  Feature pull requests have to be merged in order unless their contributor or reviewer decide to temporarily skip it.\n   Such a decision has to be justified by the existence of unresolved issues in that particular pull request.  There is a so-called \u201cmerge ticket\u201d in Jira for  develop  and for each release branch. Committers must not merge code\n   into these branches unless they are the assignee of the corresponding ticket.  By default, the merge ticket for  develop  should be always assigned to the reviewer of the next feature pull request\n   to be merged.  The merge ticket for  develop , can be temporarily taken by anyone for merging a bug fix after coordinating this with\n   the current assignee of the ticket  No features can be merged in the release branches, so the merge tickets corresponding to a release branch will be\n   unassigned by default. Reviewers merging bug fixes must assign the ticket to themselves before doing so, and then\n   leave it unassigned after finishing.  The release ticket should not be unassigned for longer than 72 hours in which case the release manager should assign\n   it to the reviewer of the next pull request in line.  After taking up a review (or being assigned to one), a basic review has to be done within the following 14 days for a\n   bug fix or 21 days for a feature. A basic review means that either some issues should be pointed out or the pull\n   request should be approved.  No pull request shall be without a reviewer for more than 14 days. If no committer is willing to take up the review\n   on their own, the review will be assigned.  Any committer may merge an arbitrary set of  approved  pull requests, even if he is not the official reviewer, given\n   that:  The committer sends an announcement to the development list 24 hours in advance, including a list of the pull\n  requests to be merged and no other committer objects to that.  The committer checks that all the patches are working (which basically means to review the patch set as a whole).    A reviewer may decline a pull request if issues were pointed out but were neither fixed nor discussed for more than\n   14 days. It is generally suggested to try to contact the contributor before declining the pull request and to\n   additionally bring the problem up at the technical meeting.",
            "title": "Reviewing Rules"
        },
        {
            "location": "/reviewing-and-merging/#reviewing-a-pull-request",
            "text": "There is no list of things you are required to do as reviewer of a pull request. Our primary goals in doing reviews for\nall pull requests are to ensure that:   There are no bugs in the pull request  The feature works as advertised  It does not break any other features    There are no obvious legal problems  Licenses seem to be fine  Licenses are added to the  NOTICES  file    Feature documentation is in place  An upgrade path exists (usually relevant for database changes)   The exact review process heavily depends on the type, size and purpose of the pull request. For example, it does not\nmake sense to run the unit or integration tests for pull requests containing documentation only. Instead, reviewers\nshould run  mkdocs  to build the documentation.  Here are some things a reviewer should usually do:   Check if code looks sensible (e.g. no nonsensical files, no obvious formatting errors, no large binary files, \u2026)  Perform the merge locally to make sure there are no conflicts  Build Opencast with the  -P dev,dist  flag (build all modules) and tests enabled (default). If you have some more time\n   (e.g. lunch break), clear your local Maven repository (usually  ~/.m2 ) before starting the build process  Locally run Opencast to make sure it still works after the merge  Make sure the issue has been fixed (as described in the pull request and/or the Jira ticket) or the feature does\n   what it is supposed to  Check and build the documentation",
            "title": "Reviewing a Pull Request"
        },
        {
            "location": "/release-manager/",
            "text": "Release Manager Guide\n\n\nRole\n\n\nThe release manager is ultimately responsible for making sure that the development process is being followed during his\nor her release.\n\n\nThe release manager has the following duties:\n\n\n\n\nTo ensure that the release measures up to the quality expected by the community.\n\n\nTo ensure that the development process is followed and amended if required.\n\n\nTo ensure that the release is timely and does not languish in process.\n\n\nTo encourage committers to be involved in testing and fixing of bugs.\n\n\n\n\nIt is in the release manager's responsibility to force decisions around the release, help negotiate the acceptance or\nrejection of contributions and to provide regular updates about the release on list and during the weekly technical and\nmonthly adopter meetings. It is important to note that, while the release manager drives the release process, the\ncommitter body is in charge of both the work and the decision making, meaning that votes and successful proposals from\nthis body take precedence over a release managers decision.\n\n\nThe release manager does not have to be a committer. In case the release manager is not, a committer must agree to be\nthe proxy release manager for communication on the confidential committers list.\n\n\nA release manager can abandon the release at any time, giving up their duties and privileges of being the release\nmanager. The committer list must then either vote within 72 hours on a new release manager, or consider the release\nabandoned (the major, minor, and maintenance numbers remain unchanged).\n\n\nDuties\n\n\nSetting Release Schedule\n\n\nReleases should happen twice a year, usually within a time span of 9.5 months between the cut of the previous release\nbranch and the final release. The release manager should create a release schedule as soon as possible.\nFor more details about the release schedule, have a look at the \nDevelopment Process\n\n\nCreation of Release Branch\n\n\nAccording to the set release schedule, at one point a release branch should be cut, effectively marking a feature freeze\nfor a given release.\n\n\nOnce a release process has started, a branch should be created with the proposed version number of that release. This\nbranch is created off of \ndevelop\n and should be named \nr/N.x\n (e.g. \nr/3.x\n for the Opencast 3.0 release branch).\nIn the following command, we assume that the release branch for 3.0 is to be created. For other versions, please adjust\nthe version number accordingly.\n\n\nCreate the Branch:\n\n\n\n\n\n\nGrab the merge ticket for \ndevelop\n. You are going to make changes there and it becomes ugly if someone else changes\n   something at the same time.\n\n\n\n\n\n\nCheck out \ndevelop\n and make sure it has the latest state (replace \n<remote>\n with your remote name for the community\n   repository):\n\n\ngit checkout develop\ngit pull <remote> develop\n\n\n\n\n\n\n\nCreate and push release branch:\n\n\ngit checkout -b r/3.x\ngit push <remote> r/3.x\n\n\n\n\n\n\n\nMake sure you did not modify any files. If you did, stash those changes.\n\n\n\n\n\n\nThat is it for the release branch. Now lets make sure we update the versions in \ndevelop\n in preparation for the next\n   release:\n\n\ngit checkout develop\nfor i in `find . -name pom.xml`; do \\\n  sed -i 's/<version>3.0-SNAPSHOT<!--<version-->4.0-SNAPSHOT<!--' $i; done\n\n\n\n\n\n\n\nHave a look at the changes. Make sure no library version we use has the version \n3.0-SNAPSHOT\n and was accidentally\n   changed. Also make sure that nothing else was modified:\n\n\ngit diff\n\n\n\n\n\n\n\nCheck again for unwanted changes.\n\n\n\n\n\n\nIf everything looks fine, commit everything and push it to the community repository:\n\n\ngit commit -as\ngit push <remote--> develop\n\n\n\n\n\n\n\nFinally change the \nfixVersion\n and \nsummary\n on the merge ticket for 3.0 and create a new one for develop.\n\n\n\n\n\n\nAt this point, the developer community should then be notified. Consider using the following as a template email:\n\n\nTo: dev@opencast.org\nSubject: Release Branch for Opencast <VERSION> Cut\n\nHi everyone,\nit is my pleasure to announce that the <VERSION> release branch has now been\ncut, available as r/<VERSION>. Pull requests for bug fixes are to be made\nagainst this branch.\n\nRemember that the release schedule for this release:\n\n  <RELEASE_SCHEDULE>\n\nAs always, we hope to have a lot of people testing this version, especially\nduring the public QA phase.  Please report any bugs or issues you encounter.\n\n\n\nCheck Status of Language Translations\n\n\nOn the date when the release branch is cut, the release manager is responsible to check whether there are language\ntranslations that need to be included or excluded for the upcoming release.\nHave a look at \nInclusion and Exclusion of Languages\n for the criteria.\n\n\n\n\nCheck whether translations not yet included in Opencast meet the inclusion criteria (candidates for includsion)\n\n\nCheck whether translations in Opencast meet the exclusion criteria (endangered translations)\n\n\nPublish an announcement on the Opencast Users list that specifies:\n    a. Translations that will be included in the upcoming release\n    b. Endangered translations\n\n\n\n\nPlease create a single post on the Opencast Users list:\n\n\nTo: users@opencast.org\nSubject: Opencast <VERSION>: Language translation status\n\nHi everyone,\n\nWhile checking the translation statuses of the languages available on Crowdin (see [1]), we have found\nthat the following language translations meet the criteria to be included in Opencast <VERSION>:\n\n- <LANGUAGE1> (<PERCENTAGE1>)\n- <LANGUAGE2> (<PERCENTAGE2>)\n- ....\n\nSincerly,\nYour Opencast <VERSION> Release Manager\n\n[1] Opencast project on Crowdin, https://crowdin.com/project/opencast-community\n[2] Inclusion and Exclusion of Translations, https://docs.opencast.org/develop/developer/...\n\n\n\nIn case endangered languages have been identified, this needs to be communicated immediately to the Opencast community.\nPlease create a post for each endangered translation on the Opencast Users list:\n\n\nTo: users@opencast.org\nSubject: Opencast <VERSION>: <LANGUAGE> translation is endangered! [HELP NEEDED!]\n\nHi everyone,\n\nWhile checking the translation status of the <LANGUAGE> translation, we have found that it is\nonly <PERCENTAGE> translated.\n\nThis is not enough to justify its inclusion in the upcoming Opencast release (see [1]).\n\nWe hereby declare the <LANGUAGE> translation endangered! This means that it will not be included in\nOpencast <VERSION> unless it is saved by the community.\n\nTo save the <LANGUAGE> translation from removal from the Opencast release, <LANGUAGE> needs to be\ntranslated at least 90% until <DATE>.\n\nSincerly,\nYour Opencast <VERSION> Release Managers\n\n[1] Inclusion and Exclusion of Translations, https://docs.opencast.org/\n\n\n\nCreating the Merge Ticket\n\n\nThe \nOpencast pull request filter\n links the versions currently in development. The\nmerge ticket identifier needs to be added to that filter. To do this, create a ticket with a title in the format of\n\nMerge the result of the current peer review to <VERSION>\n. The ticket will be automatically detected by the pull \nrequest filter and will appear shortly.\n\n\nCreating the Release Version\n\n\nThe release manager is responsible for creating, or triggering the creation of, the appropriate fix version for the new\nrelease. You may be able to do this yourself by assigning a new fix version to their newly created merge ticket. If you\nare unable to do that, please contact one of the JIRA administrators so we can create it for you!\n\n\nRelease Documentation\n\n\nThe \nOpencast release documentation\n will be built automatically from available release tags.\nHowever, new branches need to be included.  As release manager, please talk to\nthe \nadministrator\n of that\ntool to ensure the ticket is added.\n\n\nModeration of Peer Reviews\n\n\nApart from creating branches and tags, one of the most important things for release managers to do is to ensure that\npull requests for the release are going forward. This does not mean that the release manager has to do the reviews, but\nhe should talk to developers, remind them about outstanding reviews and help to resolve possible issues.\n\n\nMerging Release Branch Into Develop\n\n\nTo not have to merge bug fixes into several branches and create several pull requests, the release manager should merge\nthe release branch back into \ndevelop\n on a regular basis. It is encouraged to do that frequently, to not let the\nbranches diverge too much and to avoid possible merge conflicts.\n\n\nTo merge the release branch into \ndevelop\n. As example, we do that for 3.0. Please adjust the version accordingly:\n\n\n\n\n\n\nGrab the merge ticket for \ndevelop\n. You are not doing any changes to the release branch, so you will not need that\n   merge ticket. If someone else holds the merge ticket for a feature pull request, talk to that person that you will\n   temporarily steal the ticket.\n\n\n\n\n\n\nUpdate release branch:\n\n\ngit checkout r/3.x\ngit pull <remote> r/3.x\n\n\n\n\n\n\n\nUpdate \ndevelop\n:\n\n\ngit checkout develop\ngit pull <remote> develop\n\n\n\n\n\n\n\nMerge the release branch. Not that if large merge conflicts arise, you may ask for help from the people creating the\n   problematic patches:\n\n\ngit merge r/3.x\n\n\n\n\n\n\n\nPush updated branch into the community repository:\n\n\ngit push <remote> develop\n\n\n\n\n\n\n\nLeave a comment in the merge ticket and assign it back to the next pull request in line on \ndevelop\n.\n\n\n\n\n\n\nUpdating Translations\n\n\nUpdating the \nlocalization translations\n is easy, and should be done at minimum as part of every\nrelease candidate.\n\n\nBeta Versions and Release Candidates\n\n\nFor testing purposes, the release manager should regularly create beta versions. Especially before the public QA phase,\na beta version should exist. Additionally, he should create a release candidate for testing before proposing that a\nrelease be cut.\n\n\nCreate a version/tag. Again, version 3.0 is used as example. Please adjust the version accordingly:\n\n\n\n\n\n\nSwitch to release branch you want to create the beta from:\n\n\ngit checkout r/3.x\n\n\n\n\n\n\n\nSwitch to a new branch to create the release (name does not really matter):\n\n\ngit checkout -b r/3.0-beta1\n\n\n\n\n\n\n\nUpdate the \nlocalization translations\n.\n\n\n\n\n\n\nMake version changes for release. You can use \nsed\n to make things easier. Please make sure, the changes are correct:\n\n\nfor i in `find . -name pom.xml`; do \\\n  sed -i 's/<version>3.0-SNAPSHOT<!--<version-->3.0-beta1<!--' $i; done\n\n\n\n\n\n\n\nCommit changes and create release tag:\n\n\ngit commit -asS -m 'Opencast 3.0-beta1'\ngit tag -s 3.0-beta1\n\n\n\n\n\n\n\nSwitch back to release branch and push tags:\n\n\ngit checkout r/3.x\ngit push <remote--> 3.0-beta1:3.0-beta1\n\n\n\n\n\n\n\nYou can remove the new branch afterwards:\n\n\ngit branch -D r/3.0-beta1\n\n\n\n\n\n\n\nFor a release candidate, instead of \nA.B-betaX\n the tag should be named \nA.B-rcX\n.\n\n\nAt this point the developer community should then be notified. Consider using the following email template:\n\n\nTo: dev@opencast.org\nSubject: <VERSION> Available for testing!\n\nHi everyone,\nI am pleased to announce that Opencast <VERSION> is now available for\ntesting. Please download the source from GitHub [1] or use git to check\nout the tag.\n\nIssue Count:\n\n  Blockers   <BLOCKER_COUNT>\n  Critical   <CRITICAL_ISSUE_COUNT>\n  Major      <MAJOR_ISSUE_COUNT>\n  Minor      <MINOR_ISSUE_COUNT>\n\nPlease test this release as thoroughly as\npossible.\n\n[1] https://github.com/opencast/opencast/releases\n\n\n\nIf the version is a release candidate, you probably want to highlight that there are no \nBlockers\n left at the moment\nand \n#propose\n this to become the final release.\n\n\nReleasing\n\n\nOnce the proposal for a release candidate to become the final release has passed, the release manager should create the\nfinal release. In the following example, again, version 3.0 is used. Please adjust the version accordingly. We also\nassume the final release should be based on \n3.0-rc2\n.\n\n\n\n\n\n\nCheck which commit the release candidate was based on:\n\n\ngit merge-base 3.0-rc2 r/3.x\n  060dfc3e2328518ae402846577fc6e7ce3b650d7\n\n\n\n\n\n\n\nSwitch to commit you want to create the release from:\n\n\ngit checkout 060dfc3e2328518ae402846577fc6e7ce3b650d7\n\n\n\n\n\n\n\nSwitch to a new branch to create the release (name does not really matter):\n\n\ngit checkout -b r/3.0\n\n\n\n\n\n\n\nAdd release notes, and update the changelog using the \ncreate-changelog\n\n   \nhelper script\n to\n   easily format the list, the commit:\n\n\nvim docs/guides/admin/docs/releasenotes.md docs/guides/admin/docs/changelog.md\ngit commit docs/guides/admin/docs/releasenotes.md docs/guides/admin/docs/changelog.md -sS\n\n\n\n\n\n\n\nUpdate the \nlocalization translations\n.\n\n\n\n\n\n\nMerge release notes into release branch:\n\n\ngit checkout r/3.x\ngit merge r/3.0\ngit checkout r/3.0\n\n\n\n\n\n\n\nMake version changes for release. You can use \nsed\n to make things easier. Please make sure, the changes are correct:\n\n\nfor i in `find . -name pom.xml`; do \\\n  sed -i 's/<version>3.0-SNAPSHOT<!--<version-->3.0<!--' $i; done\n\n\n\n\n\n\n\nCommit changes and create release tag:\n\n\ngit commit -asS -m 'Opencast 3.0'\ngit tag -s 3.0\n\n\n\n\n\n\n\nSwitch back to release branch, push release notes and tags:\n\n\ngit checkout r/3.x\ngit push <remote--> 3.0:3.0\ngit push <remote> r/3.x\n\n\n\n\n\n\n\nYou can remove the new branch afterwards:\n\n\ngit branch -D r/3.0\n\n\n\n\n\n\n\nRelease the branch in JIRA, and create the next one. Talk to your JIRA administrators to have this done.\n\n\n\n\n\n\nPush the built artifacts to Maven. Bug the QA Coordinator to do this so that he remembers to set this up from the CI\n    servers.\n\n\n\n\n\n\nPush the built artifacts back to GitHub. Create a new release using the\n    \ngraphical user interface\n to upload the distribution tarballs\n    manually.\n\n\n\n\n\n\nUpdate \nthe website\n with a pull request, or directly if you have\n    the appropriate permissions.\n\n\n\n\n\n\nFinally, send a release notice to Opencast's announcement list. Note that posting to this list is restricted to those\nwho need access to avoid general discussions on that list. In case you do not already have permissions to post on this\nlist, please ask to be given permission. For the message, you may use the following template:\n\n\nTo: announcements@opencast.org\nSubject: Opencast <VERSION> Released\nHi all,\nit is my pleasure to announce that Opencast <VERSION> has been released and\ncan be downloaded from GitHub [1] or checked out via git.\n\nThe documentation for this release can be found at [http://docs.opencast.org].\n\nRPM and Debian packages will be available soon. Watch for announcements on\nthe users list.\n\nTo all committers and involved contributors, thank you for all your work.\nThis could not have happened without you and I am glad we were able to work\ntogether and get this release out.\n\n[1] https://github.com/opencast/opencast/releases\n\n\n\nAppointment of Next Release Manager\n\n\nIdentification of a volunteer\n\n\nAfter the release branch is cut, all work on \ndevelop\n is effectively the preparation for the next release. At this\npoint, the release manager sends an inquiry to the users, developers and community list to identify a volunteer for the\njob of release manager for the next release.\n\n\nFor that, this email template may be used:\n\n\nTo: dev@opencast.org\nSubject: Opencast <NEXT_RELEASE_VERSION> release manager wanted\n\nHi everyone,\nas release manager of Opencast <VERSION> release, it is my duty to announce\nthat the Opencast community is looking for a release manager of the upcoming\n<NEXT_RELEASE_VERSION> release between now and <INTENDED RELEASE DATE>\n(release date).\n\nNote that the release manager's duties do not contain a lot of technical\nwork. Instead, they focus on motivation, coordination, and ensuring that the\ndevelopment process [1] is being followed. The role of the release manager\nis described in more detail in the Opencast development documentation wiki\n[2].\n\nThe job does not have to be done by one person alone and it has proven good\npractice to have two people fill this job as co-release managers to help\nkeep up the process during vacation, sickness and in case of local\nemergencies.\n\nI am looking forward to your applications on list, please voice your\ninterest no later than <TWO WEEKS FROM NOW>.\n\n[1] http://docs.opencast.org/develop/developer/development/\n[2] http://docs.opencast.org/develop/developer/release-manager/\n\n\n\nInitiate the Vote\n\n\nIn the case where someone steps up and offers to fill in the role of a release manager for the upcoming release, a vote\nis held on the committers list to determine whether the candidate is deemed suitable for the position. Should there be\nmore than one candidate wanting to become the release manager for the next release, the candidate with the largest\nnumber of votes and no \u201c-1\u201d gets elected.\n\n\nThis email template may be used to initiate the vote:\n\n\nTo: committers@opencast.org\nSubject: [#proposal] Vote on Release Managers of Opencast <NEXT_RELEASE_VERSION>\n\nHi everyone,\nafter roughly two weeks of looking for candidates for the position of the\nrelease manager of the upcoming Opencast <NEXT_RELEASE_VERSION> release, I\nam happy to announce that the following Opencast members have volunteered\nfor the position and have expressed the intention of sharing the position as\nrelease managers:\n\n  <Name, Institition>\n  <Name, Institution>\n\nAs the release manager of Opencast <BRANCH_VERSION_FINAL> and in accordance\nwith the development process [1], I hereby open the vote on accepting the\napplications of <Name(s)>. The vote will be open for the coming 72h.\n\n[1] http://docs.opencast.org/develop/developer/development/\n\n\n\nAnnouncing Election Results\n\n\nVotes, once complete, are announced on the developer list by the current QA, or the last release manager.\n\n\nAs an example:\n\n\nTo: dev@opencast.org\nSubject: Release Managers of Opencast <NEXT_RELEASE_VERSION>\n\nHi everyone,\n\nIt is my pleasure to announce that the following person/people have been\nelected to position of Release Manager for the upcoming Opencast <NEXT_RELEASE_VERSION>\nrelease:\n\n  <Name, Institution>\n  <Name, Institution>\n\nWe wish to thank them for volunteering, and hope the release goes smoothly!\n\n\n\nOnce the vote has been held, the current release manager announces the elected release manager on list, and the newly\nelected release manager is expected to start work on the release shortly after.",
            "title": "Release Manager"
        },
        {
            "location": "/release-manager/#release-manager-guide",
            "text": "",
            "title": "Release Manager Guide"
        },
        {
            "location": "/release-manager/#role",
            "text": "The release manager is ultimately responsible for making sure that the development process is being followed during his\nor her release.  The release manager has the following duties:   To ensure that the release measures up to the quality expected by the community.  To ensure that the development process is followed and amended if required.  To ensure that the release is timely and does not languish in process.  To encourage committers to be involved in testing and fixing of bugs.   It is in the release manager's responsibility to force decisions around the release, help negotiate the acceptance or\nrejection of contributions and to provide regular updates about the release on list and during the weekly technical and\nmonthly adopter meetings. It is important to note that, while the release manager drives the release process, the\ncommitter body is in charge of both the work and the decision making, meaning that votes and successful proposals from\nthis body take precedence over a release managers decision.  The release manager does not have to be a committer. In case the release manager is not, a committer must agree to be\nthe proxy release manager for communication on the confidential committers list.  A release manager can abandon the release at any time, giving up their duties and privileges of being the release\nmanager. The committer list must then either vote within 72 hours on a new release manager, or consider the release\nabandoned (the major, minor, and maintenance numbers remain unchanged).",
            "title": "Role"
        },
        {
            "location": "/release-manager/#duties",
            "text": "",
            "title": "Duties"
        },
        {
            "location": "/release-manager/#setting-release-schedule",
            "text": "Releases should happen twice a year, usually within a time span of 9.5 months between the cut of the previous release\nbranch and the final release. The release manager should create a release schedule as soon as possible.\nFor more details about the release schedule, have a look at the  Development Process",
            "title": "Setting Release Schedule"
        },
        {
            "location": "/release-manager/#creation-of-release-branch",
            "text": "According to the set release schedule, at one point a release branch should be cut, effectively marking a feature freeze\nfor a given release.  Once a release process has started, a branch should be created with the proposed version number of that release. This\nbranch is created off of  develop  and should be named  r/N.x  (e.g.  r/3.x  for the Opencast 3.0 release branch).\nIn the following command, we assume that the release branch for 3.0 is to be created. For other versions, please adjust\nthe version number accordingly.  Create the Branch:    Grab the merge ticket for  develop . You are going to make changes there and it becomes ugly if someone else changes\n   something at the same time.    Check out  develop  and make sure it has the latest state (replace  <remote>  with your remote name for the community\n   repository):  git checkout develop\ngit pull <remote> develop    Create and push release branch:  git checkout -b r/3.x\ngit push <remote> r/3.x    Make sure you did not modify any files. If you did, stash those changes.    That is it for the release branch. Now lets make sure we update the versions in  develop  in preparation for the next\n   release:  git checkout develop\nfor i in `find . -name pom.xml`; do \\\n  sed -i 's/<version>3.0-SNAPSHOT<!--<version-->4.0-SNAPSHOT<!--' $i; done    Have a look at the changes. Make sure no library version we use has the version  3.0-SNAPSHOT  and was accidentally\n   changed. Also make sure that nothing else was modified:  git diff    Check again for unwanted changes.    If everything looks fine, commit everything and push it to the community repository:  git commit -as\ngit push <remote--> develop    Finally change the  fixVersion  and  summary  on the merge ticket for 3.0 and create a new one for develop.    At this point, the developer community should then be notified. Consider using the following as a template email:  To: dev@opencast.org\nSubject: Release Branch for Opencast <VERSION> Cut\n\nHi everyone,\nit is my pleasure to announce that the <VERSION> release branch has now been\ncut, available as r/<VERSION>. Pull requests for bug fixes are to be made\nagainst this branch.\n\nRemember that the release schedule for this release:\n\n  <RELEASE_SCHEDULE>\n\nAs always, we hope to have a lot of people testing this version, especially\nduring the public QA phase.  Please report any bugs or issues you encounter.",
            "title": "Creation of Release Branch"
        },
        {
            "location": "/release-manager/#check-status-of-language-translations",
            "text": "On the date when the release branch is cut, the release manager is responsible to check whether there are language\ntranslations that need to be included or excluded for the upcoming release.\nHave a look at  Inclusion and Exclusion of Languages  for the criteria.   Check whether translations not yet included in Opencast meet the inclusion criteria (candidates for includsion)  Check whether translations in Opencast meet the exclusion criteria (endangered translations)  Publish an announcement on the Opencast Users list that specifies:\n    a. Translations that will be included in the upcoming release\n    b. Endangered translations   Please create a single post on the Opencast Users list:  To: users@opencast.org\nSubject: Opencast <VERSION>: Language translation status\n\nHi everyone,\n\nWhile checking the translation statuses of the languages available on Crowdin (see [1]), we have found\nthat the following language translations meet the criteria to be included in Opencast <VERSION>:\n\n- <LANGUAGE1> (<PERCENTAGE1>)\n- <LANGUAGE2> (<PERCENTAGE2>)\n- ....\n\nSincerly,\nYour Opencast <VERSION> Release Manager\n\n[1] Opencast project on Crowdin, https://crowdin.com/project/opencast-community\n[2] Inclusion and Exclusion of Translations, https://docs.opencast.org/develop/developer/...  In case endangered languages have been identified, this needs to be communicated immediately to the Opencast community.\nPlease create a post for each endangered translation on the Opencast Users list:  To: users@opencast.org\nSubject: Opencast <VERSION>: <LANGUAGE> translation is endangered! [HELP NEEDED!]\n\nHi everyone,\n\nWhile checking the translation status of the <LANGUAGE> translation, we have found that it is\nonly <PERCENTAGE> translated.\n\nThis is not enough to justify its inclusion in the upcoming Opencast release (see [1]).\n\nWe hereby declare the <LANGUAGE> translation endangered! This means that it will not be included in\nOpencast <VERSION> unless it is saved by the community.\n\nTo save the <LANGUAGE> translation from removal from the Opencast release, <LANGUAGE> needs to be\ntranslated at least 90% until <DATE>.\n\nSincerly,\nYour Opencast <VERSION> Release Managers\n\n[1] Inclusion and Exclusion of Translations, https://docs.opencast.org/",
            "title": "Check Status of Language Translations"
        },
        {
            "location": "/release-manager/#creating-the-merge-ticket",
            "text": "The  Opencast pull request filter  links the versions currently in development. The\nmerge ticket identifier needs to be added to that filter. To do this, create a ticket with a title in the format of Merge the result of the current peer review to <VERSION> . The ticket will be automatically detected by the pull \nrequest filter and will appear shortly.",
            "title": "Creating the Merge Ticket"
        },
        {
            "location": "/release-manager/#creating-the-release-version",
            "text": "The release manager is responsible for creating, or triggering the creation of, the appropriate fix version for the new\nrelease. You may be able to do this yourself by assigning a new fix version to their newly created merge ticket. If you\nare unable to do that, please contact one of the JIRA administrators so we can create it for you!",
            "title": "Creating the Release Version"
        },
        {
            "location": "/release-manager/#release-documentation",
            "text": "The  Opencast release documentation  will be built automatically from available release tags.\nHowever, new branches need to be included.  As release manager, please talk to\nthe  administrator  of that\ntool to ensure the ticket is added.",
            "title": "Release Documentation"
        },
        {
            "location": "/release-manager/#moderation-of-peer-reviews",
            "text": "Apart from creating branches and tags, one of the most important things for release managers to do is to ensure that\npull requests for the release are going forward. This does not mean that the release manager has to do the reviews, but\nhe should talk to developers, remind them about outstanding reviews and help to resolve possible issues.",
            "title": "Moderation of Peer Reviews"
        },
        {
            "location": "/release-manager/#merging-release-branch-into-develop",
            "text": "To not have to merge bug fixes into several branches and create several pull requests, the release manager should merge\nthe release branch back into  develop  on a regular basis. It is encouraged to do that frequently, to not let the\nbranches diverge too much and to avoid possible merge conflicts.  To merge the release branch into  develop . As example, we do that for 3.0. Please adjust the version accordingly:    Grab the merge ticket for  develop . You are not doing any changes to the release branch, so you will not need that\n   merge ticket. If someone else holds the merge ticket for a feature pull request, talk to that person that you will\n   temporarily steal the ticket.    Update release branch:  git checkout r/3.x\ngit pull <remote> r/3.x    Update  develop :  git checkout develop\ngit pull <remote> develop    Merge the release branch. Not that if large merge conflicts arise, you may ask for help from the people creating the\n   problematic patches:  git merge r/3.x    Push updated branch into the community repository:  git push <remote> develop    Leave a comment in the merge ticket and assign it back to the next pull request in line on  develop .",
            "title": "Merging Release Branch Into Develop"
        },
        {
            "location": "/release-manager/#updating-translations",
            "text": "Updating the  localization translations  is easy, and should be done at minimum as part of every\nrelease candidate.",
            "title": "Updating Translations"
        },
        {
            "location": "/release-manager/#beta-versions-and-release-candidates",
            "text": "For testing purposes, the release manager should regularly create beta versions. Especially before the public QA phase,\na beta version should exist. Additionally, he should create a release candidate for testing before proposing that a\nrelease be cut.  Create a version/tag. Again, version 3.0 is used as example. Please adjust the version accordingly:    Switch to release branch you want to create the beta from:  git checkout r/3.x    Switch to a new branch to create the release (name does not really matter):  git checkout -b r/3.0-beta1    Update the  localization translations .    Make version changes for release. You can use  sed  to make things easier. Please make sure, the changes are correct:  for i in `find . -name pom.xml`; do \\\n  sed -i 's/<version>3.0-SNAPSHOT<!--<version-->3.0-beta1<!--' $i; done    Commit changes and create release tag:  git commit -asS -m 'Opencast 3.0-beta1'\ngit tag -s 3.0-beta1    Switch back to release branch and push tags:  git checkout r/3.x\ngit push <remote--> 3.0-beta1:3.0-beta1    You can remove the new branch afterwards:  git branch -D r/3.0-beta1    For a release candidate, instead of  A.B-betaX  the tag should be named  A.B-rcX .  At this point the developer community should then be notified. Consider using the following email template:  To: dev@opencast.org\nSubject: <VERSION> Available for testing!\n\nHi everyone,\nI am pleased to announce that Opencast <VERSION> is now available for\ntesting. Please download the source from GitHub [1] or use git to check\nout the tag.\n\nIssue Count:\n\n  Blockers   <BLOCKER_COUNT>\n  Critical   <CRITICAL_ISSUE_COUNT>\n  Major      <MAJOR_ISSUE_COUNT>\n  Minor      <MINOR_ISSUE_COUNT>\n\nPlease test this release as thoroughly as\npossible.\n\n[1] https://github.com/opencast/opencast/releases  If the version is a release candidate, you probably want to highlight that there are no  Blockers  left at the moment\nand  #propose  this to become the final release.",
            "title": "Beta Versions and Release Candidates"
        },
        {
            "location": "/release-manager/#releasing",
            "text": "Once the proposal for a release candidate to become the final release has passed, the release manager should create the\nfinal release. In the following example, again, version 3.0 is used. Please adjust the version accordingly. We also\nassume the final release should be based on  3.0-rc2 .    Check which commit the release candidate was based on:  git merge-base 3.0-rc2 r/3.x\n  060dfc3e2328518ae402846577fc6e7ce3b650d7    Switch to commit you want to create the release from:  git checkout 060dfc3e2328518ae402846577fc6e7ce3b650d7    Switch to a new branch to create the release (name does not really matter):  git checkout -b r/3.0    Add release notes, and update the changelog using the  create-changelog \n    helper script  to\n   easily format the list, the commit:  vim docs/guides/admin/docs/releasenotes.md docs/guides/admin/docs/changelog.md\ngit commit docs/guides/admin/docs/releasenotes.md docs/guides/admin/docs/changelog.md -sS    Update the  localization translations .    Merge release notes into release branch:  git checkout r/3.x\ngit merge r/3.0\ngit checkout r/3.0    Make version changes for release. You can use  sed  to make things easier. Please make sure, the changes are correct:  for i in `find . -name pom.xml`; do \\\n  sed -i 's/<version>3.0-SNAPSHOT<!--<version-->3.0<!--' $i; done    Commit changes and create release tag:  git commit -asS -m 'Opencast 3.0'\ngit tag -s 3.0    Switch back to release branch, push release notes and tags:  git checkout r/3.x\ngit push <remote--> 3.0:3.0\ngit push <remote> r/3.x    You can remove the new branch afterwards:  git branch -D r/3.0    Release the branch in JIRA, and create the next one. Talk to your JIRA administrators to have this done.    Push the built artifacts to Maven. Bug the QA Coordinator to do this so that he remembers to set this up from the CI\n    servers.    Push the built artifacts back to GitHub. Create a new release using the\n     graphical user interface  to upload the distribution tarballs\n    manually.    Update  the website  with a pull request, or directly if you have\n    the appropriate permissions.    Finally, send a release notice to Opencast's announcement list. Note that posting to this list is restricted to those\nwho need access to avoid general discussions on that list. In case you do not already have permissions to post on this\nlist, please ask to be given permission. For the message, you may use the following template:  To: announcements@opencast.org\nSubject: Opencast <VERSION> Released\nHi all,\nit is my pleasure to announce that Opencast <VERSION> has been released and\ncan be downloaded from GitHub [1] or checked out via git.\n\nThe documentation for this release can be found at [http://docs.opencast.org].\n\nRPM and Debian packages will be available soon. Watch for announcements on\nthe users list.\n\nTo all committers and involved contributors, thank you for all your work.\nThis could not have happened without you and I am glad we were able to work\ntogether and get this release out.\n\n[1] https://github.com/opencast/opencast/releases",
            "title": "Releasing"
        },
        {
            "location": "/release-manager/#appointment-of-next-release-manager",
            "text": "",
            "title": "Appointment of Next Release Manager"
        },
        {
            "location": "/release-manager/#identification-of-a-volunteer",
            "text": "After the release branch is cut, all work on  develop  is effectively the preparation for the next release. At this\npoint, the release manager sends an inquiry to the users, developers and community list to identify a volunteer for the\njob of release manager for the next release.  For that, this email template may be used:  To: dev@opencast.org\nSubject: Opencast <NEXT_RELEASE_VERSION> release manager wanted\n\nHi everyone,\nas release manager of Opencast <VERSION> release, it is my duty to announce\nthat the Opencast community is looking for a release manager of the upcoming\n<NEXT_RELEASE_VERSION> release between now and <INTENDED RELEASE DATE>\n(release date).\n\nNote that the release manager's duties do not contain a lot of technical\nwork. Instead, they focus on motivation, coordination, and ensuring that the\ndevelopment process [1] is being followed. The role of the release manager\nis described in more detail in the Opencast development documentation wiki\n[2].\n\nThe job does not have to be done by one person alone and it has proven good\npractice to have two people fill this job as co-release managers to help\nkeep up the process during vacation, sickness and in case of local\nemergencies.\n\nI am looking forward to your applications on list, please voice your\ninterest no later than <TWO WEEKS FROM NOW>.\n\n[1] http://docs.opencast.org/develop/developer/development/\n[2] http://docs.opencast.org/develop/developer/release-manager/",
            "title": "Identification of a volunteer"
        },
        {
            "location": "/release-manager/#initiate-the-vote",
            "text": "In the case where someone steps up and offers to fill in the role of a release manager for the upcoming release, a vote\nis held on the committers list to determine whether the candidate is deemed suitable for the position. Should there be\nmore than one candidate wanting to become the release manager for the next release, the candidate with the largest\nnumber of votes and no \u201c-1\u201d gets elected.  This email template may be used to initiate the vote:  To: committers@opencast.org\nSubject: [#proposal] Vote on Release Managers of Opencast <NEXT_RELEASE_VERSION>\n\nHi everyone,\nafter roughly two weeks of looking for candidates for the position of the\nrelease manager of the upcoming Opencast <NEXT_RELEASE_VERSION> release, I\nam happy to announce that the following Opencast members have volunteered\nfor the position and have expressed the intention of sharing the position as\nrelease managers:\n\n  <Name, Institition>\n  <Name, Institution>\n\nAs the release manager of Opencast <BRANCH_VERSION_FINAL> and in accordance\nwith the development process [1], I hereby open the vote on accepting the\napplications of <Name(s)>. The vote will be open for the coming 72h.\n\n[1] http://docs.opencast.org/develop/developer/development/",
            "title": "Initiate the Vote"
        },
        {
            "location": "/release-manager/#announcing-election-results",
            "text": "Votes, once complete, are announced on the developer list by the current QA, or the last release manager.  As an example:  To: dev@opencast.org\nSubject: Release Managers of Opencast <NEXT_RELEASE_VERSION>\n\nHi everyone,\n\nIt is my pleasure to announce that the following person/people have been\nelected to position of Release Manager for the upcoming Opencast <NEXT_RELEASE_VERSION>\nrelease:\n\n  <Name, Institution>\n  <Name, Institution>\n\nWe wish to thank them for volunteering, and hope the release goes smoothly!  Once the vote has been held, the current release manager announces the elected release manager on list, and the newly\nelected release manager is expected to start work on the release shortly after.",
            "title": "Announcing Election Results"
        },
        {
            "location": "/qa-coordinator/",
            "text": "QA Coordinator Guide\n\n\nRole\n\n\nThe QA coordinator is ultimately responsible for making sure that quality assurance (QA) processes are occurring during\neach release window, and for other project related tasks.\n\n\nThe QA Coordinator has the following duties:\n\n\nEstablish and manage QA process, technologies, and methods\n\n\n\n\nManage CI infrastructure\n\n\nCreate and expand automated testing infrastructure\n\n\nEnsure committers are following testing procedures\n\n\n\n\nEnsure codebase stability\n\n\n\n\nCleanup obsolete branches\n\n\nHelp with merge issues\n\n\nSetup and manage automated distributable builds\n\n\nCode cleanup\n\n\n\n\nOrganize community/committers\n\n\n\n\nRemain active on list\n\n\nOrganize Technical meeting\n\n\nEncourage additional committers to join the project\n\n\nManage crowdin translators - ensure join requests are dealt with\n\n\nHandle (security issue reports)[security.md], and notifications once handled\n\n\nOccasionally purge non-active committers, moving them to the emeritus list in the main pom, and removing their\n   permissions in JIRA\n\n\n\n\nExpand documentation\n\n\n\n\nEnsure documentation is build and published\n\n\nExpand documentation, and/or organize volunteer documentation tasks",
            "title": "QA Coordinator"
        },
        {
            "location": "/qa-coordinator/#qa-coordinator-guide",
            "text": "",
            "title": "QA Coordinator Guide"
        },
        {
            "location": "/qa-coordinator/#role",
            "text": "The QA coordinator is ultimately responsible for making sure that quality assurance (QA) processes are occurring during\neach release window, and for other project related tasks.  The QA Coordinator has the following duties:  Establish and manage QA process, technologies, and methods   Manage CI infrastructure  Create and expand automated testing infrastructure  Ensure committers are following testing procedures   Ensure codebase stability   Cleanup obsolete branches  Help with merge issues  Setup and manage automated distributable builds  Code cleanup   Organize community/committers   Remain active on list  Organize Technical meeting  Encourage additional committers to join the project  Manage crowdin translators - ensure join requests are dealt with  Handle (security issue reports)[security.md], and notifications once handled  Occasionally purge non-active committers, moving them to the emeritus list in the main pom, and removing their\n   permissions in JIRA   Expand documentation   Ensure documentation is build and published  Expand documentation, and/or organize volunteer documentation tasks",
            "title": "Role"
        },
        {
            "location": "/security/",
            "text": "Opencast Security Issue Process\n\n\nThis document summarizes how issues are reported, who is responsible for what actions, and how things are handled\ninternally. The instructions here should be considered the \nminimum\n, and further/faster responses are certainly\npossible depending on the severity and type of issue.\n\n\n\n\nFor Users and Administrators\n\n\nWhat to do if you find a security issue\n\n\nReport it to \nsecurity@opencast.org\n! Please include a complete description of the issue, including which version(s) it\naffects, as well as any steps required to reproduce it. This email will be sent privately to the full list of\ncommitters for the project. You should receive an email acknowledging the issue from the QA coordinator, or release\nmanager(s) within 3 business days. At this point, depending on the issue, you may be asked for your Attlassian and GitHub\nlogins. It is enouraged to have one, since internal discussion on JIRA will be restricted to committers and the\nreporter. Likewise, all code reviews will be done on in an internal GitHub repository.\n\n\nWhat to do once you have reported your security issue\n\n\nWait, and/or help fix the issue. The committers will work to find a mitigation for the immediate case, and a proper\nsolution for the long term. This may take a while, please be patient. It may also require you to test it if the issue\nis derived from a complex system that most committers would not necessarily have access to (e.g: your LDAP or LTI\nservers).\n\n\nWhat happens once the issue has been fixed?\n\n\nA notice to \nsecurity-notices@opencast.org\n will be released once the issue has been resolved and proper patches applied\nto the codebase. This notice may be accompanied by a release, or instructions on how to patch a live system depending\non the issue.\n\n\n\n\nFor Committers\n\n\nWhat to do with a security report\n\n\nIf no one else has, create a JIRA issue with a 'Committer' security level, and the details in the security report.\nAssign the ticket either to yourself (if you intend on working on it) or nobody, and reply on \ncommitters@opencast.org\n\nwith the ticket. Thus far most of our security issues have come with patches attached, however this will not always be\ntrue. Issues which require work beyond application of a provided patch should be treated the same as any other JIRA\nissue, aside from the security level. Note that that security level will keep non-committers from viewing the ticket\nor comments. Depending on the issue and severity, the QA coordinator and/or release manager(s) may apply for a Common\n Vulnerability and Exposures (CVE) number as well.\n\n\nWhere do we review security patches?\n\n\nMinor patches can be reviewed on an adhoc basis but larger patches, especially those requring collaboration in private,\nor extensive comment and review, can use the matterhorn-security repository under the opencast-community account. Note\nthat this repository is private to committers, and reporters. Add the security repository to your remotes with this\ncommand:\n\n\ngit remote add security git@bitbucket.org:opencast-community/opencast-security.git\n\n\n\nThen create your branch locally. When the branch is ready to be pushed to the security repo do something like this:\n\n\ngit push security <your branch name>\n\n\n\nYou can then create your branch like you normally would, pushing it to security rather than your own repository.\n\n\nOnce a security issue has been resolved\n\n\nOnce a security issue has been resolved, the QA coordinator, and/or the release manager(s) affected will work together\nto ensure that any relevant release(s) are created and available, and then release the security notice. This notice\nmust contain the CVE (if applicable) and JIRA ticket number, as well as the affected version(s) of Opencast, a\ndescription of the issue, mitigation/upgrade instructions, as well as credit to the reporter(s) of the issue. As an\nexample, this is a good notice:\n\n\nHello,\nthis is the official security notice regarding a security issue\nrecently discovered in Opencast.\n\nDescription:\n\n   The Solr index for the search service (back-end e.g. for player and\n   media module) in some cases returns results that should not be\n   available to the current user.\n\n\nAffects:\n\n   This issue affects all recent versions of Opencast.\n\n\nDetails:\n\n   Solr in some cases returned results that should not be available to\n   the current user. For example, if `UserX` has the role `ROLE_USER`\n   and a video should only be available for `ROLE_USER_ADMIN`, `UserX`\n   can still access it.\n\n   This may happen only if the second role starts with the complete\n   first role. If the rules do not overlap, there should be no problem.\n\n\nPatching the system:\n\n   Patches for this issue are included in Opencast 2.2.4 and 2.3.0.\n   A patch can also be found at\n   https://bitbucket.org/opencast-community/opencast/pull-requests/1236\n\n\nCredits:\n\n  Thanks to Matthias Neugebauer from the University of M\u00fcnster for\n  finding, reporting and fixing the issue.\n\n\nBest regards,\nLars Kiesow\n\n\n\nOnce the issue has been fixed and the notice sent, the security level should be removed from the JIRA ticket so it\nbecomes publicly viewable.",
            "title": "Security Issues"
        },
        {
            "location": "/security/#opencast-security-issue-process",
            "text": "This document summarizes how issues are reported, who is responsible for what actions, and how things are handled\ninternally. The instructions here should be considered the  minimum , and further/faster responses are certainly\npossible depending on the severity and type of issue.",
            "title": "Opencast Security Issue Process"
        },
        {
            "location": "/security/#for-users-and-administrators",
            "text": "",
            "title": "For Users and Administrators"
        },
        {
            "location": "/security/#what-to-do-if-you-find-a-security-issue",
            "text": "Report it to  security@opencast.org ! Please include a complete description of the issue, including which version(s) it\naffects, as well as any steps required to reproduce it. This email will be sent privately to the full list of\ncommitters for the project. You should receive an email acknowledging the issue from the QA coordinator, or release\nmanager(s) within 3 business days. At this point, depending on the issue, you may be asked for your Attlassian and GitHub\nlogins. It is enouraged to have one, since internal discussion on JIRA will be restricted to committers and the\nreporter. Likewise, all code reviews will be done on in an internal GitHub repository.",
            "title": "What to do if you find a security issue"
        },
        {
            "location": "/security/#what-to-do-once-you-have-reported-your-security-issue",
            "text": "Wait, and/or help fix the issue. The committers will work to find a mitigation for the immediate case, and a proper\nsolution for the long term. This may take a while, please be patient. It may also require you to test it if the issue\nis derived from a complex system that most committers would not necessarily have access to (e.g: your LDAP or LTI\nservers).",
            "title": "What to do once you have reported your security issue"
        },
        {
            "location": "/security/#what-happens-once-the-issue-has-been-fixed",
            "text": "A notice to  security-notices@opencast.org  will be released once the issue has been resolved and proper patches applied\nto the codebase. This notice may be accompanied by a release, or instructions on how to patch a live system depending\non the issue.",
            "title": "What happens once the issue has been fixed?"
        },
        {
            "location": "/security/#for-committers",
            "text": "",
            "title": "For Committers"
        },
        {
            "location": "/security/#what-to-do-with-a-security-report",
            "text": "If no one else has, create a JIRA issue with a 'Committer' security level, and the details in the security report.\nAssign the ticket either to yourself (if you intend on working on it) or nobody, and reply on  committers@opencast.org \nwith the ticket. Thus far most of our security issues have come with patches attached, however this will not always be\ntrue. Issues which require work beyond application of a provided patch should be treated the same as any other JIRA\nissue, aside from the security level. Note that that security level will keep non-committers from viewing the ticket\nor comments. Depending on the issue and severity, the QA coordinator and/or release manager(s) may apply for a Common\n Vulnerability and Exposures (CVE) number as well.",
            "title": "What to do with a security report"
        },
        {
            "location": "/security/#where-do-we-review-security-patches",
            "text": "Minor patches can be reviewed on an adhoc basis but larger patches, especially those requring collaboration in private,\nor extensive comment and review, can use the matterhorn-security repository under the opencast-community account. Note\nthat this repository is private to committers, and reporters. Add the security repository to your remotes with this\ncommand:  git remote add security git@bitbucket.org:opencast-community/opencast-security.git  Then create your branch locally. When the branch is ready to be pushed to the security repo do something like this:  git push security <your branch name>  You can then create your branch like you normally would, pushing it to security rather than your own repository.",
            "title": "Where do we review security patches?"
        },
        {
            "location": "/security/#once-a-security-issue-has-been-resolved",
            "text": "Once a security issue has been resolved, the QA coordinator, and/or the release manager(s) affected will work together\nto ensure that any relevant release(s) are created and available, and then release the security notice. This notice\nmust contain the CVE (if applicable) and JIRA ticket number, as well as the affected version(s) of Opencast, a\ndescription of the issue, mitigation/upgrade instructions, as well as credit to the reporter(s) of the issue. As an\nexample, this is a good notice:  Hello,\nthis is the official security notice regarding a security issue\nrecently discovered in Opencast.\n\nDescription:\n\n   The Solr index for the search service (back-end e.g. for player and\n   media module) in some cases returns results that should not be\n   available to the current user.\n\n\nAffects:\n\n   This issue affects all recent versions of Opencast.\n\n\nDetails:\n\n   Solr in some cases returned results that should not be available to\n   the current user. For example, if `UserX` has the role `ROLE_USER`\n   and a video should only be available for `ROLE_USER_ADMIN`, `UserX`\n   can still access it.\n\n   This may happen only if the second role starts with the complete\n   first role. If the rules do not overlap, there should be no problem.\n\n\nPatching the system:\n\n   Patches for this issue are included in Opencast 2.2.4 and 2.3.0.\n   A patch can also be found at\n   https://bitbucket.org/opencast-community/opencast/pull-requests/1236\n\n\nCredits:\n\n  Thanks to Matthias Neugebauer from the University of M\u00fcnster for\n  finding, reporting and fixing the issue.\n\n\nBest regards,\nLars Kiesow  Once the issue has been fixed and the notice sent, the security level should be removed from the JIRA ticket so it\nbecomes publicly viewable.",
            "title": "Once a security issue has been resolved"
        },
        {
            "location": "/code-style/",
            "text": "Code Style\n\n\nMaven will automatically check for coding style violations for Java and interrupt the build process if any are found,\ndisplaying a message about it. Apart from that, here are some general rules:\n\n\nGeneral Rules\n\n\n\n\nUTF-8 encoded\n\n\nNo trailing spaces\n\n\nEnd files with a newline character\n\n\n\n\nJava, HTML and JavaScript\n\n\n\n\nIndentation is done with exactly two spaces\n\n\nNo line of code should be wider than 120 columns\n\n\nAvoid unnecessary code style changes\n\n\n\n\nMarkdown\n\n\n\n\nAvoid lines wider than 120 columns\n\n\nAvoid unnecessary style changes\n\n\n\n\nEverything Else\n\n\n\n\nTry applying the Java style rules\n\n\nIf in doubt, ask on list\n\n\n\n\nLogging Rules\n\n\nThe following is a list of logging levels and their use.\n\n\n\n\n\n\n\n\nLevel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nTRACE\n\n\nInformation that would only be useful when debugging a specific subsystem.\n\n\n\n\n\n\nDEBUG\n\n\nInformation relevant to development. Used to provide detailed information for developers.\n\n\n\n\n\n\nINFO\n\n\nInformation relevant to server administrators. Creating, updating, and deleting files should be logged here.\n\n\n\n\n\n\nWARN\n\n\nHandled exceptions. A warning should be logged any time there is a possible problem administrators may need to investigate..\n\n\n\n\n\n\nERROR\n\n\nUnhandled exceptions. Problems that were not automatically handled.",
            "title": "Code Style"
        },
        {
            "location": "/code-style/#code-style",
            "text": "Maven will automatically check for coding style violations for Java and interrupt the build process if any are found,\ndisplaying a message about it. Apart from that, here are some general rules:",
            "title": "Code Style"
        },
        {
            "location": "/code-style/#general-rules",
            "text": "UTF-8 encoded  No trailing spaces  End files with a newline character",
            "title": "General Rules"
        },
        {
            "location": "/code-style/#java-html-and-javascript",
            "text": "Indentation is done with exactly two spaces  No line of code should be wider than 120 columns  Avoid unnecessary code style changes",
            "title": "Java, HTML and JavaScript"
        },
        {
            "location": "/code-style/#markdown",
            "text": "Avoid lines wider than 120 columns  Avoid unnecessary style changes",
            "title": "Markdown"
        },
        {
            "location": "/code-style/#everything-else",
            "text": "Try applying the Java style rules  If in doubt, ask on list",
            "title": "Everything Else"
        },
        {
            "location": "/code-style/#logging-rules",
            "text": "The following is a list of logging levels and their use.     Level  Description      TRACE  Information that would only be useful when debugging a specific subsystem.    DEBUG  Information relevant to development. Used to provide detailed information for developers.    INFO  Information relevant to server administrators. Creating, updating, and deleting files should be logged here.    WARN  Handled exceptions. A warning should be logged any time there is a possible problem administrators may need to investigate..    ERROR  Unhandled exceptions. Problems that were not automatically handled.",
            "title": "Logging Rules"
        },
        {
            "location": "/documentation/",
            "text": "Documentation\n\n\nOne important measurement for code quality is its documentation. This is especially the case for open source projects\nthat count on the support of external developers and a strong community around the code base.  With that in mind, here\nare some of the goals you should keep in mind when working within the Opencast codebase.\n\n\nPackage Level Documentation\n\n\nPackage documentation should cover the general concepts that are being used throughout the package, along with the\nprincipal interfaces and classes that are being used.  A good example is provided by the \nJava 6 sql package description\n\n.\n\n\nWhere does the documentation go?\n\n\nThe package information should be put into a file called \npackage-info.java\n and reside in the root of the package.\nGenerally, the package-info is a java class itself consisting of documentation and package declaration only.\nDocumentation can be found \nhere\n.\n\n\nChecklist\n\n\nIn order to achieve decent package documentation, make sure your documentation answers the following questions:\n\n\n\n\nWhat problem domain does your package deal with?\n\n\nAre there any concepts that the developer should understand?\n\n\nWhat are the different strategies that your package might implement?\n\n\nWhat are the entry points into your package in terms of interfaces and classes?\n\n\nWhat best practices are there to use the package?\n\n\nWhat major requirements need to be met before being able to use the package?\n\n\nIs there related external documentation (rfc, specifications) that should be linked?\n\n\n\n\nClasses\n\n\nBy looking at the documentation of a class or an interface, the developer should have a clear idea as to how the class\ncan be used, what pitfalls there might be in terms of threading, performance etc. Again, a good example can be found in\nthe \nUrl class\n of the Java Development Kit.\n\n\nDocumentation Body\n\n\n\n\nHas a one-sentence description been given on what the class does or describe?\n\n\nIs there a description of concepts that should be known to users of the class?\n\n\nAre there possible pitfalls in the area of threading, transactions or performance?\n\n\nAre any other issues covered that might arise when using the class?\n\n\nHave any constraints be documented, like special behaviour of the \nequals()\n method?\n\n\nAre best practices on how to use the class documented?\n\n\n\n\nTags\n\n\n\n\nAre there related classes or external resources that should be linked using \n@see\n?\n\n\n\n\nMethods\n\n\nAs with type documentation, the notes on a method should consist of instructions on what to expect in terms of behaviour\nwhen the method is called. Also, the user should be informed about any constraints that might apply to the objects\nstate, the format of input parameters etc. As an example, take a look at the \nconstructor for the URL class\n\n\nof the Java Development Kit.\n\n\nDocumentation Body\n\n\n\n\nIn general, what does the method do?\n\n\nAre there any requirements regarding the format of the input parameters?\n\n\nWhat does the method return with respect to input parameter values or state?\n\n\nIf applicable, are there any constraints regarding an objects state?\n\n\nHow are special parameter values (e.g. \nnull\n) handled?\n\n\nDoes the user know what exceptions are thrown under which circumstances?\n\n\n\n\nTags\n\n\n\n\nAre the input parameters documented using the \n@param\n tag?\n\n\nIs the return value documented using the \n@return\n tag?\n\n\nAre there related methods that should be linked using \n@see\n?\n\n\nAre the exceptions documented with \n@throws\n?\n\n\n\n\nREST Endpoints\n\n\nAll Opencast REST endpoints must display HTML formatted documentation at the \n/docs\n path.\n\n\nPlease be sure that your documentation includes:\n\n\n\n\nAn entry for each path pattern, categorized as read and write paths.\n\n\nDescriptions for each path pattern, including:\n\n\nThe HTTP method (\nGET\n, \nPOST\n, \nPUT\n, \nDELETE\n, \u2026)\n\n\nRequired and optional parameters\n\n\nThe expected input, including data formats and headers\n\n\nThe expected output, including data formats, headers, and HTTP response codes",
            "title": "Documentation"
        },
        {
            "location": "/documentation/#documentation",
            "text": "One important measurement for code quality is its documentation. This is especially the case for open source projects\nthat count on the support of external developers and a strong community around the code base.  With that in mind, here\nare some of the goals you should keep in mind when working within the Opencast codebase.",
            "title": "Documentation"
        },
        {
            "location": "/documentation/#package-level-documentation",
            "text": "Package documentation should cover the general concepts that are being used throughout the package, along with the\nprincipal interfaces and classes that are being used.  A good example is provided by the  Java 6 sql package description .",
            "title": "Package Level Documentation"
        },
        {
            "location": "/documentation/#where-does-the-documentation-go",
            "text": "The package information should be put into a file called  package-info.java  and reside in the root of the package.\nGenerally, the package-info is a java class itself consisting of documentation and package declaration only.\nDocumentation can be found  here .",
            "title": "Where does the documentation go?"
        },
        {
            "location": "/documentation/#checklist",
            "text": "In order to achieve decent package documentation, make sure your documentation answers the following questions:   What problem domain does your package deal with?  Are there any concepts that the developer should understand?  What are the different strategies that your package might implement?  What are the entry points into your package in terms of interfaces and classes?  What best practices are there to use the package?  What major requirements need to be met before being able to use the package?  Is there related external documentation (rfc, specifications) that should be linked?",
            "title": "Checklist"
        },
        {
            "location": "/documentation/#classes",
            "text": "By looking at the documentation of a class or an interface, the developer should have a clear idea as to how the class\ncan be used, what pitfalls there might be in terms of threading, performance etc. Again, a good example can be found in\nthe  Url class  of the Java Development Kit.",
            "title": "Classes"
        },
        {
            "location": "/documentation/#documentation-body",
            "text": "Has a one-sentence description been given on what the class does or describe?  Is there a description of concepts that should be known to users of the class?  Are there possible pitfalls in the area of threading, transactions or performance?  Are any other issues covered that might arise when using the class?  Have any constraints be documented, like special behaviour of the  equals()  method?  Are best practices on how to use the class documented?",
            "title": "Documentation Body"
        },
        {
            "location": "/documentation/#tags",
            "text": "Are there related classes or external resources that should be linked using  @see ?",
            "title": "Tags"
        },
        {
            "location": "/documentation/#methods",
            "text": "As with type documentation, the notes on a method should consist of instructions on what to expect in terms of behaviour\nwhen the method is called. Also, the user should be informed about any constraints that might apply to the objects\nstate, the format of input parameters etc. As an example, take a look at the  constructor for the URL class \nof the Java Development Kit.",
            "title": "Methods"
        },
        {
            "location": "/documentation/#documentation-body_1",
            "text": "In general, what does the method do?  Are there any requirements regarding the format of the input parameters?  What does the method return with respect to input parameter values or state?  If applicable, are there any constraints regarding an objects state?  How are special parameter values (e.g.  null ) handled?  Does the user know what exceptions are thrown under which circumstances?",
            "title": "Documentation Body"
        },
        {
            "location": "/documentation/#tags_1",
            "text": "Are the input parameters documented using the  @param  tag?  Is the return value documented using the  @return  tag?  Are there related methods that should be linked using  @see ?  Are the exceptions documented with  @throws ?",
            "title": "Tags"
        },
        {
            "location": "/documentation/#rest-endpoints",
            "text": "All Opencast REST endpoints must display HTML formatted documentation at the  /docs  path.  Please be sure that your documentation includes:   An entry for each path pattern, categorized as read and write paths.  Descriptions for each path pattern, including:  The HTTP method ( GET ,  POST ,  PUT ,  DELETE , \u2026)  Required and optional parameters  The expected input, including data formats and headers  The expected output, including data formats, headers, and HTTP response codes",
            "title": "REST Endpoints"
        },
        {
            "location": "/decision-making/",
            "text": "Decision Making\n\n\nThe most important thing about engaging with Opencast is that all people with an opinion are entitled to express that\nopinion and, where appropriate, have it considered by the community.\n\n\nTo some, the idea of having to establish consensus in a large and distributed team sounds inefficient and frustrating.\nDo not despair though, we have a set of simple processes to ensure things proceed at a good pace.\n\n\nIn Opencast we do not like to vote. We reserve that for the few things that need official approval for legal or\nprocess reasons (e.g. a release or a new committer). Most of the time we work with the consensus building techniques\ndocumented below.\n\n\nLazy Consensus\n\n\nLazy consensus\n is the first, and possibly the most important, consensus building tool we have.\nEssentially lazy consensus means that you do not need to get explicit approval to proceed, but you need to be prepared\nto listen if someone objects.\n\n\nConsensus Building\n\n\nSometimes lazy consensus is not appropriate. In such cases it is necessary to make a proposal to the mailing list and\ndiscuss options. There are mechanisms for quickly showing your support or otherwise for a proposal and \nbuilding\nconsensus\n amongst the community.\n\n\nOnce there is a consensus people can proceed with the work under the \nlazy consensus\n model.\n\n\nVoting\n\n\nOccasionally a \"feel\" for consensus is not enough. Sometimes we need to have a measurable consensus. For example, when\n\nvoting\n in new committers or to approve a release.",
            "title": "Overview"
        },
        {
            "location": "/decision-making/#decision-making",
            "text": "The most important thing about engaging with Opencast is that all people with an opinion are entitled to express that\nopinion and, where appropriate, have it considered by the community.  To some, the idea of having to establish consensus in a large and distributed team sounds inefficient and frustrating.\nDo not despair though, we have a set of simple processes to ensure things proceed at a good pace.  In Opencast we do not like to vote. We reserve that for the few things that need official approval for legal or\nprocess reasons (e.g. a release or a new committer). Most of the time we work with the consensus building techniques\ndocumented below.",
            "title": "Decision Making"
        },
        {
            "location": "/decision-making/#lazy-consensus",
            "text": "Lazy consensus  is the first, and possibly the most important, consensus building tool we have.\nEssentially lazy consensus means that you do not need to get explicit approval to proceed, but you need to be prepared\nto listen if someone objects.",
            "title": "Lazy Consensus"
        },
        {
            "location": "/decision-making/#consensus-building",
            "text": "Sometimes lazy consensus is not appropriate. In such cases it is necessary to make a proposal to the mailing list and\ndiscuss options. There are mechanisms for quickly showing your support or otherwise for a proposal and  building\nconsensus  amongst the community.  Once there is a consensus people can proceed with the work under the  lazy consensus  model.",
            "title": "Consensus Building"
        },
        {
            "location": "/decision-making/#voting",
            "text": "Occasionally a \"feel\" for consensus is not enough. Sometimes we need to have a measurable consensus. For example, when voting  in new committers or to approve a release.",
            "title": "Voting"
        },
        {
            "location": "/decision-making/lazy-consensus/",
            "text": "Lazy Consensus\n\n\nThe concept of \"Lazy Consensus\" is very important in our project. Lazy Consensus means that when you are convinced that\nyou know what the community would like to see happen you can simply assume that you already have consensus and get on\nwith the work. You do not have to insist people discuss and/or approve your plan, and you certainly do not need to call\na vote to get approval. You just assume you have the community's support unless someone says otherwise.\n\n\nWe have a time machine (git), this means that as long as you commit (or submit patches) early and often the community\nhas plenty of opportunity to indicate disapproval. If you believe the community will support your action you can operate\non lazy consensus as long as you are prepared to roll back any work should a valid objection be raised.\n\n\nAvoiding Unnecessary Discussion\n\n\nThe key thing about lazy consensus is that it is easier for people to agree, by doing nothing, than it is to object,\nwhich requires an alternative to be proposed. This has two effects, firstly people are less likely to object for the\nsake of it and secondly it cuts down on the amount of unnecessary mail traffic and discussion.\n\n\nLazy consensus means we can avoid waiting for a community based decision before proceeding. However, it does require\neveryone who cares for the health of the project to watch what is happening, as it is happening. Objecting too far down\nthe road will cause upset, but objecting (or asking for clarification of intent) early is likely to be greeted with\nrelief that someone is watching and cares.\n\n\nStating Lazy Consensus\n\n\nSometimes a member of the community will believe a specific action is the correct one for the project but is not sure\nthat there will be consensus and may not wish to proceed the work without giving the community an opportunity to\nfeedback. In these circumstances, they can make the proposal and state Lazy Consensus is in operation.\n\n\nProposals should be sent to list, preferably the development list. It is common to indicate proposals by including the\nstring \n[#proposal]\n at the beginning of the subject to make it easier for the community to identify that the mail\ncontains an important proposal.\n\n\nThis triggers the Lazy Consensus mechanism, by which the proposal is considered accepted if no one objects within 72\nhours after the proposal submission. The period of 72 hours is chosen because it accounts for different timezones and\nany non-Opencast commitments the community members may have.\n\n\nIn this approach the original proposer is not insisting that there is a discussion around the proposal, nor is it\nrequested that the community explicitly supports their actions. This differs from assuming lazy consensus since it\nallows space and time to \nexpress support or objections\n and corrections to the proposal before\nwork begins.\n\n\nSilence is Consent\n\n\nPeople may choose to indicate their support for the actions taken with a +1 mail - quick and easy to read and reassuring\nfor the implementer. However, remember, in a lazy consensus world silence is the equivalent to support. This can take\nsome time to get used to.",
            "title": "Lazy Consensus"
        },
        {
            "location": "/decision-making/lazy-consensus/#lazy-consensus",
            "text": "The concept of \"Lazy Consensus\" is very important in our project. Lazy Consensus means that when you are convinced that\nyou know what the community would like to see happen you can simply assume that you already have consensus and get on\nwith the work. You do not have to insist people discuss and/or approve your plan, and you certainly do not need to call\na vote to get approval. You just assume you have the community's support unless someone says otherwise.  We have a time machine (git), this means that as long as you commit (or submit patches) early and often the community\nhas plenty of opportunity to indicate disapproval. If you believe the community will support your action you can operate\non lazy consensus as long as you are prepared to roll back any work should a valid objection be raised.",
            "title": "Lazy Consensus"
        },
        {
            "location": "/decision-making/lazy-consensus/#avoiding-unnecessary-discussion",
            "text": "The key thing about lazy consensus is that it is easier for people to agree, by doing nothing, than it is to object,\nwhich requires an alternative to be proposed. This has two effects, firstly people are less likely to object for the\nsake of it and secondly it cuts down on the amount of unnecessary mail traffic and discussion.  Lazy consensus means we can avoid waiting for a community based decision before proceeding. However, it does require\neveryone who cares for the health of the project to watch what is happening, as it is happening. Objecting too far down\nthe road will cause upset, but objecting (or asking for clarification of intent) early is likely to be greeted with\nrelief that someone is watching and cares.",
            "title": "Avoiding Unnecessary Discussion"
        },
        {
            "location": "/decision-making/lazy-consensus/#stating-lazy-consensus",
            "text": "Sometimes a member of the community will believe a specific action is the correct one for the project but is not sure\nthat there will be consensus and may not wish to proceed the work without giving the community an opportunity to\nfeedback. In these circumstances, they can make the proposal and state Lazy Consensus is in operation.  Proposals should be sent to list, preferably the development list. It is common to indicate proposals by including the\nstring  [#proposal]  at the beginning of the subject to make it easier for the community to identify that the mail\ncontains an important proposal.  This triggers the Lazy Consensus mechanism, by which the proposal is considered accepted if no one objects within 72\nhours after the proposal submission. The period of 72 hours is chosen because it accounts for different timezones and\nany non-Opencast commitments the community members may have.  In this approach the original proposer is not insisting that there is a discussion around the proposal, nor is it\nrequested that the community explicitly supports their actions. This differs from assuming lazy consensus since it\nallows space and time to  express support or objections  and corrections to the proposal before\nwork begins.",
            "title": "Stating Lazy Consensus"
        },
        {
            "location": "/decision-making/lazy-consensus/#silence-is-consent",
            "text": "People may choose to indicate their support for the actions taken with a +1 mail - quick and easy to read and reassuring\nfor the implementer. However, remember, in a lazy consensus world silence is the equivalent to support. This can take\nsome time to get used to.",
            "title": "Silence is Consent"
        },
        {
            "location": "/decision-making/consensus-building/",
            "text": "Consensus Building\n\n\nIn some cases there is no obvious path to take or you might want to have reassurance for the path you want to take.\nIn these cases people will often need to build consensus by making proposals and eliciting responses.\n\n\nWe want to avoid unnecessary discussion and the creation of significant amounts of unnecessary mail that everyone in the\ncommunity needs to read. That is not to say that we want to avoid constructive discussion. This is the lifeblood of a\nsuccessful project. However, there is a shorthand notation for showing support, or otherwise, for a proposal.\n\n\nSending out a Proposal\n\n\nProposals should be send to list. It is common to indicate proposals by including the\nstring \n[#proposal]\n at the beginning of the subject to make it easier for the community to identify that the mail\ncontains an important proposal.\n\n\nThe list used should usually be the development list. In very rare cases, other lists may also be used: The users list\nwhen the matter discussed only targets adopters/uses. The committers list if the matter discussed needs to be kept\nprivate e.g. for personal or security reasons.\n\n\nPlease avoid cross-posting a proposal on multiple lists. It will usually fracture the discussion.\n\n\nExpressing Approval or Disapproval\n\n\nFirst of all, it is important to understand that everyone is invited to express their opinion of any given action or\nproposal. Opencast is a community project in which no single individual has more power than any other single individual\n(except in a very few procedural situations).\n\n\nThe notation used is \n+1\n, \n-1\n and \n0\n. It is also common to see \n+0\n and \n-0\n.\n\n\nSo, what do these notations mean?\n\n\n\n\n+1\n means \"I agree with this and will help make it happen\"\n\n\n+0\n means \"I agree with this but probably won't make it happen, so my opinion is not that important\"\n\n\n-0\n means \"I don't agree with this, but I'm offering no alternative so my opinion is not that important\"\n\n\n-1\n means \"I don't agree and I am offering an alternative that I am able to help implement\"\n\n\n\n\nMany people will use fractions to indicate the strength of their feelings, e.g. \n+0.5\n. Some will even indicate this is\na definite yes with something like \n+1000\n.\n\n\nThe important thing is that this is not an exact science. It is just a shorthand way of communicating strength of\nfeeling.\n\n\nConsensus Building is Not Voting\n\n\nThe confusing thing about this notation is that it is the same notation used in a \nformal vote\n. Knowing when\nsomething is a vote and when it is a preference is important. It is easy to tell though, if the email's subject does not\nstart with \n[#vote]\n then it is just an opinion. We try not to call votes, consensus building is much more inclusive.\n\n\nThe reasons for this notation being common is that when someone wants to summarise a discussion thread they can mentally\nadd up the strength of feeling of the community and decide if there is consensus or not.\n\n\nOnce there is a clear consensus members of the community can proceed with the work under the \nlazy consensus\n\n model.",
            "title": "Consensus Building"
        },
        {
            "location": "/decision-making/consensus-building/#consensus-building",
            "text": "In some cases there is no obvious path to take or you might want to have reassurance for the path you want to take.\nIn these cases people will often need to build consensus by making proposals and eliciting responses.  We want to avoid unnecessary discussion and the creation of significant amounts of unnecessary mail that everyone in the\ncommunity needs to read. That is not to say that we want to avoid constructive discussion. This is the lifeblood of a\nsuccessful project. However, there is a shorthand notation for showing support, or otherwise, for a proposal.",
            "title": "Consensus Building"
        },
        {
            "location": "/decision-making/consensus-building/#sending-out-a-proposal",
            "text": "Proposals should be send to list. It is common to indicate proposals by including the\nstring  [#proposal]  at the beginning of the subject to make it easier for the community to identify that the mail\ncontains an important proposal.  The list used should usually be the development list. In very rare cases, other lists may also be used: The users list\nwhen the matter discussed only targets adopters/uses. The committers list if the matter discussed needs to be kept\nprivate e.g. for personal or security reasons.  Please avoid cross-posting a proposal on multiple lists. It will usually fracture the discussion.",
            "title": "Sending out a Proposal"
        },
        {
            "location": "/decision-making/consensus-building/#expressing-approval-or-disapproval",
            "text": "First of all, it is important to understand that everyone is invited to express their opinion of any given action or\nproposal. Opencast is a community project in which no single individual has more power than any other single individual\n(except in a very few procedural situations).  The notation used is  +1 ,  -1  and  0 . It is also common to see  +0  and  -0 .  So, what do these notations mean?   +1  means \"I agree with this and will help make it happen\"  +0  means \"I agree with this but probably won't make it happen, so my opinion is not that important\"  -0  means \"I don't agree with this, but I'm offering no alternative so my opinion is not that important\"  -1  means \"I don't agree and I am offering an alternative that I am able to help implement\"   Many people will use fractions to indicate the strength of their feelings, e.g.  +0.5 . Some will even indicate this is\na definite yes with something like  +1000 .  The important thing is that this is not an exact science. It is just a shorthand way of communicating strength of\nfeeling.",
            "title": "Expressing Approval or Disapproval"
        },
        {
            "location": "/decision-making/consensus-building/#consensus-building-is-not-voting",
            "text": "The confusing thing about this notation is that it is the same notation used in a  formal vote . Knowing when\nsomething is a vote and when it is a preference is important. It is easy to tell though, if the email's subject does not\nstart with  [#vote]  then it is just an opinion. We try not to call votes, consensus building is much more inclusive.  The reasons for this notation being common is that when someone wants to summarise a discussion thread they can mentally\nadd up the strength of feeling of the community and decide if there is consensus or not.  Once there is a clear consensus members of the community can proceed with the work under the  lazy consensus  model.",
            "title": "Consensus Building is Not Voting"
        },
        {
            "location": "/decision-making/voting/",
            "text": "Voting\n\n\nOccasionally a \nfeel\n for consensus is not enough. Sometimes we need to have a measurable consensus. For example, when\nvoting new committers in or to approve a release.\n\n\nPreparing for a Vote\n\n\nBefore calling a vote it is important to ensure that the community is given time to discuss the upcoming vote. This will\nbe done by posting an email to the developers list indicating the intention to call a vote and the options available. By\nthe time a vote is called there should already be consensus in the community. The vote itself is, normally, a formality.\n\n\nCalling a Vote\n\n\nOnce it is time to call the vote, a mail is posted to the committers list with a subject starting with \n[#vote]\n. This\nenables the community members to ensure they do not miss an important vote thread. It also indicates that this is not\nconsensus building but a formal vote.\n\n\nCasting Your Vote\n\n\nThe notation used in voting is:\n\n\n\n\n+1\n Yes I agree\n\n\n0\n I have no strong opinion\n\n\n-1\n I object on the following grounds\u2026\n\n\n\n\nIf you object you must support your objection and provide an alternative course of action that you are willing and able\nto implement (where appropriate).\n\n\nVotes should generally be permitted to run for at least 72 hours to provide an opportunity for all concerned persons to\nparticipate regardless of their geographic locations.\n\n\nPublishing Results\n\n\nAfter the voting is done, the outcome should be published on the public developer list. A result may be kept private, if\ndeemed necessary, for votes on security-relevant or personal topics.\n\n\nBinding Votes\n\n\nIn Opencast, only committers have binding votes. All others are either discouraged from voting (to keep the noise down)\nor else have their votes considered in an advisory nature only.\n\n\nWhen to Vote\n\n\nThere are essentially three occasions to vote:\n\n\n\n\nReleases\n\n\nChanges to the Committer body\n\n\nSignificant changes to the development process\n\n\n\n\nVeto and Majority\n\n\nBy default, all committers have a veto right when voting, meaning that a \n-1\n will effectively stop whatever was voted\nfor. After addressing the issue, a second vote may be called for. Depending on the discussion, at this point, the\ninitiator may determine this to be a majority vote.\n\n\nIn the rare case that a majority vote among committers is called for, the vote is a simple majority vote among\nparticipating committers without regards to any form of quorum. The vote will pass if there were more positive (\n+1\n)\nvotes then negative ones (\n-1\n), implying that at least one committer needs to respond.\n\n\nFormal Votes for Code Changes\n\n\nUsually, code changes have consensus and there should be no need for voting. If in doubt, contributors can \npropose\nchanges\n on list in advance. Additionally, consensus may be reached though discussion as part of\nthe review process.\n\n\nThere might be the rare case of a dispute between reviewer(s) and contributor(s) during the review process which cannot\nbe resolved easily. In such a case, both parties can call a formal majority vote to settle the issue.",
            "title": "Voting"
        },
        {
            "location": "/decision-making/voting/#voting",
            "text": "Occasionally a  feel  for consensus is not enough. Sometimes we need to have a measurable consensus. For example, when\nvoting new committers in or to approve a release.",
            "title": "Voting"
        },
        {
            "location": "/decision-making/voting/#preparing-for-a-vote",
            "text": "Before calling a vote it is important to ensure that the community is given time to discuss the upcoming vote. This will\nbe done by posting an email to the developers list indicating the intention to call a vote and the options available. By\nthe time a vote is called there should already be consensus in the community. The vote itself is, normally, a formality.",
            "title": "Preparing for a Vote"
        },
        {
            "location": "/decision-making/voting/#calling-a-vote",
            "text": "Once it is time to call the vote, a mail is posted to the committers list with a subject starting with  [#vote] . This\nenables the community members to ensure they do not miss an important vote thread. It also indicates that this is not\nconsensus building but a formal vote.",
            "title": "Calling a Vote"
        },
        {
            "location": "/decision-making/voting/#casting-your-vote",
            "text": "The notation used in voting is:   +1  Yes I agree  0  I have no strong opinion  -1  I object on the following grounds\u2026   If you object you must support your objection and provide an alternative course of action that you are willing and able\nto implement (where appropriate).  Votes should generally be permitted to run for at least 72 hours to provide an opportunity for all concerned persons to\nparticipate regardless of their geographic locations.",
            "title": "Casting Your Vote"
        },
        {
            "location": "/decision-making/voting/#publishing-results",
            "text": "After the voting is done, the outcome should be published on the public developer list. A result may be kept private, if\ndeemed necessary, for votes on security-relevant or personal topics.",
            "title": "Publishing Results"
        },
        {
            "location": "/decision-making/voting/#binding-votes",
            "text": "In Opencast, only committers have binding votes. All others are either discouraged from voting (to keep the noise down)\nor else have their votes considered in an advisory nature only.",
            "title": "Binding Votes"
        },
        {
            "location": "/decision-making/voting/#when-to-vote",
            "text": "There are essentially three occasions to vote:   Releases  Changes to the Committer body  Significant changes to the development process",
            "title": "When to Vote"
        },
        {
            "location": "/decision-making/voting/#veto-and-majority",
            "text": "By default, all committers have a veto right when voting, meaning that a  -1  will effectively stop whatever was voted\nfor. After addressing the issue, a second vote may be called for. Depending on the discussion, at this point, the\ninitiator may determine this to be a majority vote.  In the rare case that a majority vote among committers is called for, the vote is a simple majority vote among\nparticipating committers without regards to any form of quorum. The vote will pass if there were more positive ( +1 )\nvotes then negative ones ( -1 ), implying that at least one committer needs to respond.",
            "title": "Veto and Majority"
        },
        {
            "location": "/decision-making/voting/#formal-votes-for-code-changes",
            "text": "Usually, code changes have consensus and there should be no need for voting. If in doubt, contributors can  propose\nchanges  on list in advance. Additionally, consensus may be reached though discussion as part of\nthe review process.  There might be the rare case of a dispute between reviewer(s) and contributor(s) during the review process which cannot\nbe resolved easily. In such a case, both parties can call a formal majority vote to settle the issue.",
            "title": "Formal Votes for Code Changes"
        },
        {
            "location": "/development-environment/",
            "text": "Development Environment\n\n\nDeveloper Builds\n\n\nBesides the default \ndist\n Maven profile, the assemblies project defines a second \ndev\n profile which will cause only\none allinone distribution to be created. It is already unpacked and ready to be started. Activate the profile using:\n\n\nmvn clean install -Pdev\n\n\n\nThe administrative user interface needs nodejs to build and phantomjs for testing purposes. These will be downloaded as\nprebuilt binaries during the maven build process. If there are no prebuilt binaries for your operating system, you can\nbuild the tools manually and then build opencast using the \nfrontend-no-prebuilt\n maven profile:\n\n\nmvn clean install -Pdev,frontend-no-prebuilt\n\n\n\nLogging During Builds\n\n\nWhile building Opencast, the default log level for Opencast modules is \nWARN\n. To increase logging for development,\nedit the log level configuration in \ndocs/log4j/log4j.properties\n.\n\n\nBuilding single modules\n\n\nWhen working on a single Opencast module, it can be extremely helpful to watch the newly built version and include\nit automatically in the Opencast OSGi infrastructure. This can be done through the\n\nbundle:watch\n command in Karaf. The workflow would\nbe as follows:\n\n\n\n\nStart Opencast and use \nla -u\n in the Karaf console to list all installed bundles/modules. Note down the IDs of the\n   bundles you want to watch.\n\n\nUse \nbundle:watch IDs\n to watch the desired modules, e.g. \nbundle:watch 190 199\n\n\nMake your changes and rebuild the module (e.g. execute \nmvn clean install\n in the module folder).\n\n\nWatch how Karaf automatically redeploys the changed jars from your local Maven repository. You can verify that\n   everything went smoothly by checking the log with \nlog:tail\n.\n\n\n\n\nThe updated bundles are only available in the currently running Karaf instance. To create a Opencast version that has\nthis changes permanently, you have to run \nmvn clean install\n in the the assemblies directory again. Your current\ninstance will be deleted by the new assembly!\n\n\nIn several cases the bundle:watch can bring Karaf in an unstable condition, as dependencies between bundles will not\ncorrectly be restored, after the new bundle has been deployed.\n\n\nAttaching a Remote Debugger to Karaf\n\n\nTo debug a running Opencast system, you can attach a remote debugger in your IDE (Eclipse or NetBeans, i.e.). For that\nyou have to enable the remote debugging in Karaf OSGI server that runs Opencast.\n\n\nYou have to add \"debug\" as an additional paramenter to the Opencast start script:\n\n\nbin/start-opencast debug\n\n\n\nIf you want to enable debug permanently you can export the variable in the shell:\n\n\nexport DEFAULT_JAVA_DEBUG_OPTS='-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005'\n\n\n\nYou can connect the remote debugger of your IDE on port \n5005\n.\n\n\nFor more information on remote debugging with Karaf you can visit \nthis\nsite.\n\n\nIt is not recommended to enable remote debugging on production systems!",
            "title": "Overview"
        },
        {
            "location": "/development-environment/#development-environment",
            "text": "",
            "title": "Development Environment"
        },
        {
            "location": "/development-environment/#developer-builds",
            "text": "Besides the default  dist  Maven profile, the assemblies project defines a second  dev  profile which will cause only\none allinone distribution to be created. It is already unpacked and ready to be started. Activate the profile using:  mvn clean install -Pdev  The administrative user interface needs nodejs to build and phantomjs for testing purposes. These will be downloaded as\nprebuilt binaries during the maven build process. If there are no prebuilt binaries for your operating system, you can\nbuild the tools manually and then build opencast using the  frontend-no-prebuilt  maven profile:  mvn clean install -Pdev,frontend-no-prebuilt",
            "title": "Developer Builds"
        },
        {
            "location": "/development-environment/#logging-during-builds",
            "text": "While building Opencast, the default log level for Opencast modules is  WARN . To increase logging for development,\nedit the log level configuration in  docs/log4j/log4j.properties .",
            "title": "Logging During Builds"
        },
        {
            "location": "/development-environment/#building-single-modules",
            "text": "When working on a single Opencast module, it can be extremely helpful to watch the newly built version and include\nit automatically in the Opencast OSGi infrastructure. This can be done through the bundle:watch  command in Karaf. The workflow would\nbe as follows:   Start Opencast and use  la -u  in the Karaf console to list all installed bundles/modules. Note down the IDs of the\n   bundles you want to watch.  Use  bundle:watch IDs  to watch the desired modules, e.g.  bundle:watch 190 199  Make your changes and rebuild the module (e.g. execute  mvn clean install  in the module folder).  Watch how Karaf automatically redeploys the changed jars from your local Maven repository. You can verify that\n   everything went smoothly by checking the log with  log:tail .   The updated bundles are only available in the currently running Karaf instance. To create a Opencast version that has\nthis changes permanently, you have to run  mvn clean install  in the the assemblies directory again. Your current\ninstance will be deleted by the new assembly!  In several cases the bundle:watch can bring Karaf in an unstable condition, as dependencies between bundles will not\ncorrectly be restored, after the new bundle has been deployed.",
            "title": "Building single modules"
        },
        {
            "location": "/development-environment/#attaching-a-remote-debugger-to-karaf",
            "text": "To debug a running Opencast system, you can attach a remote debugger in your IDE (Eclipse or NetBeans, i.e.). For that\nyou have to enable the remote debugging in Karaf OSGI server that runs Opencast.  You have to add \"debug\" as an additional paramenter to the Opencast start script:  bin/start-opencast debug  If you want to enable debug permanently you can export the variable in the shell:  export DEFAULT_JAVA_DEBUG_OPTS='-Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=5005'  You can connect the remote debugger of your IDE on port  5005 .  For more information on remote debugging with Karaf you can visit  this\nsite.  It is not recommended to enable remote debugging on production systems!",
            "title": "Attaching a Remote Debugger to Karaf"
        },
        {
            "location": "/development-environment-docker/",
            "text": "Development Environment with Docker\n\n\nSetting up and maintaining a proper Opencast build environment can be challenging. The \nopencast/build\n Docker image,\ndeveloped by the University of M\u00fcnster, provides such a build environment already configured and ready to use. In fact,\nbecause of Docker's isolation functionality, multiple environments can be operated side by side on a single machine.\n\n\nSetting up a Docker build environment\n\n\nA \ndocker-compose\n file is provided to start up the development environment. You also need the ActiveMQ configuration\n(see \"Testing Locally with Docker\" guide in the administration documentation).\n\n\n$ mkdir assets\n$ curl -o docker-compose.yml https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.build.yml\n$ curl -o assets/activemq.xml https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/assets/activemq.xml\n\n\n\nNow create a folder where the Opencast repository should be located, and expose its path as an environment variable. You\nmust also create the local Maven repository if it does not already exist.\n\n\n$ mkdir -p opencast ~/.m2\n$ export OPENCAST_SRC=$PWD/opencast\n\n\n\nThe \nOPENCAST_SRC\n variable is used in the compose file to set up a Docker volume so that the host and Docker container\ncan share the Opencast codebase. Similarly, the local Maven repository is shared in order to persist Maven artifacts\nbeyond the lifetime of the Docker container. If you do not want to use the default path \n~/.m2\n you can set the\n\nM2_REPO\n variable to any other directory on the host system.\n\n\nNext, you should specify your UID and GID. A matching user will then be created within the container so that all new\nfiles can also be accessed from the host. If these variables remain unset, both default to 1000.\n\n\n$ export OPENCAST_BUILD_USER_UID=$(id -u)\n$ export OPENCAST_BUILD_USER_GID=$(id -g)\n\n\n\nWith this you are ready to start up the build environment:\n\n\n$ docker-compose up -d\n\n\n\nYou can enter the Opencast build environment with the \nexec\n command. Omitting the \n--user opencast-builder\n argument\nwould give you a root shell, but that is not necessary because the user \nopencast-builder\n can use \nsudo\n within the\ncontainer.\n\n\n$ docker-compose exec --user opencast-builder opencast bash\n\n\n\nThere are multiple helper scripts available within the container:\n\n\n# Clone the Opencast source code to the shared volume.\n$ oc_clone\n\n# Build Opencast.\n$ oc_build\n\n# Install Opencast in the same way as it would be installed in the other Opencast Docker images.\n$ oc_install <distribution>\n\n# Run the installed Opencast\n$ oc_run\n\n# Uninstall Opencast.\n$ oc_uninstall\n\n# Remove all Opencast files (database, media packages, etc.).\n$ oc_clean_data\n\n\n\nThese scripts are provided to automate common tasks, but you can also run the necessary commands directly. The install\nscript has the advantage that it automatically connects Opencast to the configured ActiveMQ instance available at\n\ntcp://activemq:61616\n.\n\n\nSince the Opencast code is shared, any change from an IDE is directly visible within the container.\n\n\nAttaching a Remote Debugger to Karaf\n\n\nBy default, the compose file sets the necessary variables to enable remote debugging. The network port is published by\nthe container so that you can connect the remote debugger of your IDE to the port \n5005\n on \nlocalhost\n.",
            "title": "With Docker"
        },
        {
            "location": "/development-environment-docker/#development-environment-with-docker",
            "text": "Setting up and maintaining a proper Opencast build environment can be challenging. The  opencast/build  Docker image,\ndeveloped by the University of M\u00fcnster, provides such a build environment already configured and ready to use. In fact,\nbecause of Docker's isolation functionality, multiple environments can be operated side by side on a single machine.",
            "title": "Development Environment with Docker"
        },
        {
            "location": "/development-environment-docker/#setting-up-a-docker-build-environment",
            "text": "A  docker-compose  file is provided to start up the development environment. You also need the ActiveMQ configuration\n(see \"Testing Locally with Docker\" guide in the administration documentation).  $ mkdir assets\n$ curl -o docker-compose.yml https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/docker-compose.build.yml\n$ curl -o assets/activemq.xml https://raw.githubusercontent.com/opencast/opencast-docker/<version>/docker-compose/assets/activemq.xml  Now create a folder where the Opencast repository should be located, and expose its path as an environment variable. You\nmust also create the local Maven repository if it does not already exist.  $ mkdir -p opencast ~/.m2\n$ export OPENCAST_SRC=$PWD/opencast  The  OPENCAST_SRC  variable is used in the compose file to set up a Docker volume so that the host and Docker container\ncan share the Opencast codebase. Similarly, the local Maven repository is shared in order to persist Maven artifacts\nbeyond the lifetime of the Docker container. If you do not want to use the default path  ~/.m2  you can set the M2_REPO  variable to any other directory on the host system.  Next, you should specify your UID and GID. A matching user will then be created within the container so that all new\nfiles can also be accessed from the host. If these variables remain unset, both default to 1000.  $ export OPENCAST_BUILD_USER_UID=$(id -u)\n$ export OPENCAST_BUILD_USER_GID=$(id -g)  With this you are ready to start up the build environment:  $ docker-compose up -d  You can enter the Opencast build environment with the  exec  command. Omitting the  --user opencast-builder  argument\nwould give you a root shell, but that is not necessary because the user  opencast-builder  can use  sudo  within the\ncontainer.  $ docker-compose exec --user opencast-builder opencast bash  There are multiple helper scripts available within the container:  # Clone the Opencast source code to the shared volume.\n$ oc_clone\n\n# Build Opencast.\n$ oc_build\n\n# Install Opencast in the same way as it would be installed in the other Opencast Docker images.\n$ oc_install <distribution>\n\n# Run the installed Opencast\n$ oc_run\n\n# Uninstall Opencast.\n$ oc_uninstall\n\n# Remove all Opencast files (database, media packages, etc.).\n$ oc_clean_data  These scripts are provided to automate common tasks, but you can also run the necessary commands directly. The install\nscript has the advantage that it automatically connects Opencast to the configured ActiveMQ instance available at tcp://activemq:61616 .  Since the Opencast code is shared, any change from an IDE is directly visible within the container.",
            "title": "Setting up a Docker build environment"
        },
        {
            "location": "/development-environment-docker/#attaching-a-remote-debugger-to-karaf",
            "text": "By default, the compose file sets the necessary variables to enable remote debugging. The network port is published by\nthe container so that you can connect the remote debugger of your IDE to the port  5005  on  localhost .",
            "title": "Attaching a Remote Debugger to Karaf"
        },
        {
            "location": "/committer/",
            "text": "Committers and Contributors\n\n\nWhat is a committer, and how does that differ from a contributor?\n\n\nThe Opencast project welcomes all those who are interested in contributing in concrete ways. Contributions can take \nmany forms, and there are various mechanisms by which one can contribute (signing up for the mailing list or \nbrowsing our issue tracker are both great places to start). Anyone can become a contributor, and there is no \nexpectation of future commitment to the project, no specific skill requirements, and no selection process. Some of the\ncontributions individuals have given in the past include:\n\n\n\n\nSupporting new users (users are often the best people to support new users)\n\n\nReporting bugs\n\n\nIdentifying requirements\n\n\nProviding design and pedagogical direction\n\n\nAdding features and fixing bugs\n\n\nAssisting with project infrastructure\n\n\nWriting documentation\n\n\nAssisting in translation of both documentation and the system itself\n\n\nPerforming Quality Assurance tasks as needed as part of the QA process prior to release\n\n\n\n\nAs contributors gain experience and familiarity with the project they generally find that making such contributions \nbecomes easier. With a sufficient level of participation and commitment to the project, contributors may be nominated\nby existing committers to join the committer body. While similar in day-to-day activities as contributors, committers\nhave shown a dedicated interest in supporting the project over the longer term. Committership allows individuals to\nmore easily carry on with their project related activities by giving them direct access to the projects resources. In\nOpencast, the project's resources include not only code, but also designs, documents, and other non-code resources. As\nsuch, we welcome and value committers both in the traditional sense (e.g. programmers) as well as in the broader sense\n(e.g. people who are committed to the project).\n\n\nThe committer body is the group of individuals who drive, manage, and govern the product. They make releases, set\npolicy, and determine the both the quality and feature-set of Opencast.\n\n\nResponsibilities of a committer\n\n\nCommitters responsibilities are centered around two key principles, that there is a commitment to excellence and\nsuccess, and that there is a commitment to being active and involved. These commitments are demonstrated through\nactivities such as:\n\n\n\n\nBeing involved in quality assurance of the source code, documentation, designs, and other project pieces.\n\n\nBeing active and engaging in the broader community, including supporting adopters and providing prompt feedback.\n\n\nKnowing when a change is beyond your ability and asking for help.\n\n\nKeeping informed of project governance and direction.\n\n\nFostering a collegial environment between the group of committers.\n\n\nEnsuring that incoming code adheres to our \nlicense\n requirements. Minor patches can be accepted \n   without concern, but the main reviewer \nmust\n ensure that a CLA (and CCLA) is in place prior to merging in the \n   contribution.\n\n\n20% of the time a committer invests to the project is to be allocated for general purposes, i.e. work not directly\n   associated with the committer's individual or institutional concerns.\n\n\n\n\nAll committers must signed a ICLA. The privileges and rights of being a committer do not come into effect until an ICLA\nhas been received and processed. The ICLA, as well as the list of ICLA signatories, can be found\n\nhere\n. Your employer will also need to sign a CCLA as well.\n\n\nHow do I become a committer?\n\n\nCommitters must be recommended by existing committers and pass a vote of the committer body. Committers proposing a\ncontributor for commit rights should present a solid background of why this person would be a good fit, as well as\ntheir work history within the project. This history, baring special circumstances, should be significant and of a high\nquality.\n\n\nWhat happens if I stop contributing?\n\n\nCommitter status can be lost through any of the methods below:\n\n\n\n\nCommitter Emeritus\n: By being absent or inactive for a period of six months or more, or by request, a committer\n   enters emeritus status. No vote is required to enter this state, and committer status can be restored just by \n   making an inquiry to the project infrastructure group. While in emeritus, committers lose access to project \n   resources (e.g. git write access), as well as lose the ability to vote and engage in discussion on the committers\n   mailing list.\n\n\nRevocation of Commit Privileges\n: A committer may make a proposal to remove an individual from the committer body.\n   Discussion and voting happen on the confidential committers mailing list, and the committer in question is not \n   entitled to a vote (though they do get to participate in the discussion).",
            "title": "Committers"
        },
        {
            "location": "/committer/#committers-and-contributors",
            "text": "",
            "title": "Committers and Contributors"
        },
        {
            "location": "/committer/#what-is-a-committer-and-how-does-that-differ-from-a-contributor",
            "text": "The Opencast project welcomes all those who are interested in contributing in concrete ways. Contributions can take \nmany forms, and there are various mechanisms by which one can contribute (signing up for the mailing list or \nbrowsing our issue tracker are both great places to start). Anyone can become a contributor, and there is no \nexpectation of future commitment to the project, no specific skill requirements, and no selection process. Some of the\ncontributions individuals have given in the past include:   Supporting new users (users are often the best people to support new users)  Reporting bugs  Identifying requirements  Providing design and pedagogical direction  Adding features and fixing bugs  Assisting with project infrastructure  Writing documentation  Assisting in translation of both documentation and the system itself  Performing Quality Assurance tasks as needed as part of the QA process prior to release   As contributors gain experience and familiarity with the project they generally find that making such contributions \nbecomes easier. With a sufficient level of participation and commitment to the project, contributors may be nominated\nby existing committers to join the committer body. While similar in day-to-day activities as contributors, committers\nhave shown a dedicated interest in supporting the project over the longer term. Committership allows individuals to\nmore easily carry on with their project related activities by giving them direct access to the projects resources. In\nOpencast, the project's resources include not only code, but also designs, documents, and other non-code resources. As\nsuch, we welcome and value committers both in the traditional sense (e.g. programmers) as well as in the broader sense\n(e.g. people who are committed to the project).  The committer body is the group of individuals who drive, manage, and govern the product. They make releases, set\npolicy, and determine the both the quality and feature-set of Opencast.",
            "title": "What is a committer, and how does that differ from a contributor?"
        },
        {
            "location": "/committer/#responsibilities-of-a-committer",
            "text": "Committers responsibilities are centered around two key principles, that there is a commitment to excellence and\nsuccess, and that there is a commitment to being active and involved. These commitments are demonstrated through\nactivities such as:   Being involved in quality assurance of the source code, documentation, designs, and other project pieces.  Being active and engaging in the broader community, including supporting adopters and providing prompt feedback.  Knowing when a change is beyond your ability and asking for help.  Keeping informed of project governance and direction.  Fostering a collegial environment between the group of committers.  Ensuring that incoming code adheres to our  license  requirements. Minor patches can be accepted \n   without concern, but the main reviewer  must  ensure that a CLA (and CCLA) is in place prior to merging in the \n   contribution.  20% of the time a committer invests to the project is to be allocated for general purposes, i.e. work not directly\n   associated with the committer's individual or institutional concerns.   All committers must signed a ICLA. The privileges and rights of being a committer do not come into effect until an ICLA\nhas been received and processed. The ICLA, as well as the list of ICLA signatories, can be found here . Your employer will also need to sign a CCLA as well.",
            "title": "Responsibilities of a committer"
        },
        {
            "location": "/committer/#how-do-i-become-a-committer",
            "text": "Committers must be recommended by existing committers and pass a vote of the committer body. Committers proposing a\ncontributor for commit rights should present a solid background of why this person would be a good fit, as well as\ntheir work history within the project. This history, baring special circumstances, should be significant and of a high\nquality.",
            "title": "How do I become a committer?"
        },
        {
            "location": "/committer/#what-happens-if-i-stop-contributing",
            "text": "Committer status can be lost through any of the methods below:   Committer Emeritus : By being absent or inactive for a period of six months or more, or by request, a committer\n   enters emeritus status. No vote is required to enter this state, and committer status can be restored just by \n   making an inquiry to the project infrastructure group. While in emeritus, committers lose access to project \n   resources (e.g. git write access), as well as lose the ability to vote and engage in discussion on the committers\n   mailing list.  Revocation of Commit Privileges : A committer may make a proposal to remove an individual from the committer body.\n   Discussion and voting happen on the confidential committers mailing list, and the committer in question is not \n   entitled to a vote (though they do get to participate in the discussion).",
            "title": "What happens if I stop contributing?"
        },
        {
            "location": "/license/",
            "text": "Licenses and Legal Matters\n\n\n\n\nThis is a guide from developers for developers and therefore not an official legal document. We try to be as accurate\nas possible but cannot guarantee that there are no mistakes. If in doubt, please send a question to the Opencast\ndeveloper mailing list, to the Opencast Board or to the Apereo Foundation, preferably in that order.\n\n\n\n\nWhich Licenses May I Use for Opencast?\n\n\nAll libraries that are used in Opencast need to be compatible with the Educational Community License version 2.0.\n\n\nIn short, if the license is on:\n\n\n\n\nthe Apereo or Apache Category-A list, it is fine to use the library.\n\n\nthe Apereo or Apache Category-B list, we may use it unmodified. Please avoid Category-B if possible.\n\n\nthe Apereo or Apache Category-X list, we cannot use it.\n\n\n\n\nEverything else needs to go to the Apereo foundation for approval.\n\n\nThese lists, along with a more detailed explanation, can be found on the \nApereo page about practices on third-party\nlicenses\n\n\nHere is the slightly longer section from the \u201eApereo Licensing & Intellectual Property Practices\u201c page:\n\n\nHow To Label Third Party Libraries\n\n\nThird party libraries that are used within an Opencast system in production need to be listed in the \nNOTICES\n file,\nwhich can be found in the root directory of our code repository. Libraries and tools that are only used for testing or\nbuilding the project, or are run via system call, do not need to be listed (e.g. maven, maven plugins, junit, ...).\n\n\nJavaScript Libraries\n\n\nFor JavaScript libraries, list the file or folder that is included and give a short statement about the copyright and\nlicense. This can usually be taken from the copyright header at the top of the library.\n\n\nExample:\n\n\nmodules/matterhorn-admin-ui-ng/src/main/webapp/lib/angular/*\n  AngularJS v1.3.6\n  (c) 2010-2014 Google, Inc. http://angularjs.org\n  License: MIT\n\n\n\nJava Libraries / Maven Dependencies\n\n\nJava dependencies are listed pre module. Maven provides some helpful tools to list dependencies and even report\nlibraries. Have a look at the output of \nmvn dependency:list\n and \nmvn dependency:tree\n or generate a full report for a\nmodule using:\n\n\nmvn -s settings.xml project-info-reports:dependencies\n\n\n\nThis will create a file \ntarget/site/dependencies.html\n containing a full report, including the library versions and\nlicenses.\n\n\nFinally, add the library and license to the \nNOTICES\n file in the form:\n\n\nrn-workflow-service-remote\n  GroupId       ArtifactId    License\n  commons-io    commons-io    The Apache Software License, Version 2.0",
            "title": "Licenses and Legal Matters"
        },
        {
            "location": "/license/#licenses-and-legal-matters",
            "text": "This is a guide from developers for developers and therefore not an official legal document. We try to be as accurate\nas possible but cannot guarantee that there are no mistakes. If in doubt, please send a question to the Opencast\ndeveloper mailing list, to the Opencast Board or to the Apereo Foundation, preferably in that order.",
            "title": "Licenses and Legal Matters"
        },
        {
            "location": "/license/#which-licenses-may-i-use-for-opencast",
            "text": "All libraries that are used in Opencast need to be compatible with the Educational Community License version 2.0.  In short, if the license is on:   the Apereo or Apache Category-A list, it is fine to use the library.  the Apereo or Apache Category-B list, we may use it unmodified. Please avoid Category-B if possible.  the Apereo or Apache Category-X list, we cannot use it.   Everything else needs to go to the Apereo foundation for approval.  These lists, along with a more detailed explanation, can be found on the  Apereo page about practices on third-party\nlicenses  Here is the slightly longer section from the \u201eApereo Licensing & Intellectual Property Practices\u201c page:",
            "title": "Which Licenses May I Use for Opencast?"
        },
        {
            "location": "/license/#how-to-label-third-party-libraries",
            "text": "Third party libraries that are used within an Opencast system in production need to be listed in the  NOTICES  file,\nwhich can be found in the root directory of our code repository. Libraries and tools that are only used for testing or\nbuilding the project, or are run via system call, do not need to be listed (e.g. maven, maven plugins, junit, ...).",
            "title": "How To Label Third Party Libraries"
        },
        {
            "location": "/license/#javascript-libraries",
            "text": "For JavaScript libraries, list the file or folder that is included and give a short statement about the copyright and\nlicense. This can usually be taken from the copyright header at the top of the library.  Example:  modules/matterhorn-admin-ui-ng/src/main/webapp/lib/angular/*\n  AngularJS v1.3.6\n  (c) 2010-2014 Google, Inc. http://angularjs.org\n  License: MIT",
            "title": "JavaScript Libraries"
        },
        {
            "location": "/license/#java-libraries-maven-dependencies",
            "text": "Java dependencies are listed pre module. Maven provides some helpful tools to list dependencies and even report\nlibraries. Have a look at the output of  mvn dependency:list  and  mvn dependency:tree  or generate a full report for a\nmodule using:  mvn -s settings.xml project-info-reports:dependencies  This will create a file  target/site/dependencies.html  containing a full report, including the library versions and\nlicenses.  Finally, add the library and license to the  NOTICES  file in the form:  rn-workflow-service-remote\n  GroupId       ArtifactId    License\n  commons-io    commons-io    The Apache Software License, Version 2.0",
            "title": "Java Libraries / Maven Dependencies"
        },
        {
            "location": "/governance/",
            "text": "Opencast Governance\n\n\nThe Opencast community is governed by a document defining the rights and responsibilities of the board, committer,\nand contributor bodies.  This document can be found \nhere\n.",
            "title": "Governance"
        },
        {
            "location": "/governance/#opencast-governance",
            "text": "The Opencast community is governed by a document defining the rights and responsibilities of the board, committer,\nand contributor bodies.  This document can be found  here .",
            "title": "Opencast Governance"
        },
        {
            "location": "/localization/",
            "text": "Localization\n\n\nIntroduction\n\n\nThe Opencast project uses the\n\nCrowdin Localization Management Platform\n for translating\nOpencast into a variety of languages.\n\n\nThe English translation (en-US) acts as source language that is translated to other languages using Crowdin.\nWhile all translation files are located in the Opencast code repository, only the English translation should\nbe modified in the code repository - all other translation files are downloaded from Crowdin.\n\n\nImportant:\n \nAll translation files for languages other than English (en-US) are downloaded from Crowdin.\nModifications to the translation files in the Opencast code repository will be regularly overwritten and\ntherefore will be lost!\n\n\nNote that Crowdin managers take care of uploading the English sources (and possibly translations) to Crowdin and download the\nothers translations from Crowdin.\n\n\nI would like Opencast to support my language. Is this possible?\n\n\nYes, absolutely! If you are willing to take the effort to provide the translation, we are happy to include your\nfavorite language in Opencast!\n\n\nHow can I provide a language translation?\n\n\nWe use the \nCrowdin Localization Management Platform\n - an easy to\nuse web service for localization management. To provide a language translation, please perform the following steps:\n\n\n\n\nCreate a free account on \nCrowdin\n\n\nVisit the \nOpencast project\n on Crowdin and issue a join request\n\n\nTranslate Opencast on Crowdin\n\n\n\n\nOnce the translation reaches at least 90% (prefarable 100%), please read the section about include and exclusion\nof translations just below.\n\n\nIn case you have questions, we are happy to answer them on the Opencast Users mailing list.\n\n\nInclusion and Exclusion of Translations\n\n\nOpencast supports a number of languages right out-of-the-box. Please find the criteria for inclusion and exlusion of\nlanguage translations in Opencast releases below:\n\n\n\n\n\n\nA not yet supported translation is included into the next major release if it is translated at least 90% at the\n    time when the release branch is cut. The release managers will take the review if no other reviewer can be found.\n\n\n\n\n\n\nA not yet supported translation may be included in the current release branch anytime if it is translated to 100%\n    and a reviewer is found. It will then be part of the next minor release and major release if feasible\n\n\n\n\n\n\nAn endangered translation is a supported translation that is translated less than 80% at the time when the release\n    branch of the next major release is cut. The release managers will publish a list of endangered languages if any\n\n\n\n\n\n\nAn endangered translation will be removed with the next major release if it is not saved. The release managers take\n    care of the removal in case no other person will\n\n\n\n\n\n\nAn endangered translation may be saved by reaching at least 90% translated until at least two weeks before the\n    release date of the next major release and a reviewer is found\n\n\n\n\n\n\nNote that \nCrowdin\n is displaying the percentage translated for \neach language. It is the percentages shown on that page that act as reference.\nConsidering the dates when releases branch are cut, the respective releases schedules act as reference.\n\n\nCrowdin Management And Administration\n\n\nCrowdin managers are persons with privileged access to Crowdin needed to upload new files to be translated to Crowdin.\nThe rest of document should help future Crowdin managers to get familiar with Crowdin quickly.\n\n\nAccepting Translators\n\n\nWe ask that Crowdin users who wish to help translate Opencast send a brief, understandable sentence regarding why they\nwish to help translate Opencast. Users who do not send this in should be asked via the Crowdin messaging system. Something\nas simple as 'I want to help translate $project into [language]' would more than suffice.\n\n\nVersioning\n\n\nCrowdin supports versions management by allowing the management of multiple branches. The relation of\nOpencast code repository branches to Crowdin branches follows the following convention:\n\n\nThe Opencast branch \nr/a.b.x\n corresponds to Crowdin branch \na.b.x\n.\n\n\nCrowdin does automatically detect equal strings across branches so there is no need to configure anything when\na new branch is created.\n\n\nWhen releasing a new version \na.b.c\n of Opencast, the following actions must be performed to keep the Opencast code\nrepository in sync with Crowdin:\n\n\n\n\nDownload the translations from Crowdin branch \na.b.x\n\n\nCommit the downloaded translations into the Opencast branch \nr/a.b.x\n\n\nRelease Opencast \na.b.c\n\n\nMerge Opencast branch \nr/a.b.x\n into Opencast branch \ndevelop\n\n\nUpload sources of Opencast branch \ndevelop\n to Crowdin branch \ndevelop\n\n\nUpload translations of Opencast branch \ndevelop\n to Crodwin branch \ndevelop\n\n\n\n\nWorking with Crowdin CLI\n\n\nThe Crowdin CLI command line tool is used to synchronize the source language files and\ntranslations between the Opencast code repository and the Crowdin project Opencast.\n\n\nThe Crowdin CLI configuration can be found in \n/.crowdin.yaml\n\n\nPlease perform the following steps to get the tool running on your local host:\n\n\n\n\nDownload the \nCrowdin CLI tool\n\n\nGet the API key for the project Opencast \n  \n\n\nAdd the following line to your local Crowdin configuration file (\n~/.crowdin.yaml\n):\nthe first line:\napi_key: <secret key>\n\n\n\n\n\n\n\nNow you can use the Crowdin CLI command line tool to upload source language files and download translations.\n\n\nTo upload the sources from the Opencast code repository to Crowdin, use the following command:\n\n\njava -jar crowdin-cli.jar --config .crowdin.yaml upload sources -b <branch>\n\n\n\nIn case you need to upload the translations from the Opencast code repository branch \n<branch>\n, use the command:\n\n\njava -jar crowdin-cli.jar --config .crowdin.yaml upload translations -b <branch>\n\n\n\nNote that the branch \n<branch>\n will be automatically created if it is not yet existing.\n\n\nTo download the translations from Crowdin, use the following command:\n\n\njava -jar crowdin-cli.jar --config .crowdin.yaml download -b <branch>\n\n\n\nFurther Information\n\n\n\n\nCrowdin Opencast Project\n\n\nCrowdin CLI Documentation\n\n\nCrowdin Versions Management Documentation\n\n\nCrowdin Language Codes",
            "title": "Localization"
        },
        {
            "location": "/localization/#localization",
            "text": "",
            "title": "Localization"
        },
        {
            "location": "/localization/#introduction",
            "text": "The Opencast project uses the Crowdin Localization Management Platform  for translating\nOpencast into a variety of languages.  The English translation (en-US) acts as source language that is translated to other languages using Crowdin.\nWhile all translation files are located in the Opencast code repository, only the English translation should\nbe modified in the code repository - all other translation files are downloaded from Crowdin.  Important:   All translation files for languages other than English (en-US) are downloaded from Crowdin.\nModifications to the translation files in the Opencast code repository will be regularly overwritten and\ntherefore will be lost!  Note that Crowdin managers take care of uploading the English sources (and possibly translations) to Crowdin and download the\nothers translations from Crowdin.",
            "title": "Introduction"
        },
        {
            "location": "/localization/#i-would-like-opencast-to-support-my-language-is-this-possible",
            "text": "Yes, absolutely! If you are willing to take the effort to provide the translation, we are happy to include your\nfavorite language in Opencast!",
            "title": "I would like Opencast to support my language. Is this possible?"
        },
        {
            "location": "/localization/#how-can-i-provide-a-language-translation",
            "text": "We use the  Crowdin Localization Management Platform  - an easy to\nuse web service for localization management. To provide a language translation, please perform the following steps:   Create a free account on  Crowdin  Visit the  Opencast project  on Crowdin and issue a join request  Translate Opencast on Crowdin   Once the translation reaches at least 90% (prefarable 100%), please read the section about include and exclusion\nof translations just below.  In case you have questions, we are happy to answer them on the Opencast Users mailing list.",
            "title": "How can I provide a language translation?"
        },
        {
            "location": "/localization/#inclusion-and-exclusion-of-translations",
            "text": "Opencast supports a number of languages right out-of-the-box. Please find the criteria for inclusion and exlusion of\nlanguage translations in Opencast releases below:    A not yet supported translation is included into the next major release if it is translated at least 90% at the\n    time when the release branch is cut. The release managers will take the review if no other reviewer can be found.    A not yet supported translation may be included in the current release branch anytime if it is translated to 100%\n    and a reviewer is found. It will then be part of the next minor release and major release if feasible    An endangered translation is a supported translation that is translated less than 80% at the time when the release\n    branch of the next major release is cut. The release managers will publish a list of endangered languages if any    An endangered translation will be removed with the next major release if it is not saved. The release managers take\n    care of the removal in case no other person will    An endangered translation may be saved by reaching at least 90% translated until at least two weeks before the\n    release date of the next major release and a reviewer is found    Note that  Crowdin  is displaying the percentage translated for \neach language. It is the percentages shown on that page that act as reference.\nConsidering the dates when releases branch are cut, the respective releases schedules act as reference.",
            "title": "Inclusion and Exclusion of Translations"
        },
        {
            "location": "/localization/#crowdin-management-and-administration",
            "text": "Crowdin managers are persons with privileged access to Crowdin needed to upload new files to be translated to Crowdin.\nThe rest of document should help future Crowdin managers to get familiar with Crowdin quickly.",
            "title": "Crowdin Management And Administration"
        },
        {
            "location": "/localization/#accepting-translators",
            "text": "We ask that Crowdin users who wish to help translate Opencast send a brief, understandable sentence regarding why they\nwish to help translate Opencast. Users who do not send this in should be asked via the Crowdin messaging system. Something\nas simple as 'I want to help translate $project into [language]' would more than suffice.",
            "title": "Accepting Translators"
        },
        {
            "location": "/localization/#versioning",
            "text": "Crowdin supports versions management by allowing the management of multiple branches. The relation of\nOpencast code repository branches to Crowdin branches follows the following convention:  The Opencast branch  r/a.b.x  corresponds to Crowdin branch  a.b.x .  Crowdin does automatically detect equal strings across branches so there is no need to configure anything when\na new branch is created.  When releasing a new version  a.b.c  of Opencast, the following actions must be performed to keep the Opencast code\nrepository in sync with Crowdin:   Download the translations from Crowdin branch  a.b.x  Commit the downloaded translations into the Opencast branch  r/a.b.x  Release Opencast  a.b.c  Merge Opencast branch  r/a.b.x  into Opencast branch  develop  Upload sources of Opencast branch  develop  to Crowdin branch  develop  Upload translations of Opencast branch  develop  to Crodwin branch  develop",
            "title": "Versioning"
        },
        {
            "location": "/localization/#working-with-crowdin-cli",
            "text": "The Crowdin CLI command line tool is used to synchronize the source language files and\ntranslations between the Opencast code repository and the Crowdin project Opencast.  The Crowdin CLI configuration can be found in  /.crowdin.yaml  Please perform the following steps to get the tool running on your local host:   Download the  Crowdin CLI tool  Get the API key for the project Opencast \n    Add the following line to your local Crowdin configuration file ( ~/.crowdin.yaml ):\nthe first line: api_key: <secret key>    Now you can use the Crowdin CLI command line tool to upload source language files and download translations.  To upload the sources from the Opencast code repository to Crowdin, use the following command:  java -jar crowdin-cli.jar --config .crowdin.yaml upload sources -b <branch>  In case you need to upload the translations from the Opencast code repository branch  <branch> , use the command:  java -jar crowdin-cli.jar --config .crowdin.yaml upload translations -b <branch>  Note that the branch  <branch>  will be automatically created if it is not yet existing.  To download the translations from Crowdin, use the following command:  java -jar crowdin-cli.jar --config .crowdin.yaml download -b <branch>",
            "title": "Working with Crowdin CLI"
        },
        {
            "location": "/localization/#further-information",
            "text": "Crowdin Opencast Project  Crowdin CLI Documentation  Crowdin Versions Management Documentation  Crowdin Language Codes",
            "title": "Further Information"
        },
        {
            "location": "/packaging/",
            "text": "Packaging Guidelines\n\n\nThis page is intended as a guideline for packagers. It may help to figure out where to place parts of Opencast.  The\nlocations, etc. proposed here should never overrule the official packaging guides for a specific operating system or\ndistribution.  If in doubt follow the guides for your distribution like for example the \nFedora Packaging\nGuidelines\n\n\nIntroduction\n\n\nIn a Unix file system there are different places for different types of data. Executables, for example, may be placed in\n\n/usr/bin\n, libraries in \n/usr/lib\n, etc. These places are defined by the operating system distributor and the\n\nFilesystem Hierarchy Standard\n. Latter is followed by almost every major\ndistributor, but not everything in there is clearly defined.\n\n\nEspecially software which is installed automatically\u2013for example software from RPM or DEB repositories\u2013should follow\nthese rules so conflicts are minimized and the user will have one place to look for one kind of data. For example if you\nare searching for a system-wide configuration file for any software on Linux every user will always look in \n/etc\n.\n\n\nIf you want to package Opencast use the following documentations to decide where to place files:\n\n\n\n\nDistribution guidelines like the \nFedora Packaging Guidelines\n\n\nFilesystem Hierarchy Standard\n\n\nThis Guide\n\n\n\n\nLocations To Use\n\n\nThe following locations should be used for Opencast and its related data:\n\n\n\n\n/usr/share/opencast\n:\n   Software and data not modified by Opencast. This includes felix, the Opencast modules and external libraries.\n\n\n/etc/opencast\n:\n   Opencast related configuration files (Felix and service configuration, workflows, encoding profiles, etc.)\n\n\n/var/log/opencast\n:\n   The Opencast logfiles. Consider to enable logrotate for this directory.\n\n\n/srv/opencast\n or \n/var/lib/opencast\n:\n   Opencast storage, including the recordings, the archive, the Solr indexes, etc. You may use one of these\n   directories or both. For more details have a look at the explanation below and the discussion in the comments.\n\n\n/tmp/opencast\n:\n   Temporary data which are not necessarily preserved between reboots. This includes the felix-cache and other temporary\n   data.\n\n\n/usr/sbin/opencast\n:\n   Opencast startscript\n\n\n/etc/init.d/opencast\n\n   SysV-Initscript (if necessary)\n\n\n\n\nReasoning for these Locations\n\n\n/usr/share/opencast \u2013 Opencast Software Components\n\n\nThe Filesystem Hierarchy Standard states that \u201c\nThe /usr/share hierarchy is for all read-only architecture independent\ndata files.\n\u201d and that \u201c\nAny program or package which contains or requires data that does not need to be modified should\nstore that data in /usr/share\n\u201d.  It is also used for this purpose by cups, emacs, cmake, pulseaudio, gimp, \u2026 It sould\nbe used for felix.jar and all the modules (lib directory)\n\n\n/etc/opencast \u2013 Opencast Configuration\n\n\nThe Filesystem Hierarchy Standard states that \u201c\nThe /etc hierarchy contains configuration files. A \"configuration file\"\nis a local file used to control the operation of a program; it must be static and cannot be an executable binary.\n\u201d\n\n\n/var/log/opencast/ \u2013 Opencast Logs\n\n\nThe Filesystem Hierarchy Standard states that \u201c\nThis directory contains miscellaneous log files. Most logs must be\nwritten to this directory or an appropriate subdirectory.\n\u201d\n\n\n/srv/opencast and/or /var/lib/opencast/ \u2013 Data modified by Opencast\n\n\nAbout this the Filesystem Hierarchy Standard says that \u201c\nThis hierarchy holds state information pertaining to an\napplication or the system. State information is data that programs modify while they run, \u2026\n\u201d also \u201c\n/var/lib/\n is\nthe location that must be used for all distribution packaging support\u2026\n\u201d\n\n\nWhy Not Use /opt For Packages\n\n\nWhile it is ok to place software in \n/opt\n if you install the manually as \n/opt\n is intended to be used for \u201c\nAdd-on\napplication software\n\u201d by the Filesystem Hierarchy Standard, it should never be used for automatic installations (RPMs\nDebian packages, \u2026).. The Fedora Packaging Guidelines for example are pretty clear about this:\n\n\n\u201c*No Files or Directories under /srv, /opt, or /usr/local [\u2026] In addition, no Fedora package can have any files or\ndirectories under /opt or /usr/local, as these directories are not permitted to be used by Distributions in the FHS.\n\n\nThe reason for this is that the FHS is handing control of the directory structure under /opt to the system administrator\nby stating that \u201c\nDistributions [\u2026] must not modify or delete software installed by the local system administrator \u2026\n\u201d.\n\n\nThat is something you cannot guarantee with automatic installations. For example if you use RPMs, the only way to do\nthis would be to mark every single file (binaries, modules, assets, \u2026) as configuration files which are not to be\nreplaced in case they are modified. It is quite obvious that this would be a a really bad idea leading to a number of\nfurther problems.\n\n\nNotice For System Operators\n\n\nThis guide is supposed to defines default locations for an Opencast system. It does not restrict your own system\nconfiguration.\n\n\nFor a Opencast system it is for example quite common to mount an external storage (NFS, \u2026) and use it as storage for\nOpencast. You do not have to mount it to \n/var/lib/opencast\n if you do not want to. Instead, mount it in /media or\nwherever you want\u2013it is your system afterall\u2013and either change the Opencast configuration to use the directory of your\ndirectly, or put appropriate symlinks in \n/var/lib/opencast\n. This is, however, system specific and should not be done\nfor packages.",
            "title": "Packaging"
        },
        {
            "location": "/packaging/#packaging-guidelines",
            "text": "This page is intended as a guideline for packagers. It may help to figure out where to place parts of Opencast.  The\nlocations, etc. proposed here should never overrule the official packaging guides for a specific operating system or\ndistribution.  If in doubt follow the guides for your distribution like for example the  Fedora Packaging\nGuidelines",
            "title": "Packaging Guidelines"
        },
        {
            "location": "/packaging/#introduction",
            "text": "In a Unix file system there are different places for different types of data. Executables, for example, may be placed in /usr/bin , libraries in  /usr/lib , etc. These places are defined by the operating system distributor and the Filesystem Hierarchy Standard . Latter is followed by almost every major\ndistributor, but not everything in there is clearly defined.  Especially software which is installed automatically\u2013for example software from RPM or DEB repositories\u2013should follow\nthese rules so conflicts are minimized and the user will have one place to look for one kind of data. For example if you\nare searching for a system-wide configuration file for any software on Linux every user will always look in  /etc .  If you want to package Opencast use the following documentations to decide where to place files:   Distribution guidelines like the  Fedora Packaging Guidelines  Filesystem Hierarchy Standard  This Guide",
            "title": "Introduction"
        },
        {
            "location": "/packaging/#locations-to-use",
            "text": "The following locations should be used for Opencast and its related data:   /usr/share/opencast :\n   Software and data not modified by Opencast. This includes felix, the Opencast modules and external libraries.  /etc/opencast :\n   Opencast related configuration files (Felix and service configuration, workflows, encoding profiles, etc.)  /var/log/opencast :\n   The Opencast logfiles. Consider to enable logrotate for this directory.  /srv/opencast  or  /var/lib/opencast :\n   Opencast storage, including the recordings, the archive, the Solr indexes, etc. You may use one of these\n   directories or both. For more details have a look at the explanation below and the discussion in the comments.  /tmp/opencast :\n   Temporary data which are not necessarily preserved between reboots. This includes the felix-cache and other temporary\n   data.  /usr/sbin/opencast :\n   Opencast startscript  /etc/init.d/opencast \n   SysV-Initscript (if necessary)",
            "title": "Locations To Use"
        },
        {
            "location": "/packaging/#reasoning-for-these-locations",
            "text": "",
            "title": "Reasoning for these Locations"
        },
        {
            "location": "/packaging/#usrshareopencast-opencast-software-components",
            "text": "The Filesystem Hierarchy Standard states that \u201c The /usr/share hierarchy is for all read-only architecture independent\ndata files. \u201d and that \u201c Any program or package which contains or requires data that does not need to be modified should\nstore that data in /usr/share \u201d.  It is also used for this purpose by cups, emacs, cmake, pulseaudio, gimp, \u2026 It sould\nbe used for felix.jar and all the modules (lib directory)",
            "title": "/usr/share/opencast \u2013 Opencast Software Components"
        },
        {
            "location": "/packaging/#etcopencast-opencast-configuration",
            "text": "The Filesystem Hierarchy Standard states that \u201c The /etc hierarchy contains configuration files. A \"configuration file\"\nis a local file used to control the operation of a program; it must be static and cannot be an executable binary. \u201d",
            "title": "/etc/opencast \u2013 Opencast Configuration"
        },
        {
            "location": "/packaging/#varlogopencast-opencast-logs",
            "text": "The Filesystem Hierarchy Standard states that \u201c This directory contains miscellaneous log files. Most logs must be\nwritten to this directory or an appropriate subdirectory. \u201d",
            "title": "/var/log/opencast/ \u2013 Opencast Logs"
        },
        {
            "location": "/packaging/#srvopencast-andor-varlibopencast-data-modified-by-opencast",
            "text": "About this the Filesystem Hierarchy Standard says that \u201c This hierarchy holds state information pertaining to an\napplication or the system. State information is data that programs modify while they run, \u2026 \u201d also \u201c /var/lib/  is\nthe location that must be used for all distribution packaging support\u2026 \u201d",
            "title": "/srv/opencast and/or /var/lib/opencast/ \u2013 Data modified by Opencast"
        },
        {
            "location": "/packaging/#why-not-use-opt-for-packages",
            "text": "While it is ok to place software in  /opt  if you install the manually as  /opt  is intended to be used for \u201c Add-on\napplication software \u201d by the Filesystem Hierarchy Standard, it should never be used for automatic installations (RPMs\nDebian packages, \u2026).. The Fedora Packaging Guidelines for example are pretty clear about this:  \u201c*No Files or Directories under /srv, /opt, or /usr/local [\u2026] In addition, no Fedora package can have any files or\ndirectories under /opt or /usr/local, as these directories are not permitted to be used by Distributions in the FHS.  The reason for this is that the FHS is handing control of the directory structure under /opt to the system administrator\nby stating that \u201c Distributions [\u2026] must not modify or delete software installed by the local system administrator \u2026 \u201d.  That is something you cannot guarantee with automatic installations. For example if you use RPMs, the only way to do\nthis would be to mark every single file (binaries, modules, assets, \u2026) as configuration files which are not to be\nreplaced in case they are modified. It is quite obvious that this would be a a really bad idea leading to a number of\nfurther problems.",
            "title": "Why Not Use /opt For Packages"
        },
        {
            "location": "/packaging/#notice-for-system-operators",
            "text": "This guide is supposed to defines default locations for an Opencast system. It does not restrict your own system\nconfiguration.  For a Opencast system it is for example quite common to mount an external storage (NFS, \u2026) and use it as storage for\nOpencast. You do not have to mount it to  /var/lib/opencast  if you do not want to. Instead, mount it in /media or\nwherever you want\u2013it is your system afterall\u2013and either change the Opencast configuration to use the directory of your\ndirectly, or put appropriate symlinks in  /var/lib/opencast . This is, however, system specific and should not be done\nfor packages.",
            "title": "Notice For System Operators"
        },
        {
            "location": "/proposal-log/",
            "text": "Opencast Proposals\n\n\nAll important decisions for Opencast have to be made on list. For more details, please have a look at out \ndocumentation\nabout decision making\n.\n\n\nThe following list contains a list of passed proposals for reference.\n\n\nPassed Proposals\n\n\nCrowdin Acceptance Policy\n\n\nProposed by Greg Logan \ngregorydlogan@gmail.com\n, passed on November 17, 2017\n\n\nHi all,\n\nPer the discussion in the meeting today, we need to set a policy regarding what\nis expected of our Crowdin translators prior to joining the translation team.\nMy proposal is that they must write a brief, understandable sentence regarding\nwhy they want to help translate Opencast via the Crowdin UI.  This is an\noptional field in the workflow where they request to be a translator (ie, no new\ntools or fields) which is sometimes filled in, but mostly left blank.  Something\nlike\n\n'I want to help translate $project into [language]'\n\nwould be sufficient.  This filters out the bots, yet is simple enough that\nsomeone with Google translate ought to be able to work something out.  Once this\npasses I will update the Crowdin and Opencast docs regarding the requirements,\nand then we should be good to go.\n\nProposal closes EOD 2017-11-17.\n\n\n\nRename Matterhorn Repository To Opencast\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, passed on July 13, 2017\n\n\nHi everyone,\nI think we have reached a point where people are wondering what the\nhell matterhorn is ;-D\n\nThat is why I #propose to rename our official repository from\nmatterhorn to opencast:\n\nold: https://bitbucket.org/opencast-community/matterhorn/\nnew: https://bitbucket.org/opencast-community/opencast/\n\nThis proposal will end on Thu Jul 13 16:00 CEST 2017\n\nRegards,\nLars\n\n\n\nCriteria For Inclusion Of Translations\n\n\nProposed by Sven Stauber \nsven.stauber@switch.ch\n, passed on April 28, 2017\n\n\nDear all,\nThere are currently no rules about the criteria needed for a translation to be\nincluded or excluded from the official Opencast releases.\n\nI hereby propose the following rules:\n\n1.  A not yet supported translation is included into the next major release if\n    it is translated to at least 90% at the time when the release branch is cut.\n    The release managers will take the review if no other reviewer can be found.\n\n2.  A not yet supported translation may be included in the current release\n    branch anytime if it is translated to 100% and a reviewer is found. It will\n    then be part of the next minor release and major release if feasible\n\n3.  An endangered translation is a supported translation that is translated less\n    than 80% at the time when the release branch of the next major release is\n    cut. The release managers will publish a list of endangered languages if any\n\n4.  An endangered translation will be removed with the next major release if it\n    is not saved. The release managers take care of the removal in case no other\n    person will\n\n5.  An endangered translation may be saved by reaching at least 90% translated\n    until at least two weeks before the release date of the next major release\n    and a reviewer is found\n\n6. Considering the percentages of being translated, Crowdin acts as reference\n\n7. Considering the dates of the release cuts of major releases, the respective\n   releases schedules act as reference\n\nBest,\nSven\n\n\n\nMake Maintenance Releases Easier\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, passed on April 24, 2017\n\n\nHi everyone,\nover the last years, I have cut a lot of Opencast maintenance releases.\nThe process is to announce that a release will be cut, create a release\ncandidate and wait 72h without veto to actually release.\n\nI have always sent out the voting mail as required by our release\nprocess and I can always count on the usual response: No reply.\n\nThis is actually not very surprising since for example now for the\n2.3.3 release, people have either already tested the latest state of\nr/2.3.3 or are involved in the next big release already.\n\nIn short this means that we always have a three day waiting period in\nwhich basically nothing happens. That is why I would like to change the\nprocess for *maintenance releases* in the following way:\n\n  A release manager may cut new maintenance releases at any time\n  without prior release candidate.\n  He should openly announce the date for a new release a week before\n  the release or at any earlier point in time.\n\nNote that this will also allow a release manager to release as fast as\npossible if necessary (e.g. security fix) since the announcement is not\nstrictly required but only a strong advise.\n\nThis should lessen the work for the a release managers and will enable\nmore agile release processes. We also should not really loose any QA\nwork since everyone knows when releases will happen and people can\nalways test the latest state of a release branch which will become the\nnew release.\n\nThis proposal will not affect major releases where release candidates\nwith three days testing period would still be required.\n\nI hope you agree with this change,\nLars\n\n\n\nMinor documentation changes do not require JIRA issues or PRs\n\n\nProposed by Stephen Marquard \nstephen.marquard@uct.ac.za\n, passed on June 9, 2017\n\n\nTo reduce the overhead involved in improving our documentation, I #propose that\nminor fixes to documentation may be committed to either maintenance branches or\ndevelop without requiring a JIRA issue or pull request.\n\nMarkdown docs can be edited directly on bitbucket (and git should we move to\nthat), which is a very fast and convenient way for developers to fix\ndocumentation.\n\nConstraints: documentation fixes committed in this way should be minor changes\nonly; for example fixing typos, layout, formatting, links or small changes to\nexisting content, but no significant new content (which should continue to go\nthrough the usual review process).\n\n\n\nRequiring Java 1.8 for 3.0\n\n\nProposed by Greg Logan \ngregorydlogan@gmail.com\n, passed on June 12, 2017\n\n\nHi folks,\n\nFor those following along, James Perrin has identified an issue where 3.0\nrequires Java 1.8 at runtime.  We haven't formally included that\nrequirement for 3.0 yet (it's already required for 4.0), but I hereby\npropose that we do.  No one seems to have noticed this requirement was\nalready present in 3.0 (not even me!), even at this late in the release\ncycle which speaks, I think, to the already widespread adoption of Java\n1.8.  We would also have to go back and redo all of our testing were we to\nchange the problematic jar to an earlier version, which would be\nunfortunate for our release timelines.\n\nThis proposal closes EOD 2017-06-12 UTC -6, at which point I should be able\nto cut the release.\n\nG\n\n\n\nOfficially declare the Admin UI Facade as internal API for exclusive use by the module matterhorn-adminui-ng\n\n\nProposed by Sven Stauber \nsven.stauber@switch.ch\n, passed on December 16, 2016\n\n\nDear all,\nI hereby propose to officially declare the Admin UI Facade as internal API for\nexclusive use by the module matterhorn-adminui-ng.\n\nReason:\nThe Admin UI Facade is essentially the backend of the Admin UI.  While it would\nbe technically possible to use this API for other purposes, this would introduce\ndependencies to components other than the Admin UI.\n\nAllowing such dependencies to come into existence would cause changes to the\nAdmin UI Facade to potentially break other (possibly unknown external)\ncomponents.  Hence, we would need to announce, coordinate and discuss changes to\nthis API to not break dependencies to components we potentially don't even know.\nThis would unnecessarily slow down the future development of the Admin UI.  In\naddition, Opencast 2.3 introduces the External API which has been explicitly\ndesigned to meet the requirements of an API used to integrate other components.\n\nChanges needed:\nThe documentation needs to reflect that the Admin UI Facade is an internal API\nthat will be changed without prior announcement whenever needed without\nrespecting dependencies other than the Admin UI itself and therefore people\nshall not use this API for integration purposes.\n\nBest,\nSven\n\n\n\nOpencast Next: Code Cleanup\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, passed on Thu, 7 July 2016 15:21:19 UTC\n\n\nHi everyone,\na while ago we discussed on the technical meeting that we would like to\nremove some old code from Opencast since these parts do not work\nproperly (sometimes not at all) or are unused.\n\nWhy cleaning up? To name some reasons:\n\n- Less code to run (less memory, faster start-up)\n- Less things to compile (faster build)\n- Less dependencies\n- People do not accidentally stumble upon broken things\n- Less work for maintenance\n\nAnd now here is what I #propose to remove and a reason why I think this\nshould be removed. I already took the comments people made in the first\ndraft [1] into account, although I still dared to include the two last\nitems but this time, hopefully with a convincing reason for why they\nshould be removed.\n\n1. Old Administrative User Interface (matterhorn-admin-ui)\n   The reason for this should be obvious: We got a new one. The old one\n   has not been tested for the last three releases, is not linked\n   anywhere anymore and is partly buggy due to changes to Opencast. To\n   maintain two interfaces for one thing do not make sense.\n\n2. Hold-state Workflow Operations\n   These do not work with the new interface any longer and the concept\n   has since been replaced by the actions you can perform on archived\n   material.\n\n3. CleanSessionsFilter\n   Old temporary bug fix. For more details read the thread on our\n   developer list.\n\n4. Republish Workflow Operation Handler\n   It can be removed since it has been replaced by a flag on\n   the publish operation in 2.x.\n\n5. Old workflows + encodings\n   We got new ones. These were only left because of the old ui.\n\n6. Old player (Flash in engage ui)\n   Flash is dead. We have the new player and Paella.\n\n7. Most of shared_ressources\n   Almost everything in here belongs to old user interfaces.\n\n8. matterhorn-engage-player\n   This is the old player Flex project. Iam not even sure it can still\n   be compiled.\n\n\n9. matterhorn-test-harness\n   Old integration tests\n\n10. matterhorn-mediapackage-ui\n    Old UI ressources\n\n11. matterhorn-manager-*\n    Old, outdated configuration modification via web ui. This was never\n    used and would need a major update to get it working again at all.\n\n12. matterhorn-load-test*\n    Some tests. I have never seen them executed by anyone.\n\n13. matterhorn-holdstate-workflowoperation\n    Workflow operations requiring a hold state which does not exist\n    anymore with the new admin interface.\n\n14. matterhorn-deprecated-workflowoperation\n    The name says everything. This includes the download DVD operation.\n\n15. matterhorn-annotation-*\n    This should not work with either of the current players anymore.\n\n16. docs/jmeter, docs/scripts/load_testing\n    Configuration for a performance testing tool. Not used for a long\n    time and not up-to-date.\n\n17. Everything unused from:\n    https://data.lkiesow.de/opencast/apidocs/deprecated-list.html\n    E.g. FunctionException and ProcessExecutor(Exception)\n\n18. matterhorn-webconsole\n    Karaf comes with a web console. We do not use our old implementation\n    anymore.\n\n19. matterhorn-mediapackage-manipulator\n    Rest endpoint for media package manipulation. It's not used anymore\n    except by components to be removed.\n\n\n20. matterhorn-search-service-feeds\n    Broken implementation for RSS/Atom feeds\n\n21. matterhorn-caption-* and embed operation\n    Service for converting different subtitle formats and operation to\n    embed these subtitles into the media files. This is *not* player\n    caption support. If required, FFmpeg can be used for conversion\n    between several subtitle formats. Asked on list [2], no one uses\n    this.\n\n\nAs indicated before, points 20 and 21 had some comments for leaving them\nin which did not convince me to not propose this. \u201cInstead of removing\nit, fix it\u201d is an easy thing to say but sadly requires ressources.\nKeeping it, announcing it as features and then tell people that it is\nnot working only afterwards is a bad thing and I would like to avoid\nthat.\n\nNote that all the code is still in our history so that we loose nothing\nif we want the old code back.\n\nPlease feel free to indicate if this action is fine for you or if you\nwant to keep some of the marked code. Please provide a reason if you do.\n\nBest regards,\nLars\n\n[1] http://bit.ly/28YOEZ1\n[2] http://bit.ly/28Ztlt8\n\n\n\nThis proposal has passed with these additional corrections:\n\n\nHi,\nwe discussed this on today's technical meeting and I'm slightly\nchanging the proposal:\n\n20. Let's remove matterhorn-search-service-feeds only after September\n    1st which is a realistic time to get things into the next Opencast\n    release. If someone has fixed the issue by them, we will, of\n    course, keep it.\n    This change takes into account that some people have said they are\n    interested into fixing that module, but will make sure that it's\n    removed if no one fixes it to not have an advertised but broken\n    feature.\n\n21. I will be looking into adding subtitle support in a sensible way\n    before removing the matterhorn-caption-* modules or at least\n    clarify if they can still be used.\n\nRegards,\nLars\n\n\n\nHi James,\na couple of days, I talked to someone saying that he will soon provide\na patch adding exactly this functionality. The holdstate operations are\ndefinitely broken due to their UI.\n\nMy suggestion for a compromise here:\n - Remove them if that patch for archiving the options is released\n - Remove them if no one fixes them in time (September 1st) for 2.3\n\nIf you want to bring them back later, we always keep the code in our\nhistory.\n\nRegards,\nLars\n\n> Hi,\n> I would like to keep 2 and presumably 13. Both Manchester and AFAIK\n> Cape Town have use cases for hold states since there is still no\n> mechanism for passing WF configuration options from one WF to another.\n> Regards\n> James\n\n\n\nThe patch has \nalready been published\n.\n\n\nOpencast Community Repository Owners\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, passed on Fri, 13 May 2016 18:41:52 UTC\n\n\nHi,\ntoday, in the technical meeting, we shortly discussed how to handle\nrequests, problems, etc regarding the other repositories we are hosting\nunder the umbrella of the Opencast community:\n\n  https://bitbucket.org/opencast-community/profile/repositories\n\nWhile we have people who care about the official Opencast repository as\nwell as rules about what may be merged, who may merge things, \u2026 we do\nnot have that for other repositories and for some it's very unclear.\n\nThat is why I would like to propose that every repository under the\numbrella of the Opencast community needs to have a \u201cproject owner\u201d\nbeing responsible for that repository. Usually it should be the one\nrequesting that repository, but of course it can be someone else known\nin the community.\n\nI would also like to propose that if there is no one willing to take up\nthe responsibility to take care of a repository (ownership) if an old\nowner leaves, the repository should either be removed or marked as\ndeprecated and moved to a separate section if so requested.\n\nFinally, I would like to propose that we use the new \u201cproject\u201d feature\nof BitBucket to group the repositories into the groups:\n\n- Opencast\n- Contrib\n- Adopters\n- Deprecated (<- to be created if needed)\n\nCurrently, all repositories are in one big project.\n\nRegards,\nLars\n\n\n\nRename Opencast Mailing Lists\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, passed on Thu, 14 Apr 2016 00:00:00 UTC\n\n\nHi everyone,\ntraditionally, we have the three mailing lists:\n\n - matterhorn@opencast.org (development list)\n - matterhorn-users@opencast.org (user list)\n - community@opencast.org (more or less announcements)\n\nRecently, though, we have seen especially the last two list being used\nfor user questions and problems. That is not surprising as we dropped\nthe name \u201cMatterhorn\u201d and new users do not know what that the list\nmatterhorn-users is meant for questions about Opencast.\n\nThat is why I would like to rename these lists to\n\n - dev@opencast.org or development@opencast.org (I prefer the short\n   name but don't have very strong feelings about that)\n - users@opencast.org\n - announcements@opencast.org\n\nTogether with the already existing security-notices list, this gives\nthese lists a very clear meaning. It would also have the benefit that\nusers only interested in general announcements could subscribe to one\nlist only which would likely be a very low-traffic mailing list.\n\nAdditionally, this would make it sufficient to send announcements to\none list, instead of sending it to all three lists.\n\nTo prevent general questions on the announcements list, I suggest we\ngrant posting rights to board members, committers or other people who\nhave or had a role in our community only. I don't think we need to be\ntoo strict here but should make sure that people understand what this\nlist is for.\n\nFinally, for the sake of our current members, I would suggest that we\nforward the mails to the old addresses for at least until the end of\nthe year, if that is possible.\n\nBest regards,\nLars\n\n\n\nDocumentation Pull Request Merge Order\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, passed on Thu, 25 Feb 2016 20:52:00 UTC\n\n\nHi everyone,\nas discussed in this weeks technical meeting, I hereby #propose to\nallow out-of-order merges of documentation pull requests in the same way\nwe have this exception for bug-fixes.\n\nto be precise, I #propose to change the development process docs for\nreviewing and merging [1] in the following way:\n\n[old]\n\n - Pull requests for bug fixes (t/MH-XXXXX-...) may be reviewed and\n   merged out of order.\n\n[new]\n\n - Pull requests for bug fixes or documentation may be reviewed and\n   merged out of order.\n\nRegards,\nLars\n\n[1] https://docs.opencast.org/develop/developer/reviewing-and-merging/\n\n\n\nRemoving instances of print statements with a style rule #proposal\n\n\nProposed by Greg Logan \ngregorydlogan@gmail.com\n, passed on Wed, 12 Feb 2016 12:00:00 UTC\n\n\nHi folks,\n\nI noticed in a recently review that there are still System.out.println\nstatements in use in our codebase.  I was surprised, because thought we had\npreviously implemented a checkstyle rule which would have banned those\nstatements!  I hereby #propose that we implement the changes outlined in\nhttps://opencast.jira.com/browse/MH-11222, and remove these statements in\nfavour of logger statements.  I also propose that we add this rule to the\ncheckstyle ruleset so that we don't have to deal with this again going\nforward.  Proposal closes EOD 2016-02-03.\n\nG\n\n\n\nHow to release a new Opencast version\u2026\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, passed on Fri, 14 Aug 2015 12:54:51 UTC\n\n\nHi everyone,\nserving as co-release manager for two versions of Opencast, I noticed\nthat our current release process has some aspects of the release defined\nin a way that is more hindering than helpful and I want to #propose a\nslight change to these recommendations.\n\nI hereby #propose:\n\n1. Get rid of the `master` branch, make `develop` the main branch.\n2. Do not use the --no-ff flags for merges\n3. Do not create versions/tags in a release branch. Separate them.\n\n\nReasoning:\n\n1. The short explanation whould be: When did you explicitely checked\n   out `master` last time? People rarely do that. If I want a specific\n   version, I use the tag, if not I want the release branch or\n   `develop`.\n   If you think about it, then the whole reason for `master` in GitFlow\n   is to always provide the last stable version to users who just check\n   out the repository and do nothing else. The problem with Opencast is,\n   that we support multiple versions at the same time. If in a couple\n   of weeks 1.6.2 is being released, it is the latest stable. Is it? If\n   I check out `master`, however, I will still get 2.0 as we cannot\n   merge 1.6.x afterwards. While you can grasp the reasons behind this,\n   it is a bit confusing for users and it is much easier to just tell\n   them to use the tag to check out a specific version.\n   That it, if they do not use the tarballs from BitBucket anyway.\n\n2. First of all, most people seem to be using BitBucket for\n   auto-merging and it does not use --no-ff. So we are not really\n   consistent anyway. Being consistent and using  --no-ff would mean to\n   forbid the usage of the BitBucket merge.\n   Second, have a look at the confusing mess that are the current\n   branches (I tried to find something in the visualization a while ago\n   but gave up). It would be much cleaner to try using fast-forward\n   merges. So instead of using non-fast-forward commits I would argue\n   that we should instead try to use as many fast-forward commits as\n   possible.\n\n3. Once we decided to have the tags in our branches like this:\n\n      ---- A ---- B (tagged) ----- C ---- D -->\n\n   A is the commit containing the version that is decided to be\n   released. B is the tagged version. It is exactly the same code as A\n   except for the pom.xml versions that are modified. Finally C then\n   reverts B as the modified version should not be part of the release\n   branch, .... After C, the code is basically A again except for the\n   history (which we later need to merge which can be problematic). D\n   would then be the next \u201creal\u201d commit, meaning the next fix.\n\n   Much easier to handle would be the following structure:\n\n     ---- A ---- D -->\n           \\\n            B (tagged)\n\n   You do not have to revert that commit, you do not need to merge the\n   easily conflicting pom.xml changes and in the end, you would anyway\n   check out the tag using  git checkout <tag>  if you want that\n   specific version\n\n\nBranching structure:\n\nTo have a complete overview, this is what the new branching structure\nwould look like:\n\n\n  develop --*--*--*--*--*----*--------*--------*---->\n                   \\        /                 /\n            r/x.y.z *--*--*---*--*--*--*--*--*---->\n                           \\                  \\\n                            * x.y.z-beta1      * x.y.z-rc1\n\nRegards,\nLars\n\n\n\nMoving away from the 3rd party scripts\n\n\nProposed by Greg Logan \ngregorydlogan@gmail.com\n, passed by Fri, 24 Jul 2015 16:45:40 UTC\n\n\nHi folks,\n\nAs it stands right now we depend on the 3rd party tool script to\ninstall a great many of our 3rd party dependencies.  These are\nutilities like tesseract, ffmpeg, sox, etc.  This script is maintained\nby Matjaz, in his own time.  I'd like to take a moment to thank him\nfor a doing a great job on a particularly annoying aspect of\nsupporting our work!  I know it hasn't been easy, especially\nsupporting vast number of different OS versions!\n\nWith the release of 2.0 I noticed that our 3rd party tool script is\nbecoming both a little out of date, and difficult to maintain.  I took\na quick look around and it seems like *most* of our dependencies are\navailable from normal distribution repositories for Debian based\nsystems, and I'm told that there is a similar situation for Redhat\nbased systems.  I am unsure of how many of our users are running\nMatterhorn on Mac, but I would hope that our developers who are\nworking on Mac would be able to provide instructions and/or binaries\nfor those users.  The only dependency where there might be a universal\nsticking point is ffmpeg (due to patent concerns), however ffmpeg\nbuilds a full static binary with each release, so I assume we can\neither depend on this and/or cache them somewhere.\n\nWhat this means is that we can potentially remove the 3rd party script\nfrom our repository.  I hereby #propose we find a way to do that,\nwhich would remove the 3rd party script from the repository and\nreplace it with a number of new steps in the install documentation.\n\nG\n\n\n\nStatus of youtube in 2.0 and #proposal to change the default workflow\n\n\nProposed by R\u00fcdiger Rolf \nrrolf@Uni-Osnabrueck.DE\n, passed on Sat, 13 Jun 2015 14:15:55 UTC\n\n\nHi list!\n\nThere was some discussion in the DevOps meeting yesterday if the\nYoutube distribution would work or not. I offered to check this.\n\nThe good news first: IT WORKS!\nJust follow this manual and your Matterhorn - ups Opencast -  is ready\nto distribute to Youtube.\n\n  http://docs.opencast.org/r/2.0.x/admin/modules/youtubepublication/\n\nThe bad news: The default workflow definition does not really support\nthe publishing on Youtube, as only one video file could be published\nby the current WOH.\n\n  https://opencast.jira.com/browse/MH-10920\n\nThe reason is simple and the fix would be too. But there are some\noptions to fix this:\n\n1. Remove the option to distribute to Youtube from the default workflow\n   definition, as the complicated configuration would have to come\n   first anyway.\n2. Only let \"presenter\" or \"presentation\" be published to Youtube. We\n   would need a new youtube tag and add this to the compose operation\n   and the youtube operation.\n3. Introduce the composite operation to the workflow definition and\n   publish only the resulting single stream to Youtube.\n4. Upgrade the WOH to support publishing of multiple files.\n\nI would say that option 4 could be 2.1 goal, but not for 2.0.\n\nI would #propose to go for option 1, as nobody can use Youtube\nout-of-the-box anyway. And the admin could then setup  an appropriate\nYoutube workflow for their needs too.\n\nRegards\nR\u00fcdiger\n\n\n\nEpisode DublinCore Catalog\n\n\nProposed by Karen Dolan \nkdolan@dce.harvard.edu\n, Passed on Sat, 30 May 2015 12:39:05 UTC\n\n\nDear Opencast-ees,\n\nThe following proposal addresses MH-10821[1]. An issue that exposes a\nknow long time ambiguity regarding metadata and the ingest service.\nThe reason that its a proposal is that it normalizes the handling of\ninbound episode catalog metadata in the ingest service.\n\n\n1) A new configuration parameter, boolean, for the Ingest Service. The\n   config param identifies if episode metadata precedence is for\n   Ingestee (i.e. Opencast system) or the Ingester (i.e. Capture\n   Agent).\n\n   For example: at our site, the scheduling entity is the metadata\n   authority. All updates are made to the Scheduling endpoint. The\n   Capture Agent always has stale episode catalog metadata. At other\n   sites, updates are made on the Capture Agent directly. The\n   community default can be for priority to the Capture Agent.\n\n2) All Ingest endpoints perform the same consistent process to ensure\n   that an episode catalog will exist, manually or automatically\n   provided.\n\n3) The process performs the following...\n\n3.1. Gather data\n\n - Check if inbound media package contain a reference to an Episode\n   DublinCore catalog and if that catalog contains a title.\n - Check if the inbound media package contains a title attribute.\n - Check if the Workflow service has a reference to the mediapackage's\n   Episode Dublin Core catalog\n - Check if the Scheduler service retained a reference to the event's\n   Episode Dublin Core catalog\n\n3.2. Use config param to prioritize action on acquiring an Episode dc\n   catalog for the media package\n\n  If Capture Agent metadata takes precedence:\n     - Take the inbound Episode dc catalog, if it exists\n     - Take the Episode dc catalog from the workflow service, if it\n       exists\n     - Take the Episode dc  catalog from the scheduler service, if it\n       exists\n     - Create an Episode dc catalog from the title in the media\n       package,, if it exists\n     - Create an Episode dc catalog using a default title (i.e.\n       \"Recording-1234556XYZ\")\n\n If Opencast metadata takes precedence:\n     - Take the Episode dc catalog from the workflow service, if it\n       exists\n     - Take the Episode dc  catalog from the scheduler service, if it\n       exists\n     - Take the inbound Episode dc catalog if it exists\n     - Create an Episode dc catalog from the title in the media\n       package, if it exists\n     - Create an Episode dc catalog using a default title (i.e.\n       \"Recording-1234556XYZ\")\n\nI'll start a pull for the above, and appreciate any thoughts.\n\nRegards,\nKaren\n\n[1] https://opencast.jira.com/browse/MH-10821\n\n\n\nDropping Taglines\n\n\nProposed by  Greg Logan \ngregorydlogan@gmail.com\n, Passed on Fri, 29 May 2015 16:19:09 UTC\n\n\nHi folks,\n\nI hereby propose that we drop the practice of having taglines.  I\npropose this because we don't have a place in the new admin UI to put\nthem, nor have I ever heard any of the adopters make use of it.  I know\nwe don't use it as a committing group, which means that *no one* is\nusing them.\n\nG\n\n\n\nWiki Cleanup\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, Passed on Fri, 24 May 2015 11:36:49 UTC\n\n\nHi everyone,\nsince we partly switched to our new documentation [1] I would like to\nmake sure that the old and mostly outdated documentation goes away so\nthat no one stumbles upon that. When I had a look at the wikis we\ncurrently have I noticed that most of our 17(!) wikis have not been\ntouched in years and can probably go away.\n\nHere is a list of our wikis and what I #propose to do with/to them:\n\nKeep (maybe clean-up a bit):\n - Matterhorn Adopter Guides\n - Matterhorn Developer Wiki\n - Opencast Matterhorn D/A/CH\n - Opencast Matterhorn Espa\u00f1ol\n - LectureSight\n\nExport as PDF to archive the contents and then delete:\n - Matterhorn Release Docs - 1.0\n - Matterhorn Release Docs - 1.1\n - Matterhorn Release Docs - 1.2\n - Matterhorn Release Docs - 1.3\n - Matterhorn Release Docs - 1.4\n - Matterhorn Release Docs - 1.5\n - Matterhorn Release Docs - TRUNK\n\nKeep until 2.1 is out then export as PDF and delete:\n - Matterhorn Release Docs - 1.6\n\nJust delete:\n - Analytic video annotation\n - Infra\n - Matterhorn Documents\n - Opencast Community\n\n\nPlease let me know if you agree or disagree with this proposal.\n\nRegards,\nLars\n\n[1] http://documentation.opencast.org\n\n\n\nJira Clean-Up\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, Passed on Fri, 8 May 2015 11:52:16 UTC\n\n\nHi everyone,\nas discussed in the technical meeting, I hereby #propose:\n\n  The \u201cBlocker\u201d and \u201cRelease Blocker\u201d severity status are more or less\n  redundant. As part of cleaning up Jira, let us remove the \u201cRelease\n  Blocker\u201d severity in favor of \u201cBlocker\u201d.\n\nAs footnote, some statistics: Since the beginning of 2014, 70 Release\nBlockers have been files in Jira while mere *8* Blockers have been\nfiles.\n\nRegards,\nLars\n\n\n\nOpencast Documentation\n\n\nProposed by R\u00fcdiger Rolf \nrrolf@uni-osnabrueck.de\n, Passed on Sat, 02 May 2015 14:43:28 UTC\n\n\nHi all,\n\nTobias, Basil, Lars and I discussed status of the current migration of\nthe Opencast (Matterhorn) documentation to GIT. We still see some open\nissues that need clarification so we would like to propose the\nfollowing points:\n\n*1. Formating and Hosting of the Documentation *\n\nWe want to use https://readthedocs.org to or a similar service create\na more appealing HTML version from the Markdown of the documentation.\n\nThe documentation will be versioned there so that for older versions\nthe documentation is still available. By default the \"latest\" version\nis shown.  The versions of the documenation will be generated based on\nthe release branches.\n\n*2. Structure of the Documentation*\n\nWe see the documentation in*Git *separating into 3 sections:\n\n - /Administration Guide/: with information about the installation,\n   configuration, customization and integration. This will be the part\n   of information by an administrator to setup\n   Opencast.\n\n - /Developer Guide/: All information related to implementation\n   details of Opencast, so that this will be updated in a pull request\n   (API changes, module descriptions, architecture). The development\n   process documents should also go here as only committers usually\n   should change these.\n\n - /User Guide/: Documentation of the (new) Admin UI that was already\n   started by Entwine and the Engage UI (especially Theodul Player).\n   This guide should only describe options available on the UIs.\n\nWithin the *Wiki* we still see the need for 2 sections:\n\n - /Developer Wiki/: Proposals, working documents and meeting notes\n   will be kept here so that anybody can edit these. So information\n   not to close to any existing implementation that might still be in\n   a process of discussion can be found here.\n\n - /Adopters Wiki/: This can be the place where adopters share their\n   best practises, configurations, hardware recommendations,\n   third-party software documentation etc. Again anyone can contribute\n   to this wiki.\n\nThe difference between the Wiki and Git is in the first line that the\nGit documentation should become a quality assured ressource for\nOpencast users. The Git documentation should be reviewed within the\nrelease process and it will be part of the review process of a pull\nrequest, to make sure that the needed documentation changes have been\ncontributed too.\n\nThe Wikis on the other hand should be a more open platform where\neverybody can contribute and users might find cookbooks to enhance\ntheir system, or they can share ideas.\n\nSo now we would like to get your opinion on this proposal.\n\nThank you,\nR\u00fcdiger\n\n\n\nRequirement Specification\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, Passed on Thu, 16 Apr 2015 15:55:31 UTC\n\n\nOn list or IRC we often see that people do not really know the current\nrequirements for a specific version of Opencast Matterhorn. Of course\nthere are the pom.xml files specifying internal dependencies, but there\nis nothing for 3rd-party-tools, ...\n\nIt would be nice to add a file specifying these requirements in a\nformat that is easy to parse and can hence be used for automatic\nscripts to generate dependency lists, ...\n\nThat is why I hereby #propose to add a requirements.xml file that\nspecifies the requirements for Opencast Matterhorn:\n - Required tools including versions\n - Which modules require which tools\n - Which modules conflict with each other (negative requirement)\n\nThis is mainly what is not specified by the pom.xml files yet.\n\n\n\nJira Clean-Up (Tags VS Labels)\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, Passed on Thu, 19. Mar 2015 15:43:20 UTC\n\n\n\u2026then hereby I officially #propose removing the labels from Jira.\n\n\n\nFor more details, have a look at the mail thread at:\n\n\nhttps://groups.google.com/a/opencast.org/forum/#!topic/matterhorn/vIdWQkZmbdQ\n\n\n\nFFmpeg Update\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, Passed on Sat, 14 Mar 2015 22:12:18 UTC\n\n\nLooking at the FFmpeg project for the last two years, you will notice\nthat they developed a pretty stable release cycle with a release of a\nnew stable version approximately every three month.\n\nTo stop us from having to propose an update again and again, I hereby\npropose the following general rule for our support of FFmpeg:\n\n  A Matterhorn release will oficially support the latest stable\n  version of FFmpeg released at the time the release branch is cut and\n  all other FFmpeg versions with the same major version number released\n  afterwards.\n\nFor example, for Matterhorn 2 this would mean that we will officially\nsupport FFmpeg 2.5.4 and all later 2.x versions like 2.6 which has\nbeen released on the 7th of March or a possible 2.7 onece it is\nreleased. We would, however, not necessarily support an FFmpeg 3 as it\n*might* come with an interface change that *could* break compatibility.\n\nThat obviously does not mean that older versions of FFmpeg just stop\nworking. In fact, most parts of the default Matterhorn configuration\nshould at the moment still work with FFmpeg 1.x but we will not test or\nfix compatibility problems.\n\n\n\nProposal Log\n\n\nProposed by Lars Kiesow \nlkiesow@uos.de\n, Passed on Sat, 14 Mar 2015 16:35:08 UTC\n\n\nIt would be wonderful if we had a central place to look up the proposals\nthat have passed.\n\nThat is why I hereby propose that:\n\n - We create a proposal log in our new documentation containing all\n   proposals that have passed on list.\n\n - A proposal will become effective only after it is written down in\n   that log. That should usually be done by the person who sent out\n   that proposal.\n\nThis will, of course, not affect the existing decision making rules\n(proposal on list, marked with #proposal, lazy consensus after three\ndays, no -1, ...)",
            "title": "Proposal Log"
        },
        {
            "location": "/proposal-log/#opencast-proposals",
            "text": "All important decisions for Opencast have to be made on list. For more details, please have a look at out  documentation\nabout decision making .  The following list contains a list of passed proposals for reference.",
            "title": "Opencast Proposals"
        },
        {
            "location": "/proposal-log/#passed-proposals",
            "text": "",
            "title": "Passed Proposals"
        },
        {
            "location": "/proposal-log/#crowdin-acceptance-policy",
            "text": "Proposed by Greg Logan  gregorydlogan@gmail.com , passed on November 17, 2017  Hi all,\n\nPer the discussion in the meeting today, we need to set a policy regarding what\nis expected of our Crowdin translators prior to joining the translation team.\nMy proposal is that they must write a brief, understandable sentence regarding\nwhy they want to help translate Opencast via the Crowdin UI.  This is an\noptional field in the workflow where they request to be a translator (ie, no new\ntools or fields) which is sometimes filled in, but mostly left blank.  Something\nlike\n\n'I want to help translate $project into [language]'\n\nwould be sufficient.  This filters out the bots, yet is simple enough that\nsomeone with Google translate ought to be able to work something out.  Once this\npasses I will update the Crowdin and Opencast docs regarding the requirements,\nand then we should be good to go.\n\nProposal closes EOD 2017-11-17.",
            "title": "Crowdin Acceptance Policy"
        },
        {
            "location": "/proposal-log/#rename-matterhorn-repository-to-opencast",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , passed on July 13, 2017  Hi everyone,\nI think we have reached a point where people are wondering what the\nhell matterhorn is ;-D\n\nThat is why I #propose to rename our official repository from\nmatterhorn to opencast:\n\nold: https://bitbucket.org/opencast-community/matterhorn/\nnew: https://bitbucket.org/opencast-community/opencast/\n\nThis proposal will end on Thu Jul 13 16:00 CEST 2017\n\nRegards,\nLars",
            "title": "Rename Matterhorn Repository To Opencast"
        },
        {
            "location": "/proposal-log/#criteria-for-inclusion-of-translations",
            "text": "Proposed by Sven Stauber  sven.stauber@switch.ch , passed on April 28, 2017  Dear all,\nThere are currently no rules about the criteria needed for a translation to be\nincluded or excluded from the official Opencast releases.\n\nI hereby propose the following rules:\n\n1.  A not yet supported translation is included into the next major release if\n    it is translated to at least 90% at the time when the release branch is cut.\n    The release managers will take the review if no other reviewer can be found.\n\n2.  A not yet supported translation may be included in the current release\n    branch anytime if it is translated to 100% and a reviewer is found. It will\n    then be part of the next minor release and major release if feasible\n\n3.  An endangered translation is a supported translation that is translated less\n    than 80% at the time when the release branch of the next major release is\n    cut. The release managers will publish a list of endangered languages if any\n\n4.  An endangered translation will be removed with the next major release if it\n    is not saved. The release managers take care of the removal in case no other\n    person will\n\n5.  An endangered translation may be saved by reaching at least 90% translated\n    until at least two weeks before the release date of the next major release\n    and a reviewer is found\n\n6. Considering the percentages of being translated, Crowdin acts as reference\n\n7. Considering the dates of the release cuts of major releases, the respective\n   releases schedules act as reference\n\nBest,\nSven",
            "title": "Criteria For Inclusion Of Translations"
        },
        {
            "location": "/proposal-log/#make-maintenance-releases-easier",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , passed on April 24, 2017  Hi everyone,\nover the last years, I have cut a lot of Opencast maintenance releases.\nThe process is to announce that a release will be cut, create a release\ncandidate and wait 72h without veto to actually release.\n\nI have always sent out the voting mail as required by our release\nprocess and I can always count on the usual response: No reply.\n\nThis is actually not very surprising since for example now for the\n2.3.3 release, people have either already tested the latest state of\nr/2.3.3 or are involved in the next big release already.\n\nIn short this means that we always have a three day waiting period in\nwhich basically nothing happens. That is why I would like to change the\nprocess for *maintenance releases* in the following way:\n\n  A release manager may cut new maintenance releases at any time\n  without prior release candidate.\n  He should openly announce the date for a new release a week before\n  the release or at any earlier point in time.\n\nNote that this will also allow a release manager to release as fast as\npossible if necessary (e.g. security fix) since the announcement is not\nstrictly required but only a strong advise.\n\nThis should lessen the work for the a release managers and will enable\nmore agile release processes. We also should not really loose any QA\nwork since everyone knows when releases will happen and people can\nalways test the latest state of a release branch which will become the\nnew release.\n\nThis proposal will not affect major releases where release candidates\nwith three days testing period would still be required.\n\nI hope you agree with this change,\nLars",
            "title": "Make Maintenance Releases Easier"
        },
        {
            "location": "/proposal-log/#minor-documentation-changes-do-not-require-jira-issues-or-prs",
            "text": "Proposed by Stephen Marquard  stephen.marquard@uct.ac.za , passed on June 9, 2017  To reduce the overhead involved in improving our documentation, I #propose that\nminor fixes to documentation may be committed to either maintenance branches or\ndevelop without requiring a JIRA issue or pull request.\n\nMarkdown docs can be edited directly on bitbucket (and git should we move to\nthat), which is a very fast and convenient way for developers to fix\ndocumentation.\n\nConstraints: documentation fixes committed in this way should be minor changes\nonly; for example fixing typos, layout, formatting, links or small changes to\nexisting content, but no significant new content (which should continue to go\nthrough the usual review process).",
            "title": "Minor documentation changes do not require JIRA issues or PRs"
        },
        {
            "location": "/proposal-log/#requiring-java-18-for-30",
            "text": "Proposed by Greg Logan  gregorydlogan@gmail.com , passed on June 12, 2017  Hi folks,\n\nFor those following along, James Perrin has identified an issue where 3.0\nrequires Java 1.8 at runtime.  We haven't formally included that\nrequirement for 3.0 yet (it's already required for 4.0), but I hereby\npropose that we do.  No one seems to have noticed this requirement was\nalready present in 3.0 (not even me!), even at this late in the release\ncycle which speaks, I think, to the already widespread adoption of Java\n1.8.  We would also have to go back and redo all of our testing were we to\nchange the problematic jar to an earlier version, which would be\nunfortunate for our release timelines.\n\nThis proposal closes EOD 2017-06-12 UTC -6, at which point I should be able\nto cut the release.\n\nG",
            "title": "Requiring Java 1.8 for 3.0"
        },
        {
            "location": "/proposal-log/#officially-declare-the-admin-ui-facade-as-internal-api-for-exclusive-use-by-the-module-matterhorn-adminui-ng",
            "text": "Proposed by Sven Stauber  sven.stauber@switch.ch , passed on December 16, 2016  Dear all,\nI hereby propose to officially declare the Admin UI Facade as internal API for\nexclusive use by the module matterhorn-adminui-ng.\n\nReason:\nThe Admin UI Facade is essentially the backend of the Admin UI.  While it would\nbe technically possible to use this API for other purposes, this would introduce\ndependencies to components other than the Admin UI.\n\nAllowing such dependencies to come into existence would cause changes to the\nAdmin UI Facade to potentially break other (possibly unknown external)\ncomponents.  Hence, we would need to announce, coordinate and discuss changes to\nthis API to not break dependencies to components we potentially don't even know.\nThis would unnecessarily slow down the future development of the Admin UI.  In\naddition, Opencast 2.3 introduces the External API which has been explicitly\ndesigned to meet the requirements of an API used to integrate other components.\n\nChanges needed:\nThe documentation needs to reflect that the Admin UI Facade is an internal API\nthat will be changed without prior announcement whenever needed without\nrespecting dependencies other than the Admin UI itself and therefore people\nshall not use this API for integration purposes.\n\nBest,\nSven",
            "title": "Officially declare the Admin UI Facade as internal API for exclusive use by the module matterhorn-adminui-ng"
        },
        {
            "location": "/proposal-log/#opencast-next-code-cleanup",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , passed on Thu, 7 July 2016 15:21:19 UTC  Hi everyone,\na while ago we discussed on the technical meeting that we would like to\nremove some old code from Opencast since these parts do not work\nproperly (sometimes not at all) or are unused.\n\nWhy cleaning up? To name some reasons:\n\n- Less code to run (less memory, faster start-up)\n- Less things to compile (faster build)\n- Less dependencies\n- People do not accidentally stumble upon broken things\n- Less work for maintenance\n\nAnd now here is what I #propose to remove and a reason why I think this\nshould be removed. I already took the comments people made in the first\ndraft [1] into account, although I still dared to include the two last\nitems but this time, hopefully with a convincing reason for why they\nshould be removed.\n\n1. Old Administrative User Interface (matterhorn-admin-ui)\n   The reason for this should be obvious: We got a new one. The old one\n   has not been tested for the last three releases, is not linked\n   anywhere anymore and is partly buggy due to changes to Opencast. To\n   maintain two interfaces for one thing do not make sense.\n\n2. Hold-state Workflow Operations\n   These do not work with the new interface any longer and the concept\n   has since been replaced by the actions you can perform on archived\n   material.\n\n3. CleanSessionsFilter\n   Old temporary bug fix. For more details read the thread on our\n   developer list.\n\n4. Republish Workflow Operation Handler\n   It can be removed since it has been replaced by a flag on\n   the publish operation in 2.x.\n\n5. Old workflows + encodings\n   We got new ones. These were only left because of the old ui.\n\n6. Old player (Flash in engage ui)\n   Flash is dead. We have the new player and Paella.\n\n7. Most of shared_ressources\n   Almost everything in here belongs to old user interfaces.\n\n8. matterhorn-engage-player\n   This is the old player Flex project. Iam not even sure it can still\n   be compiled.\n\n\n9. matterhorn-test-harness\n   Old integration tests\n\n10. matterhorn-mediapackage-ui\n    Old UI ressources\n\n11. matterhorn-manager-*\n    Old, outdated configuration modification via web ui. This was never\n    used and would need a major update to get it working again at all.\n\n12. matterhorn-load-test*\n    Some tests. I have never seen them executed by anyone.\n\n13. matterhorn-holdstate-workflowoperation\n    Workflow operations requiring a hold state which does not exist\n    anymore with the new admin interface.\n\n14. matterhorn-deprecated-workflowoperation\n    The name says everything. This includes the download DVD operation.\n\n15. matterhorn-annotation-*\n    This should not work with either of the current players anymore.\n\n16. docs/jmeter, docs/scripts/load_testing\n    Configuration for a performance testing tool. Not used for a long\n    time and not up-to-date.\n\n17. Everything unused from:\n    https://data.lkiesow.de/opencast/apidocs/deprecated-list.html\n    E.g. FunctionException and ProcessExecutor(Exception)\n\n18. matterhorn-webconsole\n    Karaf comes with a web console. We do not use our old implementation\n    anymore.\n\n19. matterhorn-mediapackage-manipulator\n    Rest endpoint for media package manipulation. It's not used anymore\n    except by components to be removed.\n\n\n20. matterhorn-search-service-feeds\n    Broken implementation for RSS/Atom feeds\n\n21. matterhorn-caption-* and embed operation\n    Service for converting different subtitle formats and operation to\n    embed these subtitles into the media files. This is *not* player\n    caption support. If required, FFmpeg can be used for conversion\n    between several subtitle formats. Asked on list [2], no one uses\n    this.\n\n\nAs indicated before, points 20 and 21 had some comments for leaving them\nin which did not convince me to not propose this. \u201cInstead of removing\nit, fix it\u201d is an easy thing to say but sadly requires ressources.\nKeeping it, announcing it as features and then tell people that it is\nnot working only afterwards is a bad thing and I would like to avoid\nthat.\n\nNote that all the code is still in our history so that we loose nothing\nif we want the old code back.\n\nPlease feel free to indicate if this action is fine for you or if you\nwant to keep some of the marked code. Please provide a reason if you do.\n\nBest regards,\nLars\n\n[1] http://bit.ly/28YOEZ1\n[2] http://bit.ly/28Ztlt8  This proposal has passed with these additional corrections:  Hi,\nwe discussed this on today's technical meeting and I'm slightly\nchanging the proposal:\n\n20. Let's remove matterhorn-search-service-feeds only after September\n    1st which is a realistic time to get things into the next Opencast\n    release. If someone has fixed the issue by them, we will, of\n    course, keep it.\n    This change takes into account that some people have said they are\n    interested into fixing that module, but will make sure that it's\n    removed if no one fixes it to not have an advertised but broken\n    feature.\n\n21. I will be looking into adding subtitle support in a sensible way\n    before removing the matterhorn-caption-* modules or at least\n    clarify if they can still be used.\n\nRegards,\nLars  Hi James,\na couple of days, I talked to someone saying that he will soon provide\na patch adding exactly this functionality. The holdstate operations are\ndefinitely broken due to their UI.\n\nMy suggestion for a compromise here:\n - Remove them if that patch for archiving the options is released\n - Remove them if no one fixes them in time (September 1st) for 2.3\n\nIf you want to bring them back later, we always keep the code in our\nhistory.\n\nRegards,\nLars\n\n> Hi,\n> I would like to keep 2 and presumably 13. Both Manchester and AFAIK\n> Cape Town have use cases for hold states since there is still no\n> mechanism for passing WF configuration options from one WF to another.\n> Regards\n> James  The patch has  already been published .",
            "title": "Opencast Next: Code Cleanup"
        },
        {
            "location": "/proposal-log/#opencast-community-repository-owners",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , passed on Fri, 13 May 2016 18:41:52 UTC  Hi,\ntoday, in the technical meeting, we shortly discussed how to handle\nrequests, problems, etc regarding the other repositories we are hosting\nunder the umbrella of the Opencast community:\n\n  https://bitbucket.org/opencast-community/profile/repositories\n\nWhile we have people who care about the official Opencast repository as\nwell as rules about what may be merged, who may merge things, \u2026 we do\nnot have that for other repositories and for some it's very unclear.\n\nThat is why I would like to propose that every repository under the\numbrella of the Opencast community needs to have a \u201cproject owner\u201d\nbeing responsible for that repository. Usually it should be the one\nrequesting that repository, but of course it can be someone else known\nin the community.\n\nI would also like to propose that if there is no one willing to take up\nthe responsibility to take care of a repository (ownership) if an old\nowner leaves, the repository should either be removed or marked as\ndeprecated and moved to a separate section if so requested.\n\nFinally, I would like to propose that we use the new \u201cproject\u201d feature\nof BitBucket to group the repositories into the groups:\n\n- Opencast\n- Contrib\n- Adopters\n- Deprecated (<- to be created if needed)\n\nCurrently, all repositories are in one big project.\n\nRegards,\nLars",
            "title": "Opencast Community Repository Owners"
        },
        {
            "location": "/proposal-log/#rename-opencast-mailing-lists",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , passed on Thu, 14 Apr 2016 00:00:00 UTC  Hi everyone,\ntraditionally, we have the three mailing lists:\n\n - matterhorn@opencast.org (development list)\n - matterhorn-users@opencast.org (user list)\n - community@opencast.org (more or less announcements)\n\nRecently, though, we have seen especially the last two list being used\nfor user questions and problems. That is not surprising as we dropped\nthe name \u201cMatterhorn\u201d and new users do not know what that the list\nmatterhorn-users is meant for questions about Opencast.\n\nThat is why I would like to rename these lists to\n\n - dev@opencast.org or development@opencast.org (I prefer the short\n   name but don't have very strong feelings about that)\n - users@opencast.org\n - announcements@opencast.org\n\nTogether with the already existing security-notices list, this gives\nthese lists a very clear meaning. It would also have the benefit that\nusers only interested in general announcements could subscribe to one\nlist only which would likely be a very low-traffic mailing list.\n\nAdditionally, this would make it sufficient to send announcements to\none list, instead of sending it to all three lists.\n\nTo prevent general questions on the announcements list, I suggest we\ngrant posting rights to board members, committers or other people who\nhave or had a role in our community only. I don't think we need to be\ntoo strict here but should make sure that people understand what this\nlist is for.\n\nFinally, for the sake of our current members, I would suggest that we\nforward the mails to the old addresses for at least until the end of\nthe year, if that is possible.\n\nBest regards,\nLars",
            "title": "Rename Opencast Mailing Lists"
        },
        {
            "location": "/proposal-log/#documentation-pull-request-merge-order",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , passed on Thu, 25 Feb 2016 20:52:00 UTC  Hi everyone,\nas discussed in this weeks technical meeting, I hereby #propose to\nallow out-of-order merges of documentation pull requests in the same way\nwe have this exception for bug-fixes.\n\nto be precise, I #propose to change the development process docs for\nreviewing and merging [1] in the following way:\n\n[old]\n\n - Pull requests for bug fixes (t/MH-XXXXX-...) may be reviewed and\n   merged out of order.\n\n[new]\n\n - Pull requests for bug fixes or documentation may be reviewed and\n   merged out of order.\n\nRegards,\nLars\n\n[1] https://docs.opencast.org/develop/developer/reviewing-and-merging/",
            "title": "Documentation Pull Request Merge Order"
        },
        {
            "location": "/proposal-log/#removing-instances-of-print-statements-with-a-style-rule-proposal",
            "text": "Proposed by Greg Logan  gregorydlogan@gmail.com , passed on Wed, 12 Feb 2016 12:00:00 UTC  Hi folks,\n\nI noticed in a recently review that there are still System.out.println\nstatements in use in our codebase.  I was surprised, because thought we had\npreviously implemented a checkstyle rule which would have banned those\nstatements!  I hereby #propose that we implement the changes outlined in\nhttps://opencast.jira.com/browse/MH-11222, and remove these statements in\nfavour of logger statements.  I also propose that we add this rule to the\ncheckstyle ruleset so that we don't have to deal with this again going\nforward.  Proposal closes EOD 2016-02-03.\n\nG",
            "title": "Removing instances of print statements with a style rule #proposal"
        },
        {
            "location": "/proposal-log/#how-to-release-a-new-opencast-version",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , passed on Fri, 14 Aug 2015 12:54:51 UTC  Hi everyone,\nserving as co-release manager for two versions of Opencast, I noticed\nthat our current release process has some aspects of the release defined\nin a way that is more hindering than helpful and I want to #propose a\nslight change to these recommendations.\n\nI hereby #propose:\n\n1. Get rid of the `master` branch, make `develop` the main branch.\n2. Do not use the --no-ff flags for merges\n3. Do not create versions/tags in a release branch. Separate them.\n\n\nReasoning:\n\n1. The short explanation whould be: When did you explicitely checked\n   out `master` last time? People rarely do that. If I want a specific\n   version, I use the tag, if not I want the release branch or\n   `develop`.\n   If you think about it, then the whole reason for `master` in GitFlow\n   is to always provide the last stable version to users who just check\n   out the repository and do nothing else. The problem with Opencast is,\n   that we support multiple versions at the same time. If in a couple\n   of weeks 1.6.2 is being released, it is the latest stable. Is it? If\n   I check out `master`, however, I will still get 2.0 as we cannot\n   merge 1.6.x afterwards. While you can grasp the reasons behind this,\n   it is a bit confusing for users and it is much easier to just tell\n   them to use the tag to check out a specific version.\n   That it, if they do not use the tarballs from BitBucket anyway.\n\n2. First of all, most people seem to be using BitBucket for\n   auto-merging and it does not use --no-ff. So we are not really\n   consistent anyway. Being consistent and using  --no-ff would mean to\n   forbid the usage of the BitBucket merge.\n   Second, have a look at the confusing mess that are the current\n   branches (I tried to find something in the visualization a while ago\n   but gave up). It would be much cleaner to try using fast-forward\n   merges. So instead of using non-fast-forward commits I would argue\n   that we should instead try to use as many fast-forward commits as\n   possible.\n\n3. Once we decided to have the tags in our branches like this:\n\n      ---- A ---- B (tagged) ----- C ---- D -->\n\n   A is the commit containing the version that is decided to be\n   released. B is the tagged version. It is exactly the same code as A\n   except for the pom.xml versions that are modified. Finally C then\n   reverts B as the modified version should not be part of the release\n   branch, .... After C, the code is basically A again except for the\n   history (which we later need to merge which can be problematic). D\n   would then be the next \u201creal\u201d commit, meaning the next fix.\n\n   Much easier to handle would be the following structure:\n\n     ---- A ---- D -->\n           \\\n            B (tagged)\n\n   You do not have to revert that commit, you do not need to merge the\n   easily conflicting pom.xml changes and in the end, you would anyway\n   check out the tag using  git checkout <tag>  if you want that\n   specific version\n\n\nBranching structure:\n\nTo have a complete overview, this is what the new branching structure\nwould look like:\n\n\n  develop --*--*--*--*--*----*--------*--------*---->\n                   \\        /                 /\n            r/x.y.z *--*--*---*--*--*--*--*--*---->\n                           \\                  \\\n                            * x.y.z-beta1      * x.y.z-rc1\n\nRegards,\nLars",
            "title": "How to release a new Opencast version\u2026"
        },
        {
            "location": "/proposal-log/#moving-away-from-the-3rd-party-scripts",
            "text": "Proposed by Greg Logan  gregorydlogan@gmail.com , passed by Fri, 24 Jul 2015 16:45:40 UTC  Hi folks,\n\nAs it stands right now we depend on the 3rd party tool script to\ninstall a great many of our 3rd party dependencies.  These are\nutilities like tesseract, ffmpeg, sox, etc.  This script is maintained\nby Matjaz, in his own time.  I'd like to take a moment to thank him\nfor a doing a great job on a particularly annoying aspect of\nsupporting our work!  I know it hasn't been easy, especially\nsupporting vast number of different OS versions!\n\nWith the release of 2.0 I noticed that our 3rd party tool script is\nbecoming both a little out of date, and difficult to maintain.  I took\na quick look around and it seems like *most* of our dependencies are\navailable from normal distribution repositories for Debian based\nsystems, and I'm told that there is a similar situation for Redhat\nbased systems.  I am unsure of how many of our users are running\nMatterhorn on Mac, but I would hope that our developers who are\nworking on Mac would be able to provide instructions and/or binaries\nfor those users.  The only dependency where there might be a universal\nsticking point is ffmpeg (due to patent concerns), however ffmpeg\nbuilds a full static binary with each release, so I assume we can\neither depend on this and/or cache them somewhere.\n\nWhat this means is that we can potentially remove the 3rd party script\nfrom our repository.  I hereby #propose we find a way to do that,\nwhich would remove the 3rd party script from the repository and\nreplace it with a number of new steps in the install documentation.\n\nG",
            "title": "Moving away from the 3rd party scripts"
        },
        {
            "location": "/proposal-log/#status-of-youtube-in-20-and-proposal-to-change-the-default-workflow",
            "text": "Proposed by R\u00fcdiger Rolf  rrolf@Uni-Osnabrueck.DE , passed on Sat, 13 Jun 2015 14:15:55 UTC  Hi list!\n\nThere was some discussion in the DevOps meeting yesterday if the\nYoutube distribution would work or not. I offered to check this.\n\nThe good news first: IT WORKS!\nJust follow this manual and your Matterhorn - ups Opencast -  is ready\nto distribute to Youtube.\n\n  http://docs.opencast.org/r/2.0.x/admin/modules/youtubepublication/\n\nThe bad news: The default workflow definition does not really support\nthe publishing on Youtube, as only one video file could be published\nby the current WOH.\n\n  https://opencast.jira.com/browse/MH-10920\n\nThe reason is simple and the fix would be too. But there are some\noptions to fix this:\n\n1. Remove the option to distribute to Youtube from the default workflow\n   definition, as the complicated configuration would have to come\n   first anyway.\n2. Only let \"presenter\" or \"presentation\" be published to Youtube. We\n   would need a new youtube tag and add this to the compose operation\n   and the youtube operation.\n3. Introduce the composite operation to the workflow definition and\n   publish only the resulting single stream to Youtube.\n4. Upgrade the WOH to support publishing of multiple files.\n\nI would say that option 4 could be 2.1 goal, but not for 2.0.\n\nI would #propose to go for option 1, as nobody can use Youtube\nout-of-the-box anyway. And the admin could then setup  an appropriate\nYoutube workflow for their needs too.\n\nRegards\nR\u00fcdiger",
            "title": "Status of youtube in 2.0 and #proposal to change the default workflow"
        },
        {
            "location": "/proposal-log/#episode-dublincore-catalog",
            "text": "Proposed by Karen Dolan  kdolan@dce.harvard.edu , Passed on Sat, 30 May 2015 12:39:05 UTC  Dear Opencast-ees,\n\nThe following proposal addresses MH-10821[1]. An issue that exposes a\nknow long time ambiguity regarding metadata and the ingest service.\nThe reason that its a proposal is that it normalizes the handling of\ninbound episode catalog metadata in the ingest service.\n\n\n1) A new configuration parameter, boolean, for the Ingest Service. The\n   config param identifies if episode metadata precedence is for\n   Ingestee (i.e. Opencast system) or the Ingester (i.e. Capture\n   Agent).\n\n   For example: at our site, the scheduling entity is the metadata\n   authority. All updates are made to the Scheduling endpoint. The\n   Capture Agent always has stale episode catalog metadata. At other\n   sites, updates are made on the Capture Agent directly. The\n   community default can be for priority to the Capture Agent.\n\n2) All Ingest endpoints perform the same consistent process to ensure\n   that an episode catalog will exist, manually or automatically\n   provided.\n\n3) The process performs the following...\n\n3.1. Gather data\n\n - Check if inbound media package contain a reference to an Episode\n   DublinCore catalog and if that catalog contains a title.\n - Check if the inbound media package contains a title attribute.\n - Check if the Workflow service has a reference to the mediapackage's\n   Episode Dublin Core catalog\n - Check if the Scheduler service retained a reference to the event's\n   Episode Dublin Core catalog\n\n3.2. Use config param to prioritize action on acquiring an Episode dc\n   catalog for the media package\n\n  If Capture Agent metadata takes precedence:\n     - Take the inbound Episode dc catalog, if it exists\n     - Take the Episode dc catalog from the workflow service, if it\n       exists\n     - Take the Episode dc  catalog from the scheduler service, if it\n       exists\n     - Create an Episode dc catalog from the title in the media\n       package,, if it exists\n     - Create an Episode dc catalog using a default title (i.e.\n       \"Recording-1234556XYZ\")\n\n If Opencast metadata takes precedence:\n     - Take the Episode dc catalog from the workflow service, if it\n       exists\n     - Take the Episode dc  catalog from the scheduler service, if it\n       exists\n     - Take the inbound Episode dc catalog if it exists\n     - Create an Episode dc catalog from the title in the media\n       package, if it exists\n     - Create an Episode dc catalog using a default title (i.e.\n       \"Recording-1234556XYZ\")\n\nI'll start a pull for the above, and appreciate any thoughts.\n\nRegards,\nKaren\n\n[1] https://opencast.jira.com/browse/MH-10821",
            "title": "Episode DublinCore Catalog"
        },
        {
            "location": "/proposal-log/#dropping-taglines",
            "text": "Proposed by  Greg Logan  gregorydlogan@gmail.com , Passed on Fri, 29 May 2015 16:19:09 UTC  Hi folks,\n\nI hereby propose that we drop the practice of having taglines.  I\npropose this because we don't have a place in the new admin UI to put\nthem, nor have I ever heard any of the adopters make use of it.  I know\nwe don't use it as a committing group, which means that *no one* is\nusing them.\n\nG",
            "title": "Dropping Taglines"
        },
        {
            "location": "/proposal-log/#wiki-cleanup",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , Passed on Fri, 24 May 2015 11:36:49 UTC  Hi everyone,\nsince we partly switched to our new documentation [1] I would like to\nmake sure that the old and mostly outdated documentation goes away so\nthat no one stumbles upon that. When I had a look at the wikis we\ncurrently have I noticed that most of our 17(!) wikis have not been\ntouched in years and can probably go away.\n\nHere is a list of our wikis and what I #propose to do with/to them:\n\nKeep (maybe clean-up a bit):\n - Matterhorn Adopter Guides\n - Matterhorn Developer Wiki\n - Opencast Matterhorn D/A/CH\n - Opencast Matterhorn Espa\u00f1ol\n - LectureSight\n\nExport as PDF to archive the contents and then delete:\n - Matterhorn Release Docs - 1.0\n - Matterhorn Release Docs - 1.1\n - Matterhorn Release Docs - 1.2\n - Matterhorn Release Docs - 1.3\n - Matterhorn Release Docs - 1.4\n - Matterhorn Release Docs - 1.5\n - Matterhorn Release Docs - TRUNK\n\nKeep until 2.1 is out then export as PDF and delete:\n - Matterhorn Release Docs - 1.6\n\nJust delete:\n - Analytic video annotation\n - Infra\n - Matterhorn Documents\n - Opencast Community\n\n\nPlease let me know if you agree or disagree with this proposal.\n\nRegards,\nLars\n\n[1] http://documentation.opencast.org",
            "title": "Wiki Cleanup"
        },
        {
            "location": "/proposal-log/#jira-clean-up",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , Passed on Fri, 8 May 2015 11:52:16 UTC  Hi everyone,\nas discussed in the technical meeting, I hereby #propose:\n\n  The \u201cBlocker\u201d and \u201cRelease Blocker\u201d severity status are more or less\n  redundant. As part of cleaning up Jira, let us remove the \u201cRelease\n  Blocker\u201d severity in favor of \u201cBlocker\u201d.\n\nAs footnote, some statistics: Since the beginning of 2014, 70 Release\nBlockers have been files in Jira while mere *8* Blockers have been\nfiles.\n\nRegards,\nLars",
            "title": "Jira Clean-Up"
        },
        {
            "location": "/proposal-log/#opencast-documentation",
            "text": "Proposed by R\u00fcdiger Rolf  rrolf@uni-osnabrueck.de , Passed on Sat, 02 May 2015 14:43:28 UTC  Hi all,\n\nTobias, Basil, Lars and I discussed status of the current migration of\nthe Opencast (Matterhorn) documentation to GIT. We still see some open\nissues that need clarification so we would like to propose the\nfollowing points:\n\n*1. Formating and Hosting of the Documentation *\n\nWe want to use https://readthedocs.org to or a similar service create\na more appealing HTML version from the Markdown of the documentation.\n\nThe documentation will be versioned there so that for older versions\nthe documentation is still available. By default the \"latest\" version\nis shown.  The versions of the documenation will be generated based on\nthe release branches.\n\n*2. Structure of the Documentation*\n\nWe see the documentation in*Git *separating into 3 sections:\n\n - /Administration Guide/: with information about the installation,\n   configuration, customization and integration. This will be the part\n   of information by an administrator to setup\n   Opencast.\n\n - /Developer Guide/: All information related to implementation\n   details of Opencast, so that this will be updated in a pull request\n   (API changes, module descriptions, architecture). The development\n   process documents should also go here as only committers usually\n   should change these.\n\n - /User Guide/: Documentation of the (new) Admin UI that was already\n   started by Entwine and the Engage UI (especially Theodul Player).\n   This guide should only describe options available on the UIs.\n\nWithin the *Wiki* we still see the need for 2 sections:\n\n - /Developer Wiki/: Proposals, working documents and meeting notes\n   will be kept here so that anybody can edit these. So information\n   not to close to any existing implementation that might still be in\n   a process of discussion can be found here.\n\n - /Adopters Wiki/: This can be the place where adopters share their\n   best practises, configurations, hardware recommendations,\n   third-party software documentation etc. Again anyone can contribute\n   to this wiki.\n\nThe difference between the Wiki and Git is in the first line that the\nGit documentation should become a quality assured ressource for\nOpencast users. The Git documentation should be reviewed within the\nrelease process and it will be part of the review process of a pull\nrequest, to make sure that the needed documentation changes have been\ncontributed too.\n\nThe Wikis on the other hand should be a more open platform where\neverybody can contribute and users might find cookbooks to enhance\ntheir system, or they can share ideas.\n\nSo now we would like to get your opinion on this proposal.\n\nThank you,\nR\u00fcdiger",
            "title": "Opencast Documentation"
        },
        {
            "location": "/proposal-log/#requirement-specification",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , Passed on Thu, 16 Apr 2015 15:55:31 UTC  On list or IRC we often see that people do not really know the current\nrequirements for a specific version of Opencast Matterhorn. Of course\nthere are the pom.xml files specifying internal dependencies, but there\nis nothing for 3rd-party-tools, ...\n\nIt would be nice to add a file specifying these requirements in a\nformat that is easy to parse and can hence be used for automatic\nscripts to generate dependency lists, ...\n\nThat is why I hereby #propose to add a requirements.xml file that\nspecifies the requirements for Opencast Matterhorn:\n - Required tools including versions\n - Which modules require which tools\n - Which modules conflict with each other (negative requirement)\n\nThis is mainly what is not specified by the pom.xml files yet.",
            "title": "Requirement Specification"
        },
        {
            "location": "/proposal-log/#jira-clean-up-tags-vs-labels",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , Passed on Thu, 19. Mar 2015 15:43:20 UTC  \u2026then hereby I officially #propose removing the labels from Jira.  For more details, have a look at the mail thread at:  https://groups.google.com/a/opencast.org/forum/#!topic/matterhorn/vIdWQkZmbdQ",
            "title": "Jira Clean-Up (Tags VS Labels)"
        },
        {
            "location": "/proposal-log/#ffmpeg-update",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , Passed on Sat, 14 Mar 2015 22:12:18 UTC  Looking at the FFmpeg project for the last two years, you will notice\nthat they developed a pretty stable release cycle with a release of a\nnew stable version approximately every three month.\n\nTo stop us from having to propose an update again and again, I hereby\npropose the following general rule for our support of FFmpeg:\n\n  A Matterhorn release will oficially support the latest stable\n  version of FFmpeg released at the time the release branch is cut and\n  all other FFmpeg versions with the same major version number released\n  afterwards.\n\nFor example, for Matterhorn 2 this would mean that we will officially\nsupport FFmpeg 2.5.4 and all later 2.x versions like 2.6 which has\nbeen released on the 7th of March or a possible 2.7 onece it is\nreleased. We would, however, not necessarily support an FFmpeg 3 as it\n*might* come with an interface change that *could* break compatibility.\n\nThat obviously does not mean that older versions of FFmpeg just stop\nworking. In fact, most parts of the default Matterhorn configuration\nshould at the moment still work with FFmpeg 1.x but we will not test or\nfix compatibility problems.",
            "title": "FFmpeg Update"
        },
        {
            "location": "/proposal-log/#proposal-log",
            "text": "Proposed by Lars Kiesow  lkiesow@uos.de , Passed on Sat, 14 Mar 2015 16:35:08 UTC  It would be wonderful if we had a central place to look up the proposals\nthat have passed.\n\nThat is why I hereby propose that:\n\n - We create a proposal log in our new documentation containing all\n   proposals that have passed on list.\n\n - A proposal will become effective only after it is written down in\n   that log. That should usually be done by the person who sent out\n   that proposal.\n\nThis will, of course, not affect the existing decision making rules\n(proposal on list, marked with #proposal, lazy consensus after three\ndays, no -1, ...)",
            "title": "Proposal Log"
        },
        {
            "location": "/asset-manager/",
            "text": "Architecture\n\n\nModules\n\n\nThe AssetManager consists of the following modules:\n\n\n\n\nmatterhorn-asset-manager-api\n\nAn API module defining the core AssetManager functions, properties and the query language.\n\n\nmatterhorn-asset-manager-impl\n\nThe default implementation of the AssetManager as an OSGi service, containing the storage API for pluggable asset stores.\n\n\nmatterhorn-asset-manager-storage-fs\n\nThe default  implementation of the AssetStore. Depends on matterhorn-asset-manager-impl.\n\n\nmatterhorn-asset-manager-util\n\nAdditional functionality for the AssetManager providing utilities such as starting workflows on archived snapshots, etc.\n\n\nmatterhorn-asset-manager-workflowoperation\n\nA workflow operation handler to take media package snapshots of a media package from inside a running workflow.\n\n\n\n\nHigh Level View\n\n\nTODO Describes components and how they relate.\n\n\nClasses\n\n\nTODO Most important classes and how they relate\n\n\nDefault Implementation\n\n\nAssetStore\n\n\nAssets are stored in the following directory structure.\n\n\n$BASE_PATH\n |\u2014 <organization_id>\n     |\u2014 <media_package_id>\n         |\u2014 <version>\n             |\u2014 manifest.xml\n             |\u2014 <media_package_element_id>.<ext>\n\n\n\nDatabase\n\n\nThe asset manager uses four tables\n\n\n\n\nmh_assets_snapshot\n\n  Manages snapshots. Each snapshot may be linked to zero or more assets.\n\n\nmh_assets_asset\n\n  Manages the assets of a snapshot.\n\n\nmh_assets_properties\n\n  Manages the properties. This table is indirectly linked to the snapshot table via column \nmediapackage_id\n. \n\n\nmh_assets_version_claim\n\n  Manages the next free version number per episode. \n\n\n\n\nSecurity\n\n\nTODO\n\n\nUsage\n\n\nTaking Snapshots\n\n\nTODO\n\n\nWorking with Properties\n\n\nProperties are associated with an episode, not a single snapshot. \nThey act as annotations helping services to work with saved media packages without having to implement their own storage layer. \nProperties are typed and can be used to create queries.\n\n\nGetting Started\n\n\nLet's start with an fictious example of an ApprovalService.\nThe approval service keeps track of approvals given by an editor to publish a media package. \nOnly approved media packages may be published and the editor should also be able to leave a comment defining a publication as prohibited. \nHere, three properties are needed, an approval flag, a text field for comments and a time stamp for the date of approval.\nThe following code snippet sets a property on an episode, \nwith am referring to the AssetManager and mp the media package id of type String of the episode.\n\n\nAssetManager am = \u2026;\nString mp = \u2026; // a media package id\nam.setProperty(Property.mk(PropertyId.mk(\n  mp, \"org.opencastproject.approval\", \"approval\"),\n  Value.mk(true)));\n\n\n\nIt is recommended to use namespace names after the service's package name, in the example: \norg.opencastproject.approval\n.\nThis code looks overly verbose. Also you need to deal with namespace names and property names directly. \nThat's cumbersome and error prone even though you might intoduce constants for them. \nTo help remedy this situation a little helper class class \nPropertySchema\n exists. \nIt is strongly recommended to make use of it. Here's how it goes.\n\n\nstatic class ApprovalPops extends PropertySchema {\n public ApprovalProps(AQueryBuilder q) {\n   super(q, \"org.opencastproject.approval\");\n }\n\n public PropertyField<Boolean> approved() {\n   return booleanProp(\"approved\");\n }\n\n public PropertyField<String> comment() {\n   return stringProp(\"comment\");\n }\n\n public PropertyField<Date> date() {\n   return dateProp(\"date\");\n }\n}\n\n\n\nNow you can set properties like this.\n\n\nam.setProperty(p.approved().mk(mp, false));\nam.setProperty(p.comment().mk(mp, \"Audio quality is too poor!\"));\nam.setProperty(p.date().mk(mp, new Date());\n\n\n\nNow, if you want to find all episodes that have been rejected you need to create and run the following query.\n\n\nAQueryBuilder q = am.createQuery();\nAResult r = q.select(q.snapshot()).where(p.approved().eq(true)).run();\n\n\n\nThis query yields all snapshots of all episodes that have been approved. \nBut that's not exactly what we want as we are only interested in the latest snapshot generated when we re-run the approval process, \nand resetting all previous approvals.\n\n\nq.select(q.snapshot())\n  .where(p.approved().eq(true).and(q.version().isLatest())\n  .run();\n\n\n\nThis will only return the latest version of each episode. \nHowever, along with the information of the approved  episodes,we want to display when they were approved. \nLooking at the AResult and ARecord interfaces it seems that properties need to be selected in order to fetch them.\n\n\nq.select(q.snapshot(), q.properties())\n  .where(p.approved().eq(true).and(q.version().isLatest())\n  .run();\n\n\n\nHere we go. Now we can access all properties stored with the returned snapshots.\nNow, let's assume other services make heavy use of properties too. \nThis may cause serious database IO if we always select all properties like we did using the q.properties() target. \nLet's do better.\n\n\nq.select(q.snapshot(), q.propertiesOf(\"org.opencastproject.approval\"))\n  .where(p.approved().eq(true).and(q.version().isLatest())\n  .run();\n\n\n\nThis will return only the properties of our service's namespace. But do we have to deal with namespace strings again? No.\n\n\nq.select(q.snapshot(), q.propertiesOf(p.allProperties()))\n  .where(p.approved().eq(true).and(q.version().isLatest())\n  .run();\n\n\n\nOur implementation of \nPropertySchema\n provides as with a ready to use target for the properties of our namespace only. \nIn our use case we could reduce IO even further since we're only interested in the date property.\n\n\nq.select(q.snapshot(), q.propertiesOf(p.date().target()))\n  .where(p.approved().eq(true).and(q.version().isLatest())\n  .run();\n\n\n\nThis is the query returns only the latest snapshots of all episodes being approved together with the date of approval. \nNow that you've seen how to create properties let's move on to delete them again.\n\n\nDeleting Properties\n\n\nProperties are deleted pretty much like they are queried, using a delete query.\n\n\nq.delete(q.propertiesOf(p.allProperties())).run();\n\n\n\nThe above query deletes all properties that belong to schema p from all episodes. If you want to restrict deletion to a single episode, add an id predicate to the where clause.\n\n\nq.delete(q.propertiesOf(p.allProperties()))\n  .where(q.mediaPackageId(mpId))\n  .run();\n\n\n\nDeleting just a single property from all episodes is also possible.\n\n\nq.delete(p.approved()).run();\n\n\n\nOr multiple properties at once.\n\n\nq.delete(p.approved(), p.comment()).run();\n\n\n\nPlease see the query API documentation for further information.\n\n\nValue Types\n\n\nThe following type are available for properties:\n\n\n\n\nLong\n\n\nString\n\n\nDate\n\n\nBoolean\n\n\nVersion\n\n  Version is the AssetManager type that abstracts a snapshot version.\n\n\n\n\nDecomposing properties\n\n\nSince properties are type safe they cannot be accessed directly. \nIf you know the type of the property you can access its value using a type evidence constant.\n\n\nString string = p.getValue().get(Value.STRING);\nBoolean bool = p.getValue().get(Value.BOOLEAN);\n\n\n\nType evidence constants are defined in class \nValue\n.\nIf the type is unknown since you are iterating a mixed collection of values, for example if you need to decompose the value.\nDecomposition is the act of pattern matching against the value's type. Each case is handled by a different function, \nall returning the same type. Let's say you are iterating over a collection of values and want to print them, formatted, to the console. \nAll \nhandle*\n parameters are functions of type \nFn\n taking the raw value as input and returning a String.\n\n\nList<Value> vs = \u2026;\nfor (Value v : vs) {\n  String f = v.decompose(\n    handleStringFn,\n    handleDateFn,\n    handleLongFn,\n    handleBooleanFn,\n    handleVersionFn);       \n  System.out.println(f);\n}\n\n\n\nThe class \norg.opencastproject.assetmanager.api.fn.Properties\n contains various utility functions to help extracting values from properties.\n\n\nUsing PropertySchema\n\n\nYou've already seen that a property is constructed from a media package id, a namespace, a property name and a value. \nSince this is a bit cumbersome, the API features an abstract base class to construct property schemas. \nThe resulting schema implementations encapsulate all the string constants so that you don't have to deal with them manually. \nPlease see the example in the \nGetting Started\n section. It is strongly recommended to work with schemas as much as possible.\n\n\nCreating and Running Queries\n\n\nCreating and running a query is a two step process. First, you create a new \nAQueryBuilder\n.\n\n\nAQueryBuilder q = am.createQuery();\n\n\n\nNext, you build a query like this.\n\n\nASelectQuery s = q.select(q.snapshot())\n  .where(q.mediaPackageId(mpId).and(q.version().isLatest());\n\n\n\nNow it's time to actually run the query against the database.\n\n\nAResult r = s.run();\n\n\n\nAll this can, of course, be done in a single statement, but it has been broken up in several steps  to show you the intermediate types.\n\n\nam.createQuery()\n  .select(q.snapshot())\n  .where(q.mediaPackageId(mpId).and(q.version().isLatest())\n  .run();\n\n\n\nThe result set \nr\n contains the retrieved data encapsulated in stream of \nARecord\n objects. \nIf nothing matched the given predicates then a call to r.getRecords() yields an empty stream.\nPlease note that even though a \nStream\n is returned, it does not mean that the result set is actually streamed\u2014or lazily \nloaded\u2014from the database. The \nStream\n interface is just far more powerful than the collection types from JCL.\n\n\nA note on immutability\n\n\nPlease note that all classes of the query API are immutable and therefore safe to be used in a concurrent environment. \nWhenever you call a factory method on an instance of one of the query classes a new instance is yielded. They never mutate state.\n\n\nAccessing Query Results\n\n\nRunning a query yields an object of type \nAResult\n which in turn yields the found result records. \nBesides it also provides some general result metadata like the set limit, offset etc.\nAn \nARecord\n holds the found snapshots and properties, depending on the select targets and the predicates. \nIf no snapshots have been selected then, none will be returned here. The same holds true for properties. \nHowever, an \nARecord\n instance holding the media package id is created regardless of the requested targets.\nThe typical pattern to access query results is to iterate over the stream of records. \nThis can be accomplished using a simple for loop or one of the functional methods that the \nStream\n type provides, \ne.g. map over the elements of a stream to create a new one.\nFor easy access to fetched resources you may wrap the result in an enrichment.\n\n\nAResult r = \u2026;\nRichAResult rr = Enrichments.enrich(r);\n\n\n\nRichAResult\n features methods to directly access all fetched snapshots and properties.\n\n\nDeleting Snapshots\n\n\nThis works exactly like deleting properties, except that you need to specify snapshots instead of properties. \nPlease note that it's also possible to specify snapshots and properties simultanously.\n\n\nq.delete(\"owner\", q.snapshot()).where(q.version().isLatest().not()).run();\n\n\n\nThe above query deletes all snapshots but the latest. This is a good query to free up some disc space.\n\n\nSnapshots can only be deleted per owner.\n\n\nQuery Language Reference\n\n\nThe query API features\n\n\n\n\nselect clause and targets\n\n\nwhere clause with boolean and relational operations, nesting of boolean operations\n\n\nselecting by properties\n\n\norder-by clause\n\n\nquerying and deleting\n\n\n\n\nPlease see the API doc for further information about the various elements and how to create them.",
            "title": "Asset Manager"
        },
        {
            "location": "/asset-manager/#architecture",
            "text": "",
            "title": "Architecture"
        },
        {
            "location": "/asset-manager/#modules",
            "text": "The AssetManager consists of the following modules:   matterhorn-asset-manager-api \nAn API module defining the core AssetManager functions, properties and the query language.  matterhorn-asset-manager-impl \nThe default implementation of the AssetManager as an OSGi service, containing the storage API for pluggable asset stores.  matterhorn-asset-manager-storage-fs \nThe default  implementation of the AssetStore. Depends on matterhorn-asset-manager-impl.  matterhorn-asset-manager-util \nAdditional functionality for the AssetManager providing utilities such as starting workflows on archived snapshots, etc.  matterhorn-asset-manager-workflowoperation \nA workflow operation handler to take media package snapshots of a media package from inside a running workflow.",
            "title": "Modules"
        },
        {
            "location": "/asset-manager/#high-level-view",
            "text": "TODO Describes components and how they relate.",
            "title": "High Level View"
        },
        {
            "location": "/asset-manager/#classes",
            "text": "TODO Most important classes and how they relate",
            "title": "Classes"
        },
        {
            "location": "/asset-manager/#default-implementation",
            "text": "",
            "title": "Default Implementation"
        },
        {
            "location": "/asset-manager/#assetstore",
            "text": "Assets are stored in the following directory structure.  $BASE_PATH\n |\u2014 <organization_id>\n     |\u2014 <media_package_id>\n         |\u2014 <version>\n             |\u2014 manifest.xml\n             |\u2014 <media_package_element_id>.<ext>",
            "title": "AssetStore"
        },
        {
            "location": "/asset-manager/#database",
            "text": "The asset manager uses four tables   mh_assets_snapshot \n  Manages snapshots. Each snapshot may be linked to zero or more assets.  mh_assets_asset \n  Manages the assets of a snapshot.  mh_assets_properties \n  Manages the properties. This table is indirectly linked to the snapshot table via column  mediapackage_id .   mh_assets_version_claim \n  Manages the next free version number per episode.",
            "title": "Database"
        },
        {
            "location": "/asset-manager/#security",
            "text": "TODO",
            "title": "Security"
        },
        {
            "location": "/asset-manager/#usage",
            "text": "",
            "title": "Usage"
        },
        {
            "location": "/asset-manager/#taking-snapshots",
            "text": "TODO",
            "title": "Taking Snapshots"
        },
        {
            "location": "/asset-manager/#working-with-properties",
            "text": "Properties are associated with an episode, not a single snapshot. \nThey act as annotations helping services to work with saved media packages without having to implement their own storage layer. \nProperties are typed and can be used to create queries.",
            "title": "Working with Properties"
        },
        {
            "location": "/asset-manager/#getting-started",
            "text": "Let's start with an fictious example of an ApprovalService.\nThe approval service keeps track of approvals given by an editor to publish a media package. \nOnly approved media packages may be published and the editor should also be able to leave a comment defining a publication as prohibited. \nHere, three properties are needed, an approval flag, a text field for comments and a time stamp for the date of approval.\nThe following code snippet sets a property on an episode, \nwith am referring to the AssetManager and mp the media package id of type String of the episode.  AssetManager am = \u2026;\nString mp = \u2026; // a media package id\nam.setProperty(Property.mk(PropertyId.mk(\n  mp, \"org.opencastproject.approval\", \"approval\"),\n  Value.mk(true)));  It is recommended to use namespace names after the service's package name, in the example:  org.opencastproject.approval .\nThis code looks overly verbose. Also you need to deal with namespace names and property names directly. \nThat's cumbersome and error prone even though you might intoduce constants for them. \nTo help remedy this situation a little helper class class  PropertySchema  exists. \nIt is strongly recommended to make use of it. Here's how it goes.  static class ApprovalPops extends PropertySchema {\n public ApprovalProps(AQueryBuilder q) {\n   super(q, \"org.opencastproject.approval\");\n }\n\n public PropertyField<Boolean> approved() {\n   return booleanProp(\"approved\");\n }\n\n public PropertyField<String> comment() {\n   return stringProp(\"comment\");\n }\n\n public PropertyField<Date> date() {\n   return dateProp(\"date\");\n }\n}  Now you can set properties like this.  am.setProperty(p.approved().mk(mp, false));\nam.setProperty(p.comment().mk(mp, \"Audio quality is too poor!\"));\nam.setProperty(p.date().mk(mp, new Date());  Now, if you want to find all episodes that have been rejected you need to create and run the following query.  AQueryBuilder q = am.createQuery();\nAResult r = q.select(q.snapshot()).where(p.approved().eq(true)).run();  This query yields all snapshots of all episodes that have been approved. \nBut that's not exactly what we want as we are only interested in the latest snapshot generated when we re-run the approval process, \nand resetting all previous approvals.  q.select(q.snapshot())\n  .where(p.approved().eq(true).and(q.version().isLatest())\n  .run();  This will only return the latest version of each episode. \nHowever, along with the information of the approved  episodes,we want to display when they were approved. \nLooking at the AResult and ARecord interfaces it seems that properties need to be selected in order to fetch them.  q.select(q.snapshot(), q.properties())\n  .where(p.approved().eq(true).and(q.version().isLatest())\n  .run();  Here we go. Now we can access all properties stored with the returned snapshots.\nNow, let's assume other services make heavy use of properties too. \nThis may cause serious database IO if we always select all properties like we did using the q.properties() target. \nLet's do better.  q.select(q.snapshot(), q.propertiesOf(\"org.opencastproject.approval\"))\n  .where(p.approved().eq(true).and(q.version().isLatest())\n  .run();  This will return only the properties of our service's namespace. But do we have to deal with namespace strings again? No.  q.select(q.snapshot(), q.propertiesOf(p.allProperties()))\n  .where(p.approved().eq(true).and(q.version().isLatest())\n  .run();  Our implementation of  PropertySchema  provides as with a ready to use target for the properties of our namespace only. \nIn our use case we could reduce IO even further since we're only interested in the date property.  q.select(q.snapshot(), q.propertiesOf(p.date().target()))\n  .where(p.approved().eq(true).and(q.version().isLatest())\n  .run();  This is the query returns only the latest snapshots of all episodes being approved together with the date of approval. \nNow that you've seen how to create properties let's move on to delete them again.",
            "title": "Getting Started"
        },
        {
            "location": "/asset-manager/#deleting-properties",
            "text": "Properties are deleted pretty much like they are queried, using a delete query.  q.delete(q.propertiesOf(p.allProperties())).run();  The above query deletes all properties that belong to schema p from all episodes. If you want to restrict deletion to a single episode, add an id predicate to the where clause.  q.delete(q.propertiesOf(p.allProperties()))\n  .where(q.mediaPackageId(mpId))\n  .run();  Deleting just a single property from all episodes is also possible.  q.delete(p.approved()).run();  Or multiple properties at once.  q.delete(p.approved(), p.comment()).run();  Please see the query API documentation for further information.",
            "title": "Deleting Properties"
        },
        {
            "location": "/asset-manager/#value-types",
            "text": "The following type are available for properties:   Long  String  Date  Boolean  Version \n  Version is the AssetManager type that abstracts a snapshot version.",
            "title": "Value Types"
        },
        {
            "location": "/asset-manager/#decomposing-properties",
            "text": "Since properties are type safe they cannot be accessed directly. \nIf you know the type of the property you can access its value using a type evidence constant.  String string = p.getValue().get(Value.STRING);\nBoolean bool = p.getValue().get(Value.BOOLEAN);  Type evidence constants are defined in class  Value .\nIf the type is unknown since you are iterating a mixed collection of values, for example if you need to decompose the value.\nDecomposition is the act of pattern matching against the value's type. Each case is handled by a different function, \nall returning the same type. Let's say you are iterating over a collection of values and want to print them, formatted, to the console. \nAll  handle*  parameters are functions of type  Fn  taking the raw value as input and returning a String.  List<Value> vs = \u2026;\nfor (Value v : vs) {\n  String f = v.decompose(\n    handleStringFn,\n    handleDateFn,\n    handleLongFn,\n    handleBooleanFn,\n    handleVersionFn);       \n  System.out.println(f);\n}  The class  org.opencastproject.assetmanager.api.fn.Properties  contains various utility functions to help extracting values from properties.",
            "title": "Decomposing properties"
        },
        {
            "location": "/asset-manager/#using-propertyschema",
            "text": "You've already seen that a property is constructed from a media package id, a namespace, a property name and a value. \nSince this is a bit cumbersome, the API features an abstract base class to construct property schemas. \nThe resulting schema implementations encapsulate all the string constants so that you don't have to deal with them manually. \nPlease see the example in the  Getting Started  section. It is strongly recommended to work with schemas as much as possible.",
            "title": "Using PropertySchema"
        },
        {
            "location": "/asset-manager/#creating-and-running-queries",
            "text": "Creating and running a query is a two step process. First, you create a new  AQueryBuilder .  AQueryBuilder q = am.createQuery();  Next, you build a query like this.  ASelectQuery s = q.select(q.snapshot())\n  .where(q.mediaPackageId(mpId).and(q.version().isLatest());  Now it's time to actually run the query against the database.  AResult r = s.run();  All this can, of course, be done in a single statement, but it has been broken up in several steps  to show you the intermediate types.  am.createQuery()\n  .select(q.snapshot())\n  .where(q.mediaPackageId(mpId).and(q.version().isLatest())\n  .run();  The result set  r  contains the retrieved data encapsulated in stream of  ARecord  objects. \nIf nothing matched the given predicates then a call to r.getRecords() yields an empty stream.\nPlease note that even though a  Stream  is returned, it does not mean that the result set is actually streamed\u2014or lazily \nloaded\u2014from the database. The  Stream  interface is just far more powerful than the collection types from JCL.",
            "title": "Creating and Running Queries"
        },
        {
            "location": "/asset-manager/#a-note-on-immutability",
            "text": "Please note that all classes of the query API are immutable and therefore safe to be used in a concurrent environment. \nWhenever you call a factory method on an instance of one of the query classes a new instance is yielded. They never mutate state.",
            "title": "A note on immutability"
        },
        {
            "location": "/asset-manager/#accessing-query-results",
            "text": "Running a query yields an object of type  AResult  which in turn yields the found result records. \nBesides it also provides some general result metadata like the set limit, offset etc.\nAn  ARecord  holds the found snapshots and properties, depending on the select targets and the predicates. \nIf no snapshots have been selected then, none will be returned here. The same holds true for properties. \nHowever, an  ARecord  instance holding the media package id is created regardless of the requested targets.\nThe typical pattern to access query results is to iterate over the stream of records. \nThis can be accomplished using a simple for loop or one of the functional methods that the  Stream  type provides, \ne.g. map over the elements of a stream to create a new one.\nFor easy access to fetched resources you may wrap the result in an enrichment.  AResult r = \u2026;\nRichAResult rr = Enrichments.enrich(r);  RichAResult  features methods to directly access all fetched snapshots and properties.",
            "title": "Accessing Query Results"
        },
        {
            "location": "/asset-manager/#deleting-snapshots",
            "text": "This works exactly like deleting properties, except that you need to specify snapshots instead of properties. \nPlease note that it's also possible to specify snapshots and properties simultanously.  q.delete(\"owner\", q.snapshot()).where(q.version().isLatest().not()).run();  The above query deletes all snapshots but the latest. This is a good query to free up some disc space.  Snapshots can only be deleted per owner.",
            "title": "Deleting Snapshots"
        },
        {
            "location": "/asset-manager/#query-language-reference",
            "text": "The query API features   select clause and targets  where clause with boolean and relational operations, nesting of boolean operations  selecting by properties  order-by clause  querying and deleting   Please see the API doc for further information about the various elements and how to create them.",
            "title": "Query Language Reference"
        },
        {
            "location": "/scheduler/",
            "text": "Scheduler\n\n\nModules\n\n\nThe scheduler service consists of the following modules:\n\n\n\n\nmatterhorn-scheduler-api\n\nAn API module defining the core scheduler functions and properties.\n\n\nmatterhorn-scheduler-impl\n\nThe default implementation of the scheduler service as an OSGi service using the AssetManager as it's backend storage.\n\n\nmatterhorn-scheduler-remote\n\nThe remote implementation of the scheduler service as an OSGi service.\n\n\nmatterhorn-scheduler-conflict-handler\n\nThe default implementation of a conflict handler strategy.\n\n\nmatterhorn-scheduler-conflict-notifier-comment\n\nA conflict notifier implementation adding comments on the conflicting events.\n\n\nmatterhorn-scheduler-conflict-notifier-email\n\nA conflict notifier implementation sending an email including all conflicting events.\n\n\n\n\nDatabase\n\n\nThe scheduler service uses three tables:\n\n\n\n\nmh_scheduled_extended_event\n\n  Manages extended scheduled event metadata. Not used yet.\n\n\nmh_scheduled_last_modified\n\n  Manages the last recording modification date of a status change on an event sent by the capture agent.\n\n\nmh_scheduled_transaction\n\n  Manages the active transactions.\n\n\n\n\nConflict Handler\n\n\nThe conflict handler implements a strategy to resolve conflicts by either using the new or the old schedule according the\nconfiguration.\n\n\nConflict Notifier\n\n\nThere are two implementations of a conflict notifier available and activated by default.\n\n\n\n\nThe \nEmail conflict notifier\n will send an email including all conflicting events to a configured recipient.\n\n\nThe \nComment conflict notifier\n will add a comment on the conflicting event describing the conflict.\n\n\n\n\nDefault API\n\n\nHere is a sample to create a single event with the scheduler Java API.\n\n\n  public void createEvent(Event event) {\n    schedulerService.addEvent(event.getStart(),\n                              event.getEnd(),\n                              event.getAgentId(),\n                              event.getUsers(),\n                              event.getMediaPackage(),\n                              event.getWfProperties(),\n                              event.getCaMetadata(),\n                              event.getOptOut(),\n                              event.getSource(),\n                              \"organization-xyz-script\";\n  }\n\n\n\nTransactional API\n\n\nHere is a simplified code example of how to use the Scheduler Java API to synchronize timetable events to scheduled\nevents. It is mandatory that the media package identifier is stable for the created events of the timetable system.\n\n\n  public void syncTimeTable(List<Event> timeTableEvents) {\n    SchedulerTransaction tx = null;\n    try {\n      logger.info(\"Sync timetable to scheduler | start\");\n      tx = schedulerService.createTransaction(\"timetable\");\n      for (Event event : timeTableEvents) {\n        tx.addEvent(\n                event.getStart(),\n                event.getEnd(),\n                event.getAgentId(),\n                event.getUsers(),\n                event.getMediaPackage(),\n                event.getWfProperties(),\n                event.getCaMetadata(),\n                event.getOptOut());\n      }\n      tx.commit();\n      logger.info(\"Sync timetable to scheduler | end\");\n    } catch (Exception e) {\n      logger.error(\"Sync timetable to scheduler | error\\n{}\", e);\n      if (tx != null) {\n        logger.error(\"Sync timetable to scheduler | rollback transaction\");\n        try {\n          tx.rollback();\n        } catch (Exception e2) {\n          logger.error(\"Sync timetable to scheduler | error doing rollback\\n{}\", e2);\n        }\n      }\n    }\n  }",
            "title": "Scheduler"
        },
        {
            "location": "/scheduler/#scheduler",
            "text": "",
            "title": "Scheduler"
        },
        {
            "location": "/scheduler/#modules",
            "text": "The scheduler service consists of the following modules:   matterhorn-scheduler-api \nAn API module defining the core scheduler functions and properties.  matterhorn-scheduler-impl \nThe default implementation of the scheduler service as an OSGi service using the AssetManager as it's backend storage.  matterhorn-scheduler-remote \nThe remote implementation of the scheduler service as an OSGi service.  matterhorn-scheduler-conflict-handler \nThe default implementation of a conflict handler strategy.  matterhorn-scheduler-conflict-notifier-comment \nA conflict notifier implementation adding comments on the conflicting events.  matterhorn-scheduler-conflict-notifier-email \nA conflict notifier implementation sending an email including all conflicting events.",
            "title": "Modules"
        },
        {
            "location": "/scheduler/#database",
            "text": "The scheduler service uses three tables:   mh_scheduled_extended_event \n  Manages extended scheduled event metadata. Not used yet.  mh_scheduled_last_modified \n  Manages the last recording modification date of a status change on an event sent by the capture agent.  mh_scheduled_transaction \n  Manages the active transactions.",
            "title": "Database"
        },
        {
            "location": "/scheduler/#conflict-handler",
            "text": "The conflict handler implements a strategy to resolve conflicts by either using the new or the old schedule according the\nconfiguration.",
            "title": "Conflict Handler"
        },
        {
            "location": "/scheduler/#conflict-notifier",
            "text": "There are two implementations of a conflict notifier available and activated by default.   The  Email conflict notifier  will send an email including all conflicting events to a configured recipient.  The  Comment conflict notifier  will add a comment on the conflicting event describing the conflict.",
            "title": "Conflict Notifier"
        },
        {
            "location": "/scheduler/#default-api",
            "text": "Here is a sample to create a single event with the scheduler Java API.    public void createEvent(Event event) {\n    schedulerService.addEvent(event.getStart(),\n                              event.getEnd(),\n                              event.getAgentId(),\n                              event.getUsers(),\n                              event.getMediaPackage(),\n                              event.getWfProperties(),\n                              event.getCaMetadata(),\n                              event.getOptOut(),\n                              event.getSource(),\n                              \"organization-xyz-script\";\n  }",
            "title": "Default API"
        },
        {
            "location": "/scheduler/#transactional-api",
            "text": "Here is a simplified code example of how to use the Scheduler Java API to synchronize timetable events to scheduled\nevents. It is mandatory that the media package identifier is stable for the created events of the timetable system.    public void syncTimeTable(List<Event> timeTableEvents) {\n    SchedulerTransaction tx = null;\n    try {\n      logger.info(\"Sync timetable to scheduler | start\");\n      tx = schedulerService.createTransaction(\"timetable\");\n      for (Event event : timeTableEvents) {\n        tx.addEvent(\n                event.getStart(),\n                event.getEnd(),\n                event.getAgentId(),\n                event.getUsers(),\n                event.getMediaPackage(),\n                event.getWfProperties(),\n                event.getCaMetadata(),\n                event.getOptOut());\n      }\n      tx.commit();\n      logger.info(\"Sync timetable to scheduler | end\");\n    } catch (Exception e) {\n      logger.error(\"Sync timetable to scheduler | error\\n{}\", e);\n      if (tx != null) {\n        logger.error(\"Sync timetable to scheduler | rollback transaction\");\n        try {\n          tx.rollback();\n        } catch (Exception e2) {\n          logger.error(\"Sync timetable to scheduler | error doing rollback\\n{}\", e2);\n        }\n      }\n    }\n  }",
            "title": "Transactional API"
        },
        {
            "location": "/modules/",
            "text": "Modules Development Guides\n\n\nThese guides will provide you information relevant for development of specific modules\nor subsystems of Opencast.\n\n\n\n\nAdministrative User Interface\n\n\nDevelopment\n\n\nStyle Guide\n\n\n\n\n\n\nCapture Agent\n\n\nPlayer\n\n\nArchitecture\n\n\nCore Reference\n\n\nEvents\n\n\nPersistent local storage\n\n\nCreate a new Plugin\n\n\nTesting\n\n\n\n\n\n\nStream Security",
            "title": "Overview"
        },
        {
            "location": "/modules/#modules-development-guides",
            "text": "These guides will provide you information relevant for development of specific modules\nor subsystems of Opencast.   Administrative User Interface  Development  Style Guide    Capture Agent  Player  Architecture  Core Reference  Events  Persistent local storage  Create a new Plugin  Testing    Stream Security",
            "title": "Modules Development Guides"
        },
        {
            "location": "/modules/admin-ui/development/",
            "text": "Coding Principles\n\n\n\n  \nModularity\n\n  \nReusable interface components to build out new views based on the existing code structure.\n\n  \nValidation\n\n  \nAll code languages are HTML5 and CSS3 and adhere to W3C standards.\n\n  \nExtension\n\n  \nFor ease of UI and UX changes the styling elements are driven by SASS CSS pre-compiler.\n\n\n\n\n\nStyle Guide\n\n\nThe style guide defines a set of guidelines that the design follows to maintain a consistent look and feel.\nIt is defined to be flexible, easy to update and consistent. Before delving deeper into the UI or\ndeveloping additional features we recommend familiarizing yourself with some of the items.\n\n\nModifying Sources\n\n\nWhen you make changes to the sources, it should be sufficient to rebuild the\nAdmin UI NG module and copy the packaged module file into the Opencast assembly.\n\n\nExample:\n\n\ncd modules/matterhorn-admin-ui-ng\nmvn install\ncp ./target/matterhorn-admin-ui-ng-2.2-SNAPSHOT.jar ../../build/opencast-dist-allinone-2.2-SNAPSHOT/system/org/opencastproject/matterhorn-admin-ui-ng/2.2-SNAPSHOT/matterhorn-admin-ui-ng-2.2-SNAPSHOT.jar\n\n\n\nNote: Before you run \nmvn install\n from a module's root directory,\nplease make sure that you have built the complete software at least once\n--i.e. you should have already run \nmvn install\n from the repository root\nat some point.\n\n\nNote: In the example above, the paths are for a specific Opencast version.\nYour paths might look different.\n\n\nPrerequisites\n\n\n\n\n\n\nCheckout and build Opencast.\n\n\n\n\n\n\nYou will need to install \nNodeJS\n (which includes npm).\n\n\n\n\n\n\nBefore setting up the local server ensure that your npm is up-to-date (this might require \nsudo\n on certain systems):\n\n\nnpm update -g npm\n\n\n\n\n\n\n\nYou can also run a local version of \nGrunt\n and \nNodeJS\n from the Opencast module:\n\n\ncd modules/matterhorn-admin-ui-ng\nexport PATH=node:node_modules/grunt-cli/bin:node_modules/karma/bin:$PATH\n\n\n\nNote: The node and node_modules folders are created during the Maven build process.\n\n\nNote: We already had reports of Grunt behaving differently on different systems.\nWatch out for local or system-wide installations of Grunt and/or NodeJS as they can\nchange the build behavior of Admin UI NG.\n\n\nDebugging Javascript unit tests\n\n\nOur Javascript unit tests are built in \nJasmine\n (a behavior-driven development framework for\ntesting JavaScript code), and live in \nmodules/matterhorn-admin-ui-ng/src/test/resources/test/unit\n.\n\n\nOccasionally something breaks, or you need to disable or focus on a single test.\nWhile reading the Jasmine, Karma and Grunt docs are encouraged, here are a\nfew common recipes that might be useful:\n\n\nDisabling a unit test temporarily\n\n\nAdd \nx\n to the broken test. For example:\n\n\n\n\n\n\n\n\nBefore\n\n\nAfter\n\n\n\n\n\n\n\n\n\n\nit('runs a test', function () {\n\n\nx\nit('runs a test', function () {\n\n\n\n\n\n\n\n\nRunning a single unit test\n\n\nAdd \nf\n (for focus) to the relevant test.  For example:\n\n\n\n\n\n\n\n\nBefore\n\n\nAfter\n\n\n\n\n\n\n\n\n\n\nit('runs a test', function () {\n\n\nf\nit('runs a test', function () {\n\n\n\n\n\n\n\n\nTriggering a browser debugging session\n\n\nThis triggers an instance of the selected browser(s) to open and begin running\nthe tests.  There will be a \nDebug\n button which will open another tab where the JavaScript has not been minified,\n use this second tab for debugging. Refreshing the debugging page will rerun the tests.\n\n\nTo run Karma\n\n\n\n\n\n\nChrome\n\n\nnpm run test-chrome\n\n\n\n\n\n\nFirefox\n\n\nnpm run test-firefox\n\n\n\n\n\n\nIE\n\n\nnpm run test-ie\n\n\n\n\n\n\nAdditional browsers are supported, the full list can be found at \nhttps://karma-runner.github.io/\n.\n\n\nLive working with a running Opencast\n\n\nIn order to speed up the UI development process, you can test the code without\nbuilding the module with Maven. There is a Grunt task for starting a standalone web server offering the UI from\nthe source and a separate task that will monitoring any change to the Sass, JavaScript and HTML files and reload the\npage dynamically.\n\n\nBe warned that some functionality in this live setup can be limited.\nBefore reporting an issue, please test if you can reproduced the issue with a built Opencast.\n\n\nThis setup may be configured as follows:\n\n\n\n\n\n\nFollow the instructions in the Prerequisites section.\n\n\n\n\n\n\nStart your Opencast instance.\n\n\n\n\n\n\nChange to the Admin UI module directory.\n\n\ncd modules/matterhorn-admin-ui-ng\n\n\n\n\n\n\n\nInstall project dependencies.\n\n\nnpm install\n\n\n\n\n\n\n\nStart the standalone web server by running:\n\n\ngrunt proxy --proxy.host=http://localhost:8080 --proxy.username=opencast_system_account --proxy.password=CHANGE_ME\n\n\n\n\n\n\n\nNote: host, username and password have to match your configuration \n../etc/custom.properties\n\n\nGrunt should print out the \nURL\n where you can see the standalone page running\nfrom source.\n\n\nStarted connect web server on http://localhost:9000\n\n\n\nTo run the watcher that updates the displayed page dynamically, run in the same folder:\n\n\ngrunt watch\n\n\n\nWhich should then display:\n\n\nRunning \"watch\" task\nWaiting...\n\n\n\nThe watch process monitors the \njs\n,\nscss\n and \nsass\n files for changes and should dynamically reload the page.\n\n\nNote: A refresh of the page might be required to start the live reload script\n\n\nLive working with a Mockup\n\n\nIf you do not want to keep a running Opencast instance for developing the\nAdmin UI NG, you can start a mockup.\n\n\nBe warned that \na lot\n of this mockup's functionality acts very differently from\nan actual Opencast instance\n\n\nThis setup may be configured as follows:\n\n\n\n\n\n\nFollow the instructions in the Prerequisites section.\n\n\n\n\n\n\nChange to the Admin UI module directory.\n\n\ncd modules/matterhorn-admin-ui-ng\n\n\n\n\n\n\n\nInstall project dependencies.\n\n\nnpm install\n\n\n\n\n\n\n\nStart the mockup webserver by running:\n\n\ngrunt serve\n\n\n\n\n\n\n\nGrunt should print out the \nURL\n where you can see the standalone page running\nfrom source.\n\n\nStarted connect web server on http://localhost:9000\n\n\n\nIf you make changes to the Admin UI NG source files, the page should auto reload to display the changes.\n\n\nUpdate Node Dependencies\n\n\nInstalling \nnpm-check-updates\n and running it at the start of developing / improving a component can ensure that the\nnode modules stays up-to-date and dependency bugs are reduced.\n\n\nNote: Test the build (\nmvn install\n, \nnpm install\n, \ngrunt\n) thoroughly when upgrading modules as this might cause some\nunexpected build failures (resetting the grunt version to \"grunt\": \"^0.4.0\" might resolve some of the initial issues).\n\n\n\n\n\n\nInstallation.\n\n\nnpm install -g npm-check-updates\n\n\n\n\n\n\n\nShow any new dependencies for the project in the current directory.\n\n\nncu\n\n\n\n\n\n\n\nUpgrade a project's package file.\n\n\nncu -u\n\n\n\n\n\n\n\nA detailed reference of the command-line tool can be found at\n\nhttps://www.npmjs.com/package/npm-check-updates\n.",
            "title": "Development"
        },
        {
            "location": "/modules/admin-ui/development/#coding-principles",
            "text": "Modularity \n   Reusable interface components to build out new views based on the existing code structure. \n   Validation \n   All code languages are HTML5 and CSS3 and adhere to W3C standards. \n   Extension \n   For ease of UI and UX changes the styling elements are driven by SASS CSS pre-compiler.",
            "title": "Coding Principles"
        },
        {
            "location": "/modules/admin-ui/development/#style-guide",
            "text": "The style guide defines a set of guidelines that the design follows to maintain a consistent look and feel.\nIt is defined to be flexible, easy to update and consistent. Before delving deeper into the UI or\ndeveloping additional features we recommend familiarizing yourself with some of the items.",
            "title": "Style Guide"
        },
        {
            "location": "/modules/admin-ui/development/#modifying-sources",
            "text": "When you make changes to the sources, it should be sufficient to rebuild the\nAdmin UI NG module and copy the packaged module file into the Opencast assembly.  Example:  cd modules/matterhorn-admin-ui-ng\nmvn install\ncp ./target/matterhorn-admin-ui-ng-2.2-SNAPSHOT.jar ../../build/opencast-dist-allinone-2.2-SNAPSHOT/system/org/opencastproject/matterhorn-admin-ui-ng/2.2-SNAPSHOT/matterhorn-admin-ui-ng-2.2-SNAPSHOT.jar  Note: Before you run  mvn install  from a module's root directory,\nplease make sure that you have built the complete software at least once\n--i.e. you should have already run  mvn install  from the repository root\nat some point.  Note: In the example above, the paths are for a specific Opencast version.\nYour paths might look different.",
            "title": "Modifying Sources"
        },
        {
            "location": "/modules/admin-ui/development/#prerequisites",
            "text": "Checkout and build Opencast.    You will need to install  NodeJS  (which includes npm).    Before setting up the local server ensure that your npm is up-to-date (this might require  sudo  on certain systems):  npm update -g npm    You can also run a local version of  Grunt  and  NodeJS  from the Opencast module:  cd modules/matterhorn-admin-ui-ng\nexport PATH=node:node_modules/grunt-cli/bin:node_modules/karma/bin:$PATH  Note: The node and node_modules folders are created during the Maven build process.  Note: We already had reports of Grunt behaving differently on different systems.\nWatch out for local or system-wide installations of Grunt and/or NodeJS as they can\nchange the build behavior of Admin UI NG.",
            "title": "Prerequisites"
        },
        {
            "location": "/modules/admin-ui/development/#debugging-javascript-unit-tests",
            "text": "Our Javascript unit tests are built in  Jasmine  (a behavior-driven development framework for\ntesting JavaScript code), and live in  modules/matterhorn-admin-ui-ng/src/test/resources/test/unit .  Occasionally something breaks, or you need to disable or focus on a single test.\nWhile reading the Jasmine, Karma and Grunt docs are encouraged, here are a\nfew common recipes that might be useful:",
            "title": "Debugging Javascript unit tests"
        },
        {
            "location": "/modules/admin-ui/development/#disabling-a-unit-test-temporarily",
            "text": "Add  x  to the broken test. For example:     Before  After      it('runs a test', function () {  x it('runs a test', function () {",
            "title": "Disabling a unit test temporarily"
        },
        {
            "location": "/modules/admin-ui/development/#running-a-single-unit-test",
            "text": "Add  f  (for focus) to the relevant test.  For example:     Before  After      it('runs a test', function () {  f it('runs a test', function () {",
            "title": "Running a single unit test"
        },
        {
            "location": "/modules/admin-ui/development/#triggering-a-browser-debugging-session",
            "text": "This triggers an instance of the selected browser(s) to open and begin running\nthe tests.  There will be a  Debug  button which will open another tab where the JavaScript has not been minified,\n use this second tab for debugging. Refreshing the debugging page will rerun the tests.  To run Karma    Chrome  npm run test-chrome    Firefox  npm run test-firefox    IE  npm run test-ie    Additional browsers are supported, the full list can be found at  https://karma-runner.github.io/ .",
            "title": "Triggering a browser debugging session"
        },
        {
            "location": "/modules/admin-ui/development/#live-working-with-a-running-opencast",
            "text": "In order to speed up the UI development process, you can test the code without\nbuilding the module with Maven. There is a Grunt task for starting a standalone web server offering the UI from\nthe source and a separate task that will monitoring any change to the Sass, JavaScript and HTML files and reload the\npage dynamically.  Be warned that some functionality in this live setup can be limited.\nBefore reporting an issue, please test if you can reproduced the issue with a built Opencast.  This setup may be configured as follows:    Follow the instructions in the Prerequisites section.    Start your Opencast instance.    Change to the Admin UI module directory.  cd modules/matterhorn-admin-ui-ng    Install project dependencies.  npm install    Start the standalone web server by running:  grunt proxy --proxy.host=http://localhost:8080 --proxy.username=opencast_system_account --proxy.password=CHANGE_ME    Note: host, username and password have to match your configuration  ../etc/custom.properties  Grunt should print out the  URL  where you can see the standalone page running\nfrom source.  Started connect web server on http://localhost:9000  To run the watcher that updates the displayed page dynamically, run in the same folder:  grunt watch  Which should then display:  Running \"watch\" task\nWaiting...  The watch process monitors the  js , scss  and  sass  files for changes and should dynamically reload the page.  Note: A refresh of the page might be required to start the live reload script",
            "title": "Live working with a running Opencast"
        },
        {
            "location": "/modules/admin-ui/development/#live-working-with-a-mockup",
            "text": "If you do not want to keep a running Opencast instance for developing the\nAdmin UI NG, you can start a mockup.  Be warned that  a lot  of this mockup's functionality acts very differently from\nan actual Opencast instance  This setup may be configured as follows:    Follow the instructions in the Prerequisites section.    Change to the Admin UI module directory.  cd modules/matterhorn-admin-ui-ng    Install project dependencies.  npm install    Start the mockup webserver by running:  grunt serve    Grunt should print out the  URL  where you can see the standalone page running\nfrom source.  Started connect web server on http://localhost:9000  If you make changes to the Admin UI NG source files, the page should auto reload to display the changes.",
            "title": "Live working with a Mockup"
        },
        {
            "location": "/modules/admin-ui/development/#update-node-dependencies",
            "text": "Installing  npm-check-updates  and running it at the start of developing / improving a component can ensure that the\nnode modules stays up-to-date and dependency bugs are reduced.  Note: Test the build ( mvn install ,  npm install ,  grunt ) thoroughly when upgrading modules as this might cause some\nunexpected build failures (resetting the grunt version to \"grunt\": \"^0.4.0\" might resolve some of the initial issues).    Installation.  npm install -g npm-check-updates    Show any new dependencies for the project in the current directory.  ncu    Upgrade a project's package file.  ncu -u    A detailed reference of the command-line tool can be found at https://www.npmjs.com/package/npm-check-updates .",
            "title": "Update Node Dependencies"
        },
        {
            "location": "/modules/admin-ui/style/",
            "text": "Administrative User Interface: Style Guide\n\n\n\n\nColor Palette\n\n\nTypeface\n\n\nView Structure\n\n\nLogo\n        \n\n\nNavigation\n\n\nModals\n\n\nForms\n\n\nIcons\n\n\nButtons\n\n\nDropdowns\n\n\nAlerts and Indicators\n\n\nReferences",
            "title": "Overview"
        },
        {
            "location": "/modules/admin-ui/style/#administrative-user-interface-style-guide",
            "text": "Color Palette  Typeface  View Structure  Logo           Navigation  Modals  Forms  Icons  Buttons  Dropdowns  Alerts and Indicators  References",
            "title": "Administrative User Interface: Style Guide"
        },
        {
            "location": "/modules/admin-ui/style/color-palette/",
            "text": "Color Palette\n\n\nThe color palette is a very cool feeling range of icy blues and crisp greens with\ncold grey accents. The subtle differences between the colors offer a comfortable\nviewing experience without losing an ease of differentiation between elements.\nThe blend of colors work together in a mature fashion presenting a more\nprofessional environment for users. Percentage tints can be used of any of these colors.\n\n\n#37C180\n\n\n#378DD4\n\n\n#24425C\n\n\n#8C939B\n\n\n#FAFAFA\n\n\n\n\n\n  \n\n    \n\n      \n\n        \n#268559\n\n      \n\n        \n#2c9966\n\n      \n\n        \n#31ad73\n\n      \n\n        \n#37c180\n\n      \n\n        \n#47cb8d\n\n      \n\n        \n#5bd099\n\n      \n\n        \n#6fd6a5\n\n      \n                                     \n    \n\n  \n\n\n\n\n\n\n  \n\n    \n\n      \n\n        \n#0e1b25\n\n      \n\n        \n#162837\n\n      \n\n      \n\n        \n#1d354a\n\n      \n\n      \n\n        \n#24425c\n\n      \n\n      \n\n        \n#2b4f6e\n\n      \n\n      \n\n        \n#325c81\n\n      \n\n      \n\n        \n#3a6993\n\n      \n                                     \n    \n\n  \n\n\n\n\n\n\nSecondary Color Palette\n\n\nThe Secondary Palette should be used as a guide for the tone of a color. It is intended to be ever evolving, offering an endless palette to choose from.\n\n\n\n  \n\n    \n\n        \n\n          \n\n            \n#4da1f7\n\n          \n\n          \n\n            \nBright Blue\n\n          \n\n          \n\n            \n\n              \nHEX\n\n              \n#4da1f7\n\n            \n\n          \n\n          \n\n            \n\n              \nRGB\n\n              \n77, 161, 247\n\n            \n\n          \n\n          \n\n            \n\n              \nSCSS\n\n              \n$bright-blue\n\n            \n\n          \n\n        \n\n    \n    \n    \n\n        \n\n          \n\n            \n#fa1919\n\n          \n\n          \n\n            \nRed\n\n          \n\n          \n\n            \n\n              \nHEX\n\n              \n#fa1919\n\n            \n\n          \n\n          \n\n            \n\n              \nRGB\n\n              \n250, 25, 25\n\n            \n\n          \n\n          \n\n            \n\n              \nSCSS\n\n              \n$red\n\n            \n\n          \n\n        \n\n      \n    \n      \n\n        \n\n          \n\n            \n#e45253\n\n          \n\n          \n\n            \nAlternate Red\n\n          \n\n          \n\n            \n\n              \nHEX\n\n              \n#e45253\n\n            \n\n          \n\n          \n\n            \n\n              \nRGB\n\n              \n228, 82, 83\n\n            \n\n          \n\n          \n\n            \n\n              \nSCSS\n\n              \n$alt-red\n\n            \n\n          \n\n        \n\n      \n    \n      \n\n        \n\n          \n\n            \n#e4d12e\n\n          \n\n          \n\n            \nYellow\n\n          \n\n          \n\n            \n\n              \nHEX\n\n              \n#e4d12e\n\n            \n\n          \n\n          \n\n            \n\n              \nRGB\n\n              \n228, 209, 46\n\n            \n\n          \n\n          \n\n            \n\n              \nSCSS\n\n              \n$yellow\n\n            \n\n          \n\n        \n\n    \n\n  \n\n\n\n\n\n\nShades of gray\n\n\nA selection of grayscale colors for background, border or text color use.\n\n\n\n  \n\n    \n\n      \n\n        \n#222222\n\n      \n\n      \n\n        \n#4b4b4b\n\n      \n\n      \n\n        \n#646464\n\n      \n\n      \n\n        \n#7d7d7d\n\n      \n\n      \n\n        \n#969696\n\n      \n\n      \n\n        \n#c8c8c8\n\n      \n\n      \n\n        \n#e1e1e1\n\n      \n      \n      \n\n        \n#fafafa",
            "title": "Color Palette"
        },
        {
            "location": "/modules/admin-ui/style/color-palette/#color-palette",
            "text": "The color palette is a very cool feeling range of icy blues and crisp greens with\ncold grey accents. The subtle differences between the colors offer a comfortable\nviewing experience without losing an ease of differentiation between elements.\nThe blend of colors work together in a mature fashion presenting a more\nprofessional environment for users. Percentage tints can be used of any of these colors.  #37C180  #378DD4  #24425C  #8C939B  #FAFAFA   \n   \n     \n       \n         #268559 \n       \n         #2c9966 \n       \n         #31ad73 \n       \n         #37c180 \n       \n         #47cb8d \n       \n         #5bd099 \n       \n         #6fd6a5 \n                                            \n     \n     \n   \n     \n       \n         #0e1b25 \n       \n         #162837 \n       \n       \n         #1d354a \n       \n       \n         #24425c \n       \n       \n         #2b4f6e \n       \n       \n         #325c81 \n       \n       \n         #3a6993",
            "title": "Color Palette"
        },
        {
            "location": "/modules/admin-ui/style/color-palette/#secondary-color-palette",
            "text": "The Secondary Palette should be used as a guide for the tone of a color. It is intended to be ever evolving, offering an endless palette to choose from.  \n   \n     \n         \n           \n             #4da1f7 \n           \n           \n             Bright Blue \n           \n           \n             \n               HEX \n               #4da1f7 \n             \n           \n           \n             \n               RGB \n               77, 161, 247 \n             \n           \n           \n             \n               SCSS \n               $bright-blue \n             \n           \n         \n         \n     \n         \n           \n             #fa1919 \n           \n           \n             Red \n           \n           \n             \n               HEX \n               #fa1919 \n             \n           \n           \n             \n               RGB \n               250, 25, 25 \n             \n           \n           \n             \n               SCSS \n               $red \n             \n           \n         \n           \n       \n         \n           \n             #e45253 \n           \n           \n             Alternate Red \n           \n           \n             \n               HEX \n               #e45253 \n             \n           \n           \n             \n               RGB \n               228, 82, 83 \n             \n           \n           \n             \n               SCSS \n               $alt-red \n             \n           \n         \n           \n       \n         \n           \n             #e4d12e \n           \n           \n             Yellow \n           \n           \n             \n               HEX \n               #e4d12e \n             \n           \n           \n             \n               RGB \n               228, 209, 46 \n             \n           \n           \n             \n               SCSS \n               $yellow",
            "title": "Secondary Color Palette"
        },
        {
            "location": "/modules/admin-ui/style/color-palette/#shades-of-gray",
            "text": "A selection of grayscale colors for background, border or text color use.  \n   \n     \n       \n         #222222 \n       \n       \n         #4b4b4b \n       \n       \n         #646464 \n       \n       \n         #7d7d7d \n       \n       \n         #969696 \n       \n       \n         #c8c8c8 \n       \n       \n         #e1e1e1 \n             \n       \n         #fafafa",
            "title": "Shades of gray"
        },
        {
            "location": "/modules/admin-ui/style/typeface/",
            "text": "Typeface\n\n\nOpen Sans is an extremely versatile Humanist Sans-Serif\ntypeface designed by Steve Matteson. Delivering a crystal clear\nlook and feel, Open Sans enables users to quickly navigate the\nsoftware without any clutter. The strengths of this typeface\nsurpass both web and print applications offering excellent\nlegibility for both forms of media. Open Sans is a widely available\nfree font offered through Google Fonts and is widely seen as a\nweb standard face.\n\n\nPlease see \nReferences - Open Sans\n for license information.\n\n\n\n\n  \n\n    \nLight\n\n    \nAa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz\n\n\n   \nfont-weight\n:\n 300\n;\n   \nfont-style\n:\n normal\n;\n\n\n  \n\n\n  \n\n    \nLight Italic\n\n    \nAa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz\n\n\n   \nfont-weight\n:\n 300\n;\n   \nfont-style\n:\n italic\n;\n\n    \n  \n\n\n  \n\n    \nRegular\n\n    \nAa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz\n\n\n   \nfont-weight\n:\n 400\n;\n   \nfont-style\n:\n normal\n;\n\n\n  \n\n\n  \n\n    \nRegular Italic\n\n    \nAa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz\n\n\n   \nfont-weight\n:\n 400\n;\n   \nfont-style\n:\n italic\n;\n\n\n  \n\n\n  \n\n    \nSemibold\n\n    \nAa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz\n\n\n   \nfont-weight\n:\n 600\n;\n   \nfont-style\n:\n normal\n;\n\n\n    \n    \n  \n\n\n  \n\n    \nSemibold Italic\n\n    \nAa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz\n\n\n   \nfont-weight\n:\n 600\n;\n   \nfont-style\n:\n italic\n;\n\n\n  \n     \n\n  \n\n    \nBold\n\n    \nAa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz\n\n\n   \nfont-weight\n:\n 700\n;\n   \nfont-style\n:\n normal\n;\n\n\n  \n\n\n  \n\n    \nBold Italic\n\n    \nAa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz\n\n\n   \nfont-weight\n:\n 700\n;\n   \nfont-style\n:\n italic\n;\n\n\n  \n     \n\n  \n\n    \nExtrabold\n\n    \nAa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy\n\n\n   \nfont-weight\n:\n 800\n;\n   \nfont-style\n:\n normal\n;\n\n\n  \n\n\n  \n\n    \nExtrabold Italic\n\n    \nAa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz\n\n\n   \nfont-weight\n:\n 800\n;\n   \nfont-style\n:\n italic\n;\n\n\n  \n  \n\n\n\n\n\nUsage\n\n\nbody {\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 14px;\n  font-weight: 400;\n  font-style: normal;\n  line-height: 1;\n}\n\n\n\nHeader Bar and Navigation\n\n\n\n\n#user-dd {\n  /* [ User Profile ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 12px;\n  font-weight: 400;\n  font-style: normal;\n  color: #ffffff;  /* rgb(255, 255, 255) */\n}\n\nbutton {\n  /* [ Action Button ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 12px;\n  font-weight: 600;\n  font-style: normal;\n  color: #ffffff; /* rgb(255, 255, 255) */\n}\n\nnav a {\n  /*  [ Navigation Link - standard ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 14px;\n  font-weight: 600;\n  font-style: normal;\n  color: #5d7589; /* rgb(93,\u200b 117,\u200b 137) */\n}\n\nnav a.active {\n  /*  [ Navigation Link - current / active ] */\n  color: #fafafa; /* rgb(250,\u200b 250,\u200b 250) */\n}\n\n\n\n\nTable View\n\n\n\n\nh1 {\n  /* [ Table Header ] */\n  font-size: 23px;\n  font-weight: 100;\n  font-style: normal;\n  color: #46647e; /* rgb(70,\u200b 100,\u200b 126) */\n}\n\nh4 {\n  /* [ Table sub-heading ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 11px;\n  font-weight: 400;\n  font-style: normal;\n  color: #666666; /* rgb(102,\u200b 102,\u200b 102) */\n}\n\n.filters {\n  /*  [ Filter text ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 12px;\n  font-weight: 600;\n  font-style: normal;\n  color: #666666; /* rgb(102,\u200b 102,\u200b 102) */\n}\n\ninput#search  {\n  /*  [ search input box ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 13px;\n  font-weight: 600;\n  font-style: normal;\n  color: #666666; /* rgb(102,\u200b 102,\u200b 102) */\n}\n\n.filters .ng-multi-value  {\n  /*  [ value to be filtered by ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 11px;\n  font-weight: 400;\n  font-style: normal;\n  color: #ffffff; /* rgb(255, 255, 255) */\n}\n\nth {\n  /*  [ Table header ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 13px;\n  font-weight: 600;\n  font-style: normal;\n  color: #666666; /* rgb(102,\u200b 102,\u200b 102) */\n}\n\ntd {\n  /*  [ table data / cell ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 12px;\n  font-weight: 400;\n  font-style: normal;\n  color: #666666; /* rgb(102,\u200b 102,\u200b 102) */\n}\n\n.action-bar a  {\n  /*  [ Edit button on table header ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 14px;\n  font-weight: 400;\n  font-style: normal;\n  color: #3aa5ef; /* rgb(58,\u200b 165,\u200b 239) */\n}",
            "title": "Typeface"
        },
        {
            "location": "/modules/admin-ui/style/typeface/#typeface",
            "text": "Open Sans is an extremely versatile Humanist Sans-Serif\ntypeface designed by Steve Matteson. Delivering a crystal clear\nlook and feel, Open Sans enables users to quickly navigate the\nsoftware without any clutter. The strengths of this typeface\nsurpass both web and print applications offering excellent\nlegibility for both forms of media. Open Sans is a widely available\nfree font offered through Google Fonts and is widely seen as a\nweb standard face.  Please see  References - Open Sans  for license information.  \n\n   \n     Light \n     Aa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz      font-weight :  300 ;\n    font-style :  normal ; \n   \n\n   \n     Light Italic \n     Aa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz      font-weight :  300 ;\n    font-style :  italic ;     \n   \n\n   \n     Regular \n     Aa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz      font-weight :  400 ;\n    font-style :  normal ; \n   \n\n   \n     Regular Italic \n     Aa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz      font-weight :  400 ;\n    font-style :  italic ; \n   \n\n   \n     Semibold \n     Aa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz      font-weight :  600 ;\n    font-style :  normal ; \n         \n   \n\n   \n     Semibold Italic \n     Aa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz      font-weight :  600 ;\n    font-style :  italic ; \n        \n\n   \n     Bold \n     Aa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz      font-weight :  700 ;\n    font-style :  normal ; \n   \n\n   \n     Bold Italic \n     Aa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz      font-weight :  700 ;\n    font-style :  italic ; \n        \n\n   \n     Extrabold \n     Aa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy      font-weight :  800 ;\n    font-style :  normal ; \n   \n\n   \n     Extrabold Italic \n     Aa Bb Cc Dd Ee Ff Gg Hh Ii Jj Kk Ll Mm Nn Oo Pp Qq Rr Ss Tt Uu Vv Ww Xx Yy Zz      font-weight :  800 ;\n    font-style :  italic ;",
            "title": "Typeface"
        },
        {
            "location": "/modules/admin-ui/style/typeface/#usage",
            "text": "body {\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 14px;\n  font-weight: 400;\n  font-style: normal;\n  line-height: 1;\n}",
            "title": "Usage"
        },
        {
            "location": "/modules/admin-ui/style/typeface/#header-bar-and-navigation",
            "text": "#user-dd {\n  /* [ User Profile ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 12px;\n  font-weight: 400;\n  font-style: normal;\n  color: #ffffff;  /* rgb(255, 255, 255) */\n}\n\nbutton {\n  /* [ Action Button ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 12px;\n  font-weight: 600;\n  font-style: normal;\n  color: #ffffff; /* rgb(255, 255, 255) */\n}\n\nnav a {\n  /*  [ Navigation Link - standard ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 14px;\n  font-weight: 600;\n  font-style: normal;\n  color: #5d7589; /* rgb(93,\u200b 117,\u200b 137) */\n}\n\nnav a.active {\n  /*  [ Navigation Link - current / active ] */\n  color: #fafafa; /* rgb(250,\u200b 250,\u200b 250) */\n}",
            "title": "Header Bar and Navigation"
        },
        {
            "location": "/modules/admin-ui/style/typeface/#table-view",
            "text": "h1 {\n  /* [ Table Header ] */\n  font-size: 23px;\n  font-weight: 100;\n  font-style: normal;\n  color: #46647e; /* rgb(70,\u200b 100,\u200b 126) */\n}\n\nh4 {\n  /* [ Table sub-heading ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 11px;\n  font-weight: 400;\n  font-style: normal;\n  color: #666666; /* rgb(102,\u200b 102,\u200b 102) */\n}\n\n.filters {\n  /*  [ Filter text ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 12px;\n  font-weight: 600;\n  font-style: normal;\n  color: #666666; /* rgb(102,\u200b 102,\u200b 102) */\n}\n\ninput#search  {\n  /*  [ search input box ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 13px;\n  font-weight: 600;\n  font-style: normal;\n  color: #666666; /* rgb(102,\u200b 102,\u200b 102) */\n}\n\n.filters .ng-multi-value  {\n  /*  [ value to be filtered by ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 11px;\n  font-weight: 400;\n  font-style: normal;\n  color: #ffffff; /* rgb(255, 255, 255) */\n}\n\nth {\n  /*  [ Table header ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 13px;\n  font-weight: 600;\n  font-style: normal;\n  color: #666666; /* rgb(102,\u200b 102,\u200b 102) */\n}\n\ntd {\n  /*  [ table data / cell ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 12px;\n  font-weight: 400;\n  font-style: normal;\n  color: #666666; /* rgb(102,\u200b 102,\u200b 102) */\n}\n\n.action-bar a  {\n  /*  [ Edit button on table header ] */\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 14px;\n  font-weight: 400;\n  font-style: normal;\n  color: #3aa5ef; /* rgb(58,\u200b 165,\u200b 239) */\n}",
            "title": "Table View"
        },
        {
            "location": "/modules/admin-ui/style/view-structure/",
            "text": "Main View Structure\n\n\nThe Admin UI is divided up into four main sections.\n\n\n\n  \n1\n\n  \n\n  \nThe header bar contains the logo, link to help and playback, user profile and language options.\n\n\n\n\n\n\n  \n2\n\n  \n\n  \nThe action bar is made up of navigational elements such as the navigation tabs, main menu and/or action buttons.\n\n\n\n\n\n\n  \n3\n\n  \n\n  \nThis is the main \"work\" area of the page where the content is loaded; replacing the existing elements depending on the menu item that is selected.\n\n\n\n\n\n\n  \n4\n\n  \n\n  \nThe footer holds the version information.\n\n\n\n\n\n\nTable View Structure\n\n\nThe table view structure is used to display the majority of the information of the system and is used as entry point to the display of information in a modal or more intricate displays.\n\n\n\n  \n1\n\n  \n\n  \n\n    The header of the table view contains a section that shows the current table heading (with a sub-heading) and a section to filter and/or search the table.\n    \n\n    To filter the table click on the add filter icon and select the column and value to filter the table on. Multiple filters can be selected at any one time.\n    \n\n    Filters and search values can be saved and given a custom name and description for future use.\n  \n\n\n\n\n\n\n  \n2\n\n  \n\n  \n\n    As with any other HTML table the structure is divided into a header and a body. The header consists of columns, that are sortable, and a link to edit the columns and their order.\n    \n\n    The table body contains the information of an item in a row and the\n    \naction buttons\n\n    that allows a user to interact with that item.\n  \n\n\n\n\n\n\n  \n3\n\n  \n\n  \nThe table footer contains a page selector and a dropdown to change the number of rows that are shown.",
            "title": "View Structure"
        },
        {
            "location": "/modules/admin-ui/style/view-structure/#main-view-structure",
            "text": "The Admin UI is divided up into four main sections.  \n   1 \n   \n   The header bar contains the logo, link to help and playback, user profile and language options.   \n   2 \n   \n   The action bar is made up of navigational elements such as the navigation tabs, main menu and/or action buttons.   \n   3 \n   \n   This is the main \"work\" area of the page where the content is loaded; replacing the existing elements depending on the menu item that is selected.   \n   4 \n   \n   The footer holds the version information.",
            "title": "Main View Structure"
        },
        {
            "location": "/modules/admin-ui/style/view-structure/#table-view-structure",
            "text": "The table view structure is used to display the majority of the information of the system and is used as entry point to the display of information in a modal or more intricate displays.  \n   1 \n   \n   \n    The header of the table view contains a section that shows the current table heading (with a sub-heading) and a section to filter and/or search the table.\n     \n    To filter the table click on the add filter icon and select the column and value to filter the table on. Multiple filters can be selected at any one time.\n     \n    Filters and search values can be saved and given a custom name and description for future use.\n     \n   2 \n   \n   \n    As with any other HTML table the structure is divided into a header and a body. The header consists of columns, that are sortable, and a link to edit the columns and their order.\n     \n    The table body contains the information of an item in a row and the\n     action buttons \n    that allows a user to interact with that item.\n     \n   3 \n   \n   The table footer contains a page selector and a dropdown to change the number of rows that are shown.",
            "title": "Table View Structure"
        },
        {
            "location": "/modules/admin-ui/style/spacing/",
            "text": "Logo Spacing\n\n\n\n  \n\n  \n\n  The Logo is placed at the very top-left of the view with a height of 20 pixels.\n  The color fill for the logo is a single distinctive color (\n#FFFFFF\n) to be in contrast to the background color of the main header bar.",
            "title": "Logo"
        },
        {
            "location": "/modules/admin-ui/style/spacing/#logo-spacing",
            "text": "The Logo is placed at the very top-left of the view with a height of 20 pixels.\n  The color fill for the logo is a single distinctive color ( #FFFFFF ) to be in contrast to the background color of the main header bar.",
            "title": "Logo Spacing"
        },
        {
            "location": "/modules/admin-ui/style/navigation/",
            "text": "Navigation Tab\n\n\nThe section navigation tab is placed on the left side of the viewing area\nfor a user to easily access other sections of the Admin UI.\n\n\n\n  \n\n  \n\n    By default the main menu is hidden to allow for the maximum viewing area and to have a clean navigation area displaying the current important location.\n    \n    \n    Clicking on the main menu button displays the menu bar with all of the appropriate menu icons (Shown below).\n  \n\n\n\n\n\n\n  \n\n  \n\n    The expanded main menu consists of a number of icons, each representing an available section in the Admin UI.\n    \n\n    The main menu button consists of an anchor (\na\n) tag that wraps around a text (\ni\n)\n    element which has a \nbackground-image\n to display the icon.\n    \n\n    The text (\ni\n) element also contains \ndata-title\n\n    attribute that displays the tooltip (on hover over the icon) and is updated by the page translator object.",
            "title": "Navigation"
        },
        {
            "location": "/modules/admin-ui/style/navigation/#navigation-tab",
            "text": "The section navigation tab is placed on the left side of the viewing area\nfor a user to easily access other sections of the Admin UI.  \n   \n   \n    By default the main menu is hidden to allow for the maximum viewing area and to have a clean navigation area displaying the current important location.\n         \n    Clicking on the main menu button displays the menu bar with all of the appropriate menu icons (Shown below).\n     \n   \n   \n    The expanded main menu consists of a number of icons, each representing an available section in the Admin UI.\n     \n    The main menu button consists of an anchor ( a ) tag that wraps around a text ( i )\n    element which has a  background-image  to display the icon.\n     \n    The text ( i ) element also contains  data-title \n    attribute that displays the tooltip (on hover over the icon) and is updated by the page translator object.",
            "title": "Navigation Tab"
        },
        {
            "location": "/modules/admin-ui/style/modals/",
            "text": "Modals\n\n\nModals are a very important part of this interface. Modals are\nused throughout the software to control a specific function.\nModals should be used for every instance of setting controls,\nuser confirmations, exporting or importing data and other\nrelated tasks. Sizing of modals depend solely on how complex\nthe action is.\n\n\n1000 pixel width\n\n\nFor use with complex modals.\n\n\n\n850 pixel width\n\n\nFor use with moderately complex modals.\n\n\n\n600 pixel width\n\n\nFor use with less complex modals.\n\n\n\n400 pixel width\n\n\nFor use with confirmation modals.\n\n\n\n\n\n\nModal Types\n\n\nA variety of modal types are available for use based on what the\nmodal is to be used for. When extending, please ensure only the\nfollowing types of modals are used.\n\n\n\n  \nStep-by-Step\n\n  \n\n    \n\n    The step-by-step modal guides the user through the required steps to complete a particular task. The sequence of forms might have an impact on subsequent steps. The create event modal is a good example.\n  \n\n  \nTabbed\n\n  \n\n    \n\n    The tabbed modal is used to display information divided up into logical sections. It is not that important that the sequence of forms be maintained, validation is done on all the forms before completion of the task. The edit/create user modal as shown above demonstrates the usage of a tabbed modal.\n\n  \nSingle View\n\n  \n\n    \n\n    Single view modals are used to display a singular form or perform a simple action.",
            "title": "Modals"
        },
        {
            "location": "/modules/admin-ui/style/modals/#modals",
            "text": "Modals are a very important part of this interface. Modals are\nused throughout the software to control a specific function.\nModals should be used for every instance of setting controls,\nuser confirmations, exporting or importing data and other\nrelated tasks. Sizing of modals depend solely on how complex\nthe action is.",
            "title": "Modals"
        },
        {
            "location": "/modules/admin-ui/style/modals/#1000-pixel-width",
            "text": "For use with complex modals.",
            "title": "1000 pixel width"
        },
        {
            "location": "/modules/admin-ui/style/modals/#850-pixel-width",
            "text": "For use with moderately complex modals.",
            "title": "850 pixel width"
        },
        {
            "location": "/modules/admin-ui/style/modals/#600-pixel-width",
            "text": "For use with less complex modals.",
            "title": "600 pixel width"
        },
        {
            "location": "/modules/admin-ui/style/modals/#400-pixel-width",
            "text": "For use with confirmation modals.",
            "title": "400 pixel width"
        },
        {
            "location": "/modules/admin-ui/style/modals/#modal-types",
            "text": "A variety of modal types are available for use based on what the\nmodal is to be used for. When extending, please ensure only the\nfollowing types of modals are used.  \n   Step-by-Step \n   \n     \n    The step-by-step modal guides the user through the required steps to complete a particular task. The sequence of forms might have an impact on subsequent steps. The create event modal is a good example.\n   \n   Tabbed \n   \n     \n    The tabbed modal is used to display information divided up into logical sections. It is not that important that the sequence of forms be maintained, validation is done on all the forms before completion of the task. The edit/create user modal as shown above demonstrates the usage of a tabbed modal. \n   Single View \n   \n     \n    Single view modals are used to display a singular form or perform a simple action.",
            "title": "Modal Types"
        },
        {
            "location": "/modules/admin-ui/style/forms/",
            "text": "Forms\n\n\nThere are currently \n2\n form conventions used in the system and they are\nclosely associated with the modal type that the form is displayed in.\n\n\n\n  \nStep-by-Step Modal\n\n  \n\n    The form displayed in the step-by-step modal is displayed in a 2 column table; where each row has a label (left column)\n    and an input field (right column). To complete the form the required fields (\n*\n) need to be filled in and so forth until the completion of the modal action.\n    \n\n    The form inputs are read-only on initial display and if editable will activate when the user\n    clicks on the value (underlined text) or on the edit button located on the right side of the form field.\n    \n\n    Dropdown selection boxes will appear on editing/interaction of the field, if the field is so defined.    \n  \n\n\n\n\n\n\n\ninput[type=\"date\"], input[type=\"time\"], input[type=\"text\"],\ninput[type=\"email\"], input[type=\"password\"], input[type=\"search\"], textarea {\n  background-color: #fff;\n  border: 1px solid #c9d0d3;\n  border-radius: 4px;\n  color: #666;\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 13px;\n  font-weight: 600;\n  height: 40px;\n  margin: 0 auto;\n  padding: 0 0 0 10px;\n  width: 100%;\n}\n\n.edit {\n  /* Edit button - fa-pencil-square */\n  font-size: 14px;\n  margin: 5px;\n}\n\nspan.editable, td.editable span {\n  /* Clickable element for field editing */\n  border-bottom: 1px dashed #999;\n  font-size: 12px;\n  font-weight: 400;\n  color: #666;\n  line-height: 25px;\n}\n\n.chosen-container {\n  /* Drop down selector */\n  font-size: 13px;\n  font-weight: 400;    \n  width: 250px;\n}\n\n.td span {\n  /* Table Label */\n  font-size: 12px;\n  font-weight: 400;\n  color: #666;\n  line-height: 25px;\n}\n\n\n\n  \n  \nTabbed\n\n  \n\n    The tabbed modal is normally a much smaller modal and the fields required to complete the action fewer and more specific.\n    The form has larger input fields and the labels are positioned above them.\n  \n\n\n\n\n\n\n\n.form-container label {\n  font-family: \"Open Sans\",\u200bHelvetica,\u200bsans-serif;\n  font-size: 14px;\n  font-weight: 400;\n  color: #666;\n  line-height   14px\n}\n\n.form-container input {\n  /* Inherits style as defined for inputs (above) */\n  padding: 12px 20px 12px 15px;\n  margin: 10px 0px 5px 0px;\n  width: 100%;\n  line-height: 18px;\n}\n\n\n\n\n\ninput#search {\n  background-image: url(\"../img/search.png\");\n  background-position: 14px center;\n  background-repeat: no-repeat;\n  height: 40px;\n  padding: 0 20px 0 40px !important;\n}\n\nselect[multiple] {\n  background: #fff none repeat scroll 0 0;\n  border: 1px solid #c9d0d3;\n  border-radius: 4px;\n  color: #666;\n  font-size: 13px;\n  font-weight: 400;\n  padding: 10px;\n}",
            "title": "Forms"
        },
        {
            "location": "/modules/admin-ui/style/forms/#forms",
            "text": "There are currently  2  form conventions used in the system and they are\nclosely associated with the modal type that the form is displayed in.  \n   Step-by-Step Modal \n   \n    The form displayed in the step-by-step modal is displayed in a 2 column table; where each row has a label (left column)\n    and an input field (right column). To complete the form the required fields ( * ) need to be filled in and so forth until the completion of the modal action.\n     \n    The form inputs are read-only on initial display and if editable will activate when the user\n    clicks on the value (underlined text) or on the edit button located on the right side of the form field.\n     \n    Dropdown selection boxes will appear on editing/interaction of the field, if the field is so defined.    \n      input[type=\"date\"], input[type=\"time\"], input[type=\"text\"],\ninput[type=\"email\"], input[type=\"password\"], input[type=\"search\"], textarea {\n  background-color: #fff;\n  border: 1px solid #c9d0d3;\n  border-radius: 4px;\n  color: #666;\n  font-family: \"Open Sans\",Helvetica,sans-serif;\n  font-size: 13px;\n  font-weight: 600;\n  height: 40px;\n  margin: 0 auto;\n  padding: 0 0 0 10px;\n  width: 100%;\n}\n\n.edit {\n  /* Edit button - fa-pencil-square */\n  font-size: 14px;\n  margin: 5px;\n}\n\nspan.editable, td.editable span {\n  /* Clickable element for field editing */\n  border-bottom: 1px dashed #999;\n  font-size: 12px;\n  font-weight: 400;\n  color: #666;\n  line-height: 25px;\n}\n\n.chosen-container {\n  /* Drop down selector */\n  font-size: 13px;\n  font-weight: 400;    \n  width: 250px;\n}\n\n.td span {\n  /* Table Label */\n  font-size: 12px;\n  font-weight: 400;\n  color: #666;\n  line-height: 25px;\n}    \n   Tabbed \n   \n    The tabbed modal is normally a much smaller modal and the fields required to complete the action fewer and more specific.\n    The form has larger input fields and the labels are positioned above them.\n      .form-container label {\n  font-family: \"Open Sans\",\u200bHelvetica,\u200bsans-serif;\n  font-size: 14px;\n  font-weight: 400;\n  color: #666;\n  line-height   14px\n}\n\n.form-container input {\n  /* Inherits style as defined for inputs (above) */\n  padding: 12px 20px 12px 15px;\n  margin: 10px 0px 5px 0px;\n  width: 100%;\n  line-height: 18px;\n}   input#search {\n  background-image: url(\"../img/search.png\");\n  background-position: 14px center;\n  background-repeat: no-repeat;\n  height: 40px;\n  padding: 0 20px 0 40px !important;\n}\n\nselect[multiple] {\n  background: #fff none repeat scroll 0 0;\n  border: 1px solid #c9d0d3;\n  border-radius: 4px;\n  color: #666;\n  font-size: 13px;\n  font-weight: 400;\n  padding: 10px;\n}",
            "title": "Forms"
        },
        {
            "location": "/modules/admin-ui/style/icons/",
            "text": "Icons\n\n\nThe icon set is carefully designed for simplicity to convey a clear\nand concise user experience. Having a simple but effective icon set is crucial for ease\nof use within sophisticated software environments.\n\n\nSome icons are saved as pre-rendered images and can be found in the resource folder (\n.../src/main/webapp/img\n). Other icons are based on \nFont Awesome\n which gives us scalable vector icons that can be customized by size, color, drop shadow, and anything that is provided by CSS.\n\n\nFor more links and license information refer to \nReferences - Font Awesome\n.\n\n\nNote:\n Font Awesome contains over 630 icons, \nthe cheat sheet of icons\n lists the icons and the corresponding CSS class.\n\n\n\n  \n\n    \n\n    \n\n    \n\n    \n\n    \n\n  \n\n  \n\n    \n normal\n\n    \n fa-rotate-90\n\n    \n fa-rotate-180\n\n    \n fa-rotate-270\n\n    \n fa-flip-horizontal\n\n    \n fa-flip-vertical\n  \n\n  \n\n    \n\n      \n\n      \n\n    \n\n    fa-twitter on fa-square-o\n\n    \n\n      \n\n      \n\n    \n\n    fa-flag on fa-circle\n\n    \n\n      \n\n      \n\n    \n\n    fa-terminal on fa-square\n\n    \n\n      \n\n      \n\n    \n\n    fa-ban on fa-camera\n  \n\n\n\n\n\n\nSection Navigation Tab Icons\n\n\nThese icons are to represent different sections within the UI and\nshould only be represented in a \u201cflat\u201d graphic style. Simplicity is\nkey in the design of section icons. The user must easily identify\nthe icons. Extension of these icons must represent a similar style.\n\n\n\n\n\n\n/* [ Inactive ] */\n\n\ncolor\n:\n #C6C6C6\n;\n\n\n\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n\n\n\n\n\n\n\n/* [ Active ] */\n\n\ncolor\n:\n #A1A1A1\n;\n\n\n\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n\n\n\n\n\n\n\nCountry Icons\n\n\nCountry icons are located at the top-right of the interface\nbeside the user dropdown to indicate language that the UI is\nrepresented in.\n\n\nEach flag should:\n\n\n\n\nbe public domain\n\n\nbe an svg image\n\n\nhave an aspect ratio of 3:2\n\n\nbe named according to the Crowdin languages\n\n\nbe without additional decoration (official flags)\n\n\n\n\nA good source for these flags are the national flag articles of Wikipedia.\nE.g. \nhttps://en.wikipedia.org/wiki/Flag_of_Germany\n\n\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n\n\n\n.nav-dd-container .lang img {\n    border: 1px solid gray;\n    border-radius: 1px;\n    height: 18px;\n    vertical-align: middle;\n}",
            "title": "Icons"
        },
        {
            "location": "/modules/admin-ui/style/icons/#icons",
            "text": "The icon set is carefully designed for simplicity to convey a clear\nand concise user experience. Having a simple but effective icon set is crucial for ease\nof use within sophisticated software environments.  Some icons are saved as pre-rendered images and can be found in the resource folder ( .../src/main/webapp/img ). Other icons are based on  Font Awesome  which gives us scalable vector icons that can be customized by size, color, drop shadow, and anything that is provided by CSS.  For more links and license information refer to  References - Font Awesome .  Note:  Font Awesome contains over 630 icons,  the cheat sheet of icons  lists the icons and the corresponding CSS class.  \n   \n     \n     \n     \n     \n     \n   \n   \n      normal \n      fa-rotate-90 \n      fa-rotate-180 \n      fa-rotate-270 \n      fa-flip-horizontal \n      fa-flip-vertical\n   \n   \n     \n       \n       \n     \n    fa-twitter on fa-square-o \n     \n       \n       \n     \n    fa-flag on fa-circle \n     \n       \n       \n     \n    fa-terminal on fa-square \n     \n       \n       \n     \n    fa-ban on fa-camera",
            "title": "Icons"
        },
        {
            "location": "/modules/admin-ui/style/icons/#section-navigation-tab-icons",
            "text": "These icons are to represent different sections within the UI and\nshould only be represented in a \u201cflat\u201d graphic style. Simplicity is\nkey in the design of section icons. The user must easily identify\nthe icons. Extension of these icons must represent a similar style.    /* [ Inactive ] */  color :  #C6C6C6 ;  \n   \n   \n   \n   \n   \n   \n       /* [ Active ] */  color :  #A1A1A1 ;",
            "title": "Section Navigation Tab Icons"
        },
        {
            "location": "/modules/admin-ui/style/icons/#country-icons",
            "text": "Country icons are located at the top-right of the interface\nbeside the user dropdown to indicate language that the UI is\nrepresented in.  Each flag should:   be public domain  be an svg image  have an aspect ratio of 3:2  be named according to the Crowdin languages  be without additional decoration (official flags)   A good source for these flags are the national flag articles of Wikipedia. E.g.  https://en.wikipedia.org/wiki/Flag_of_Germany  \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n     .nav-dd-container .lang img {\n    border: 1px solid gray;\n    border-radius: 1px;\n    height: 18px;\n    vertical-align: middle;\n}",
            "title": "Country Icons"
        },
        {
            "location": "/modules/admin-ui/style/buttons/",
            "text": "Main Action Buttons\n\n\n\n  \n\n  \nMain Action buttons appear in the action bar. These buttons are generally to start an action like exporting or importing a list, creating a new event or series.\n\n\n\n\n\n\n\n  \n\n\n/* [ Main Button ] */\n\n\n.action-nav-bar .btn-group .add\n {\n\n  \ncolor\n:\n #FFFFFF\n;\n  \nbackground-color\n:\n #39c985\n;\n  \nbackground-image\n:\n linear-gradient(\n#39c985\n, \n#2d9b67\n)\n;\n  \nborder\n:\n 1px solid \n#193043\n;\n\n}\n\n\n\n\n\n\nModal Buttons\n\n\n\n  \n\n\n/* [ Modal Button - Accept ] */\n\n\n.modal\n a\n {\n\n  \ncolor\n:\n #FFFFFF\n;\n  \nbackground-color\n:\n #39c985\n;\n  \nbackground-image\n:\n linear-gradient(\n#39c985\n, \n#2d9b67\n)\n;\n  \nborder\n:\n 1px solid \n#20724b\n;\n\n}\n\n\n\n\n\n\n\n  \n\n\n/* [ Modal Button - Cancel / Return ] */\n\n\n.modal\n a\n.cancel\n {\n\n  \ncolor\n:\n #666666\n;\n  \nbackground-color\n:\n #FFFFFF\n;\n  \nbackground-image\n:\n linear-gradient(\n#FFFFFF\n, \n#f7f7f7\n)\n;\n  \nborder\n:\n 1px solid \n#c9d0d3\n;\n\n}\n\n\n\n\n\n\nAction buttons\n\n\nAction buttons are used to allow the user to control steps in a process. Usually placed within a table view, actions\ninclude options to delete, process and view statistics. These action buttons will generally open a modal and should be\nplaced in a specific hierarchical order for consistency.\n\n\n\n\nDetail Actions\n\n\nSub Actions\n\n\nDelete Actions",
            "title": "Buttons"
        },
        {
            "location": "/modules/admin-ui/style/buttons/#main-action-buttons",
            "text": "Main Action buttons appear in the action bar. These buttons are generally to start an action like exporting or importing a list, creating a new event or series.    \n    /* [ Main Button ] */  .action-nav-bar .btn-group .add  { \n   color :  #FFFFFF ;\n   background-color :  #39c985 ;\n   background-image :  linear-gradient( #39c985 ,  #2d9b67 ) ;\n   border :  1px solid  #193043 ; }",
            "title": "Main Action Buttons"
        },
        {
            "location": "/modules/admin-ui/style/buttons/#modal-buttons",
            "text": "/* [ Modal Button - Accept ] */  .modal  a  { \n   color :  #FFFFFF ;\n   background-color :  #39c985 ;\n   background-image :  linear-gradient( #39c985 ,  #2d9b67 ) ;\n   border :  1px solid  #20724b ; }    \n    /* [ Modal Button - Cancel / Return ] */  .modal  a .cancel  { \n   color :  #666666 ;\n   background-color :  #FFFFFF ;\n   background-image :  linear-gradient( #FFFFFF ,  #f7f7f7 ) ;\n   border :  1px solid  #c9d0d3 ; }",
            "title": "Modal Buttons"
        },
        {
            "location": "/modules/admin-ui/style/buttons/#action-buttons",
            "text": "Action buttons are used to allow the user to control steps in a process. Usually placed within a table view, actions\ninclude options to delete, process and view statistics. These action buttons will generally open a modal and should be\nplaced in a specific hierarchical order for consistency.   Detail Actions  Sub Actions  Delete Actions",
            "title": "Action buttons"
        },
        {
            "location": "/modules/admin-ui/style/dropdowns/",
            "text": "Dropdowns\n\n\nDropdowns are used when update actions are\nrequired or to trigger bulk actions.\n\n\n\n  \n\n\n.drop-down-container\n {\n\n  \ncolor\n:\n #666666\n;\n  \nbackground-color\n:\n #FFFFFF\n;\n  \nbackground-image\n:\n linear-gradient(\n#ffffff\n, \n#f7f7f7\n)\n;\n  \nborder\n:\n 1px solid \n#c9d0d3\n;\n  \nfont-size\n:\n 12px\n;\n  \nfont-weight\n:\n 600\n;\n\n}\n\n\n\n\n\n\n\n  \n\n\n.drop-down-container\n {\n\n  \ncolor\n:\n #666666\n;\n  \nbackground-color\n:\n #FFFFFF\n;\n  \nbackground-image\n:\n linear-gradient(\n#ffffff\n, \n#f7f7f7\n)\n;\n  \nborder\n:\n 1px solid \n#c9d0d3\n;\n  \nfont-size\n:\n 12px\n;\n  \nfont-weight\n:\n 600\n;\n\n}\n\n\n\n\n\n\n\n  \n\n\n.df-profile-filters .filters-list header\n {\n\n  \nbackground-image\n:\n linear-gradient(\n#ffffff\n, \n#f7f7f7\n)\n;\n  \nborder\n:\n 1px solid \n#c9d0d3\n;\n\n}\n\n\n.df-profile-filters .input-container .save\n {\n\n  \ncolor\n:\n #ffffff\n;\n  \nbackground-color\n:\n #39c985\n;\n  \nbackground-image\n:\n linear-gradient(\n#39c985\n, \n#2d9b67\n)\n;\n  \nborder\n:\n 1px solid \n#c9d0d3\n;\n\n}",
            "title": "Dropdowns"
        },
        {
            "location": "/modules/admin-ui/style/dropdowns/#dropdowns",
            "text": "Dropdowns are used when update actions are\nrequired or to trigger bulk actions.  \n    .drop-down-container  { \n   color :  #666666 ;\n   background-color :  #FFFFFF ;\n   background-image :  linear-gradient( #ffffff ,  #f7f7f7 ) ;\n   border :  1px solid  #c9d0d3 ;\n   font-size :  12px ;\n   font-weight :  600 ; }    \n    .drop-down-container  { \n   color :  #666666 ;\n   background-color :  #FFFFFF ;\n   background-image :  linear-gradient( #ffffff ,  #f7f7f7 ) ;\n   border :  1px solid  #c9d0d3 ;\n   font-size :  12px ;\n   font-weight :  600 ; }    \n    .df-profile-filters .filters-list header  { \n   background-image :  linear-gradient( #ffffff ,  #f7f7f7 ) ;\n   border :  1px solid  #c9d0d3 ; }  .df-profile-filters .input-container .save  { \n   color :  #ffffff ;\n   background-color :  #39c985 ;\n   background-image :  linear-gradient( #39c985 ,  #2d9b67 ) ;\n   border :  1px solid  #c9d0d3 ; }",
            "title": "Dropdowns"
        },
        {
            "location": "/modules/admin-ui/style/alerts-indicators/",
            "text": "Alerts\n\n\nAlerts are used to tell users when actions are incomplete, or\nrejected. Alerts should be placed at the top of the display view\nto have an importance in hierarchy. Alerts are represented\nin \"Success\", \"Info\", \"Warning\" and \"Danger\" (Error) states with their\ncorresponding colors below.\n\n\n\n\n.alert {\n    font-weight: 600;\n    min-height: 40px;\n}\n\n.alert .close {\n    font-size: 20px;\n}\n\n/* $state-success-text - $state-success-bg - $state-success-border */\n.alert.success {\n    background: #dff0d8 none repeat scroll 0 0;\n    border: 1px solid #d4eacb;\n}\n\n.alert.success p {\n  color: #3c763d;\n}\n\n/* $state-info-text - $state-info-bg - $state-info-border */\n.alert.info {\n    background: #d9edf7 none repeat scroll 0 0;\n    border: 1px solid #c3e1f0;\n}\n\n.alert.info p {\n  color: #387fa2;\n}\n\n/* $state-warning-text - $state-warning-bg - $state-warning-border */\n.alert.warning {\n    background: #fcf8e3 none repeat scroll 0 0;\n    border: 1px solid #f5f0cc;\n}\n\n.alert.warning p {\n  color: #8a6d3b;\n}\n\n/* $state-danger-text - $state-danger-bg - $state-danger-border */\n.alert.danger {\n    background: #f2dede none repeat scroll 0 0;\n    border: 1px solid #ebd1d1;\n}\n\n.alert.danger p {\n  color: #a94442;\n}\n\n\n\nIndicators\n\n\nIndicator lights should be visible to represent the health of an\naction or system.\n\n\n\n  \n\n  \n\n    \nActive - Green: \n#37c180\n \n$green\n\n    \nSuspended - Yellow: \n#e4d12e\n \n$yellow\n\n    \nError - Red: \n#fa1919 \n \n$red\n\n    \nRunning - Blue: \n#378dd4 \n \n$blue",
            "title": "Alerts and Indicators"
        },
        {
            "location": "/modules/admin-ui/style/alerts-indicators/#alerts",
            "text": "Alerts are used to tell users when actions are incomplete, or\nrejected. Alerts should be placed at the top of the display view\nto have an importance in hierarchy. Alerts are represented\nin \"Success\", \"Info\", \"Warning\" and \"Danger\" (Error) states with their\ncorresponding colors below.   .alert {\n    font-weight: 600;\n    min-height: 40px;\n}\n\n.alert .close {\n    font-size: 20px;\n}\n\n/* $state-success-text - $state-success-bg - $state-success-border */\n.alert.success {\n    background: #dff0d8 none repeat scroll 0 0;\n    border: 1px solid #d4eacb;\n}\n\n.alert.success p {\n  color: #3c763d;\n}\n\n/* $state-info-text - $state-info-bg - $state-info-border */\n.alert.info {\n    background: #d9edf7 none repeat scroll 0 0;\n    border: 1px solid #c3e1f0;\n}\n\n.alert.info p {\n  color: #387fa2;\n}\n\n/* $state-warning-text - $state-warning-bg - $state-warning-border */\n.alert.warning {\n    background: #fcf8e3 none repeat scroll 0 0;\n    border: 1px solid #f5f0cc;\n}\n\n.alert.warning p {\n  color: #8a6d3b;\n}\n\n/* $state-danger-text - $state-danger-bg - $state-danger-border */\n.alert.danger {\n    background: #f2dede none repeat scroll 0 0;\n    border: 1px solid #ebd1d1;\n}\n\n.alert.danger p {\n  color: #a94442;\n}",
            "title": "Alerts"
        },
        {
            "location": "/modules/admin-ui/style/alerts-indicators/#indicators",
            "text": "Indicator lights should be visible to represent the health of an\naction or system.  \n   \n   \n     Active - Green:  #37c180   $green \n     Suspended - Yellow:  #e4d12e   $yellow \n     Error - Red:  #fa1919    $red \n     Running - Blue:  #378dd4    $blue",
            "title": "Indicators"
        },
        {
            "location": "/modules/admin-ui/style/references/",
            "text": "Initial Admin UI Design\n\n\nThe initial release of the Admin UI design was completed in the early part of 2015 thanks to the combined\nefforts of \nEntwine\n, \nETH Zurich\n, \nSWITCH\n and \nUniversity of Manchester\n.\nThe result of this effort is a more technically advanced and intuitive  interface that results in a capture and media management solution that is both powerful and extensible.\n\n\nThe main focus for the new administrative ui was design and usability. While the functionality of the ui has been conceived by the solutions architects at Entwine, a professional team of designers at \nEspress Labs\n defined a consistent design language and provided the development team with design templates for the individual sections of the ui.\n\n\nThe resulting style guide clearly describes how individual parts and pieces are to be designed, which fonts and colors are available, how notifications should be displayed to the user and much more. On top of that, the design team delivered HTML templates for each screen and dialog so that there was little left to do for the frontend engineers but turn the templates into a great looking interactive application.\n\n\nOriginal Design Document:\n \nAdmin UI - A Guide to Style (Admin-UI-Style-Guide-v3.pdf)\n\n\nLinks:\n\n\n\n\nEntwine (http://entwinemedia.com/)\n\n\nETH Zurich (https://www.ethz.ch/en.html)\n\n\nSWITCH (https://www.switch.ch/)\n\n\nUniversity of Manchester (http://www.manchester.ac.uk/)\n\n\nEspress Labs (http://espresslabs.com/)\n\n\n\n\n\n\nOpen Sans\n\n\nOpen Sans is a humanist sans serif typeface designed by Steve Matteson, Type Director of Ascender Corp. This version contains the complete 897 character set, which includes the standard ISO Latin 1, Latin CE, Greek and Cyrillic character sets. Open Sans was designed with an upright stress, open forms and a neutral, yet friendly appearance. It was optimized for print, web, and mobile interfaces, and has excellent legibility characteristics in its letterforms.\n\n\nLink:\n \nGoogle Fonts - Open Sans (https://fonts.google.com/specimen/Open+Sans)\n\n\nLicense: \n \nApache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0)\n\n\n\n\nFont Awesome\n\n\nFont Awesome gives you scalable vector icons that can instantly be customized \u2014 size, color, drop shadow, and anything that can be done with the power of CSS.\n\n\nFont Awesome is fully open source and is GPL friendly. You can use it for commercial projects, open source projects, or really just about whatever you want.\n\n\nLink:\n \nFont Awesome (http://fontawesome.io/)\n\n\nLicense: \n \nFont Awesome - License (http://fontawesome.io/license/)\n\n\n\n\nSass\n\n\n\n  \n\n  \n\n    Sass is the most mature, stable, and powerful professional grade CSS extension language in the world.\n    \n\n    Sass is completely compatible with all versions of CSS. We take this compatibility seriously, so that you can seamlessly use any available CSS libraries.\n  \n\n\n\n\n\nLink:\n \nSass (http://sass-lang.com/)\n\n\n\n\nHTML\n\n\n\n  \n\n  \n\n  HTML5 is a markup language used for structuring and presenting content on the World Wide Web. It is the fifth and current version of the HTML standard.\n  \n\n  It was published in October 2014 by the World Wide Web Consortium (W3C) to improve the language with support for the latest multimedia, while keeping it both easily readable by humans and consistently understood by computers and devices such as web browsers, parsers, etc. HTML5 is intended to subsume not only HTML 4, but also XHTML 1 and DOM Level 2 HTML.\n  \n\n  HTML5 includes detailed processing models to encourage more interoperable implementations; it extends, improves and rationalizes the markup available for documents, and introduces markup and application programming interfaces (APIs) for complex web applications. For the same reasons, HTML5 is also a candidate for cross-platform mobile applications, because it includes features designed with low-powered devices in mind.\n  \n\n\n\n\n\nLinks:\n\n\n\n\nHTML 5 (https://www.w3.org/TR/html5/)\n\n\nHTML Validator (https://validator.w3.org/)",
            "title": "References"
        },
        {
            "location": "/modules/admin-ui/style/references/#initial-admin-ui-design",
            "text": "The initial release of the Admin UI design was completed in the early part of 2015 thanks to the combined\nefforts of  Entwine ,  ETH Zurich ,  SWITCH  and  University of Manchester .\nThe result of this effort is a more technically advanced and intuitive  interface that results in a capture and media management solution that is both powerful and extensible.  The main focus for the new administrative ui was design and usability. While the functionality of the ui has been conceived by the solutions architects at Entwine, a professional team of designers at  Espress Labs  defined a consistent design language and provided the development team with design templates for the individual sections of the ui.  The resulting style guide clearly describes how individual parts and pieces are to be designed, which fonts and colors are available, how notifications should be displayed to the user and much more. On top of that, the design team delivered HTML templates for each screen and dialog so that there was little left to do for the frontend engineers but turn the templates into a great looking interactive application.  Original Design Document:   Admin UI - A Guide to Style (Admin-UI-Style-Guide-v3.pdf)  Links:   Entwine (http://entwinemedia.com/)  ETH Zurich (https://www.ethz.ch/en.html)  SWITCH (https://www.switch.ch/)  University of Manchester (http://www.manchester.ac.uk/)  Espress Labs (http://espresslabs.com/)",
            "title": "Initial Admin UI Design"
        },
        {
            "location": "/modules/admin-ui/style/references/#open-sans",
            "text": "Open Sans is a humanist sans serif typeface designed by Steve Matteson, Type Director of Ascender Corp. This version contains the complete 897 character set, which includes the standard ISO Latin 1, Latin CE, Greek and Cyrillic character sets. Open Sans was designed with an upright stress, open forms and a neutral, yet friendly appearance. It was optimized for print, web, and mobile interfaces, and has excellent legibility characteristics in its letterforms.  Link:   Google Fonts - Open Sans (https://fonts.google.com/specimen/Open+Sans)  License:    Apache License, Version 2.0 (http://www.apache.org/licenses/LICENSE-2.0)",
            "title": "Open Sans"
        },
        {
            "location": "/modules/admin-ui/style/references/#font-awesome",
            "text": "Font Awesome gives you scalable vector icons that can instantly be customized \u2014 size, color, drop shadow, and anything that can be done with the power of CSS.  Font Awesome is fully open source and is GPL friendly. You can use it for commercial projects, open source projects, or really just about whatever you want.  Link:   Font Awesome (http://fontawesome.io/)  License:    Font Awesome - License (http://fontawesome.io/license/)",
            "title": "Font Awesome"
        },
        {
            "location": "/modules/admin-ui/style/references/#sass",
            "text": "Sass is the most mature, stable, and powerful professional grade CSS extension language in the world.\n     \n    Sass is completely compatible with all versions of CSS. We take this compatibility seriously, so that you can seamlessly use any available CSS libraries.\n     Link:   Sass (http://sass-lang.com/)",
            "title": "Sass"
        },
        {
            "location": "/modules/admin-ui/style/references/#html",
            "text": "HTML5 is a markup language used for structuring and presenting content on the World Wide Web. It is the fifth and current version of the HTML standard.\n   \n  It was published in October 2014 by the World Wide Web Consortium (W3C) to improve the language with support for the latest multimedia, while keeping it both easily readable by humans and consistently understood by computers and devices such as web browsers, parsers, etc. HTML5 is intended to subsume not only HTML 4, but also XHTML 1 and DOM Level 2 HTML.\n   \n  HTML5 includes detailed processing models to encourage more interoperable implementations; it extends, improves and rationalizes the markup available for documents, and introduces markup and application programming interfaces (APIs) for complex web applications. For the same reasons, HTML5 is also a candidate for cross-platform mobile applications, because it includes features designed with low-powered devices in mind.\n     Links:   HTML 5 (https://www.w3.org/TR/html5/)  HTML Validator (https://validator.w3.org/)",
            "title": "HTML"
        },
        {
            "location": "/modules/capture-agent/",
            "text": "Introduction\n\n\nThis guide describes the communication protocol between Opencast and any Capture Agent.  For the sake of simplicity, the\nfollowing variables are used throughout this guide:\n\n\n\n\n$HOST\n is your core's base URL\n\n\n$AGENT_NAME\n is the agent's name\n\n\n$RECORDING_ID\n is the recording's ID\n\n\n$SERIES_ID\n is the UUID of the series\n\n\n$CUTOFF\n is a Unix timestamp of the furthest point in time you want scheduling data for\n\n\n\n\nBasic Rules\n\n\n\n\nThe core \nMUST NOT\n attempt to connect to the agent, communication is always happening from  agent to core\n\n\nThe agent \nMUST\n get the endpoint location from the service registry\n\n\nThe agent \nMUST\n try to send its recording states to the core on a regular basis during recordings\n\n\nThe agent \nSHOULD\n send its state to the core on a semi regular basis\n\n\nThe agent \nMAY\n send its capabilities to the core on a semi regular basis\n\n\nThe agent \nMUST\n attempt to update its calendaring data regularly\n\n\nThe agent \nMUST\n must capture with all available inputs if no inputs are selected\n\n\nThe agent \nMAY\n tell the core the address of its web interface\n\n\n\n\nQuick Overview\n\n\nThe following list gives a short overview over the communication between agent and core. Remember, it is up to the agent\nto initiate the connections. Also note that ideally some operations may run in parallel.\n\n\n\n\nrequest rest endpoints\n\n\nregister agent and set status\n\n\nset the agents capabilities\n\n\nrepeat:\n\n\nwhile no recording\n\n\nget schedule/calendar\n\n\n\n\n\n\nset agent and recording state\n\n\nstart recording\n\n\nset agent and recording state\n\n\nupdate ingest endpoints\n\n\ningest recording\n\n\nset agent and recording state\n\n\n\n\n\n\n\n\nAction Details\n\n\nThis is a detailed description of the steps described in the quick overview section.\n\n\nFor details about the REST endpoints, please \nalways\n consult the Opencast REST documentation which can be found in the\ntop-right corner of the administrative user interface of each running Opencast instance. Note that most endpoints can\nhandle both JSON and XML although throughout this guide, for all examples, only JSON is used.\n\n\nGet Endpoint Locations From Service Registry\n\n\nFirst, you need to get the locations of the REST endpoints to talk to. These information can be retrieved from the\ncentral service registry. It is likely that Opencast is running as a distributed system which means you cannot expect\nall endpoints on a single host.\n\n\nThree endpoint locations need to be requested:\n\n\n\n\nThe capture-admin endpoint to register the agent and set status and configuration: \norg.opencastproject.capture.admin\n\n\nThe scheduler endpoint to get the current schedule for the agent from: \norg.opencastproject.scheduler\n\n\nThe ingest endpoint to upload the recordings to once they are done: \norg.opencastproject.ingest\n\n\n\n\nTo ask for an endpoint you would send an HTTP GET request to\n\n\n${HOST}/services/available.json?serviceType=<SERVICE>\n\n\n\nA result would look like\n\n\n{\n  \"services\" : {\n    \"service\" : {\n      \"active\" : true,\n      \"host\" : \"http://example.opencast.org:8080\",\n      \"path\" : \"/capture-admin\",\n      ...\n    }\n  }\n}\n\n\n\nThese endpoints should be requested once when starting up the capture agent. While the capture-admin and scheduler\nendpoints may then be assumed to never change during the runtime of the capture agent, the ingest endpoint may change\nand the data should be re-requested every time before uploading (ingesting) data to the core.\n\n\nRegister the Capture Agent and set Current Status\n\n\nOnce the endpoints to talk to are known, it is time to register the capture agent at the core so that scheduled events\ncan be added. This can be done by sending an HTTP POST request to:\n\n\n${CAPTURE-ADMIN-ENDPOINT}/agents/<name>\n\n\n\n\u2026including the following data fields:\n\n\nstate=idle\naddress=http(s)://<ca-web-ui>\n\n\n\nThe name has to be a unique identifier of a single capture agent. Using the same name for several agents would mean\nsharing the same schedule and status which in general should be avoided.\n\n\nSending this request will register the capture agent. After this, the capture agent should appear in the admin interface\nand schedules can be added for this agent.\n\n\nSetting \naddress\n is optional. It can be used to link an administrative web\ninterface of a capture agent.\n\n\nSetting Agent Capabilities\n\n\nAdditional to registering, the agent may set its capabilities allowing users to select possible inputs in the user\ninterface of Opencast when scheduling events. The configuration may be set as XML or JSON representation of a Java\nproperties file and can be set via an HTTP POST request to:\n\n\n/capture-admin/agents/$AGENT_NAME/configuration\n\n\n\nGetting the Calendar/Schedule\n\n\nThe calendar can be retrieved by sending an HTTP GET request to\n\n\n${SCHEDULER-ENDPOINT}/calendars?agentid=<name>\n\n\n\nThe format returned is iCal. The file contains all scheduled upcoming recordings the capture agent should handle.\n\n\nDepending on the amount of recordings scheduled for the particular capture agent, this file may become very large. That\nis why there are two way of limiting the amount of necessary data to transfer and process:\n\n\n\n\n\n\nSending the optional parameter \ncutoff\n to limit the schedule to a particular time span in the future.\n\n\n${SCHEDULER-ENDPOINT}/calendars?agentid=\n&cutoff=\n\n\n\n\n\n\nThe value for cutoff is a Unix timestamp in milliseconds from now. Events beginning after this time will not be\n   included in the returned schedule.\n\n\n\n\nUse the HTTP ETag and If-Not-Modified header to have Opencast only sent schedules when they have actually changed.\n\n\n\n\nSet Agent and Recording State\n\n\nSetting the agent state is identical to the registration of the capture agent and done by sending an HTTP POST request\nto:\n\n\n${CAPTURE-ADMIN-ENDPOINT}/agents/<name>\n\n\n\n\u2026including the following data fields:\n\n\nstate=capturing\naddress=http(s)://<ca-web-ui>\n\n\n\nAdditionally, set the recording state with an HTTP POST request to\n\n\n${CAPTURE-ADMIN-ENDPOINT}/recordings/<recording_id>\n\n\n\n\u2026including the data field:\n\n\nstate=capturing\n\n\n\nRecording\n\n\nThis task is device specific. Use whatever means necessary to get the recording\ndone.\n\n\nSet Agent and Recording State\n\n\nThis step is identical to the previous status update but for the state.\n\n\nIf the recording has failed, the recording state is updated with \ncapture_error\n while the agent's state is set back to\n\nidle\n if the error is non-permanent and to \nerror\n if it is permanent and block further recordings.\n\n\nIf the recording was successful, both states are set to \nuploading\n.\n\n\nGet Ingest Endpoint Locations From Service Registry\n\n\nThis step is identical to first request to the service registry expect that it is sufficient to request the location for\nthe service \norg.opencastproject.ingest\n. If this request fails, assume the old data to be valid.\n\n\nIngest (Upload) Recording\n\n\nUse the ingest endpoint to upload the recording.\n\n\nThere are multiple different methods to ingest media. Please refer to the REST endpoint documentation for details of\nthese methods. The most commonly used are:\n\n\n\n\nSingle request ingest using an HTTP POST request to\n\n\n${INGEST-ENDPOINT}/addMediaPackage\n\n\n\n\n\n\nMulti request ingest using HTTP POST requests to\n\n\n${INGEST-ENDPOINT}/createMediaPackage\n\n\n${INGEST-ENDPOINT}/addDCCatalog\n\n\n${INGEST-ENDPOINT}/addTrack\n\n\n${INGEST-ENDPOINT}/ingest\n\n\n\n\n\n\n\n\nIf possible, please follow these additional rules about recording files:\n\n\n\n\nRecordings may be deleted if the ingest was successful.\n\n\nRecordings should be stored in case of a failure.\n\n\n\n\nUpload Metadata\n\n\nThe calendar (iCal) with the scheduled events retrieved in an earlier step also contains metadata catalogs as attached\nfiles. To modify metadata, these catalogs can be modified and ingested as well. Opencast's default setting is to use\nthese for updating the existing metadata in the system.\n\n\nIf no metadata modifications are required (usual case), please do not modify these files and do not upload\nthem. In short: Ignore these attachments\n\n\nAdditional note for Opencast \u2264 3.x: Opencast only creates events in the database after ingesting the files. Scheduled\ndata are kept separately. That is why for these Opencast versions, all metadata files need to be ingested. Usually, that\nmeans to take the metadata catalogs from the schedule and ingest them unmodified using for example the \n/addDCCatalog\n\nendpoint.\n\n\nSet Agent and Recording State\n\n\nAgain, this step is identical to the previous status updates except for the state.\n\n\nIf the upload has failed, the recording state is updated with \nupload_error\n while the agents state is set back to\n\nidle\n if the error is non-permanent or to \nerror\n otherwise.\n\n\nIf the upload was successful, the recording status is set to \nupload_finished\n while the agents state is set back to\n\nidle\n.\n\n\nAgent State And Configuration\n\n\nThis section describes some additional aspects of the communication between capture agent and the Opencast core.\n\n\nCreating An Agent On The Core\n\n\nAn agent record is created on the core the first time the agent communicates with the core. There is no special endpoint\nor registration required, just send the state and the agent record will be created.\n\n\nAgent State\n\n\nAdditional to the required status updates outlined above, the agent should continue to send this status information on a\nregular basis to allow Opencast to determine that the agent is still active. If the agent fails to do so, it may be\nmarked as offline in the Opencast user interface after a certain amount of time (The default is 120min).\n\n\nAgent Configuration\n\n\nIf a special configuration is required, the agent should send its configuration data in a regular interval to ensure\nOpencast has the updated configuration even if the core is reset in the meantime.\n\n\nIt should also send the configuration when the agent's configuration changes to avoid conflicts between selected and\navailable options.\n\n\nThe format of this XML structure is the following:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\\\">\n<properties>\n  <comment>Capabilities for $AGENT_NAME</comment>\n  <entry key=\"$KEY_NAME\">$VALUE</entry>\n  \u2026\n</properties>\n\n\n\nIf sent as JSON, the format is a simple JSON object:\n\n\n{\n  'key':'value',\n  'key2':'value2'\n}\n\n\n\nTo specify inputs the user can select, the special key \ncapture.device.names\n is used.  It is a comma separated list of\ninputs which will be presented in the Opencast user interface.\n\n\nRecording State\n\n\nIf the agent is processing (recording) a previously scheduled event, it must send the recording's state to the core. It\nmay do this on a regular basis but at least should do this once the state of the recording changes since, for example,\nthe recording process has started.\n\n\nNote that these status changes are used in the administrative user interface and failing to set a state may cause the\ninterface to display a warning such as \u201cThe agent may have failed to start this recording\u201d.\n\n\nTo send the recording's state to the core, a valid state (as defined here) is sent via HTTP POST to:\n\n\n${CAPTURE-ADMIN-ENDPOINT}/recordings/<recording_id>\n\n\n\nCalendaring Data\n\n\nAgent's are expected to understand Opencast's iCalendar implementation. They should poll the calendar endpoint in a\nregular interval to update their internal schedule.\n\n\nAgent's should use a permanent cache (e.g. disk or database) for the cached schedule to be able to handle power and/or\nnetwork failures gracefully. This also allows an agent to be used in a network-less environment, for example for mobile\nrecordings: Merely cache the calendar data once after which the agent is brought to its destination where it will\ncapture and cache the pre-scheduled recordings.\n\n\nTo retrieve the calendar for an agent an HTTP GET is performed to\n\n\n${SCHEDULER-ENDPOINT}/calendars?agentid=<name>\n\n\n\nNote that the schedule has ETag support, which is very useful to speed up the processing of larger calendars.\n\n\nCapture Agent Configuration File\n\n\nTODO: Verify that this is still necessary with \u2265 4.0\n\n\nOne file attached to each scheduled event is \norg.opencastproject.capture.agent.properties\n. This file contains the\ncapture agent configuration directives (e.g. turning inputs on and off) as well as workflow directives which are\nimportant for the ingest process without which the core may misbehave.\n\n\nAll keys in this file contain prefixes identifying the type of property. For example, workflow directives are prefixed\nby \norg.opencastproject.workflow.config\n.  When passing the configuration directive to the core using the file  ingest\nREST endpoints, the agent must usually strip this prefix from the parameter. For example,\n\norg.opencastproject.workflow.config.trimHold=true\n should be passed as \ntrimHold=true\n.\n\n\nThe \norg.opencastproject.workflow.definition directive\n is important as well, this is the workflow definition identifier\nand should be passed as a parameter during the ingest operation.\n\n\nExample configuration file:\n\n\n#Capture Agent specific data\n#Tue May 22 17:34:22 CST 2012\norg.opencastproject.workflow.config.trimHold=true\ncapture.device.names=MOCK_SCREEN,MOCK_PRESENTER,MOCK_MICROPHONE\norg.opencastproject.workflow.definition=full\nevent.title=Test Capture\nevent.location=demo_capture_agent\n\n\n\nIngesting Media\n\n\nOpencast provides several different methods to ingest media, with each having some advantages and disadvantages. The\nfollowing description will give a short overview of the different methods. For more details, again, have a look at the\nREST endpoint documentation of the ingest service.\n\n\nMulti Request Ingest\n\n\nThis is the recommended way to use for most capture agents. It offers the most features to use and does not require any\npre- and post-processing of ingested material.\n\n\nUsing this method, a number of successive HTTP calls are made during the ingestion of media. The result of a successful\ncall is the newly updated media package. This media package is created by one call, then amended by a number of other\ncalls, each adding additional elements like tracks, attachments or metadata catalohs. Finally, it is then passed to the\nlast endpoint to begin processing.\n\n\nThe advantage to this process is that in case of a network failure only one particular element needs to be repeated in\ncontrast to repeating the whole process required by all other ingest methods.\n\n\nTo begin, the agent must first generate a valid media package. This is done via an HTTP GET request to\n\n${INGEST-ENDPOINT}/createMediaPackage\n. The resulting media package will contain the base skeleton used in later calls.\nEach following call will require a media package as input and will modify and return it to be used for the next call.\n\n\nThe next step(s) vary. Essentially, each generated file for a recording must be added, one at a time, to the media\npackage. For this, an agent may use the following REST endpoints:\n\n\n\n\n${INGEST-ENDPOINT}/addTrack\n to add media files (video, audio, \u2026) used for processing and/or publication\n\n\n${INGEST-ENDPOINT}/addDCCatalog\n to add the dublin core metadata catalogs like the basic episode metadata (title, \u2026)\n\n\n${INGEST-ENDPOINT}/addCatalog\n to add all types of metadata catalogs.  This is a more general version of\n  \naddDCCatalog\n and is seldom necessary.\n\n\n${INGEST-ENDPOINT}/addAttachment\n to add arbitrary attachments (cover images, access control catalogs, \u2026) to the\n  media package.\n\n\n\n\nFinally, once you have added all files, it is time to ingest the media package and begin processing. After this, no\nfurther files can be added.\n\n\nTo ingest a recording, an HTTP POST is sent to \n${INGEST-SERVICE}/ingest\n.\n\n\nSingle Request Ingest\n\n\nThe single request ingest will, as its name implies, handle the whole process as part of a single HTTP request. This\nis a convenient way of adding smaller ingest since the implementation does not require to store any internal state. The\noperation is atomic after all: Either it succeeds or fails.\n\n\nThe disadvantage to this is that the complexity of ingests is limited, e.g. no attachments can be added to the media\npackage this way, and a failure means that all files need to be re-transferred.\n\n\nFor this method, the agent posts all data to \n${INGEST-ENDPOINT}/addMediaPackage\n.\n\n\nZipped Media Ingest\n\n\nIn general, the use of this method is discouraged because of the additional load for packing and unpacking the material\ncompared to the negligible gain. For this method, the captured media, along with some metadata files is zipped and then\nHTTP POSTed to the core. The core then unzips the media package and begins processing. This unzipping operation is quite\ndisk intensive, and the REST endpoint does not return until the unzipping is done. Thus, please beware of proxy timeouts\nand additional disk utilization.\n\n\nTo ingest a zipped media package an HTTP POST is performed to \n${INGEST-ENDPOINT}/addZippedMediaPackage\n. The BODY of\nthe POST must contain the zipped media package.\n\n\nFurther Reading\n\n\nThe communication involve several REST endpoints. Additional documentation about these can be found in the REST docs of\nthe specific service. The REST documentation can be found at \n/rest_docs.html\n in every Opencast instance to reflect\nthat servers unique capabilities.\n\n\nServices involved in the communication with the capture agent are:\n\n\n\n\nThe capture admin service used to register the capture agent and set its current status.\n\n\nThe scheduler service to get scheduled recordings for an agent.\n\n\nThe ingest service to upload recording files and start processing.",
            "title": "Capture Agent"
        },
        {
            "location": "/modules/capture-agent/#introduction",
            "text": "This guide describes the communication protocol between Opencast and any Capture Agent.  For the sake of simplicity, the\nfollowing variables are used throughout this guide:   $HOST  is your core's base URL  $AGENT_NAME  is the agent's name  $RECORDING_ID  is the recording's ID  $SERIES_ID  is the UUID of the series  $CUTOFF  is a Unix timestamp of the furthest point in time you want scheduling data for",
            "title": "Introduction"
        },
        {
            "location": "/modules/capture-agent/#basic-rules",
            "text": "The core  MUST NOT  attempt to connect to the agent, communication is always happening from  agent to core  The agent  MUST  get the endpoint location from the service registry  The agent  MUST  try to send its recording states to the core on a regular basis during recordings  The agent  SHOULD  send its state to the core on a semi regular basis  The agent  MAY  send its capabilities to the core on a semi regular basis  The agent  MUST  attempt to update its calendaring data regularly  The agent  MUST  must capture with all available inputs if no inputs are selected  The agent  MAY  tell the core the address of its web interface",
            "title": "Basic Rules"
        },
        {
            "location": "/modules/capture-agent/#quick-overview",
            "text": "The following list gives a short overview over the communication between agent and core. Remember, it is up to the agent\nto initiate the connections. Also note that ideally some operations may run in parallel.   request rest endpoints  register agent and set status  set the agents capabilities  repeat:  while no recording  get schedule/calendar    set agent and recording state  start recording  set agent and recording state  update ingest endpoints  ingest recording  set agent and recording state",
            "title": "Quick Overview"
        },
        {
            "location": "/modules/capture-agent/#action-details",
            "text": "This is a detailed description of the steps described in the quick overview section.  For details about the REST endpoints, please  always  consult the Opencast REST documentation which can be found in the\ntop-right corner of the administrative user interface of each running Opencast instance. Note that most endpoints can\nhandle both JSON and XML although throughout this guide, for all examples, only JSON is used.",
            "title": "Action Details"
        },
        {
            "location": "/modules/capture-agent/#get-endpoint-locations-from-service-registry",
            "text": "First, you need to get the locations of the REST endpoints to talk to. These information can be retrieved from the\ncentral service registry. It is likely that Opencast is running as a distributed system which means you cannot expect\nall endpoints on a single host.  Three endpoint locations need to be requested:   The capture-admin endpoint to register the agent and set status and configuration:  org.opencastproject.capture.admin  The scheduler endpoint to get the current schedule for the agent from:  org.opencastproject.scheduler  The ingest endpoint to upload the recordings to once they are done:  org.opencastproject.ingest   To ask for an endpoint you would send an HTTP GET request to  ${HOST}/services/available.json?serviceType=<SERVICE>  A result would look like  {\n  \"services\" : {\n    \"service\" : {\n      \"active\" : true,\n      \"host\" : \"http://example.opencast.org:8080\",\n      \"path\" : \"/capture-admin\",\n      ...\n    }\n  }\n}  These endpoints should be requested once when starting up the capture agent. While the capture-admin and scheduler\nendpoints may then be assumed to never change during the runtime of the capture agent, the ingest endpoint may change\nand the data should be re-requested every time before uploading (ingesting) data to the core.",
            "title": "Get Endpoint Locations From Service Registry"
        },
        {
            "location": "/modules/capture-agent/#register-the-capture-agent-and-set-current-status",
            "text": "Once the endpoints to talk to are known, it is time to register the capture agent at the core so that scheduled events\ncan be added. This can be done by sending an HTTP POST request to:  ${CAPTURE-ADMIN-ENDPOINT}/agents/<name>  \u2026including the following data fields:  state=idle\naddress=http(s)://<ca-web-ui>  The name has to be a unique identifier of a single capture agent. Using the same name for several agents would mean\nsharing the same schedule and status which in general should be avoided.  Sending this request will register the capture agent. After this, the capture agent should appear in the admin interface\nand schedules can be added for this agent.  Setting  address  is optional. It can be used to link an administrative web\ninterface of a capture agent.",
            "title": "Register the Capture Agent and set Current Status"
        },
        {
            "location": "/modules/capture-agent/#setting-agent-capabilities",
            "text": "Additional to registering, the agent may set its capabilities allowing users to select possible inputs in the user\ninterface of Opencast when scheduling events. The configuration may be set as XML or JSON representation of a Java\nproperties file and can be set via an HTTP POST request to:  /capture-admin/agents/$AGENT_NAME/configuration",
            "title": "Setting Agent Capabilities"
        },
        {
            "location": "/modules/capture-agent/#getting-the-calendarschedule",
            "text": "The calendar can be retrieved by sending an HTTP GET request to  ${SCHEDULER-ENDPOINT}/calendars?agentid=<name>  The format returned is iCal. The file contains all scheduled upcoming recordings the capture agent should handle.  Depending on the amount of recordings scheduled for the particular capture agent, this file may become very large. That\nis why there are two way of limiting the amount of necessary data to transfer and process:    Sending the optional parameter  cutoff  to limit the schedule to a particular time span in the future.  ${SCHEDULER-ENDPOINT}/calendars?agentid= &cutoff=    The value for cutoff is a Unix timestamp in milliseconds from now. Events beginning after this time will not be\n   included in the returned schedule.   Use the HTTP ETag and If-Not-Modified header to have Opencast only sent schedules when they have actually changed.",
            "title": "Getting the Calendar/Schedule"
        },
        {
            "location": "/modules/capture-agent/#set-agent-and-recording-state",
            "text": "Setting the agent state is identical to the registration of the capture agent and done by sending an HTTP POST request\nto:  ${CAPTURE-ADMIN-ENDPOINT}/agents/<name>  \u2026including the following data fields:  state=capturing\naddress=http(s)://<ca-web-ui>  Additionally, set the recording state with an HTTP POST request to  ${CAPTURE-ADMIN-ENDPOINT}/recordings/<recording_id>  \u2026including the data field:  state=capturing",
            "title": "Set Agent and Recording State"
        },
        {
            "location": "/modules/capture-agent/#recording",
            "text": "This task is device specific. Use whatever means necessary to get the recording\ndone.",
            "title": "Recording"
        },
        {
            "location": "/modules/capture-agent/#set-agent-and-recording-state_1",
            "text": "This step is identical to the previous status update but for the state.  If the recording has failed, the recording state is updated with  capture_error  while the agent's state is set back to idle  if the error is non-permanent and to  error  if it is permanent and block further recordings.  If the recording was successful, both states are set to  uploading .",
            "title": "Set Agent and Recording State"
        },
        {
            "location": "/modules/capture-agent/#get-ingest-endpoint-locations-from-service-registry",
            "text": "This step is identical to first request to the service registry expect that it is sufficient to request the location for\nthe service  org.opencastproject.ingest . If this request fails, assume the old data to be valid.",
            "title": "Get Ingest Endpoint Locations From Service Registry"
        },
        {
            "location": "/modules/capture-agent/#ingest-upload-recording",
            "text": "Use the ingest endpoint to upload the recording.  There are multiple different methods to ingest media. Please refer to the REST endpoint documentation for details of\nthese methods. The most commonly used are:   Single request ingest using an HTTP POST request to  ${INGEST-ENDPOINT}/addMediaPackage    Multi request ingest using HTTP POST requests to  ${INGEST-ENDPOINT}/createMediaPackage  ${INGEST-ENDPOINT}/addDCCatalog  ${INGEST-ENDPOINT}/addTrack  ${INGEST-ENDPOINT}/ingest     If possible, please follow these additional rules about recording files:   Recordings may be deleted if the ingest was successful.  Recordings should be stored in case of a failure.",
            "title": "Ingest (Upload) Recording"
        },
        {
            "location": "/modules/capture-agent/#upload-metadata",
            "text": "The calendar (iCal) with the scheduled events retrieved in an earlier step also contains metadata catalogs as attached\nfiles. To modify metadata, these catalogs can be modified and ingested as well. Opencast's default setting is to use\nthese for updating the existing metadata in the system.  If no metadata modifications are required (usual case), please do not modify these files and do not upload\nthem. In short: Ignore these attachments  Additional note for Opencast \u2264 3.x: Opencast only creates events in the database after ingesting the files. Scheduled\ndata are kept separately. That is why for these Opencast versions, all metadata files need to be ingested. Usually, that\nmeans to take the metadata catalogs from the schedule and ingest them unmodified using for example the  /addDCCatalog \nendpoint.",
            "title": "Upload Metadata"
        },
        {
            "location": "/modules/capture-agent/#set-agent-and-recording-state_2",
            "text": "Again, this step is identical to the previous status updates except for the state.  If the upload has failed, the recording state is updated with  upload_error  while the agents state is set back to idle  if the error is non-permanent or to  error  otherwise.  If the upload was successful, the recording status is set to  upload_finished  while the agents state is set back to idle .",
            "title": "Set Agent and Recording State"
        },
        {
            "location": "/modules/capture-agent/#agent-state-and-configuration",
            "text": "This section describes some additional aspects of the communication between capture agent and the Opencast core.",
            "title": "Agent State And Configuration"
        },
        {
            "location": "/modules/capture-agent/#creating-an-agent-on-the-core",
            "text": "An agent record is created on the core the first time the agent communicates with the core. There is no special endpoint\nor registration required, just send the state and the agent record will be created.",
            "title": "Creating An Agent On The Core"
        },
        {
            "location": "/modules/capture-agent/#agent-state",
            "text": "Additional to the required status updates outlined above, the agent should continue to send this status information on a\nregular basis to allow Opencast to determine that the agent is still active. If the agent fails to do so, it may be\nmarked as offline in the Opencast user interface after a certain amount of time (The default is 120min).",
            "title": "Agent State"
        },
        {
            "location": "/modules/capture-agent/#agent-configuration",
            "text": "If a special configuration is required, the agent should send its configuration data in a regular interval to ensure\nOpencast has the updated configuration even if the core is reset in the meantime.  It should also send the configuration when the agent's configuration changes to avoid conflicts between selected and\navailable options.  The format of this XML structure is the following:  <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\\\">\n<properties>\n  <comment>Capabilities for $AGENT_NAME</comment>\n  <entry key=\"$KEY_NAME\">$VALUE</entry>\n  \u2026\n</properties>  If sent as JSON, the format is a simple JSON object:  {\n  'key':'value',\n  'key2':'value2'\n}  To specify inputs the user can select, the special key  capture.device.names  is used.  It is a comma separated list of\ninputs which will be presented in the Opencast user interface.",
            "title": "Agent Configuration"
        },
        {
            "location": "/modules/capture-agent/#recording-state",
            "text": "If the agent is processing (recording) a previously scheduled event, it must send the recording's state to the core. It\nmay do this on a regular basis but at least should do this once the state of the recording changes since, for example,\nthe recording process has started.  Note that these status changes are used in the administrative user interface and failing to set a state may cause the\ninterface to display a warning such as \u201cThe agent may have failed to start this recording\u201d.  To send the recording's state to the core, a valid state (as defined here) is sent via HTTP POST to:  ${CAPTURE-ADMIN-ENDPOINT}/recordings/<recording_id>",
            "title": "Recording State"
        },
        {
            "location": "/modules/capture-agent/#calendaring-data",
            "text": "Agent's are expected to understand Opencast's iCalendar implementation. They should poll the calendar endpoint in a\nregular interval to update their internal schedule.  Agent's should use a permanent cache (e.g. disk or database) for the cached schedule to be able to handle power and/or\nnetwork failures gracefully. This also allows an agent to be used in a network-less environment, for example for mobile\nrecordings: Merely cache the calendar data once after which the agent is brought to its destination where it will\ncapture and cache the pre-scheduled recordings.  To retrieve the calendar for an agent an HTTP GET is performed to  ${SCHEDULER-ENDPOINT}/calendars?agentid=<name>  Note that the schedule has ETag support, which is very useful to speed up the processing of larger calendars.",
            "title": "Calendaring Data"
        },
        {
            "location": "/modules/capture-agent/#capture-agent-configuration-file",
            "text": "TODO: Verify that this is still necessary with \u2265 4.0  One file attached to each scheduled event is  org.opencastproject.capture.agent.properties . This file contains the\ncapture agent configuration directives (e.g. turning inputs on and off) as well as workflow directives which are\nimportant for the ingest process without which the core may misbehave.  All keys in this file contain prefixes identifying the type of property. For example, workflow directives are prefixed\nby  org.opencastproject.workflow.config .  When passing the configuration directive to the core using the file  ingest\nREST endpoints, the agent must usually strip this prefix from the parameter. For example, org.opencastproject.workflow.config.trimHold=true  should be passed as  trimHold=true .  The  org.opencastproject.workflow.definition directive  is important as well, this is the workflow definition identifier\nand should be passed as a parameter during the ingest operation.  Example configuration file:  #Capture Agent specific data\n#Tue May 22 17:34:22 CST 2012\norg.opencastproject.workflow.config.trimHold=true\ncapture.device.names=MOCK_SCREEN,MOCK_PRESENTER,MOCK_MICROPHONE\norg.opencastproject.workflow.definition=full\nevent.title=Test Capture\nevent.location=demo_capture_agent",
            "title": "Capture Agent Configuration File"
        },
        {
            "location": "/modules/capture-agent/#ingesting-media",
            "text": "Opencast provides several different methods to ingest media, with each having some advantages and disadvantages. The\nfollowing description will give a short overview of the different methods. For more details, again, have a look at the\nREST endpoint documentation of the ingest service.",
            "title": "Ingesting Media"
        },
        {
            "location": "/modules/capture-agent/#multi-request-ingest",
            "text": "This is the recommended way to use for most capture agents. It offers the most features to use and does not require any\npre- and post-processing of ingested material.  Using this method, a number of successive HTTP calls are made during the ingestion of media. The result of a successful\ncall is the newly updated media package. This media package is created by one call, then amended by a number of other\ncalls, each adding additional elements like tracks, attachments or metadata catalohs. Finally, it is then passed to the\nlast endpoint to begin processing.  The advantage to this process is that in case of a network failure only one particular element needs to be repeated in\ncontrast to repeating the whole process required by all other ingest methods.  To begin, the agent must first generate a valid media package. This is done via an HTTP GET request to ${INGEST-ENDPOINT}/createMediaPackage . The resulting media package will contain the base skeleton used in later calls.\nEach following call will require a media package as input and will modify and return it to be used for the next call.  The next step(s) vary. Essentially, each generated file for a recording must be added, one at a time, to the media\npackage. For this, an agent may use the following REST endpoints:   ${INGEST-ENDPOINT}/addTrack  to add media files (video, audio, \u2026) used for processing and/or publication  ${INGEST-ENDPOINT}/addDCCatalog  to add the dublin core metadata catalogs like the basic episode metadata (title, \u2026)  ${INGEST-ENDPOINT}/addCatalog  to add all types of metadata catalogs.  This is a more general version of\n   addDCCatalog  and is seldom necessary.  ${INGEST-ENDPOINT}/addAttachment  to add arbitrary attachments (cover images, access control catalogs, \u2026) to the\n  media package.   Finally, once you have added all files, it is time to ingest the media package and begin processing. After this, no\nfurther files can be added.  To ingest a recording, an HTTP POST is sent to  ${INGEST-SERVICE}/ingest .",
            "title": "Multi Request Ingest"
        },
        {
            "location": "/modules/capture-agent/#single-request-ingest",
            "text": "The single request ingest will, as its name implies, handle the whole process as part of a single HTTP request. This\nis a convenient way of adding smaller ingest since the implementation does not require to store any internal state. The\noperation is atomic after all: Either it succeeds or fails.  The disadvantage to this is that the complexity of ingests is limited, e.g. no attachments can be added to the media\npackage this way, and a failure means that all files need to be re-transferred.  For this method, the agent posts all data to  ${INGEST-ENDPOINT}/addMediaPackage .",
            "title": "Single Request Ingest"
        },
        {
            "location": "/modules/capture-agent/#zipped-media-ingest",
            "text": "In general, the use of this method is discouraged because of the additional load for packing and unpacking the material\ncompared to the negligible gain. For this method, the captured media, along with some metadata files is zipped and then\nHTTP POSTed to the core. The core then unzips the media package and begins processing. This unzipping operation is quite\ndisk intensive, and the REST endpoint does not return until the unzipping is done. Thus, please beware of proxy timeouts\nand additional disk utilization.  To ingest a zipped media package an HTTP POST is performed to  ${INGEST-ENDPOINT}/addZippedMediaPackage . The BODY of\nthe POST must contain the zipped media package.",
            "title": "Zipped Media Ingest"
        },
        {
            "location": "/modules/capture-agent/#further-reading",
            "text": "The communication involve several REST endpoints. Additional documentation about these can be found in the REST docs of\nthe specific service. The REST documentation can be found at  /rest_docs.html  in every Opencast instance to reflect\nthat servers unique capabilities.  Services involved in the communication with the capture agent are:   The capture admin service used to register the capture agent and set its current status.  The scheduler service to get scheduled recordings for an agent.  The ingest service to upload recording files and start processing.",
            "title": "Further Reading"
        },
        {
            "location": "/modules/player/architecture/",
            "text": "Architecture\n\n\nOverview\n\n\nThe architecture of the theodul player has a plugin based structure based around a core. The core and the plugins have\nbeen realized as OSGi modules. Each plugin can be separately build.\n\n\nThe following figure shows the OSGi architecture of the player.\n\n\n\n\nAll Theodul OSGi modules are stored under:\n\n\nmodules/matterhorn-engage-theodul-*\n#Core module\nmodules/matterhorn-engage-theodul-api/\nmodules/matterhorn-engage-theodul-core/\n#A plugin module\nmodules/matterhorn-engage-theodul-plugin-*\nmodules/matterhorn-engage-theodul-plugin-tab-description/\n\n\n\nPlugin Manager\n\n\nThe main workflow is implemented by the core, which recognizes new plugins, collects information about the plugin type\nand resources, runs the JavaScript logic and inserts the first compiled templates into the HTML DOM.\n\n\nThe Plugin Manager Endpoint recognizes the OSGi modules. Each plugin has some information about its name and its\nresources. The Plugin Manager collects these information and publishes them via a REST endpoint. The following URL links\nto an example REST endpoint:\n\n\nhttp://localhost:8080/engage/theodul/manager/list.json\n\n\n\nThe documentation and test forms of the endpoint can be found on the Opencast start page. The following data in JSON\nshows an example list of plugins, which are used by the player and provided by the Plugin Manager Endpoint.\n\n\n{\n  \"pluginlist\":{\n    \"plugins\":[\n    {\n      \"name\":\"EngagePluginTabSlidetext\",\n      \"id\":\"6\",\n      \"description\":\"Simple implementation of a tab with the text of the slides\",\n      \"static-path\":\"6\\/static\"\n    },\n    {\n      \"name\":\"EngagePluginControlsMockup\",\n      \"id\":\"5\",\n      \"description\":\"Simple implementation of a control bar\",\n      \"static-path\":\"5\\/static\"\n    }]\n  }\n}\n\n\n\nNext to the Plugin Manager there is the Theodul Core module, which publishes the main HTML page, core.html.\n\n\nUI Core\n\n\nThe \ncore.html\n is the main entry point and starts the Javascript core logic. Following listing shows the directory\nstructure of core in the \nmatterhorn-engage-theodul-core OSGi\n module.\n\n\n|-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------spec\n\n\n\nAll Theodul JavaScript components are defined as a RequireJS module. The file \nengage_init.js\n is loaded firstly and\ncontains the configuration of RequireJS. This init script additionally loads the core module, which is defined in the\n\nengage_core.js\n.\n\n\nThe core module initializes the main HTML view. This view is realized as a BackboneJS view and is linked to a global\nBackbone model, which is stored in the model module in \nengage_model.js\n. The view is returned by the core module, so\nevery other module, which has a dependency to the core module, has a reference to the view (simply called \nEngage\n in\nthe plugins) and its functions. See the Core Reference for more information about the functions of the core view.\n\n\nPlugins\n\n\nPlugins in the Theodul player are developed and distributed in own OSGi modules. Every plugin has a special UI type. In\ndependency of this type the core injects the plugin to the right position of the player. The following plugin types are\npossible:\n\n\n\n\n\n\n\n\nPlugin Type\n\n\nDescription\n\n\nCharacteristics\n\n\nModule Name\n\n\nJS Plugin Type Name\n\n\nMaven Plugin Type Name\n\n\n\n\n\n\n\n\n\n\nControls\n\n\nImplements the main controls of the top of the player\n\n\nOnly one plugin per player possible.\n\n\nmatterhorn-engage-theodul-plugin-controls\n\n\nengage_controls\n\n\ncontrols\n\n\n\n\n\n\nTimeline\n\n\nTimeline information below the main controls.\n\n\nGood for processing time-based data like user tracking, slide previews or annotations.\n\n\nOptional plugin, more than one possible.  matterhorn-engage-theodul-plugin-timeline-\n\n\nengage_timeline\n\n\ntimeline\n\n\n\n\n\n\nVideodisplay\n\n\nImplementation of the video display.\n\n\nCurrently only one plugin per player possible, but in the future more video displays should be possible.\n\n\nmatterhorn-engage-theodul-plugin-video-\n\n\nengage_video\n\n\nvideo\n\n\n\n\n\n\nDescription/Label\n\n\nA plugin below the video display, good to show simple information about the video, like a title and the creator.\n\n\nOnly one plugin per player possible.\n\n\nmatterhorn-engage-theodul-plugin-description\n\n\nengage_description\n\n\ndescription\n\n\n\n\n\n\nTab\n\n\nShows a tab in the tab view at the bottom of the player.\n\n\nOptional plugin, more than one possible.\n\n\nmatterhorn-engage-theodul-plugin-tab-\n\n\nengage_tab\n\n\ntab\n\n\n\n\n\n\nCustom\n\n\nA custom plugin without a relationship to an UI element.\n\n\nGood for a custom REST endpoint, global data representation or to load custom JS code or libraries.\n\n\nOptional plugin, more than one possible.\n\n\nNo connection to a preserved UI element.\n\n\nmatterhorn-engage-theodul-plugin-custom-\n\n\n\n\n\n\n\n\nThe following listing shows the directory structure of a plugin module:\n\n\n|-src\n|---main\n|-----java\n|-------org\n|---------opencastproject\n|-----------engage\n|-------------theodul\n|---------------plugin\n|-----------------controls  #Simple Java class, and optional REST endpoint\n|-----resources\n|-------OSGI-INF            #OSGi information about the plugin\n|-------static              #web ressources, contains the main.js entry point of the plugin\n|---------images            #plugin ressources\n|---------js                #plugin js libs\n|-----------bootstrap\n|-----------jqueryui\n|---test                    #Jasmine test ressources\n|-----resources\n|-------js\n|---------engage            #Test Wrapper of the core\n|---------lib               #Required test libs\n|---------spec              #Jasmine test specs\n\n\n\nThe main JavaScript entry point of the plugin is main.js in the static folder. This contains the RequireJS module\ndefinition of the plugin and the main logic. All other plugin logic can be implemented as a RequireJS module and loaded\nin the main module. The main module should have a dependency to the core, the Engage object. With this object you have\naccess to main features of the core. See the Core Reference for more information about that.\n\n\nAfter the initialization process of the plugin, the plugin returns a plugin object with information about the plugin,\nlike the type, the name, the ui template etc. This object is used by the core to decide about the UI type/location of\nplugin. The Core Reference describes the plugin object, before and after it is being processed by the core.\n\n\nHave a look to the code of a plugin to get an impression about the plugin implementation.\n\n\nModel View Controller Support\n\n\nThe Theodul player supports MVC design patterns for each plugin based on methods and objects of the BackboneJS library.\nIt is not necessary to design a plugin in MVC style but it is highly recommended. An overview of the methods and objects\nof the BackboneJS library is listed on the official website of BackboneJS.\n\n\nEach plugin with a visual component has a reference to its view container and its template to fill the view container.\nHave a look at the Core Reference how to access the container and the template data. With this information the plugin\ncan create a Backbone view with a reference to the to div container and a render function to compile the template.\n\n\nThe next step is the creation of a model, which is being bound to the view. An usual way is to create a Backbone model,\nwhich is being passed by the view. In the initialization function of the view, the view binds the model change event to\nhis render function:\n\n\nBind the \"change\" event always to the render function of a view\n\n\n// bind the render function always to the view\n_.bindAll(this, \"render\");\n// listen for changes of the model and bind the render function to this\nthis.model.bind(\"change\", this.render);\n\n\n\nThe model can only be visible by the plugin itself or it can be added to the global Engage model of the core. Adding the\nmodel to the Engage model has the advantage, that on the one hand data can be used by other plugins and on the other\nhand it is able to listen to change- or add-events. So other plugins are able to listen to a change of data in another\nmodel and can react to it by e.g. re-render its view. This feature is e.g. used by the \"mhConnection\" custom plugin. The\nplugin receives data of Opencast endpoints and saves them to a model, which is being added to the Engage Model. Each\ntime the plugin gets newer endpoint data and updates its model's data, each plugin gets a notification and can re-render\nits view.\n\n\nA typical way to add a model to the Engage model is to add the model in the initialization function of the plugin after\nall other initializations. Here is an example of the video plugin:\n\n\nAdd a custom model to the Engage Model\n\n\nEngage.model.set(\"videoDataModel\", new VideoDataModel(videoDisplays, videoSources, duration));\n\n\n\nIn the same initialization function an event handler should be added to notice the addition of the model. Has the model\nsuccessfully been added, a view with this model and other data can be created:\n\n\nModel Event Handler\n\n\nEngage.model.on(\"change:videoDataModel\", function() {\n   new VideoDataView(this.get(\"videoDataModel\"), plugin.template, videojs_swf);\n});\n\n\n\nIf another plugin wants to use the defined \"videoDataModel\" model, it has to list it in its own initialization process:\n\n\nEngage.model.on(\"change:videoDataModel\", function() {\n   initCount -= 1;\n   if (initCount === 0) {\n      initPlugin();\n   }\n});\n\n\n\nHave a look at the full implementation of the VideoJS Plugin and the Controls Plugin to get an idea how the Backbone MVC\ndesign works. For completeness' sake, the \"Controller\" does not have an extra Object in the Backbone MVC design. The\n\"Controller\" is usually used as the render function in the view. This function can be very complex and should link to\nother functions, which are short and easy to be tested by the Jasmine Test Framework.",
            "title": "Architecture"
        },
        {
            "location": "/modules/player/architecture/#architecture",
            "text": "",
            "title": "Architecture"
        },
        {
            "location": "/modules/player/architecture/#overview",
            "text": "The architecture of the theodul player has a plugin based structure based around a core. The core and the plugins have\nbeen realized as OSGi modules. Each plugin can be separately build.  The following figure shows the OSGi architecture of the player.   All Theodul OSGi modules are stored under:  modules/matterhorn-engage-theodul-*\n#Core module\nmodules/matterhorn-engage-theodul-api/\nmodules/matterhorn-engage-theodul-core/\n#A plugin module\nmodules/matterhorn-engage-theodul-plugin-*\nmodules/matterhorn-engage-theodul-plugin-tab-description/",
            "title": "Overview"
        },
        {
            "location": "/modules/player/architecture/#plugin-manager",
            "text": "The main workflow is implemented by the core, which recognizes new plugins, collects information about the plugin type\nand resources, runs the JavaScript logic and inserts the first compiled templates into the HTML DOM.  The Plugin Manager Endpoint recognizes the OSGi modules. Each plugin has some information about its name and its\nresources. The Plugin Manager collects these information and publishes them via a REST endpoint. The following URL links\nto an example REST endpoint:  http://localhost:8080/engage/theodul/manager/list.json  The documentation and test forms of the endpoint can be found on the Opencast start page. The following data in JSON\nshows an example list of plugins, which are used by the player and provided by the Plugin Manager Endpoint.  {\n  \"pluginlist\":{\n    \"plugins\":[\n    {\n      \"name\":\"EngagePluginTabSlidetext\",\n      \"id\":\"6\",\n      \"description\":\"Simple implementation of a tab with the text of the slides\",\n      \"static-path\":\"6\\/static\"\n    },\n    {\n      \"name\":\"EngagePluginControlsMockup\",\n      \"id\":\"5\",\n      \"description\":\"Simple implementation of a control bar\",\n      \"static-path\":\"5\\/static\"\n    }]\n  }\n}  Next to the Plugin Manager there is the Theodul Core module, which publishes the main HTML page, core.html.",
            "title": "Plugin Manager"
        },
        {
            "location": "/modules/player/architecture/#ui-core",
            "text": "The  core.html  is the main entry point and starts the Javascript core logic. Following listing shows the directory\nstructure of core in the  matterhorn-engage-theodul-core OSGi  module.  |-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------spec  All Theodul JavaScript components are defined as a RequireJS module. The file  engage_init.js  is loaded firstly and\ncontains the configuration of RequireJS. This init script additionally loads the core module, which is defined in the engage_core.js .  The core module initializes the main HTML view. This view is realized as a BackboneJS view and is linked to a global\nBackbone model, which is stored in the model module in  engage_model.js . The view is returned by the core module, so\nevery other module, which has a dependency to the core module, has a reference to the view (simply called  Engage  in\nthe plugins) and its functions. See the Core Reference for more information about the functions of the core view.",
            "title": "UI Core"
        },
        {
            "location": "/modules/player/architecture/#plugins",
            "text": "Plugins in the Theodul player are developed and distributed in own OSGi modules. Every plugin has a special UI type. In\ndependency of this type the core injects the plugin to the right position of the player. The following plugin types are\npossible:     Plugin Type  Description  Characteristics  Module Name  JS Plugin Type Name  Maven Plugin Type Name      Controls  Implements the main controls of the top of the player  Only one plugin per player possible.  matterhorn-engage-theodul-plugin-controls  engage_controls  controls    Timeline  Timeline information below the main controls.  Good for processing time-based data like user tracking, slide previews or annotations.  Optional plugin, more than one possible.  matterhorn-engage-theodul-plugin-timeline-  engage_timeline  timeline    Videodisplay  Implementation of the video display.  Currently only one plugin per player possible, but in the future more video displays should be possible.  matterhorn-engage-theodul-plugin-video-  engage_video  video    Description/Label  A plugin below the video display, good to show simple information about the video, like a title and the creator.  Only one plugin per player possible.  matterhorn-engage-theodul-plugin-description  engage_description  description    Tab  Shows a tab in the tab view at the bottom of the player.  Optional plugin, more than one possible.  matterhorn-engage-theodul-plugin-tab-  engage_tab  tab    Custom  A custom plugin without a relationship to an UI element.  Good for a custom REST endpoint, global data representation or to load custom JS code or libraries.  Optional plugin, more than one possible.  No connection to a preserved UI element.  matterhorn-engage-theodul-plugin-custom-     The following listing shows the directory structure of a plugin module:  |-src\n|---main\n|-----java\n|-------org\n|---------opencastproject\n|-----------engage\n|-------------theodul\n|---------------plugin\n|-----------------controls  #Simple Java class, and optional REST endpoint\n|-----resources\n|-------OSGI-INF            #OSGi information about the plugin\n|-------static              #web ressources, contains the main.js entry point of the plugin\n|---------images            #plugin ressources\n|---------js                #plugin js libs\n|-----------bootstrap\n|-----------jqueryui\n|---test                    #Jasmine test ressources\n|-----resources\n|-------js\n|---------engage            #Test Wrapper of the core\n|---------lib               #Required test libs\n|---------spec              #Jasmine test specs  The main JavaScript entry point of the plugin is main.js in the static folder. This contains the RequireJS module\ndefinition of the plugin and the main logic. All other plugin logic can be implemented as a RequireJS module and loaded\nin the main module. The main module should have a dependency to the core, the Engage object. With this object you have\naccess to main features of the core. See the Core Reference for more information about that.  After the initialization process of the plugin, the plugin returns a plugin object with information about the plugin,\nlike the type, the name, the ui template etc. This object is used by the core to decide about the UI type/location of\nplugin. The Core Reference describes the plugin object, before and after it is being processed by the core.  Have a look to the code of a plugin to get an impression about the plugin implementation.",
            "title": "Plugins"
        },
        {
            "location": "/modules/player/architecture/#model-view-controller-support",
            "text": "The Theodul player supports MVC design patterns for each plugin based on methods and objects of the BackboneJS library.\nIt is not necessary to design a plugin in MVC style but it is highly recommended. An overview of the methods and objects\nof the BackboneJS library is listed on the official website of BackboneJS.  Each plugin with a visual component has a reference to its view container and its template to fill the view container.\nHave a look at the Core Reference how to access the container and the template data. With this information the plugin\ncan create a Backbone view with a reference to the to div container and a render function to compile the template.  The next step is the creation of a model, which is being bound to the view. An usual way is to create a Backbone model,\nwhich is being passed by the view. In the initialization function of the view, the view binds the model change event to\nhis render function:  Bind the \"change\" event always to the render function of a view  // bind the render function always to the view\n_.bindAll(this, \"render\");\n// listen for changes of the model and bind the render function to this\nthis.model.bind(\"change\", this.render);  The model can only be visible by the plugin itself or it can be added to the global Engage model of the core. Adding the\nmodel to the Engage model has the advantage, that on the one hand data can be used by other plugins and on the other\nhand it is able to listen to change- or add-events. So other plugins are able to listen to a change of data in another\nmodel and can react to it by e.g. re-render its view. This feature is e.g. used by the \"mhConnection\" custom plugin. The\nplugin receives data of Opencast endpoints and saves them to a model, which is being added to the Engage Model. Each\ntime the plugin gets newer endpoint data and updates its model's data, each plugin gets a notification and can re-render\nits view.  A typical way to add a model to the Engage model is to add the model in the initialization function of the plugin after\nall other initializations. Here is an example of the video plugin:",
            "title": "Model View Controller Support"
        },
        {
            "location": "/modules/player/architecture/#add-a-custom-model-to-the-engage-model",
            "text": "Engage.model.set(\"videoDataModel\", new VideoDataModel(videoDisplays, videoSources, duration));  In the same initialization function an event handler should be added to notice the addition of the model. Has the model\nsuccessfully been added, a view with this model and other data can be created:  Model Event Handler  Engage.model.on(\"change:videoDataModel\", function() {\n   new VideoDataView(this.get(\"videoDataModel\"), plugin.template, videojs_swf);\n});  If another plugin wants to use the defined \"videoDataModel\" model, it has to list it in its own initialization process:  Engage.model.on(\"change:videoDataModel\", function() {\n   initCount -= 1;\n   if (initCount === 0) {\n      initPlugin();\n   }\n});  Have a look at the full implementation of the VideoJS Plugin and the Controls Plugin to get an idea how the Backbone MVC\ndesign works. For completeness' sake, the \"Controller\" does not have an extra Object in the Backbone MVC design. The\n\"Controller\" is usually used as the render function in the view. This function can be very complex and should link to\nother functions, which are short and easy to be tested by the Jasmine Test Framework.",
            "title": "Add a custom model to the Engage Model"
        },
        {
            "location": "/modules/player/core.reference/",
            "text": "Core Reference\n\n\nEngage Core\n\n\nRequireJS Path\n\n\n'engage/engage_core'\n\n\n\nInherited object functions of the BackboneJS view, see http://backbonejs.org/#View\n\n\nAdded object functions and properties:\n\n\n\n\n\n\n\n\nName\n\n\nParameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nlog(value):void\n\n\nvalue:String\n\n\nfunction\n\n\nfunction to log via the core cross browser\n\n\n\n\n\n\nEvent:EngageEvent\n\n\nnone\n\n\nproperty\n\n\nReturns the EngageEvent object prototype, the see EngageEvent Object for more information\n\n\n\n\n\n\ntrigger(event):void\n\n\nevent:EngageEvent\n\n\nfunction\n\n\ntriggers an EngageEvent\n\n\n\n\n\n\non(event, handler, context):void\n\n\nevent:EngageEvent, handler:function, context:object\n\n\nfunction\n\n\ninstall an event handler on a EngageEvent\n\n\n\n\n\n\nmodel:EngageModel\n\n\nnone\n\n\nproperty\n\n\nReturns the singleton engage model for this session, see EngageModel for more information's\n\n\n\n\n\n\ngetPluginPath(pluginName):String\n\n\npluginName:String\n\n\nfunction\n\n\nReturns the absolute path of a plugin by name.\n\n\n\n\n\n\n\n\nEngageEvent Object\n\n\n\n\n\n\n\n\nName\n\n\nParamters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nEngageEvent(name, description, type)\n\n\nname:String, description:String, type:String\n\n\nconstructor\n\n\nCreate a new unbound EngageEvent, with a name, description and a type. For Example: var myEvent = new EngageEvent('play', 'plays the video', 'trigger')\n\n\n\n\n\n\ngetName:String\n\n\nnone\n\n\nfunction\n\n\nGets the name\n\n\n\n\n\n\ngetDescription:String\n\n\nnone\n\n\nfunction\n\n\nGets the description\n\n\n\n\n\n\ngetType:String\n\n\nnone\n\n\nfunction\n\n\nGets the Type, can be a \"handler\", \"trigger\" or \"both\"\n\n\n\n\n\n\ntoString:String\n\n\nnone\n\n\nfunction\n\n\nBuild a string that describes the event\n\n\n\n\n\n\n\n\nEngage Model\n\n\nInherited object functions of the BackboneJS model, see http://backbonejs.org/#Model, how to use BackboneJS models. This model is a global singleton object and can be used by each plugin to add new models which can be used by another plugin again.\n\n\nNo special functions are added, but the model is filled with some default data. This default data can be used by each plugin, which has a reference to the EngageModel.\n\n\n\n\n\n\n\n\nProperty Name\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\npluginsInfo\n\n\nBackbone Model\n\n\nContains Information's of each plugin\n\n\n\n\n\n\npluginModels\n\n\nBackbone Collection\n\n\nContains the plugin models\n\n\n\n\n\n\nurlParameters\n\n\nObject\n\n\nContains the data of the URL parameters.\n\n\n\n\n\n\n\n\nPlugin Object\n\n\nEach plugin \nmust\n create and return a object with some properties which are set by the plugin itself. It is recommend to keep a reference to the object because some properties are set by the core after the plugin is processed.\n\n\n\n\n\n\n\n\nProperty Name\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nname\n\n\nString\n\n\nName of the plugin, e.g. \"Engage Controls\". \nThis property is set by the plugin.\n\n\n\n\n\n\ntype\n\n\nString\n\n\nType of the plugin, e.g. \"engage_controls\", see the plugin table in Architecture for the other plugin types. \nThis property is set by the plugin.\n\n\n\n\n\n\nversion\n\n\nString\n\n\nVersion of plugin. \nThis property is set by the plugin.\n\n\n\n\n\n\nstyles\n\n\nArray of Strings\n\n\nArray of the paths of css files relative to the static folder of each plugin . \nThis property is set by the plugin.\n\n\n\n\n\n\ntemplate\n\n\nString\n\n\nBefore the plugin object is returned by the plugin logic, the template property contains the path to the template relative to the static folder. \nThe path property is set first by the plugin\n. After the plugin object is returned and the Theodul core processed the plugin, the template property is filled with the real template data and can be used to re-render the view.\n\n\n\n\n\n\ncontainer\n\n\nString\n\n\nContains the ID of the HTML div container, which contains the rendered template. This can be used to re-render the view. \nThis property is set by the core.\n\n\n\n\n\n\npluginPath\n\n\nString\n\n\nContains the absolute path of the plugin.  \nThis property is set by the core.\n\n\n\n\n\n\nevents\n\n\nObject\n\n\nContains all events which are used of this plugin. Each handled and each triggered event.",
            "title": "Core Reference"
        },
        {
            "location": "/modules/player/core.reference/#core-reference",
            "text": "",
            "title": "Core Reference"
        },
        {
            "location": "/modules/player/core.reference/#engage-core",
            "text": "RequireJS Path  'engage/engage_core'  Inherited object functions of the BackboneJS view, see http://backbonejs.org/#View  Added object functions and properties:     Name  Parameters  Type  Description      log(value):void  value:String  function  function to log via the core cross browser    Event:EngageEvent  none  property  Returns the EngageEvent object prototype, the see EngageEvent Object for more information    trigger(event):void  event:EngageEvent  function  triggers an EngageEvent    on(event, handler, context):void  event:EngageEvent, handler:function, context:object  function  install an event handler on a EngageEvent    model:EngageModel  none  property  Returns the singleton engage model for this session, see EngageModel for more information's    getPluginPath(pluginName):String  pluginName:String  function  Returns the absolute path of a plugin by name.",
            "title": "Engage Core"
        },
        {
            "location": "/modules/player/core.reference/#engageevent-object",
            "text": "Name  Paramters  Type  Description      EngageEvent(name, description, type)  name:String, description:String, type:String  constructor  Create a new unbound EngageEvent, with a name, description and a type. For Example: var myEvent = new EngageEvent('play', 'plays the video', 'trigger')    getName:String  none  function  Gets the name    getDescription:String  none  function  Gets the description    getType:String  none  function  Gets the Type, can be a \"handler\", \"trigger\" or \"both\"    toString:String  none  function  Build a string that describes the event",
            "title": "EngageEvent Object"
        },
        {
            "location": "/modules/player/core.reference/#engage-model",
            "text": "Inherited object functions of the BackboneJS model, see http://backbonejs.org/#Model, how to use BackboneJS models. This model is a global singleton object and can be used by each plugin to add new models which can be used by another plugin again.  No special functions are added, but the model is filled with some default data. This default data can be used by each plugin, which has a reference to the EngageModel.     Property Name  Type  Description      pluginsInfo  Backbone Model  Contains Information's of each plugin    pluginModels  Backbone Collection  Contains the plugin models    urlParameters  Object  Contains the data of the URL parameters.",
            "title": "Engage Model"
        },
        {
            "location": "/modules/player/core.reference/#plugin-object",
            "text": "Each plugin  must  create and return a object with some properties which are set by the plugin itself. It is recommend to keep a reference to the object because some properties are set by the core after the plugin is processed.     Property Name  Type  Description      name  String  Name of the plugin, e.g. \"Engage Controls\".  This property is set by the plugin.    type  String  Type of the plugin, e.g. \"engage_controls\", see the plugin table in Architecture for the other plugin types.  This property is set by the plugin.    version  String  Version of plugin.  This property is set by the plugin.    styles  Array of Strings  Array of the paths of css files relative to the static folder of each plugin .  This property is set by the plugin.    template  String  Before the plugin object is returned by the plugin logic, the template property contains the path to the template relative to the static folder.  The path property is set first by the plugin . After the plugin object is returned and the Theodul core processed the plugin, the template property is filled with the real template data and can be used to re-render the view.    container  String  Contains the ID of the HTML div container, which contains the rendered template. This can be used to re-render the view.  This property is set by the core.    pluginPath  String  Contains the absolute path of the plugin.   This property is set by the core.    events  Object  Contains all events which are used of this plugin. Each handled and each triggered event.",
            "title": "Plugin Object"
        },
        {
            "location": "/modules/player/events/",
            "text": "Theodul Pass Player - Events\n\n\nA Theodul Pass Player plugin can trigger and/or subscribe to events.\n\n\nAn event is defined in the events section of the plugin and looks like this:\n\n\nNAME: new Engage.Event(\"MODULE:NAME\", \"DESCRIPTION\", \"OPTION\")\n\n\n\nThe event has the event name \"MODULE:NAME\", the description DESCRIPTION and one of the options \"trigger\", \"handler\" or \"both\" as OPTION. When the plugin just triggers the event, the option is \"trigger\", when it just handles the events the option is \"handler\" and when it does both - trigger and handle it - the option is \"both\".\n\n\nAn event can be triggered via\n\n\nEngage.trigger(plugin.events.NAME.getName(), [parameter(s)]);\n\n\n\nand can be subscribed to via\n\n\nEngage.on(plugin.events.NAME.getName(), function () {});\n\n\n\nThe following list contains all events of the Core + of all official plugins, sorted alphabetically after \"Event name\" for version 1.0 of Feb 12, 2015.\n\n\nCurrently official plugins are\n\n\n\n\nControls\n\n\nMHConnection\n\n\nNotifications\n\n\nUsertracking\n\n\nDescription\n\n\nDescription (Tab)\n\n\nSlide text (Tab)\n\n\nShortcuts (Tab)\n\n\nTimeline statistics\n\n\nVideodisplay\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEvent name\n\n\nAdditional parameters\n\n\nDescription\n\n\nTriggered in\n\n\nHandled in\n\n\n\n\n\n\n\n\n\n\ncoreInit\n\n\nCore:init\n\n\n\n\n\n\nCore\n\n\n\n\n\n\n\n\nplugin_load_done\n\n\nCore:plugin_load_done\n\n\n\n\n\n\nCore\n\n\nCore, Controls, MHConnection, Notifications, Usertracking, Description, Description (Tab), Slide text (Tab), Shortcuts (Tab), Timeline statistics, Videodisplay\n\n\n\n\n\n\ntimelineplugin_closed\n\n\nEngage:timelineplugin_closed\n\n\nNote: No \"Engage Event\", just use as string, example: Engage.on(\"Engage:timelineplugin_closed\", function() {});\n\n\nwhen the timeline plugin container closed\n\n\nCore\n\n\n\n\n\n\n\n\ntimelineplugin_opened\n\n\nEngage:timelineplugin_opened\n\n\nNote: No \"Engage Event\", just use as string, example: Engage.on(\"Engage:timelineplugin_opened\", function() {});\n\n\nwhen the timeline plugin container opened\n\n\nCore\n\n\nTimeline statistics\n\n\n\n\n\n\ngetMediaInfo\n\n\nMhConnection:getMediaInfo\n\n\n\n\n\n\n\n\nMHConnection\n\n\n\n\n\n\ngetMediaPackage\n\n\nMhConnection:getMediaPackage\n\n\n\n\n\n\n\n\nMHConnection\n\n\n\n\n\n\nmediaPackageModelError\n\n\nMhConnection:mediaPackageModelError\n\n\n\n\n\n\nMHConnection\n\n\nCore, Controls, Notifications, Usertracking, Description, Description (Tab), Slide text (Tab), Shortcuts (Tab), Timeline statistics, Videodisplay\n\n\n\n\n\n\ncustomError\n\n\nNotification:customError\n\n\nmsg: The message to display\n\n\nan error occurred\n\n\nCore, Controls, Videodisplay\n\n\nNotifications\n\n\n\n\n\n\ncustomNotification\n\n\nNotification:customNotification\n\n\nmsg: The message to display\n\n\na custom message\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\ncustomOKMessage\n\n\nNotification:customOKMessage\n\n\nmsg: The message to display\n\n\na custom message with an OK button\n\n\nControls\n\n\nNotifications\n\n\n\n\n\n\ncustomSuccess\n\n\nNotification:customSuccess\n\n\nmsg: The message to display\n\n\na custom success message\n\n\nCore, Controls\n\n\nNotifications\n\n\n\n\n\n\nsegmentMouseout\n\n\nSegment:mouseOut\n\n\nno: Segment number\n\n\nthe mouse is off a segment\n\n\nControls, Slide text (Tab)\n\n\nControls, Slide text (Tab)\n\n\n\n\n\n\nsegmentMouseover\n\n\nSegment:mouseOver\n\n\nno: Segment number\n\n\nthe mouse is over a segment\n\n\nControls, Slide text (Tab)\n\n\nControls, Slide text (Tab)\n\n\n\n\n\n\nsliderMousein\n\n\nSlider:mouseIn\n\n\n\n\nthe mouse entered the slider\n\n\nControls\n\n\n\n\n\n\n\n\nsliderMouseout\n\n\nSlider:mouseOut\n\n\n\n\nthe mouse is off the slider\n\n\nControls\n\n\n\n\n\n\n\n\nsliderMousemove\n\n\nSlider:mouseMoved\n\n\ntimeInMs: The time on the hovered position in ms\n\n\nthe mouse is moving over the slider\n\n\nControls\n\n\n\n\n\n\n\n\nsliderStart\n\n\nSlider:start\n\n\n\n\nslider started\n\n\nControls\n\n\n\n\n\n\n\n\nsliderStop\n\n\nSlider:stop\n\n\ntime: The time the slider stopped at\n\n\nslider stopped\n\n\nControls\n\n\nVideodisplay\n\n\n\n\n\n\naspectRatioSet\n\n\nVideo:aspectRatioSet\n\n\nas: (array) as[0] = width, as[1] = height, as[2] = aspect ratio in %\n\n\nthe aspect ratio has been calculated\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\naudioCodecNotSupported\n\n\nVideo:audioCodecNotSupported\n\n\n\n\nwhen the audio codec seems not to be supported by the browser\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\nautoplay\n\n\nVideo:autoplay\n\n\n\n\nautoplay the video\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nbufferedAndAutoplaying\n\n\nVideo:bufferedAndAutoplaying\n\n\n\n\nbuffering successful, was playing, autoplaying now\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\nbufferedButNotAutoplaying\n\n\nVideo:bufferedButNotAutoplaying\n\n\n\n\nbuffering successful, was not playing, not autoplaying now\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\nbuffering\n\n\nVideo:buffering\n\n\n\n\nvideo is buffering\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\nended\n\n\nVideo:ended\n\n\ntriggeredByMaster: Whether or not the event has been triggered by master\n\n\nvideo ended\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\nfullscreenCancel\n\n\nVideo:fullscreenCancel\n\n\n\n\ncancel fullscreen\n\n\nControls, Videodisplay\n\n\nVideodisplay\n\n\n\n\n\n\nfullscreenChange\n\n\nVideo:fullscreenChange\n\n\n\n\na fullscreen change happened\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\nfullscreenEnable\n\n\nVideo:fullscreenEnable\n\n\n\n\nenable fullscreen\n\n\nControls, Core\n\n\nControls, Videodisplay\n\n\n\n\n\n\nisAudioOnly\n\n\nVideo:isAudioOnly\n\n\naudio: true if audio only, false else\n\n\nwhether it's audio only or not\n\n\nVideodisplay\n\n\nControls, Notifications\n\n\n\n\n\n\ninitialSeek\n\n\nVideo:initialSeek\n\n\ntime: The time to seek to\n\n\nSeeks initially after all plugins have been loaded after a short delay\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nmute\n\n\nVideo:mute\n\n\n\n\nmute\n\n\nVideodisplay\n\n\nVideodisplay\n\n\n\n\n\n\nmuteToggle\n\n\nVideo:muteToggle\n\n\n\n\ntoggle mute and unmute\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nnextChapter\n\n\nVideo:nextChapter\n\n\n\n\nCore\n\n\n\n\n\n\n\n\n\n\nnumberOfVideodisplaysSet\n\n\nVideo:numberOfVideodisplaysSet\n\n\nno: Number of videodisplays\n\n\nthe number of videodisplays has been set\n\n\nVideodisplay\n\n\n\n\n\n\n\n\npause\n\n\nVideo:pause\n\n\ntriggeredByMaster: Whether or not the event has been triggered by master\n\n\npauses the video\n\n\n\n\n\n\n\n\n\n\nCore, Controls, Videodisplay\n\n\nControls, Videodisplay\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplay\n\n\nVideo:play\n\n\ntriggeredByMaster: Whether or not the event has been triggered by master\n\n\nplays the video\n\n\nCore, Controls, Videodisplay\n\n\nControls,Videodisplay\n\n\n\n\n\n\nplayPause\n\n\nVideo:playPause\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\npreviousChapter\n\n\nVideo:previousChapter\n\n\n\n\n\n\nCore\n\n\n\n\n\n\n\n\nplaybackRateChanged\n\n\nVideo:playbackRateChanged\n\n\nrate: The video playback rate (0.0-x, default: 1.0)\n\n\nThe video playback rate changed\n\n\nControls\n\n\nControls, Videodisplay\n\n\n\n\n\n\nplaybackRateIncrease\n\n\nVideo:playbackRateIncrease\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nplaybackRateDecrease\n\n\nVideo:playbackRateDecrease\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nplayerLoaded\n\n\nVideo:playerLoaded\n\n\n\n\nplayer loaded successfully\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nready\n\n\nVideo:ready\n\n\n\n\nall videos loaded successfully\n\n\nVideodisplay\n\n\nControls, Notifications\n\n\n\n\n\n\nseek\n\n\nVideo:seek\n\n\ntime: Current time in seconds  seek video to a given position in seconds\n\n\nCore, Controls, Slide text (Tab)\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nseekLeft\n\n\nVideo:seekLeft\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nseekRight\n\n\nVideo:seekRight\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nsynchronizing\n\n\nVideo:synchronizing\n\n\n\n\nsynchronizing videos with the master video\n\n\nVideodisplay\n\n\n\n\n\n\n\n\ntimeupdate\n\n\nVideo:timeupdate\n\n\ntime: Current time in seconds, triggeredByMaster: Whether or not the event has been triggered by master\n\n\na timeupdate happened\n\n\nVideodisplay\n\n\nControls, Usertracking\n\n\n\n\n\n\nqualitySet\n\n\nVideo:qualitySet\n\n\nquality: the quality that has been set a video quality has been set\n\n\nControls\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nunmute\n\n\nVideo:unmute\n\n\n\n\nunmute\n\n\nControls\n\n\nControls\n\n\n\n\n\n\nusingFlash\n\n\nVideo:usingFlash\n\n\nflash: true if flash is being used, false else\n\n\nflash is being used\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\nvideoFormatsFound\n\n\nVideo:videoFormatsFound\n\n\nformat: array of video formats if different video formats (qualities) have been found\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\n\n\nvolumechange\n\n\nVideo:volumechange\n\n\nvol: Current volume (0 is off (muted), 1.0 is all the way up, 0.5 is half way)\n\n\na volume change happened\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nvolumeDown\n\n\nVideo:volumeDown\n\n\n\n\n\n\nCore\n\n\nControls\n\n\n\n\n\n\nvolumeGet\n\n\nVideo:volumeGet\n\n\ncallback: A callback function with the current volume as a parameter\n\n\nget the volume\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nvolumeSet\n\n\nVideo:volumeSet\n\n\npercentAsDecimal: Volume to set (0 is off (muted), 1.0 is all the way up, 0.5 is half way)\n\n\nset the volume\n\n\nControls\n\n\nControls, Videodisplay\n\n\n\n\n\n\nvolumeUp\n\n\nVideo:volumeUp\n\n\n\n\n\n\nCore\n\n\nControls",
            "title": "Events"
        },
        {
            "location": "/modules/player/events/#theodul-pass-player-events",
            "text": "A Theodul Pass Player plugin can trigger and/or subscribe to events.  An event is defined in the events section of the plugin and looks like this:  NAME: new Engage.Event(\"MODULE:NAME\", \"DESCRIPTION\", \"OPTION\")  The event has the event name \"MODULE:NAME\", the description DESCRIPTION and one of the options \"trigger\", \"handler\" or \"both\" as OPTION. When the plugin just triggers the event, the option is \"trigger\", when it just handles the events the option is \"handler\" and when it does both - trigger and handle it - the option is \"both\".  An event can be triggered via  Engage.trigger(plugin.events.NAME.getName(), [parameter(s)]);  and can be subscribed to via  Engage.on(plugin.events.NAME.getName(), function () {});  The following list contains all events of the Core + of all official plugins, sorted alphabetically after \"Event name\" for version 1.0 of Feb 12, 2015.  Currently official plugins are   Controls  MHConnection  Notifications  Usertracking  Description  Description (Tab)  Slide text (Tab)  Shortcuts (Tab)  Timeline statistics  Videodisplay      Name  Event name  Additional parameters  Description  Triggered in  Handled in      coreInit  Core:init    Core     plugin_load_done  Core:plugin_load_done    Core  Core, Controls, MHConnection, Notifications, Usertracking, Description, Description (Tab), Slide text (Tab), Shortcuts (Tab), Timeline statistics, Videodisplay    timelineplugin_closed  Engage:timelineplugin_closed  Note: No \"Engage Event\", just use as string, example: Engage.on(\"Engage:timelineplugin_closed\", function() {});  when the timeline plugin container closed  Core     timelineplugin_opened  Engage:timelineplugin_opened  Note: No \"Engage Event\", just use as string, example: Engage.on(\"Engage:timelineplugin_opened\", function() {});  when the timeline plugin container opened  Core  Timeline statistics    getMediaInfo  MhConnection:getMediaInfo     MHConnection    getMediaPackage  MhConnection:getMediaPackage     MHConnection    mediaPackageModelError  MhConnection:mediaPackageModelError    MHConnection  Core, Controls, Notifications, Usertracking, Description, Description (Tab), Slide text (Tab), Shortcuts (Tab), Timeline statistics, Videodisplay    customError  Notification:customError  msg: The message to display  an error occurred  Core, Controls, Videodisplay  Notifications    customNotification  Notification:customNotification  msg: The message to display  a custom message  Videodisplay  Notifications    customOKMessage  Notification:customOKMessage  msg: The message to display  a custom message with an OK button  Controls  Notifications    customSuccess  Notification:customSuccess  msg: The message to display  a custom success message  Core, Controls  Notifications    segmentMouseout  Segment:mouseOut  no: Segment number  the mouse is off a segment  Controls, Slide text (Tab)  Controls, Slide text (Tab)    segmentMouseover  Segment:mouseOver  no: Segment number  the mouse is over a segment  Controls, Slide text (Tab)  Controls, Slide text (Tab)    sliderMousein  Slider:mouseIn   the mouse entered the slider  Controls     sliderMouseout  Slider:mouseOut   the mouse is off the slider  Controls     sliderMousemove  Slider:mouseMoved  timeInMs: The time on the hovered position in ms  the mouse is moving over the slider  Controls     sliderStart  Slider:start   slider started  Controls     sliderStop  Slider:stop  time: The time the slider stopped at  slider stopped  Controls  Videodisplay    aspectRatioSet  Video:aspectRatioSet  as: (array) as[0] = width, as[1] = height, as[2] = aspect ratio in %  the aspect ratio has been calculated  Videodisplay  Controls    audioCodecNotSupported  Video:audioCodecNotSupported   when the audio codec seems not to be supported by the browser  Videodisplay  Notifications    autoplay  Video:autoplay   autoplay the video  Core  Videodisplay    bufferedAndAutoplaying  Video:bufferedAndAutoplaying   buffering successful, was playing, autoplaying now  Videodisplay  Notifications    bufferedButNotAutoplaying  Video:bufferedButNotAutoplaying   buffering successful, was not playing, not autoplaying now  Videodisplay  Notifications    buffering  Video:buffering   video is buffering  Videodisplay  Notifications    ended  Video:ended  triggeredByMaster: Whether or not the event has been triggered by master  video ended  Videodisplay  Controls    fullscreenCancel  Video:fullscreenCancel   cancel fullscreen  Controls, Videodisplay  Videodisplay    fullscreenChange  Video:fullscreenChange   a fullscreen change happened  Videodisplay  Controls    fullscreenEnable  Video:fullscreenEnable   enable fullscreen  Controls, Core  Controls, Videodisplay    isAudioOnly  Video:isAudioOnly  audio: true if audio only, false else  whether it's audio only or not  Videodisplay  Controls, Notifications    initialSeek  Video:initialSeek  time: The time to seek to  Seeks initially after all plugins have been loaded after a short delay  Core  Videodisplay    mute  Video:mute   mute  Videodisplay  Videodisplay    muteToggle  Video:muteToggle   toggle mute and unmute  Core  Videodisplay    nextChapter  Video:nextChapter   Core      numberOfVideodisplaysSet  Video:numberOfVideodisplaysSet  no: Number of videodisplays  the number of videodisplays has been set  Videodisplay     pause  Video:pause  triggeredByMaster: Whether or not the event has been triggered by master  pauses the video      Core, Controls, Videodisplay  Controls, Videodisplay        play  Video:play  triggeredByMaster: Whether or not the event has been triggered by master  plays the video  Core, Controls, Videodisplay  Controls,Videodisplay    playPause  Video:playPause    Core  Videodisplay    previousChapter  Video:previousChapter    Core     playbackRateChanged  Video:playbackRateChanged  rate: The video playback rate (0.0-x, default: 1.0)  The video playback rate changed  Controls  Controls, Videodisplay    playbackRateIncrease  Video:playbackRateIncrease    Core  Videodisplay    playbackRateDecrease  Video:playbackRateDecrease    Core  Videodisplay    playerLoaded  Video:playerLoaded   player loaded successfully  Videodisplay     ready  Video:ready   all videos loaded successfully  Videodisplay  Controls, Notifications    seek  Video:seek  time: Current time in seconds  seek video to a given position in seconds  Core, Controls, Slide text (Tab)  Videodisplay     seekLeft  Video:seekLeft    Core  Videodisplay    seekRight  Video:seekRight    Core  Videodisplay    synchronizing  Video:synchronizing   synchronizing videos with the master video  Videodisplay     timeupdate  Video:timeupdate  time: Current time in seconds, triggeredByMaster: Whether or not the event has been triggered by master  a timeupdate happened  Videodisplay  Controls, Usertracking    qualitySet  Video:qualitySet  quality: the quality that has been set a video quality has been set  Controls  Videodisplay     unmute  Video:unmute   unmute  Controls  Controls    usingFlash  Video:usingFlash  flash: true if flash is being used, false else  flash is being used  Videodisplay  Controls    videoFormatsFound  Video:videoFormatsFound  format: array of video formats if different video formats (qualities) have been found  Videodisplay  Controls     volumechange  Video:volumechange  vol: Current volume (0 is off (muted), 1.0 is all the way up, 0.5 is half way)  a volume change happened  Videodisplay     volumeDown  Video:volumeDown    Core  Controls    volumeGet  Video:volumeGet  callback: A callback function with the current volume as a parameter  get the volume  Videodisplay     volumeSet  Video:volumeSet  percentAsDecimal: Volume to set (0 is off (muted), 1.0 is all the way up, 0.5 is half way)  set the volume  Controls  Controls, Videodisplay    volumeUp  Video:volumeUp    Core  Controls",
            "title": "Theodul Pass Player - Events"
        },
        {
            "location": "/modules/player/storage/",
            "text": "How to store data in the browser persistently\n\n\nThe Theodul Pass Player uses basil.js for storing persistent data such as the volume and the playback rate.\n\n\nBasil.js unifies localstorage, cookies and session storage and provides an easy-to-use JavaScript API.\n\n\nExample Usage\n\n\nIn your plugin you just have to require the basil lib which is being distributed globally:\n\n\ndefine([..., \"basil\", ...], function(..., Basil, ...) {\n    ...\n}\n\n\n\nAfter that basil needs to be set up:\n\n\nvar basilOptions = {\n    namespace: 'mhStorage'\n};\nBasil = new window.Basil(basilOptions);\n\n\n\nThe default plugins have \"mhStorage\" as their namespace, feel free to set your own. The default storage is the localstorage; if the localstorage is not available, a cookie is being used and so on.\n\n\nAfter setting up basil, the usage is straightforward:\n\n\nBasil.set(\"someKey\", \"someValue); // set a value\nBasil.get(\"someKey\"); // get a value",
            "title": "Storage"
        },
        {
            "location": "/modules/player/storage/#how-to-store-data-in-the-browser-persistently",
            "text": "The Theodul Pass Player uses basil.js for storing persistent data such as the volume and the playback rate.  Basil.js unifies localstorage, cookies and session storage and provides an easy-to-use JavaScript API.",
            "title": "How to store data in the browser persistently"
        },
        {
            "location": "/modules/player/storage/#example-usage",
            "text": "In your plugin you just have to require the basil lib which is being distributed globally:  define([..., \"basil\", ...], function(..., Basil, ...) {\n    ...\n}  After that basil needs to be set up:  var basilOptions = {\n    namespace: 'mhStorage'\n};\nBasil = new window.Basil(basilOptions);  The default plugins have \"mhStorage\" as their namespace, feel free to set your own. The default storage is the localstorage; if the localstorage is not available, a cookie is being used and so on.  After setting up basil, the usage is straightforward:  Basil.set(\"someKey\", \"someValue); // set a value\nBasil.get(\"someKey\"); // get a value",
            "title": "Example Usage"
        },
        {
            "location": "/modules/player/plugin.development/",
            "text": "How To Create A New Plugin\n\n\nPlugin Archetype\n\n\nThe \nMaven Archetype Plugin\n provides a convenient mechanism\nfor automatically generating projects. Project templates are called Archetypes and they are basically maven artifacts of\na special kind of packaging, \u2018maven-archetype\u2019.\n\n\nWith the Theodul Plugin Archetype you can create a new plugin project in no time and start writing the plugin\u2019s business\nlogic right away, without caring about the POM or SCR component declarations.\n\n\nInstallation\n\n\nThe Theodul Plugin Archetype is included in the Opencast source code (Theodul Player branch) in the modules directory.\nTo make the artifact available on your system you need to install it like any other atrifacts. In the Opencast source\ndirectory type:\n\n\n> cd modules/matterhorn-engage-theodul-plugin-archetype\n> mvn install\n\n\n\nAfter successful build and installation the archetype is available in your system.\n\n\nGenerating a new plugin\n\n\nTo generate a new plugin project simply go to the modules directory inside the Opencast source directory and type:\n\n\n> mvn archetype:generate -DarchetypeGroupId=org.opencastproject -DarchetypeArtifactId=matterhorn-theodul-plugin\n\n\n\nProvided the archetype is installed maven will now ask you for the properties configuration for the new project:\n\n\n[INFO] Generating project in Interactive mode\n[INFO] Archetype [org.opencastproject:matterhorn-theodul-plugin:1.5-SNAPSHOT] found in catalog local\nDefine value for property 'groupId': : org.opencastproject\nDefine value for property 'artifactId': : matterhorn-engage-theodul-plugin-test\nDefine value for property 'version': 1.0-SNAPSHOT: : 1.5-SNAPSHOT\nDefine value for property 'package': org.opencastproject: : org.opencastproject.engage.theodul.plugin.custom.test\nDefine value for property 'plugin_description': : A test plugin\nDefine value for property 'plugin_name': : testName \nDefine value for property 'plugin_type': : custom\nDefine value for property 'plugin_version': : 0.1\nDefine value for property 'plugin_rest': : false\nConfirm properties configuration:\ngroupId: org.opencastproject\nartifactId: matterhorn-engage-theodul-plugin-test\nversion: 1.5-SNAPSHOT\npackage: org.opencastproject.engage.theodul.plugin.test\nplugin_description: A test plugin\nplugin_name: test\nplugin_rest: true\n Y: : y\n[INFO] ----------------------------------------------------------------------------\n[INFO] Using following parameters for creating project from Archetype: matterhorn-theodul-plugin:1.5-SNAPSHOT\n[INFO] ----------------------------------------------------------------------------\n[INFO] Parameter: groupId, Value: org.opencastproject\n[INFO] Parameter: artifactId, Value: matterhorn-engage-theodul-plugin-test\n[INFO] Parameter: version, Value: 1.5-SNAPSHOT\n[INFO] Parameter: package, Value: org.opencastproject.engage.theodul.plugin.test\n[INFO] Parameter: packageInPathFormat, Value: org/opencastproject/engage/theodul/plugin/test\n[INFO] Parameter: package, Value: org.opencastproject.engage.theodul.plugin.test\n[INFO] Parameter: version, Value: 1.5-SNAPSHOT\n[INFO] Parameter: plugin_description, Value: A test plugin\n[INFO] Parameter: plugin_name, Value: test\n[INFO] Parameter: groupId, Value: org.opencastproject\n[INFO] Parameter: plugin_rest, Value: true\n[INFO] Parameter: artifactId, Value: matterhorn-engage-theodul-plugin-test\n[INFO] project created from Archetype in dir: /home/wulff/code/UOS/plugin-archetype/test/matterhorn-engage-theodul-plugin-test\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 3:39.195s\n[INFO] Finished at: Thu Jan 23 15:48:37 CET 2014\n[INFO] Final Memory: 15M/308M\n[INFO] ------------------------------------------------------------------------\n\n\n\nThere you go, the newly created plugin project is waiting to be filled with life in the directory that is named after\nthe atrifactId you entered before.\n\n\nProject Properties\n\n\nIn addition to the above explanation, here is a description of the properties you have to specify when generating a new\nproject with the Theodul Plugin Archetype:\n\n\ngroupId\n\n\nMaven group ID. For the Opencast developers this is\n\n\norg.opencastproject\n\n\n\nartifactId\n\n\nMaven artifact ID. Name by which your project is identified as an artifact by maven. Think of it as the project name. It\nwill also be used as the name for your projects root directory. During the course of the Theodul project the following\nnaming scheme came up:\n\n\nmatterhorn-engage-theodul-plugin-<plugin type>-<plugin name>\n\n\n\nversion\n\n\nThe project version. For Opencast developers: simply put in the version of the Opencast source tree your are working\non.\n\n\npackage\n\n\nThe Java package in which the source for the back end part of your plugin will live. The following scheme is used by the\nTheodul developers:\n\n\norg.opencastproject.engage.theodul.plugin.<plugin type>.<plugin name>\n\n\n\nplugin_version\n\n\nThe version of the plugin itself. This is not to be confused with the maven project version which will, for instance, be\nupdated when the Opencast version changes.\n\n\nplugin_type\n\n\nThe type of the plugin to be created. See https://opencast.jira.com/wiki/display/MH/Architecture\nPossible types are: custom, controls, timeline, video, description, tab\n\n\nplugin_name\n\n\nThe name by which your plugin will be registered by the plugin manager when running.\n\n\nplugin_description\n\n\n(optional) A short description of the plugin. The description will be provided by the \nplugin list endpoint\n\n together with the other plugin data.\n\n\nplugin_rest\n\n\n(boolean) Whether or not the plugin should provide a Opencast Rest endpoint. If set to true, the Java class that makes\nup the back end part of your plugin will be augmented with the annotations necessary to work as a Rest endpoint provider\nin Opencast. Also an example endpoint (GET:sayHello) will be generated.\n\n\nExample Plugin\n\n\nHave a look at the \nsnow showcase example plugin (custom)\n.\n\n\nDebugging\n\n\nTo display debug information in the developer console, add the following parameters to the URL:\n\n\nDisplay debug information\n\n\n&debug=true\n\n\n\nDisplay event debug information\n\n\n&debugEvents=true",
            "title": "Plugin Development"
        },
        {
            "location": "/modules/player/plugin.development/#how-to-create-a-new-plugin",
            "text": "",
            "title": "How To Create A New Plugin"
        },
        {
            "location": "/modules/player/plugin.development/#plugin-archetype",
            "text": "The  Maven Archetype Plugin  provides a convenient mechanism\nfor automatically generating projects. Project templates are called Archetypes and they are basically maven artifacts of\na special kind of packaging, \u2018maven-archetype\u2019.  With the Theodul Plugin Archetype you can create a new plugin project in no time and start writing the plugin\u2019s business\nlogic right away, without caring about the POM or SCR component declarations.",
            "title": "Plugin Archetype"
        },
        {
            "location": "/modules/player/plugin.development/#installation",
            "text": "The Theodul Plugin Archetype is included in the Opencast source code (Theodul Player branch) in the modules directory.\nTo make the artifact available on your system you need to install it like any other atrifacts. In the Opencast source\ndirectory type:  > cd modules/matterhorn-engage-theodul-plugin-archetype\n> mvn install  After successful build and installation the archetype is available in your system.",
            "title": "Installation"
        },
        {
            "location": "/modules/player/plugin.development/#generating-a-new-plugin",
            "text": "To generate a new plugin project simply go to the modules directory inside the Opencast source directory and type:  > mvn archetype:generate -DarchetypeGroupId=org.opencastproject -DarchetypeArtifactId=matterhorn-theodul-plugin  Provided the archetype is installed maven will now ask you for the properties configuration for the new project:  [INFO] Generating project in Interactive mode\n[INFO] Archetype [org.opencastproject:matterhorn-theodul-plugin:1.5-SNAPSHOT] found in catalog local\nDefine value for property 'groupId': : org.opencastproject\nDefine value for property 'artifactId': : matterhorn-engage-theodul-plugin-test\nDefine value for property 'version': 1.0-SNAPSHOT: : 1.5-SNAPSHOT\nDefine value for property 'package': org.opencastproject: : org.opencastproject.engage.theodul.plugin.custom.test\nDefine value for property 'plugin_description': : A test plugin\nDefine value for property 'plugin_name': : testName \nDefine value for property 'plugin_type': : custom\nDefine value for property 'plugin_version': : 0.1\nDefine value for property 'plugin_rest': : false\nConfirm properties configuration:\ngroupId: org.opencastproject\nartifactId: matterhorn-engage-theodul-plugin-test\nversion: 1.5-SNAPSHOT\npackage: org.opencastproject.engage.theodul.plugin.test\nplugin_description: A test plugin\nplugin_name: test\nplugin_rest: true\n Y: : y\n[INFO] ----------------------------------------------------------------------------\n[INFO] Using following parameters for creating project from Archetype: matterhorn-theodul-plugin:1.5-SNAPSHOT\n[INFO] ----------------------------------------------------------------------------\n[INFO] Parameter: groupId, Value: org.opencastproject\n[INFO] Parameter: artifactId, Value: matterhorn-engage-theodul-plugin-test\n[INFO] Parameter: version, Value: 1.5-SNAPSHOT\n[INFO] Parameter: package, Value: org.opencastproject.engage.theodul.plugin.test\n[INFO] Parameter: packageInPathFormat, Value: org/opencastproject/engage/theodul/plugin/test\n[INFO] Parameter: package, Value: org.opencastproject.engage.theodul.plugin.test\n[INFO] Parameter: version, Value: 1.5-SNAPSHOT\n[INFO] Parameter: plugin_description, Value: A test plugin\n[INFO] Parameter: plugin_name, Value: test\n[INFO] Parameter: groupId, Value: org.opencastproject\n[INFO] Parameter: plugin_rest, Value: true\n[INFO] Parameter: artifactId, Value: matterhorn-engage-theodul-plugin-test\n[INFO] project created from Archetype in dir: /home/wulff/code/UOS/plugin-archetype/test/matterhorn-engage-theodul-plugin-test\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 3:39.195s\n[INFO] Finished at: Thu Jan 23 15:48:37 CET 2014\n[INFO] Final Memory: 15M/308M\n[INFO] ------------------------------------------------------------------------  There you go, the newly created plugin project is waiting to be filled with life in the directory that is named after\nthe atrifactId you entered before.",
            "title": "Generating a new plugin"
        },
        {
            "location": "/modules/player/plugin.development/#project-properties",
            "text": "In addition to the above explanation, here is a description of the properties you have to specify when generating a new\nproject with the Theodul Plugin Archetype:",
            "title": "Project Properties"
        },
        {
            "location": "/modules/player/plugin.development/#groupid",
            "text": "Maven group ID. For the Opencast developers this is  org.opencastproject",
            "title": "groupId"
        },
        {
            "location": "/modules/player/plugin.development/#artifactid",
            "text": "Maven artifact ID. Name by which your project is identified as an artifact by maven. Think of it as the project name. It\nwill also be used as the name for your projects root directory. During the course of the Theodul project the following\nnaming scheme came up:  matterhorn-engage-theodul-plugin-<plugin type>-<plugin name>",
            "title": "artifactId"
        },
        {
            "location": "/modules/player/plugin.development/#version",
            "text": "The project version. For Opencast developers: simply put in the version of the Opencast source tree your are working\non.",
            "title": "version"
        },
        {
            "location": "/modules/player/plugin.development/#package",
            "text": "The Java package in which the source for the back end part of your plugin will live. The following scheme is used by the\nTheodul developers:  org.opencastproject.engage.theodul.plugin.<plugin type>.<plugin name>",
            "title": "package"
        },
        {
            "location": "/modules/player/plugin.development/#plugin_version",
            "text": "The version of the plugin itself. This is not to be confused with the maven project version which will, for instance, be\nupdated when the Opencast version changes.",
            "title": "plugin_version"
        },
        {
            "location": "/modules/player/plugin.development/#plugin_type",
            "text": "The type of the plugin to be created. See https://opencast.jira.com/wiki/display/MH/Architecture\nPossible types are: custom, controls, timeline, video, description, tab",
            "title": "plugin_type"
        },
        {
            "location": "/modules/player/plugin.development/#plugin_name",
            "text": "The name by which your plugin will be registered by the plugin manager when running.",
            "title": "plugin_name"
        },
        {
            "location": "/modules/player/plugin.development/#plugin_description",
            "text": "(optional) A short description of the plugin. The description will be provided by the  plugin list endpoint  together with the other plugin data.",
            "title": "plugin_description"
        },
        {
            "location": "/modules/player/plugin.development/#plugin_rest",
            "text": "(boolean) Whether or not the plugin should provide a Opencast Rest endpoint. If set to true, the Java class that makes\nup the back end part of your plugin will be augmented with the annotations necessary to work as a Rest endpoint provider\nin Opencast. Also an example endpoint (GET:sayHello) will be generated.",
            "title": "plugin_rest"
        },
        {
            "location": "/modules/player/plugin.development/#example-plugin",
            "text": "Have a look at the  snow showcase example plugin (custom) .",
            "title": "Example Plugin"
        },
        {
            "location": "/modules/player/plugin.development/#debugging",
            "text": "To display debug information in the developer console, add the following parameters to the URL:  Display debug information  &debug=true  Display event debug information  &debugEvents=true",
            "title": "Debugging"
        },
        {
            "location": "/modules/player/testing/",
            "text": "How To Test With Phantom.js and Jasmine\n\n\nIntegration Of Jasmine Into The Build Process (Maven)\n\n\nJasmine\n is integrated with the\n\njasmine-maven-plugin\n into the maven build process. Therefore only the pom.xml file\nwill be enhanced by the following code, which specifies the \njasmine-maven-plugin\n\nas plugin for the build process. The configuration of the jasmine-maven-plugin is also done in this file. The meaning of\nevery configuration parameter can be looked up on the jasmine-maven-plugin project page under this\n\nlink\n. The following configuration uses a the\nspecRunnerTemplate \nREQUIRE_JS\n in order to function properly with \nRequireJS\n. Further\ninformation about spec runner templates can be found\n\nhere\n. On the next build the needed\ndependencies will be automatically resolved just like it is in the nature of maven.\n\n\npom.xml\n\n\n<build>\n<plugins>\n    ...\n      <plugin>\n        <groupId>com.github.searls</groupId>\n        <artifactId>jasmine-maven-plugin</artifactId>\n        <version>1.3.1.2</version>\n        <executions>\n          <execution>\n            <goals>\n              <goal>test</goal>\n            </goals>\n          </execution>\n        </executions>\n        <configuration>\n          <preloadSources>\n            <source>${project.basedir}/src/test/resources/js/lib/require.js</source>\n          </preloadSources>\n          <jsSrcDir>${project.basedir}/src/main/resources/static</jsSrcDir>\n          <sourceIncludes>\n            <include>**/*.js</include>\n            <include>**/*.coffee</include>\n          </sourceIncludes>\n          <jsTestSrcDir>${project.basedir}/src/test/resources/js/spec</jsTestSrcDir>\n          <specIncludes>\n            <include>**/spec_helper.js</include>\n            <include>**/*.js</include>\n            <include>**/*.coffee</include>\n          </specIncludes>\n          <specRunnerTemplate>REQUIRE_JS</specRunnerTemplate>\n          <format>progress</format>\n        </configuration>\n      </plugin>\n  </plugins>\n</build>\n\n\n\nTesting The Engage Core\n\n\nThis chapter gives an overview over the directory structure used for testing the theodul engage core module, the configuration for the specs in the \nspec_helper.js\n and how to write specs for the core.\n\n\nDirectory Structure\n\n\nThe test relevant files are located in the \nsrc/test/resources/ui/js/spec\n tree. Files that filename ends on \n_spec.js\n are considered as files with executable tests. The \nspec_helper.js\n in configured in the \npom.xml\n for the initial setup.\n\n\nDirectory Structure Testing Engage Core\n\n\n|-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------spec    #Tests the *_spec.js and the helper file spec_helper.js\n\n\n\nSpec Helper\n\n\nThe file \nspec_helper.js\n takes over the configuration of RequireJS which is usually done by the \nengage_init.js\n. The\npaths differ slighty from the player has at runtime.\n\n\nspec_helper for engage_core module\n\n\n/*global requirejs*/\nrequirejs.config({\n  baseUrl: 'src/js/lib',\n  paths: {\n    require: 'require',\n    jquery: 'jquery',\n    underscore: 'underscore',\n    backbone: 'backbone',\n    engage: '../engage',\n    plugins: '../engage/plugin/*/static'\n  },\n  shim: {\n    'backbone': {\n      //script dependencies\n      deps: ['underscore', 'jquery'],\n      //global variable\n      exports: 'Backbone'\n    },\n    'underscore': {\n      //global variable\n      exports: '_'\n    }\n  }\n});\nvar PLUGIN_MANAGER_PATH = '/engage/theodul/manager/list.json';\nvar PLUGIN_PATH = '/engage/theodul/plugin/';\n\n\n\nTesting Engage Plugins\n\n\nThis chapter gives an overview over the directory structure used for testing a theodul engage plugin module, the\nconfiguration for the specs in the \nspec_helper.js\n and how to write specs for a plugin.\n\n\nDirectory Structure\n\n\nThe test relevant files are located in the \nsrc/test/resources/ui/js/spec\n tree. Files that filename ends on\n\n_spec.js\n are considered as files with executable tests. The \nspec_helper.js\n in configured in the \npom.xml\n for\nthe initial setup. In the directory \ntest/resources/ui/js/engage\n is a mockup of the theodul engage core module in\norder to be able to test the plugin module independent. The directory \ntest/resources/ui/js/lib\n provides the\nlibraries which are provides by the engage core module at runtime of the player, as well to be able to test the plugin\nmodule independently.\n\n\nDirectory Structure Testing Plugins\n\n\n|-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------engage  #Mockup of the engage_core.js and engage_model.js\n|-----------lib     #Libraries used and provided by the core (A copy of the lib directory in the engage core module)\n|-----------spec    #Tests the *_spec.js and the helper file spec_helper.js\n\n\n\nSpec Helper\n\n\nThe file \nspec_helper.js\n takes over the configuration of RequireJS which is usually done by the \nengage_init.js\n. The\npaths differ slighty from the player uses at runtime.\n\n\n/*global requirejs*/\nrequirejs.config({\n  baseUrl: 'src/',\n  paths: {\n    require: 'test/resources/js/lib/require',\n    jquery: 'test/resources/js/lib/jquery',\n    underscore: 'test/resources/js/lib/underscore',\n    backbone: 'test/resources/js/lib/backbone',\n    engage: 'test/resources/js/engage'\n  },\n  shim: {\n    'backbone': {\n      //script dependencies\n      deps: ['underscore', 'jquery'],\n      //global variable\n      exports: 'Backbone'\n    },\n    'underscore': {\n      //global variable\n      exports: '_'\n    }\n  }\n});\n\n\n\nWriting Specs\n\n\nTODO\n\n\nRunning The Tests\n\n\nNow you can start the build process and the jasmine specs will be executed. Each . stands for a successful test. F\nstands for a failure and will stop the build process like it is specified in the configuration. The example output shows\na manipulated version of the tests for the theodul engage core in order to illustrate a failing test. Normally all three\ntests should succeed at this point.\n\n\nTesting on build\n\n\nmvn install -DdeployTo=${FELIX_HOME}\n    // some output before\n    [INFO]\n    -------------------------------------------------------\n     J A S M I N E   S P E C S\n    -------------------------------------------------------\n    [INFO]\n    F..\n\n    1 failure:\n\n      1.) EngageCore it should have a model <<< FAILURE!\n\n        * Expected { cid : 'c3', ... _pending : false } not to be defined.\n\n    Results: 3 specs, 1 failures\n    // some output before\n\n\n\nThe jasmine-maven-plugin can also be executed manually and show the result in a browser. This can be achieved by the\nfollowing command:\n\n\nManual testing\n\n\nmvn jasmine:bdd\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Building matterhorn-engage-theodul-core 1.5-SNAPSHOT\n    [INFO] ------------------------------------------------------------------------\n    [INFO]\n    [INFO] --- jasmine-maven-plugin:1.3.1.2:bdd (default-cli) @ matterhorn-engage-theodul-core ---\n    2014-01-28 14:33:30.722:INFO:oejs.Server:jetty-8.1.10.v20130312\n    2014-01-28 14:33:30.746:INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:8234\n    [INFO]\n\n    Server started--it's time to spec some JavaScript! You can run your specs as you develop by visiting this URL in\n    a web browser:\n\n    http://localhost:8234\n\n    The server will monitor these two directories for scripts that you add, remove, and change:\n\n    source directory: src/main/resources/ui\n\n    spec directory: src/test/resources/ui/js/spec\n\n    Just leave this process running as you test-drive your code, refreshing your browser window to re-run your specs.\n    You can kill the server with Ctrl-C when you're done.\n\n\n\nIn a browser you should see an output like it is shown on the next screenshot.",
            "title": "Testing"
        },
        {
            "location": "/modules/player/testing/#how-to-test-with-phantomjs-and-jasmine",
            "text": "",
            "title": "How To Test With Phantom.js and Jasmine"
        },
        {
            "location": "/modules/player/testing/#integration-of-jasmine-into-the-build-process-maven",
            "text": "Jasmine  is integrated with the jasmine-maven-plugin  into the maven build process. Therefore only the pom.xml file\nwill be enhanced by the following code, which specifies the  jasmine-maven-plugin \nas plugin for the build process. The configuration of the jasmine-maven-plugin is also done in this file. The meaning of\nevery configuration parameter can be looked up on the jasmine-maven-plugin project page under this link . The following configuration uses a the\nspecRunnerTemplate  REQUIRE_JS  in order to function properly with  RequireJS . Further\ninformation about spec runner templates can be found here . On the next build the needed\ndependencies will be automatically resolved just like it is in the nature of maven.  pom.xml  <build>\n<plugins>\n    ...\n      <plugin>\n        <groupId>com.github.searls</groupId>\n        <artifactId>jasmine-maven-plugin</artifactId>\n        <version>1.3.1.2</version>\n        <executions>\n          <execution>\n            <goals>\n              <goal>test</goal>\n            </goals>\n          </execution>\n        </executions>\n        <configuration>\n          <preloadSources>\n            <source>${project.basedir}/src/test/resources/js/lib/require.js</source>\n          </preloadSources>\n          <jsSrcDir>${project.basedir}/src/main/resources/static</jsSrcDir>\n          <sourceIncludes>\n            <include>**/*.js</include>\n            <include>**/*.coffee</include>\n          </sourceIncludes>\n          <jsTestSrcDir>${project.basedir}/src/test/resources/js/spec</jsTestSrcDir>\n          <specIncludes>\n            <include>**/spec_helper.js</include>\n            <include>**/*.js</include>\n            <include>**/*.coffee</include>\n          </specIncludes>\n          <specRunnerTemplate>REQUIRE_JS</specRunnerTemplate>\n          <format>progress</format>\n        </configuration>\n      </plugin>\n  </plugins>\n</build>",
            "title": "Integration Of Jasmine Into The Build Process (Maven)"
        },
        {
            "location": "/modules/player/testing/#testing-the-engage-core",
            "text": "This chapter gives an overview over the directory structure used for testing the theodul engage core module, the configuration for the specs in the  spec_helper.js  and how to write specs for the core.",
            "title": "Testing The Engage Core"
        },
        {
            "location": "/modules/player/testing/#directory-structure",
            "text": "The test relevant files are located in the  src/test/resources/ui/js/spec  tree. Files that filename ends on  _spec.js  are considered as files with executable tests. The  spec_helper.js  in configured in the  pom.xml  for the initial setup.  Directory Structure Testing Engage Core  |-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------spec    #Tests the *_spec.js and the helper file spec_helper.js",
            "title": "Directory Structure"
        },
        {
            "location": "/modules/player/testing/#spec-helper",
            "text": "The file  spec_helper.js  takes over the configuration of RequireJS which is usually done by the  engage_init.js . The\npaths differ slighty from the player has at runtime.  spec_helper for engage_core module  /*global requirejs*/\nrequirejs.config({\n  baseUrl: 'src/js/lib',\n  paths: {\n    require: 'require',\n    jquery: 'jquery',\n    underscore: 'underscore',\n    backbone: 'backbone',\n    engage: '../engage',\n    plugins: '../engage/plugin/*/static'\n  },\n  shim: {\n    'backbone': {\n      //script dependencies\n      deps: ['underscore', 'jquery'],\n      //global variable\n      exports: 'Backbone'\n    },\n    'underscore': {\n      //global variable\n      exports: '_'\n    }\n  }\n});\nvar PLUGIN_MANAGER_PATH = '/engage/theodul/manager/list.json';\nvar PLUGIN_PATH = '/engage/theodul/plugin/';",
            "title": "Spec Helper"
        },
        {
            "location": "/modules/player/testing/#testing-engage-plugins",
            "text": "This chapter gives an overview over the directory structure used for testing a theodul engage plugin module, the\nconfiguration for the specs in the  spec_helper.js  and how to write specs for a plugin.",
            "title": "Testing Engage Plugins"
        },
        {
            "location": "/modules/player/testing/#directory-structure_1",
            "text": "The test relevant files are located in the  src/test/resources/ui/js/spec  tree. Files that filename ends on _spec.js  are considered as files with executable tests. The  spec_helper.js  in configured in the  pom.xml  for\nthe initial setup. In the directory  test/resources/ui/js/engage  is a mockup of the theodul engage core module in\norder to be able to test the plugin module independent. The directory  test/resources/ui/js/lib  provides the\nlibraries which are provides by the engage core module at runtime of the player, as well to be able to test the plugin\nmodule independently.  Directory Structure Testing Plugins  |-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------engage  #Mockup of the engage_core.js and engage_model.js\n|-----------lib     #Libraries used and provided by the core (A copy of the lib directory in the engage core module)\n|-----------spec    #Tests the *_spec.js and the helper file spec_helper.js",
            "title": "Directory Structure"
        },
        {
            "location": "/modules/player/testing/#spec-helper_1",
            "text": "The file  spec_helper.js  takes over the configuration of RequireJS which is usually done by the  engage_init.js . The\npaths differ slighty from the player uses at runtime.  /*global requirejs*/\nrequirejs.config({\n  baseUrl: 'src/',\n  paths: {\n    require: 'test/resources/js/lib/require',\n    jquery: 'test/resources/js/lib/jquery',\n    underscore: 'test/resources/js/lib/underscore',\n    backbone: 'test/resources/js/lib/backbone',\n    engage: 'test/resources/js/engage'\n  },\n  shim: {\n    'backbone': {\n      //script dependencies\n      deps: ['underscore', 'jquery'],\n      //global variable\n      exports: 'Backbone'\n    },\n    'underscore': {\n      //global variable\n      exports: '_'\n    }\n  }\n});",
            "title": "Spec Helper"
        },
        {
            "location": "/modules/player/testing/#writing-specs",
            "text": "TODO",
            "title": "Writing Specs"
        },
        {
            "location": "/modules/player/testing/#running-the-tests",
            "text": "Now you can start the build process and the jasmine specs will be executed. Each . stands for a successful test. F\nstands for a failure and will stop the build process like it is specified in the configuration. The example output shows\na manipulated version of the tests for the theodul engage core in order to illustrate a failing test. Normally all three\ntests should succeed at this point.  Testing on build  mvn install -DdeployTo=${FELIX_HOME}\n    // some output before\n    [INFO]\n    -------------------------------------------------------\n     J A S M I N E   S P E C S\n    -------------------------------------------------------\n    [INFO]\n    F..\n\n    1 failure:\n\n      1.) EngageCore it should have a model <<< FAILURE!\n\n        * Expected { cid : 'c3', ... _pending : false } not to be defined.\n\n    Results: 3 specs, 1 failures\n    // some output before  The jasmine-maven-plugin can also be executed manually and show the result in a browser. This can be achieved by the\nfollowing command:  Manual testing  mvn jasmine:bdd\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Building matterhorn-engage-theodul-core 1.5-SNAPSHOT\n    [INFO] ------------------------------------------------------------------------\n    [INFO]\n    [INFO] --- jasmine-maven-plugin:1.3.1.2:bdd (default-cli) @ matterhorn-engage-theodul-core ---\n    2014-01-28 14:33:30.722:INFO:oejs.Server:jetty-8.1.10.v20130312\n    2014-01-28 14:33:30.746:INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:8234\n    [INFO]\n\n    Server started--it's time to spec some JavaScript! You can run your specs as you develop by visiting this URL in\n    a web browser:\n\n    http://localhost:8234\n\n    The server will monitor these two directories for scripts that you add, remove, and change:\n\n    source directory: src/main/resources/ui\n\n    spec directory: src/test/resources/ui/js/spec\n\n    Just leave this process running as you test-drive your code, refreshing your browser window to re-run your specs.\n    You can kill the server with Ctrl-C when you're done.  In a browser you should see an output like it is shown on the next screenshot.",
            "title": "Running The Tests"
        },
        {
            "location": "/modules/stream-security/",
            "text": "Stream Security Developer Guide\n\n\nTo get an introduction to Stream Security, please read the sub section Stream Security in the section Modules of the Admin Guide.\n\n\nOpencast Signing Protocol\n\n\nThe Signing Providers as well as the verification components that are developed by the Opencast community implement the policy and signature specified in the Opencast Signing Protocol. \n\n\nPolicy\n\n\nThe policy is a Base64 encoded JSON document. A human-readable version of the JSON document looks like this:\n\n\n{\n  \"Statement\":{\n    \"Resource\":\"http:\\/\\/opencast.org\\/engage\\/resource.mp4\",\n    \"Condition\":{\n      \"DateLessThan\":1425170777000,\n      \"DateGreaterThan\":1425084379000,\n      \"IpAddress\":\"10.0.0.1\"\n    }\n  }\n}\n\n\n\n\n\n\n\n\n\nProperty Name\n\n\nProperty Description\n\n\n\n\n\n\n\n\n\n\nResource\n\n\nURL of the resource, must exactly match the requested URL including the schema. In case of a RTMP request, this is only the resource path, without the RTMP application name or the server.\n\n\n\n\n\n\nDateLessThan\n\n\nUnix epoch that a resource should expire on in milliseconds\n\n\n\n\n\n\nDateGreaterThan\n\n\nUnix epoch that a resource should become available in milliseconds\n\n\n\n\n\n\nIpAddress\n\n\nClient's IP address that will be accessing the resource\n\n\n\n\n\n\n\n\nProperties in bold are mandatory.\n\n\nBefore the JSON document is Base64 encoded, all whitespaces need to be removed. The above sample document would then look like this:\n\n\n{\"Statement\":{\"Resource\":\"http:\\/\\/opencast.org\\/engage\\/resource.mp4\",\"Condition\":{\"DateLessThan\":1425170777000,\"DateGreaterThan\":1425084379000,\"IpAddress\":\"10.0.0.1\"}}}\n\n\n\nThe Base64-encoding must be performed in a URL safe way which means that instead of using the characters \u2018+\u2019 and \u2018/\u2019 they have to be replaced by '-' and '_' respectively. The example above would be encoded into:\n\n\neyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0=\n\n\n\nThe encoded policy must be sent to the server as a query parameter named \u2018policy\u2019, e.g.\n\n\nhttp://opencast.org/engage/resource.mp4?policy=eyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0\n\n\n\nNote: Be aware that Base64 encoding can have up to two \u2018=\u2019 characters at the end of the string to pad a message to a necessary length divisible by 3. All components should be able to handle Base64 encoded strings with or without this padding (Resources signed by Opencast will have the padding characters URL encoded to \u2018%3D\u2019).\n\n\nSignature\n\n\nThe signature is a hash-based message authentication code (HMAC) based on a secret key. The algorithm used is HMAC-SHA-256. Only the encoded policy needs to be taken as input for the hash-calculation.\n\n\nThe keys used are simple character strings without any special format. It could be something like \u2018AbCdEfGh\u2019, but it\u2019s recommended to use a key with a length of 256 bit like \u20182195265EE84ED1E1324D31F37F7E3\u2019. Each key must have a unique identifier, e.g. \u2018key1\u2019. In this example, the following key has been used:\n\n\nKey ID: demoKeyOne\nSecret Key: 6EDB5EDDCF994B7432C371D7C274F\n\n\nThe HMAC for the signature from the previous section calculated based on the \ndemoKey1\n is \n\n\nc8712284aabc843f76a132a3a7c8997670414b2f89cb96b367d5f35d0f62a2e4\n\n\n\nThe signature must also be sent as a query parameter that forms part of the resource request. The example from above would now look like this:\n\n\nhttp://opencast.org/engage/resource.mp4?policy=eyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0&signature=c8712284aabc843f76a132a3a7c8997670414b2f89cb96b367d5f35d0f62a2e4\n\n\n\nThe same is true for the key id, which needs to be included to determine which key was used to create the signature. \n\n\nhttp://opencast.org/engage/resource.mp4?policy=eyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0&signature=c8712284aabc843f76a132a3a7c8997670414b2f89cb96b367d5f35d0f62a2e4&keyId=demoKeyOne\n\n\n\nSigning URLs from a 3rd party system\n\n\nURL signatures also need to be issued for resources presented on and linked from a third party system (such as a custom video portal). There are two options for signing 3rd party system URLs:\n\n\nOption #1: Use the existing URL Signing Service**\n\n\nIf the third party system is based on Java, the existing URL Signing bundles/JARs can be reused. They do not have dependencies to other parts of Opencast and can therefore be used independently.\n\n\nThese bundles are required:\n\n\n\n\nmatterhorn-urlsigning-common\n\n\nmatterhorn-urlsigning-service-api\n\n\nmatterhorn-urlsigning-service-impl\n\n\n\n\nCode example:\n\n\nprivate UrlSigningService urlSigningService;\n\n/** OSGi DI */\nvoid setUrlSigningService(UrlSigningService service) {\n  this.urlSigningService = service;\n}\n\n\u2026 \n\nString urlToSign = \u201chttp://my.custom.url/with/path.mp4\u201d;\nlong signedUrlExpiresDuration = 60;\n\nif (urlSigningService.accepts(urlToSign)) {\n  try {\n    String signedUrl = urlSigningService.sign(\n        urlToSign,\n        signedUrlExpiresDuration,\n        null,\n        null);\n    ...\n  } catch (UrlSigningException e) {\n    // handle exception\n  }\n}\n\n\n\nOption #2: Create custom URL Signing Service\n\n\nBased on the technical details outlined in the Opencast Signing Protocol, a URL Signing Service that is compatible with the other existing parts of the Stream Security system can be implemented.\n\n\nOption #3: Give Access to Third Party Systems to Signing REST Endpoints\n\n\nOpencast servers that have been configured to use URL signing service will have two REST endpoints at http://admin.matterhorn.com:8080/signing/docs. The accepts endpoint will return true if the Opencast server can sign a particular URL. The sign endpoint will return a signed URL when the correct parameters are given. Due to the sensitive nature of these endpoints they are locked down to be only accessible by a user with ROLE_ADMIN privileges in the etc/security/mh_default_org.xml configuration file. Creating a new user with this role and accessing the endpoint using these credentials will allow a third party system to sign any URLs.\n\n\nFurther information\n\n\n\n\nFor an overview of Stream Security, please consult the sub section Stream Security in the section Modules of the Admin Guide.\n\n\nFor information about how to configure stream security on your Opencast servers, please consult the sub section Stream Security in the section Configuration of the Admin Guide",
            "title": "Stream Security"
        },
        {
            "location": "/modules/stream-security/#stream-security-developer-guide",
            "text": "To get an introduction to Stream Security, please read the sub section Stream Security in the section Modules of the Admin Guide.",
            "title": "Stream Security Developer Guide"
        },
        {
            "location": "/modules/stream-security/#opencast-signing-protocol",
            "text": "The Signing Providers as well as the verification components that are developed by the Opencast community implement the policy and signature specified in the Opencast Signing Protocol.",
            "title": "Opencast Signing Protocol"
        },
        {
            "location": "/modules/stream-security/#policy",
            "text": "The policy is a Base64 encoded JSON document. A human-readable version of the JSON document looks like this:  {\n  \"Statement\":{\n    \"Resource\":\"http:\\/\\/opencast.org\\/engage\\/resource.mp4\",\n    \"Condition\":{\n      \"DateLessThan\":1425170777000,\n      \"DateGreaterThan\":1425084379000,\n      \"IpAddress\":\"10.0.0.1\"\n    }\n  }\n}     Property Name  Property Description      Resource  URL of the resource, must exactly match the requested URL including the schema. In case of a RTMP request, this is only the resource path, without the RTMP application name or the server.    DateLessThan  Unix epoch that a resource should expire on in milliseconds    DateGreaterThan  Unix epoch that a resource should become available in milliseconds    IpAddress  Client's IP address that will be accessing the resource     Properties in bold are mandatory.  Before the JSON document is Base64 encoded, all whitespaces need to be removed. The above sample document would then look like this:  {\"Statement\":{\"Resource\":\"http:\\/\\/opencast.org\\/engage\\/resource.mp4\",\"Condition\":{\"DateLessThan\":1425170777000,\"DateGreaterThan\":1425084379000,\"IpAddress\":\"10.0.0.1\"}}}  The Base64-encoding must be performed in a URL safe way which means that instead of using the characters \u2018+\u2019 and \u2018/\u2019 they have to be replaced by '-' and '_' respectively. The example above would be encoded into:  eyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0=  The encoded policy must be sent to the server as a query parameter named \u2018policy\u2019, e.g.  http://opencast.org/engage/resource.mp4?policy=eyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0  Note: Be aware that Base64 encoding can have up to two \u2018=\u2019 characters at the end of the string to pad a message to a necessary length divisible by 3. All components should be able to handle Base64 encoded strings with or without this padding (Resources signed by Opencast will have the padding characters URL encoded to \u2018%3D\u2019).",
            "title": "Policy"
        },
        {
            "location": "/modules/stream-security/#signature",
            "text": "The signature is a hash-based message authentication code (HMAC) based on a secret key. The algorithm used is HMAC-SHA-256. Only the encoded policy needs to be taken as input for the hash-calculation.  The keys used are simple character strings without any special format. It could be something like \u2018AbCdEfGh\u2019, but it\u2019s recommended to use a key with a length of 256 bit like \u20182195265EE84ED1E1324D31F37F7E3\u2019. Each key must have a unique identifier, e.g. \u2018key1\u2019. In this example, the following key has been used:  Key ID: demoKeyOne\nSecret Key: 6EDB5EDDCF994B7432C371D7C274F  The HMAC for the signature from the previous section calculated based on the  demoKey1  is   c8712284aabc843f76a132a3a7c8997670414b2f89cb96b367d5f35d0f62a2e4  The signature must also be sent as a query parameter that forms part of the resource request. The example from above would now look like this:  http://opencast.org/engage/resource.mp4?policy=eyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0&signature=c8712284aabc843f76a132a3a7c8997670414b2f89cb96b367d5f35d0f62a2e4  The same is true for the key id, which needs to be included to determine which key was used to create the signature.   http://opencast.org/engage/resource.mp4?policy=eyJTdGF0ZW1lbnQiOnsiUmVzb3VyY2UiOiJodHRwOlwvXC9vcGVuY2FzdC5vcmdcL2VuZ2FnZVwvcmVzb3VyY2UubXA0IiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6MTQyNTE3MDc3NzAwMCwiRGF0ZUdyZWF0ZXJUaGFuIjoxNDI1MDg0Mzc5MDAwLCJJcEFkZHJlc3MiOiIxMC4wLjAuMSJ9fX0&signature=c8712284aabc843f76a132a3a7c8997670414b2f89cb96b367d5f35d0f62a2e4&keyId=demoKeyOne",
            "title": "Signature"
        },
        {
            "location": "/modules/stream-security/#signing-urls-from-a-3rd-party-system",
            "text": "URL signatures also need to be issued for resources presented on and linked from a third party system (such as a custom video portal). There are two options for signing 3rd party system URLs:",
            "title": "Signing URLs from a 3rd party system"
        },
        {
            "location": "/modules/stream-security/#option-1-use-the-existing-url-signing-service",
            "text": "If the third party system is based on Java, the existing URL Signing bundles/JARs can be reused. They do not have dependencies to other parts of Opencast and can therefore be used independently.  These bundles are required:   matterhorn-urlsigning-common  matterhorn-urlsigning-service-api  matterhorn-urlsigning-service-impl   Code example:  private UrlSigningService urlSigningService;\n\n/** OSGi DI */\nvoid setUrlSigningService(UrlSigningService service) {\n  this.urlSigningService = service;\n}\n\n\u2026 \n\nString urlToSign = \u201chttp://my.custom.url/with/path.mp4\u201d;\nlong signedUrlExpiresDuration = 60;\n\nif (urlSigningService.accepts(urlToSign)) {\n  try {\n    String signedUrl = urlSigningService.sign(\n        urlToSign,\n        signedUrlExpiresDuration,\n        null,\n        null);\n    ...\n  } catch (UrlSigningException e) {\n    // handle exception\n  }\n}",
            "title": "Option #1: Use the existing URL Signing Service**"
        },
        {
            "location": "/modules/stream-security/#option-2-create-custom-url-signing-service",
            "text": "Based on the technical details outlined in the Opencast Signing Protocol, a URL Signing Service that is compatible with the other existing parts of the Stream Security system can be implemented.",
            "title": "Option #2: Create custom URL Signing Service"
        },
        {
            "location": "/modules/stream-security/#option-3-give-access-to-third-party-systems-to-signing-rest-endpoints",
            "text": "Opencast servers that have been configured to use URL signing service will have two REST endpoints at http://admin.matterhorn.com:8080/signing/docs. The accepts endpoint will return true if the Opencast server can sign a particular URL. The sign endpoint will return a signed URL when the correct parameters are given. Due to the sensitive nature of these endpoints they are locked down to be only accessible by a user with ROLE_ADMIN privileges in the etc/security/mh_default_org.xml configuration file. Creating a new user with this role and accessing the endpoint using these credentials will allow a third party system to sign any URLs.",
            "title": "Option #3: Give Access to Third Party Systems to Signing REST Endpoints"
        },
        {
            "location": "/modules/stream-security/#further-information",
            "text": "For an overview of Stream Security, please consult the sub section Stream Security in the section Modules of the Admin Guide.  For information about how to configure stream security on your Opencast servers, please consult the sub section Stream Security in the section Configuration of the Admin Guide",
            "title": "Further information"
        },
        {
            "location": "/modules/oaipmh/",
            "text": "OAI-PMH\n\n\nOverview\n\n\nOAI-PMH is an XML based protocol for metadata exchange using HTTP as the transport layer. An OAI-PMH system consists\nof two parts, a repository on the one and the harvester on the other end. The repository is an HTTP accessible server\nthat exposes metadata to its client, the harvester. A repository is required to deliver metadata following the\n\nDublinCore element set version 1.1\n metadata scheme. Additionally it may\ndeliver metadata in any arbitrary format, that can be encoded as XML.\n\n\nFor a more detailed introduction please see the\n\nOAI-PMH specification\n.\n\n\nMetadata Prefixes\n\n\nThe Opencast OAI-PMH server supports three metadata prefixes:\n\n\n\n\n\n\n\n\nPrefix\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\noai_dc\n\n\nDublin core element set 1.1 as required by the OAI-PMH specification\n\n\n\n\n\n\nmatterhorn\n\n\nOpencast media package representation\n\n\n\n\n\n\nmatterhorn-inlined\n\n\nOpencast media package representation with embedded catalogs\n\n\n\n\n\n\n\n\nNote that the metadata prefix \noai_dc\n is a standard metadata representation supported by all OAI-PMH servers and\nharverster, while the other prefixes are specific to Opencast.\nIf you use an harvester in your third-party application, the havester will therefore need to be extended to\nsupport the Opencast-specific metadata prefixes.\n\n\nGlossary\n\n\n\n\n\n\n\n\nTerm\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nRepository\n\n\nAn entity that holds a set of items to be disseminated via the OAI-PMH protocol. Different repositories may hold different sets of items.\n\n\n\n\n\n\nChannel\n\n\nThe client's perspective on a repository. Each channel is backed by a single repository (1:1 relationship) so these terms may be used synonymously depending on the perspective.\n\n\n\n\n\n\nItem\n\n\nThe base entity of a repository. In Opencast an item is equal to a mediapackage.\n\n\n\n\n\n\nMetadata format\n\n\nOAI-PMH repositories disseminate their content in various formats. The oai_dc format is mandatory to each OAI-PMH repository. Formats are expressed in XML.\n\n\n\n\n\n\nMetadata prefix\n\n\nThe prefix identifies a metadata format. The terms are often used synonymously.",
            "title": "OAI-PMH"
        },
        {
            "location": "/modules/oaipmh/#oai-pmh",
            "text": "",
            "title": "OAI-PMH"
        },
        {
            "location": "/modules/oaipmh/#overview",
            "text": "OAI-PMH is an XML based protocol for metadata exchange using HTTP as the transport layer. An OAI-PMH system consists\nof two parts, a repository on the one and the harvester on the other end. The repository is an HTTP accessible server\nthat exposes metadata to its client, the harvester. A repository is required to deliver metadata following the DublinCore element set version 1.1  metadata scheme. Additionally it may\ndeliver metadata in any arbitrary format, that can be encoded as XML.  For a more detailed introduction please see the OAI-PMH specification .",
            "title": "Overview"
        },
        {
            "location": "/modules/oaipmh/#metadata-prefixes",
            "text": "The Opencast OAI-PMH server supports three metadata prefixes:     Prefix  Description      oai_dc  Dublin core element set 1.1 as required by the OAI-PMH specification    matterhorn  Opencast media package representation    matterhorn-inlined  Opencast media package representation with embedded catalogs     Note that the metadata prefix  oai_dc  is a standard metadata representation supported by all OAI-PMH servers and\nharverster, while the other prefixes are specific to Opencast.\nIf you use an harvester in your third-party application, the havester will therefore need to be extended to\nsupport the Opencast-specific metadata prefixes.",
            "title": "Metadata Prefixes"
        },
        {
            "location": "/modules/oaipmh/#glossary",
            "text": "Term  Description      Repository  An entity that holds a set of items to be disseminated via the OAI-PMH protocol. Different repositories may hold different sets of items.    Channel  The client's perspective on a repository. Each channel is backed by a single repository (1:1 relationship) so these terms may be used synonymously depending on the perspective.    Item  The base entity of a repository. In Opencast an item is equal to a mediapackage.    Metadata format  OAI-PMH repositories disseminate their content in various formats. The oai_dc format is mandatory to each OAI-PMH repository. Formats are expressed in XML.    Metadata prefix  The prefix identifies a metadata format. The terms are often used synonymously.",
            "title": "Glossary"
        },
        {
            "location": "/infrastructure/",
            "text": "Opencast Infrastructure\n\n\nList of Opencast project infrastructure and administrators.  For detailed notes go \nhere\n\n\nTest Servers\n\n\n\n\n\n\n\n\nInstitution\n\n\nHostname\n\n\nAdmin (Software)\n\n\nAdmin (Hardware)\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nUniversity of Osnabr\u00fcck\n\n\ndevelop.opencast.org\n\n\nLars Kiesow\n\n\nLars Kiesow\n\n\n\n\n\n\n\n\nETH Z\u00fcrich\n\n\nstable.opencast.org\n\n\nLars Kiesow\n\n\nMarkus Borzechowski\n\n\n\n\n\n\n\n\nSWITCH\n\n\nadmin.oc-test.switch.ch\n\n\nGreg Logan\n\n\nLars Kiesow\n\n\nMay be unavailable after 2017-07\n\n\n\n\n\n\nSWITCH\n\n\nplayer.oc-test.switch.ch\n\n\nGreg Logan\n\n\nLars Kiesow\n\n\n\n\n\n\n\n\nSWITCH\n\n\ningest.oc-test.switch.ch\n\n\nGreg Logan\n\n\nLars Kiesow\n\n\n\n\n\n\n\n\nSWITCH\n\n\nworker1.oc-test.switch.ch\n\n\nGreg Logan\n\n\nLars Kiesow\n\n\n\n\n\n\n\n\nSWITCH\n\n\nworker2.oc-test.switch.ch\n\n\nGreg Logan\n\n\nLars Kiesow\n\n\ninactive\n\n\n\n\n\n\nSWITCH\n\n\nworker3.oc-test.switch.ch\n\n\nGreg Logan\n\n\nLars Kiesow\n\n\ninactive\n\n\n\n\n\n\nSWITCH\n\n\nworker4.oc-test.switch.ch\n\n\nGreg Logan\n\n\nLars Kiesow\n\n\ninactive\n\n\n\n\n\n\nSWITCH\n\n\ndatabase.oc-test.switch.ch\n\n\nGreg Logan\n\n\nLars Kiesow\n\n\n\n\n\n\n\n\nSWITCH\n\n\ndownload.oc-test.switch.ch\n\n\nGreg Logan\n\n\nLars Kiesow\n\n\nmessage broker\n\n\n\n\n\n\nSWITCH\n\n\nstreaming.oc-test.switch.ch\n\n\nGreg Logan\n\n\nLars Kiesow\n\n\nstorage/nfs\n\n\n\n\n\n\nSWITCH\n\n\n10.0.207.247 (intern)\n\n\nLars Kiesow\n\n\nLars Kiesow\n\n\ncapture agent\n\n\n\n\n\n\n\n\nMaven Repository\n\n\n\n\n\n\n\n\nInstitution\n\n\nHostname\n\n\nAdmin (Software)\n\n\nAdmin (Hardware)\n\n\nNotes\n\n\n\n\n\n\n\n\n\n\nHarvard DCE\n\n\nmvncache.opencast.org\n\n\nLars Kiesow\n\n\nDCE Devel group\n\n\nAmazon Cloud\n\n\n\n\n\n\nUniversity of Osnabr\u00fcck\n\n\nnexus.opencast.org\n\n\nLars Kiesow\n\n\nLars Kiesow\n\n\n\n\n\n\n\n\n\n\nNexus administration:\n\n\n\n\nLars Kiesow (uos, dce)\n\n\nMichael Stypa (uos)\n\n\n\n\nOther Hosted Services\n\n\n\n\n\n\n\n\nInstitution\n\n\nHostname\n\n\nAdmin (Software)\n\n\nAdmin (Hardware)\n\n\n\n\n\n\n\n\n\n\nUniversity of Osnabr\u00fcck\n\n\npkg.opencast.org\n\n\nLars Kiesow\n\n\nLars Kiesow\n\n\n\n\n\n\nUniversity of Osnabr\u00fcck\n\n\npullrequests.opencast.org\n\n\nLars Kiesow\n\n\nLars Kiesow\n\n\n\n\n\n\nUniversity of Osnabr\u00fcck\n\n\nbuild.opencast.org\n\n\nGreg Logan\n\n\nLars Kiesow\n\n\n\n\n\n\nUniversity of Osnabr\u00fcck\n\n\ndocs.opencast.org\n\n\nLars Kiesow\n\n\nLars Kiesow\n\n\n\n\n\n\nUniversity of Osnabr\u00fcck\n\n\nopencast.org\n\n\nR\u00fcdiger Rolf\n\n\nUOS RZ\n\n\n\n\n\n\n\n\nAdministrators\n\n\nWhat is an administractor, and how does that differ from a committer?\n\n\nAn administrator is someone within the Opencast community who has administrative access to one or more of our major\ntools.  These tools are\n\n\n\n\nJIRA\n\n\nGitHub\n\n\nGoogle Groups\n\n\nCrowdin\n\n\n\n\nWhile many of our administrators are committers, an administrator is \nnot\n a committer by necessity.  Administrators\nhave important responsibilities within the community, but mainly work behind the scenes.  These responsibilities\ninclude:\n\n\n\n\nAdding new committers to the relevant group(s)\n\n\nRemoving old committers from the relevant group(s)\n\n\nContacting support when required for hosted projects (Atlassian, Crowdin, Google)\n\n\n\n\nAdding or removing Committers\n\n\nWhile the committer body manages its own membership, it does not directly have the power to add or remove users\nfrom the appropriate groups across all of our hosted products.  Administrators are required to modify the various\ngroups in multiple places when a change is necessary.  These changes are\n\n\n\n\nModifying the \nJIRA committers group\n\n\nModifying the \nGitHub committers group\n upon request\n\n\nModifying the \nGoogle committers group\n\n\nModifying the \nCrowdin commiters group\n\n\n\n\nCurrent Administrators\n\n\nAdministrators may not have complete access to all services, however we will coordinate to handle requests in a timely\nmanner.  If you need to contact an administrator for access to one of the services above, please contact them in this\norder:\n\n\n\n\nGreg Logan\n\n\nLars Kiesow\n\n\nOlaf Schulte\n\n\n\n\nVideo Conferencing\n\n\n\n\nBigBlueButton\n\n\nConference rooms\n\n\nPassword: welcome\n\n\n\n\n\n\nRecordings\n\n\nFlash based\n\n\n\n\n\n\nAppearIn\n\n\nConference room\n\n\nWebRTC based; Max. 8 users",
            "title": "Overview"
        },
        {
            "location": "/infrastructure/#opencast-infrastructure",
            "text": "List of Opencast project infrastructure and administrators.  For detailed notes go  here",
            "title": "Opencast Infrastructure"
        },
        {
            "location": "/infrastructure/#test-servers",
            "text": "Institution  Hostname  Admin (Software)  Admin (Hardware)  Notes      University of Osnabr\u00fcck  develop.opencast.org  Lars Kiesow  Lars Kiesow     ETH Z\u00fcrich  stable.opencast.org  Lars Kiesow  Markus Borzechowski     SWITCH  admin.oc-test.switch.ch  Greg Logan  Lars Kiesow  May be unavailable after 2017-07    SWITCH  player.oc-test.switch.ch  Greg Logan  Lars Kiesow     SWITCH  ingest.oc-test.switch.ch  Greg Logan  Lars Kiesow     SWITCH  worker1.oc-test.switch.ch  Greg Logan  Lars Kiesow     SWITCH  worker2.oc-test.switch.ch  Greg Logan  Lars Kiesow  inactive    SWITCH  worker3.oc-test.switch.ch  Greg Logan  Lars Kiesow  inactive    SWITCH  worker4.oc-test.switch.ch  Greg Logan  Lars Kiesow  inactive    SWITCH  database.oc-test.switch.ch  Greg Logan  Lars Kiesow     SWITCH  download.oc-test.switch.ch  Greg Logan  Lars Kiesow  message broker    SWITCH  streaming.oc-test.switch.ch  Greg Logan  Lars Kiesow  storage/nfs    SWITCH  10.0.207.247 (intern)  Lars Kiesow  Lars Kiesow  capture agent",
            "title": "Test Servers"
        },
        {
            "location": "/infrastructure/#maven-repository",
            "text": "Institution  Hostname  Admin (Software)  Admin (Hardware)  Notes      Harvard DCE  mvncache.opencast.org  Lars Kiesow  DCE Devel group  Amazon Cloud    University of Osnabr\u00fcck  nexus.opencast.org  Lars Kiesow  Lars Kiesow      Nexus administration:   Lars Kiesow (uos, dce)  Michael Stypa (uos)",
            "title": "Maven Repository"
        },
        {
            "location": "/infrastructure/#other-hosted-services",
            "text": "Institution  Hostname  Admin (Software)  Admin (Hardware)      University of Osnabr\u00fcck  pkg.opencast.org  Lars Kiesow  Lars Kiesow    University of Osnabr\u00fcck  pullrequests.opencast.org  Lars Kiesow  Lars Kiesow    University of Osnabr\u00fcck  build.opencast.org  Greg Logan  Lars Kiesow    University of Osnabr\u00fcck  docs.opencast.org  Lars Kiesow  Lars Kiesow    University of Osnabr\u00fcck  opencast.org  R\u00fcdiger Rolf  UOS RZ",
            "title": "Other Hosted Services"
        },
        {
            "location": "/infrastructure/#administrators",
            "text": "",
            "title": "Administrators"
        },
        {
            "location": "/infrastructure/#what-is-an-administractor-and-how-does-that-differ-from-a-committer",
            "text": "An administrator is someone within the Opencast community who has administrative access to one or more of our major\ntools.  These tools are   JIRA  GitHub  Google Groups  Crowdin   While many of our administrators are committers, an administrator is  not  a committer by necessity.  Administrators\nhave important responsibilities within the community, but mainly work behind the scenes.  These responsibilities\ninclude:   Adding new committers to the relevant group(s)  Removing old committers from the relevant group(s)  Contacting support when required for hosted projects (Atlassian, Crowdin, Google)",
            "title": "What is an administractor, and how does that differ from a committer?"
        },
        {
            "location": "/infrastructure/#adding-or-removing-committers",
            "text": "While the committer body manages its own membership, it does not directly have the power to add or remove users\nfrom the appropriate groups across all of our hosted products.  Administrators are required to modify the various\ngroups in multiple places when a change is necessary.  These changes are   Modifying the  JIRA committers group  Modifying the  GitHub committers group  upon request  Modifying the  Google committers group  Modifying the  Crowdin commiters group",
            "title": "Adding or removing Committers"
        },
        {
            "location": "/infrastructure/#current-administrators",
            "text": "Administrators may not have complete access to all services, however we will coordinate to handle requests in a timely\nmanner.  If you need to contact an administrator for access to one of the services above, please contact them in this\norder:   Greg Logan  Lars Kiesow  Olaf Schulte",
            "title": "Current Administrators"
        },
        {
            "location": "/infrastructure/#video-conferencing",
            "text": "BigBlueButton  Conference rooms  Password: welcome    Recordings  Flash based    AppearIn  Conference room  WebRTC based; Max. 8 users",
            "title": "Video Conferencing"
        },
        {
            "location": "/infrastructure/notes/",
            "text": "Infrastructure Notes\n\n\nThis page contains notes about the current configuration of the Opencast servers around the world\n\n\nHarvard DCE\n\n\nCommon Configuration Choices\n\n\n\n\nUnattended upgrade\n\n\nCentOS Linux release 7.x\n\n\n\n\nnexus.dcex.harvard.edu\n\n\n\n\nUsing \npackaged Nexus\n\n\n\n\nETH\n\n\nopencast-nexus.ethz.ch\n\n\n\n\nUnattended upgrade\n\n\nRHEL 7.x\n\n\nUsing \npackaged Nexus\n\n\n\n\nSWITCH\n\n\nCommon Configuration Choices\n\n\n\n\nUnattended upgrade\n\n\nCentOS Linux release 7.x\n\n\n\n\nTest Cluster (*.oc-test.switch.ch)\n\n\n\n\nRebuilt weekly via cron + shell, manual branch selection\n\n\n\n\nUniversity of Osnabr\u00fcck\n\n\nCommon Configuration Choices\n\n\n\n\nUnattended upgrade\n\n\nScientific Linux 7.x\n\n\n\n\nbuild.opencast.org\n\n\n\n\nBuilds are triggered by cron, manual branch selection\n\n\n\n\nnexus.opencast.org, nexus.virtuos.uos.de\n\n\n\n\nGeoIP based redirect for all Nexus servers\n\n\nUsing \npackaged Nexus\n\n\n\n\noctestallinone.virtuos.uos.de\n\n\n\n\nUsing tarballs build from build.opencast.org\n\n\n\n\npullrequests.opencast.org\n\n\n\n\nScientific Linux 6.x\n\n\nDue for retirement, services will be moved to repo.opencast.org VM and DNS updated\n\n\nMerge ticket list needs to be set manually\n\n\n\n\nrepo.opencast.org and pkg.opencast.org\n\n\n\n\nSame server\n\n\n\n\nUniversity of Saskatchewean\n\n\nCommon Configuration Choices\n\n\n\n\nDebian 8.x\n\n\nUnattended upgrades\n\n\n\n\nTesting Cluster (test*.usask.ca)\n\n\n\n\nUsing Debian packages for Opencast\n\n\nNightly reset and upgrade\n\n\n\n\noc-cache.usask.ca\n\n\n\n\nUsing \nDocker Nexus",
            "title": "Notes"
        },
        {
            "location": "/infrastructure/notes/#infrastructure-notes",
            "text": "This page contains notes about the current configuration of the Opencast servers around the world",
            "title": "Infrastructure Notes"
        },
        {
            "location": "/infrastructure/notes/#harvard-dce",
            "text": "",
            "title": "Harvard DCE"
        },
        {
            "location": "/infrastructure/notes/#common-configuration-choices",
            "text": "Unattended upgrade  CentOS Linux release 7.x",
            "title": "Common Configuration Choices"
        },
        {
            "location": "/infrastructure/notes/#nexusdcexharvardedu",
            "text": "Using  packaged Nexus",
            "title": "nexus.dcex.harvard.edu"
        },
        {
            "location": "/infrastructure/notes/#eth",
            "text": "",
            "title": "ETH"
        },
        {
            "location": "/infrastructure/notes/#opencast-nexusethzch",
            "text": "Unattended upgrade  RHEL 7.x  Using  packaged Nexus",
            "title": "opencast-nexus.ethz.ch"
        },
        {
            "location": "/infrastructure/notes/#switch",
            "text": "",
            "title": "SWITCH"
        },
        {
            "location": "/infrastructure/notes/#common-configuration-choices_1",
            "text": "Unattended upgrade  CentOS Linux release 7.x",
            "title": "Common Configuration Choices"
        },
        {
            "location": "/infrastructure/notes/#test-cluster-oc-testswitchch",
            "text": "Rebuilt weekly via cron + shell, manual branch selection",
            "title": "Test Cluster (*.oc-test.switch.ch)"
        },
        {
            "location": "/infrastructure/notes/#university-of-osnabruck",
            "text": "",
            "title": "University of Osnabr\u00fcck"
        },
        {
            "location": "/infrastructure/notes/#common-configuration-choices_2",
            "text": "Unattended upgrade  Scientific Linux 7.x",
            "title": "Common Configuration Choices"
        },
        {
            "location": "/infrastructure/notes/#buildopencastorg",
            "text": "Builds are triggered by cron, manual branch selection",
            "title": "build.opencast.org"
        },
        {
            "location": "/infrastructure/notes/#nexusopencastorg-nexusvirtuosuosde",
            "text": "GeoIP based redirect for all Nexus servers  Using  packaged Nexus",
            "title": "nexus.opencast.org, nexus.virtuos.uos.de"
        },
        {
            "location": "/infrastructure/notes/#octestallinonevirtuosuosde",
            "text": "Using tarballs build from build.opencast.org",
            "title": "octestallinone.virtuos.uos.de"
        },
        {
            "location": "/infrastructure/notes/#pullrequestsopencastorg",
            "text": "Scientific Linux 6.x  Due for retirement, services will be moved to repo.opencast.org VM and DNS updated  Merge ticket list needs to be set manually",
            "title": "pullrequests.opencast.org"
        },
        {
            "location": "/infrastructure/notes/#repoopencastorg-and-pkgopencastorg",
            "text": "Same server",
            "title": "repo.opencast.org and pkg.opencast.org"
        },
        {
            "location": "/infrastructure/notes/#university-of-saskatchewean",
            "text": "",
            "title": "University of Saskatchewean"
        },
        {
            "location": "/infrastructure/notes/#common-configuration-choices_3",
            "text": "Debian 8.x  Unattended upgrades",
            "title": "Common Configuration Choices"
        },
        {
            "location": "/infrastructure/notes/#testing-cluster-testusaskca",
            "text": "Using Debian packages for Opencast  Nightly reset and upgrade",
            "title": "Testing Cluster (test*.usask.ca)"
        },
        {
            "location": "/infrastructure/notes/#oc-cacheusaskca",
            "text": "Using  Docker Nexus",
            "title": "oc-cache.usask.ca"
        },
        {
            "location": "/infrastructure/maven-repository/",
            "text": "Opencast Maven Repository\n\n\nThe Maven repository server maintains a copy of all the Java dependencies used by Opencast.\n\n\nAdding Libraries To The Repository\n\n\n\n\nLogin as an administrator on the \nOpencast Nexus Master\n\n\nSelect repository\n\n\nSelect the artifact upload tab\n\n\nFill in the details and upload the file\n\n\n\n\nSetting-up Another Maven Repository\n\n\nHaving a repository server run in your local network can significantly improve the speed artifacts are retrieved while\nbuilding Opencast.\n\n\nDocker\n\n\nThere is a preconfigured Docker image for a Nexus server set-up for Opencast. To run an Opencast Nexus using Docker,\nfollow these steps:\n\n\ndocker run \\\n    --name mvncache \\\n    -p 8000:8000 \\\n    docker.io/lkiesow/opencast-maven-repository\n\n\n\n\n\nThe \n-p\n option will map the internal port of the server in Docker to the port on the host machine.\n\n\n\n\nPrefer a Specific Repository\n\n\nIf you did set-up a local repository or just want to select a specific global repository by default, you can use a\ncustom Maven configuration. To do that, create asettings file in \n~/.m2/settings.xml\n like this:\n\n\n<settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0\n  http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n  <mirrors>\n    <mirror>\n      <id>opencast-osna</id>\n      <name>Osnabr\u00fcck Opencast Repository</name>\n      <url>https://nexus.opencast.org/nexus/content/groups/public</url>\n      <mirrorOf>opencast</mirrorOf>\n    </mirror>\n  </mirrors>\n</settings>\n\n\n\nThis example would add a mirror for the primary Opencast Maven repository, causing the Osnabr\u00fcck repository to be the\npreferred repository to use. You can find some example configurations in \ndocs/maven/\n.\n\n\nPushing artifacts to Maven\n\n\nPushing to your local Maven repository\n\n\nThe following command will add a file to your local Maven repository.  This is useful for testing if your artifacts are\ncorrectly placed prior to pushing to the mainline Nexus repository.\n\n\nmvn install:install-file \\\n -Dfile=$filename \\\n -DgroupId=$groupId \\\n -DartifactId=$artifactId \\\n -Dpackaging=$packaging \\\n -Dversion=$version \\\n -DgeneratePom=$generatePom\n\n\n\nVariable Map\n\n\n\n\n\n\n\n\nVariable\n\n\nWhat it does\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nfilename\n\n\nThe path to the local file you want in your repository\n\n\naudio.mp2\n\n\n\n\n\n\ngroupId\n\n\nThe Opencast group ID\n\n\norg.opencastproject\n\n\n\n\n\n\nartifactId\n\n\nThe artifact ID. This is the name of the artifact according to Maven\n\n\naudio\n\n\n\n\n\n\npackaging\n\n\nThe file type (effectively), this should match the filename's extension\n\n\nmp2\n\n\n\n\n\n\nversion\n\n\nThe artifact's version\n\n\n1.1\n\n\n\n\n\n\ngeneratePom\n\n\nWhether or not to generate a pom file automatically\n\n\ntrue\n\n\n\n\n\n\n\n\nPushing to the remote Nexus repository\n\n\nThe following command will push a file to the remote Nexus repository.  Normally builds are pushed to to the remote\nautomatically as part of the CI server build, however if there is a need to push to the repo this is the command you\nneed. To deploy to the remote repository you will first need a username and password. This can be obtained from the QA\ncoordinator. Once you have that, put them in your \n.m2/settings.xml\n file. It should look like this\n\n\n<settings>\n  <servers>\n    <server>\n      <id>opencast</id>\n      <username>$username</username>\n      <password>$password</password>\n    </server>\n    ...\n  </servers>\n  ....\n</settings>\n\n\n\nThe command to push the file looks like this. Not that pushing files from your local Maven repository directly is not\npossible, instead you must copy them \noutside\n the repository and push from there. See below for help on that.\n\n\nmvn deploy:deploy-file \\\n  -DrepositoryId=$repo_id \\\n  -Durl=$url \\\n  -Dfile=$filename \\\n  -DgroupId=$groupId \\\n  -DartifactId=$artifactId \\\n  -Dpackaging=$packaging \\\n  -Dversion=$version \\\n  -DgeneratePom=$generatePom\n\n\n\nVariable Map\n\n\n\n\n\n\n\n\nVariable\n\n\nWhat it does\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nrepo_id\n\n\nIdentifies which set of credentials from your .m2/settings.xml file to use\n\n\nopencast\n\n\n\n\n\n\nurl\n\n\nWhere to push the file\n\n\nhttp://nexus.virtuos.uos.de:8081/nexus/content/repositories/snapshots\n\n\n\n\n\n\nfilename\n\n\nThe path to the local file you want in your repository\n\n\naudio_out.mp2\n\n\n\n\n\n\ngroupId\n\n\nThe Opencast group ID\n\n\norg.opencastproject\n\n\n\n\n\n\nartifactId\n\n\nThe artifact ID. This is the name of the artifact according to Maven\n\n\naudio\n\n\n\n\n\n\npackaging\n\n\nThe file type (effectively), this should match the filename's extension\n\n\nmp2\n\n\n\n\n\n\nversion\n\n\nThe artifact's version\n\n\n1.1\n\n\n\n\n\n\ngeneratePom\n\n\nWhether or not to generate a pom file automatically\n\n\ntrue\n\n\n\n\n\n\n\n\nHelp with push to the remote Nexus repository\n\n\nUploading to Nexus is more difficult than it should be: You can't just run deploy:deploy-file. This script is handy\nwhen you need to manually upload something like a previous release.  Make a copy of\n\n~/.m2/repository/org/opencastproject/*\n to \n$SOURCE_FILES\n inside of your git clone, check out the version you're\nuploading, then run this script.  There will be numerous errors as it processes things that either don't have\nartifacts, or don't have artifacts in the version you're uploading, but those can be ignored.\n\n\n#!/bin/bash\n\nCORE_NEXUS=\"nexus.virtuos.uos.de:8081\"\nSOURCE_FILES=\"nexus_copy\"\n\nuploadVersion() {\n  ls $1 | while read line\n  do\n    mvn deploy:deploy-file \\\n      -DrepositoryId=opencast \\\n      -Durl=http://$CORE_NEXUS/nexus/content/repositories/releases \\\n      -Dfile=$SOURCE_FILES/$line/$2/$line-$2.jar \\\n      -DgroupId=org.opencastproject -DartifactId=$line \\\n      -Dversion=$2 \\\n      -DgeneratePom=true \\\n      -Dpackaging=jar\n  done\n}\n\ngit checkout <VERSION>\nuploadVersion ~/.m2/repository/org/opencastproject <VERSION>",
            "title": "Maven Repository"
        },
        {
            "location": "/infrastructure/maven-repository/#opencast-maven-repository",
            "text": "The Maven repository server maintains a copy of all the Java dependencies used by Opencast.",
            "title": "Opencast Maven Repository"
        },
        {
            "location": "/infrastructure/maven-repository/#adding-libraries-to-the-repository",
            "text": "Login as an administrator on the  Opencast Nexus Master  Select repository  Select the artifact upload tab  Fill in the details and upload the file",
            "title": "Adding Libraries To The Repository"
        },
        {
            "location": "/infrastructure/maven-repository/#setting-up-another-maven-repository",
            "text": "Having a repository server run in your local network can significantly improve the speed artifacts are retrieved while\nbuilding Opencast.",
            "title": "Setting-up Another Maven Repository"
        },
        {
            "location": "/infrastructure/maven-repository/#docker",
            "text": "There is a preconfigured Docker image for a Nexus server set-up for Opencast. To run an Opencast Nexus using Docker,\nfollow these steps:  docker run \\\n    --name mvncache \\\n    -p 8000:8000 \\\n    docker.io/lkiesow/opencast-maven-repository   The  -p  option will map the internal port of the server in Docker to the port on the host machine.",
            "title": "Docker"
        },
        {
            "location": "/infrastructure/maven-repository/#prefer-a-specific-repository",
            "text": "If you did set-up a local repository or just want to select a specific global repository by default, you can use a\ncustom Maven configuration. To do that, create asettings file in  ~/.m2/settings.xml  like this:  <settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\"\n  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n  xsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0\n  http://maven.apache.org/xsd/settings-1.0.0.xsd\">\n  <mirrors>\n    <mirror>\n      <id>opencast-osna</id>\n      <name>Osnabr\u00fcck Opencast Repository</name>\n      <url>https://nexus.opencast.org/nexus/content/groups/public</url>\n      <mirrorOf>opencast</mirrorOf>\n    </mirror>\n  </mirrors>\n</settings>  This example would add a mirror for the primary Opencast Maven repository, causing the Osnabr\u00fcck repository to be the\npreferred repository to use. You can find some example configurations in  docs/maven/ .",
            "title": "Prefer a Specific Repository"
        },
        {
            "location": "/infrastructure/maven-repository/#pushing-artifacts-to-maven",
            "text": "",
            "title": "Pushing artifacts to Maven"
        },
        {
            "location": "/infrastructure/maven-repository/#pushing-to-your-local-maven-repository",
            "text": "The following command will add a file to your local Maven repository.  This is useful for testing if your artifacts are\ncorrectly placed prior to pushing to the mainline Nexus repository.  mvn install:install-file \\\n -Dfile=$filename \\\n -DgroupId=$groupId \\\n -DartifactId=$artifactId \\\n -Dpackaging=$packaging \\\n -Dversion=$version \\\n -DgeneratePom=$generatePom  Variable Map     Variable  What it does  Example      filename  The path to the local file you want in your repository  audio.mp2    groupId  The Opencast group ID  org.opencastproject    artifactId  The artifact ID. This is the name of the artifact according to Maven  audio    packaging  The file type (effectively), this should match the filename's extension  mp2    version  The artifact's version  1.1    generatePom  Whether or not to generate a pom file automatically  true",
            "title": "Pushing to your local Maven repository"
        },
        {
            "location": "/infrastructure/maven-repository/#pushing-to-the-remote-nexus-repository",
            "text": "The following command will push a file to the remote Nexus repository.  Normally builds are pushed to to the remote\nautomatically as part of the CI server build, however if there is a need to push to the repo this is the command you\nneed. To deploy to the remote repository you will first need a username and password. This can be obtained from the QA\ncoordinator. Once you have that, put them in your  .m2/settings.xml  file. It should look like this  <settings>\n  <servers>\n    <server>\n      <id>opencast</id>\n      <username>$username</username>\n      <password>$password</password>\n    </server>\n    ...\n  </servers>\n  ....\n</settings>  The command to push the file looks like this. Not that pushing files from your local Maven repository directly is not\npossible, instead you must copy them  outside  the repository and push from there. See below for help on that.  mvn deploy:deploy-file \\\n  -DrepositoryId=$repo_id \\\n  -Durl=$url \\\n  -Dfile=$filename \\\n  -DgroupId=$groupId \\\n  -DartifactId=$artifactId \\\n  -Dpackaging=$packaging \\\n  -Dversion=$version \\\n  -DgeneratePom=$generatePom  Variable Map     Variable  What it does  Example      repo_id  Identifies which set of credentials from your .m2/settings.xml file to use  opencast    url  Where to push the file  http://nexus.virtuos.uos.de:8081/nexus/content/repositories/snapshots    filename  The path to the local file you want in your repository  audio_out.mp2    groupId  The Opencast group ID  org.opencastproject    artifactId  The artifact ID. This is the name of the artifact according to Maven  audio    packaging  The file type (effectively), this should match the filename's extension  mp2    version  The artifact's version  1.1    generatePom  Whether or not to generate a pom file automatically  true",
            "title": "Pushing to the remote Nexus repository"
        },
        {
            "location": "/infrastructure/maven-repository/#help-with-push-to-the-remote-nexus-repository",
            "text": "Uploading to Nexus is more difficult than it should be: You can't just run deploy:deploy-file. This script is handy\nwhen you need to manually upload something like a previous release.  Make a copy of ~/.m2/repository/org/opencastproject/*  to  $SOURCE_FILES  inside of your git clone, check out the version you're\nuploading, then run this script.  There will be numerous errors as it processes things that either don't have\nartifacts, or don't have artifacts in the version you're uploading, but those can be ignored.  #!/bin/bash\n\nCORE_NEXUS=\"nexus.virtuos.uos.de:8081\"\nSOURCE_FILES=\"nexus_copy\"\n\nuploadVersion() {\n  ls $1 | while read line\n  do\n    mvn deploy:deploy-file \\\n      -DrepositoryId=opencast \\\n      -Durl=http://$CORE_NEXUS/nexus/content/repositories/releases \\\n      -Dfile=$SOURCE_FILES/$line/$2/$line-$2.jar \\\n      -DgroupId=org.opencastproject -DartifactId=$line \\\n      -Dversion=$2 \\\n      -DgeneratePom=true \\\n      -Dpackaging=jar\n  done\n}\n\ngit checkout <VERSION>\nuploadVersion ~/.m2/repository/org/opencastproject <VERSION>",
            "title": "Help with push to the remote Nexus repository"
        },
        {
            "location": "/api/",
            "text": "Opencast API\n\n\nIntroduction\n\n\nIn order to allow for robust technical integration of applications like learning management systems or mobile\napplications, Opencast offers an Application API (AAPI) to allow those applications to provide access\nto and management of resources exposed through the API.\nThe API has been designed and implemented to support large numbers of clients, each with considerable\namounts of requests per time interval. In addition, security has been a focus to ensure protection of the\nmanaged data and to support use cases promoting differing views on the managed data.\n\n\nArchitectural Overview\n\n\nThe Application API has been implemented as an abstraction layer to multiple internal APIs that the underlying\napplication (Opencast) offers for the manipulation of resources like series, events or users (see \nFigure\n1: Architectural overview\n).\n\n\nAuthentication and Authorization\n\n\nThe API features a dedicated security layer that is in charge of providing support for a variety of authentication\nand authorization mechanisms. Additionally, the security layer provides means for delegation of authorization to\nthe client application in cases where the API client needs to manage its own set of assets with implicit access\ncontrol.\nThese concepts are documented in greater detail in the following \nAuthentication\n and \nAuthorization\n chapters.\n\n\nRequests for data\n\n\nThe abstraction layer is backed by a dedicated index, which is kept up-to-date using Opencast\u2019s message\nbroker. When a request to an API method is received (1), the data is compiled using the index and returned to\nthe client (2). Since the index is scalable and optimized for performance, a large number of requests can be\nprocessed per time interval.\nThe corresponding requests along with the potential responses are defined later on in the \nAPI\n chapter.\n\n\nProcessing of updates\n\n\nWhenever a client sends updated information to the Application API, it will forward that information to the\ncorresponding Opencast services (3), which in turn will process the data and send messages to the\nmessage bus accordingly (4). The messages are consumed by the Application API\u2019s data store and can be\nserved to its clients from then on.\nThe corresponding requests along with the data structures and potential responses are defined later on in\nthe \nAPI\n chapter.\n\n\n\n\nFigure 1: Architectural overview\n\n\nRequests are authenticated and authorized (1), and corresponding responses are sent back to the client (2). Updates are passed on to the backing application services and the modified data is then received through the application\u2019s message infrastructure (4), (5).\n\n\nAccess\n\n\nThe Application API has been implemented using the \nRestful State Transfer\n paradigm to expose resources of the underlying system in the URL space that are then accessible using the HTTP protocol and verbs \nGET\n, \nPOST\n, \nPUT\n and \nDELETE\n.\n\n\nSince as part of the communication, the API is used to transfer potentially sensitive data between the client and the server including the username and password as part of the Basic Authentication protocol, the API will usually only be available over a secure HTTPS connection only.\n\n\nUrl Space\n\n\nThe API is located at the \n/api\n namespace on the Opencast admin node. This results in all requests to the Application API starting with \nhttps://<hostname>/api\n, where the hostname is depending on the installation and tenant (see \u201cMulti Tenancy\u201d).\n\n\nVersioning\n\n\nThe API is versioned so that applications developed against one version of the API won\u2019t break with enhancements or replacements of existing versions as long as they stay on the same major version. The set of currently supported versions as well as the current version are exposed through REST methods as part of the meta API.\n\n\nVersion scheme\n\n\nThe application API is following the \nsemantic versioning standard\n, which is suggesting the use of versions of the form \nx.z.y\n where \nx\n is the major version, \ny\n is the minor version and \nz\n is the patch level.\n\n\n\n\n\n\n\n\nPart\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nMajor\n\n\nChanges are potentially backward incompatible and require changing client code.\n\n\n\n\n\n\nMinor\n\n\nFunctionality is added in a backwards-compatible manner.\n\n\n\n\n\n\nPatch\n\n\nBugfixes applied in a backwards-compatible manner.\n\n\n\n\n\n\n\n\nBackwards Compatibility\n\n\nAs a consequence, the API is expected to be backwards compatible between minor version upgrades, including the patch level. This means that a client that has been developed against version 1.0.0 of the api will work with version 1.1.3 as well. This however may not be true going from version 1.1.0 to 2.0.0\n\n\nMulti tenancy\n\n\nWith Opencast being a multi tenant application, the application API reflects that characteristics as well. Requests are mapped to individual tenants by matching the requests\u2019s target hostname against the list of tenant hostnames.",
            "title": "Introduction"
        },
        {
            "location": "/api/#opencast-api",
            "text": "",
            "title": "Opencast API"
        },
        {
            "location": "/api/#introduction",
            "text": "In order to allow for robust technical integration of applications like learning management systems or mobile\napplications, Opencast offers an Application API (AAPI) to allow those applications to provide access\nto and management of resources exposed through the API.\nThe API has been designed and implemented to support large numbers of clients, each with considerable\namounts of requests per time interval. In addition, security has been a focus to ensure protection of the\nmanaged data and to support use cases promoting differing views on the managed data.",
            "title": "Introduction"
        },
        {
            "location": "/api/#architectural-overview",
            "text": "The Application API has been implemented as an abstraction layer to multiple internal APIs that the underlying\napplication (Opencast) offers for the manipulation of resources like series, events or users (see  Figure\n1: Architectural overview ).",
            "title": "Architectural Overview"
        },
        {
            "location": "/api/#authentication-and-authorization",
            "text": "The API features a dedicated security layer that is in charge of providing support for a variety of authentication\nand authorization mechanisms. Additionally, the security layer provides means for delegation of authorization to\nthe client application in cases where the API client needs to manage its own set of assets with implicit access\ncontrol.\nThese concepts are documented in greater detail in the following  Authentication  and  Authorization  chapters.",
            "title": "Authentication and Authorization"
        },
        {
            "location": "/api/#requests-for-data",
            "text": "The abstraction layer is backed by a dedicated index, which is kept up-to-date using Opencast\u2019s message\nbroker. When a request to an API method is received (1), the data is compiled using the index and returned to\nthe client (2). Since the index is scalable and optimized for performance, a large number of requests can be\nprocessed per time interval.\nThe corresponding requests along with the potential responses are defined later on in the  API  chapter.",
            "title": "Requests for data"
        },
        {
            "location": "/api/#processing-of-updates",
            "text": "Whenever a client sends updated information to the Application API, it will forward that information to the\ncorresponding Opencast services (3), which in turn will process the data and send messages to the\nmessage bus accordingly (4). The messages are consumed by the Application API\u2019s data store and can be\nserved to its clients from then on.\nThe corresponding requests along with the data structures and potential responses are defined later on in\nthe  API  chapter.   Figure 1: Architectural overview  Requests are authenticated and authorized (1), and corresponding responses are sent back to the client (2). Updates are passed on to the backing application services and the modified data is then received through the application\u2019s message infrastructure (4), (5).",
            "title": "Processing of updates"
        },
        {
            "location": "/api/#access",
            "text": "The Application API has been implemented using the  Restful State Transfer  paradigm to expose resources of the underlying system in the URL space that are then accessible using the HTTP protocol and verbs  GET ,  POST ,  PUT  and  DELETE .  Since as part of the communication, the API is used to transfer potentially sensitive data between the client and the server including the username and password as part of the Basic Authentication protocol, the API will usually only be available over a secure HTTPS connection only.",
            "title": "Access"
        },
        {
            "location": "/api/#url-space",
            "text": "The API is located at the  /api  namespace on the Opencast admin node. This results in all requests to the Application API starting with  https://<hostname>/api , where the hostname is depending on the installation and tenant (see \u201cMulti Tenancy\u201d).",
            "title": "Url Space"
        },
        {
            "location": "/api/#versioning",
            "text": "The API is versioned so that applications developed against one version of the API won\u2019t break with enhancements or replacements of existing versions as long as they stay on the same major version. The set of currently supported versions as well as the current version are exposed through REST methods as part of the meta API.",
            "title": "Versioning"
        },
        {
            "location": "/api/#version-scheme",
            "text": "The application API is following the  semantic versioning standard , which is suggesting the use of versions of the form  x.z.y  where  x  is the major version,  y  is the minor version and  z  is the patch level.     Part  Comment      Major  Changes are potentially backward incompatible and require changing client code.    Minor  Functionality is added in a backwards-compatible manner.    Patch  Bugfixes applied in a backwards-compatible manner.",
            "title": "Version scheme"
        },
        {
            "location": "/api/#backwards-compatibility",
            "text": "As a consequence, the API is expected to be backwards compatible between minor version upgrades, including the patch level. This means that a client that has been developed against version 1.0.0 of the api will work with version 1.1.3 as well. This however may not be true going from version 1.1.0 to 2.0.0",
            "title": "Backwards Compatibility"
        },
        {
            "location": "/api/#multi-tenancy",
            "text": "With Opencast being a multi tenant application, the application API reflects that characteristics as well. Requests are mapped to individual tenants by matching the requests\u2019s target hostname against the list of tenant hostnames.",
            "title": "Multi tenancy"
        },
        {
            "location": "/api/usage/",
            "text": "Version\n\n\nSince the API is versioned, it supports specification of a version identifier as part of the standard \nAccept\n HTTP request header:\n\n\n\n\n\n\n\n\nHeader\n\n\nType\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nAccept\n\n\nString\n\n\nThe format is specified to use \napplication/<version>\n, or \napplication/<version>+<format>\n to also specify the required format.\n\n\n\n\n\n\n\n\nSample\n\n\nAccept: application/v1.0.0+json\n\n\n\nIf that header is not specified, or no version information can be extracted from the header, the assumption is that the request should be executed against the most recent version. If the version specified is not available, \n400 (BAD REQUEST)\n is returned as the HTTP response code.\n\n\nWith every response, the api version is specified as part of the standard HTTP \nContent-Type\n header, as in \napplication/v1.0.0+xml\n.\n\n\nVersions should be specified as obtained from the \nBase API\n call to \n/versions\n.\n\n\nAuthentication\n\n\nThe API is using basic authentication. In order to make calls to the API, the following standard request headers need to be sent with every request:\n\n\n\n\n\n\n\n\nHeader\n\n\nType\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nAuthorization\n\n\nString\n\n\nSends username and password as defined in \nBasic Authentication\n\n\n\n\n\n\n\n\nAuthorization\n\n\nThere are multiple ways to authorize a request - see the \nauthorization section\n for more details. In short, the Application API either supports specifying the execution user, the execution user\u2019s roles or a combination of the two in which case the execution roles will be added to the execution user\u2019s existing roles.\n\n\nIf no user is specified, Opencast\u2019s \nanonymous\n user is used to execute the request, potentially enriched by the roles provided using the \nX-ROLES\n request.\n\n\n\n\n\n\n\n\nHeader\n\n\nType\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nX-API-AS-USER\n\n\nString\n\n\nId of the user in whose name the request should be executed\n\n\n\n\n\n\nX-API-WITH-ROLES\n\n\nString\n\n\nSet of roles, separated by whitespace, that the execution user should be assigned in addition to existing roles.\n\n\n\n\n\n\n\n\nFormats and Encoding\n\n\nContent Type\n\n\nThe Application API currently supports \nJSON\n format only.\n\n\n\n\n\n\n\n\nHeader\n\n\nType\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nAccept\n\n\nString\n\n\nThe expected response format is \napplication/json\n\n\n\n\n\n\n\n\nIf that header is not specified, the \nContent-Type\n will be \napplication/<version>+json\n.\n\n\n\n\nNote that the same header should be used to specify the version of the api that is expected to return the response. In this case, the header looks like this: \napplication/v1+json\n. See the \nversioning chapter of the general section\n for more details.\n\n\n\n\nData types\n\n\n\n\n\n\n\n\nType\n\n\nEncoding\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nDate\n\n\nISO 8601\n\n\nE. g. 2015-03-11\n\n\n\n\n\n\nDate Time\n\n\nISO 8601\n\n\nE. g. 2015-03-11T13:23:51Z\n\n\n\n\n\n\nDate (Time) range\n\n\nISO 8601\n\n\ndate | date \u201c/\u201d | \u201d/\u201d date | date \u201c/\u201d date | date\n\n\n\n\n\n\n\n\nEncoding of single objects\n\n\nJSON notation\n\n\nSingle objects are enclosed in curly braces \"{}\" and are not explicitly named.\n\n\nSample\n\n\n{\n  \"firstname\": \"John\",\n  \"lastname\": \"Doe\"\n}\n\n\n\nEncoding of collections of objects\n\n\nJSON notation\n\n\nCollections of objects are enclosed in braces \"[ ... ]\" and are not explicitly named.\n\n\nSample\n\n\n[\n  {\n    \"firstname\": \"Jane\",\n    \"lastname\": \"Doe\"\n  },\n  {\n    \"firstname\": \"John\",\n    \"lastname\": \"Doe\"\n  }\n]\n\n\n\nEncoding of empty fields\n\n\nInstead of dropping fields that do not contain a value for a specific data object from the JSON response structure, the respective identity element should be used:\n\n\n\n\n\n\n\n\nType\n\n\nEncoding\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nLiterals\n\n\n\"\"\n\n\nStrings and numbers\n\n\n\n\n\n\nObjects\n\n\n{}\n\n\nNon-existing objects\n\n\n\n\n\n\nArrays\n\n\n[]\n\n\nNon-existing list of literals or objects\n\n\n\n\n\n\n\n\nSorting\n\n\nSorting of result sets is supported by a set of well-defined fields per request, one at a time. Each api request explicitly defines the fields that support sorting.\n\n\nSort field\n\n\n\n\n\n\n\n\nParameter\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nsort\n\n\nTakes the name of the field that defines the sort criteria.\n\n\n\n\n\n\n\n\nExample\n\n\nOrdering the list of events by title:\n\n\nGET /api/events?sort=title\n\n\n\nSort order\n\n\n\n\n\n\n\n\nParameter\n\n\nEncoding\n\n\nComment\n\n\n\n\n\n\n\n\n\n\norder\n\n\nasc\n, \ndesc\n\n\nDefault value is \nasc\n.\n\n\n\n\n\n\n\n\nExample\n\n\nOrdering the list of events by title in ascending order:\n\n\nGET /api/events?sort=title&order=asc\n\n\n\nFiltering\n\n\nFiltering of result sets is supported by a set of well-defined fields per request. Multiple filter criteria can be defined by specifying the \nfilter\n parameter more than once. In this case, the criteria are applied using logical \nand\n.\n\n\nEach api request explicitly defines the fields that support filtering.\n\n\n\n\n\n\n\n\nParamter\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nfilter\n\n\nFilter conditions must be URL encoded\n\n\n\n\n\n\n\n\nExample\n\n\nFilter the list of events by status and by series.\n\n\nGET /api/events?filter=status%3dpublished&filter=series%3dmath\n\n\n\nPaging\n\n\nWhen loading large result sets, being able to address and access the data in well-defined chunks using a limit and offset is essential. Paging is enabled for all requests that return lists of items.\n\n\n\n\n\n\n\n\nParamter\n\n\nComment\n\n\n\n\n\n\n\n\n\n\nlimit\n\n\nThe number of records to return per request\n\n\n\n\n\n\noffset\n\n\nThe index of the first record to return\n\n\n\n\n\n\n\n\nExample\n\n\nFrom the list of events, return items 50-74.\n\n\nGET /api/events?limit=25&offset=50",
            "title": "Usage"
        },
        {
            "location": "/api/usage/#version",
            "text": "Since the API is versioned, it supports specification of a version identifier as part of the standard  Accept  HTTP request header:     Header  Type  Comment      Accept  String  The format is specified to use  application/<version> , or  application/<version>+<format>  to also specify the required format.     Sample  Accept: application/v1.0.0+json  If that header is not specified, or no version information can be extracted from the header, the assumption is that the request should be executed against the most recent version. If the version specified is not available,  400 (BAD REQUEST)  is returned as the HTTP response code.  With every response, the api version is specified as part of the standard HTTP  Content-Type  header, as in  application/v1.0.0+xml .  Versions should be specified as obtained from the  Base API  call to  /versions .",
            "title": "Version"
        },
        {
            "location": "/api/usage/#authentication",
            "text": "The API is using basic authentication. In order to make calls to the API, the following standard request headers need to be sent with every request:     Header  Type  Comment      Authorization  String  Sends username and password as defined in  Basic Authentication",
            "title": "Authentication"
        },
        {
            "location": "/api/usage/#authorization",
            "text": "There are multiple ways to authorize a request - see the  authorization section  for more details. In short, the Application API either supports specifying the execution user, the execution user\u2019s roles or a combination of the two in which case the execution roles will be added to the execution user\u2019s existing roles.  If no user is specified, Opencast\u2019s  anonymous  user is used to execute the request, potentially enriched by the roles provided using the  X-ROLES  request.     Header  Type  Comment      X-API-AS-USER  String  Id of the user in whose name the request should be executed    X-API-WITH-ROLES  String  Set of roles, separated by whitespace, that the execution user should be assigned in addition to existing roles.",
            "title": "Authorization"
        },
        {
            "location": "/api/usage/#formats-and-encoding",
            "text": "",
            "title": "Formats and Encoding"
        },
        {
            "location": "/api/usage/#content-type",
            "text": "The Application API currently supports  JSON  format only.     Header  Type  Comment      Accept  String  The expected response format is  application/json     If that header is not specified, the  Content-Type  will be  application/<version>+json .   Note that the same header should be used to specify the version of the api that is expected to return the response. In this case, the header looks like this:  application/v1+json . See the  versioning chapter of the general section  for more details.",
            "title": "Content Type"
        },
        {
            "location": "/api/usage/#data-types",
            "text": "Type  Encoding  Comment      Date  ISO 8601  E. g. 2015-03-11    Date Time  ISO 8601  E. g. 2015-03-11T13:23:51Z    Date (Time) range  ISO 8601  date | date \u201c/\u201d | \u201d/\u201d date | date \u201c/\u201d date | date",
            "title": "Data types"
        },
        {
            "location": "/api/usage/#encoding-of-single-objects",
            "text": "",
            "title": "Encoding of single objects"
        },
        {
            "location": "/api/usage/#json-notation",
            "text": "Single objects are enclosed in curly braces \"{}\" and are not explicitly named.  Sample  {\n  \"firstname\": \"John\",\n  \"lastname\": \"Doe\"\n}",
            "title": "JSON notation"
        },
        {
            "location": "/api/usage/#encoding-of-collections-of-objects",
            "text": "",
            "title": "Encoding of collections of objects"
        },
        {
            "location": "/api/usage/#json-notation_1",
            "text": "Collections of objects are enclosed in braces \"[ ... ]\" and are not explicitly named.  Sample  [\n  {\n    \"firstname\": \"Jane\",\n    \"lastname\": \"Doe\"\n  },\n  {\n    \"firstname\": \"John\",\n    \"lastname\": \"Doe\"\n  }\n]",
            "title": "JSON notation"
        },
        {
            "location": "/api/usage/#encoding-of-empty-fields",
            "text": "Instead of dropping fields that do not contain a value for a specific data object from the JSON response structure, the respective identity element should be used:     Type  Encoding  Comment      Literals  \"\"  Strings and numbers    Objects  {}  Non-existing objects    Arrays  []  Non-existing list of literals or objects",
            "title": "Encoding of empty fields"
        },
        {
            "location": "/api/usage/#sorting",
            "text": "Sorting of result sets is supported by a set of well-defined fields per request, one at a time. Each api request explicitly defines the fields that support sorting.",
            "title": "Sorting"
        },
        {
            "location": "/api/usage/#sort-field",
            "text": "Parameter  Comment      sort  Takes the name of the field that defines the sort criteria.     Example  Ordering the list of events by title:  GET /api/events?sort=title",
            "title": "Sort field"
        },
        {
            "location": "/api/usage/#sort-order",
            "text": "Parameter  Encoding  Comment      order  asc ,  desc  Default value is  asc .     Example  Ordering the list of events by title in ascending order:  GET /api/events?sort=title&order=asc",
            "title": "Sort order"
        },
        {
            "location": "/api/usage/#filtering",
            "text": "Filtering of result sets is supported by a set of well-defined fields per request. Multiple filter criteria can be defined by specifying the  filter  parameter more than once. In this case, the criteria are applied using logical  and .  Each api request explicitly defines the fields that support filtering.     Paramter  Comment      filter  Filter conditions must be URL encoded     Example  Filter the list of events by status and by series.  GET /api/events?filter=status%3dpublished&filter=series%3dmath",
            "title": "Filtering"
        },
        {
            "location": "/api/usage/#paging",
            "text": "When loading large result sets, being able to address and access the data in well-defined chunks using a limit and offset is essential. Paging is enabled for all requests that return lists of items.     Paramter  Comment      limit  The number of records to return per request    offset  The index of the first record to return     Example  From the list of events, return items 50-74.  GET /api/events?limit=25&offset=50",
            "title": "Paging"
        },
        {
            "location": "/api/authentication/",
            "text": "Introduction\n\n\nThe Application API\u2019s security layer is designed to support a multitude of mechanisms for authentication such as api keys, digest authentication and others. While the current implementation only supports basic authentication, further authentication mechanisms may be added in the future.\n\n\nBasic Authentication\n\n\nThe Application API is protected by basic authentication, requiring a user and a password be sent in the form of the standard HTTP \nAuthorization\n header. (see \nFigure 2\n). In the header, the username and password are sent encoded in Base64 format.\nThe incoming requests are matched against an existing user whose password needs to match with the one that is found in the Authorization request header.\n\n\nNOTE: Basic authentication is not activated by default, please activate it in the security settings (\netc/security/mh_default_org.xml\n) before using the Application API.\n\n\n\n\n\n\n\n\nFigure 2: Authentication and\u2028 authorization based on Basic\u2028 Authentication\n\n\nProtection of authentication data\n\n\nSince Base64 is by no means regarded as encryption in the sense of security, it is strongly recommended to only offer access to the Application API over HTTPS rather than over HTTP in order to avoid unprotected transmission of the username and password via the Authorization header.\n\n\nValidation criteria\n\n\nWhen initiating the connection, the Application API analyzes the header and extracts the username to match against an existing API user. If that user is found, the connection is authenticated, otherwise it\u2019s rejected.",
            "title": "Authentication"
        },
        {
            "location": "/api/authentication/#introduction",
            "text": "The Application API\u2019s security layer is designed to support a multitude of mechanisms for authentication such as api keys, digest authentication and others. While the current implementation only supports basic authentication, further authentication mechanisms may be added in the future.",
            "title": "Introduction"
        },
        {
            "location": "/api/authentication/#basic-authentication",
            "text": "The Application API is protected by basic authentication, requiring a user and a password be sent in the form of the standard HTTP  Authorization  header. (see  Figure 2 ). In the header, the username and password are sent encoded in Base64 format.\nThe incoming requests are matched against an existing user whose password needs to match with the one that is found in the Authorization request header.  NOTE: Basic authentication is not activated by default, please activate it in the security settings ( etc/security/mh_default_org.xml ) before using the Application API.     Figure 2: Authentication and\u2028 authorization based on Basic\u2028 Authentication",
            "title": "Basic Authentication"
        },
        {
            "location": "/api/authentication/#protection-of-authentication-data",
            "text": "Since Base64 is by no means regarded as encryption in the sense of security, it is strongly recommended to only offer access to the Application API over HTTPS rather than over HTTP in order to avoid unprotected transmission of the username and password via the Authorization header.",
            "title": "Protection of authentication data"
        },
        {
            "location": "/api/authentication/#validation-criteria",
            "text": "When initiating the connection, the Application API analyzes the header and extracts the username to match against an existing API user. If that user is found, the connection is authenticated, otherwise it\u2019s rejected.",
            "title": "Validation criteria"
        },
        {
            "location": "/api/authorization/",
            "text": "Introduction\n\n\nThe Application API can be accessed in two different ways: Either using a single dedicated user with access to everything (\u201csuper user\u201d) or by implementing more fine grained access through user and role switching upon every request (\u201cuser switching\u201d or \u201csudo\u201d execution mode), where the request is executed in the name and using the roles of the specified user.\n\n\nThe first method is ideal for scenarios where the end users of the external application are not managed in Opencast. The downside of this approach is a potential security risk as well as the inability to audit and track changes made by the external applications back to the actual user who actually triggered the changes. The second method is more cumbersome to implement but leads a much improved control and assessment of security.\n\n\nDelegation of Authorization\n\n\nIn situations where the provider of the API offers a super user who is allowed \u201csudo\u201d requests that are executed on behalf of another user, the API is actually delegating authorization to the client application. In this cause authorization is performed upon login of the super user, but then the super user can switch to any other user or any set of roles (with a few exceptions for security reasons).\n\n\nNote that in order to allow for user switching, a specific role needs to be assigned to the super user, and that role cannot be obtained by manipulating the role set (see \nRole switching\n).\n\n\nUser switching\n\n\nWhen working with a super user, it is considered a best practice to specify a dedicated execution user upon each request whenever possible and reasonable. This way, creation or modification of resources can later be audited and mapped back to that user if needed.\n\n\nThe execution user can be specified by setting the \nX-RUN-AS-USER\n request header with the user name as its value, as seen in this sample request:\n\n\n\n\n\n\n\n\nRequest\n\n\nHeaders\n\n\n\n\n\n\n\n\n\n\nGET /api\n\n\nX-RUN-AS-USER: john.doe\n\n\n\n\n\n\n\n\nSwitching to another user can potentially fail for various reasons: The user might not exist or may not be allowed to switch to due to potential privilege escalation, or the current user might not be allowed to switch users at all.\n\n\nIf the request to switch to another user fails, the following response codes are returned:\n\n\n\n\n\n\n\n\nResponse code\n\n\nComment\n\n\n\n\n\n\n\n\n\n\n403 (FORBIDDEN)\n\n\nThe current user is not allowed to switch users\n\n\n\n\n\n\n403 (FORBIDDEN)\n\n\nThe user cannot be switched to due to potential escalation of privileges\n\n\n\n\n\n\n412 Precondition failed\n\n\nThe user specified in the X-RUN-AS-USER header does not exist\n\n\n\n\n\n\n\n\nRole switching\n\n\nRather than specifying an execution user, the client might choose to specify a set of roles that should be used when executing the request. This technique is recommended in cases where the users are not managed by the API. By specifying a set of roles, the corresponding request will be executed using the API\u2019s anonymous user but equipped with the specified set of roles.\n\n\nThe execution user\u2019s roles can be specified by setting the \nX-RUN-WITH-ROLES\n request header with the set of roles as its value and with individual roles separated by comma, as seen in this sample request:\n\n\n\n\n\n\n\n\nRequest\n\n\nHeaders\n\n\n\n\n\n\n\n\n\n\nGET /api\n\n\nX-RUN-WITH-ROLES: ROLE_A,ROLE_B\n\n\n\n\n\n\n\n\nSwitching to a set of roles can potentially fail for various reasons: The role may not be granted to due to potential privilege escalation, or the current user might not be allowed to switch roles at all.\nIf the request to apply a set of roles fails, the following response codes are returned:\n\n\n\n\n\n\n\n\nResponse code\n\n\nComment\n\n\n\n\n\n\n\n\n\n\n403 (FORBIDDEN)\n\n\nThe current user is not allowed to switch roles\n\n\n\n\n\n\n403 (FORBIDDEN)\n\n\nThe roles cannot be granted to due to potential escalation of privileges\n\n\n\n\n\n\n\n\nBest practice\n\n\nOne user per external application\n\n\nAs a best practice, the API provider should create one super user per external application and tenant, so that access through that super user can be controlled, limited and turned off individually for each external application and tenant.\n\n\nPreference for user and role switching\n\n\nClient implementations accessing the API through a super user are urged to implement and enforce user and role switching as much as possible, since it allows for auditing of user activity on the API and introduces less risk by running requests with a limited set of privileges.\n\n\nObviously, if all requests are executed using the super user directly, it is not possible to track which user initiated a given action.\n\n\nAccess Control\n\n\nMost events in Opencast come with an access control list (ACL), containing entries that map actions to roles, either allowing or denying that action. Opencast currently only supports the ability to explicitly allow an action and consider everything else to be denied.\n\n\nRoles\n\n\nWhen a user authenticates against Opencast, it is assigned its set of roles that determine the user's access to Opencast data entities. There are multiple ways to associate roles with a user:\n\n\n\n\nExplicit assignment directly to the user\n\n\nDirectly through membership in groups (ROLE_GROUP_<group name>)\n\n\nIndirectly through membership in groups (whatever roles have been assigned to the group)\n\n\n\n\nIn addition, a special role is assigned that uniquely identifies a user (\"user role\"). The user role can be determined by\nevaluating the \nuserrole\n attribute in the Base API's call to \n/info/me\n.",
            "title": "Authorization"
        },
        {
            "location": "/api/authorization/#introduction",
            "text": "The Application API can be accessed in two different ways: Either using a single dedicated user with access to everything (\u201csuper user\u201d) or by implementing more fine grained access through user and role switching upon every request (\u201cuser switching\u201d or \u201csudo\u201d execution mode), where the request is executed in the name and using the roles of the specified user.  The first method is ideal for scenarios where the end users of the external application are not managed in Opencast. The downside of this approach is a potential security risk as well as the inability to audit and track changes made by the external applications back to the actual user who actually triggered the changes. The second method is more cumbersome to implement but leads a much improved control and assessment of security.",
            "title": "Introduction"
        },
        {
            "location": "/api/authorization/#delegation-of-authorization",
            "text": "In situations where the provider of the API offers a super user who is allowed \u201csudo\u201d requests that are executed on behalf of another user, the API is actually delegating authorization to the client application. In this cause authorization is performed upon login of the super user, but then the super user can switch to any other user or any set of roles (with a few exceptions for security reasons).  Note that in order to allow for user switching, a specific role needs to be assigned to the super user, and that role cannot be obtained by manipulating the role set (see  Role switching ).",
            "title": "Delegation of Authorization"
        },
        {
            "location": "/api/authorization/#user-switching",
            "text": "When working with a super user, it is considered a best practice to specify a dedicated execution user upon each request whenever possible and reasonable. This way, creation or modification of resources can later be audited and mapped back to that user if needed.  The execution user can be specified by setting the  X-RUN-AS-USER  request header with the user name as its value, as seen in this sample request:     Request  Headers      GET /api  X-RUN-AS-USER: john.doe     Switching to another user can potentially fail for various reasons: The user might not exist or may not be allowed to switch to due to potential privilege escalation, or the current user might not be allowed to switch users at all.  If the request to switch to another user fails, the following response codes are returned:     Response code  Comment      403 (FORBIDDEN)  The current user is not allowed to switch users    403 (FORBIDDEN)  The user cannot be switched to due to potential escalation of privileges    412 Precondition failed  The user specified in the X-RUN-AS-USER header does not exist",
            "title": "User switching"
        },
        {
            "location": "/api/authorization/#role-switching",
            "text": "Rather than specifying an execution user, the client might choose to specify a set of roles that should be used when executing the request. This technique is recommended in cases where the users are not managed by the API. By specifying a set of roles, the corresponding request will be executed using the API\u2019s anonymous user but equipped with the specified set of roles.  The execution user\u2019s roles can be specified by setting the  X-RUN-WITH-ROLES  request header with the set of roles as its value and with individual roles separated by comma, as seen in this sample request:     Request  Headers      GET /api  X-RUN-WITH-ROLES: ROLE_A,ROLE_B     Switching to a set of roles can potentially fail for various reasons: The role may not be granted to due to potential privilege escalation, or the current user might not be allowed to switch roles at all.\nIf the request to apply a set of roles fails, the following response codes are returned:     Response code  Comment      403 (FORBIDDEN)  The current user is not allowed to switch roles    403 (FORBIDDEN)  The roles cannot be granted to due to potential escalation of privileges",
            "title": "Role switching"
        },
        {
            "location": "/api/authorization/#best-practice",
            "text": "",
            "title": "Best practice"
        },
        {
            "location": "/api/authorization/#one-user-per-external-application",
            "text": "As a best practice, the API provider should create one super user per external application and tenant, so that access through that super user can be controlled, limited and turned off individually for each external application and tenant.",
            "title": "One user per external application"
        },
        {
            "location": "/api/authorization/#preference-for-user-and-role-switching",
            "text": "Client implementations accessing the API through a super user are urged to implement and enforce user and role switching as much as possible, since it allows for auditing of user activity on the API and introduces less risk by running requests with a limited set of privileges.  Obviously, if all requests are executed using the super user directly, it is not possible to track which user initiated a given action.",
            "title": "Preference for user and role switching"
        },
        {
            "location": "/api/authorization/#access-control",
            "text": "Most events in Opencast come with an access control list (ACL), containing entries that map actions to roles, either allowing or denying that action. Opencast currently only supports the ability to explicitly allow an action and consider everything else to be denied.",
            "title": "Access Control"
        },
        {
            "location": "/api/authorization/#roles",
            "text": "When a user authenticates against Opencast, it is assigned its set of roles that determine the user's access to Opencast data entities. There are multiple ways to associate roles with a user:   Explicit assignment directly to the user  Directly through membership in groups (ROLE_GROUP_<group name>)  Indirectly through membership in groups (whatever roles have been assigned to the group)   In addition, a special role is assigned that uniquely identifies a user (\"user role\"). The user role can be determined by\nevaluating the  userrole  attribute in the Base API's call to  /info/me .",
            "title": "Roles"
        },
        {
            "location": "/api/glossary/",
            "text": "General\n\n\nClient\n\n\nA system that is using this API, making requests and consuming responses.\n\n\nData\n\n\nEvent\n\n\nA recording that is either going to take place, has been recorded using Opencast scheduling or has been uploaded either using this API or the Opencast administrative user interface. A collection of events may be grouped using a series.\n\n\nSeries\n\n\nA collection of events.\n\n\nUsers and Groups\n\n\nUser\n\n\nA person accessing data provided by the API.\n\n\nProducer\n\n\nA user that is managing individual recordings or groups of recordings. The producer uses the API to create, curate, publish, retract recordings.\n\n\nSpectator\n\n\nA spectator accesses a subset of recordings that has been published by a producer.",
            "title": "Glossary"
        },
        {
            "location": "/api/glossary/#general",
            "text": "",
            "title": "General"
        },
        {
            "location": "/api/glossary/#client",
            "text": "A system that is using this API, making requests and consuming responses.",
            "title": "Client"
        },
        {
            "location": "/api/glossary/#data",
            "text": "",
            "title": "Data"
        },
        {
            "location": "/api/glossary/#event",
            "text": "A recording that is either going to take place, has been recorded using Opencast scheduling or has been uploaded either using this API or the Opencast administrative user interface. A collection of events may be grouped using a series.",
            "title": "Event"
        },
        {
            "location": "/api/glossary/#series",
            "text": "A collection of events.",
            "title": "Series"
        },
        {
            "location": "/api/glossary/#users-and-groups",
            "text": "",
            "title": "Users and Groups"
        },
        {
            "location": "/api/glossary/#user",
            "text": "A person accessing data provided by the API.",
            "title": "User"
        },
        {
            "location": "/api/glossary/#producer",
            "text": "A user that is managing individual recordings or groups of recordings. The producer uses the API to create, curate, publish, retract recordings.",
            "title": "Producer"
        },
        {
            "location": "/api/glossary/#spectator",
            "text": "A spectator accesses a subset of recordings that has been published by a producer.",
            "title": "Spectator"
        },
        {
            "location": "/api/base-api/",
            "text": "Information\n\n\nGET /api\n\n\n\n\n\n\nUser and Organization\n\n\nGET /api/info/me\n\n\nGET /api/info/me/roles\n\n\nGET /api/info/organization\n\n\nGET /api/info/organization/properties\n\n\n\n\n\n\nVersions\n\n\nGET /api/version\n\n\nGET /api/version/default\n\n\n\n\n\n\n\n\n\n\nInformation\n\n\nIn order to assess key characteristics of the API and to test general connectivity, the API\u2019s root url is not protected through authentication:\n\n\nGET /api\n\n\nReturns key characteristics of the API such as the server name and the default version.\n\n\nResponse\n\n\n200 (OK)\n: The api information is returned.\n\n\n{\n  \"url\": \"https:\\/\\/api.opencast.org\",\n  \"version\": \"v1.0.1\"\n}\n\n\n\nUser and Organization\n\n\nGET /api/info/me\n\n\nReturns information on the logged in user.\n\n\nResponse\n\n\n200 (OK)\n: The user information is returned.\n\n\n{\n  \"email\": \"nowhere@opencast.org\",\n  \"name\": \"Opencast Student\",\n  \"provider\": \"opencast\",\n  \"userrole\": \"ROLE_USER_92623987_OPENCAST_ORG\",\n  \"username\": \"92623987@opencast.org\"\n}\n\n\n\nGET /api/info/me/roles\n\n\nReturns current user's roles.\n\n\nResponse\n\n\n200 (OK)\n: The set of roles is returned.\n\n\n[\n  \"ROLE_USER_92623987@opencast.org\",\n  \"ROLE_STUDENT\"\n]\n\n\n\nGET /api/info/organization\n\n\nReturns the current organization.\n\n\nResponse\n\n\n200 (OK)\n: The organization details are returned.\n\n\n{\n  \"adminRole\": \"ROLE_ADMIN\",\n  \"anonymousRole\": \"ROLE_ANONYMOUS\",\n  \"id\": \"opencast\",\n  \"name\": \"Opencast\"\n}\n\n\n\nGET /api/info/organization/properties\n\n\nReturns the current organization's properties.\n\n\nResponse\n\n\n200 (OK)\n: The organization properties are returned.\n\n\n{\n  \"org.opencastproject.feed.url\": \"http://feeds.opencast.org\",\n  \"org.opencastproject.admin.documentation.url\": \"http://documentation.opencast.org\",\n  \"org.opencastproject.external.api.url\": \"http://api.opencast.org\"\n}\n\n\n\nVersions\n\n\nGET /api/version\n\n\nReturns a list of available version as well as the default version.\n\n\nResponse\n\n\n200 (OK)\n: The default version is returned.\n\n\n{\n  \"versions\": [\n    \"v1.0.0\",\n    \"v1.1.0\"\n  ],\n  \"default\": \"v1.1.0\"\n}\n\n\n\nGET /api/version/default\n\n\nReturns the default version.\n\n\nResponse\n\n\n200 (OK)\n: The default version is returned.\n\n\n{\n  \"default\": \"v1.1.0\"\n}",
            "title": "Base API"
        },
        {
            "location": "/api/base-api/#information",
            "text": "In order to assess key characteristics of the API and to test general connectivity, the API\u2019s root url is not protected through authentication:",
            "title": "Information"
        },
        {
            "location": "/api/base-api/#get-api",
            "text": "Returns key characteristics of the API such as the server name and the default version.  Response  200 (OK) : The api information is returned.  {\n  \"url\": \"https:\\/\\/api.opencast.org\",\n  \"version\": \"v1.0.1\"\n}",
            "title": "GET /api"
        },
        {
            "location": "/api/base-api/#user-and-organization",
            "text": "",
            "title": "User and Organization"
        },
        {
            "location": "/api/base-api/#get-apiinfome",
            "text": "Returns information on the logged in user.  Response  200 (OK) : The user information is returned.  {\n  \"email\": \"nowhere@opencast.org\",\n  \"name\": \"Opencast Student\",\n  \"provider\": \"opencast\",\n  \"userrole\": \"ROLE_USER_92623987_OPENCAST_ORG\",\n  \"username\": \"92623987@opencast.org\"\n}",
            "title": "GET /api/info/me"
        },
        {
            "location": "/api/base-api/#get-apiinfomeroles",
            "text": "Returns current user's roles.  Response  200 (OK) : The set of roles is returned.  [\n  \"ROLE_USER_92623987@opencast.org\",\n  \"ROLE_STUDENT\"\n]",
            "title": "GET /api/info/me/roles"
        },
        {
            "location": "/api/base-api/#get-apiinfoorganization",
            "text": "Returns the current organization.  Response  200 (OK) : The organization details are returned.  {\n  \"adminRole\": \"ROLE_ADMIN\",\n  \"anonymousRole\": \"ROLE_ANONYMOUS\",\n  \"id\": \"opencast\",\n  \"name\": \"Opencast\"\n}",
            "title": "GET /api/info/organization"
        },
        {
            "location": "/api/base-api/#get-apiinfoorganizationproperties",
            "text": "Returns the current organization's properties.  Response  200 (OK) : The organization properties are returned.  {\n  \"org.opencastproject.feed.url\": \"http://feeds.opencast.org\",\n  \"org.opencastproject.admin.documentation.url\": \"http://documentation.opencast.org\",\n  \"org.opencastproject.external.api.url\": \"http://api.opencast.org\"\n}",
            "title": "GET /api/info/organization/properties"
        },
        {
            "location": "/api/base-api/#versions",
            "text": "",
            "title": "Versions"
        },
        {
            "location": "/api/base-api/#get-apiversion",
            "text": "Returns a list of available version as well as the default version.  Response  200 (OK) : The default version is returned.  {\n  \"versions\": [\n    \"v1.0.0\",\n    \"v1.1.0\"\n  ],\n  \"default\": \"v1.1.0\"\n}",
            "title": "GET /api/version"
        },
        {
            "location": "/api/base-api/#get-apiversiondefault",
            "text": "Returns the default version.  Response  200 (OK) : The default version is returned.  {\n  \"default\": \"v1.1.0\"\n}",
            "title": "GET /api/version/default"
        },
        {
            "location": "/api/events-api/",
            "text": "General\n\n\nGET /api/events\n\n\nPOST /api/events\n\n\nGET /api/events/{event_id}\n\n\nPOST /api/events/{event_id}\n\n\nDELETE /api/events/{event_id}\n\n\n\n\n\n\nAccess Policy\n\n\nGET /api/events/{event_id}/acl\n\n\nPUT /api/events/{event_id}/acl\n\n\nPOST /api/events/{event_id}/acl/{action}\n\n\nDELETE /api/events/{event_id}/acl/{action}/{role}\n\n\n\n\n\n\nMetadata\n\n\nGET /api/events/{event_id}/metadata\n\n\nGET /api/events/{event_id}/metadata\n\n\nPUT /api/events/{event_id}/metadata\n\n\nDELETE /api/events/{event_id}/metadata\n\n\n\n\n\n\nPublications\n\n\nGET /api/events/{event_id}/publications\n\n\nGET /api/events/{event_id}/publications/{publication_id}\n\n\n\n\n\n\n\n\n\n\nGeneral\n\n\nGET /api/events\n\n\nReturns a list of events.\n\n\nBy setting the optional \nsign\n parameter to \ntrue\n, the method will pre-sign distribution urls if signing is turned on in Opencast. Remember to consider the \nmaximum validity of signed URLs\n when caching this response.\n\n\n\n\n\n\n\n\nQuery String Parameter\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsign\n\n\nboolean\n\n\nWhether public distribution urls should be signed.\n\n\n\n\n\n\nwithacl\n\n\nboolean\n\n\nWhether the acl metadata should be included in the response.\n\n\n\n\n\n\nwithmetadata\n\n\nboolean\n\n\nWhether the metadata catalogs should be included in the response.\n\n\n\n\n\n\nwithpublications\n\n\nboolean\n\n\nWhether the publication ids and urls should be included in the response.\n\n\n\n\n\n\nfilter\n\n\nstring\n\n\nA comma seperated list of filters to limit the results with. A filter is the filter's name followed by a colon \":\" and then the value to filter with so it is the form \nFilter Name\n:\nValue to Filter With\n. See the below table for the list of available filters.\n\n\n\n\n\n\nsort\n\n\nstring\n\n\nSort the results based upon a list of comma seperated sorting criteria. In the comma seperated list each type of sorting is specified as a pair such as: \nSort Name\n:\nASC\n or \nSort Name\n:\nDESC\n. Adding the suffix ASC or DESC sets the order as ascending or descending order and is mandatory. See the below table about the available sort names in the table below.\n\n\n\n\n\n\nlimit\n\n\ninteger\n\n\nThe maximum number of results to return for a single request.\n\n\n\n\n\n\noffset\n\n\ninteger\n\n\nNumber of results to skip based on the limit. 0 is the first set of results up to the limit, 1 is the second set of results after the first limit, 2 is third set of results after skipping the first two sets of results etc.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFilter Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ncontributors\n\n\nEvents where the contributors match.\n\n\n\n\n\n\nlocation\n\n\nEvents based upon the location it is scheduled in.\n\n\n\n\n\n\nseries\n\n\nEvents based upon which series they are a part of.\n\n\n\n\n\n\nsubject\n\n\nFilters events based upon which subject they are a part of.\n\n\n\n\n\n\ntextFilter\n\n\nFilters events where any part of the event's metadata fields match this value.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSort Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntitle\n\n\nBy the title of the event.\n\n\n\n\n\n\npresenter\n\n\nBy the presenter of the event.\n\n\n\n\n\n\nstart_date\n\n\nBy the start date of the event.\n\n\n\n\n\n\nend_date\n\n\nBy the end date of the event.\n\n\n\n\n\n\nreview_status\n\n\nBy whether the event has been reviewed and approved or not.\n\n\n\n\n\n\nworkflow_state\n\n\nBy the current processing state of the event. Is it scheduled to be recorded (INSTANTIATED), currently processing (RUNNING), paused waiting for a resource or user paused (PAUSED), cancelled (STOPPED), currently failing (FAILING), already failed (FAILED), or finally SUCCEEDED.\n\n\n\n\n\n\nscheduling_status\n\n\nBy the current scheduling status of the event.\n\n\n\n\n\n\nseries_name\n\n\nBy the series name of the event.\n\n\n\n\n\n\nlocation\n\n\nBy the location (capture agent) that the event will be or has been recorded on.\n\n\n\n\n\n\n\n\nSample request\n\n\nhttps://opencast.example.org/api/events?sort=title:DESC&limit=5&offset=1&filter=location:ca-01\n\n\n\nResponse\n\n\n200 (OK)\n: A (potentially empty) list of events is returned.\n\n\n[\n  {\n    \"archive_version\": 2,\n    \"created\": \"2015-03-12T10:38:54Z\",\n    \"creator\": \"Opencast Administrator\",\n    \"contributors\": [\"Physics Department\"],\n    \"description\": \"Cooling without moving parts and using only heat as an input\",\n    \"duration\": 7200000,\n    \"has_previews\": true,\n    \"identifier\": \"e6aeb8df-a852-46cd-8128-b89de696f20e\",\n    \"location\": \"physics-e-01\",\n    \"presenters\": [\"Prof. A. Einstein\"],\n    \"publication_status\": [ \"youtube\", \"internal\" ],\n    \"processing_state\": \"SUCCEEDED\",\n    \"start_time\": \"2015-03-20T04:00:00Z\",\n    \"subjects\": [\"Space\", \"Final Frontier\"],\n    \"title\": \"Einstein refrigerator\"\n  },\n  {\n    \"archive_version\": 5,\n    \"created\": \"2015-03-12T10:38:54Z\",\n    \"creator\": \"Opencast Administrator\",\n    \"contributors\": [\"Physics Department\"],\n    \"description\": \"The history of the universe from the big bang to black holes\",\n    \"duration\": 7200000,\n    \"has_previews\": true,\n    \"identifier\": \"f5aeb8df-a852-46cd-8128-b89de696f20e\",\n    \"location\": \"physics-e-02\",\n    \"presenters\": [\"Prof. Stephen Hawking\"],\n    \"publication_status\": [ \"youtube\", \"internal\" ],\n    \"processing_state\": \"SUCCEEDED\",\n    \"start_time\": \"2015-03-20T04:00:00Z\",\n    \"subjects\": [\"Space\", \"Final Frontier\"],\n    \"title\": \"The Theory of Everything\"\n  }\n]\n\n\n\n\n\nPOST /api/events\n\n\nCreates an event by sending metadata, access control list, processing instructions and files in a \nmultipart request\n.\n\n\n\n\n\n\n\n\nMultipart Form Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nacl\n\n\nstring\n\n\nA collection of roles with their possible action\n\n\n\n\n\n\nmetadata\n\n\nstring\n\n\nEvent metadata as Form param\n\n\n\n\n\n\npresenter\n\n\nfile\n\n\nPresenter movie track\n\n\n\n\n\n\npresentation\n\n\nfile\n\n\nPresentation movie track\n\n\n\n\n\n\naudio\n\n\nfile\n\n\nAudio track\n\n\n\n\n\n\nprocessing\n\n\nstring\n\n\nProcessing instructions task configuration\n\n\n\n\n\n\n\n\nSample\n\n\nmetadata:\n\n\n[\n  {\n    \"flavor\": \"dublincore/episode\",\n    \"fields\": [\n      {\n        \"id\": \"title\",\n        \"value\": \"Captivating title\"\n      },\n      {\n        \"id\": \"subjects\",\n        \"value\": [\"John Clark\", \"Thiago Melo Costa\"]\n      },\n      {\n        \"id\": \"description\",\n        \"value\": \"A great description\"\n      },\n      {\n        \"id\": \"startDate\",\n        \"value\": \"2016-06-22\"\n      },\n      {\n        \"id\": \"startTime\",\n        \"value\": \"13:30:00Z\"\n      }\n    ]\n  }\n]\n\n\n\nprocessing:\n\n\n{\n  \"workflow\": \"ng-schedule-and-upload\",\n  \"configuration\": {\n    \"flagForCutting\": \"false\",\n    \"flagForReview\": \"false\",\n    \"publishToEngage\": \"true\",\n    \"publishToHarvesting\": \"true\",\n    \"straightToPublishing\": \"true\"\n  }\n}\n\n\n\nacl:\n\n\n[\n  {\n    \"action\": \"write\",\n    \"role\": \"ROLE_ADMIN\"\n  },\n  {\n    \"action\": \"read\",\n    \"role\": \"ROLE_USER\"\n  }\n]\n\n\n\nResponse\n\n\n201 (CREATED)\n: A new event is created and its identifier is returned in the \nLocation\n header.\n\n\n400 (BAD REQUEST)\n: The request is invalid or inconsistent.\n\n\nLocation: http://api.opencast.org/api/events/e6aeb8df-a852-46cd-8128-b89de696f20e\n\n\n\n{\n  \"identifier\": \"e6aeb8df-a852-46cd-8128-b89de696f20e\"\n}\n\n\n\n\n\nGET /api/events/{event_id}\n\n\nReturns a single event.\n\n\nBy setting the optional \nsign\n parameter to \ntrue\n, the method will pre-sign distribution urls if signing is turned on in Opencast. Remember to consider the \nmaximum validity of signed URLs\n when caching this response.\n\n\n\n\n\n\n\n\nQuery String Parameter\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsign\n\n\nboolean\n\n\nWhether public distribution urls should be signed.\n\n\n\n\n\n\nwithacl\n\n\nboolean\n\n\nWhether the acl metadata should be included in the response.\n\n\n\n\n\n\nwithmetadata\n\n\nboolean\n\n\nWhether the metadata catalogs should be included in the response.\n\n\n\n\n\n\nwithpublications\n\n\nboolean\n\n\nWhether the publication ids and urls should be included in the response.\n\n\n\n\n\n\n\n\nResponse\n\n\n200 (OK)\n: The event is returned.\n\n\n404 (NOT FOUND)\n: The specified event does not exist.\n\n\n{\n  \"archive_version\": 2,\n  \"created\": \"2015-03-12T10:38:54Z\",\n  \"creator\": \"Opencast Administrator\",\n  \"contributors\": [\"Physics Department\"],\n  \"description\": \"Cooling without moving parts and using only heat as an input\",\n  \"duration\": 7200000,\n  \"has_previews\": true,\n  \"identifier\": \"e6aeb8df-a852-46cd-8128-b89de696f20e\",\n  \"location\": \"physics-e-01\",\n  \"presenters\": [\"Prof. A. Einstein\"],\n  \"publication_status\": [ \"youtube\", \"internal\" ],\n  \"processing_state\": \"SUCCEEDED\",\n  \"start_time\": \"2015-03-20T04:00:00Z\",\n  \"subjects\": [\"Space\", \"Final Frontier\"],\n  \"title\": \"Einstein refrigerator\"\n}\n\n\n\n\n\nPOST /api/events/{event_id}\n\n\nUpdates an event.\n\n\n\n\n\n\n\n\nMultipart Form Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nacl\n\n\nstring\n\n\nA collection of roles with their possible action\n\n\n\n\n\n\nmetadata\n\n\nstring\n\n\nEvent metadata as Form param\n\n\n\n\n\n\npresenter\n\n\nfile\n\n\nPresenter movie track\n\n\n\n\n\n\npresentation\n\n\nfile\n\n\nPresentation movie track\n\n\n\n\n\n\naudio\n\n\nfile\n\n\nAudio track\n\n\n\n\n\n\nprocessing\n\n\nstring\n\n\nProcessing instructions task configuration\n\n\n\n\n\n\n\n\nSample\n\n\nThis sample request will update the Dublin Core metadata section of the event only.\n\n\nmetadata:\n\n\n[\n  {\n    \"flavor\": \"dublincore/episode\",\n    \"fields\": [\n      {\n        \"id\": \"title\",\n        \"value\": \"Captivating title\"\n      },\n      {\n        \"id\": \"subjects\",\n        \"value\": [\"Space\", \"Final Frontier\"]\n      },\n      {\n        \"id\": \"description\",\n        \"value\": \"A great description\"\n      }\n    ]\n  }\n]\n\n\n\nResponse\n\n\n204 (NO CONTENT)\n: The event has been updated.\n\n\n404 (NOT FOUND)\n: The specified event does not exist.\n\n\n\n\nDELETE /api/events/{event_id}\n\n\nDeletes an event.\n\n\nResponse\n\n\n204 (NO CONTENT)\n: The event has been deleted.\n\n\n404 (NOT FOUND)\n: The specified event does not exist.\n\n\nAccess Policy\n\n\nMost events in Opencast come with an access control list (ACL), containing entries that map actions to roles, either allowing or denying that action.\n\n\nThe section on roles in the chapter on \nAuthorization\n will help shed some light on what kind of roles are available and how they are assigned to the current user.\n\n\n\n\nGET /api/events/{event_id}/acl\n\n\nReturns an event's access policy.\n\n\nResponse\n\n\n200 (OK)\n: The access control list for the specified event is returned.\n\n\n404 (NOT FOUND)\n: The specified event does not exist.\n\n\n[\n  {\n    \"allow\": true,\n    \"action\": \"write\",\n    \"role\": \"ROLE_ADMIN\"\n  },\n  {\n    \"allow\": true,\n    \"action\": \"read\",\n    \"role\": \"ROLE_USER\"\n  }\n]\n\n\n\n\n\nPUT /api/events/{event_id}/acl\n\n\nUpdate an event's access policy.\n\n\n\n\n\n\n\n\nForm Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nacl\n\n\nstring\n\n\nAccess policy\n\n\n\n\n\n\n\n\nSample\n\n\nacl:\n\n\n[\n  {\n    \"allow\": true,\n    \"action\": \"write\",\n    \"role\": \"ROLE_ADMIN\"\n  },\n  {\n    \"allow\": true,\n    \"action\": \"read\",\n    \"role\": \"ROLE_USER\"\n  }\n]\n\n\n\nResponse\n\n\n204 (NO CONTENT)\n: The access control list for the specified event is updated.\n\n\n404 (NOT FOUND)\n: The specified event does not exist.\n\n\n\n\nPOST /api/events/{event_id}/acl/{action}\n\n\nGrants permission to execute \naction\n on the specified event to any user with role \nrole\n. Note that this is a convenience method to avoid having to build and post a complete access control list.\n\n\n\n\n\n\n\n\nPath Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nevent_id\n\n\nstring\n\n\nEvent identifier\n\n\n\n\n\n\naction\n\n\nstring\n\n\nThe action that is allowed to be executed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nForm Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nrole\n\n\nstring\n\n\nThe role that is granted permission\n\n\n\n\n\n\n\n\nSample\n\n\nrole: \"ROLE_STUDENT\"\n\n\n\nResponse\n\n\n204 (NO CONTENT)\n: The permission has been created in the access control list of the specified event.\n\n\n404 (NOT FOUND)\n: The specified event does not exist.\n\n\n\n\nDELETE /api/events/{event_id}/acl/{action}/{role}\n\n\nRevokes permission to execute \naction\n on the specified event from any user with role \nrole\n.\n\n\n\n\n\n\n\n\nPath Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nevent_id\n\n\nstring\n\n\nEvent identifier\n\n\n\n\n\n\naction\n\n\nstring\n\n\nThe action that is no longer allowed to be executed\n\n\n\n\n\n\nrole\n\n\nstring\n\n\nThe role that is no longer granted permission\n\n\n\n\n\n\n\n\nResponse\n\n\n204 (NO CONTENT)\n: The permission has been revoked from the access control list of the specified event.\n\n\n404 (NOT FOUND)\n: The specified event does not exist.\n\n\nMetadata\n\n\n\n\nGET /api/events/{event_id}/metadata\n\n\nReturns the complete set of metadata.\n\n\nResponse\n\n\n200 (OK)\n: The metadata collection is returned.\n\n\n404 (OK)\n: The specified event does not exist.\n\n\n[\n  {\n    \"label\": \"EVENTS.EVENTS.DETAILS.CATALOG.EPISODE\",\n    \"flavor\": \"dublincore/episode\",\n    \"fields\": [\n      {\n        \"id\": \"title\",\n        \"readOnly\": false,\n        \"value\": \"Captivating title\",\n        \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\",\n        \"type\": \"text\",\n        \"required\": true\n      },\n      {\n        \"id\": \"description\",\n        \"readOnly\": false,\n        \"value\": \"A great description\",\n        \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.DESCRIPTION\",\n        \"type\": \"text_long\",\n        \"required\": false\n      }\n    ]\n  },\n  {\n    \"label\": \"EVENTS.EVENTS.DETAILS.CATALOG.LICENSE\",\n    \"flavor\": \"license/episode\",\n    \"fields\": [\n      {\n        \"id\": \"license\",\n        \"readOnly\": false,\n        \"value\": \"CCND\",\n        \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.LICENSE\",\n        \"collection\": {\n          \"BSD\": \"EVENTS.LICENSE.BSD\",\n          \"GPL3\": \"EVENTS.LICENSE.GPL\",\n          \"CCND\": \"EVENTS.LICENSE.CCND\"\n        },\n        \"type\": \"text\",\n        \"required\": false\n      }\n    ]\n  }\n]\n\n\n\n\n\nGET /api/events/{event_id}/metadata\n\n\nReturns the event's metadata of the specified type. For a metadata catalog there is the flavor such as \"dublincore/episode\" and this is the unique type.\n\n\n\n\n\n\n\n\nQuery String Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntype\n\n\nString\n\n\nThe type of metadata to get\n\n\n\n\n\n\n\n\nResponse\n\n\n200 (OK)\n: The metadata collection is returned.\n\n\n404 (NOT FOUND)\n: The specified event does not exist.\n\n\n[\n  {\n    \"id\": \"title\",\n    \"readOnly\": false,\n    \"value\": \"Captivating title\",\n    \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\",\n    \"type\": \"text\",\n    \"required\": true\n  },\n  {\n    \"id\": \"description\",\n    \"readOnly\": false,\n    \"value\": \"A great description\",\n    \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.DESCRIPTION\",\n    \"type\": \"text_long\",\n    \"required\": false\n  }\n]\n\n\n\n\n\nPUT /api/events/{event_id}/metadata\n\n\nUpdate the metadata with the matching type of the specified event. For a metadata catalog there is the flavor such as \"dublincore/episode\" and this is the unique type.\n\n\n\n\n\n\n\n\nQuery String Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntype\n\n\nString\n\n\nThe type of metadata to update\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nForm Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nmetadata\n\n\nstring\n\n\nMetadata catalog in JSON format\n\n\n\n\n\n\n\n\nSample\n\n\nmetadata:\n\n\n[\n  {\n    \"id\": \"title\",\n    \"value\": \"Captivating title\"\n  },\n  {\n    \"id\": \"subjects\",\n    \"value\": [\"Space\", \"Final Frontier\"]\n  },\n  {\n    \"id\": \"description\",\n    \"value\": \"A great description\"\n  }\n]\n\n\n\nResponse\n\n\n204 (NO CONTENT)\n: The metadata of the given namespace has been updated.\n\n\n400 (BAD REQUEST)\n: The request is invalid or inconsistent.\n\n\n404 (NOT FOUND)\n: The specified event does not exist.\n\n\n\n\nDELETE /api/events/{event_id}/metadata\n\n\nDelete the metadata namespace catalog of the specified event. This will remove all fields and values of the catalog.\n\n\n\n\n\n\n\n\nQuery String Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntype\n\n\nString\n\n\nThe type of metadata to delete\n\n\n\n\n\n\n\n\nResponse\n\n\n204 (NO CONTENT)\n: The metadata of the given namespace has been updated.\n\n\n403 (FORBIDDEN)\n: The main metadata catalog dublincore/episode cannot be deleted as it has mandatory fields.\n\n\n404 (NOT FOUND)\n: The specified event does not exist.\n\n\nPublications\n\n\n\n\nGET /api/events/{event_id}/publications\n\n\nReturns an event's list of publications.\n\n\nResponse\n\n\n200 (OK)\n: The list of publications is returned.\n\n\n404 (NOT FOUND)\n: The specified event does not exist.\n\n\n[\n  {\n    \"id\":\"publication-1\",\n    \"channel\":\"engage\",\n    \"mediatype\":\"text/html\",\n    \"url\":\"http://engage.opencast.org/engage/ui/player.html?id=123\"\n  },\n  {\n    \"id\":\"publication-2\",\n    \"channel\":\"oaipmh\",\n    \"mediatype\":\"text/html\",\n    \"url\":\"http://oaipmh.opencast.org/default/?verb=GetRecord&id=123\"\n  }\n]\n\n\n\n\n\nGET /api/events/{event_id}/publications/{publication_id}\n\n\nReturns a single publication.\n\n\nResponse\n\n\n200 (OK)\n: The track details are returned.\n\n\n404 (NOT FOUND)\n: The specified event does not exist.\n\n\n404 (NOT FOUND)\n: The specified publication does not exist.\n\n\n{\n  \"id\":\"publication-1\",\n  \"channel\":\"engage\",\n  \"mediatype\":\"text/html\",\n  \"url\":\"http://engage.opencast.org/engage/ui/player.html?id=123\",\n  \"media\":[\n    {\n      \"id\":\"track-1\",\n      \"mediatype\":\"video/mp4\",\n      \"url\":\"http://download.opencast.org/123/presenter.mp4\",\n      \"flavor\":\"presenter/delivery\",\n      \"size\":84938490,\n      \"checksum\":\"58308405383094\",\n      \"tags\":[\n\n      ],\n      \"has_audio\":true,\n      \"has_video\":true,\n      \"duration\":3648,\n      \"description\":\"Video: h264 (Constrained Baseline) (avc1 / 0x31637661), yuv420p, 640x360, 447 kb/s, 25 fps, 25\"\n    },\n    {\n      \"id\":\"track-2\",\n      \"mediatype\":\"audio/aac\",\n      \"url\":\"http://download.opencast.org/123/presenter.m4a\",\n      \"flavor\":\"presenter/audio\",\n      \"size\":9364,\n      \"checksum\":\"839478372\",\n      \"tags\":[\n\n      ],\n      \"has_audio\":true,\n      \"has_video\":false,\n      \"duration\":3648,\n      \"description\":\"aac (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\"\n    }\n  ],\n  \"attachments\":[\n    {\n      \"id\":\"attachment-1\",\n      \"mediatype\":\"image/png\",\n      \"url\":\"http://download.opencast.org/123/preview.png\",\n      \"flavor\":\"presenter/preview\",\n      \"size\":62728,\n      \"checksum\":\"389475737\",\n      \"tags\":[\n\n      ]\n    }\n  ],\n  \"metadata\":[\n    {\n      \"id\":\"catalog-1\",\n      \"mediatype\":\"text/xml\",\n      \"url\":\"http://download.opencast.org/123/dublincore.xml\",\n      \"flavor\":\"dublincore/episode\",\n      \"size\":364,\n      \"checksum\":\"18498498383\",\n      \"tags\":[\n\n      ]\n    }\n  ]\n}",
            "title": "Events API"
        },
        {
            "location": "/api/events-api/#general",
            "text": "",
            "title": "General"
        },
        {
            "location": "/api/events-api/#get-apievents",
            "text": "Returns a list of events.  By setting the optional  sign  parameter to  true , the method will pre-sign distribution urls if signing is turned on in Opencast. Remember to consider the  maximum validity of signed URLs  when caching this response.     Query String Parameter  Type  Description      sign  boolean  Whether public distribution urls should be signed.    withacl  boolean  Whether the acl metadata should be included in the response.    withmetadata  boolean  Whether the metadata catalogs should be included in the response.    withpublications  boolean  Whether the publication ids and urls should be included in the response.    filter  string  A comma seperated list of filters to limit the results with. A filter is the filter's name followed by a colon \":\" and then the value to filter with so it is the form  Filter Name : Value to Filter With . See the below table for the list of available filters.    sort  string  Sort the results based upon a list of comma seperated sorting criteria. In the comma seperated list each type of sorting is specified as a pair such as:  Sort Name : ASC  or  Sort Name : DESC . Adding the suffix ASC or DESC sets the order as ascending or descending order and is mandatory. See the below table about the available sort names in the table below.    limit  integer  The maximum number of results to return for a single request.    offset  integer  Number of results to skip based on the limit. 0 is the first set of results up to the limit, 1 is the second set of results after the first limit, 2 is third set of results after skipping the first two sets of results etc.        Filter Name  Description      contributors  Events where the contributors match.    location  Events based upon the location it is scheduled in.    series  Events based upon which series they are a part of.    subject  Filters events based upon which subject they are a part of.    textFilter  Filters events where any part of the event's metadata fields match this value.        Sort Name  Description      title  By the title of the event.    presenter  By the presenter of the event.    start_date  By the start date of the event.    end_date  By the end date of the event.    review_status  By whether the event has been reviewed and approved or not.    workflow_state  By the current processing state of the event. Is it scheduled to be recorded (INSTANTIATED), currently processing (RUNNING), paused waiting for a resource or user paused (PAUSED), cancelled (STOPPED), currently failing (FAILING), already failed (FAILED), or finally SUCCEEDED.    scheduling_status  By the current scheduling status of the event.    series_name  By the series name of the event.    location  By the location (capture agent) that the event will be or has been recorded on.     Sample request  https://opencast.example.org/api/events?sort=title:DESC&limit=5&offset=1&filter=location:ca-01  Response  200 (OK) : A (potentially empty) list of events is returned.  [\n  {\n    \"archive_version\": 2,\n    \"created\": \"2015-03-12T10:38:54Z\",\n    \"creator\": \"Opencast Administrator\",\n    \"contributors\": [\"Physics Department\"],\n    \"description\": \"Cooling without moving parts and using only heat as an input\",\n    \"duration\": 7200000,\n    \"has_previews\": true,\n    \"identifier\": \"e6aeb8df-a852-46cd-8128-b89de696f20e\",\n    \"location\": \"physics-e-01\",\n    \"presenters\": [\"Prof. A. Einstein\"],\n    \"publication_status\": [ \"youtube\", \"internal\" ],\n    \"processing_state\": \"SUCCEEDED\",\n    \"start_time\": \"2015-03-20T04:00:00Z\",\n    \"subjects\": [\"Space\", \"Final Frontier\"],\n    \"title\": \"Einstein refrigerator\"\n  },\n  {\n    \"archive_version\": 5,\n    \"created\": \"2015-03-12T10:38:54Z\",\n    \"creator\": \"Opencast Administrator\",\n    \"contributors\": [\"Physics Department\"],\n    \"description\": \"The history of the universe from the big bang to black holes\",\n    \"duration\": 7200000,\n    \"has_previews\": true,\n    \"identifier\": \"f5aeb8df-a852-46cd-8128-b89de696f20e\",\n    \"location\": \"physics-e-02\",\n    \"presenters\": [\"Prof. Stephen Hawking\"],\n    \"publication_status\": [ \"youtube\", \"internal\" ],\n    \"processing_state\": \"SUCCEEDED\",\n    \"start_time\": \"2015-03-20T04:00:00Z\",\n    \"subjects\": [\"Space\", \"Final Frontier\"],\n    \"title\": \"The Theory of Everything\"\n  }\n]",
            "title": "GET /api/events"
        },
        {
            "location": "/api/events-api/#post-apievents",
            "text": "Creates an event by sending metadata, access control list, processing instructions and files in a  multipart request .     Multipart Form Parameters  Type  Description      acl  string  A collection of roles with their possible action    metadata  string  Event metadata as Form param    presenter  file  Presenter movie track    presentation  file  Presentation movie track    audio  file  Audio track    processing  string  Processing instructions task configuration     Sample  metadata:  [\n  {\n    \"flavor\": \"dublincore/episode\",\n    \"fields\": [\n      {\n        \"id\": \"title\",\n        \"value\": \"Captivating title\"\n      },\n      {\n        \"id\": \"subjects\",\n        \"value\": [\"John Clark\", \"Thiago Melo Costa\"]\n      },\n      {\n        \"id\": \"description\",\n        \"value\": \"A great description\"\n      },\n      {\n        \"id\": \"startDate\",\n        \"value\": \"2016-06-22\"\n      },\n      {\n        \"id\": \"startTime\",\n        \"value\": \"13:30:00Z\"\n      }\n    ]\n  }\n]  processing:  {\n  \"workflow\": \"ng-schedule-and-upload\",\n  \"configuration\": {\n    \"flagForCutting\": \"false\",\n    \"flagForReview\": \"false\",\n    \"publishToEngage\": \"true\",\n    \"publishToHarvesting\": \"true\",\n    \"straightToPublishing\": \"true\"\n  }\n}  acl:  [\n  {\n    \"action\": \"write\",\n    \"role\": \"ROLE_ADMIN\"\n  },\n  {\n    \"action\": \"read\",\n    \"role\": \"ROLE_USER\"\n  }\n]  Response  201 (CREATED) : A new event is created and its identifier is returned in the  Location  header.  400 (BAD REQUEST) : The request is invalid or inconsistent.  Location: http://api.opencast.org/api/events/e6aeb8df-a852-46cd-8128-b89de696f20e  {\n  \"identifier\": \"e6aeb8df-a852-46cd-8128-b89de696f20e\"\n}",
            "title": "POST /api/events"
        },
        {
            "location": "/api/events-api/#get-apieventsevent_id",
            "text": "Returns a single event.  By setting the optional  sign  parameter to  true , the method will pre-sign distribution urls if signing is turned on in Opencast. Remember to consider the  maximum validity of signed URLs  when caching this response.     Query String Parameter  Type  Description      sign  boolean  Whether public distribution urls should be signed.    withacl  boolean  Whether the acl metadata should be included in the response.    withmetadata  boolean  Whether the metadata catalogs should be included in the response.    withpublications  boolean  Whether the publication ids and urls should be included in the response.     Response  200 (OK) : The event is returned.  404 (NOT FOUND) : The specified event does not exist.  {\n  \"archive_version\": 2,\n  \"created\": \"2015-03-12T10:38:54Z\",\n  \"creator\": \"Opencast Administrator\",\n  \"contributors\": [\"Physics Department\"],\n  \"description\": \"Cooling without moving parts and using only heat as an input\",\n  \"duration\": 7200000,\n  \"has_previews\": true,\n  \"identifier\": \"e6aeb8df-a852-46cd-8128-b89de696f20e\",\n  \"location\": \"physics-e-01\",\n  \"presenters\": [\"Prof. A. Einstein\"],\n  \"publication_status\": [ \"youtube\", \"internal\" ],\n  \"processing_state\": \"SUCCEEDED\",\n  \"start_time\": \"2015-03-20T04:00:00Z\",\n  \"subjects\": [\"Space\", \"Final Frontier\"],\n  \"title\": \"Einstein refrigerator\"\n}",
            "title": "GET /api/events/{event_id}"
        },
        {
            "location": "/api/events-api/#post-apieventsevent_id",
            "text": "Updates an event.     Multipart Form Parameters  Type  Description      acl  string  A collection of roles with their possible action    metadata  string  Event metadata as Form param    presenter  file  Presenter movie track    presentation  file  Presentation movie track    audio  file  Audio track    processing  string  Processing instructions task configuration     Sample  This sample request will update the Dublin Core metadata section of the event only.  metadata:  [\n  {\n    \"flavor\": \"dublincore/episode\",\n    \"fields\": [\n      {\n        \"id\": \"title\",\n        \"value\": \"Captivating title\"\n      },\n      {\n        \"id\": \"subjects\",\n        \"value\": [\"Space\", \"Final Frontier\"]\n      },\n      {\n        \"id\": \"description\",\n        \"value\": \"A great description\"\n      }\n    ]\n  }\n]  Response  204 (NO CONTENT) : The event has been updated.  404 (NOT FOUND) : The specified event does not exist.",
            "title": "POST /api/events/{event_id}"
        },
        {
            "location": "/api/events-api/#delete-apieventsevent_id",
            "text": "Deletes an event.  Response  204 (NO CONTENT) : The event has been deleted.  404 (NOT FOUND) : The specified event does not exist.",
            "title": "DELETE /api/events/{event_id}"
        },
        {
            "location": "/api/events-api/#access-policy",
            "text": "Most events in Opencast come with an access control list (ACL), containing entries that map actions to roles, either allowing or denying that action.  The section on roles in the chapter on  Authorization  will help shed some light on what kind of roles are available and how they are assigned to the current user.",
            "title": "Access Policy"
        },
        {
            "location": "/api/events-api/#get-apieventsevent_idacl",
            "text": "Returns an event's access policy.  Response  200 (OK) : The access control list for the specified event is returned.  404 (NOT FOUND) : The specified event does not exist.  [\n  {\n    \"allow\": true,\n    \"action\": \"write\",\n    \"role\": \"ROLE_ADMIN\"\n  },\n  {\n    \"allow\": true,\n    \"action\": \"read\",\n    \"role\": \"ROLE_USER\"\n  }\n]",
            "title": "GET /api/events/{event_id}/acl"
        },
        {
            "location": "/api/events-api/#put-apieventsevent_idacl",
            "text": "Update an event's access policy.     Form Parameters  Type  Description      acl  string  Access policy     Sample  acl:  [\n  {\n    \"allow\": true,\n    \"action\": \"write\",\n    \"role\": \"ROLE_ADMIN\"\n  },\n  {\n    \"allow\": true,\n    \"action\": \"read\",\n    \"role\": \"ROLE_USER\"\n  }\n]  Response  204 (NO CONTENT) : The access control list for the specified event is updated.  404 (NOT FOUND) : The specified event does not exist.",
            "title": "PUT /api/events/{event_id}/acl"
        },
        {
            "location": "/api/events-api/#post-apieventsevent_idaclaction",
            "text": "Grants permission to execute  action  on the specified event to any user with role  role . Note that this is a convenience method to avoid having to build and post a complete access control list.     Path Parameters  Type  Description      event_id  string  Event identifier    action  string  The action that is allowed to be executed        Form Parameters  Type  Description      role  string  The role that is granted permission     Sample  role: \"ROLE_STUDENT\"  Response  204 (NO CONTENT) : The permission has been created in the access control list of the specified event.  404 (NOT FOUND) : The specified event does not exist.",
            "title": "POST /api/events/{event_id}/acl/{action}"
        },
        {
            "location": "/api/events-api/#delete-apieventsevent_idaclactionrole",
            "text": "Revokes permission to execute  action  on the specified event from any user with role  role .     Path Parameters  Type  Description      event_id  string  Event identifier    action  string  The action that is no longer allowed to be executed    role  string  The role that is no longer granted permission     Response  204 (NO CONTENT) : The permission has been revoked from the access control list of the specified event.  404 (NOT FOUND) : The specified event does not exist.",
            "title": "DELETE /api/events/{event_id}/acl/{action}/{role}"
        },
        {
            "location": "/api/events-api/#metadata",
            "text": "",
            "title": "Metadata"
        },
        {
            "location": "/api/events-api/#get-apieventsevent_idmetadata",
            "text": "Returns the complete set of metadata.  Response  200 (OK) : The metadata collection is returned.  404 (OK) : The specified event does not exist.  [\n  {\n    \"label\": \"EVENTS.EVENTS.DETAILS.CATALOG.EPISODE\",\n    \"flavor\": \"dublincore/episode\",\n    \"fields\": [\n      {\n        \"id\": \"title\",\n        \"readOnly\": false,\n        \"value\": \"Captivating title\",\n        \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\",\n        \"type\": \"text\",\n        \"required\": true\n      },\n      {\n        \"id\": \"description\",\n        \"readOnly\": false,\n        \"value\": \"A great description\",\n        \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.DESCRIPTION\",\n        \"type\": \"text_long\",\n        \"required\": false\n      }\n    ]\n  },\n  {\n    \"label\": \"EVENTS.EVENTS.DETAILS.CATALOG.LICENSE\",\n    \"flavor\": \"license/episode\",\n    \"fields\": [\n      {\n        \"id\": \"license\",\n        \"readOnly\": false,\n        \"value\": \"CCND\",\n        \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.LICENSE\",\n        \"collection\": {\n          \"BSD\": \"EVENTS.LICENSE.BSD\",\n          \"GPL3\": \"EVENTS.LICENSE.GPL\",\n          \"CCND\": \"EVENTS.LICENSE.CCND\"\n        },\n        \"type\": \"text\",\n        \"required\": false\n      }\n    ]\n  }\n]",
            "title": "GET /api/events/{event_id}/metadata"
        },
        {
            "location": "/api/events-api/#get-apieventsevent_idmetadata_1",
            "text": "Returns the event's metadata of the specified type. For a metadata catalog there is the flavor such as \"dublincore/episode\" and this is the unique type.     Query String Parameters  Type  Description      type  String  The type of metadata to get     Response  200 (OK) : The metadata collection is returned.  404 (NOT FOUND) : The specified event does not exist.  [\n  {\n    \"id\": \"title\",\n    \"readOnly\": false,\n    \"value\": \"Captivating title\",\n    \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\",\n    \"type\": \"text\",\n    \"required\": true\n  },\n  {\n    \"id\": \"description\",\n    \"readOnly\": false,\n    \"value\": \"A great description\",\n    \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.DESCRIPTION\",\n    \"type\": \"text_long\",\n    \"required\": false\n  }\n]",
            "title": "GET /api/events/{event_id}/metadata"
        },
        {
            "location": "/api/events-api/#put-apieventsevent_idmetadata",
            "text": "Update the metadata with the matching type of the specified event. For a metadata catalog there is the flavor such as \"dublincore/episode\" and this is the unique type.     Query String Parameters  Type  Description      type  String  The type of metadata to update        Form Parameters  Type  Description      metadata  string  Metadata catalog in JSON format     Sample  metadata:  [\n  {\n    \"id\": \"title\",\n    \"value\": \"Captivating title\"\n  },\n  {\n    \"id\": \"subjects\",\n    \"value\": [\"Space\", \"Final Frontier\"]\n  },\n  {\n    \"id\": \"description\",\n    \"value\": \"A great description\"\n  }\n]  Response  204 (NO CONTENT) : The metadata of the given namespace has been updated.  400 (BAD REQUEST) : The request is invalid or inconsistent.  404 (NOT FOUND) : The specified event does not exist.",
            "title": "PUT /api/events/{event_id}/metadata"
        },
        {
            "location": "/api/events-api/#delete-apieventsevent_idmetadata",
            "text": "Delete the metadata namespace catalog of the specified event. This will remove all fields and values of the catalog.     Query String Parameters  Type  Description      type  String  The type of metadata to delete     Response  204 (NO CONTENT) : The metadata of the given namespace has been updated.  403 (FORBIDDEN) : The main metadata catalog dublincore/episode cannot be deleted as it has mandatory fields.  404 (NOT FOUND) : The specified event does not exist.",
            "title": "DELETE /api/events/{event_id}/metadata"
        },
        {
            "location": "/api/events-api/#publications",
            "text": "",
            "title": "Publications"
        },
        {
            "location": "/api/events-api/#get-apieventsevent_idpublications",
            "text": "Returns an event's list of publications.  Response  200 (OK) : The list of publications is returned.  404 (NOT FOUND) : The specified event does not exist.  [\n  {\n    \"id\":\"publication-1\",\n    \"channel\":\"engage\",\n    \"mediatype\":\"text/html\",\n    \"url\":\"http://engage.opencast.org/engage/ui/player.html?id=123\"\n  },\n  {\n    \"id\":\"publication-2\",\n    \"channel\":\"oaipmh\",\n    \"mediatype\":\"text/html\",\n    \"url\":\"http://oaipmh.opencast.org/default/?verb=GetRecord&id=123\"\n  }\n]",
            "title": "GET /api/events/{event_id}/publications"
        },
        {
            "location": "/api/events-api/#get-apieventsevent_idpublicationspublication_id",
            "text": "Returns a single publication.  Response  200 (OK) : The track details are returned.  404 (NOT FOUND) : The specified event does not exist.  404 (NOT FOUND) : The specified publication does not exist.  {\n  \"id\":\"publication-1\",\n  \"channel\":\"engage\",\n  \"mediatype\":\"text/html\",\n  \"url\":\"http://engage.opencast.org/engage/ui/player.html?id=123\",\n  \"media\":[\n    {\n      \"id\":\"track-1\",\n      \"mediatype\":\"video/mp4\",\n      \"url\":\"http://download.opencast.org/123/presenter.mp4\",\n      \"flavor\":\"presenter/delivery\",\n      \"size\":84938490,\n      \"checksum\":\"58308405383094\",\n      \"tags\":[\n\n      ],\n      \"has_audio\":true,\n      \"has_video\":true,\n      \"duration\":3648,\n      \"description\":\"Video: h264 (Constrained Baseline) (avc1 / 0x31637661), yuv420p, 640x360, 447 kb/s, 25 fps, 25\"\n    },\n    {\n      \"id\":\"track-2\",\n      \"mediatype\":\"audio/aac\",\n      \"url\":\"http://download.opencast.org/123/presenter.m4a\",\n      \"flavor\":\"presenter/audio\",\n      \"size\":9364,\n      \"checksum\":\"839478372\",\n      \"tags\":[\n\n      ],\n      \"has_audio\":true,\n      \"has_video\":false,\n      \"duration\":3648,\n      \"description\":\"aac (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\"\n    }\n  ],\n  \"attachments\":[\n    {\n      \"id\":\"attachment-1\",\n      \"mediatype\":\"image/png\",\n      \"url\":\"http://download.opencast.org/123/preview.png\",\n      \"flavor\":\"presenter/preview\",\n      \"size\":62728,\n      \"checksum\":\"389475737\",\n      \"tags\":[\n\n      ]\n    }\n  ],\n  \"metadata\":[\n    {\n      \"id\":\"catalog-1\",\n      \"mediatype\":\"text/xml\",\n      \"url\":\"http://download.opencast.org/123/dublincore.xml\",\n      \"flavor\":\"dublincore/episode\",\n      \"size\":364,\n      \"checksum\":\"18498498383\",\n      \"tags\":[\n\n      ]\n    }\n  ]\n}",
            "title": "GET /api/events/{event_id}/publications/{publication_id}"
        },
        {
            "location": "/api/series-api/",
            "text": "General\n\n\nGET /api/series\n\n\nGET /api/series/{series_id}\n\n\nPOST /api/series\n\n\nDELETE /api/series/{series_id}\n\n\n\n\n\n\nMetadata\n\n\nGET /api/series/{series_id}/metadata\n\n\nGET /api/series/{series_id}/metadata\n\n\nPUT /api/series/{series_id}/metadata\n\n\nDELETE /api/series/{series_id}/metadata\n\n\n\n\n\n\nAccess Policy\n\n\nGET /api/series/{series_id}/acl\n\n\nPUT /api/series/{series_id}/acl\n\n\n\n\n\n\nProperties\n\n\nGET /api/series/{series_id}/properties\n\n\nPUT /api/series/{series_id}/properties\n\n\n\n\n\n\n\n\n\n\nGeneral\n\n\nGET /api/series\n\n\nReturns a list of series.\n\n\n\n\n\n\n\n\nQuery String Parameter\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfilter\n\n\nstring\n\n\nA comma seperated list of filters to limit the results with. A filter is the filter's name followed by a colon \":\" and then the value to filter with so it is the form \nFilter Name\n:\nValue to Filter With\n. See the below table for the list of available filters.\n\n\n\n\n\n\nsort\n\n\nstring\n\n\nSort the results based upon a list of comma seperated sorting criteria. In the comma seperated list each type of sorting is specified as a pair such as: \nSort Name\n:\nASC\n or \nSort Name\n:\nDESC\n. Adding the suffix ASC or DESC sets the order as ascending or descending order and is mandatory. See the below table about the available sort names in the table below.\n\n\n\n\n\n\nlimit\n\n\ninteger\n\n\nThe maximum number of results to return for a single request.\n\n\n\n\n\n\noffset\n\n\ninteger\n\n\nNumber of results to skip based on the limit. 0 is the first set of results up to the limit, 1 is the second set of results after the first limit, 2 is third set of results after skipping the first two sets of results etc.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFilter Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ncontributors\n\n\nSeries where the contributors specified in the metadata field match.\n\n\n\n\n\n\ncreator\n\n\nSeries where the creator specified in the metadata field match.\n\n\n\n\n\n\ncreationDate\n\n\nSeries that were created between two dates. The two dates are in UTC format to the second i.e. yyyy-MM-ddTHH:mm:ssZ e.g. 2014-09-27T16:25Z. They are seperated by a forward slash (url encoded or not) so an example of the full filter would be CreationDate:2015-05-08T00:00:00.000Z/2015-05-10T00:00:00.000Z\n\n\n\n\n\n\nlanguage\n\n\nSeries based upon the language specified.\n\n\n\n\n\n\nlicense\n\n\nSeries based upon the license specified.\n\n\n\n\n\n\norganizers\n\n\nSeries where the organizers specified in the metadata field match.\n\n\n\n\n\n\nmanagedAcl\n\n\nSeries who have the same managed acl name.\n\n\n\n\n\n\nsubject\n\n\nBy the subject they are a part of.\n\n\n\n\n\n\ntextFilter\n\n\nFilters series where any part of the series' metadata fields match this value.\n\n\n\n\n\n\ntitle\n\n\nBy the title of the series.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSort Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ncontributors\n\n\nBy the series contributors.\n\n\n\n\n\n\ncreated\n\n\nBy when the series was created.\n\n\n\n\n\n\ncreator\n\n\nBy who created the series.\n\n\n\n\n\n\ntitle\n\n\nBy the title of the series.\n\n\n\n\n\n\n\n\nSample request\n\n\nhttps://opencast.domain.com/api/series?filter=creator:Default Administrator&sort=title:ASC&limit=2&offset=1\n\n\n\nResponse\n\n\n200 (OK)\n: A (potentially empty) list of series is returned.\n\n\n[\n  {\n    \"contributors\": [\"John Doe\"],\n    \"title\": \"The Opencast API\",\n    \"publishers\": [\"John Doe\"],\n    \"subjects\": [\"Topic\", \"Screencast\"],\n    \"created\": \"2015-03-12T09:51:32Z\",\n    \"organizers\": [\"Opencast Community\"],\n    \"identifier\": \"763545de-7e1c-4c8a-bcd9-902511f0e15b\",\n    \"creator\": \"Opencast Administrator\"\n  },\n  {\n    \"contributors\": [\"Jane Doe\"],\n    \"title\": \"The Opencast Admin UI\",\n    \"publishers\": [\"John Doe\"],\n    \"subjects\": [\"Topic\", \"Screencast\"],\n    \"created\": \"2015-03-12T09:51:32Z\",\n    \"organizers\": [\"Opencast Community\"],\n    \"identifier\": \"353545de-7e1c-4c8a-bcd9-902511f0e15b\",\n    \"creator\": \"Opencast Administrator\"\n  }\n]\n\n\n\n\n\nGET /api/series/{series_id}\n\n\nReturns a single series.\n\n\nResponse\n\n\n200 (OK)\n: The series is returned.\n\n\n404 (NOT FOUND)\n: The specified series does not exist.\n\n\n{\n  \"identifier\": \"4fd0ef66-aea5-4b7a-a62a-a4ada0eafd6f\",\n  \"title\": \"The Opencast API\",\n  \"description\": \"A cool demo of the Opencast API\",\n  \"subjects\": [\"Topic\", \"Screencast\"],\n  \"organization\": \"mh_default_org\",\n  \"creator\": \"Default Administrator\",\n  \"created\": \"2015-03-12T09:58:06Z\",\n  \"organizers\": [\"Opencast Community\"],\n  \"contributors\": [\"John Doe\"],\n  \"publishers\": [\"John Doe\"],\n  \"opt_out\": false\n}\n\n\n\n\n\nPOST /api/series\n\n\nCreates a series.\n\n\n\n\n\n\n\n\nForm Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nmetadata\n\n\nString\n\n\nSeries metadata\n\n\n\n\n\n\nacl\n\n\nString\n\n\nA collection of roles with their possible action\n\n\n\n\n\n\ntheme\n\n\nString\n\n\nThe theme ID to be applied to the series\n\n\n\n\n\n\n\n\nSample\n\n\nmetadata:\n\n\n[\n  {\n    \"label\": \"Opencast Series DublinCore\",\n    \"flavor\": \"dublincore/series\",\n    \"fields\": [\n      {\n        \"id\": \"title\",\n        \"value\": \"Captivating title\"\n      },\n      {\n        \"id\": \"subjects\",\n        \"value\": [\"John Clark\", \"Thiago Melo Costa\"]\n      },\n      {\n        \"id\": \"description\",\n        \"value\": \"A great description\"\n      }\n    ]\n  }\n]\n\n\n\nacl:\n\n\n[\n  {\n    \"allow\": true,\n    \"action\": \"write\",\n    \"role\": \"ROLE_ADMIN\"\n  },\n  {\n    \"allow\": true,\n    \"action\": \"read\",\n    \"role\": \"ROLE_USER\"\n  }\n]\n\n\n\ntheme:\n\n\n\"1234\"\n\n\n\nResponse\n\n\n201 (CREATED)\n: A new series is created and its identifier is returned in the \nLocation\n header.\n\n\n400 (BAD REQUEST)\n: The request is invalid or inconsistent.\n\n\n401 (UNAUTHORIZED)\n: The user doesn't have the rights to create the series.\n\n\nLocation: http://api.opencast.org/api/series/4fd0ef66-aea5-4b7a-a62a-a4ada0eafd6f\n\n\n\n{\n  \"identifier\": \"4fd0ef66-aea5-4b7a-a62a-a4ada0eafd6f\"\n}\n\n\n\n\n\nDELETE /api/series/{series_id}\n\n\nDeletes a series\n\n\nResponse\n\n\n204 (NO CONTENT)\n: The series has been deleted.\n\n\n404 (NOT FOUND)\n: The specified series does not exist.\n\n\nMetadata\n\n\n\n\nGET /api/series/{series_id}/metadata\n\n\nReturns a series' metadata of all types.\n\n\nResponse\n\n\n200 (OK)\n: The series' metadata are returned.\n\n\n404 (NOT FOUND)\n: The specified series does not exist.\n\n\n[\n  {\n    \"label\": \"EVENTS.EVENTS.DETAILS.CATALOG.EPISODE\",\n    \"flavor\": \"dublincore/series\",\n    \"fields\": [\n      {\n        \"id\": \"title\",\n        \"readOnly\": false,\n        \"value\": \"Captivating title\",\n        \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\",\n        \"type\": \"text\",\n        \"required\": true\n      },\n      {\n        \"id\": \"description\",\n        \"readOnly\": false,\n        \"value\": \"A great description\",\n        \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.DESCRIPTION\",\n        \"type\": \"text_long\",\n        \"required\": false\n      }\n    ]\n  },\n  {\n    \"label\": \"EVENTS.EVENTS.DETAILS.CATALOG.LICENSE\",\n    \"flavor\": \"license/series\",\n    \"fields\": [\n      {\n        \"id\": \"license\",\n        \"readOnly\": false,\n        \"value\": \"CCND\",\n        \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.LICENSE\",\n        \"collection\": {\n          \"BSD\": \"EVENTS.LICENSE.BSD\",\n          \"GPL3\": \"EVENTS.LICENSE.GPL\",\n          \"CCND\": \"EVENTS.LICENSE.CCND\"\n        },\n        \"type\": \"text\",\n        \"required\": false\n      }\n    ]\n  }\n]\n\n\n\n\n\nGET /api/series/{series_id}/metadata\n\n\nReturns a series' metadata collection of the given type when the query string parameter type is specified. For each metadata catalog there is a unique property called the flavor such as dublincore/series so the type in this example would be \"dublincore/series\".\n\n\n\n\n\n\n\n\nQuery String Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntype\n\n\nString\n\n\nThe type of metadata to return\n\n\n\n\n\n\n\n\nResponse\n\n\n200 (OK)\n: The series' metadata are returned.\n\n\n404 (NOT FOUND)\n: The specified series does not exist.\n\n\n[\n  {\n    \"id\": \"title\",\n    \"readOnly\": false,\n    \"value\": \"Captivating title\",\n    \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\",\n    \"type\": \"text\",\n    \"required\": true\n  },\n  {\n    \"id\": \"description\",\n    \"readOnly\": false,\n    \"value\": \"A great description\",\n    \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.DESCRIPTION\",\n    \"type\": \"text_long\",\n    \"required\": false\n  }\n]\n\n\n\n\n\nPUT /api/series/{series_id}/metadata\n\n\nUpdate a series' metadata of the given type. For a metadata catalog there is the flavor such as \"dublincore/series\" and this is the unique type.\n\n\n\n\n\n\n\n\nQuery String Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntype\n\n\nString\n\n\nThe type of metadata to update\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nForm Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nmetadata\n\n\nString\n\n\nSeries metadata as Form param\n\n\n\n\n\n\n\n\nSample\n\n\nmetadata:\n\n\n[\n  {\n    \"id\": \"title\",\n    \"value\": \"Captivating title - edited\"\n  },\n  {\n    \"id\": \"creator\",\n    \"value\": [\"John Clark\", \"Thiago Melo Costa\"]\n  },\n  {\n    \"id\": \"description\",\n    \"value\": \"A great description - edited\"\n  }\n]\n\n\n\nResponse\n\n\n200 (OK)\n: The series' metadata have been updated.\n\n\n400 (BAD REQUEST)\n: The request is invalid or inconsistent.\n\n\n404 (NOT FOUND)\n: The specified series does not exist.\n\n\nReturns: The full metadata catalog of the series\n\n\n\n\n\nDELETE /api/series/{series_id}/metadata\n\n\nDeletes a series' metadata catalog of the given type. All fields and values of that catalog will be deleted.\n\n\n\n\n\n\n\n\nQuery String Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntype\n\n\nString\n\n\nThe type of metadata to delete\n\n\n\n\n\n\n\n\nResponse\n\n\n204 (NO CONTENT)\n: The metadata have been deleted.\n\n\n403 (FORBIDDEN)\n: The main metadata catalog dublincore/series cannot be deleted as it has mandatory fields.\n\n\n404 (NOT FOUND)\n: The specified series does not exist.\n\n\nAccess Policy\n\n\n\n\nGET /api/series/{series_id}/acl\n\n\nReturns a series' access policy.\n\n\nResponse\n\n\n200 (OK)\n: The series' access policy is returned.\n\n\n404 (NOT FOUND)\n: The specified series does not exist.\n\n\n[\n  {\n    \"allow\": true,\n    \"action\": \"write\",\n    \"role\": \"ROLE_ADMIN\"\n  },\n  {\n    \"allow\": true,\n    \"action\": \"read\",\n    \"role\": \"ROLE_USER\"\n  }\n]\n\n\n\n\n\nPUT /api/series/{series_id}/acl\n\n\nUpdates a series' access policy.\n\n\n\n\n\n\n\n\nParameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nacl\n\n\nstring\n\n\nAccess policy\n\n\n\n\n\n\n\n\nSample\n\n\nacl:\n\n\n[\n  {\n    \"allow\": true,\n    \"action\": \"write\",\n    \"role\": \"ROLE_ADMIN\"\n  },\n  {\n    \"allow\": true,\n    \"action\": \"read\",\n    \"role\": \"ROLE_USER\"\n  }\n]\n\n\n\nResponse\n\n\n200 (OK)\n: The access control list for the specified series is updated.\n\n\n404 (NOT FOUND)\n: The specified series does not exist.\n\n\nProperties\n\n\n\n\nGET /api/series/{series_id}/properties\n\n\nReturns a series' properties.\n\n\nResponse\n\n\n200 (OK)\n: The series' properties are returned.\n\n\n404 (NOT FOUND)\n: The specified series does not exist.\n\n\n{\n  \"ondemand\": \"true\",\n  \"live\": \"false\"\n}\n\n\n\n\n\nPUT /api/series/{series_id}/properties\n\n\nUpdates a series' properties\n\n\n\n\n\n\n\n\nForm parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nproperties\n\n\nstring\n\n\nSeries properties\n\n\n\n\n\n\n\n\nSample\n\n\nproperties:\n\n\n{\n  \"ondemand\": \"true\",\n  \"live\": \"false\"\n}\n\n\n\nResponse\n\n\n200 (OK)\n: Successfully updated the series' properties.\n\n\n404 (NOT FOUND)\n: The specified series does not exist.",
            "title": "Series API"
        },
        {
            "location": "/api/series-api/#general",
            "text": "",
            "title": "General"
        },
        {
            "location": "/api/series-api/#get-apiseries",
            "text": "Returns a list of series.     Query String Parameter  Type  Description      filter  string  A comma seperated list of filters to limit the results with. A filter is the filter's name followed by a colon \":\" and then the value to filter with so it is the form  Filter Name : Value to Filter With . See the below table for the list of available filters.    sort  string  Sort the results based upon a list of comma seperated sorting criteria. In the comma seperated list each type of sorting is specified as a pair such as:  Sort Name : ASC  or  Sort Name : DESC . Adding the suffix ASC or DESC sets the order as ascending or descending order and is mandatory. See the below table about the available sort names in the table below.    limit  integer  The maximum number of results to return for a single request.    offset  integer  Number of results to skip based on the limit. 0 is the first set of results up to the limit, 1 is the second set of results after the first limit, 2 is third set of results after skipping the first two sets of results etc.        Filter Name  Description      contributors  Series where the contributors specified in the metadata field match.    creator  Series where the creator specified in the metadata field match.    creationDate  Series that were created between two dates. The two dates are in UTC format to the second i.e. yyyy-MM-ddTHH:mm:ssZ e.g. 2014-09-27T16:25Z. They are seperated by a forward slash (url encoded or not) so an example of the full filter would be CreationDate:2015-05-08T00:00:00.000Z/2015-05-10T00:00:00.000Z    language  Series based upon the language specified.    license  Series based upon the license specified.    organizers  Series where the organizers specified in the metadata field match.    managedAcl  Series who have the same managed acl name.    subject  By the subject they are a part of.    textFilter  Filters series where any part of the series' metadata fields match this value.    title  By the title of the series.        Sort Name  Description      contributors  By the series contributors.    created  By when the series was created.    creator  By who created the series.    title  By the title of the series.     Sample request  https://opencast.domain.com/api/series?filter=creator:Default Administrator&sort=title:ASC&limit=2&offset=1  Response  200 (OK) : A (potentially empty) list of series is returned.  [\n  {\n    \"contributors\": [\"John Doe\"],\n    \"title\": \"The Opencast API\",\n    \"publishers\": [\"John Doe\"],\n    \"subjects\": [\"Topic\", \"Screencast\"],\n    \"created\": \"2015-03-12T09:51:32Z\",\n    \"organizers\": [\"Opencast Community\"],\n    \"identifier\": \"763545de-7e1c-4c8a-bcd9-902511f0e15b\",\n    \"creator\": \"Opencast Administrator\"\n  },\n  {\n    \"contributors\": [\"Jane Doe\"],\n    \"title\": \"The Opencast Admin UI\",\n    \"publishers\": [\"John Doe\"],\n    \"subjects\": [\"Topic\", \"Screencast\"],\n    \"created\": \"2015-03-12T09:51:32Z\",\n    \"organizers\": [\"Opencast Community\"],\n    \"identifier\": \"353545de-7e1c-4c8a-bcd9-902511f0e15b\",\n    \"creator\": \"Opencast Administrator\"\n  }\n]",
            "title": "GET /api/series"
        },
        {
            "location": "/api/series-api/#get-apiseriesseries_id",
            "text": "Returns a single series.  Response  200 (OK) : The series is returned.  404 (NOT FOUND) : The specified series does not exist.  {\n  \"identifier\": \"4fd0ef66-aea5-4b7a-a62a-a4ada0eafd6f\",\n  \"title\": \"The Opencast API\",\n  \"description\": \"A cool demo of the Opencast API\",\n  \"subjects\": [\"Topic\", \"Screencast\"],\n  \"organization\": \"mh_default_org\",\n  \"creator\": \"Default Administrator\",\n  \"created\": \"2015-03-12T09:58:06Z\",\n  \"organizers\": [\"Opencast Community\"],\n  \"contributors\": [\"John Doe\"],\n  \"publishers\": [\"John Doe\"],\n  \"opt_out\": false\n}",
            "title": "GET /api/series/{series_id}"
        },
        {
            "location": "/api/series-api/#post-apiseries",
            "text": "Creates a series.     Form Parameters  Type  Description      metadata  String  Series metadata    acl  String  A collection of roles with their possible action    theme  String  The theme ID to be applied to the series     Sample  metadata:  [\n  {\n    \"label\": \"Opencast Series DublinCore\",\n    \"flavor\": \"dublincore/series\",\n    \"fields\": [\n      {\n        \"id\": \"title\",\n        \"value\": \"Captivating title\"\n      },\n      {\n        \"id\": \"subjects\",\n        \"value\": [\"John Clark\", \"Thiago Melo Costa\"]\n      },\n      {\n        \"id\": \"description\",\n        \"value\": \"A great description\"\n      }\n    ]\n  }\n]  acl:  [\n  {\n    \"allow\": true,\n    \"action\": \"write\",\n    \"role\": \"ROLE_ADMIN\"\n  },\n  {\n    \"allow\": true,\n    \"action\": \"read\",\n    \"role\": \"ROLE_USER\"\n  }\n]  theme:  \"1234\"  Response  201 (CREATED) : A new series is created and its identifier is returned in the  Location  header.  400 (BAD REQUEST) : The request is invalid or inconsistent.  401 (UNAUTHORIZED) : The user doesn't have the rights to create the series.  Location: http://api.opencast.org/api/series/4fd0ef66-aea5-4b7a-a62a-a4ada0eafd6f  {\n  \"identifier\": \"4fd0ef66-aea5-4b7a-a62a-a4ada0eafd6f\"\n}",
            "title": "POST /api/series"
        },
        {
            "location": "/api/series-api/#delete-apiseriesseries_id",
            "text": "Deletes a series  Response  204 (NO CONTENT) : The series has been deleted.  404 (NOT FOUND) : The specified series does not exist.",
            "title": "DELETE /api/series/{series_id}"
        },
        {
            "location": "/api/series-api/#metadata",
            "text": "",
            "title": "Metadata"
        },
        {
            "location": "/api/series-api/#get-apiseriesseries_idmetadata",
            "text": "Returns a series' metadata of all types.  Response  200 (OK) : The series' metadata are returned.  404 (NOT FOUND) : The specified series does not exist.  [\n  {\n    \"label\": \"EVENTS.EVENTS.DETAILS.CATALOG.EPISODE\",\n    \"flavor\": \"dublincore/series\",\n    \"fields\": [\n      {\n        \"id\": \"title\",\n        \"readOnly\": false,\n        \"value\": \"Captivating title\",\n        \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\",\n        \"type\": \"text\",\n        \"required\": true\n      },\n      {\n        \"id\": \"description\",\n        \"readOnly\": false,\n        \"value\": \"A great description\",\n        \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.DESCRIPTION\",\n        \"type\": \"text_long\",\n        \"required\": false\n      }\n    ]\n  },\n  {\n    \"label\": \"EVENTS.EVENTS.DETAILS.CATALOG.LICENSE\",\n    \"flavor\": \"license/series\",\n    \"fields\": [\n      {\n        \"id\": \"license\",\n        \"readOnly\": false,\n        \"value\": \"CCND\",\n        \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.LICENSE\",\n        \"collection\": {\n          \"BSD\": \"EVENTS.LICENSE.BSD\",\n          \"GPL3\": \"EVENTS.LICENSE.GPL\",\n          \"CCND\": \"EVENTS.LICENSE.CCND\"\n        },\n        \"type\": \"text\",\n        \"required\": false\n      }\n    ]\n  }\n]",
            "title": "GET /api/series/{series_id}/metadata"
        },
        {
            "location": "/api/series-api/#get-apiseriesseries_idmetadata_1",
            "text": "Returns a series' metadata collection of the given type when the query string parameter type is specified. For each metadata catalog there is a unique property called the flavor such as dublincore/series so the type in this example would be \"dublincore/series\".     Query String Parameters  Type  Description      type  String  The type of metadata to return     Response  200 (OK) : The series' metadata are returned.  404 (NOT FOUND) : The specified series does not exist.  [\n  {\n    \"id\": \"title\",\n    \"readOnly\": false,\n    \"value\": \"Captivating title\",\n    \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.TITLE\",\n    \"type\": \"text\",\n    \"required\": true\n  },\n  {\n    \"id\": \"description\",\n    \"readOnly\": false,\n    \"value\": \"A great description\",\n    \"label\": \"EVENTS.EVENTS.DETAILS.METADATA.DESCRIPTION\",\n    \"type\": \"text_long\",\n    \"required\": false\n  }\n]",
            "title": "GET /api/series/{series_id}/metadata"
        },
        {
            "location": "/api/series-api/#put-apiseriesseries_idmetadata",
            "text": "Update a series' metadata of the given type. For a metadata catalog there is the flavor such as \"dublincore/series\" and this is the unique type.     Query String Parameters  Type  Description      type  String  The type of metadata to update        Form Parameters  Type  Description      metadata  String  Series metadata as Form param     Sample  metadata:  [\n  {\n    \"id\": \"title\",\n    \"value\": \"Captivating title - edited\"\n  },\n  {\n    \"id\": \"creator\",\n    \"value\": [\"John Clark\", \"Thiago Melo Costa\"]\n  },\n  {\n    \"id\": \"description\",\n    \"value\": \"A great description - edited\"\n  }\n]  Response  200 (OK) : The series' metadata have been updated.  400 (BAD REQUEST) : The request is invalid or inconsistent.  404 (NOT FOUND) : The specified series does not exist.  Returns: The full metadata catalog of the series",
            "title": "PUT /api/series/{series_id}/metadata"
        },
        {
            "location": "/api/series-api/#delete-apiseriesseries_idmetadata",
            "text": "Deletes a series' metadata catalog of the given type. All fields and values of that catalog will be deleted.     Query String Parameters  Type  Description      type  String  The type of metadata to delete     Response  204 (NO CONTENT) : The metadata have been deleted.  403 (FORBIDDEN) : The main metadata catalog dublincore/series cannot be deleted as it has mandatory fields.  404 (NOT FOUND) : The specified series does not exist.",
            "title": "DELETE /api/series/{series_id}/metadata"
        },
        {
            "location": "/api/series-api/#access-policy",
            "text": "",
            "title": "Access Policy"
        },
        {
            "location": "/api/series-api/#get-apiseriesseries_idacl",
            "text": "Returns a series' access policy.  Response  200 (OK) : The series' access policy is returned.  404 (NOT FOUND) : The specified series does not exist.  [\n  {\n    \"allow\": true,\n    \"action\": \"write\",\n    \"role\": \"ROLE_ADMIN\"\n  },\n  {\n    \"allow\": true,\n    \"action\": \"read\",\n    \"role\": \"ROLE_USER\"\n  }\n]",
            "title": "GET /api/series/{series_id}/acl"
        },
        {
            "location": "/api/series-api/#put-apiseriesseries_idacl",
            "text": "Updates a series' access policy.     Parameters  Type  Description      acl  string  Access policy     Sample  acl:  [\n  {\n    \"allow\": true,\n    \"action\": \"write\",\n    \"role\": \"ROLE_ADMIN\"\n  },\n  {\n    \"allow\": true,\n    \"action\": \"read\",\n    \"role\": \"ROLE_USER\"\n  }\n]  Response  200 (OK) : The access control list for the specified series is updated.  404 (NOT FOUND) : The specified series does not exist.",
            "title": "PUT /api/series/{series_id}/acl"
        },
        {
            "location": "/api/series-api/#properties",
            "text": "",
            "title": "Properties"
        },
        {
            "location": "/api/series-api/#get-apiseriesseries_idproperties",
            "text": "Returns a series' properties.  Response  200 (OK) : The series' properties are returned.  404 (NOT FOUND) : The specified series does not exist.  {\n  \"ondemand\": \"true\",\n  \"live\": \"false\"\n}",
            "title": "GET /api/series/{series_id}/properties"
        },
        {
            "location": "/api/series-api/#put-apiseriesseries_idproperties",
            "text": "Updates a series' properties     Form parameters  Type  Description      properties  string  Series properties     Sample  properties:  {\n  \"ondemand\": \"true\",\n  \"live\": \"false\"\n}  Response  200 (OK) : Successfully updated the series' properties.  404 (NOT FOUND) : The specified series does not exist.",
            "title": "PUT /api/series/{series_id}/properties"
        },
        {
            "location": "/api/groups-api/",
            "text": "General\n\n\nGET /api/groups\n\n\nGET /api/groups/{group_id}\n\n\nPOST /api/groups\n\n\nPUT /api/groups/{group_id}\n\n\nDELETE /api/groups/{group_id}\n\n\n\n\n\n\nMembers\n\n\nPOST /api/groups/{group_id}/members\n\n\nDELETE /api/groups/{group_id}/members/{member_id}\n\n\n\n\n\n\n\n\n\n\nGeneral\n\n\nGET /api/groups\n\n\nReturns a list of groups.\n\n\n\n\n\n\n\n\nQuery String Parameter\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfilter\n\n\nstring\n\n\nA comma seperated list of filters to limit the results with. A filter is the filter's name followed by a colon \":\" and then the value to filter with so it is the form \nFilter Name\n:\nValue to Filter With\n. See the below table for the list of available filters.\n\n\n\n\n\n\nsort\n\n\nstring\n\n\nSort the results based upon a list of comma seperated sorting criteria. In the comma seperated list each type of sorting is specified as a pair such as: \nSort Name\n:\nASC\n or \nSort Name\n:\nDESC\n. Adding the suffix ASC or DESC sets the order as ascending or descending order and is mandatory. See the below table about the available sort names in the table below.\n\n\n\n\n\n\nlimit\n\n\ninteger\n\n\nThe maximum number of results to return for a single request.\n\n\n\n\n\n\noffset\n\n\ninteger\n\n\nNumber of results to skip based on the limit. 0 is the first set of results up to the limit, 1 is the second set of results after the first limit, 2 is third set of results after skipping the first two sets of results etc.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFilter Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nname\n\n\nGroups where the name specified in the metadata field match.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSort Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nname\n\n\nBy the group name\n\n\n\n\n\n\ndescription\n\n\nBy the group description\n\n\n\n\n\n\nrole\n\n\nBy the group role\n\n\n\n\n\n\nmembers\n\n\nBy the group members\n\n\n\n\n\n\nroles\n\n\nBy the group roles\n\n\n\n\n\n\n\n\nSample request\n\n\nhttps://opencast.domain.com/api/groups?sort=name:ASC&limit=2&offset=1\n\n\n\nResponse\n\n\n200 (OK)\n: A (potentially empty) list of groups.\n\n\n[\n  {\n    \"organization\": \"mh_default_org\",\n    \"description\": \"System administrators\",\n    \"roles\": {\n      \"role\": [\n        \"ROLE_ADMIN\",\n        \"ROLE_SUDO\"\n      ]\n    },\n    \"name\": \"Default System Administrators\",\n    \"identifier\": \"MH_DEFAULT_ORG_SYSTEM_ADMINS\",\n    \"members\": {\n      \"member\": \"admin\"\n    }\n  },\n  {\n    \"organization\": \"mh_default_org\",\n    \"description\": \"External application users\",\n    \"roles\": {\n      \"role\": [\n        \"ROLE_API\",\n        \"ROLE_SUDO\",\n        \"ROLE_API_SERIES_EDIT\",\n        \"ROLE_API_EVENTS_VIEW\"\n      ]\n    },\n    \"name\": \"Default External Applications\",\n    \"identifier\": \"MH_DEFAULT_ORG_EXTERNAL_APPLICATIONS\",\n    \"members\": \"\"\n  }\n]\n\n\n\nGET /api/groups/{group_id}\n\n\nReturns a single group.\n\n\nSample request\n\n\nhttps://opencast.domain.com/api/groups/MH_DEFAULT_ORG_SYSTEM_ADMINS\n\n\n\nResponse\n\n\n200 (OK)\n: The group is returned.\n\n\n404 (NOT FOUND)\n: The specified group does not exist.\n\n\n{\n  \"organization\": \"mh_default_org\",\n  \"description\": \"System administrators\",\n  \"roles\": {\n    \"role\": [\n      \"ROLE_ADMIN\",\n      \"ROLE_SUDO\"\n    ]\n  },\n  \"name\": \"Default System Administrators\",\n  \"identifier\": \"MH_DEFAULT_ORG_SYSTEM_ADMINS\",\n  \"members\": {\n    \"member\": \"admin\"\n  }\n}\n\n\n\nPOST /api/groups\n\n\nCreates a group.\n\n\n\n\n\n\n\n\nForm Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nname\n\n\nString\n\n\nGroup Name\n\n\n\n\n\n\ndescription\n\n\nString\n\n\nGroup Description\n\n\n\n\n\n\nroles\n\n\nString\n\n\nComma-separated list of roles\n\n\n\n\n\n\nmembers\n\n\nString\n\n\nComma-separated list of members\n\n\n\n\n\n\n\n\nResponse\n\n\n201 (CREATED)\n: A new group is created.\n\n\n400 (BAD REQUEST)\n: The request is invalid or inconsistent.\n\n\nPUT /api/groups/{group_id}\n\n\nUpdates a group.\n\n\n\n\n\n\n\n\nForm Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nname\n\n\nString\n\n\nGroup Name\n\n\n\n\n\n\ndescription\n\n\nString\n\n\nGroup Description\n\n\n\n\n\n\nroles\n\n\nString\n\n\nComma-separated list of roles\n\n\n\n\n\n\nmembers\n\n\nString\n\n\nComma-separated list of members\n\n\n\n\n\n\n\n\nSample\n\n\nTODO\n\n\n\nResponse\n\n\n200 (OK)\n: The group has been updated.\n\n\n404 (NOT FOUND)\n: The specified group does not exist.\n\n\nDELETE /api/groups/{group_id}\n\n\nDeletes a group.\n\n\nResponse\n\n\n204 (NO CONTENT)\n: The group has been deleted.\n\n\n404 (NOT FOUND)\n: The specified group does not exist.\n\n\nMembers\n\n\nPOST /api/groups/{group_id}/members\n\n\nAdds a member to a group.\n\n\n\n\n\n\n\n\nForm Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nmember\n\n\nString\n\n\nMember Name\n\n\n\n\n\n\n\n\nSample\n\n\nhttps://opencast.domain.com/api/groups/MH_DEFAULT_ORG_SYSTEM_ADMINS/members\n\n\n\nResponse\n\n\n200 (OK)\n: The member was already member of the group.\n\n\n204 (NO CONTENT)\n: The member has been added.\n\n\n404 (NOT FOUND)\n: The specified group does not exist.\n\n\nDELETE /api/groups/{group_id}/members/{member_id}\n\n\nRemoves a member from a group\n\n\nSample\n\n\nhttps://opencast.domain.com/api/groups/MH_DEFAULT_ORG_SYSTEM_ADMINS/members/admin\n\n\n\nResponse\n\n\n204 (NO CONTENT)\n: The member has been removed.\n\n\n404 (NOT FOUND)\n: The specified group or member does not exist.",
            "title": "Groups API"
        },
        {
            "location": "/api/groups-api/#general",
            "text": "",
            "title": "General"
        },
        {
            "location": "/api/groups-api/#get-apigroups",
            "text": "Returns a list of groups.     Query String Parameter  Type  Description      filter  string  A comma seperated list of filters to limit the results with. A filter is the filter's name followed by a colon \":\" and then the value to filter with so it is the form  Filter Name : Value to Filter With . See the below table for the list of available filters.    sort  string  Sort the results based upon a list of comma seperated sorting criteria. In the comma seperated list each type of sorting is specified as a pair such as:  Sort Name : ASC  or  Sort Name : DESC . Adding the suffix ASC or DESC sets the order as ascending or descending order and is mandatory. See the below table about the available sort names in the table below.    limit  integer  The maximum number of results to return for a single request.    offset  integer  Number of results to skip based on the limit. 0 is the first set of results up to the limit, 1 is the second set of results after the first limit, 2 is third set of results after skipping the first two sets of results etc.        Filter Name  Description      name  Groups where the name specified in the metadata field match.        Sort Name  Description      name  By the group name    description  By the group description    role  By the group role    members  By the group members    roles  By the group roles     Sample request  https://opencast.domain.com/api/groups?sort=name:ASC&limit=2&offset=1  Response  200 (OK) : A (potentially empty) list of groups.  [\n  {\n    \"organization\": \"mh_default_org\",\n    \"description\": \"System administrators\",\n    \"roles\": {\n      \"role\": [\n        \"ROLE_ADMIN\",\n        \"ROLE_SUDO\"\n      ]\n    },\n    \"name\": \"Default System Administrators\",\n    \"identifier\": \"MH_DEFAULT_ORG_SYSTEM_ADMINS\",\n    \"members\": {\n      \"member\": \"admin\"\n    }\n  },\n  {\n    \"organization\": \"mh_default_org\",\n    \"description\": \"External application users\",\n    \"roles\": {\n      \"role\": [\n        \"ROLE_API\",\n        \"ROLE_SUDO\",\n        \"ROLE_API_SERIES_EDIT\",\n        \"ROLE_API_EVENTS_VIEW\"\n      ]\n    },\n    \"name\": \"Default External Applications\",\n    \"identifier\": \"MH_DEFAULT_ORG_EXTERNAL_APPLICATIONS\",\n    \"members\": \"\"\n  }\n]",
            "title": "GET /api/groups"
        },
        {
            "location": "/api/groups-api/#get-apigroupsgroup_id",
            "text": "Returns a single group.  Sample request  https://opencast.domain.com/api/groups/MH_DEFAULT_ORG_SYSTEM_ADMINS  Response  200 (OK) : The group is returned.  404 (NOT FOUND) : The specified group does not exist.  {\n  \"organization\": \"mh_default_org\",\n  \"description\": \"System administrators\",\n  \"roles\": {\n    \"role\": [\n      \"ROLE_ADMIN\",\n      \"ROLE_SUDO\"\n    ]\n  },\n  \"name\": \"Default System Administrators\",\n  \"identifier\": \"MH_DEFAULT_ORG_SYSTEM_ADMINS\",\n  \"members\": {\n    \"member\": \"admin\"\n  }\n}",
            "title": "GET /api/groups/{group_id}"
        },
        {
            "location": "/api/groups-api/#post-apigroups",
            "text": "Creates a group.     Form Parameters  Type  Description      name  String  Group Name    description  String  Group Description    roles  String  Comma-separated list of roles    members  String  Comma-separated list of members     Response  201 (CREATED) : A new group is created.  400 (BAD REQUEST) : The request is invalid or inconsistent.",
            "title": "POST /api/groups"
        },
        {
            "location": "/api/groups-api/#put-apigroupsgroup_id",
            "text": "Updates a group.     Form Parameters  Type  Description      name  String  Group Name    description  String  Group Description    roles  String  Comma-separated list of roles    members  String  Comma-separated list of members     Sample  TODO  Response  200 (OK) : The group has been updated.  404 (NOT FOUND) : The specified group does not exist.",
            "title": "PUT /api/groups/{group_id}"
        },
        {
            "location": "/api/groups-api/#delete-apigroupsgroup_id",
            "text": "Deletes a group.  Response  204 (NO CONTENT) : The group has been deleted.  404 (NOT FOUND) : The specified group does not exist.",
            "title": "DELETE /api/groups/{group_id}"
        },
        {
            "location": "/api/groups-api/#members",
            "text": "",
            "title": "Members"
        },
        {
            "location": "/api/groups-api/#post-apigroupsgroup_idmembers",
            "text": "Adds a member to a group.     Form Parameters  Type  Description      member  String  Member Name     Sample  https://opencast.domain.com/api/groups/MH_DEFAULT_ORG_SYSTEM_ADMINS/members  Response  200 (OK) : The member was already member of the group.  204 (NO CONTENT) : The member has been added.  404 (NOT FOUND) : The specified group does not exist.",
            "title": "POST /api/groups/{group_id}/members"
        },
        {
            "location": "/api/groups-api/#delete-apigroupsgroup_idmembersmember_id",
            "text": "Removes a member from a group  Sample  https://opencast.domain.com/api/groups/MH_DEFAULT_ORG_SYSTEM_ADMINS/members/admin  Response  204 (NO CONTENT) : The member has been removed.  404 (NOT FOUND) : The specified group or member does not exist.",
            "title": "DELETE /api/groups/{group_id}/members/{member_id}"
        },
        {
            "location": "/api/security-api/",
            "text": "Introduction\n\n\nOpencast is distributing encoded media to download and streaming servers to make that media available to end users. At the same time, that media needs to be protected such that - once provided a link to the download and/or streaming representations - only authorized users are able to consume it.\n\n\nThis is achieved by handing signed URLs to end users which are validated by the distribution servers and become invalid after a given period of time (usually 1 hour, depending on the server configuration).\n\n\nAs a consequence, users of the API who are presenting URLs to distributed media for playback will need to make sure that those urls are signed, otherwise the distribution servers will refuse to deliver the content and respond with a \n401 NOT AUTHORIZED\n status.\n\n\nBest practices\n\n\nThe use of signed URLs requires a set of best practices to be followed when clients interact with the API, most notably in the area of performance and caching.\n\n\nPerformance\n\n\nWhen consuming URLs that need to be signed before handing them to the user, client implementors may be inclinded to use the \nsign=true\n parameter for the events queries to request all URLs to be already signed. On one hand, this saves the client implementation from having to explicitly sign those URLs that users are visiting for playback. On the other hand, signing URLs introduces an overhead to performance for the pre-signing of all urls that are sent to the client, so in these cases it will be important to make sure not to transfer large lists \nand\n require presigning.\n\n\nCaching\n\n\nOne obvious caveat when using pre-signed URLs is the use of cached responses. As described above, signed URLs have a maxmimum life time and therefore need to be refreshed on a regular basis so that a user's request to play back a recording won't be rejected by the distribution servers.\n\n\nSecure access by source IP\n\n\nThe signing facility of the security API provides the ability to sign URLs and restrict that URL to a given IP address.\n\n\nEven though this greatly increases security in sense that signed URLs can only be accessed from that device, it is important to note that in many network setups, source IP addresses of network packets will undergo network address translation (NAT) with NAT replacing the original source address from private networks with a single public address, thereby diminishing the security impact of adding the source IP address immensely.\n\n\nURL Signing\n\n\nPOST /api/security/sign\n\n\nReturns a signed URL that can be played back for the indicated period of time, while access is optionally restricted to the specified IP address.\n\n\n\n\n\n\n\n\nForm Parameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nurl\n\n\nString\n\n\nThe linke to encode. \nrequired\n\n\n\n\n\n\nvalid-until\n\n\ndate\n\n\nUntil when is the signed url valid\n\n\n\n\n\n\nvalid-source\n\n\nip\n\n\nThe IP address from which the url can be accessed\n\n\n\n\n\n\n\n\nResponse\n\n\n200 (OK)\n: The signed URL is returned.\n\n\n401 (NOT AUTHORIZED)\n: The caller is not authorized to have the link signed.\n\n\n{\n  \"url\": \"http://opencast.org/video.mp4?valid-until=2015-03-11T13:23:51Z&keyId=default&signature=lsjhdf67tefj3\",\n  \"valid-until\": \"2015-03-11T13:23:51Z\"\n}",
            "title": "Security API"
        },
        {
            "location": "/api/security-api/#introduction",
            "text": "Opencast is distributing encoded media to download and streaming servers to make that media available to end users. At the same time, that media needs to be protected such that - once provided a link to the download and/or streaming representations - only authorized users are able to consume it.  This is achieved by handing signed URLs to end users which are validated by the distribution servers and become invalid after a given period of time (usually 1 hour, depending on the server configuration).  As a consequence, users of the API who are presenting URLs to distributed media for playback will need to make sure that those urls are signed, otherwise the distribution servers will refuse to deliver the content and respond with a  401 NOT AUTHORIZED  status.",
            "title": "Introduction"
        },
        {
            "location": "/api/security-api/#best-practices",
            "text": "The use of signed URLs requires a set of best practices to be followed when clients interact with the API, most notably in the area of performance and caching.",
            "title": "Best practices"
        },
        {
            "location": "/api/security-api/#performance",
            "text": "When consuming URLs that need to be signed before handing them to the user, client implementors may be inclinded to use the  sign=true  parameter for the events queries to request all URLs to be already signed. On one hand, this saves the client implementation from having to explicitly sign those URLs that users are visiting for playback. On the other hand, signing URLs introduces an overhead to performance for the pre-signing of all urls that are sent to the client, so in these cases it will be important to make sure not to transfer large lists  and  require presigning.",
            "title": "Performance"
        },
        {
            "location": "/api/security-api/#caching",
            "text": "One obvious caveat when using pre-signed URLs is the use of cached responses. As described above, signed URLs have a maxmimum life time and therefore need to be refreshed on a regular basis so that a user's request to play back a recording won't be rejected by the distribution servers.",
            "title": "Caching"
        },
        {
            "location": "/api/security-api/#secure-access-by-source-ip",
            "text": "The signing facility of the security API provides the ability to sign URLs and restrict that URL to a given IP address.  Even though this greatly increases security in sense that signed URLs can only be accessed from that device, it is important to note that in many network setups, source IP addresses of network packets will undergo network address translation (NAT) with NAT replacing the original source address from private networks with a single public address, thereby diminishing the security impact of adding the source IP address immensely.",
            "title": "Secure access by source IP"
        },
        {
            "location": "/api/security-api/#url-signing",
            "text": "",
            "title": "URL Signing"
        },
        {
            "location": "/api/security-api/#post-apisecuritysign",
            "text": "Returns a signed URL that can be played back for the indicated period of time, while access is optionally restricted to the specified IP address.     Form Parameters  Type  Description      url  String  The linke to encode.  required    valid-until  date  Until when is the signed url valid    valid-source  ip  The IP address from which the url can be accessed     Response  200 (OK) : The signed URL is returned.  401 (NOT AUTHORIZED) : The caller is not authorized to have the link signed.  {\n  \"url\": \"http://opencast.org/video.mp4?valid-until=2015-03-11T13:23:51Z&keyId=default&signature=lsjhdf67tefj3\",\n  \"valid-until\": \"2015-03-11T13:23:51Z\"\n}",
            "title": "POST /api/security/sign"
        }
    ]
}