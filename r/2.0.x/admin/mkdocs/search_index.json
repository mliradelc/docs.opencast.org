{
    "docs": [
        {
            "location": "/",
            "text": "Opencast Administration Guide\n\n\nWelcome to the Matterhorn Universe! Matterhorn is an open-source enterprise\nlevel lecture recording system. The core of the system delivers functionality\nfor scheduling, media encoding, editing and content delivery. For lecture\ncapture, Matterhorn provides capture agent software and third party appliances\nare available. An awesome community provides new features and support.\n\n\nThe Software\n\n\nMatterhorn contains everything you need for scheduling captures, trimming,\ncaptioning, and conversion of output media to several formats and our engage\ncomponents.  The core can be deployed on one (all-in-one deployment) or many\n(distributed deployment) Linux servers so your Matterhorn installation can grow\nwith the needs of your university.\n\n\nRelease Documentation\n\n\nThe Matterhorn Release Documentation is the official Matterhorn documentation\nfor each release. It contains:\n\n\n\n\nRelease Notes\n\n\nInstallation Guides\n\n\nConfiguration Guides\n\n\nBasic Configuration\n\n\nDatabase Configuration\n\n\nWorkflow Configuration\n\n\nEncoding Configuration\n\n\nmore...\n\n\n\n\n\n\nModule Documentation\n\n\nAtom and RSS Feed\n\n\nMedia Module\n\n\nText Extraction\n\n\nVideo Segmentation\n\n\nYouTube Publication\n\n\nmore...\n\n\n\n\n\n\nUpgrade Instructions\n\n\n\n\nFurther Documentation\n\n\nApart from these official documentation, further guides and tips can be found\nin the \nMatterhorn Adopter Wiki\n, as well as on\nthe mailing lists, the IRC channel and the regular meetings.",
            "title": "Administration Guide"
        },
        {
            "location": "/#opencast-administration-guide",
            "text": "Welcome to the Matterhorn Universe! Matterhorn is an open-source enterprise\nlevel lecture recording system. The core of the system delivers functionality\nfor scheduling, media encoding, editing and content delivery. For lecture\ncapture, Matterhorn provides capture agent software and third party appliances\nare available. An awesome community provides new features and support.",
            "title": "Opencast Administration Guide"
        },
        {
            "location": "/#the-software",
            "text": "Matterhorn contains everything you need for scheduling captures, trimming,\ncaptioning, and conversion of output media to several formats and our engage\ncomponents.  The core can be deployed on one (all-in-one deployment) or many\n(distributed deployment) Linux servers so your Matterhorn installation can grow\nwith the needs of your university.",
            "title": "The Software"
        },
        {
            "location": "/#release-documentation",
            "text": "The Matterhorn Release Documentation is the official Matterhorn documentation\nfor each release. It contains:   Release Notes  Installation Guides  Configuration Guides  Basic Configuration  Database Configuration  Workflow Configuration  Encoding Configuration  more...    Module Documentation  Atom and RSS Feed  Media Module  Text Extraction  Video Segmentation  YouTube Publication  more...    Upgrade Instructions",
            "title": "Release Documentation"
        },
        {
            "location": "/#further-documentation",
            "text": "Apart from these official documentation, further guides and tips can be found\nin the  Matterhorn Adopter Wiki , as well as on\nthe mailing lists, the IRC channel and the regular meetings.",
            "title": "Further Documentation"
        },
        {
            "location": "/release.notes/",
            "text": "Opencast 2.0: Release Notes\n\n\nOpencast Matterhorn becomes simply Opencast\n\n\nFor a long time Matterhorn was the one project of the Opencast community and it was hard to distinguish between the two\nnames. With the new major release and the move towards Apereo, the Board decided to harmonize the names and\ndrop the former codename \u201c\nMatterhorn\n\u201d. Hence, Matterhorn is dead, long live Opencast!\n\n\nNew Features\n\n\n\n\nNew administrative user interface\n \u2013\n   One of the most obvious changes in the new release is the new administrative user interface. It has been completely\n   rewritten from scratch, using up-to-date technologies and a cleaner design. For more details, have a look at the\n   \nOpencast Users Guide\n.\n\n\nNew Engage player\n \u2013\n   Opencast 2.0 now offers a HTML5 video player. Its user-interface is accessible: you can control the player with\n   keyboard-shortcuts, ARIA profiles support screen-readers and captions are supported.\n   The architecture is very modular in design so that new plugins can easily be created. HLS is now supported as a\n   streaming protocol but RTMP is still available through a Flash fallback.\n\n\nPlayer Architecture\n\n\nPlayer Configuration\n\n\n\n\n\n\nNew media module\n \u2013\n   The Media Module has been slightly updated. It offers a new tile design which adapts to different screen sizes,\n   from mobile devices to regular desktop resolutions.\n   Within the Media Module configuration an easy selection of various players has been implemented so that the\n   administrator can define the default player to be used.\n\n\nNew FFmpeg-based video editor backend\n \u2013\n   This change allows us to get rid of the GStreamer dependency.\n\n\nNew video segmenter\n \u2013\n   Opencast 2.0 comes with a new video segmenter based on the FFmpeg \nselect\n filter. It makes the process much faster\n   and (if configured properly) will even allow detection of scene changes in presenter videos.\n\n\nNew silence detector\n \u2013\n   As with the video segmenter, the silence detector has been replaced with an FFmpeg-based implementation.\n\n\nNew documentation\n \u2013\n   Until now, the Opencast documentation was confusing because it was split-up into several wikis and people never knew\n   where to look for a topic. All official documentation can now be found at\n   \nhttp://docs.opencast.org/\n. The documentation is also included in the source code, so\n   that it is connected with the current state of development.  Apart from the official documentation, two wikis still\n   exist. These are the \nOpencast Adopters Wiki\n (meant for users to share their guides)\n   and the \nOpencast Development Wiki\n (meant for storing working drafts).\n\n\n\n\nImportant Administrative Notes\n\n\n\n\nApache ActiveMQ\n \u2013\n   Since Opencast 2, the Apache ActiveMQ message broker is used to enable an asynchronous, fast and reliable data\n   exchange between back-end and user interface. It requires, however, to run ActiveMQ as external service, much like\n   running a separate database (e.g. MariaDB).\n\n\nNo GStreamer 0.10 dependency\n \u2013\n   For a long time, Opencast has used GStreamer 0.10 and the Java bindings for that version. This GStreamer version\n   has been deprecated for years and is slowly disappearing from all major operating systems. Upgrading GStreamer proved\n   nearly impossible since there are no Java bindings for the newer versions. Therefore, we decided to get rid of\n   GStreamer, mainly by replacing it with FFmpeg.\n\n\n\n\nRemoved Components\n\n\n\n\nReference capture agent\n \u2013\n   For a long time, Opencast came with a reference capture agent, providing a free, open source software capture agent.\n   In the last years, however, it was mainly replaced by other capture agents. One reason for that was the fact that the\n   development of the reference capture agent itself has come to a halt due to lack of interest. That is why\n   it was decided to separate the capture agent code from the Opencast core and move it into its own project.\n\n\nGStreamer service\n \u2013\n   As outlined before, GStreamer 0.10 has been removed from Opencast 2.0. Many parts have been thus replaced. One\n   module that has not been replaced, but simply removed instead, is the GStreamer service, which provided a backend\n   for other modules to talk to the deprecated GStreamer version using the deprecated Java bindings.\n\n\n\n\nHow to Upgrade\n\n\nNote that backing up your Opencast instance before doing a major update is strongly recommended.\n\n\n\n\nCheck out/download Opencast 2.0\n\n\nStop your current Opencast instance\n\n\nBack up Opencast files and database (optional)\n\n\nRun the appropriate database upgrade script (docs/upgrade/1.6_to_2.0)\n\n\nReview the configuration changes and adjust your configuration accordingly\n\n\nUpdate the third party tools as documented\n\n\nBuild Opencast 2.0\n\n\nStart Opencast\n\n\n\n\nAdditional Notes About 2.0.2\n\n\nOpencast 2.0.2 is a bug fix release including a database update script. Some indexes were missing in the Opencast 2.0\ndatabase which would eventually slow down Opencast. This is now fixed. This means that in order to update, a database\nupdate is required. Please use the provided update script.",
            "title": "Release Notes"
        },
        {
            "location": "/release.notes/#opencast-20-release-notes",
            "text": "Opencast Matterhorn becomes simply Opencast  For a long time Matterhorn was the one project of the Opencast community and it was hard to distinguish between the two\nnames. With the new major release and the move towards Apereo, the Board decided to harmonize the names and\ndrop the former codename \u201c Matterhorn \u201d. Hence, Matterhorn is dead, long live Opencast!",
            "title": "Opencast 2.0: Release Notes"
        },
        {
            "location": "/release.notes/#new-features",
            "text": "New administrative user interface  \u2013\n   One of the most obvious changes in the new release is the new administrative user interface. It has been completely\n   rewritten from scratch, using up-to-date technologies and a cleaner design. For more details, have a look at the\n    Opencast Users Guide .  New Engage player  \u2013\n   Opencast 2.0 now offers a HTML5 video player. Its user-interface is accessible: you can control the player with\n   keyboard-shortcuts, ARIA profiles support screen-readers and captions are supported.\n   The architecture is very modular in design so that new plugins can easily be created. HLS is now supported as a\n   streaming protocol but RTMP is still available through a Flash fallback.  Player Architecture  Player Configuration    New media module  \u2013\n   The Media Module has been slightly updated. It offers a new tile design which adapts to different screen sizes,\n   from mobile devices to regular desktop resolutions.\n   Within the Media Module configuration an easy selection of various players has been implemented so that the\n   administrator can define the default player to be used.  New FFmpeg-based video editor backend  \u2013\n   This change allows us to get rid of the GStreamer dependency.  New video segmenter  \u2013\n   Opencast 2.0 comes with a new video segmenter based on the FFmpeg  select  filter. It makes the process much faster\n   and (if configured properly) will even allow detection of scene changes in presenter videos.  New silence detector  \u2013\n   As with the video segmenter, the silence detector has been replaced with an FFmpeg-based implementation.  New documentation  \u2013\n   Until now, the Opencast documentation was confusing because it was split-up into several wikis and people never knew\n   where to look for a topic. All official documentation can now be found at\n    http://docs.opencast.org/ . The documentation is also included in the source code, so\n   that it is connected with the current state of development.  Apart from the official documentation, two wikis still\n   exist. These are the  Opencast Adopters Wiki  (meant for users to share their guides)\n   and the  Opencast Development Wiki  (meant for storing working drafts).",
            "title": "New Features"
        },
        {
            "location": "/release.notes/#important-administrative-notes",
            "text": "Apache ActiveMQ  \u2013\n   Since Opencast 2, the Apache ActiveMQ message broker is used to enable an asynchronous, fast and reliable data\n   exchange between back-end and user interface. It requires, however, to run ActiveMQ as external service, much like\n   running a separate database (e.g. MariaDB).  No GStreamer 0.10 dependency  \u2013\n   For a long time, Opencast has used GStreamer 0.10 and the Java bindings for that version. This GStreamer version\n   has been deprecated for years and is slowly disappearing from all major operating systems. Upgrading GStreamer proved\n   nearly impossible since there are no Java bindings for the newer versions. Therefore, we decided to get rid of\n   GStreamer, mainly by replacing it with FFmpeg.",
            "title": "Important Administrative Notes"
        },
        {
            "location": "/release.notes/#removed-components",
            "text": "Reference capture agent  \u2013\n   For a long time, Opencast came with a reference capture agent, providing a free, open source software capture agent.\n   In the last years, however, it was mainly replaced by other capture agents. One reason for that was the fact that the\n   development of the reference capture agent itself has come to a halt due to lack of interest. That is why\n   it was decided to separate the capture agent code from the Opencast core and move it into its own project.  GStreamer service  \u2013\n   As outlined before, GStreamer 0.10 has been removed from Opencast 2.0. Many parts have been thus replaced. One\n   module that has not been replaced, but simply removed instead, is the GStreamer service, which provided a backend\n   for other modules to talk to the deprecated GStreamer version using the deprecated Java bindings.",
            "title": "Removed Components"
        },
        {
            "location": "/release.notes/#how-to-upgrade",
            "text": "Note that backing up your Opencast instance before doing a major update is strongly recommended.   Check out/download Opencast 2.0  Stop your current Opencast instance  Back up Opencast files and database (optional)  Run the appropriate database upgrade script (docs/upgrade/1.6_to_2.0)  Review the configuration changes and adjust your configuration accordingly  Update the third party tools as documented  Build Opencast 2.0  Start Opencast",
            "title": "How to Upgrade"
        },
        {
            "location": "/release.notes/#additional-notes-about-202",
            "text": "Opencast 2.0.2 is a bug fix release including a database update script. Some indexes were missing in the Opencast 2.0\ndatabase which would eventually slow down Opencast. This is now fixed. This means that in order to update, a database\nupdate is required. Please use the provided update script.",
            "title": "Additional Notes About 2.0.2"
        },
        {
            "location": "/installation/",
            "text": "Install Opencast\n\n\nInstallation from Source\n\n\nThese guides will help you to build Opencast, including all necessary third party tools. This method will most likely\nwork on all Unix-like systems.\n\n\n\n\nRedHat Enterprise Linux\n\n\nCentOS\n\n\nScientific Linux\n\n\nFedora\n\n\nDebian\n\n\nUbuntu\n\n\nMac OS X\n\n\n\n\nBuilding on most other Unix-like operating systems should be very much alike.\n\n\nInstallation from Repository\n\n\nThere is an RPM repository available for some operating systems. It provides packages containing pre-configured and\npre-built Opencast installations.\n\n\n\n\nRedHat Enterprise Linux\n\n\nCentOS\n\n\nScientific Linux\n\n\nFedora\n\n\n\n\nInstallation Across Multiple Servers\n\n\nFor production systems, it is recommended to install Opencast across multiple servers to separate the processing,\nmanagement and presentation layer, so that, for example, even if the processing layer is under full load, users can\nstill watch recordings unaffected since the presentation layer is running on a separate machine.\n\n\n\n\nInstallation Across Multiple Servers",
            "title": "Installation Home"
        },
        {
            "location": "/installation/#install-opencast",
            "text": "",
            "title": "Install Opencast"
        },
        {
            "location": "/installation/#installation-from-source",
            "text": "These guides will help you to build Opencast, including all necessary third party tools. This method will most likely\nwork on all Unix-like systems.   RedHat Enterprise Linux  CentOS  Scientific Linux  Fedora  Debian  Ubuntu  Mac OS X   Building on most other Unix-like operating systems should be very much alike.",
            "title": "Installation from Source"
        },
        {
            "location": "/installation/#installation-from-repository",
            "text": "There is an RPM repository available for some operating systems. It provides packages containing pre-configured and\npre-built Opencast installations.   RedHat Enterprise Linux  CentOS  Scientific Linux  Fedora",
            "title": "Installation from Repository"
        },
        {
            "location": "/installation/#installation-across-multiple-servers",
            "text": "For production systems, it is recommended to install Opencast across multiple servers to separate the processing,\nmanagement and presentation layer, so that, for example, even if the processing layer is under full load, users can\nstill watch recordings unaffected since the presentation layer is running on a separate machine.   Installation Across Multiple Servers",
            "title": "Installation Across Multiple Servers"
        },
        {
            "location": "/installation/multiple-servers/",
            "text": "Install Across Multiple Servers\n\n\nNote that this is not a comprehensive guide of all possible ways to install Matterhorn. It is more like a guide to good\npractice and presents what a lot of people are running.\n\n\nStep 1: Install Matterhorn\n\n\nFor a distributed set-up you basically only need to put the right modules onto the right node in the Matterhorn system.\nTo make things less complicated, these modules are grouped together as profiles which you can directly build and\ninstall.\n\n\nIf you want to build Matterhorn yourself, you can invoke the build process for certain modules by using mavens \n-P\n\noption. For example the following command will build the three profiles called worker-standalone, serviceregistry and\nworkspace (These are the profiles needed for a worker node):\n\n\nmvn clean install -DdeployTo=/path/to/matterhorn/ \\\n  -Pworker-standalone,serviceregistry,workspace\n\n\n\nIf you are using the Matterhorn RPM repository instead, you can do the same by installing the profile packages like\nthis:\n\n\nyum install opencast-matterhorn14-profile-worker-standalone \\\n  opencast-matterhorn14-profile-serviceregistry \\\n  opencast-matterhorn14-profile-workspace\n\n\n\nTo make things easier, the repository also contains a set of predefined distribution packages which will automatically\ninstall all dependencies for a given node type. For example, to install a Matterhorn worker node:\n\n\nyum install opencast-matterhorn14-distribution-worker\n\n\n\nThis is the general idea behind a distributed set-up of Matterhorn. The following list will now give a list of examples\nabout how you could distribute Matterhorn over a given set of machines and what you need to install for that.  You\nshould be aware that these examples are not the only possible ways of setting up Matterhorn. They are, however, a good\nway to start.\n\n\nWhat is not specified in this list is the location of the database and the storage server. You can place them either\n   on one of the Matterhorn nodes or create a dedicated machine for them. The latter will obviously give you more\n   performance.\n\n\nAll-In-One\n\n\nThis is the default set-up described in the basic installation guides. It works fine for testing purposes should,\nhowever, not be used in production. It is not distributed but is listed here to have a comprehensive list of necessary\nprofiles. For an All-In-One system the following profiles need to be installed:\n\n\nadmin, dist, engage, worker, workspace, serviceregistry, directory-db\n\n\n\nMaven build command:\n\n\nmvn clean install -DdeployTo=/path/to/matterhorn/\n\n\n\nRPM Repository installation:\n\n\nyum install opencast-matterhorn14-distribution-default\n\n\n\nTwo-Server Set-up\n\n\nThis set-up is the minimum set-up recommended for productive use. It will separate the distribution layer from the\nadministrative and working layer. This means that even if one server is under heavy load as videos are processed, etc.\nit will not effect the distribution and users should still be able to watch videos smoothly. However, it might happen\nthat under heavy load the handling of the administrative ui gets a bit rough.\n\n\nNecessary profiles to build:\n\n\nadmin-worker: admin,workspace,dist-stub,engage-stub,worker,serviceregistry\nengage: engage-standalone,serviceregistry,dist-standalone,workspace\n\n\n\nMaven build commands:\n\n\n# admin-worker\nmvn clean install -DdeployTo=/path/to/matterhorn/ \\\n  -Padmin,workspace,dist-stub,engage-stub,worker,serviceregistry\n# engage\nmvn clean install -DdeployTo=/path/to/matterhorn/ \\\n  -Pengage-standalone,serviceregistry,dist-standalone,workspace\n\n\n\nRPM Repository installation:\n\n\n# admin-worker\nyum install opencast-matterhorn14-distribution-admin-worker\n# engage\nyum install opencast-matterhorn14-distribution-engage\n\n\n\nThree (or more) Server Set-up\n\n\nWhile in the last example we have created one combined node for both the administrative tools and the workers, in this\nexample we will split this node into dedicated worker and admin nodes. Using this set-up it is easy to increase the\nsystems performance simply by adding further worker nodes to the system.\n\n\nNecessary profiles to build:\n\n\nadmin: admin,workspace,dist-stub,engage-stub,worker-stub,serviceregistry\nworker: serviceregistry,workspace,worker-standalone\nengage: engage-standalone,serviceregistry,dist-standalone,workspace\n\n\n\nMaven build commands:\n\n\n# admin\nmvn clean install -DdeployTo=/path/to/matterhorn/ \\\n  -Padmin,workspace,dist-stub,engage-stub,worker-stub,serviceregistry\n# worker\nmvn clean install -DdeployTo=/path/to/matterhorn/ \\\n  -Pserviceregistry,workspace,worker-standalone\n# engage\nmvn clean install -DdeployTo=/path/to/matterhorn/ \\\n  -Pengage-standalone,serviceregistry,dist-standalone,workspace\n\n\n\nRPM Repository installation:\n\n\n# admin\nyum install opencast-matterhorn14-distribution-admin\n# worker\nyum install opencast-matterhorn14-distribution-worker\n# engage\nyum install opencast-matterhorn14-distribution-engage\n\n\n\nStep 2: Set-Up NFS Server\n\n\nThough it is possible to have Matterhorn run without shared storage, it is still a good idea to do so, as hard links can\nbe used to link files instead of copying them and not everything has to be tunneled over HTTP.\n\n\nThus you should first set-up your NFS server. The best solution is certainly to have a dedicated storage server. For\nsmaller set-ups, however, it can also be put on one of the Matterhorn nodes, i.e. on the admin node.\n\n\nTo do this, you first have to install and enable the NFS server:\n\n\nyum install nfs-utils nfs-utils-lib\nchkconfig  --level 345 nfs on\nservice nfs start\n\n\n\nYou want to have one common user on all your systems, so that file permissions do not become an issue.. As preparation\nfor this it makes sense to manually create a matterhorn user and group with a common UID and GID:\n\n\ngroupadd -g 1234 matterhorn\nuseradd -g 1234 -u 1234 matterhorn\n\n\n\nIf the user and group id \n1234\n is already used, just pick another one but make sure to pick the same one on all your\nMatterhorn nodes.\n\n\nThen create the directory to be shared and set its ownership to the newly created users:\n\n\nmkdir -p /srv/matterhorn\nchown matterhorn:matterhorn /srv/matterhorn\n\n\n\nNext we actually share the storage dir. For this we need to edit the file \n/etc/exports\n and set:\n\n\n/srv/matterhorn  131.173.172.190(rw,sync,no_subtree_check)\n\n\n\nwith 131.173.172.190 being the IP address of the other machine that should get access. Finally we enable the share with:\n\n\nexportfs -a\n\n\n\nOf cause you have to open the necessary ports in your firewall configuration.  For iptables, appropriate rules could be\nfor example:\n\n\n-A INPUT -m state --state NEW -p tcp -m multiport --dport 111,892,2049,32803 -j ACCEPT\n-A INPUT -m state --state NEW -p udp -m multiport --dport 111,892,2049,32803 -j ACCEPT\n\n\n\nYou can set them by editing \n/etc/sysconfig/iptables\n and restarting the service afterwards.\n\n\nNow you have set-up your storage server. What is still left to do is to mount the network storage on all other servers\nof the matterhorn clusters except the capture agents. To do that you need to edit the \n/etc/fstab\n on each server and\nadd the command to mount the network storage on startup:\n\n\nstorageserver.example.com:/srv/matterhorn /srv/matterhorn   nfs rw,hard,intr,rsize=32768,wsize=32768 0 0\n\n\n\nImportant:\n Do not use multiple NFS shares for different parts of the Matterhorn storage dir. Matterhorn will check if\nhard links are possible across in a distributed set-up, but the detection may fail if hard links are only possible\nbetween certain parts of the storage. This may lead to failures.\n\n\nStep 3: Set-Up the Database\n\n\nFirst make sure to follow the \nregular database set-up\n.\n\n\nDo not forget to set the user also for the remote servers and grant them the necessary rights. Additionally, you need to\nconfigure your firewall:\n\n\n-A INPUT -p tcp -s 131.173.172.190 --dport 3306 -m state --state NEW,ESTABLISHED -j ACCEPT\n\n\n\nStep 4: Set-Up ActiveMQ\n\n\nSince version 2, Opencast Matterhorn requires an Apache ActiveMQ message broker as message relay for the administrative\nuser interface. ActiveMQ can either be set up to run on its own machine or on one of the existing Matterhorn nodes\n(usually the admin node).\n\n\nActiveMQ 5.10 or above should work. ActiveMQ 5.6 will not work. Versions in between are untested.\n\n\nInstallation\n\n\n\n\nIf you use the Matterhorn RPM repository, simply install the \nactivemq-dist\n package.\n\n\nIf you are running RHEL, CentOS or Fedora you can use the \nActiveMQ-dist Copr RPM repository\n   \n\n\nYou can download binary distributions from the \nApache ActiveMQ website\n\n\n\n\nConfiguration\n\n\nWhat you basically need to do is to point all your Matterhorn nodes to your message broker. For more information about\nthe configuration, have a look at the \nMessage Broker Set-Up Guide\n.\n\n\nDo not forget that ActiveMQ uses TCP port 61616 (default configuration) for communication which you might have to allow in your firewall.\n\n\nStep 5: Configure Matterhorn\n\n\nYou did already set-up and configured your database and message broker in the last steps, but there is some more\nconfiguration you have to do. First of all you should follow the Basic Configuration guide which will tell you how to\nset the login credentials etc. After that continue with the following steps:\n\n\nconfig.properties\n\n\nSet the server URL to the public url of each server (admin URL on admin, worker URL on worker, engage URL on engage, \u2026).\nThis may either be this nodes IP address or preferable its domain name:\n\n\norg.opencastproject.server.url=http://<URL>:8080\n\n\n\nSet the location of the shared storage directory:\n\n\norg.opencastproject.storage.dir=/srv/matterhorn\n\n\n\nDefine that the file repository shall access all files locally:\n\n\norg.opencastproject.file.repo.url=${org.opencastproject.admin.ui.url}\n\n\n\nload/org.opencastproject.organization-mh_default_org.cfg\n\n\nSet the base URL of the server hosting the administrative tools. Again use a domain name instead of an IP address if\npossible:\n\n\norg.opencastproject.admin.ui.url=http://<ADMIN-URL>:8080\n\n\n\nSet the base URL of the server hosting the engage tools:\n\n\norg.opencastproject.engage.ui.url=http://<ENGAGE-URL>:8080\n\n\n\nservices/org.opencastproject.serviceregistry.impl.ServiceRegistryJpaImpl.properties\n\n\nTo ensure that jobs are not dispatched by non-admin nodes you may also want to set:\n\n\ndispatchinterval=0",
            "title": "Multiple Servers"
        },
        {
            "location": "/installation/multiple-servers/#install-across-multiple-servers",
            "text": "Note that this is not a comprehensive guide of all possible ways to install Matterhorn. It is more like a guide to good\npractice and presents what a lot of people are running.",
            "title": "Install Across Multiple Servers"
        },
        {
            "location": "/installation/multiple-servers/#step-1-install-matterhorn",
            "text": "For a distributed set-up you basically only need to put the right modules onto the right node in the Matterhorn system.\nTo make things less complicated, these modules are grouped together as profiles which you can directly build and\ninstall.  If you want to build Matterhorn yourself, you can invoke the build process for certain modules by using mavens  -P \noption. For example the following command will build the three profiles called worker-standalone, serviceregistry and\nworkspace (These are the profiles needed for a worker node):  mvn clean install -DdeployTo=/path/to/matterhorn/ \\\n  -Pworker-standalone,serviceregistry,workspace  If you are using the Matterhorn RPM repository instead, you can do the same by installing the profile packages like\nthis:  yum install opencast-matterhorn14-profile-worker-standalone \\\n  opencast-matterhorn14-profile-serviceregistry \\\n  opencast-matterhorn14-profile-workspace  To make things easier, the repository also contains a set of predefined distribution packages which will automatically\ninstall all dependencies for a given node type. For example, to install a Matterhorn worker node:  yum install opencast-matterhorn14-distribution-worker  This is the general idea behind a distributed set-up of Matterhorn. The following list will now give a list of examples\nabout how you could distribute Matterhorn over a given set of machines and what you need to install for that.  You\nshould be aware that these examples are not the only possible ways of setting up Matterhorn. They are, however, a good\nway to start.  What is not specified in this list is the location of the database and the storage server. You can place them either\n   on one of the Matterhorn nodes or create a dedicated machine for them. The latter will obviously give you more\n   performance.",
            "title": "Step 1: Install Matterhorn"
        },
        {
            "location": "/installation/multiple-servers/#all-in-one",
            "text": "This is the default set-up described in the basic installation guides. It works fine for testing purposes should,\nhowever, not be used in production. It is not distributed but is listed here to have a comprehensive list of necessary\nprofiles. For an All-In-One system the following profiles need to be installed:  admin, dist, engage, worker, workspace, serviceregistry, directory-db  Maven build command:  mvn clean install -DdeployTo=/path/to/matterhorn/  RPM Repository installation:  yum install opencast-matterhorn14-distribution-default",
            "title": "All-In-One"
        },
        {
            "location": "/installation/multiple-servers/#two-server-set-up",
            "text": "This set-up is the minimum set-up recommended for productive use. It will separate the distribution layer from the\nadministrative and working layer. This means that even if one server is under heavy load as videos are processed, etc.\nit will not effect the distribution and users should still be able to watch videos smoothly. However, it might happen\nthat under heavy load the handling of the administrative ui gets a bit rough.  Necessary profiles to build:  admin-worker: admin,workspace,dist-stub,engage-stub,worker,serviceregistry\nengage: engage-standalone,serviceregistry,dist-standalone,workspace  Maven build commands:  # admin-worker\nmvn clean install -DdeployTo=/path/to/matterhorn/ \\\n  -Padmin,workspace,dist-stub,engage-stub,worker,serviceregistry\n# engage\nmvn clean install -DdeployTo=/path/to/matterhorn/ \\\n  -Pengage-standalone,serviceregistry,dist-standalone,workspace  RPM Repository installation:  # admin-worker\nyum install opencast-matterhorn14-distribution-admin-worker\n# engage\nyum install opencast-matterhorn14-distribution-engage",
            "title": "Two-Server Set-up"
        },
        {
            "location": "/installation/multiple-servers/#three-or-more-server-set-up",
            "text": "While in the last example we have created one combined node for both the administrative tools and the workers, in this\nexample we will split this node into dedicated worker and admin nodes. Using this set-up it is easy to increase the\nsystems performance simply by adding further worker nodes to the system.  Necessary profiles to build:  admin: admin,workspace,dist-stub,engage-stub,worker-stub,serviceregistry\nworker: serviceregistry,workspace,worker-standalone\nengage: engage-standalone,serviceregistry,dist-standalone,workspace  Maven build commands:  # admin\nmvn clean install -DdeployTo=/path/to/matterhorn/ \\\n  -Padmin,workspace,dist-stub,engage-stub,worker-stub,serviceregistry\n# worker\nmvn clean install -DdeployTo=/path/to/matterhorn/ \\\n  -Pserviceregistry,workspace,worker-standalone\n# engage\nmvn clean install -DdeployTo=/path/to/matterhorn/ \\\n  -Pengage-standalone,serviceregistry,dist-standalone,workspace  RPM Repository installation:  # admin\nyum install opencast-matterhorn14-distribution-admin\n# worker\nyum install opencast-matterhorn14-distribution-worker\n# engage\nyum install opencast-matterhorn14-distribution-engage",
            "title": "Three (or more) Server Set-up"
        },
        {
            "location": "/installation/multiple-servers/#step-2-set-up-nfs-server",
            "text": "Though it is possible to have Matterhorn run without shared storage, it is still a good idea to do so, as hard links can\nbe used to link files instead of copying them and not everything has to be tunneled over HTTP.  Thus you should first set-up your NFS server. The best solution is certainly to have a dedicated storage server. For\nsmaller set-ups, however, it can also be put on one of the Matterhorn nodes, i.e. on the admin node.  To do this, you first have to install and enable the NFS server:  yum install nfs-utils nfs-utils-lib\nchkconfig  --level 345 nfs on\nservice nfs start  You want to have one common user on all your systems, so that file permissions do not become an issue.. As preparation\nfor this it makes sense to manually create a matterhorn user and group with a common UID and GID:  groupadd -g 1234 matterhorn\nuseradd -g 1234 -u 1234 matterhorn  If the user and group id  1234  is already used, just pick another one but make sure to pick the same one on all your\nMatterhorn nodes.  Then create the directory to be shared and set its ownership to the newly created users:  mkdir -p /srv/matterhorn\nchown matterhorn:matterhorn /srv/matterhorn  Next we actually share the storage dir. For this we need to edit the file  /etc/exports  and set:  /srv/matterhorn  131.173.172.190(rw,sync,no_subtree_check)  with 131.173.172.190 being the IP address of the other machine that should get access. Finally we enable the share with:  exportfs -a  Of cause you have to open the necessary ports in your firewall configuration.  For iptables, appropriate rules could be\nfor example:  -A INPUT -m state --state NEW -p tcp -m multiport --dport 111,892,2049,32803 -j ACCEPT\n-A INPUT -m state --state NEW -p udp -m multiport --dport 111,892,2049,32803 -j ACCEPT  You can set them by editing  /etc/sysconfig/iptables  and restarting the service afterwards.  Now you have set-up your storage server. What is still left to do is to mount the network storage on all other servers\nof the matterhorn clusters except the capture agents. To do that you need to edit the  /etc/fstab  on each server and\nadd the command to mount the network storage on startup:  storageserver.example.com:/srv/matterhorn /srv/matterhorn   nfs rw,hard,intr,rsize=32768,wsize=32768 0 0  Important:  Do not use multiple NFS shares for different parts of the Matterhorn storage dir. Matterhorn will check if\nhard links are possible across in a distributed set-up, but the detection may fail if hard links are only possible\nbetween certain parts of the storage. This may lead to failures.",
            "title": "Step 2: Set-Up NFS Server"
        },
        {
            "location": "/installation/multiple-servers/#step-3-set-up-the-database",
            "text": "First make sure to follow the  regular database set-up .  Do not forget to set the user also for the remote servers and grant them the necessary rights. Additionally, you need to\nconfigure your firewall:  -A INPUT -p tcp -s 131.173.172.190 --dport 3306 -m state --state NEW,ESTABLISHED -j ACCEPT",
            "title": "Step 3: Set-Up the Database"
        },
        {
            "location": "/installation/multiple-servers/#step-4-set-up-activemq",
            "text": "Since version 2, Opencast Matterhorn requires an Apache ActiveMQ message broker as message relay for the administrative\nuser interface. ActiveMQ can either be set up to run on its own machine or on one of the existing Matterhorn nodes\n(usually the admin node).  ActiveMQ 5.10 or above should work. ActiveMQ 5.6 will not work. Versions in between are untested.",
            "title": "Step 4: Set-Up ActiveMQ"
        },
        {
            "location": "/installation/multiple-servers/#installation",
            "text": "If you use the Matterhorn RPM repository, simply install the  activemq-dist  package.  If you are running RHEL, CentOS or Fedora you can use the  ActiveMQ-dist Copr RPM repository\n     You can download binary distributions from the  Apache ActiveMQ website",
            "title": "Installation"
        },
        {
            "location": "/installation/multiple-servers/#configuration",
            "text": "What you basically need to do is to point all your Matterhorn nodes to your message broker. For more information about\nthe configuration, have a look at the  Message Broker Set-Up Guide .  Do not forget that ActiveMQ uses TCP port 61616 (default configuration) for communication which you might have to allow in your firewall.",
            "title": "Configuration"
        },
        {
            "location": "/installation/multiple-servers/#step-5-configure-matterhorn",
            "text": "You did already set-up and configured your database and message broker in the last steps, but there is some more\nconfiguration you have to do. First of all you should follow the Basic Configuration guide which will tell you how to\nset the login credentials etc. After that continue with the following steps:",
            "title": "Step 5: Configure Matterhorn"
        },
        {
            "location": "/installation/multiple-servers/#configproperties",
            "text": "Set the server URL to the public url of each server (admin URL on admin, worker URL on worker, engage URL on engage, \u2026).\nThis may either be this nodes IP address or preferable its domain name:  org.opencastproject.server.url=http://<URL>:8080  Set the location of the shared storage directory:  org.opencastproject.storage.dir=/srv/matterhorn  Define that the file repository shall access all files locally:  org.opencastproject.file.repo.url=${org.opencastproject.admin.ui.url}",
            "title": "config.properties"
        },
        {
            "location": "/installation/multiple-servers/#loadorgopencastprojectorganization-mh_default_orgcfg",
            "text": "Set the base URL of the server hosting the administrative tools. Again use a domain name instead of an IP address if\npossible:  org.opencastproject.admin.ui.url=http://<ADMIN-URL>:8080  Set the base URL of the server hosting the engage tools:  org.opencastproject.engage.ui.url=http://<ENGAGE-URL>:8080",
            "title": "load/org.opencastproject.organization-mh_default_org.cfg"
        },
        {
            "location": "/installation/multiple-servers/#servicesorgopencastprojectserviceregistryimplserviceregistryjpaimplproperties",
            "text": "To ensure that jobs are not dispatched by non-admin nodes you may also want to set:  dispatchinterval=0",
            "title": "services/org.opencastproject.serviceregistry.impl.ServiceRegistryJpaImpl.properties"
        },
        {
            "location": "/installation/rpm-fedora/",
            "text": "Install from Repository (Fedora)\n\n\nThere is an RPM software repository available for RedHat-based Linux distributions provided by the University of\nOsnabr\u00fcck. This repository provides preconfigured Opencast installations, including all 3rd-Party-Tools. Using this\nmethod, you do not have to compile the software by yourself.\n\n\nIt is also interesting for developers as all dependencies for Opencast usage, testing and development are provided by\nthe RPM repository.\n\n\nSupported Versions\n\n\nFor Fedora usually the latest two versions are supported, meaning that the support is dependent on the status of the\nFedora release. For architectures, \nonly\n \nx86_64\n is supported. 32bit architectures are \nnot\n supported.\n\n\nRegistration\n\n\nBefore you can start you need to get an account for the repository. You will need the credentials that you get by mail\nafter the registration to successfully complete this manual. The placeholders \n[your_username]\n and \n[your_password]\n\nare used in this manual wherever the credentials are needed.\n\n\n\n\nhttp://repo.virtuos.uos.de\n\n\n\n\nActivate Repository\n\n\nFirst you have to install the necessary repositories so that your package manager can access them:\n\n\n\n\n\n\nAdd matterhorn repository:\n\n\ncd /etc/yum.repos.d\ncurl -O http://repo.virtuos.uos.de/matterhorn-testing.repo \\\n  -d 'version=$releasever' -d os=fc \\\n  -u [your_username]:[your_password]\n\n\n\n\n\n\nAdd RPMfusion repository:\n\n\ndnf install --nogpgcheck \\\n  http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm \\\n  http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonf\n\n\n\n\n\n\nInstall 3rd-party-tools\n\n\nThis step is optional and only recommended for those who want to build Opencast from source. If you install Opencast\nfrom the repository, all necessary dependencies will be installed automatically.\n\n\nYou can install all necessary 3rd-Party-Tools for matterhorn like this:\n\n\nsudo dnf install opencast20-third-party-tools\n\n\n\nOr manually:\n\n\nsudo dnf install ffmpeg qt_sbtl_embedder tesseract mediainfo\n\n\n\nInstall Apache ActiveMQ\n\n\nThe Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be\ninstalled on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the\nOpencast RPM repository as well and can be installed by running:\n\n\ndnf install activemq-dist\n\n\n\nA prepared configuration file for ActiveMQ can be found at \n/usr/share/matterhorn/docs/scripts/activemq/activemq.xml\n\n\nafter Opencast itself has been installed\n and should replace \n/etc/activemq/activemq.xml\n. For an all-in-one\ninstallation the following command should suffice:\n\n\nsudo cp /usr/share/matterhorn/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml\n\n\n\nActiveMQ should be started before starting Opencast.\n\n\nMore information about how to properly set up ActiveMQ for Opencast can be found in the \nmessage broker configuration\ndocumentation\n.\n\n\nInstall Opencast\n\n\nFor this guide, \nopencast20\n is used as placeholder for the package name. It will install the latest version of the\nOpencast 2.0.x branch. If you want to install another version, please change the name accordingly.\n\n\n\n\nNotice: Since the name \nmatterhorn\n was dropped between version 1.6 and 2.0, old packages were named\n\nopencast-matterhornXX\n.\n\n\n\n\nBasic Installation\n\n\nFor a basic installation (All-In-One) just run:\n\n\nsudo dnf install opencast20\n\n\n\nThis will install the default distribution of matterhorn and all its dependencies, including the 3rd-Party-Tools.\n\n\nNow you can start Opencast:\n\n\nsudo systemctl start matterhorn.service\n\n\n\nWhile Opencast is preconfigured, it is strongly recommended to follow at least the \nBasic Configuration\nguide\n. It will help you to set your hostname, login information, \u2026\n\n\nAdvanced Installation\n\n\nWhile the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might\nwant to have more control over your system and deploy it over several machines by choosing which parts of Opencast you\nwant to install. You can list all Opencast packages with:\n\n\ndnf search opencast\n\n\n\nThis will list four kinds of packages:\n\n\nopencastXX\n is the package that was used for the basic installation. It represents a default Opencast\ndistribution.  This is what you would get if you built Opencast from source and do not change any options.\n\n\nThe \nopencastXX-distribution-...\n packages will install preconfigured Opencast distributions. Have a look at\nthe Opencast Distribution section below for more information about the different distributions.\n\n\nopencastXX-profile-...\n are the Opencast profiles from the main pom.xml. Each profile keeps track of a\ncouple of modules.  You should only install these if you know what you are doing.\n\n\nopencastXX-module-...\n are the Opencast modules itself. It should only be necessary to install these\ndirectly in special cases.  And you should only do that if you know what you are doing.\n\n\nNormally you would either install the main package or a distribution package.\n\n\nPre-built Opencast Distributions\n\n\nThe following list provides an overview of the currently available pre-built Opencast distributions. Each distribution\nshould keep track of all its dependencies.\n\n\nAdmin Opencast distribution\n\n\nopencastXX-distribution-admin\n\n\nInstall this package for an Opencast admin server. On this server, the Administrative services are hosted. You would usually\nselect this package for one node if you are running Opencast across three or more servers.\n\n\nAdmin/Worker Opencast distribution\n\n\nopencastXX-distribution-admin-worker\n\n\nCombined Admin/Worker Opencast distribution. This will install both the modules and profiles for the Administrative\nTools and the Worker. This package is targeted at medium-sized installations, where you want to separate the \"backend\"\nserver that the admin accesses from the \"frontend\" server that the viewers use.\n\n\nDefault Opencast distribution\n\n\nopencastXX-distribution-default\n\n\nThis is the default package containing all 3 main profiles (Admin, Worker, Engage) in one. This installation is only\nrecommended if you do not have many videos that you want to ingest and you do not expect many viewers. This is perfect\nfor a first test and to get an impression of Opencast, as it works out of the box and does not need much configuration.\n\n\nEngage Opencast distribution\n\n\nopencastXX-distribution-engage\n\n\nThis is the package for the Opencast Engage Modules, which are the front-end to the viewer of your videos. It is always\nhighly recommended to keep these separated from the rest of your system.\n\n\nWorker Opencast distribution\n\n\nopencastXX-distribution-worker\n\n\nThis is the worker package that contains the modules that create the most CPU load (encoding, OCR, etc). So it is\nrecommended to deploy this on a more powerful machine.\n\n\nUninstall Opencast\n\n\nSometimes you want to uninstall Opencast. For example to do a clean reinstall. You can do that by executing:\n\n\nsudo dnf remove 'opencast*'\n\n\n\nThis will not touch your created media files or modified configuration files.  If you want to remove them as well, you\nhave to to that by yourself.\n\n\n# Remove media files\nsudo rm -rf /srv/matterhorn\n\n# Remove configuration files\nsudo rm -rf /etc/matterhorn\n\n# Remove system logfiles\nsudo rm -rf /var/log/matterhorn",
            "title": "RPM Fedora"
        },
        {
            "location": "/installation/rpm-fedora/#install-from-repository-fedora",
            "text": "There is an RPM software repository available for RedHat-based Linux distributions provided by the University of\nOsnabr\u00fcck. This repository provides preconfigured Opencast installations, including all 3rd-Party-Tools. Using this\nmethod, you do not have to compile the software by yourself.  It is also interesting for developers as all dependencies for Opencast usage, testing and development are provided by\nthe RPM repository.",
            "title": "Install from Repository (Fedora)"
        },
        {
            "location": "/installation/rpm-fedora/#supported-versions",
            "text": "For Fedora usually the latest two versions are supported, meaning that the support is dependent on the status of the\nFedora release. For architectures,  only   x86_64  is supported. 32bit architectures are  not  supported.",
            "title": "Supported Versions"
        },
        {
            "location": "/installation/rpm-fedora/#registration",
            "text": "Before you can start you need to get an account for the repository. You will need the credentials that you get by mail\nafter the registration to successfully complete this manual. The placeholders  [your_username]  and  [your_password] \nare used in this manual wherever the credentials are needed.   http://repo.virtuos.uos.de",
            "title": "Registration"
        },
        {
            "location": "/installation/rpm-fedora/#activate-repository",
            "text": "First you have to install the necessary repositories so that your package manager can access them:    Add matterhorn repository:  cd /etc/yum.repos.d\ncurl -O http://repo.virtuos.uos.de/matterhorn-testing.repo \\\n  -d 'version=$releasever' -d os=fc \\\n  -u [your_username]:[your_password]    Add RPMfusion repository:  dnf install --nogpgcheck \\\n  http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm \\\n  http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonf",
            "title": "Activate Repository"
        },
        {
            "location": "/installation/rpm-fedora/#install-3rd-party-tools",
            "text": "This step is optional and only recommended for those who want to build Opencast from source. If you install Opencast\nfrom the repository, all necessary dependencies will be installed automatically.  You can install all necessary 3rd-Party-Tools for matterhorn like this:  sudo dnf install opencast20-third-party-tools  Or manually:  sudo dnf install ffmpeg qt_sbtl_embedder tesseract mediainfo",
            "title": "Install 3rd-party-tools"
        },
        {
            "location": "/installation/rpm-fedora/#install-apache-activemq",
            "text": "The Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be\ninstalled on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the\nOpencast RPM repository as well and can be installed by running:  dnf install activemq-dist  A prepared configuration file for ActiveMQ can be found at  /usr/share/matterhorn/docs/scripts/activemq/activemq.xml  after Opencast itself has been installed  and should replace  /etc/activemq/activemq.xml . For an all-in-one\ninstallation the following command should suffice:  sudo cp /usr/share/matterhorn/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml  ActiveMQ should be started before starting Opencast.  More information about how to properly set up ActiveMQ for Opencast can be found in the  message broker configuration\ndocumentation .",
            "title": "Install Apache ActiveMQ"
        },
        {
            "location": "/installation/rpm-fedora/#install-opencast",
            "text": "For this guide,  opencast20  is used as placeholder for the package name. It will install the latest version of the\nOpencast 2.0.x branch. If you want to install another version, please change the name accordingly.   Notice: Since the name  matterhorn  was dropped between version 1.6 and 2.0, old packages were named opencast-matterhornXX .",
            "title": "Install Opencast"
        },
        {
            "location": "/installation/rpm-fedora/#basic-installation",
            "text": "For a basic installation (All-In-One) just run:  sudo dnf install opencast20  This will install the default distribution of matterhorn and all its dependencies, including the 3rd-Party-Tools.  Now you can start Opencast:  sudo systemctl start matterhorn.service  While Opencast is preconfigured, it is strongly recommended to follow at least the  Basic Configuration\nguide . It will help you to set your hostname, login information, \u2026",
            "title": "Basic Installation"
        },
        {
            "location": "/installation/rpm-fedora/#advanced-installation",
            "text": "While the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might\nwant to have more control over your system and deploy it over several machines by choosing which parts of Opencast you\nwant to install. You can list all Opencast packages with:  dnf search opencast  This will list four kinds of packages:  opencastXX  is the package that was used for the basic installation. It represents a default Opencast\ndistribution.  This is what you would get if you built Opencast from source and do not change any options.  The  opencastXX-distribution-...  packages will install preconfigured Opencast distributions. Have a look at\nthe Opencast Distribution section below for more information about the different distributions.  opencastXX-profile-...  are the Opencast profiles from the main pom.xml. Each profile keeps track of a\ncouple of modules.  You should only install these if you know what you are doing.  opencastXX-module-...  are the Opencast modules itself. It should only be necessary to install these\ndirectly in special cases.  And you should only do that if you know what you are doing.  Normally you would either install the main package or a distribution package.",
            "title": "Advanced Installation"
        },
        {
            "location": "/installation/rpm-fedora/#pre-built-opencast-distributions",
            "text": "The following list provides an overview of the currently available pre-built Opencast distributions. Each distribution\nshould keep track of all its dependencies.",
            "title": "Pre-built Opencast Distributions"
        },
        {
            "location": "/installation/rpm-fedora/#admin-opencast-distribution",
            "text": "opencastXX-distribution-admin  Install this package for an Opencast admin server. On this server, the Administrative services are hosted. You would usually\nselect this package for one node if you are running Opencast across three or more servers.",
            "title": "Admin Opencast distribution"
        },
        {
            "location": "/installation/rpm-fedora/#adminworker-opencast-distribution",
            "text": "opencastXX-distribution-admin-worker  Combined Admin/Worker Opencast distribution. This will install both the modules and profiles for the Administrative\nTools and the Worker. This package is targeted at medium-sized installations, where you want to separate the \"backend\"\nserver that the admin accesses from the \"frontend\" server that the viewers use.",
            "title": "Admin/Worker Opencast distribution"
        },
        {
            "location": "/installation/rpm-fedora/#default-opencast-distribution",
            "text": "opencastXX-distribution-default  This is the default package containing all 3 main profiles (Admin, Worker, Engage) in one. This installation is only\nrecommended if you do not have many videos that you want to ingest and you do not expect many viewers. This is perfect\nfor a first test and to get an impression of Opencast, as it works out of the box and does not need much configuration.",
            "title": "Default Opencast distribution"
        },
        {
            "location": "/installation/rpm-fedora/#engage-opencast-distribution",
            "text": "opencastXX-distribution-engage  This is the package for the Opencast Engage Modules, which are the front-end to the viewer of your videos. It is always\nhighly recommended to keep these separated from the rest of your system.",
            "title": "Engage Opencast distribution"
        },
        {
            "location": "/installation/rpm-fedora/#worker-opencast-distribution",
            "text": "opencastXX-distribution-worker  This is the worker package that contains the modules that create the most CPU load (encoding, OCR, etc). So it is\nrecommended to deploy this on a more powerful machine.",
            "title": "Worker Opencast distribution"
        },
        {
            "location": "/installation/rpm-fedora/#uninstall-opencast",
            "text": "Sometimes you want to uninstall Opencast. For example to do a clean reinstall. You can do that by executing:  sudo dnf remove 'opencast*'  This will not touch your created media files or modified configuration files.  If you want to remove them as well, you\nhave to to that by yourself.  # Remove media files\nsudo rm -rf /srv/matterhorn\n\n# Remove configuration files\nsudo rm -rf /etc/matterhorn\n\n# Remove system logfiles\nsudo rm -rf /var/log/matterhorn",
            "title": "Uninstall Opencast"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/",
            "text": "Install from Repository (RedHat Enterprise Linux, CentOS, Scientific Linux)\n\n\nThere is an RPM software repository available for RedHat-based Linux distributions provided by the University of\nOsnabr\u00fcck. This repository provides preconfigured Opencast installations, including all 3rd-Party-Tools. Using this\nmethod, you do not have to compile the software by yourself.\n\n\nIt is also interesting for developers as all dependencies for Opencast usage, testing and development are provided by\nthe RPM repository.\n\n\nCurrently supported are are\n\n\n\n\nCentOS 6.x, 7.x (x86_64)\n\n\nRedHat Enterprise Linux 6.x, 7.x (x86_64)\n\n\nScientific Linux 6.x, 7.x (x86_64)\n\n\n\n\n\n\nOther architectures like i386, i686, arm, \u2026 are not supported!\n\n\n\n\nRegistration\n\n\nBefore you can start you need to get an account for the repository. You will need the credentials that you get by mail\nafter the registration to successfully complete this manual. The placeholders \n[your_username]\n and \n[your_password]\n\nare used in this manual wherever the credentials are needed.\n\n\n\n\nhttp://repo.virtuos.uos.de\n\n\n\n\nActivate Repository\n\n\nFirst you have to install the necessary repositories so that your package manager can access them:\n\n\n\n\n\n\nAdd matterhorn repository:\n\n\ncd /etc/yum.repos.d\ncurl -O http://repo.virtuos.uos.de/matterhorn.repo \\\n   -d os=el -d version=6 \\\n   -u [YOUR_USERNAME]:[YOUR_PASSWORD]\n\n\nNote: For RHEL/CentOS/SL 7.x use \nversion=7\n\n\n\n\n\n\nAdd EPEL repository:\n\n\nsudo yum install epel-release\n\n\n\n\n\n\nInstall 3rd-party-tools\n\n\nThis step is optional and only recommended for those who want to build Opencast from source. If you install Opencast\nfrom the repository, all necessary dependencies will be installed automatically.\n\n\nYou can install all necessary 3rd-Party-Tools for matterhorn like this:\n\n\nsudo yum install opencast20-third-party-tools\n\n\n\nOr manually:\n\n\nsudo yum install ffmpeg qt_sbtl_embedder tesseract mediainfo\n\n\n\nInstall Apache ActiveMQ\n\n\nThe Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be\ninstalled on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the\nOpencast RPM repository as well and can be installed by running:\n\n\nyum install activemq-dist\n\n\n\nA prepared configuration file for ActiveMQ can be found at \n/usr/share/matterhorn/docs/scripts/activemq/activemq.xml\n\n\nafter Opencast itself has been installed\n and should replace \n/etc/activemq/activemq.xml\n. For an all-in-one\ninstallation the following command should suffice:\n\n\nsudo cp /usr/share/matterhorn/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml\n\n\n\nActiveMQ should be started before starting Opencast.\n\n\nMore information about how to properly set up ActiveMQ for Opencast can be found in the \nmessage broker configuration\ndocumentation\n.\n\n\nInstall Opencast\n\n\nFor this guide, \nopencast20\n is used as placeholder for the package name. It will install the latest version of the\nOpencast 2.0.x branch. If you want to install another version, please change the name accordingly.\n\n\n\n\nNotice: Since the name \nmatterhorn\n was dropped between version 1.6 and 2.0, old packages were named\n\nopencast-matterhornXX\n.\n\n\n\n\nBasic Installation\n\n\nFor a basic installation (All-In-One) just run:\n\n\nsudo yum install opencast20\n\n\n\nThis will install the default distribution of matterhorn and all its dependencies, including the 3rd-Party-Tools.\n\n\nNow you can start Opencast.\n\n\n\n\n\n\nOn a SysV-init based system\n\n\nsudo service matterhorn start\n\n\n\n\n\n\nOn a Systemd based system\n\n\nsudo systemctl start matterhorn.service\n\n\n\n\n\n\nWhile Opencast is preconfigured, it is strongly recommended to follow at least the \nBasic Configuration\nguide\n. It will help you to set your hostname, login information, \u2026\n\n\nAdvanced Installation\n\n\nWhile the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might\nwant to have more control over your system and deploy it over several machines by choosing which parts of Opencast you\nwant to install. You can list all Opencast packages with:\n\n\nyum search opencast\n\n\n\nThis will list four kinds of packages:\n\n\nopencastXX\n is the package that was used for the basic installation. It represents a default Opencast\ndistribution.  This is what you would get if you built Opencast from source and do not change any options.\n\n\nThe \nopencastXX-distribution-...\n packages will install preconfigured Opencast distributions. Have a look at\nthe Opencast Distribution section below for more information about the different distributions.\n\n\nopencastXX-profile-...\n are the Opencast profiles from the main pom.xml. Each profile keeps track of a\ncouple of modules.  You should only install these if you know what you are doing.\n\n\nopencastXX-module-...\n are the Opencast modules itself. It should only be necessary to install these\ndirectly in special cases.  And you should only do that if you know what you are doing.\n\n\nNormally you would either install the main package or a distribution package.\n\n\nPre-built Opencast Distributions\n\n\nThe following list provides an overview of the currently available pre-built Opencast distributions. Each distribution\nshould keep track of all its dependencies.\n\n\nAdmin Opencast distribution\n\n\nopencastXX-distribution-admin\n\n\nInstall this package for an Opencast admin server. On this server, the Administrative services are hosted. You would usually\nselect this package for one node if you are running Opencast across three or more servers.\n\n\nAdmin/Worker Opencast distribution\n\n\nopencastXX-distribution-admin-worker\n\n\nCombined Admin/Worker Opencast distribution. This will install both the modules and profiles for the Administrative\nTools and the Worker. This package is targeted at medium-sized installations, where you want to seperate the \"backend\"\nserver that the admin accesses from the \"frontend\" server that the viewers use.\n\n\nDefault Opencast distribution\n\n\nopencastXX-distribution-default\n\n\nThis is the default package containing all 3 main profiles (Admin, Worker, Engage) in one. This installation is only\nrecommended if you do not have many videos that you want to ingest and you do not expect many viewers. This is perfect\nfor a first test and to get an impression of Opencast, as it works out of the box and does not need much configuration.\n\n\nEngage Opencast distribution\n\n\nopencastXX-distribution-engage\n\n\nThis is the package for the Opencast Engage Modules, which are the front-end to the viewer of your videos. It is always\nhighly recommended to keep these separated from the rest of your system.\n\n\nWorker Opencast distribution\n\n\nopencastXX-distribution-worker\n\n\nThis is the worker package that contains the modules that create the most CPU load (encoding, OCR, etc). So it is\nrecommended to deploy this on a more powerful machine.\n\n\nUninstall Opencast\n\n\nSometimes you want to uninstall Opencast. For example to do a clean reinstall. You can do that by executing:\n\n\nsudo yum remove 'opencast*'\n\n\n\nThis will not touch your created media files or modified configuration files.  If you want to remove them as well, you\nhave to to that by yourself.\n\n\n# Remove media files\nsudo rm -rf /srv/matterhorn\n\n# Remove configuration files\nsudo rm -rf /etc/matterhorn\n\n# Remove system logfiles\nsudo rm -rf /var/log/matterhorn",
            "title": "RPM RHEL/CentOS"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#install-from-repository-redhat-enterprise-linux-centos-scientific-linux",
            "text": "There is an RPM software repository available for RedHat-based Linux distributions provided by the University of\nOsnabr\u00fcck. This repository provides preconfigured Opencast installations, including all 3rd-Party-Tools. Using this\nmethod, you do not have to compile the software by yourself.  It is also interesting for developers as all dependencies for Opencast usage, testing and development are provided by\nthe RPM repository.",
            "title": "Install from Repository (RedHat Enterprise Linux, CentOS, Scientific Linux)"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#currently-supported-are-are",
            "text": "CentOS 6.x, 7.x (x86_64)  RedHat Enterprise Linux 6.x, 7.x (x86_64)  Scientific Linux 6.x, 7.x (x86_64)    Other architectures like i386, i686, arm, \u2026 are not supported!",
            "title": "Currently supported are are"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#registration",
            "text": "Before you can start you need to get an account for the repository. You will need the credentials that you get by mail\nafter the registration to successfully complete this manual. The placeholders  [your_username]  and  [your_password] \nare used in this manual wherever the credentials are needed.   http://repo.virtuos.uos.de",
            "title": "Registration"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#activate-repository",
            "text": "First you have to install the necessary repositories so that your package manager can access them:    Add matterhorn repository:  cd /etc/yum.repos.d\ncurl -O http://repo.virtuos.uos.de/matterhorn.repo \\\n   -d os=el -d version=6 \\\n   -u [YOUR_USERNAME]:[YOUR_PASSWORD]  Note: For RHEL/CentOS/SL 7.x use  version=7    Add EPEL repository:  sudo yum install epel-release",
            "title": "Activate Repository"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#install-3rd-party-tools",
            "text": "This step is optional and only recommended for those who want to build Opencast from source. If you install Opencast\nfrom the repository, all necessary dependencies will be installed automatically.  You can install all necessary 3rd-Party-Tools for matterhorn like this:  sudo yum install opencast20-third-party-tools  Or manually:  sudo yum install ffmpeg qt_sbtl_embedder tesseract mediainfo",
            "title": "Install 3rd-party-tools"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#install-apache-activemq",
            "text": "The Apache ActiveMQ message broker is required by Opencast since version 2.0. It does not necessarily have to be\ninstalled on the same machine as Opencast but would commonly for an all-in-one system. ActiveMQ is available from the\nOpencast RPM repository as well and can be installed by running:  yum install activemq-dist  A prepared configuration file for ActiveMQ can be found at  /usr/share/matterhorn/docs/scripts/activemq/activemq.xml  after Opencast itself has been installed  and should replace  /etc/activemq/activemq.xml . For an all-in-one\ninstallation the following command should suffice:  sudo cp /usr/share/matterhorn/docs/scripts/activemq/activemq.xml /etc/activemq/activemq.xml  ActiveMQ should be started before starting Opencast.  More information about how to properly set up ActiveMQ for Opencast can be found in the  message broker configuration\ndocumentation .",
            "title": "Install Apache ActiveMQ"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#install-opencast",
            "text": "For this guide,  opencast20  is used as placeholder for the package name. It will install the latest version of the\nOpencast 2.0.x branch. If you want to install another version, please change the name accordingly.   Notice: Since the name  matterhorn  was dropped between version 1.6 and 2.0, old packages were named opencast-matterhornXX .",
            "title": "Install Opencast"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#basic-installation",
            "text": "For a basic installation (All-In-One) just run:  sudo yum install opencast20  This will install the default distribution of matterhorn and all its dependencies, including the 3rd-Party-Tools.  Now you can start Opencast.    On a SysV-init based system  sudo service matterhorn start    On a Systemd based system  sudo systemctl start matterhorn.service    While Opencast is preconfigured, it is strongly recommended to follow at least the  Basic Configuration\nguide . It will help you to set your hostname, login information, \u2026",
            "title": "Basic Installation"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#advanced-installation",
            "text": "While the basic installation will give you an all-in-one Opencast distribution which is nice for testing, you might\nwant to have more control over your system and deploy it over several machines by choosing which parts of Opencast you\nwant to install. You can list all Opencast packages with:  yum search opencast  This will list four kinds of packages:  opencastXX  is the package that was used for the basic installation. It represents a default Opencast\ndistribution.  This is what you would get if you built Opencast from source and do not change any options.  The  opencastXX-distribution-...  packages will install preconfigured Opencast distributions. Have a look at\nthe Opencast Distribution section below for more information about the different distributions.  opencastXX-profile-...  are the Opencast profiles from the main pom.xml. Each profile keeps track of a\ncouple of modules.  You should only install these if you know what you are doing.  opencastXX-module-...  are the Opencast modules itself. It should only be necessary to install these\ndirectly in special cases.  And you should only do that if you know what you are doing.  Normally you would either install the main package or a distribution package.",
            "title": "Advanced Installation"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#pre-built-opencast-distributions",
            "text": "The following list provides an overview of the currently available pre-built Opencast distributions. Each distribution\nshould keep track of all its dependencies.",
            "title": "Pre-built Opencast Distributions"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#admin-opencast-distribution",
            "text": "opencastXX-distribution-admin  Install this package for an Opencast admin server. On this server, the Administrative services are hosted. You would usually\nselect this package for one node if you are running Opencast across three or more servers.",
            "title": "Admin Opencast distribution"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#adminworker-opencast-distribution",
            "text": "opencastXX-distribution-admin-worker  Combined Admin/Worker Opencast distribution. This will install both the modules and profiles for the Administrative\nTools and the Worker. This package is targeted at medium-sized installations, where you want to seperate the \"backend\"\nserver that the admin accesses from the \"frontend\" server that the viewers use.",
            "title": "Admin/Worker Opencast distribution"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#default-opencast-distribution",
            "text": "opencastXX-distribution-default  This is the default package containing all 3 main profiles (Admin, Worker, Engage) in one. This installation is only\nrecommended if you do not have many videos that you want to ingest and you do not expect many viewers. This is perfect\nfor a first test and to get an impression of Opencast, as it works out of the box and does not need much configuration.",
            "title": "Default Opencast distribution"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#engage-opencast-distribution",
            "text": "opencastXX-distribution-engage  This is the package for the Opencast Engage Modules, which are the front-end to the viewer of your videos. It is always\nhighly recommended to keep these separated from the rest of your system.",
            "title": "Engage Opencast distribution"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#worker-opencast-distribution",
            "text": "opencastXX-distribution-worker  This is the worker package that contains the modules that create the most CPU load (encoding, OCR, etc). So it is\nrecommended to deploy this on a more powerful machine.",
            "title": "Worker Opencast distribution"
        },
        {
            "location": "/installation/rpm-rhel-sl-centos/#uninstall-opencast",
            "text": "Sometimes you want to uninstall Opencast. For example to do a clean reinstall. You can do that by executing:  sudo yum remove 'opencast*'  This will not touch your created media files or modified configuration files.  If you want to remove them as well, you\nhave to to that by yourself.  # Remove media files\nsudo rm -rf /srv/matterhorn\n\n# Remove configuration files\nsudo rm -rf /etc/matterhorn\n\n# Remove system logfiles\nsudo rm -rf /var/log/matterhorn",
            "title": "Uninstall Opencast"
        },
        {
            "location": "/installation/source-debian-ubuntu/",
            "text": "Install from Source (Debian, Ubuntu)\n\n\nThese instructions outline how to install an all in one Opencast system on Ubuntu 12.04 with LTS.\n\n\nPreparation\n\n\nCreate a dedicated Opencast user.\n\n\nuseradd -d /opt/matterhorn matterhorn\n\n\n\nGet Opencast source:\n\n\nYou can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git\nrepository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The\nprior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git.\n\n\nUsing the tarball:\n\n\nSelect the tarball for the version you want to install from\nhttps://bitbucket.org/opencast-community/matterhorn/downloads#tag-downloads\n\n\n# Download desired tarball\ncurl -O https://bitbucket.org/opencast-community/matterhorn/...\ntar xf develop.tar.gz\nmv opencast-community-matterhorn-* /opt/matterhorn/\n\n\n\nCloning the Git repository:\n\n\ngit clone https://bitbucket.org/opencast-community/matterhorn.git\ncd opencast\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version\n\n\n\nInstall Dependencies\n\n\nPlease make sure to install the following dependencies. Note that not all dependencies are in the system repositories.\n\n\nRequired:\n\n\nopenjdk-7-jdk or openjdk-8-jdk\nffmpeg >= 2.5\nmaven >= 3.1\n\n\n\n\n\nNote that by default Ubuntu and Debian ship Libav and installing the \nffmpeg\n package from the default repository\nwill not get you FFmpeg. If you are unsure about where to get FFmpeg, please refer to the \nFFmpeg\nwebsite\n.\n\n\n\n\nRequired (not necessarily on the same machine):\n\n\nActiveMQ >= 5.10 (older versions untested)\n\n\n\nRequired for text extraction (recommended):\n\n\ntesseract >= 3\n\n\n\nRequired for hunspell based text filtering (optional):\n\n\nhunspell >= 1.2.8\n\n\n\nRequired for audio normalization (optional):\n\n\nsox >= 14.4\n\n\n\nDependency Download\n\n\nPre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project\nwebsite:\n\n\n\n\nGet FFmpeg\n\n\n(Get Apache Maven\n\n\nGet Apache ActiveMQ\n\n\n\n\nBuilding Opencast\n\n\nMake sure everything belongs to the user \nmatterhorn\n (you may choose a different name):\n\n\nsudo chown -R matterhorn:matterhorn /opt/matterhorn\n\n\n\nSwitch to user \nmatterhorn\n:\n\n\nsudo su - matterhorn\n\n\n\nCompile the source code:\n\n\ncd /opt/matterhorn\nmvn clean install -DdeployTo=/opt/matterhorn\n\n\n\nConfigure\n\n\nPlease follow the steps of the \nBasic Configuration guide\n. It will help you to set your\nhostname, login information, \u2026\n\n\nRunning Opencast\n\n\nInstall Opencast start script and man-page for installations in \n/opt\n:\n\n\ncd /opt/matterhorn/docs/scripts/init/opt\nsudo ./install.sh\n\n\n\nThis will install the start script along with either a SysV-Init script or a\nsystemd unit file.\n\n\nNow you can start Opencast by running\n\n\nsudo matterhorn --interactive\n\n\n\nBrowse to [http://localhost:8080] to get to the admin interface.\n\n\nRun Opencast as Service\n\n\nUsually, you do not want to run Opencast in interactive mode but as system service to make sure Opencast is run only\nonce on a system and is started automatically.\n\n\nSysV-Init:\n\n\n# Start Opencast\nsudo service matterhorn start\n# Autostart after reboot\nsudo chkconfig --level 345 matterhorn on\n\n\n\nSystemd:\n\n\n# Start Opencast\nsudo systemctl start matterhorn\n# Autostart after reboot\nsudo systemctl enable matterhorn",
            "title": "Source Debian/Ubuntu"
        },
        {
            "location": "/installation/source-debian-ubuntu/#install-from-source-debian-ubuntu",
            "text": "These instructions outline how to install an all in one Opencast system on Ubuntu 12.04 with LTS.",
            "title": "Install from Source (Debian, Ubuntu)"
        },
        {
            "location": "/installation/source-debian-ubuntu/#preparation",
            "text": "Create a dedicated Opencast user.  useradd -d /opt/matterhorn matterhorn  Get Opencast source:  You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git\nrepository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The\nprior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git.  Using the tarball:  Select the tarball for the version you want to install from\nhttps://bitbucket.org/opencast-community/matterhorn/downloads#tag-downloads  # Download desired tarball\ncurl -O https://bitbucket.org/opencast-community/matterhorn/...\ntar xf develop.tar.gz\nmv opencast-community-matterhorn-* /opt/matterhorn/  Cloning the Git repository:  git clone https://bitbucket.org/opencast-community/matterhorn.git\ncd opencast\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version",
            "title": "Preparation"
        },
        {
            "location": "/installation/source-debian-ubuntu/#install-dependencies",
            "text": "Please make sure to install the following dependencies. Note that not all dependencies are in the system repositories.  Required:  openjdk-7-jdk or openjdk-8-jdk\nffmpeg >= 2.5\nmaven >= 3.1   Note that by default Ubuntu and Debian ship Libav and installing the  ffmpeg  package from the default repository\nwill not get you FFmpeg. If you are unsure about where to get FFmpeg, please refer to the  FFmpeg\nwebsite .   Required (not necessarily on the same machine):  ActiveMQ >= 5.10 (older versions untested)  Required for text extraction (recommended):  tesseract >= 3  Required for hunspell based text filtering (optional):  hunspell >= 1.2.8  Required for audio normalization (optional):  sox >= 14.4",
            "title": "Install Dependencies"
        },
        {
            "location": "/installation/source-debian-ubuntu/#dependency-download",
            "text": "Pre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project\nwebsite:   Get FFmpeg  (Get Apache Maven  Get Apache ActiveMQ",
            "title": "Dependency Download"
        },
        {
            "location": "/installation/source-debian-ubuntu/#building-opencast",
            "text": "Make sure everything belongs to the user  matterhorn  (you may choose a different name):  sudo chown -R matterhorn:matterhorn /opt/matterhorn  Switch to user  matterhorn :  sudo su - matterhorn  Compile the source code:  cd /opt/matterhorn\nmvn clean install -DdeployTo=/opt/matterhorn",
            "title": "Building Opencast"
        },
        {
            "location": "/installation/source-debian-ubuntu/#configure",
            "text": "Please follow the steps of the  Basic Configuration guide . It will help you to set your\nhostname, login information, \u2026",
            "title": "Configure"
        },
        {
            "location": "/installation/source-debian-ubuntu/#running-opencast",
            "text": "Install Opencast start script and man-page for installations in  /opt :  cd /opt/matterhorn/docs/scripts/init/opt\nsudo ./install.sh  This will install the start script along with either a SysV-Init script or a\nsystemd unit file.  Now you can start Opencast by running  sudo matterhorn --interactive  Browse to [http://localhost:8080] to get to the admin interface.",
            "title": "Running Opencast"
        },
        {
            "location": "/installation/source-debian-ubuntu/#run-opencast-as-service",
            "text": "Usually, you do not want to run Opencast in interactive mode but as system service to make sure Opencast is run only\nonce on a system and is started automatically.  SysV-Init:  # Start Opencast\nsudo service matterhorn start\n# Autostart after reboot\nsudo chkconfig --level 345 matterhorn on  Systemd:  # Start Opencast\nsudo systemctl start matterhorn\n# Autostart after reboot\nsudo systemctl enable matterhorn",
            "title": "Run Opencast as Service"
        },
        {
            "location": "/installation/source-rhel-sl-centos/",
            "text": "Install from Source (RedHat Enterprise Linux, CentOS, Scientific Linux, Fedora)\n\n\nPreparation\n\n\nCreate a dedicated Opencast user.\n\n\nuseradd -d /opt/matterhorn opencast\n\n\n\nGet Opencast source:\n\n\nYou can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git\nrepository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The\nprior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git.\n\n\nUsing the tarball:\n\n\nSelect the tarball for the version you want to install from\nhttps://bitbucket.org/opencast-community/matterhorn/downloads#tag-downloads\n\n\n# Download desired tarball\ncurl -O https://bitbucket.org/opencast-community/matterhorn/...\ntar xf develop.tar.gz\nmv opencast-community-matterhorn-* /opt/matterhorn/\n\n\n\nCloning the Git repository:\n\n\ngit clone https://bitbucket.org/opencast-community/matterhorn.git\ncd matterhorn\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version\n\n\n\nInstall Dependencies\n\n\nPlease make sure to install the following dependencies. Note that not all dependencies are in the system repositories.\n\n\nRequired:\n\n\njava-devel >= 1:1.7.0\nffmpeg >= 2.5\nmaven >= 3.1\n\n\n\nRequired (not necessarily on the same machine):\n\n\nActiveMQ >= 5.10 (older versions untested)\n\n\n\nRequired for text extraction (recommended):\n\n\ntesseract >= 3\n\n\n\nRequired for hunspell based text filtering (optional):\n\n\nhunspell >= 1.2.8\n\n\n\nRequired for audio normalization (optional):\n\n\nsox >= 14\n\n\n\nDependency Download\n\n\nPre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project\nwebsite:\n\n\n\n\nGet FFmpeg\n\n\n(Get Apache Maven\n\n\nGet Apache ActiveMQ\n\n\n\n\nBuilding Opencast\n\n\nMake sure everything belongs to the user \nmatterhorn\n:\n\n\nsudo chown -R opencast:opencast /opt/matterhorn\n\n\n\nSwitch to user \nopencast\n:\n\n\nsudo su - opencast\n\n\n\nCompile the source code:\n\n\ncd /opt/matterhorn\nmvn clean install -DdeployTo=/opt/matterhorn\n\n\n\nConfigure\n\n\nPlease follow the steps of the Basic Configuration guide. It will help you to set your hostname, login information, \u2026\n\n\nRunning Opencast\n\n\nInstall Opencast start script and man-page for installations in \n/opt\n:\n\n\ncd /opt/matterhorn/docs/scripts/init/opt\nsudo ./install.sh\n\n\n\nThis will install the start script along with either a SysV-Init script or a\nsystemd unit file.\n\n\nNow you can start Opencast by running\n\n\nsudo matterhorn --interactive\n\n\n\nBrowse to [http://localhost:8080] to get to the admin interface.\n\n\nRun Opencast as Service\n\n\nUsually, you do not want to run Opencast in interactive mode but as system service to make sure matterhorn is run only\nonce on a system and is started automatically.\n\n\nSysV-Init:\n\n\n# Start Opencast\nsudo service matterhorn start\n# Autostart after reboot\nsudo chkconfig --level 345 matterhorn on\n\n\n\nSystemd:\n\n\n# Start Opencast\nsudo systemctl start matterhorn\n# Autostart after reboot\nsudo systemctl enable matterhorn",
            "title": "Source RHEL/CentOS"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#install-from-source-redhat-enterprise-linux-centos-scientific-linux-fedora",
            "text": "",
            "title": "Install from Source (RedHat Enterprise Linux, CentOS, Scientific Linux, Fedora)"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#preparation",
            "text": "Create a dedicated Opencast user.  useradd -d /opt/matterhorn opencast  Get Opencast source:  You can get the Opencast source code by either downloading a tarball of the source code or by cloning the Git\nrepository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The\nprior option, the tarball download, needs less tools and you do not have to download nearly as much as with Git.  Using the tarball:  Select the tarball for the version you want to install from\nhttps://bitbucket.org/opencast-community/matterhorn/downloads#tag-downloads  # Download desired tarball\ncurl -O https://bitbucket.org/opencast-community/matterhorn/...\ntar xf develop.tar.gz\nmv opencast-community-matterhorn-* /opt/matterhorn/  Cloning the Git repository:  git clone https://bitbucket.org/opencast-community/matterhorn.git\ncd matterhorn\ngit tag   <-  List all available versions\ngit checkout TAG   <-  Switch to desired version",
            "title": "Preparation"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#install-dependencies",
            "text": "Please make sure to install the following dependencies. Note that not all dependencies are in the system repositories.  Required:  java-devel >= 1:1.7.0\nffmpeg >= 2.5\nmaven >= 3.1  Required (not necessarily on the same machine):  ActiveMQ >= 5.10 (older versions untested)  Required for text extraction (recommended):  tesseract >= 3  Required for hunspell based text filtering (optional):  hunspell >= 1.2.8  Required for audio normalization (optional):  sox >= 14",
            "title": "Install Dependencies"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#dependency-download",
            "text": "Pre-built versions of most dependencies that are not in the repositories can be downloaded from the respective project\nwebsite:   Get FFmpeg  (Get Apache Maven  Get Apache ActiveMQ",
            "title": "Dependency Download"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#building-opencast",
            "text": "Make sure everything belongs to the user  matterhorn :  sudo chown -R opencast:opencast /opt/matterhorn  Switch to user  opencast :  sudo su - opencast  Compile the source code:  cd /opt/matterhorn\nmvn clean install -DdeployTo=/opt/matterhorn",
            "title": "Building Opencast"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#configure",
            "text": "Please follow the steps of the Basic Configuration guide. It will help you to set your hostname, login information, \u2026",
            "title": "Configure"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#running-opencast",
            "text": "Install Opencast start script and man-page for installations in  /opt :  cd /opt/matterhorn/docs/scripts/init/opt\nsudo ./install.sh  This will install the start script along with either a SysV-Init script or a\nsystemd unit file.  Now you can start Opencast by running  sudo matterhorn --interactive  Browse to [http://localhost:8080] to get to the admin interface.",
            "title": "Running Opencast"
        },
        {
            "location": "/installation/source-rhel-sl-centos/#run-opencast-as-service",
            "text": "Usually, you do not want to run Opencast in interactive mode but as system service to make sure matterhorn is run only\nonce on a system and is started automatically.  SysV-Init:  # Start Opencast\nsudo service matterhorn start\n# Autostart after reboot\nsudo chkconfig --level 345 matterhorn on  Systemd:  # Start Opencast\nsudo systemctl start matterhorn\n# Autostart after reboot\nsudo systemctl enable matterhorn",
            "title": "Run Opencast as Service"
        },
        {
            "location": "/installation/source-macosx/",
            "text": "Install from Source (Mac OS X)\n\n\nThis document will help you install and run Matterhorn on the Mac OS X operating system.\nTested on OS X 10.9 Mavericks.\n\n\n\n\nThe installation on Mac OS X is not officially supported. Use this at your own risk.\n\n\n\n\nPreparation\n\n\nCreate Matterhorn installation directory\n\n\nsudo mkdir -p /opt/matterhorn\nsudo chown $USER:$GROUPS /opt/matterhorn\n\n\n\nCheck out Matterhorn source\n\n\nYou can get the Matterhorn source code by either downloading a tarball of the source code or by cloning the Git repository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The prior option, the tarball download, needs less tools and you don't have to download nearly as much as with Git.\n\n\nUsing the tarball:\n\n\nSelect the tarball for the version you want to install from\nhttps://bitbucket.org/opencast-community/matterhorn/downloads#tag-downloads\n\n\n# Download desired tarball\ncurl -O https://bitbucket.org/opencast-community/matterhorn/...\ntar xf develop.tar.gz\nmv opencast-community-matterhorn-* /opt/matterhorn/\n\n\n\nCloning the Git repository:\n\n\ncd /opt\ngit clone https://bitbucket.org/opencast-community/matterhorn.git\ncd opencast\ngit checkout r/2.0.x\n\n\n\nInstall Dependencies\n\n\nPlease make sure to install the following dependencies.\n\n\nRequired:\n\n\nXcode\njdk 7 or jdk 8\nffmpeg >= 2.5\nmaven >= 3.1\n\n\n\nRequired (not necessarily on the same machine):\n\n\nActiveMQ >= 5.10 (older versions untested)\n\n\n\nRequired for text extraction (recommended):\n\n\ntesseract >= 3\n\n\n\nRequired for hunspell based text filtering (optional):\n\n\nhunspell >= 1.2.8\n\n\n\nRequired for audio normalization (optional):\n\n\nsox >= 14.4\n\n\n\nDependency Download\n\n\nYou can download Xcode in the Mac App Store. JDK 8 for OS X is available from \nOracle\n.\n\n\nUsing Homebrew\n\n\nHomebrew is a package manager for OS X. For installation instruction see \ntheir website\n.\n\n\nbrew install maven\nbrew install ffmpeg\nbrew install apache-activemq\n# Optional\nbrew install tesseract\nbrew install hunspell\nbrew install sox\n\n\n\nUsing pre-built binaries\n\n\nPre-built versions of most dependencies can be downloaded from the respective project website:\n\n\n\n\nGet Apache Maven\n\n\nGet FFmpeg\n\n\nGet Apache ActiveMQ\n\n\n\n\nBuilding Opencast\n\n\nCompile the source code:\n\n\ncd /opt/matterhorn\nmvn clean install -DdeployTo=/opt/matterhorn\n\n\n\n\n\nPlease be patient, as building matterhorn for the first time will take quite long.\n\n\n\n\nConfigure\n\n\nPlease follow the steps of the \nBasic Configuration guide\n. It will help you to set your host name, login information, etc.\nAs specified in the guide, make sure you replace the default ActiveMQ configuration with the one provided in \ndocs/scripts/activemq/activemq.xml\n. If you installed ActiveMQ using homebrew, you can find the installation path with \nbrew info activemq\n.\n\n\nRunning Opencast\n\n\nMake sure you have ActiveMQ running (unless you're running it on a different machine). Then you can start Opencast using the start-matterhorn script.\n\n\nactivemq start\ncd /opt/matterhorn\nsudo ./bin/start-matterhorn",
            "title": "Source Mac OS X"
        },
        {
            "location": "/installation/source-macosx/#install-from-source-mac-os-x",
            "text": "This document will help you install and run Matterhorn on the Mac OS X operating system.\nTested on OS X 10.9 Mavericks.   The installation on Mac OS X is not officially supported. Use this at your own risk.",
            "title": "Install from Source (Mac OS X)"
        },
        {
            "location": "/installation/source-macosx/#preparation",
            "text": "",
            "title": "Preparation"
        },
        {
            "location": "/installation/source-macosx/#create-matterhorn-installation-directory",
            "text": "sudo mkdir -p /opt/matterhorn\nsudo chown $USER:$GROUPS /opt/matterhorn",
            "title": "Create Matterhorn installation directory"
        },
        {
            "location": "/installation/source-macosx/#check-out-matterhorn-source",
            "text": "You can get the Matterhorn source code by either downloading a tarball of the source code or by cloning the Git repository. The latter option is more flexible, it is easier to upgrade and in general preferred for developers. The prior option, the tarball download, needs less tools and you don't have to download nearly as much as with Git.  Using the tarball:  Select the tarball for the version you want to install from\nhttps://bitbucket.org/opencast-community/matterhorn/downloads#tag-downloads  # Download desired tarball\ncurl -O https://bitbucket.org/opencast-community/matterhorn/...\ntar xf develop.tar.gz\nmv opencast-community-matterhorn-* /opt/matterhorn/  Cloning the Git repository:  cd /opt\ngit clone https://bitbucket.org/opencast-community/matterhorn.git\ncd opencast\ngit checkout r/2.0.x",
            "title": "Check out Matterhorn source"
        },
        {
            "location": "/installation/source-macosx/#install-dependencies",
            "text": "Please make sure to install the following dependencies.  Required:  Xcode\njdk 7 or jdk 8\nffmpeg >= 2.5\nmaven >= 3.1  Required (not necessarily on the same machine):  ActiveMQ >= 5.10 (older versions untested)  Required for text extraction (recommended):  tesseract >= 3  Required for hunspell based text filtering (optional):  hunspell >= 1.2.8  Required for audio normalization (optional):  sox >= 14.4",
            "title": "Install Dependencies"
        },
        {
            "location": "/installation/source-macosx/#dependency-download",
            "text": "You can download Xcode in the Mac App Store. JDK 8 for OS X is available from  Oracle .",
            "title": "Dependency Download"
        },
        {
            "location": "/installation/source-macosx/#using-homebrew",
            "text": "Homebrew is a package manager for OS X. For installation instruction see  their website .  brew install maven\nbrew install ffmpeg\nbrew install apache-activemq\n# Optional\nbrew install tesseract\nbrew install hunspell\nbrew install sox",
            "title": "Using Homebrew"
        },
        {
            "location": "/installation/source-macosx/#using-pre-built-binaries",
            "text": "Pre-built versions of most dependencies can be downloaded from the respective project website:   Get Apache Maven  Get FFmpeg  Get Apache ActiveMQ",
            "title": "Using pre-built binaries"
        },
        {
            "location": "/installation/source-macosx/#building-opencast",
            "text": "Compile the source code:  cd /opt/matterhorn\nmvn clean install -DdeployTo=/opt/matterhorn   Please be patient, as building matterhorn for the first time will take quite long.",
            "title": "Building Opencast"
        },
        {
            "location": "/installation/source-macosx/#configure",
            "text": "Please follow the steps of the  Basic Configuration guide . It will help you to set your host name, login information, etc.\nAs specified in the guide, make sure you replace the default ActiveMQ configuration with the one provided in  docs/scripts/activemq/activemq.xml . If you installed ActiveMQ using homebrew, you can find the installation path with  brew info activemq .",
            "title": "Configure"
        },
        {
            "location": "/installation/source-macosx/#running-opencast",
            "text": "Make sure you have ActiveMQ running (unless you're running it on a different machine). Then you can start Opencast using the start-matterhorn script.  activemq start\ncd /opt/matterhorn\nsudo ./bin/start-matterhorn",
            "title": "Running Opencast"
        },
        {
            "location": "/configuration/",
            "text": "Matterhorn Configuration Guides\n\n\nThese guides will help you to configure Matterhorn. If you are a first-time user, please make sure to at lease have a\nlook at the \nbasic configuration guide\n.\n\n\nGeneral Configuration\n\n\n\n\nBasic Configuration\n\n\nDatabase Configuration\n\n\nEncoding Profile Configuration\n\n\nLogging and Privacy Configuration\n\n\nMessage Broker Configuration\n\n\nMulti Tenancy Configuration\n\n\nSecurity Configuration\n\n\nCAS Security Configuration\n\n\n\n\n\n\nWorkflow Configuration\n\n\nWorkflow Operation Handler\n\n\n\n\n\n\n\n\nAdditional Documentation\n\n\n\n\nList of Configuration Files and Keys",
            "title": "Configuration Home"
        },
        {
            "location": "/configuration/#matterhorn-configuration-guides",
            "text": "These guides will help you to configure Matterhorn. If you are a first-time user, please make sure to at lease have a\nlook at the  basic configuration guide .",
            "title": "Matterhorn Configuration Guides"
        },
        {
            "location": "/configuration/#general-configuration",
            "text": "Basic Configuration  Database Configuration  Encoding Profile Configuration  Logging and Privacy Configuration  Message Broker Configuration  Multi Tenancy Configuration  Security Configuration  CAS Security Configuration    Workflow Configuration  Workflow Operation Handler",
            "title": "General Configuration"
        },
        {
            "location": "/configuration/#additional-documentation",
            "text": "List of Configuration Files and Keys",
            "title": "Additional Documentation"
        },
        {
            "location": "/configuration/basic/",
            "text": "Basic Configuration\n\n\nThis guide will help you to change the basic configuration settings which are required or at least strongly recommended\nfor each Opencast installation. This is basically what you should do directly after you installed Opencast on your\nmachine.\n\n\nAll these settings are made in the \nconfig.properties\n file. It can be found directly in you Opencast configuration\ndirectory. In most cases, that should be either \n/etc/matterhorn/config.properties\n or\n\n/opt/matterhorn/etc/config.properties\n. Open this file using the editor of your choice, e.g.:\n\n\nvim /etc/matterhorn/config.properties\n\n\n\nStep 1: Setting the Server URL\n\n\nThe first thing you should do is to set the server URL. To do that, find the property org.opencastproject.server.url in\nyour config.properties configuration file. This key is set to http://localhost:8080 by default.  That will only allow\naccess from the local machine. You should change this if your server should be accessible within a network. Set it to\nyour domain name or IP address like:\n\n\norg.opencastproject.server.url=http://example.com:8080\n\n\n\nNote:\n This value will be written to all generated mediapackages and thus cannot be changed for already generated media\nafterwards. At least not without an extra amount of work involving modifications to the database. So think about this\nsetting for a minute.\n\n\nStep 2: Setting the Login Details\n\n\nThere are two authentication methods for Opencast. HTTP Digest authntication and form-based authentication. Both\nmethods need a username and a password. Change the password for both! The important keys for this are:\n\n\n\n\norg.opencastproject.security.admin.user\n: The user for the administrative account. This is set to \u201cadmin\u201d by\n   default. You should definitely change the credentials if your server is reachable from the internet.\n\n\norg.opencastproject.security.admin.pass\n: The password for the administrative account. This is set to \u201copencast\u201d by\n   default. You should definitely change the credentials if your server is reachable from the internet.\n\n\norg.opencastproject.security.digest.user\n: The user for the communication between Opencast nodes. This is set to\n   \u201cmatterhorn_system_account\u201d by default.\n\n\norg.opencastproject.security.digest.pass\n: The password for the communication between Opencast nodes. This is set\n   to \u201cCHANGE_ME\u201d by default.\n\n\n\n\nNote:\n The Digest credentials are also used for internal communication of Opencast servers. So these keys have to be\nset to the same value on each of you Matterhon nodes (Core, Worker, Capture Agent, \u2026)\n\n\nStep 3: Setting up Apache ActiveMQ Message Broker\n\n\nSince version 2.0, Opencast requires a running Apache ActiveMQ instance with specific configuration.  The message\nbroker is mostly run on the admin server of Opencast but can be run separately. It needs to be started before Opencast.\nFor more details about the setup, have a look at the \nApache ActiveMQ configuration guide\n.\n\n\nStep 4: Setting the Storage Directory (optional)\n\n\nEven though it is not important for all systems \u2013 on test setups you can probably omit this \u2013 you will often want to set\nthe storage directory. This directory is used to store all media, metadata, \u2026 Often, a NFS mount is used for this. You\ncan set the directory by changing org.opencastproject.storage.dir like:\n\n\norg.opencastproject.storage.dir=/media/mhdatamount\n\n\n\nStep 5: Database Configuration (optional)\n\n\nOpencast uses an integrated HSQL database by default. While you will find it perfectly functional, it is rather slow. So\nyou are highly encouraged to switch to a stand-alone database for productional use. For more information about database\nconfiguration, have a look at the \nDatabase Configuration section\n.",
            "title": "Basic"
        },
        {
            "location": "/configuration/basic/#basic-configuration",
            "text": "This guide will help you to change the basic configuration settings which are required or at least strongly recommended\nfor each Opencast installation. This is basically what you should do directly after you installed Opencast on your\nmachine.  All these settings are made in the  config.properties  file. It can be found directly in you Opencast configuration\ndirectory. In most cases, that should be either  /etc/matterhorn/config.properties  or /opt/matterhorn/etc/config.properties . Open this file using the editor of your choice, e.g.:  vim /etc/matterhorn/config.properties",
            "title": "Basic Configuration"
        },
        {
            "location": "/configuration/basic/#step-1-setting-the-server-url",
            "text": "The first thing you should do is to set the server URL. To do that, find the property org.opencastproject.server.url in\nyour config.properties configuration file. This key is set to http://localhost:8080 by default.  That will only allow\naccess from the local machine. You should change this if your server should be accessible within a network. Set it to\nyour domain name or IP address like:  org.opencastproject.server.url=http://example.com:8080  Note:  This value will be written to all generated mediapackages and thus cannot be changed for already generated media\nafterwards. At least not without an extra amount of work involving modifications to the database. So think about this\nsetting for a minute.",
            "title": "Step 1: Setting the Server URL"
        },
        {
            "location": "/configuration/basic/#step-2-setting-the-login-details",
            "text": "There are two authentication methods for Opencast. HTTP Digest authntication and form-based authentication. Both\nmethods need a username and a password. Change the password for both! The important keys for this are:   org.opencastproject.security.admin.user : The user for the administrative account. This is set to \u201cadmin\u201d by\n   default. You should definitely change the credentials if your server is reachable from the internet.  org.opencastproject.security.admin.pass : The password for the administrative account. This is set to \u201copencast\u201d by\n   default. You should definitely change the credentials if your server is reachable from the internet.  org.opencastproject.security.digest.user : The user for the communication between Opencast nodes. This is set to\n   \u201cmatterhorn_system_account\u201d by default.  org.opencastproject.security.digest.pass : The password for the communication between Opencast nodes. This is set\n   to \u201cCHANGE_ME\u201d by default.   Note:  The Digest credentials are also used for internal communication of Opencast servers. So these keys have to be\nset to the same value on each of you Matterhon nodes (Core, Worker, Capture Agent, \u2026)",
            "title": "Step 2: Setting the Login Details"
        },
        {
            "location": "/configuration/basic/#step-3-setting-up-apache-activemq-message-broker",
            "text": "Since version 2.0, Opencast requires a running Apache ActiveMQ instance with specific configuration.  The message\nbroker is mostly run on the admin server of Opencast but can be run separately. It needs to be started before Opencast.\nFor more details about the setup, have a look at the  Apache ActiveMQ configuration guide .",
            "title": "Step 3: Setting up Apache ActiveMQ Message Broker"
        },
        {
            "location": "/configuration/basic/#step-4-setting-the-storage-directory-optional",
            "text": "Even though it is not important for all systems \u2013 on test setups you can probably omit this \u2013 you will often want to set\nthe storage directory. This directory is used to store all media, metadata, \u2026 Often, a NFS mount is used for this. You\ncan set the directory by changing org.opencastproject.storage.dir like:  org.opencastproject.storage.dir=/media/mhdatamount",
            "title": "Step 4: Setting the Storage Directory (optional)"
        },
        {
            "location": "/configuration/basic/#step-5-database-configuration-optional",
            "text": "Opencast uses an integrated HSQL database by default. While you will find it perfectly functional, it is rather slow. So\nyou are highly encouraged to switch to a stand-alone database for productional use. For more information about database\nconfiguration, have a look at the  Database Configuration section .",
            "title": "Step 5: Database Configuration (optional)"
        },
        {
            "location": "/configuration/database/",
            "text": "Database Configuration\n\n\nMatterhorn ships with embedded JDBC drivers for the H2 (HSQL), MySQL/MariaDB databases. The built in H2\ndatabased is used by default and needs no configuration, but it is strongly recommended to use MySQL or MariaDB instead\nas there will be a huge performance gain, especially if more data are in that database.\n\n\nNotice:\n For a distributed set-up of Matterhorn, you cannot use the internal H2 database.\n\n\nOther databases\n\n\nRunning Matterhorn with PostgreSQL should be possible and there is some community support for this. While it should\nwork, the support for this is unofficial and we cannot guarantee that every new feature is well tested on that platform.\n\n\nThe EclipseLink JPA implementation which is used in Matterhorn supports other databases as well and it should be\npossible to attach other database engines.\n\n\nSetting up MySQL/MariaDB\n\n\nRequirements\n\n\nBefore following this guide you should have:\n\n\n\n\nInstalled the Matterhorn Core System\n\n\nFollowed the \nBasic Configuration instructions\n\n\n\n\nStep 0: Set-up MySQL/MariaDB\n\n\nThis step is not Matterhorn specific and may be different for your needs (e.g.  if you want to have a dedicated database\nserver). It shall only be a guide for people with no experience setting up MySQL/MariaDB and to help them get things\nrunning.\n\n\nNotice:\n If your distribution still shipps MySQL instead of MariaDB, the installation should still be very much the\nsame. Only the names will of course change.\n\n\nFirst you have to install the MariaDB server. Usually you would do that by using the package management tool of you\ndistribution. On RedHat based systems (CentOS, Scientific Linux, \u2026) this should be:\n\n\nyum install mariadb mariadb-server\n\n\n\nAfter the installation you can start the server and set it up to start automatically after each reboot with the\nfollowing commands:\n\n\n# If you are using Systemd\nsystemctl start mariadb.service\nsystemctl enable mariadb.service\n# If you are using SysV-Init\nservice mariadb start\nchkconfig --level 345 mariadb on\n\n\n\nNow you have a MariaDB server running, but without a properly set up root account (no password, etc.) which might pose a\nsecurity risk. To create this initial configuration, there is a convenient tool that comes which MariaDB and which will\nhelp. You can launch this tool by executing (yes, it is still called mysql_\u2026):\n\n\nmysql_secure_installation\n\n\n\nIt will guide you through the steps of setting up a root account with password, etc.\n\n\nStep 1: Create a Matterhorn Database\n\n\nThe first step, if you have not already done this, is obviously to create a database for Matterhorn. You can use the\nfollowing SQL code to to that. For executing the SQL, use the MySQL/MariaDB client (run the mysql program from your\nshell) or use a graphical tool like phpMyAdmin. For now, we will use the MySQL shell client and the default\nadministrative (root) user. Launch the client with:\n\n\nmysql -u root -p\n\n\n\nYou will be asked for the password of the user root. After entering it, you will end up in the MySQL/MariaDB shell.\nNext, create a database called \u201cmatterhorn\u201d by executing:\n\n\nCREATE DATABASE matterhorn CHARACTER SET utf8 COLLATE utf8_general_ci;\n\n\n\nThen create a user \u201cmatterhorn\u201d with the password \u201copencast_password\u201d and grant him all necessary rights:\n\n\nGRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP,INDEX ON matterhorn.*\n  TO 'matterhorn'@'localhost' IDENTIFIED BY 'opencast_password';\n\n\n\nNotice:\n Of cause you may use other names for user or database and should use a different password.\n\n\nOn Distributed Systems, additionally to 'username'@'localhost' which would allow access from the local machine only, for\na distributed system you would also create a user like 'username'@'10.0.1.%' and grant the necessary rights to this user\nas well. The '10.0.1.%' specifies the IP range which gets access to the server with '%' being a wildcard for anything.\nFor more details on MySQL user creation have a look at MySQL Reference Manual :: 6.3.2 Adding User Accounts.\n\n\nFinally, leave the MySQL/MariaDB client shell and restart the database server to enable the user with:\n\n\nservice mysqld restart\n\n\n\nor if you have a systemd based system:\n\n\nsystemctl restart mariadb.service\n\n\n\nStep 2: Set up the Database Structure\n\n\nTo set up the database structure you can (and should!) use the Matterhorn ddl scripts. You can find the script either at\n\n/usr/share/matterhorn/docs/scripts/ddl/mysql5.sql\n or download it from BitBucket.\n\n\nSwitch to the directory that contains the mysql5.sql file and run the MySQL/MariaDB client with the user you created in\nthe previous step (-u matterhorn) and switch to the database you want to use (matterhorn):\n\n\nmysql -u matterhorn -p matterhorn\n\n\n\nRun the ddl script:\n\n\nmysql> source mysql5.sql;\n\n\n\nInstead of using the MySQL/MariaDB Client, you can, of cause, also use every other method for executing SQL code like\nphpMyAdmin or MySQL-Workbench\u2026\n\n\nStep 3: Configure Matterhorn\n\n\nThe following settings are made in the \n<MH_CONFIG_DIR>/config.properties\n file (often\n\n/etc/matterhorn/config.properties\n). Use the editor of your choice to open it, e.g.:\n\n\nvim /etc/matterhorn/config.properties\n\n\n\nNow change the following configuration keys:\n\n\norg.opencastproject.db.ddl.generation=false\n\n\n\nIf set to true, the database structure will be generated automatically. It works, but all database optimizations are\nlost. You should never do this, unless you need it for development purposes.\n\n\norg.opencastproject.db.vendor=MySQL\n\n\n\nTell Matterhorn that you use MySQL. \n\n\norg.opencastproject.db.jdbc.driver=com.mysql.jdbc.Driver\n\n\n\nTell Matterhorn to use the JDBC driver for MySQL.\n\n\norg.opencastproject.db.jdbc.url=jdbc:mysql://localhost/matterhorn\n\n\n\nTell Matterhorn where to find the database and the name of the database. Replace \u201clocalhost\u201d and \u201cmatterhorn\u201d if necessary.\n\n\norg.opencastproject.db.jdbc.user=matterhorn\n\n\n\nTell Matterhorn which username to use for accessing the database. This user need to have the rights to read from and\nwrite to the database.\n\n\norg.opencastproject.db.jdbc.pass=opencast_password\n\n\n\nTell Matterhorn which password to use for accessing the database. This must obviously fit the username.",
            "title": "Database"
        },
        {
            "location": "/configuration/database/#database-configuration",
            "text": "Matterhorn ships with embedded JDBC drivers for the H2 (HSQL), MySQL/MariaDB databases. The built in H2\ndatabased is used by default and needs no configuration, but it is strongly recommended to use MySQL or MariaDB instead\nas there will be a huge performance gain, especially if more data are in that database.  Notice:  For a distributed set-up of Matterhorn, you cannot use the internal H2 database.",
            "title": "Database Configuration"
        },
        {
            "location": "/configuration/database/#other-databases",
            "text": "Running Matterhorn with PostgreSQL should be possible and there is some community support for this. While it should\nwork, the support for this is unofficial and we cannot guarantee that every new feature is well tested on that platform.  The EclipseLink JPA implementation which is used in Matterhorn supports other databases as well and it should be\npossible to attach other database engines.",
            "title": "Other databases"
        },
        {
            "location": "/configuration/database/#setting-up-mysqlmariadb",
            "text": "",
            "title": "Setting up MySQL/MariaDB"
        },
        {
            "location": "/configuration/database/#requirements",
            "text": "Before following this guide you should have:   Installed the Matterhorn Core System  Followed the  Basic Configuration instructions",
            "title": "Requirements"
        },
        {
            "location": "/configuration/database/#step-0-set-up-mysqlmariadb",
            "text": "This step is not Matterhorn specific and may be different for your needs (e.g.  if you want to have a dedicated database\nserver). It shall only be a guide for people with no experience setting up MySQL/MariaDB and to help them get things\nrunning.  Notice:  If your distribution still shipps MySQL instead of MariaDB, the installation should still be very much the\nsame. Only the names will of course change.  First you have to install the MariaDB server. Usually you would do that by using the package management tool of you\ndistribution. On RedHat based systems (CentOS, Scientific Linux, \u2026) this should be:  yum install mariadb mariadb-server  After the installation you can start the server and set it up to start automatically after each reboot with the\nfollowing commands:  # If you are using Systemd\nsystemctl start mariadb.service\nsystemctl enable mariadb.service\n# If you are using SysV-Init\nservice mariadb start\nchkconfig --level 345 mariadb on  Now you have a MariaDB server running, but without a properly set up root account (no password, etc.) which might pose a\nsecurity risk. To create this initial configuration, there is a convenient tool that comes which MariaDB and which will\nhelp. You can launch this tool by executing (yes, it is still called mysql_\u2026):  mysql_secure_installation  It will guide you through the steps of setting up a root account with password, etc.",
            "title": "Step 0: Set-up MySQL/MariaDB"
        },
        {
            "location": "/configuration/database/#step-1-create-a-matterhorn-database",
            "text": "The first step, if you have not already done this, is obviously to create a database for Matterhorn. You can use the\nfollowing SQL code to to that. For executing the SQL, use the MySQL/MariaDB client (run the mysql program from your\nshell) or use a graphical tool like phpMyAdmin. For now, we will use the MySQL shell client and the default\nadministrative (root) user. Launch the client with:  mysql -u root -p  You will be asked for the password of the user root. After entering it, you will end up in the MySQL/MariaDB shell.\nNext, create a database called \u201cmatterhorn\u201d by executing:  CREATE DATABASE matterhorn CHARACTER SET utf8 COLLATE utf8_general_ci;  Then create a user \u201cmatterhorn\u201d with the password \u201copencast_password\u201d and grant him all necessary rights:  GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP,INDEX ON matterhorn.*\n  TO 'matterhorn'@'localhost' IDENTIFIED BY 'opencast_password';  Notice:  Of cause you may use other names for user or database and should use a different password.  On Distributed Systems, additionally to 'username'@'localhost' which would allow access from the local machine only, for\na distributed system you would also create a user like 'username'@'10.0.1.%' and grant the necessary rights to this user\nas well. The '10.0.1.%' specifies the IP range which gets access to the server with '%' being a wildcard for anything.\nFor more details on MySQL user creation have a look at MySQL Reference Manual :: 6.3.2 Adding User Accounts.  Finally, leave the MySQL/MariaDB client shell and restart the database server to enable the user with:  service mysqld restart  or if you have a systemd based system:  systemctl restart mariadb.service",
            "title": "Step 1: Create a Matterhorn Database"
        },
        {
            "location": "/configuration/database/#step-2-set-up-the-database-structure",
            "text": "To set up the database structure you can (and should!) use the Matterhorn ddl scripts. You can find the script either at /usr/share/matterhorn/docs/scripts/ddl/mysql5.sql  or download it from BitBucket.  Switch to the directory that contains the mysql5.sql file and run the MySQL/MariaDB client with the user you created in\nthe previous step (-u matterhorn) and switch to the database you want to use (matterhorn):  mysql -u matterhorn -p matterhorn  Run the ddl script:  mysql> source mysql5.sql;  Instead of using the MySQL/MariaDB Client, you can, of cause, also use every other method for executing SQL code like\nphpMyAdmin or MySQL-Workbench\u2026",
            "title": "Step 2: Set up the Database Structure"
        },
        {
            "location": "/configuration/database/#step-3-configure-matterhorn",
            "text": "The following settings are made in the  <MH_CONFIG_DIR>/config.properties  file (often /etc/matterhorn/config.properties ). Use the editor of your choice to open it, e.g.:  vim /etc/matterhorn/config.properties  Now change the following configuration keys:  org.opencastproject.db.ddl.generation=false  If set to true, the database structure will be generated automatically. It works, but all database optimizations are\nlost. You should never do this, unless you need it for development purposes.  org.opencastproject.db.vendor=MySQL  Tell Matterhorn that you use MySQL.   org.opencastproject.db.jdbc.driver=com.mysql.jdbc.Driver  Tell Matterhorn to use the JDBC driver for MySQL.  org.opencastproject.db.jdbc.url=jdbc:mysql://localhost/matterhorn  Tell Matterhorn where to find the database and the name of the database. Replace \u201clocalhost\u201d and \u201cmatterhorn\u201d if necessary.  org.opencastproject.db.jdbc.user=matterhorn  Tell Matterhorn which username to use for accessing the database. This user need to have the rights to read from and\nwrite to the database.  org.opencastproject.db.jdbc.pass=opencast_password  Tell Matterhorn which password to use for accessing the database. This must obviously fit the username.",
            "title": "Step 3: Configure Matterhorn"
        },
        {
            "location": "/configuration/message-broker/",
            "text": "Message Broker Configuration\n\n\nSince version 2, Opencast Matterhorn requires an Apache ActiveMQ message broker as message relay for the administrative\nuser interface. ActiveMQ can either be set up to run on its own machine or on one of the existing Matterhorn nodes\n(usually the admin node).\n\n\nRequired Version\n\n\n\n\nActiveMQ 5.10 or above should work.\n\n\nActiveMQ 5.6 will not work.\n\n\nVersions in between are untested.\n\n\n\n\nInstallation\n\n\n\n\nIf you use the Matterhorn RPM repository, simply install the \nactivemq-dist\n package.\n\n\nIf you are running RHEL, CentOS or Fedora you can use the \nActiveMQ-dist Copr RPM repository\n   \n\n\nYou can download binary distributions from the \nApache ActiveMQ website\n\n\n\n\nConfiguration\n\n\nWhat you basically need to do:\n\n\n\n\nSet-up required message queues for Matterhorn\n\n\nPoint all your Matterhorn nodes to your message broker.\n\n\n\n\nThe first task is easy. Matterhorn comes with a ActiveMQ configuration file, located at\n\ndocs/scripts/activemq/activemq.xml\n (RPM repo: \n/usr/share/matterhorn/docs/scripts/activemq/activemq.xml\n). This file\nwill give you a basic configuration with all queues set-up and accepting connections from all hosts over TCP port\n61616.\nSimply replace the default ActiveMQ configuration, usually located at\n/etc/activemq/activemq.xml`, with this\nfile.\n\n\nThen configure the ActiveMQ connectvion in the \nconfig.properties\n. The default configuration points to a local\ninstallation of ActiveMQ, but that can be changed with:\n\n\nactivemq.broker.url = failover://tcp://example.opencast.org:61616\n\n\n\nSecurity\n\n\nActiveMQ can secure its message queues with user name and password access. This section will go through the steps of\nsetting up a configured username and password. On the \nActiveMQ security site\n\nthere are more details about using alternative authentication and authorization providers.\n\n\nCreate ActiveMQ Admin User\n\n\nFirst, you need to create a new user that will have access to the queues. This is configured in the \nusers.properties\n\nconfiguration file in the configuration directory for ActiveMQ. It is a list of the format \nusername = password\n so, for\nexample, we could create a new admin user with the following file contents:\n\n\nadmin=password\n\n\n\nCreate ActiveMQ Admin Group\n\n\nThe next step is to provide a group that will have our user in it and will secure access to the message queues. This is\nconfigured in the file \ngroups.properties\n in the configuration directory for ActiveMQ. It is a list of the format\n\ngroup = user1,user2,\u2026\n. For example:\n\n\ngroups=user1,user2,user3\n\n\n\nTo set-up our new user to be a part of the admins group:\n\n\nadmins=admin\n\n\n\nConfigure Users and Groups Configuration Files\n\n\nNext, we need to make sure that ActiveMQ is using our \nusers.properties\n and \ngroups.properties\n files to authenticate\nand authorize users. The \nlogin.config\n file should be in the ActivemQ configuration directory and contain:\n\n\nactivemq {\n    org.apache.activemq.jaas.PropertiesLoginModule required\n    org.apache.activemq.jaas.properties.user=\"users.properties\"\n    org.apache.activemq.jaas.properties.group=\"groups.properties\";\n};\n\n\n\nConfigure Message Broker Security\n\n\nThe final step to secure the ActiveMQ queues is to limit them with a group. This can be done by editing the\n\nactivemq.xml\n configuration file in the ActiveMQ configuration directory. Inside this configuration file, we need to\nadd some XML in between the tags:\n\n\n<broker></broker>\n\n\n\nWe will add the following plugin configuration:\n\n\n<plugins>\n    <jaasAuthenticationPlugin configuration=\"activemq\" />\n    <authorizationPlugin>\n        <map>\n            <authorizationMap>\n                <authorizationEntries>\n                    <authorizationEntry queue=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" />\n                    <authorizationEntry topic=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" />\n                    <authorizationEntry topic=\"ActiveMQ.Advisory.>\" read=\"admins\" write=\"admins\" admin=\"admins\"/>\n                </authorizationEntries>\n            </authorizationMap>\n        </map>\n    </authorizationPlugin>\n</plugins>\n\n\n\nThe \njaasAuthenticationPlugin\n configures the broker to use our \nlogin.config\n file to do the authentication.\n\n\n<jaasAuthenticationPlugin configuration=\"activemq\" />\n\n\n\nThe property:\n\n\nconfiguration=activemq\n\n\n\nneeds to match the name given for surrounding object in \nlogin.config\n i.e. activemq{};\n\n\nThe \nauthorizationEntry\n gives read, write and admin access to only those members in the group admins for queues and topics.\n\n\nConfigure Matterhorn to Connect with Username and Password to Message Broker\n\n\nNow that we have secured the queues, Opencast will complain that it is unable to connect, using the current username and\npassword. The username and password used above need to be added to the \nconfig.properties\n file of Opencast.  There are\ntwo properties to set:\n\n\nactivemq.broker.username=admin\nactivemq.broker.password=password\n\n\n\nFirewall\n\n\nDo not forget that ActiveMQ uses the TCP port 61616 (default configuration) for communication.  You probably want to\nallow communication over this port in your firewall on a distributed setup, or to explicitly forbid public access on an\nall-in-one installation.",
            "title": "Message Broker"
        },
        {
            "location": "/configuration/message-broker/#message-broker-configuration",
            "text": "Since version 2, Opencast Matterhorn requires an Apache ActiveMQ message broker as message relay for the administrative\nuser interface. ActiveMQ can either be set up to run on its own machine or on one of the existing Matterhorn nodes\n(usually the admin node).",
            "title": "Message Broker Configuration"
        },
        {
            "location": "/configuration/message-broker/#required-version",
            "text": "ActiveMQ 5.10 or above should work.  ActiveMQ 5.6 will not work.  Versions in between are untested.",
            "title": "Required Version"
        },
        {
            "location": "/configuration/message-broker/#installation",
            "text": "If you use the Matterhorn RPM repository, simply install the  activemq-dist  package.  If you are running RHEL, CentOS or Fedora you can use the  ActiveMQ-dist Copr RPM repository\n     You can download binary distributions from the  Apache ActiveMQ website",
            "title": "Installation"
        },
        {
            "location": "/configuration/message-broker/#configuration",
            "text": "What you basically need to do:   Set-up required message queues for Matterhorn  Point all your Matterhorn nodes to your message broker.   The first task is easy. Matterhorn comes with a ActiveMQ configuration file, located at docs/scripts/activemq/activemq.xml  (RPM repo:  /usr/share/matterhorn/docs/scripts/activemq/activemq.xml ). This file\nwill give you a basic configuration with all queues set-up and accepting connections from all hosts over TCP port\n61616. Simply replace the default ActiveMQ configuration, usually located at /etc/activemq/activemq.xml`, with this\nfile.  Then configure the ActiveMQ connectvion in the  config.properties . The default configuration points to a local\ninstallation of ActiveMQ, but that can be changed with:  activemq.broker.url = failover://tcp://example.opencast.org:61616",
            "title": "Configuration"
        },
        {
            "location": "/configuration/message-broker/#security",
            "text": "ActiveMQ can secure its message queues with user name and password access. This section will go through the steps of\nsetting up a configured username and password. On the  ActiveMQ security site \nthere are more details about using alternative authentication and authorization providers.",
            "title": "Security"
        },
        {
            "location": "/configuration/message-broker/#create-activemq-admin-user",
            "text": "First, you need to create a new user that will have access to the queues. This is configured in the  users.properties \nconfiguration file in the configuration directory for ActiveMQ. It is a list of the format  username = password  so, for\nexample, we could create a new admin user with the following file contents:  admin=password",
            "title": "Create ActiveMQ Admin User"
        },
        {
            "location": "/configuration/message-broker/#create-activemq-admin-group",
            "text": "The next step is to provide a group that will have our user in it and will secure access to the message queues. This is\nconfigured in the file  groups.properties  in the configuration directory for ActiveMQ. It is a list of the format group = user1,user2,\u2026 . For example:  groups=user1,user2,user3  To set-up our new user to be a part of the admins group:  admins=admin",
            "title": "Create ActiveMQ Admin Group"
        },
        {
            "location": "/configuration/message-broker/#configure-users-and-groups-configuration-files",
            "text": "Next, we need to make sure that ActiveMQ is using our  users.properties  and  groups.properties  files to authenticate\nand authorize users. The  login.config  file should be in the ActivemQ configuration directory and contain:  activemq {\n    org.apache.activemq.jaas.PropertiesLoginModule required\n    org.apache.activemq.jaas.properties.user=\"users.properties\"\n    org.apache.activemq.jaas.properties.group=\"groups.properties\";\n};",
            "title": "Configure Users and Groups Configuration Files"
        },
        {
            "location": "/configuration/message-broker/#configure-message-broker-security",
            "text": "The final step to secure the ActiveMQ queues is to limit them with a group. This can be done by editing the activemq.xml  configuration file in the ActiveMQ configuration directory. Inside this configuration file, we need to\nadd some XML in between the tags:  <broker></broker>  We will add the following plugin configuration:  <plugins>\n    <jaasAuthenticationPlugin configuration=\"activemq\" />\n    <authorizationPlugin>\n        <map>\n            <authorizationMap>\n                <authorizationEntries>\n                    <authorizationEntry queue=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" />\n                    <authorizationEntry topic=\">\" read=\"admins\" write=\"admins\" admin=\"admins\" />\n                    <authorizationEntry topic=\"ActiveMQ.Advisory.>\" read=\"admins\" write=\"admins\" admin=\"admins\"/>\n                </authorizationEntries>\n            </authorizationMap>\n        </map>\n    </authorizationPlugin>\n</plugins>  The  jaasAuthenticationPlugin  configures the broker to use our  login.config  file to do the authentication.  <jaasAuthenticationPlugin configuration=\"activemq\" />  The property:  configuration=activemq  needs to match the name given for surrounding object in  login.config  i.e. activemq{};  The  authorizationEntry  gives read, write and admin access to only those members in the group admins for queues and topics.",
            "title": "Configure Message Broker Security"
        },
        {
            "location": "/configuration/message-broker/#configure-matterhorn-to-connect-with-username-and-password-to-message-broker",
            "text": "Now that we have secured the queues, Opencast will complain that it is unable to connect, using the current username and\npassword. The username and password used above need to be added to the  config.properties  file of Opencast.  There are\ntwo properties to set:  activemq.broker.username=admin\nactivemq.broker.password=password",
            "title": "Configure Matterhorn to Connect with Username and Password to Message Broker"
        },
        {
            "location": "/configuration/message-broker/#firewall",
            "text": "Do not forget that ActiveMQ uses the TCP port 61616 (default configuration) for communication.  You probably want to\nallow communication over this port in your firewall on a distributed setup, or to explicitly forbid public access on an\nall-in-one installation.",
            "title": "Firewall"
        },
        {
            "location": "/configuration/encoding/",
            "text": "Encoding Profile Configuration\n\n\nA workflow defines which operations are applied to media ingested into Matterhorn and the order of these operations. An\noperation can be something general like \u201cencode this video\u201d. The encoding profiles then specify exactly how a media is\nancoded, which filters are applied, which codecs are used and in which container these will be stored, \u2026\n\n\nMatterhorn comes with a set of such profiles generating files for both online playback and download. These profiles are\nbuild to work for everyone, meaning that in most cases optimization can be done according to local needs. So modifying\nthese profiles or building new ones often makes sense. This document will help you modify or augment Matterhorn's\ndefault encoding profiles for audio, video and still images.\n\n\nDefault Profiles and Possible Settings\n\n\nThis section contains some notes about the default profiles, explaining some thoughts behind those profiles and pointing\nat things you might want to change depending on your local set-up.\n\n\nA/V-Muxing: From lossless to safe\n\n\nThe audio/video muxing (profile.mux-av.work) is applied if audio and video are send to Matterhorn separately. The basic\nidea behind this is, to combine these separate files into one file which can later be converted in one step.\n\n\nPossible settings:\n\n\n\n\nIf you get an audio and a video file separately, it is possivle to just copy the streams and put them together into a\n   new file. This is very fast (you only have to copy the streams) and most importantly, it is lossless, as no\n   re-encoding is done. The question is: What a/v container format can/should you use for such an operation.\n\n\nYou can try to use the video container the input video came in and just add the audio. This means that you will never\n   have an unexpected video container you don't know of. I.e. if you put an .mp4 video in, it still uses and .mp4\n   container after musing, etc. This might, however, lead to problems if you throw in an audio file that cannot be muxen\n   in the specific container format (i.e. you have a FLAC audio file and an FLV container). This is, what Matterhorn\n   does at the moment.\n\n\nTo circumvent the container problem, we could also use a container format which can hold almost everything (i.e. mkv)\n   regardless of the input. This would mean that MH can handle more combinations of a/v streams but you will always end\n   up with a Matroska file after muxing. Of cause you can then encode it to mp4, etc. later on.\n\n\n\n\nThe safest option for muxing is, of cause, to always re-encode the streams. It is far slower. It always means a quality\nloss. But it can handle everything FFmpeg can handle which (dependin on your FFmpeg configuration) is quite a lot.\n\n\nTrimming: Fast and lossless VS accurate\n\n\nThe profile trim.work is used after you send your recording to trim/hold and selected new start and end points. Here you\nhave basically two choices:\n\n\n\n\nAs you only want to cut the video, you don't have to re-encode all of it. You just split the stream and put it into a\n   new file. This is fast. This is lossless. But depending on the video format this might not be accurate. You can only\n   cut a stream at an I-frame (a frame holding the full image). Doing this, FFmpeg will cut the video at the nearest\n   I-frame before the selected position meaning that you might end up with a bit more video than you thought you would\n   get. You can minimize this by making sure that the input video has a high I-frame frequency (probably a good idea\n   anyway). This is what Matterhorn does at the moment.\n\n\nThe alternative is to cut between two I-frames. This is possible, but requires the video to be re-encoded completely.\n   This means that you will spend a lot of time on this process and will always loose quality.\n\n\n\n\nCreate an Encoding Profile\n\n\nThis section will help you to understand how you can modify an existing profile or create a completly new one.\n\n\nCreating a new encoding profile is a matter of creating a configuration file and placing it in the encoding profiles\nwatch folder.\n\n\nEncoding Profile Folder\n\n\nThe \n<config_dir>/encoding\n folder allows you to quickly augment Matterhorn's existing behavior, simply by modifying or\nadding new configuration files. The file names should follow the pattern \n*.properties\n.\n\n\nThe Encoding Profile\n\n\nEncoding profiles consist of a set of key-value pairs that conform to the following pattern:\n\n\nprofile.<name>.<context>.<property> = <value>\n\n\n\nFor example:\n\n\nprofile.flash.http.name = flash download\n\n\n\nAll profiles should have the following properties:\n\n\n.name\n.input  = [audio|visual|stream|image]\n.output = [audio|visual|stream|image]\n.suffix\n.mimetype\n.ffmpeg.command\n\n\n\nFor example:\n\n\n// My audio/video encoding profile\nprofile.my-av-profile.http.name           = my audio/video encoding profile\nprofile.my-av-profile.http.input          = visual\nprofile.my-av-profile.http.output         = visual\nprofile.my-av-profile.http.suffix         = -encoded.enc\nprofile.my-av-profile.http.mimetype       = video/x-enc\nprofile.my-av-profile.http.ffmpeg.command = -i #{in.video.path} -c:v videoencoder -c:a audioencoder #{out.dir}/#{out.name}#{out.suffix}\n\n\n\nThe most important part of this profile is the \nffmpeg.command\n. This line specifies FFmpeg command line options using\n\n#{expression}\n for string replacement.\n\n\nFFmpeg\n\n\nTo create a new profile you have basically one task to do: Find an appropriate FFmpeg command line for whatever you want\nto do. For more information about FFmpeg, its options and how you can build FFmpeg with additional functionality have a\nlook at the \nOfficial FFmpeg Wiki\n. For trying out new encoding settings, just call FFmpeg\nfrom the command line.\n\n\nUsing a Profile\n\n\nOnce defined, use your encoding profile in your workflow by setting the encoding-profile property to the profiles name:\n\n\n<operation\n    id=\"compose\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encode presenter using my audio/video encoding profile\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/work</configuration>\n    <configuration key=\"target-flavor\">presenter/delivery</configuration>\n    <configuration key=\"target-tags\">rss, atom, captioning</configuration>\n    <configuration key=\"encoding-profile\">my-av-profile.http</configuration>\n  </configuration>\n</operation>\n\n\n\nHave a look at the Workflow Configuration section for more details about this.",
            "title": "Encoding"
        },
        {
            "location": "/configuration/encoding/#encoding-profile-configuration",
            "text": "A workflow defines which operations are applied to media ingested into Matterhorn and the order of these operations. An\noperation can be something general like \u201cencode this video\u201d. The encoding profiles then specify exactly how a media is\nancoded, which filters are applied, which codecs are used and in which container these will be stored, \u2026  Matterhorn comes with a set of such profiles generating files for both online playback and download. These profiles are\nbuild to work for everyone, meaning that in most cases optimization can be done according to local needs. So modifying\nthese profiles or building new ones often makes sense. This document will help you modify or augment Matterhorn's\ndefault encoding profiles for audio, video and still images.",
            "title": "Encoding Profile Configuration"
        },
        {
            "location": "/configuration/encoding/#default-profiles-and-possible-settings",
            "text": "This section contains some notes about the default profiles, explaining some thoughts behind those profiles and pointing\nat things you might want to change depending on your local set-up.",
            "title": "Default Profiles and Possible Settings"
        },
        {
            "location": "/configuration/encoding/#av-muxing-from-lossless-to-safe",
            "text": "The audio/video muxing (profile.mux-av.work) is applied if audio and video are send to Matterhorn separately. The basic\nidea behind this is, to combine these separate files into one file which can later be converted in one step.  Possible settings:   If you get an audio and a video file separately, it is possivle to just copy the streams and put them together into a\n   new file. This is very fast (you only have to copy the streams) and most importantly, it is lossless, as no\n   re-encoding is done. The question is: What a/v container format can/should you use for such an operation.  You can try to use the video container the input video came in and just add the audio. This means that you will never\n   have an unexpected video container you don't know of. I.e. if you put an .mp4 video in, it still uses and .mp4\n   container after musing, etc. This might, however, lead to problems if you throw in an audio file that cannot be muxen\n   in the specific container format (i.e. you have a FLAC audio file and an FLV container). This is, what Matterhorn\n   does at the moment.  To circumvent the container problem, we could also use a container format which can hold almost everything (i.e. mkv)\n   regardless of the input. This would mean that MH can handle more combinations of a/v streams but you will always end\n   up with a Matroska file after muxing. Of cause you can then encode it to mp4, etc. later on.   The safest option for muxing is, of cause, to always re-encode the streams. It is far slower. It always means a quality\nloss. But it can handle everything FFmpeg can handle which (dependin on your FFmpeg configuration) is quite a lot.",
            "title": "A/V-Muxing: From lossless to safe"
        },
        {
            "location": "/configuration/encoding/#trimming-fast-and-lossless-vs-accurate",
            "text": "The profile trim.work is used after you send your recording to trim/hold and selected new start and end points. Here you\nhave basically two choices:   As you only want to cut the video, you don't have to re-encode all of it. You just split the stream and put it into a\n   new file. This is fast. This is lossless. But depending on the video format this might not be accurate. You can only\n   cut a stream at an I-frame (a frame holding the full image). Doing this, FFmpeg will cut the video at the nearest\n   I-frame before the selected position meaning that you might end up with a bit more video than you thought you would\n   get. You can minimize this by making sure that the input video has a high I-frame frequency (probably a good idea\n   anyway). This is what Matterhorn does at the moment.  The alternative is to cut between two I-frames. This is possible, but requires the video to be re-encoded completely.\n   This means that you will spend a lot of time on this process and will always loose quality.",
            "title": "Trimming: Fast and lossless VS accurate"
        },
        {
            "location": "/configuration/encoding/#create-an-encoding-profile",
            "text": "This section will help you to understand how you can modify an existing profile or create a completly new one.  Creating a new encoding profile is a matter of creating a configuration file and placing it in the encoding profiles\nwatch folder.",
            "title": "Create an Encoding Profile"
        },
        {
            "location": "/configuration/encoding/#encoding-profile-folder",
            "text": "The  <config_dir>/encoding  folder allows you to quickly augment Matterhorn's existing behavior, simply by modifying or\nadding new configuration files. The file names should follow the pattern  *.properties .",
            "title": "Encoding Profile Folder"
        },
        {
            "location": "/configuration/encoding/#the-encoding-profile",
            "text": "Encoding profiles consist of a set of key-value pairs that conform to the following pattern:  profile.<name>.<context>.<property> = <value>  For example:  profile.flash.http.name = flash download  All profiles should have the following properties:  .name\n.input  = [audio|visual|stream|image]\n.output = [audio|visual|stream|image]\n.suffix\n.mimetype\n.ffmpeg.command  For example:  // My audio/video encoding profile\nprofile.my-av-profile.http.name           = my audio/video encoding profile\nprofile.my-av-profile.http.input          = visual\nprofile.my-av-profile.http.output         = visual\nprofile.my-av-profile.http.suffix         = -encoded.enc\nprofile.my-av-profile.http.mimetype       = video/x-enc\nprofile.my-av-profile.http.ffmpeg.command = -i #{in.video.path} -c:v videoencoder -c:a audioencoder #{out.dir}/#{out.name}#{out.suffix}  The most important part of this profile is the  ffmpeg.command . This line specifies FFmpeg command line options using #{expression}  for string replacement.",
            "title": "The Encoding Profile"
        },
        {
            "location": "/configuration/encoding/#ffmpeg",
            "text": "To create a new profile you have basically one task to do: Find an appropriate FFmpeg command line for whatever you want\nto do. For more information about FFmpeg, its options and how you can build FFmpeg with additional functionality have a\nlook at the  Official FFmpeg Wiki . For trying out new encoding settings, just call FFmpeg\nfrom the command line.",
            "title": "FFmpeg"
        },
        {
            "location": "/configuration/encoding/#using-a-profile",
            "text": "Once defined, use your encoding profile in your workflow by setting the encoding-profile property to the profiles name:  <operation\n    id=\"compose\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encode presenter using my audio/video encoding profile\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/work</configuration>\n    <configuration key=\"target-flavor\">presenter/delivery</configuration>\n    <configuration key=\"target-tags\">rss, atom, captioning</configuration>\n    <configuration key=\"encoding-profile\">my-av-profile.http</configuration>\n  </configuration>\n</operation>  Have a look at the Workflow Configuration section for more details about this.",
            "title": "Using a Profile"
        },
        {
            "location": "/configuration/logging.and.privacy/",
            "text": "Logging and Privacy\n\n\nThe Matterhorn User-Tracking service stores actions of the users in the engage player within the database. This data is\nused for the footprint feature below the player and for the optional Analytics component.\n\n\nThe settings for logging can be changed in the file:\n\n\n${CONF_DIR}/services/org.opencastproject.usertracking.impl.UserTrackingServiceImpl.properties\n\n\n\nThe following options are available:\n\n\n\n\norg.opencastproject.usertracking.detailedtrack\n\n   Setting this key to true enables the user tracking javascript, setting it to false prevents the user tracking data\n   from being sent. With this set to false now logging will happen at all. The footprints are not available and\n   analytics will not work. Default is true.\n\n\norg.opencastproject.usertracking.log.ip\n\n   IP-addresses will no longer be logged if this is set to false. Turning this of is needed in some contries, especially\n   Germany, if you don't have a permission from the user to store this data. Footprints will still work with this\n   feature set to false! Default is true.\n\n\norg.opencastproject.usertracking.log.user\n\n   User login names will no longer be tracked if this is set to false. Turning this of is probably needed in most\n   countries, espacially if IP-logging is still active too. Footprints will still work if this is set to false! Default\n   is true.\n\n\norg.opencastproject.usertracking.log.session\n\n   Browser session-IDs will no longer be tracked is this is set to false. This is just for the completness to prevent\n   any user related data. So far there is no known reason to turn this of. Footprints will still work if this is set to\n   false!  Default is true.\n\n\n\n\nSo if you want to use the footprint features but don't want to store any user specific data you can turn the logging of\nIP, username and session-ID off, without any problems. Analytics will probably not work then.",
            "title": "Logging and Privacy"
        },
        {
            "location": "/configuration/logging.and.privacy/#logging-and-privacy",
            "text": "The Matterhorn User-Tracking service stores actions of the users in the engage player within the database. This data is\nused for the footprint feature below the player and for the optional Analytics component.  The settings for logging can be changed in the file:  ${CONF_DIR}/services/org.opencastproject.usertracking.impl.UserTrackingServiceImpl.properties  The following options are available:   org.opencastproject.usertracking.detailedtrack \n   Setting this key to true enables the user tracking javascript, setting it to false prevents the user tracking data\n   from being sent. With this set to false now logging will happen at all. The footprints are not available and\n   analytics will not work. Default is true.  org.opencastproject.usertracking.log.ip \n   IP-addresses will no longer be logged if this is set to false. Turning this of is needed in some contries, especially\n   Germany, if you don't have a permission from the user to store this data. Footprints will still work with this\n   feature set to false! Default is true.  org.opencastproject.usertracking.log.user \n   User login names will no longer be tracked if this is set to false. Turning this of is probably needed in most\n   countries, espacially if IP-logging is still active too. Footprints will still work if this is set to false! Default\n   is true.  org.opencastproject.usertracking.log.session \n   Browser session-IDs will no longer be tracked is this is set to false. This is just for the completness to prevent\n   any user related data. So far there is no known reason to turn this of. Footprints will still work if this is set to\n   false!  Default is true.   So if you want to use the footprint features but don't want to store any user specific data you can turn the logging of\nIP, username and session-ID off, without any problems. Analytics will probably not work then.",
            "title": "Logging and Privacy"
        },
        {
            "location": "/configuration/multi.tenancy/",
            "text": "Multi Tenancy Configuration\n\n\nIntroduction\n\n\nA single Matterhorn instance can handle mutliple tenants, each of which have their own recordings in the system.\nMatterhorn refers to tenants as \norganizations\n, and an HTTP request to the Matterhorn installation is mapped to an\norganization using the server name. Therefore, a Matterhorn instance will usually be set up with multiple DNS names\npointing to the same IP, for example:\n\n\n\n\ntenant1.matterhorn.edu\n\n\ntenant2.matterhorn.edu\n\n\n\n\nA tenant configuration thus consists mainly of the DNS name that is mapped to that tenant.\n\n\nDefault Setup\n\n\nOut of the box, Matterhorn has one tenant configured, called mh_default_org that is mapped to the server name\nlocalhost:8080. As long as there is one tenant configuration only, Matterhorn will map every request to that tenant\nregardless of the server name. As soon as a second tenant configuration is available, requests will be mapped to\norganizations using the server name, and a 404 will be returned for requests that hit the Matterhorn intallation that\ncannot be mapped to any organization.\n\n\nLimitations\n\n\nMulti tenancy in Matterhorn is working, however it is not fully finished. Certain objects are still shared amongst\norganizations, most notably workflow definitions, RSS/Atom feeds and encoding profiles.\n\n\nAdding A Tenant\n\n\nTo add a tenant to the installation, two things need to be put in place: a tenant configuration and a set of security\nrules. Assume that the new tenant is called \ntenant1\n and should be mapped to \ntenant1.myuniversity.edu\n.\n\n\nTenant Configuration\n\n\nCreate a file called org.opencastproject.organization-tenant1.cfg in the /load directory of your matterhorn\ninstallation:\n\n\nid=tenant1\nname=Tenant 1\nserver=tenant1.myuniversity.edu\nport=8080\nadmin_role=ROLE_ADMIN\nanonymous_role=ROLE_ANONYMOUS\n\n# Admin and Engage Server Urls\nprop.org.opencastproject.admin.ui.url=https://tenant1_admin.myuniversity.edu\nprop.org.opencastproject.engage.ui.url=https://tenant1_engage.myuniversity.edu\n\n# Default properties for the user interface\nprop.logo_mediamodule=/img/MatterhornLogo_large.png\nprop.logo_player=/img/OpencastLogo.png\n\n# Define which parts of the admin ui should be visible\nprop.adminui.i18n_tab_episode.enable=false\nprop.adminui.i18n_tab_users.enable=false\n\n# Define which parts of the engage ui should be visible\nprop.engageui.link_download.enable=false\nprop.engageui.link_download.enable=false\n\n\n\nNote that if you are running Apache httpd with mod_proxy in front of the Matterhorn installation, the port number will be -1.\n\n\nSecurity Configuration\n\n\nCreate a file called tenant1.xml in /etc/security. This file specifies access rules for individual urls that specify\nwhich roles are needed in order to access a given url. In addition, it allows to define the directory services that are\nused to authenticate users. The file follows the standard ways on configuring Spring Security and you are free to add\nanything that can go into a Spring Security configuration.\n\n\nThe easiest way of creating that file is probably to create a copy of the already existing mh_default_org.xml.",
            "title": "Multi Tenancy"
        },
        {
            "location": "/configuration/multi.tenancy/#multi-tenancy-configuration",
            "text": "",
            "title": "Multi Tenancy Configuration"
        },
        {
            "location": "/configuration/multi.tenancy/#introduction",
            "text": "A single Matterhorn instance can handle mutliple tenants, each of which have their own recordings in the system.\nMatterhorn refers to tenants as  organizations , and an HTTP request to the Matterhorn installation is mapped to an\norganization using the server name. Therefore, a Matterhorn instance will usually be set up with multiple DNS names\npointing to the same IP, for example:   tenant1.matterhorn.edu  tenant2.matterhorn.edu   A tenant configuration thus consists mainly of the DNS name that is mapped to that tenant.",
            "title": "Introduction"
        },
        {
            "location": "/configuration/multi.tenancy/#default-setup",
            "text": "Out of the box, Matterhorn has one tenant configured, called mh_default_org that is mapped to the server name\nlocalhost:8080. As long as there is one tenant configuration only, Matterhorn will map every request to that tenant\nregardless of the server name. As soon as a second tenant configuration is available, requests will be mapped to\norganizations using the server name, and a 404 will be returned for requests that hit the Matterhorn intallation that\ncannot be mapped to any organization.",
            "title": "Default Setup"
        },
        {
            "location": "/configuration/multi.tenancy/#limitations",
            "text": "Multi tenancy in Matterhorn is working, however it is not fully finished. Certain objects are still shared amongst\norganizations, most notably workflow definitions, RSS/Atom feeds and encoding profiles.",
            "title": "Limitations"
        },
        {
            "location": "/configuration/multi.tenancy/#adding-a-tenant",
            "text": "To add a tenant to the installation, two things need to be put in place: a tenant configuration and a set of security\nrules. Assume that the new tenant is called  tenant1  and should be mapped to  tenant1.myuniversity.edu .",
            "title": "Adding A Tenant"
        },
        {
            "location": "/configuration/multi.tenancy/#tenant-configuration",
            "text": "Create a file called org.opencastproject.organization-tenant1.cfg in the /load directory of your matterhorn\ninstallation:  id=tenant1\nname=Tenant 1\nserver=tenant1.myuniversity.edu\nport=8080\nadmin_role=ROLE_ADMIN\nanonymous_role=ROLE_ANONYMOUS\n\n# Admin and Engage Server Urls\nprop.org.opencastproject.admin.ui.url=https://tenant1_admin.myuniversity.edu\nprop.org.opencastproject.engage.ui.url=https://tenant1_engage.myuniversity.edu\n\n# Default properties for the user interface\nprop.logo_mediamodule=/img/MatterhornLogo_large.png\nprop.logo_player=/img/OpencastLogo.png\n\n# Define which parts of the admin ui should be visible\nprop.adminui.i18n_tab_episode.enable=false\nprop.adminui.i18n_tab_users.enable=false\n\n# Define which parts of the engage ui should be visible\nprop.engageui.link_download.enable=false\nprop.engageui.link_download.enable=false  Note that if you are running Apache httpd with mod_proxy in front of the Matterhorn installation, the port number will be -1.",
            "title": "Tenant Configuration"
        },
        {
            "location": "/configuration/multi.tenancy/#security-configuration",
            "text": "Create a file called tenant1.xml in /etc/security. This file specifies access rules for individual urls that specify\nwhich roles are needed in order to access a given url. In addition, it allows to define the directory services that are\nused to authenticate users. The file follows the standard ways on configuring Spring Security and you are free to add\nanything that can go into a Spring Security configuration.  The easiest way of creating that file is probably to create a copy of the already existing mh_default_org.xml.",
            "title": "Security Configuration"
        },
        {
            "location": "/configuration/security/",
            "text": "Security Configuration\n\n\nThis document will help you configure the Matterhorn security policy.\n\n\nIntroduction\n\n\nMatterhorn service endpoints and user interfaces are secured by default using a set of servlet filters. The following\ndiagram illustrates the flow of an HTTP request and response through these filters.\n\n\n\n\nThe Spring Security filters used here are very powerful, but are also somewhat complicated. Please familiarize yourself\nwith the basic concepts and vocabulary described in the Spring Security documentation, then edit the xml files in\n\netc/security\n, as described below.\n\n\nConfigure Access\n\n\nTo configure access roles and URL patterns for a tenant, modify \n/etc/security/{{tenant_identifier.xml}}\n.  If you are\nnot hosting multiple tenants on your Matterhorn server or cluster, all configuration should be done in\n\nmh_default_org.xml\n.\n\n\nSome examples:\n\n\n<!-- Allow anonymous access to the welcome.html URLs -->\n<sec:intercept-url pattern='/welcome.html' access='ROLE_ANONYMOUS,ROLE_USER'/>\n\n<!-- Allow anonymous GET to the search service, but not POST or PUT -->\n<sec:intercept-url pattern='/search/**' method=\"GET\" access='ROLE_ANONYMOUS,ROLE_USER' />\n\n<!-- Allow users with the admin role to do anything -->\n<sec:intercept-url pattern='/**' access='ROLE_ADMIN'/>\n\n\n\nAuthentication Provider\n\n\nMatterhorn specifies an AuthenticationProvider by default, using a UserDetailService that is obtained from the OSGI service registry.\n\n\nYou can use this simple provider as is, loading users into the mh_user and mh_role database tables, and specifying an\nadministrative username and password in config.properties:\n\n\norg.opencastproject.security.digest.user=matterhorn_system_account\norg.opencastproject.security.digest.pass=CHANGE_ME\n\n\n\nThe set of user and role providers can be configured. If you do not want to keep users and passwords in Matterhorn's\ndatabase, you can replace the JpaUserAndRoleProvider with the LdapUserProvider by replacing the\nmatterhorn-userdirectory-jpa jar with the matterhorn-userdirectory-ldap jar.\n\n\nAdding Users to the Matterhorn Database\n\n\nAdditional users can be created by adding a username, organization and password hash to the mh_user table in the\nMatterhorn database. The default hash method is MD5 and the password must be salted with the username in curly braces.\n\n\nAt the moment, there is no graphical user interface for this task. It has to be done in the database.\n\n\nExample: Adding Garfield with the password 'monday' (in MySQL)\n\n\nINSERT INTO `matterhorn`.`mh_user` (`username`, `organization`, `password`) VALUES ('garfield', 'mh_default_org', MD5('monday{garfield}'));\n\n\n\nIn the next step roles for the newly created user can be added to the mh_role table. After that the created user and\nrole id can be added to the mh_user_role table. Here we set ROLE_USER for Garfield:\n\n\nINSERT INTO `matterhorn`.`mh_role` (`organization`, `name`, `description`) VALUES ('mh_default_org', 'ROLE_USER', 'The user role');\nINSERT INTO `matterhorn`.`mh_user_role` (`user_id`, `role_id`) VALUES ('220', '221');\n\n\n\n Note that you must set the value of the organization field to the organization ID specified in one of the\netc/load/org.opencast.organization-\n.cfg files. In a default installation this is 'mh_default_org'.\n\n\nFurther Authentication Configuration\n\n\nConfigure Central Authentication Service (CAS)",
            "title": "Security"
        },
        {
            "location": "/configuration/security/#security-configuration",
            "text": "This document will help you configure the Matterhorn security policy.",
            "title": "Security Configuration"
        },
        {
            "location": "/configuration/security/#introduction",
            "text": "Matterhorn service endpoints and user interfaces are secured by default using a set of servlet filters. The following\ndiagram illustrates the flow of an HTTP request and response through these filters.   The Spring Security filters used here are very powerful, but are also somewhat complicated. Please familiarize yourself\nwith the basic concepts and vocabulary described in the Spring Security documentation, then edit the xml files in etc/security , as described below.",
            "title": "Introduction"
        },
        {
            "location": "/configuration/security/#configure-access",
            "text": "To configure access roles and URL patterns for a tenant, modify  /etc/security/{{tenant_identifier.xml}} .  If you are\nnot hosting multiple tenants on your Matterhorn server or cluster, all configuration should be done in mh_default_org.xml .  Some examples:  <!-- Allow anonymous access to the welcome.html URLs -->\n<sec:intercept-url pattern='/welcome.html' access='ROLE_ANONYMOUS,ROLE_USER'/>\n\n<!-- Allow anonymous GET to the search service, but not POST or PUT -->\n<sec:intercept-url pattern='/search/**' method=\"GET\" access='ROLE_ANONYMOUS,ROLE_USER' />\n\n<!-- Allow users with the admin role to do anything -->\n<sec:intercept-url pattern='/**' access='ROLE_ADMIN'/>",
            "title": "Configure Access"
        },
        {
            "location": "/configuration/security/#authentication-provider",
            "text": "Matterhorn specifies an AuthenticationProvider by default, using a UserDetailService that is obtained from the OSGI service registry.  You can use this simple provider as is, loading users into the mh_user and mh_role database tables, and specifying an\nadministrative username and password in config.properties:  org.opencastproject.security.digest.user=matterhorn_system_account\norg.opencastproject.security.digest.pass=CHANGE_ME  The set of user and role providers can be configured. If you do not want to keep users and passwords in Matterhorn's\ndatabase, you can replace the JpaUserAndRoleProvider with the LdapUserProvider by replacing the\nmatterhorn-userdirectory-jpa jar with the matterhorn-userdirectory-ldap jar.",
            "title": "Authentication Provider"
        },
        {
            "location": "/configuration/security/#adding-users-to-the-matterhorn-database",
            "text": "Additional users can be created by adding a username, organization and password hash to the mh_user table in the\nMatterhorn database. The default hash method is MD5 and the password must be salted with the username in curly braces.  At the moment, there is no graphical user interface for this task. It has to be done in the database.  Example: Adding Garfield with the password 'monday' (in MySQL)  INSERT INTO `matterhorn`.`mh_user` (`username`, `organization`, `password`) VALUES ('garfield', 'mh_default_org', MD5('monday{garfield}'));  In the next step roles for the newly created user can be added to the mh_role table. After that the created user and\nrole id can be added to the mh_user_role table. Here we set ROLE_USER for Garfield:  INSERT INTO `matterhorn`.`mh_role` (`organization`, `name`, `description`) VALUES ('mh_default_org', 'ROLE_USER', 'The user role');\nINSERT INTO `matterhorn`.`mh_user_role` (`user_id`, `role_id`) VALUES ('220', '221');   Note that you must set the value of the organization field to the organization ID specified in one of the\netc/load/org.opencast.organization- .cfg files. In a default installation this is 'mh_default_org'.",
            "title": "Adding Users to the Matterhorn Database"
        },
        {
            "location": "/configuration/security/#further-authentication-configuration",
            "text": "Configure Central Authentication Service (CAS)",
            "title": "Further Authentication Configuration"
        },
        {
            "location": "/configuration/security.cas/",
            "text": "Configure Central Authentication Service (CAS)\n\n\nCAS\n\n\nMany campuses use some kind of single sign on, such as JASIG's Central Authentication Service, or CAS. This guide describes how to integrate Matterhorn into such a system.\n\n\nStep 1\n\n\nAt first uncomment Lines for OpenId and CAS in system.properties as described in the same file:\n\n\nfile:${felix.home}/lib/ext/cas-client-core-3.1.12.jar \\\nfile:${felix.home}/lib/ext/com.springsource.org.apache.xml.security-1.4.2.jar \\\nfile:${felix.home}/lib/ext/com.springsource.org.opensaml-1.1.0.jar \\\nfile:${felix.home}/lib/ext/spring-security-cas-3.1.0.RELEASE.jar \\\nfile:${felix.home}/lib/ext/com.springsource.org.jasig.cas.client-3.1.12.jar \\\nfile:${felix.home}/lib/ext/com.springsource.org.openid4java-0.9.5.jar \\\nfile:${felix.home}/lib/ext/spring-security-openid-3.1.0.RELEASE.jar\n\n\n\nStep 2\n\n\nTo configure matterhorn to use CAS, simply replace the default mh_default_org.xml with the contents of security_sample_cas.xml, available in the Matterhorn source. You must modify several settings in the sample to point to your CAS server:\n\n\n<bean id=\"casEntryPoint\" class=\"org.springframework.security.cas.web.CasAuthenticationEntryPoint\">\n  <property name=\"loginUrl\" value=\"https://auth-test.berkeley.edu/cas/login\"/>\n  <property name=\"serviceProperties\" ref=\"serviceProperties\"/>\n</bean>\n\n<bean id=\"casAuthenticationProvider\" class=\"org.springframework.security.cas.authentication.CasAuthenticationProvider\">\n  <property name=\"userDetailsService\" ref=\"userDetailsService\"/>\n  <property name=\"serviceProperties\" ref=\"serviceProperties\" />\n  <property name=\"ticketValidator\">\n    <bean class=\"org.jasig.cas.client.validation.Cas20ServiceTicketValidator\">\n      <constructor-arg index=\"0\" value=\"https://auth-test.berkeley.edu/cas\" />\n    </bean>\n  </property>\n  <property name=\"key\" value=\"cas\"/>\n</bean>\n\n\n\nYou will also need to set the public URL for your Matterhorn server:\n\n\n<bean id=\"serviceProperties\" class=\"org.springframework.security.cas.ServiceProperties\">\n  <property name=\"service\" value=\"http://localhost:8080/j_spring_cas_security_check\"/>\n  <property name=\"sendRenew\" value=\"false\"/>\n</bean>\n\n\n\nStep 3\n\n\nAssuming you are using matterhorn version 1.4 and are using LDAP for user provisioning, you will need to build and deploy relevant modules with:\n\n\nmvn clean install -Pdirectory-ldap,directory-cas,directory-openid -DdeployTo={your runtime server location here}\n\n\n\nIf not using LDAP, of course, you don't need the directory-ldap module but CAS alone will require deploying both the directory-cas and directory-openid modules.\n\n\nStep 4\n\n\nFinally, you will need to configure a UserProvider to look up users as identified by CAS, for example see:\n\n\nUniversity of Saskatchewan CAS and LDAP integration",
            "title": "Security - CAS"
        },
        {
            "location": "/configuration/security.cas/#configure-central-authentication-service-cas",
            "text": "",
            "title": "Configure Central Authentication Service (CAS)"
        },
        {
            "location": "/configuration/security.cas/#cas",
            "text": "Many campuses use some kind of single sign on, such as JASIG's Central Authentication Service, or CAS. This guide describes how to integrate Matterhorn into such a system.",
            "title": "CAS"
        },
        {
            "location": "/configuration/security.cas/#step-1",
            "text": "At first uncomment Lines for OpenId and CAS in system.properties as described in the same file:  file:${felix.home}/lib/ext/cas-client-core-3.1.12.jar \\\nfile:${felix.home}/lib/ext/com.springsource.org.apache.xml.security-1.4.2.jar \\\nfile:${felix.home}/lib/ext/com.springsource.org.opensaml-1.1.0.jar \\\nfile:${felix.home}/lib/ext/spring-security-cas-3.1.0.RELEASE.jar \\\nfile:${felix.home}/lib/ext/com.springsource.org.jasig.cas.client-3.1.12.jar \\\nfile:${felix.home}/lib/ext/com.springsource.org.openid4java-0.9.5.jar \\\nfile:${felix.home}/lib/ext/spring-security-openid-3.1.0.RELEASE.jar",
            "title": "Step 1"
        },
        {
            "location": "/configuration/security.cas/#step-2",
            "text": "To configure matterhorn to use CAS, simply replace the default mh_default_org.xml with the contents of security_sample_cas.xml, available in the Matterhorn source. You must modify several settings in the sample to point to your CAS server:  <bean id=\"casEntryPoint\" class=\"org.springframework.security.cas.web.CasAuthenticationEntryPoint\">\n  <property name=\"loginUrl\" value=\"https://auth-test.berkeley.edu/cas/login\"/>\n  <property name=\"serviceProperties\" ref=\"serviceProperties\"/>\n</bean>\n\n<bean id=\"casAuthenticationProvider\" class=\"org.springframework.security.cas.authentication.CasAuthenticationProvider\">\n  <property name=\"userDetailsService\" ref=\"userDetailsService\"/>\n  <property name=\"serviceProperties\" ref=\"serviceProperties\" />\n  <property name=\"ticketValidator\">\n    <bean class=\"org.jasig.cas.client.validation.Cas20ServiceTicketValidator\">\n      <constructor-arg index=\"0\" value=\"https://auth-test.berkeley.edu/cas\" />\n    </bean>\n  </property>\n  <property name=\"key\" value=\"cas\"/>\n</bean>  You will also need to set the public URL for your Matterhorn server:  <bean id=\"serviceProperties\" class=\"org.springframework.security.cas.ServiceProperties\">\n  <property name=\"service\" value=\"http://localhost:8080/j_spring_cas_security_check\"/>\n  <property name=\"sendRenew\" value=\"false\"/>\n</bean>",
            "title": "Step 2"
        },
        {
            "location": "/configuration/security.cas/#step-3",
            "text": "Assuming you are using matterhorn version 1.4 and are using LDAP for user provisioning, you will need to build and deploy relevant modules with:  mvn clean install -Pdirectory-ldap,directory-cas,directory-openid -DdeployTo={your runtime server location here}  If not using LDAP, of course, you don't need the directory-ldap module but CAS alone will require deploying both the directory-cas and directory-openid modules.",
            "title": "Step 3"
        },
        {
            "location": "/configuration/security.cas/#step-4",
            "text": "Finally, you will need to configure a UserProvider to look up users as identified by CAS, for example see:  University of Saskatchewan CAS and LDAP integration",
            "title": "Step 4"
        },
        {
            "location": "/configuration/workflow/",
            "text": "Create a Custom Workflow\n\n\nThis document will help you get started with creating your own Matterhorn workflows.\n - For a list of available workflow operations, see:\n  \nWorkflow Operation Handler\n\n - For a more detailed discussion on how to create your own workflow operations, see:\n  \nCreate a Custom Workflow Operation Handler\n\n\nOverview\n\n\nA Matterhorn workflow is an ordered list of operations. There is no limit to the number of operations or their\nrepetition in a given workflow.\n\n\nWorkflow operations can be configured using configuration elements. The use of string replacement in configuration\nvalues allows workflows to dynamically adapt to a given input or user decision.\n\n\nA workflow operation can run autonomously or pause itself to allow for external, usually user, interaction.\n\n\nWatch Folder\n\n\nThe Matterhorn workflow service will automatically register any workflow documents placed in the Felix workflow\nconfiguration directory:\n\n\n<mh_config_dir>/workflows\n\n\n\nDocument\n\n\nMatterhorn workflows are defined in xml documents. The name of the document should follow the pattern\n\n-workflow.xml, e.g. compose-distribute-publish-workflow.xml.\n\n\nThe structure of a Matterhorn workflow document:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  <id></id>\n  <title></title>\n  <tags></tags>\n  <description></description>\n\n  <!-- Operations -->\n  <operations>\n    <operation></operation>\n    ...\n  </operations>\n\n</definition>\n\n\n\nCreate a Workflow\n\n\nThis sections will walk you through creating a custom workflow, which will encode ingested tracks to QuickTime movies.\n\n\nAdd an Encoding Profile\n\n\nIn most cases you also want to create new encoding profiles for new workflows. You can find more information about that\ntopic on the page \u201cEncoding Profiles\u201d. For this quide we assume that we have an encoding profile \u201cmov-low.http\u201d which\ncreates a distribution format definition for mpeg4 quicktime presenter/presentation download and a \u201cfeed-cover.http\u201d\nencoding profile to create thumbnail images for the videos.\n\n\nDescribe the Workflow\n\n\nStart by naming the workflow and giving it a meaningful description:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  <id>example</id>\n  <title>Encode QuickTime, Distribute and Publish</title>\n  <tags>\n    <!-- Tell the UI where to show this workflow -->\n    <tag>upload</tag>\n    <tag>schedule</tag>\n    <tag>archive</tag>\n  </tags>\n  <description>\n    Encode to QuickTime and thumbnail.\n    Distribute to local repository.\n    Publish to search index.\n  </description>\n\n  <!-- Operations -->\n  <operations></operations>\n\n</definition>\n\n\n\nInspect the Media\n\n\nThe first operation will be to inspect the media for technical metadata, such as format and length:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    <operation\n      id=\"inspect\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Inspect media package\">\n    </operation>\n\n  </operations>\n\n</definition>\n\n\n\nThe fail-on-error attribute is a boolean determining whether the workflow will throw an error to the\nexception-handler-workflow or simply proceed with the remaining operations.\n\n\nEncoding\n\n\nThe next operations will encode the media to the QuickTime/MPEG-4 .mp4 format:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    ...\n\n    <!-- encode: quicktime/mp4 -->\n    <operation\n      id=\"compose\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode camera to quicktime/mp4\">\n      <configurations>\n        <configuration key=\"source-flavor\">presenter/source</configuration>\n        <configuration key=\"target-flavor\">presenter/delivery</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">mov-low.http</configuration>\n      </configurations>\n    </operation>\n\n    <operation\n      id=\"compose\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode screen to quicktime/mp4\">\n      <configurations>\n        <configuration key=\"source-flavor\">presentation/source</configuration>\n        <configuration key=\"target-flavor\">presentation/delivery</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">mov-low.http</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>\n\n\n\nThe target-tags attribute tags the resulting media for later use as input for other operations, using the source-tags\nattribute. See #Distribute the Media.\n\n\nThe encoding-profile attribute refers to an encoding profile defined in \netc/workflows\n. See Encoding Profiles.\n\n\nEncode to Thumbnail\n\n\nThe next operations will create thumbnails from the media:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    ...\n\n    <!-- encode: quicktime/mp4 -->\n    ...\n\n    <!-- encode: images -->\n      <!-- camera -->\n    <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode camera to thumbnail\">\n      <configurations>\n        <configuration key=\"source-flavor\">presenter/source</configuration>\n        <configuration key=\"source-tags\"></configuration>\n        <configuration key=\"target-flavor\">cover/source</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">feed-cover.http</configuration>\n        <configuration key=\"time\">1</configuration>\n      </configurations>\n    </operation>\n\n      <!-- screen -->\n    <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode screen to thumbnail\">\n      <configurations>\n        <configuration key=\"source-flavor\">presentation/source</configuration>\n        <configuration key=\"source-tags\"></configuration>\n        <configuration key=\"target-flavor\">cover/source</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">feed-cover.http</configuration>\n        <configuration key=\"time\">1</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>\n\n\n\nThe time attribute determines the approximate frame of the source media is used. The time unit is in seconds.\n\n\nDistribute the Media\n\n\nThe next operation copies the encoded media to the Matterhorn distribution channel:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    ...\n\n    <!-- encode: quicktime/mp4 -->\n    ...\n\n    <!-- encode: images -->\n    ...\n\n    <!-- distribute: local -->\n    <operation\n      id=\"publish-engage\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Distribute media to the local distribution channel\">\n      <configurations>\n        <configuration key=\"download-source-tags\">publish, rss, atom</configuration>\n        <configuration key=\"streaming-source-tags\"></configuration>\n        <configuration key=\"check-availability\">true</configuration>\n\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>\n\n\n\nThe publish-engage operation uses all media tagged as rss or atom as input.\n\n\nAccept User Input\n\n\nWorkflow definitions may optionally include variables to be replaced by user input. For instance, the \"review\" operation\ncan put a workflow \"on hold\" and wait for an administrative user to review the media before allowing processing to\ncontinue. To enable user control of individual workflow instances, the workflow definition must 1) use the ${variable}\nnotation in the workflow definition and 2) contain a custom configuration panel. Here is an example of a configurable\n\"review\" operation:\n\n\n <operation id=\"review\">\n  <configurations>\n    <configuration key=\"required-property\">${review.hold}</configuration>\n  </configurations>\n</operation>\n\n\n\nOnce the operation is configured to accept a variable, we need to describe how to gather the value from the\nadministrative user. The \n element of a workflow definitions describes this user interface snippet.\nA simple configuration panel for the \"review\" operation might look like this:\n\n\n<configuration_panel>\n  <![CDATA[\n    Hold this workflow for review? <input id=\"review.hold\" name=\"review.hold\" type=\"checkbox\" value=\"true\">\n  ]]>\n</configuration_panel>\n\n\n\nThe checkbox in this \n will now be displayed in the administrative tools, and the user's selection\nwill be used to replace the ${review.hold} variable in the workflow.\n\n\nTest the Workflow\n\n\nThe easiest way to test a workflow is to just put it into the workflow folder where it will be picked up by Matterhorn\nautomatically. This needs, however, administrative privileges. If you don't have those you can also use the workflow\nservice REST endpoint.\n\n\nYou can use the \nofficial all in one test server\n for this\n(user:admin / passwd:opencast)\n\n\n\n\n\n\nScroll down to \"POST /start\" and click on the \"Testing form\" link.\n\n\n\n\n\n\n\nCopy and paste the complete workflow definition into the \"definition\" field and click \"submit.\"\n\n\n\n\n\n\n\nOpen the Admin Tools and navigate the recordings dashboard to view the status of the workflow instance.\n\n\n\n\n\n\n\nOpen the Matterhorn Media Module to see the published media.",
            "title": "Workflow"
        },
        {
            "location": "/configuration/workflow/#create-a-custom-workflow",
            "text": "This document will help you get started with creating your own Matterhorn workflows.\n - For a list of available workflow operations, see:\n   Workflow Operation Handler \n - For a more detailed discussion on how to create your own workflow operations, see:\n   Create a Custom Workflow Operation Handler",
            "title": "Create a Custom Workflow"
        },
        {
            "location": "/configuration/workflow/#overview",
            "text": "A Matterhorn workflow is an ordered list of operations. There is no limit to the number of operations or their\nrepetition in a given workflow.  Workflow operations can be configured using configuration elements. The use of string replacement in configuration\nvalues allows workflows to dynamically adapt to a given input or user decision.  A workflow operation can run autonomously or pause itself to allow for external, usually user, interaction.",
            "title": "Overview"
        },
        {
            "location": "/configuration/workflow/#watch-folder",
            "text": "The Matterhorn workflow service will automatically register any workflow documents placed in the Felix workflow\nconfiguration directory:  <mh_config_dir>/workflows",
            "title": "Watch Folder"
        },
        {
            "location": "/configuration/workflow/#document",
            "text": "Matterhorn workflows are defined in xml documents. The name of the document should follow the pattern -workflow.xml, e.g. compose-distribute-publish-workflow.xml.  The structure of a Matterhorn workflow document:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  <id></id>\n  <title></title>\n  <tags></tags>\n  <description></description>\n\n  <!-- Operations -->\n  <operations>\n    <operation></operation>\n    ...\n  </operations>\n\n</definition>",
            "title": "Document"
        },
        {
            "location": "/configuration/workflow/#create-a-workflow",
            "text": "This sections will walk you through creating a custom workflow, which will encode ingested tracks to QuickTime movies.",
            "title": "Create a Workflow"
        },
        {
            "location": "/configuration/workflow/#add-an-encoding-profile",
            "text": "In most cases you also want to create new encoding profiles for new workflows. You can find more information about that\ntopic on the page \u201cEncoding Profiles\u201d. For this quide we assume that we have an encoding profile \u201cmov-low.http\u201d which\ncreates a distribution format definition for mpeg4 quicktime presenter/presentation download and a \u201cfeed-cover.http\u201d\nencoding profile to create thumbnail images for the videos.",
            "title": "Add an Encoding Profile"
        },
        {
            "location": "/configuration/workflow/#describe-the-workflow",
            "text": "Start by naming the workflow and giving it a meaningful description:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  <id>example</id>\n  <title>Encode QuickTime, Distribute and Publish</title>\n  <tags>\n    <!-- Tell the UI where to show this workflow -->\n    <tag>upload</tag>\n    <tag>schedule</tag>\n    <tag>archive</tag>\n  </tags>\n  <description>\n    Encode to QuickTime and thumbnail.\n    Distribute to local repository.\n    Publish to search index.\n  </description>\n\n  <!-- Operations -->\n  <operations></operations>\n\n</definition>",
            "title": "Describe the Workflow"
        },
        {
            "location": "/configuration/workflow/#inspect-the-media",
            "text": "The first operation will be to inspect the media for technical metadata, such as format and length:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    <operation\n      id=\"inspect\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Inspect media package\">\n    </operation>\n\n  </operations>\n\n</definition>  The fail-on-error attribute is a boolean determining whether the workflow will throw an error to the\nexception-handler-workflow or simply proceed with the remaining operations.",
            "title": "Inspect the Media"
        },
        {
            "location": "/configuration/workflow/#encoding",
            "text": "The next operations will encode the media to the QuickTime/MPEG-4 .mp4 format:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    ...\n\n    <!-- encode: quicktime/mp4 -->\n    <operation\n      id=\"compose\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode camera to quicktime/mp4\">\n      <configurations>\n        <configuration key=\"source-flavor\">presenter/source</configuration>\n        <configuration key=\"target-flavor\">presenter/delivery</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">mov-low.http</configuration>\n      </configurations>\n    </operation>\n\n    <operation\n      id=\"compose\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode screen to quicktime/mp4\">\n      <configurations>\n        <configuration key=\"source-flavor\">presentation/source</configuration>\n        <configuration key=\"target-flavor\">presentation/delivery</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">mov-low.http</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>  The target-tags attribute tags the resulting media for later use as input for other operations, using the source-tags\nattribute. See #Distribute the Media.  The encoding-profile attribute refers to an encoding profile defined in  etc/workflows . See Encoding Profiles.",
            "title": "Encoding"
        },
        {
            "location": "/configuration/workflow/#encode-to-thumbnail",
            "text": "The next operations will create thumbnails from the media:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    ...\n\n    <!-- encode: quicktime/mp4 -->\n    ...\n\n    <!-- encode: images -->\n      <!-- camera -->\n    <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode camera to thumbnail\">\n      <configurations>\n        <configuration key=\"source-flavor\">presenter/source</configuration>\n        <configuration key=\"source-tags\"></configuration>\n        <configuration key=\"target-flavor\">cover/source</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">feed-cover.http</configuration>\n        <configuration key=\"time\">1</configuration>\n      </configurations>\n    </operation>\n\n      <!-- screen -->\n    <operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encode screen to thumbnail\">\n      <configurations>\n        <configuration key=\"source-flavor\">presentation/source</configuration>\n        <configuration key=\"source-tags\"></configuration>\n        <configuration key=\"target-flavor\">cover/source</configuration>\n        <configuration key=\"target-tags\">rss, atom</configuration>\n        <configuration key=\"encoding-profile\">feed-cover.http</configuration>\n        <configuration key=\"time\">1</configuration>\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>  The time attribute determines the approximate frame of the source media is used. The time unit is in seconds.",
            "title": "Encode to Thumbnail"
        },
        {
            "location": "/configuration/workflow/#distribute-the-media",
            "text": "The next operation copies the encoded media to the Matterhorn distribution channel:  <definition xmlns=\"http://workflow.opencastproject.org\">\n\n  <!-- Description -->\n  ...\n\n  <!-- Operations -->\n  <operations>\n\n    <!-- inspect media -->\n    ...\n\n    <!-- encode: quicktime/mp4 -->\n    ...\n\n    <!-- encode: images -->\n    ...\n\n    <!-- distribute: local -->\n    <operation\n      id=\"publish-engage\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Distribute media to the local distribution channel\">\n      <configurations>\n        <configuration key=\"download-source-tags\">publish, rss, atom</configuration>\n        <configuration key=\"streaming-source-tags\"></configuration>\n        <configuration key=\"check-availability\">true</configuration>\n\n      </configurations>\n    </operation>\n\n  </operations>\n\n</definition>  The publish-engage operation uses all media tagged as rss or atom as input.",
            "title": "Distribute the Media"
        },
        {
            "location": "/configuration/workflow/#accept-user-input",
            "text": "Workflow definitions may optionally include variables to be replaced by user input. For instance, the \"review\" operation\ncan put a workflow \"on hold\" and wait for an administrative user to review the media before allowing processing to\ncontinue. To enable user control of individual workflow instances, the workflow definition must 1) use the ${variable}\nnotation in the workflow definition and 2) contain a custom configuration panel. Here is an example of a configurable\n\"review\" operation:   <operation id=\"review\">\n  <configurations>\n    <configuration key=\"required-property\">${review.hold}</configuration>\n  </configurations>\n</operation>  Once the operation is configured to accept a variable, we need to describe how to gather the value from the\nadministrative user. The   element of a workflow definitions describes this user interface snippet.\nA simple configuration panel for the \"review\" operation might look like this:  <configuration_panel>\n  <![CDATA[\n    Hold this workflow for review? <input id=\"review.hold\" name=\"review.hold\" type=\"checkbox\" value=\"true\">\n  ]]>\n</configuration_panel>  The checkbox in this   will now be displayed in the administrative tools, and the user's selection\nwill be used to replace the ${review.hold} variable in the workflow.",
            "title": "Accept User Input"
        },
        {
            "location": "/configuration/workflow/#test-the-workflow",
            "text": "The easiest way to test a workflow is to just put it into the workflow folder where it will be picked up by Matterhorn\nautomatically. This needs, however, administrative privileges. If you don't have those you can also use the workflow\nservice REST endpoint.  You can use the  official all in one test server  for this\n(user:admin / passwd:opencast)    Scroll down to \"POST /start\" and click on the \"Testing form\" link.    Copy and paste the complete workflow definition into the \"definition\" field and click \"submit.\"    Open the Admin Tools and navigate the recordings dashboard to view the status of the workflow instance.    Open the Matterhorn Media Module to see the published media.",
            "title": "Test the Workflow"
        },
        {
            "location": "/configuration/configuration.files.and.keys/",
            "text": "Configuration Files and Keys\n\n\nThis document will help you get an overview of the existing Matterhorn configuration files and watch folders.\n\n\nWatch Folders\n\n\nWatch folders allow you to quickly augment Matterhorn's existing behavior, simply by adding new configuration files. Below is a list of default watch folders.\n\n\nEncoding Profiles\n\n\nDefault and custom encoding profiles should be placed in \n/etc/encoding. The file names should follow the pattern *.properties.\n\n\nAtom and RSS Feeds\n\n\nDefault and custom feed definitions should be placed in \n/etc/feeds. The file names should follow the pattern *.xml.\n\n\nWorkflow Definitions\n\n\nCustom workflow definitions should be placed in \n/etc/workflows. The file names should follow the pattern *.xml.\n\n\nOSGi Bundles\n\n\nAdditional OSGi bundles should be placed in \n/lib/matterhorn. \n/etc/load should be reserved for the default configuration.\n\n\nInbox\n\n\nMedia files placed in \n/inbox will be copied to the Matterhorn working file repository and made available in the Admin Tools > Uploading Recording user interface, via the File Location menu.\n\n\nQueued media files are write-protected, copied to the working file repository and then deleted from the inbox.\n\n\nConfiguration Files\n\n\nConfiguration files use key-value pairs to determine Matterhorn's runtime behavior.\n\n\n/etc/config.properties\n\n\nconfig.properties\n is the primary Matterhorn configuration file.\n\n\nBundle Configuration Properties\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\norg.osgi.service.http.port\n\n\nPort number of http services\n\n\n8080\n\n\n\n\n\n\norg.osgi.service.http.port.secure\n\n\nPort number of https services\n\n\n8443\n\n\n\n\n\n\norg.osgi.service.http.secure.enabled\n\n\nToggle https services\n\n\nfalse\n\n\n\n\n\n\n\n\nAlternatively, edit Apache's httpd.conf to reroute Matterhorn to port 80:\n\n\nProxyPass / http://localhost:8080/\nProxyPassReverse / http://localhost:8080/\n\n\n\nOpencast Matterhorn Configuration\n\n\nGeneral\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.server.url\n\n\nURL of Matterhorn http services\n\n\nhttp://localhost:8080 e.g. org.opencastproject.server.url=http://matterhorn1.telavivuniv.org\n\n\n\n\n\n\norg.opencastproject.serviceregistry.url\n\n\nURL of the service registry, if not running in the local JVM\n\n\nThis value is needed only if the host does not have access to the relational database (see JDBC settings below).  This is common for capture agents, but not for servers.\n\n\n\n\n\n\norg.opencastproject.server.maxload\n\n\nThe maximum number of concurrent jobs this server should attempt to run\n\n\nDefaults to the number of processing cores available to the JVM, as reported by Runtime.availableProcessors()\n\n\n\n\n\n\norg.opencastproject.storage.dir\n\n\nBase path of Matterhorn data file structure. Note: This must be changed on a production server so that media will not disappear on reboot.\n\n\n${java.io.tmpdir}/opencast\n\n\n\n\n\n\norg.opencastproject.security.config\n\n\nPath to Matterhorn security configuration file\n\n\nconf/security.xml\n\n\n\n\n\n\norg.opencastproject.security.digest.user\n\n\nDigest authentication privileged user name\n\n\nmatterhorn_system_account\n\n\n\n\n\n\norg.opencastproject.security.digest.pass\n\n\nDigest authentication privileged user password\n\n\nCHANGE_ME\n\n\n\n\n\n\norg.opencastproject.anonymous.feedback.url\n\n\nThe project-wide feedback service, used to help the community understand how Matterhorn is deployed \"in the wild.  For more information on this feature, see the Project Feedback Service documentation\n\n\nNo Feedback\n\n\n\n\n\n\n\n\nStreaming\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.streaming.url\n\n\nURL of Red5 streaming server\n\n\nrtmp://localhost/matterhorn-engage\n\n\n\n\n\n\norg.opencastproject.streaming.directory\n\n\nPath to published streaming media\n\n\n${org.opencastproject.storage.dir}/streams\n\n\n\n\n\n\norg.opencastproject.streaming.flvcompatibility\n\n\nSome newer streaming server versions expect an \"flv:\" tag within the rtmp URL. Not every RTMP-streaming server is compatible with this (i.e. nginx), so this is the compatibility mode to the old syntax. true = without \"flv:\" tag - old syntax, false = with \"flv:\" tag - new syntax\n\n\nfalse\n\n\n\n\n\n\n\n\nDatabase\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.db.ddl.generation\n\n\nToggle generation of database description language\n\n\ntrue\n\n\n\n\n\n\norg.opencastproject.db.vendor\n\n\nDatabase vendor type\n\n\nHSQL\n\n\n\n\n\n\norg.opencastproject.db.jdbc.driver\n\n\nFully-qualified name of database adapter\n\n\norg.h2.Driver\n\n\n\n\n\n\norg.opencastproject.db.jdbc.url\n\n\nURL of database, using the jdbc:\n:// protocol\n\n\njdbc:h2:${org.opencastproject.storage.dir}/db;LOCK_MODE=1;MVCC=TRUE\n\n\n\n\n\n\norg.opencastproject.db.jdbc.user\n\n\nPrivileged database user name\n\n\nsa\n\n\n\n\n\n\norg.opencastproject.db.jdbc.pass\n\n\nPrivileged database user password\n\n\nsa\n\n\n\n\n\n\n\n\nDistribution\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.download.directory\n\n\nPath to published progressive media\n\n\n${org.opencastproject.storage.dir}/downloads\n\n\n\n\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.search.solr.dir\n\n\nPath to search index files\n\n\n${org.opencastproject.storage.dir}/searchindex\n\n\n\n\n\n\n\n\nWorking File Repository\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.file.repo.path\n\n\nPath to Matterhorn working file repository\n\n\n${org.opencastproject.storage.dir}/files\n\n\n\n\n\n\n\n\nWorkspace\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.workspace.rootdir\n\n\nPath to the workspace root directory\n\n\n${org.opencastproject.storage.dir}/workspace\n\n\n\n\n\n\n\n\nWorkflow\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.workflow.default.definition\n\n\nID of default workflow definition\n\n\nfull\n\n\n\n\n\n\norg.opencastproject.workflow.solr.dir\n\n\nIf using a local workflow search index, this is the directory to use for storage of the embedded solr server's index files\n\n\n${org.opencastproject.storage.dir}/workflow\n\n\n\n\n\n\norg.opencastproject.workflow.solr.url\n\n\nIf using a remote workflow search index, this is the URL to the remote solr server.  Configure either this value or org.opencastproject.workflow.solr.dir but not both.\n\n\n\n\n\n\n\n\n\n\nInbox\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\norg.opencastproject.inbox.threads\n\n\nThe number of mediapackages to ingest concurrently from the watch folder\n\n\n1\n\n\n\n\n\n\n\n\n/etc/load/org.opencastproject.organization-mh_default_org.cfg\n\n\norg.opencastproject.organization-mh_default_org.cfg\n defines the default tennant in a multi tennant setup. If you don't have a multi-tennant setup this is the file for you to edit.\n\n\nServers and URLs\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\nprop.org.opencastproject.admin.ui.url\n\n\nThe URL to the administrative tools.  This sets the URL for the \"Adminstrative Tools\" link on the Matterhorn welcome page.\n\n\nThe local server URL, or ${org.opencastproject.server.url}\n\n\n\n\n\n\nprop.org.opencastproject.engage.ui.url\n\n\nThe URL to the engage tools.  This sets the URL for the \"Engage Tools\" link on the Matterhorn welcome page.\n\n\nThe local server URL, or ${org.opencastproject.server.url}\n\n\n\n\n\n\n\n\nSecurity\n\n\n/etc/security/mh_default_org.xml\n\n\nmh_default_org.xml\n defines the Matterhorn access policy using the \nSpring Security\n framework XML schema.",
            "title": "Configuration Files and Keys"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#configuration-files-and-keys",
            "text": "This document will help you get an overview of the existing Matterhorn configuration files and watch folders.",
            "title": "Configuration Files and Keys"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#watch-folders",
            "text": "Watch folders allow you to quickly augment Matterhorn's existing behavior, simply by adding new configuration files. Below is a list of default watch folders.",
            "title": "Watch Folders"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#encoding-profiles",
            "text": "Default and custom encoding profiles should be placed in  /etc/encoding. The file names should follow the pattern *.properties.",
            "title": "Encoding Profiles"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#atom-and-rss-feeds",
            "text": "Default and custom feed definitions should be placed in  /etc/feeds. The file names should follow the pattern *.xml.",
            "title": "Atom and RSS Feeds"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#workflow-definitions",
            "text": "Custom workflow definitions should be placed in  /etc/workflows. The file names should follow the pattern *.xml.",
            "title": "Workflow Definitions"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#osgi-bundles",
            "text": "Additional OSGi bundles should be placed in  /lib/matterhorn.  /etc/load should be reserved for the default configuration.",
            "title": "OSGi Bundles"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#inbox",
            "text": "Media files placed in  /inbox will be copied to the Matterhorn working file repository and made available in the Admin Tools > Uploading Recording user interface, via the File Location menu.  Queued media files are write-protected, copied to the working file repository and then deleted from the inbox.",
            "title": "Inbox"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#configuration-files",
            "text": "Configuration files use key-value pairs to determine Matterhorn's runtime behavior.",
            "title": "Configuration Files"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#etcconfigproperties",
            "text": "config.properties  is the primary Matterhorn configuration file.",
            "title": "/etc/config.properties"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#bundle-configuration-properties",
            "text": "Name  Description  Default      org.osgi.service.http.port  Port number of http services  8080    org.osgi.service.http.port.secure  Port number of https services  8443    org.osgi.service.http.secure.enabled  Toggle https services  false     Alternatively, edit Apache's httpd.conf to reroute Matterhorn to port 80:  ProxyPass / http://localhost:8080/\nProxyPassReverse / http://localhost:8080/",
            "title": "Bundle Configuration Properties"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#opencast-matterhorn-configuration",
            "text": "",
            "title": "Opencast Matterhorn Configuration"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#general",
            "text": "Name  Description  Default      org.opencastproject.server.url  URL of Matterhorn http services  http://localhost:8080 e.g. org.opencastproject.server.url=http://matterhorn1.telavivuniv.org    org.opencastproject.serviceregistry.url  URL of the service registry, if not running in the local JVM  This value is needed only if the host does not have access to the relational database (see JDBC settings below).  This is common for capture agents, but not for servers.    org.opencastproject.server.maxload  The maximum number of concurrent jobs this server should attempt to run  Defaults to the number of processing cores available to the JVM, as reported by Runtime.availableProcessors()    org.opencastproject.storage.dir  Base path of Matterhorn data file structure. Note: This must be changed on a production server so that media will not disappear on reboot.  ${java.io.tmpdir}/opencast    org.opencastproject.security.config  Path to Matterhorn security configuration file  conf/security.xml    org.opencastproject.security.digest.user  Digest authentication privileged user name  matterhorn_system_account    org.opencastproject.security.digest.pass  Digest authentication privileged user password  CHANGE_ME    org.opencastproject.anonymous.feedback.url  The project-wide feedback service, used to help the community understand how Matterhorn is deployed \"in the wild.  For more information on this feature, see the Project Feedback Service documentation  No Feedback",
            "title": "General"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#streaming",
            "text": "Name  Description  Default      org.opencastproject.streaming.url  URL of Red5 streaming server  rtmp://localhost/matterhorn-engage    org.opencastproject.streaming.directory  Path to published streaming media  ${org.opencastproject.storage.dir}/streams    org.opencastproject.streaming.flvcompatibility  Some newer streaming server versions expect an \"flv:\" tag within the rtmp URL. Not every RTMP-streaming server is compatible with this (i.e. nginx), so this is the compatibility mode to the old syntax. true = without \"flv:\" tag - old syntax, false = with \"flv:\" tag - new syntax  false",
            "title": "Streaming"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#database",
            "text": "Name  Description  Default      org.opencastproject.db.ddl.generation  Toggle generation of database description language  true    org.opencastproject.db.vendor  Database vendor type  HSQL    org.opencastproject.db.jdbc.driver  Fully-qualified name of database adapter  org.h2.Driver    org.opencastproject.db.jdbc.url  URL of database, using the jdbc: :// protocol  jdbc:h2:${org.opencastproject.storage.dir}/db;LOCK_MODE=1;MVCC=TRUE    org.opencastproject.db.jdbc.user  Privileged database user name  sa    org.opencastproject.db.jdbc.pass  Privileged database user password  sa",
            "title": "Database"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#distribution",
            "text": "Name  Description  Default      org.opencastproject.download.directory  Path to published progressive media  ${org.opencastproject.storage.dir}/downloads",
            "title": "Distribution"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#search",
            "text": "Name  Description  Default      org.opencastproject.search.solr.dir  Path to search index files  ${org.opencastproject.storage.dir}/searchindex",
            "title": "Search"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#working-file-repository",
            "text": "Name  Description  Default      org.opencastproject.file.repo.path  Path to Matterhorn working file repository  ${org.opencastproject.storage.dir}/files",
            "title": "Working File Repository"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#workspace",
            "text": "Name  Description  Default      org.opencastproject.workspace.rootdir  Path to the workspace root directory  ${org.opencastproject.storage.dir}/workspace",
            "title": "Workspace"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#workflow",
            "text": "Name  Description  Default      org.opencastproject.workflow.default.definition  ID of default workflow definition  full    org.opencastproject.workflow.solr.dir  If using a local workflow search index, this is the directory to use for storage of the embedded solr server's index files  ${org.opencastproject.storage.dir}/workflow    org.opencastproject.workflow.solr.url  If using a remote workflow search index, this is the URL to the remote solr server.  Configure either this value or org.opencastproject.workflow.solr.dir but not both.",
            "title": "Workflow"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#inbox_1",
            "text": "Name  Description  Default      org.opencastproject.inbox.threads  The number of mediapackages to ingest concurrently from the watch folder  1",
            "title": "Inbox"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#etcloadorgopencastprojectorganization-mh_default_orgcfg",
            "text": "org.opencastproject.organization-mh_default_org.cfg  defines the default tennant in a multi tennant setup. If you don't have a multi-tennant setup this is the file for you to edit.",
            "title": "/etc/load/org.opencastproject.organization-mh_default_org.cfg"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#servers-and-urls",
            "text": "Name  Description  Default      prop.org.opencastproject.admin.ui.url  The URL to the administrative tools.  This sets the URL for the \"Adminstrative Tools\" link on the Matterhorn welcome page.  The local server URL, or ${org.opencastproject.server.url}    prop.org.opencastproject.engage.ui.url  The URL to the engage tools.  This sets the URL for the \"Engage Tools\" link on the Matterhorn welcome page.  The local server URL, or ${org.opencastproject.server.url}",
            "title": "Servers and URLs"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#security",
            "text": "",
            "title": "Security"
        },
        {
            "location": "/configuration/configuration.files.and.keys/#etcsecuritymh_default_orgxml",
            "text": "mh_default_org.xml  defines the Matterhorn access policy using the  Spring Security  framework XML schema.",
            "title": "/etc/security/mh_default_org.xml"
        },
        {
            "location": "/modules/",
            "text": "Module Documentation\n\n\nThis is a documentation for modules included in Matterhorn that do not to be configured by default, but that allow some\ntweaking. For some modules some more in depth documentation is available too.\n\n\n\n\nAtom and RSS Feed\n\n\nMedia Module\n\n\nPlayer 2.0\n\n\nConfiguration\n\n\nURL Parameter\n\n\nOptional Plugins\n\n\nDevelopment\n\n\nArchitecture\n\n\nCore Reference\n\n\nEvents\n\n\nPersistent local storage\n\n\nCreate a new Plugin\n\n\nTesting\n\n\n\n\n\n\nSearch Index\n\n\nText Extraction\n\n\nVideoeditor\n\n\nSetup\n\n\nManual\n\n\nArchitecture\n\n\n\n\n\n\nVideo Segmentation\n\n\nYouTube Publication",
            "title": "Module Configuration Home"
        },
        {
            "location": "/modules/#module-documentation",
            "text": "This is a documentation for modules included in Matterhorn that do not to be configured by default, but that allow some\ntweaking. For some modules some more in depth documentation is available too.   Atom and RSS Feed  Media Module  Player 2.0  Configuration  URL Parameter  Optional Plugins  Development  Architecture  Core Reference  Events  Persistent local storage  Create a new Plugin  Testing    Search Index  Text Extraction  Videoeditor  Setup  Manual  Architecture    Video Segmentation  YouTube Publication",
            "title": "Module Documentation"
        },
        {
            "location": "/modules/atomrss/",
            "text": "Configure Atom and RSS Feeds\n\n\nThis document will help you understand and configure the Matterhorn RSS and Atom feed catalog. The catalog supports multiple versions of each syndication format.\n\n\nFeed Catalog\n\n\nThe catalog is located at:\n\n\nhttp://<matterhorn_root>/feeds\n\n\n\nIndividual feeds are located at:\n\n\nhttp://<matterhorn_root>/feeds/<feed_selector>\n\n\n\nDefaults\n\n\nThe catalog contains the following default feeds:\n\n\nLatest\n\n\nhttp://nightly.opencastproject.org/feeds/[atom|rss|*]/<version_number>/latest\n\n\n\nNeed an example? Visit http://demo.opencastproject.org/feeds/atom/1.0/latest\n\n\nSeries\n\n\nhttp://nightly.opencastproject.org/feeds/[atom|rss|*]/<version_number>/series/<series_id>\n\n\n\nAggregation (of a set of series)\n\n\nhttp://nightly.opencastproject.org/feeds/[atom|rss|*]/<version_number>/aggregated/<name_of_configured_aggregation>\n\n\n\nCustom\n\n\nhttp://nightly.opencastproject.org/feeds/[atom|rss|*]/<version_number>/custom/<query>\n\n\n\nAggregation\n\n\nThe feed allows administrators to pre-configure feeds for specific sets of series. Given the following configuration, http://\n/feeds/aggregated/myseries would return the latest episodes from series series_1 and series_2.\nThe Matterhorn feed specifications are located in:\n\n\n<felix_home>/conf/feeds\n\n\n\nUpdate aggregation.properties, the specification for an example feed aggregation:\n\n\nfeed.selector=myseries\nfeed.series=series_1,series_2\n\n\n\nCustom\n\n\nThe Matterhorn feed specifications are located in:\n\n\n<felix_home>/conf/feeds\n\n\n\nBelow is custom.properties, the default specification for an example custom feed of published episodes:\n\n\nfeed.class=org.opencastproject.feed.impl.CustomFeedService\nfeed.uri=custom\nfeed.size=25\nfeed.selector=custom\nfeed.query=dc_title:{0}\nfeed.name=Special episodes\nfeed.description=Special collection of episodes\nfeed.copyright=All rights reserved by The Opencast Project\nfeed.home=/engage/ui\nfeed.entry=/engage/ui/embed.html?id={0}\nfeed.cover=/engage/feed-cover.png\nfeed.rssflavors=presentation/delivery,presenter/delivery\nfeed.rsstags=rss\nfeed.rssmediatype=video,audio\nfeed.atomflavors=presenter/delivery,presentation/delivery\nfeed.atomtags=atom\n\n\n\nProperties\n\n\nThe following properties are common to all feed specifications:\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfeed.class\n\n\nJava implementation, e.g. LatestFeedService.\n\n\n\n\n\n\nfeed.uri\n\n\nFeed location/identifier\n\n\n\n\n\n\nfeed.size\n\n\nMaximum number of entries in the feed (with a default of 100 if ommitted). Set to 0 to include all available entries.\n\n\n\n\n\n\nfeed.selector\n\n\nFeed route pattern, e.g. latest.\n\n\n\n\n\n\nfeed.name\n\n\nFeed title\n\n\n\n\n\n\nfeed.description\n\n\nFeed description\n\n\n\n\n\n\nfeed.copyright\n\n\nFeed copyright notice\n\n\n\n\n\n\nfeed.home\n\n\nFeed catalog homepage, e.g. http://www.opencastproject.org.\n\n\n\n\n\n\nfeed.entry\n\n\nThe route pattern used to generate links to individual enclosures, e.g. /engage/ui/embed.html?id={0}.\n\n\n\n\n\n\nfeed.cover\n\n\nFeed image\n\n\n\n\n\n\nfeed.rssflavors\n\n\nThe RSS enclosure route pattern, e.g. presenter/delivery, selected according to their appearance.\n\n\n\n\n\n\nfeed.rsstags\n\n\nA comma, semi-colon or space-separated list of tags used to filter available enclosures\n\n\n\n\n\n\nfeed.rssmediatype\n\n\nA comma, semi-colon or space-separated list of tags used to decide whether to prefer video or audio enclosures\n\n\n\n\n\n\nfeed.atomflavors\n\n\nThe Atom enclosures route pattern, e.g. presenter/delivery.\n\n\n\n\n\n\nfeed.atomtags\n\n\nA comma, semi-colon or space-separated list of tags used to filter available enclosures\n\n\n\n\n\n\n\n\nThe following properties are specific to custom feeds:\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfeed.query\n\n\nA custom lucene query, matched again Java's MessageFormat using solr.\n\n\n\n\n\n\n\n\nGiven the following query, http://\n/feeds/alphabetical/a would return all episodes starting with the letter a.\n\n\nfeed.selector=alphabetical\nfeed.query=dc_title:{0}*",
            "title": "Atom/RSS"
        },
        {
            "location": "/modules/atomrss/#configure-atom-and-rss-feeds",
            "text": "This document will help you understand and configure the Matterhorn RSS and Atom feed catalog. The catalog supports multiple versions of each syndication format.",
            "title": "Configure Atom and RSS Feeds"
        },
        {
            "location": "/modules/atomrss/#feed-catalog",
            "text": "The catalog is located at:  http://<matterhorn_root>/feeds  Individual feeds are located at:  http://<matterhorn_root>/feeds/<feed_selector>",
            "title": "Feed Catalog"
        },
        {
            "location": "/modules/atomrss/#defaults",
            "text": "The catalog contains the following default feeds:",
            "title": "Defaults"
        },
        {
            "location": "/modules/atomrss/#latest",
            "text": "http://nightly.opencastproject.org/feeds/[atom|rss|*]/<version_number>/latest  Need an example? Visit http://demo.opencastproject.org/feeds/atom/1.0/latest",
            "title": "Latest"
        },
        {
            "location": "/modules/atomrss/#series",
            "text": "http://nightly.opencastproject.org/feeds/[atom|rss|*]/<version_number>/series/<series_id>",
            "title": "Series"
        },
        {
            "location": "/modules/atomrss/#aggregation-of-a-set-of-series",
            "text": "http://nightly.opencastproject.org/feeds/[atom|rss|*]/<version_number>/aggregated/<name_of_configured_aggregation>",
            "title": "Aggregation (of a set of series)"
        },
        {
            "location": "/modules/atomrss/#custom",
            "text": "http://nightly.opencastproject.org/feeds/[atom|rss|*]/<version_number>/custom/<query>",
            "title": "Custom"
        },
        {
            "location": "/modules/atomrss/#aggregation",
            "text": "The feed allows administrators to pre-configure feeds for specific sets of series. Given the following configuration, http:// /feeds/aggregated/myseries would return the latest episodes from series series_1 and series_2.\nThe Matterhorn feed specifications are located in:  <felix_home>/conf/feeds  Update aggregation.properties, the specification for an example feed aggregation:  feed.selector=myseries\nfeed.series=series_1,series_2",
            "title": "Aggregation"
        },
        {
            "location": "/modules/atomrss/#custom_1",
            "text": "The Matterhorn feed specifications are located in:  <felix_home>/conf/feeds  Below is custom.properties, the default specification for an example custom feed of published episodes:  feed.class=org.opencastproject.feed.impl.CustomFeedService\nfeed.uri=custom\nfeed.size=25\nfeed.selector=custom\nfeed.query=dc_title:{0}\nfeed.name=Special episodes\nfeed.description=Special collection of episodes\nfeed.copyright=All rights reserved by The Opencast Project\nfeed.home=/engage/ui\nfeed.entry=/engage/ui/embed.html?id={0}\nfeed.cover=/engage/feed-cover.png\nfeed.rssflavors=presentation/delivery,presenter/delivery\nfeed.rsstags=rss\nfeed.rssmediatype=video,audio\nfeed.atomflavors=presenter/delivery,presentation/delivery\nfeed.atomtags=atom",
            "title": "Custom"
        },
        {
            "location": "/modules/atomrss/#properties",
            "text": "The following properties are common to all feed specifications:     Name  Description      feed.class  Java implementation, e.g. LatestFeedService.    feed.uri  Feed location/identifier    feed.size  Maximum number of entries in the feed (with a default of 100 if ommitted). Set to 0 to include all available entries.    feed.selector  Feed route pattern, e.g. latest.    feed.name  Feed title    feed.description  Feed description    feed.copyright  Feed copyright notice    feed.home  Feed catalog homepage, e.g. http://www.opencastproject.org.    feed.entry  The route pattern used to generate links to individual enclosures, e.g. /engage/ui/embed.html?id={0}.    feed.cover  Feed image    feed.rssflavors  The RSS enclosure route pattern, e.g. presenter/delivery, selected according to their appearance.    feed.rsstags  A comma, semi-colon or space-separated list of tags used to filter available enclosures    feed.rssmediatype  A comma, semi-colon or space-separated list of tags used to decide whether to prefer video or audio enclosures    feed.atomflavors  The Atom enclosures route pattern, e.g. presenter/delivery.    feed.atomtags  A comma, semi-colon or space-separated list of tags used to filter available enclosures     The following properties are specific to custom feeds:     Name  Description      feed.query  A custom lucene query, matched again Java's MessageFormat using solr.     Given the following query, http:// /feeds/alphabetical/a would return all episodes starting with the letter a.  feed.selector=alphabetical\nfeed.query=dc_title:{0}*",
            "title": "Properties"
        },
        {
            "location": "/modules/mediamodule.configuration/",
            "text": "Media Module Configuration\n\n\nThe Media Module is the default overview of the distributed media files.\n\n\nThe configurations for the Media Module are done for each tenant. So the configuration keys are located in\n\n<felix_home>/etc/load/org.opencastproject.organization-mh_default_org.cfg\n:\n\n\n\n\nprop.logo_large\n\n\nThis logo file will be displayed in the upper left of the Media Module page\n\n\nDefault: an Opencast logo\n\n\n\n\n\n\nprop.player\n\n\nThe player that should be use to play the videos.\n\n\nDefault: Opencast 2.0 (Theodul) player",
            "title": "Media Module Configuration"
        },
        {
            "location": "/modules/mediamodule.configuration/#media-module-configuration",
            "text": "The Media Module is the default overview of the distributed media files.  The configurations for the Media Module are done for each tenant. So the configuration keys are located in <felix_home>/etc/load/org.opencastproject.organization-mh_default_org.cfg :   prop.logo_large  This logo file will be displayed in the upper left of the Media Module page  Default: an Opencast logo    prop.player  The player that should be use to play the videos.  Default: Opencast 2.0 (Theodul) player",
            "title": "Media Module Configuration"
        },
        {
            "location": "/modules/player.architecture/",
            "text": "Architecture\n\n\nOverview\n\n\nThe architecture of the theodul player has a plugin based structure based around a core. The core and the plugins have been realized as OSGi modules. Each plugin can be separately build.\nThe following figure shows the OSGi architecture of the player.\n\n\n\n\nAll Theodul OSGi modules are stored under:\n\n\nmodules/matterhorn-engage-theodul-*\n#Core module\nmodules/matterhorn-engage-theodul-api/\nmodules/matterhorn-engage-theodul-core/\n#A plugin module\nmodules/matterhorn-engage-theodul-plugin-*\nmodules/matterhorn-engage-theodul-plugin-tab-description/\n\n\n\nPlugin Manager\n\n\nThe main workflow is implemented by the core, which recognizes new plugins, collects information about the plugin type and resources, runs the JavaScript logic and inserts the first compiled templates into the HTML DOM.\nThe Plugin Manager Endpoint recognizes the OSGi modules. Each plugin has some information about its name and its resources. The Plugin Manager collects these information and publishes them via a REST endpoint. The following URL links to an example REST endpoint:\n\n\nhttp://localhost:8080/engage/theodul/manager/list.json\n\n\nThe documentation and test forms of the endpoint can be found on the Matterhorn start page. The following data in JSON shows an example list of plugins, which are used by the player and provided by the Plugin Manager Endpoint.\n\n\n{\n  \"pluginlist\":{\n    \"plugins\":[\n    {\n      \"name\":\"EngagePluginTabSlidetext\",\n      \"id\":\"6\",\n      \"description\":\"Simple implementation of a tab with the text of the slides\",\n      \"static-path\":\"6\\/static\"\n    },\n    {\n      \"name\":\"EngagePluginControlsMockup\",\n      \"id\":\"5\",\n      \"description\":\"Simple implementation of a control bar\",\n      \"static-path\":\"5\\/static\"\n    }]\n  }\n}\n\n\n\nNext to the Plugin Manager there is the Theodul Core module, which publishes the main HTML page, core.html.\n\n\nUI Core\n\n\nThe \ncore.html\n is the main entry point and starts the Javascript core logic. Following listing shows the directory structure of core in the \nmatterhorn-engage-theodul-core OSGi\n module.\n\n\n|-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------spec\n\n\n\nAll Theodul JavaScript components are defined as a RequireJS module. The file engage_init.js is loaded firstly and contains the configuration of RequireJS. This init script additionally loads the core module, which is defined in the engage_core.js.\n\n\nThe core module initializes the main HTML view. This view is realized as a BackboneJS view and is linked to a global Backbone model, which is stored in the model module in engage_model.js. The view is returned by the core module, so every other module, which has a dependency to the core module, has a reference to the view (simply called \"Engage\" in the plugins) and it's functions. See the Core Reference for more information about the functions of the core view.\n\n\nPlugins\n\n\nPlugins in the Theodul player are developed and distributed in own OSGi modules. Every plugin has a special UI type. In dependency of this type the core injects the plugin to the right position of the player. The following plugin types are possible:\n\n\n\n\n\n\n\n\nPlugin Type\n\n\nDescription\n\n\nCharacteristics\n\n\nModule Name\n\n\nJS Plugin Type Name\n\n\nMaven Plugin Type Name\n\n\n\n\n\n\n\n\n\n\nControls\n\n\nImplements the main controls of the top of the player\n\n\nOnly one plugin per player possible.\n\n\nmatterhorn-engage-theodul-plugin-controls\n\n\nengage_controls\n\n\ncontrols\n\n\n\n\n\n\nTimeline\n\n\nTimeline information below the main controls.\n\n\nGood for processing time-based data like user tracking, slide previews or annotations.\n\n\nOptional plugin, more than one possible.  matterhorn-engage-theodul-plugin-timeline-\n\n\nengage_timeline\n\n\ntimeline\n\n\n\n\n\n\nVideodisplay\n\n\nImplementation of the video display.\n\n\nCurrently only one plugin per player possible, but in the future more video displays should be possible.\n\n\nmatterhorn-engage-theodul-plugin-video-\n\n\nengage_video\n\n\nvideo\n\n\n\n\n\n\nDescription/Label\n\n\nA plugin below the video display, good to show simple information about the video, like a title and the creator.\n\n\nOnly one plugin per player possible.\n\n\nmatterhorn-engage-theodul-plugin-description\n\n\nengage_description\n\n\ndescription\n\n\n\n\n\n\nTab\n\n\nShows a tab in the tab view at the bottom of the player.\n\n\nOptional plugin, more than one possible.\n\n\nmatterhorn-engage-theodul-plugin-tab-\n\n\nengage_tab\n\n\ntab\n\n\n\n\n\n\nCustom\n\n\nA custom plugin without a relationship to an UI element.\n\n\nGood for a custom REST endpoint, global data representation or to load custom JS code or libraries.\n\n\nOptional plugin, more than one possible.\n\n\nNo connection to a preserved UI element.\n\n\nmatterhorn-engage-theodul-plugin-custom-\n\n\n\n\n\n\n\n\nThe following listing shows the directory structure of a plugin module:\n\n\n|-src\n|---main\n|-----java\n|-------org\n|---------opencastproject\n|-----------engage\n|-------------theodul\n|---------------plugin\n|-----------------controls  #Simple Java class, and optional REST endpoint\n|-----resources\n|-------OSGI-INF            #OSGi information about the plugin\n|-------static              #web ressources, contains the main.js entry point of the plugin\n|---------images            #plugin ressources\n|---------js                #plugin js libs\n|-----------bootstrap\n|-----------jqueryui\n|---test                    #Jasmine test ressources\n|-----resources\n|-------js\n|---------engage            #Test Wrapper of the core\n|---------lib               #Required test libs\n|---------spec              #Jasmine test specs\n\n\n\nThe main JavaScript entry point of the plugin is main.js in the static folder. This contains the RequireJS module definition of the plugin and the main logic. All other plugin logic can be implemented as a RequireJS module and loaded in the main module. The main module should have a dependency to the core, the Engage object. With this object you have access to main features of the core. See the Core Reference for more information about that.\n\n\nAfter the initialization process of the plugin, the plugin returns a plugin object with information about the plugin, like the type, the name, the ui template etc. This object is used by the core to decide about the UI type/location of plugin. The Core Reference describes the plugin object, before and after it is being processed by the core.\n\n\nHave a look to the code of a plugin to get an impression about the plugin implementation.\n\n\nModel View Controller Support\n\n\nThe Theodul player supports MVC design patterns for each plugin based on methods and objects of the BackboneJS library. It is not necessary to design a plugin in MVC style but it is highly recommended. An overview of the methods and objects of the BackboneJS library is listed on the official website of BackboneJS.\n\n\nEach plugin with a visual component has a reference to its view container and its template to fill the view container. Have a look at the Core Reference how to access the container and the template data. With this information the plugin can create a Backbone view with a reference to the to div container and a render function to compile the template.\n\n\nThe next step is the creation of a model, which is being bound to the view. An usual way is to create a Backbone model, which is being passed by the view. In the initialization function of the view, the view binds the model change event to his render function:\n\n\nBind the \"change\" event always to the render function of a view\n\n\n// bind the render function always to the view\n_.bindAll(this, \"render\");\n// listen for changes of the model and bind the render function to this\nthis.model.bind(\"change\", this.render);\n\n\n\nThe model can only be visible by the plugin itself or it can be added to the global Engage model of the core. Adding the model to the Engage model has the advantage, that on the one hand data can be used by other plugins and on the other hand it is able to listen to change- or add-events. So other plugins are able to listen to a change of data in another model and can react to it by e.g. re-render its view. This feature is e.g. used by the \"mhConnection\" custom plugin. The plugin receives data of Matterhorn endpoints and saves them to a model, which is being added to the Engage Model. Each time the plugin gets newer endpoint data and updates its model's data, each plugin gets a notification and can re-render its view.\n\n\nA typical way to add a model to the Engage model is to add the model in the initialization function of the plugin after all other initializations. Here is an example of the video plugin:\n\n\nAdd a custom model to the Engage Model\n\n\nEngage.model.set(\"videoDataModel\", new VideoDataModel(videoDisplays, videoSources, duration));\n\n\n\nIn the same initialization function an event handler should be added to notice the addition of the model. Has the model successfully been added, a view with this model and other data can be created:\n\n\nModel Event Handler\n\n\nEngage.model.on(\"change:videoDataModel\", function() {\n   new VideoDataView(this.get(\"videoDataModel\"), plugin.template, videojs_swf);\n});\n\n\n\nIf another plugin wants to use the defined \"videoDataModel\" model, it has to list it in its own initialization process:\n\n\nEngage.model.on(\"change:videoDataModel\", function() {\n   initCount -= 1;\n   if (initCount === 0) {\n      initPlugin();\n   }\n});\n\n\n\nHave a look at the full implementation of the VideoJS Plugin and the Controls Plugin to get an idea how the Backbone MVC design works. For completeness' sake, the \"Controller\" does not have an extra Object in the Backbone MVC design. The \"Controller\" is usually used as the render function in the view. This function can be very complex and should link to other functions, which are short and easy to be tested by the Jasmine Test Framework.",
            "title": "Player - Architecture"
        },
        {
            "location": "/modules/player.architecture/#architecture",
            "text": "",
            "title": "Architecture"
        },
        {
            "location": "/modules/player.architecture/#overview",
            "text": "The architecture of the theodul player has a plugin based structure based around a core. The core and the plugins have been realized as OSGi modules. Each plugin can be separately build.\nThe following figure shows the OSGi architecture of the player.   All Theodul OSGi modules are stored under:  modules/matterhorn-engage-theodul-*\n#Core module\nmodules/matterhorn-engage-theodul-api/\nmodules/matterhorn-engage-theodul-core/\n#A plugin module\nmodules/matterhorn-engage-theodul-plugin-*\nmodules/matterhorn-engage-theodul-plugin-tab-description/",
            "title": "Overview"
        },
        {
            "location": "/modules/player.architecture/#plugin-manager",
            "text": "The main workflow is implemented by the core, which recognizes new plugins, collects information about the plugin type and resources, runs the JavaScript logic and inserts the first compiled templates into the HTML DOM.\nThe Plugin Manager Endpoint recognizes the OSGi modules. Each plugin has some information about its name and its resources. The Plugin Manager collects these information and publishes them via a REST endpoint. The following URL links to an example REST endpoint:  http://localhost:8080/engage/theodul/manager/list.json  The documentation and test forms of the endpoint can be found on the Matterhorn start page. The following data in JSON shows an example list of plugins, which are used by the player and provided by the Plugin Manager Endpoint.  {\n  \"pluginlist\":{\n    \"plugins\":[\n    {\n      \"name\":\"EngagePluginTabSlidetext\",\n      \"id\":\"6\",\n      \"description\":\"Simple implementation of a tab with the text of the slides\",\n      \"static-path\":\"6\\/static\"\n    },\n    {\n      \"name\":\"EngagePluginControlsMockup\",\n      \"id\":\"5\",\n      \"description\":\"Simple implementation of a control bar\",\n      \"static-path\":\"5\\/static\"\n    }]\n  }\n}  Next to the Plugin Manager there is the Theodul Core module, which publishes the main HTML page, core.html.",
            "title": "Plugin Manager"
        },
        {
            "location": "/modules/player.architecture/#ui-core",
            "text": "The  core.html  is the main entry point and starts the Javascript core logic. Following listing shows the directory structure of core in the  matterhorn-engage-theodul-core OSGi  module.  |-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------spec  All Theodul JavaScript components are defined as a RequireJS module. The file engage_init.js is loaded firstly and contains the configuration of RequireJS. This init script additionally loads the core module, which is defined in the engage_core.js.  The core module initializes the main HTML view. This view is realized as a BackboneJS view and is linked to a global Backbone model, which is stored in the model module in engage_model.js. The view is returned by the core module, so every other module, which has a dependency to the core module, has a reference to the view (simply called \"Engage\" in the plugins) and it's functions. See the Core Reference for more information about the functions of the core view.",
            "title": "UI Core"
        },
        {
            "location": "/modules/player.architecture/#plugins",
            "text": "Plugins in the Theodul player are developed and distributed in own OSGi modules. Every plugin has a special UI type. In dependency of this type the core injects the plugin to the right position of the player. The following plugin types are possible:     Plugin Type  Description  Characteristics  Module Name  JS Plugin Type Name  Maven Plugin Type Name      Controls  Implements the main controls of the top of the player  Only one plugin per player possible.  matterhorn-engage-theodul-plugin-controls  engage_controls  controls    Timeline  Timeline information below the main controls.  Good for processing time-based data like user tracking, slide previews or annotations.  Optional plugin, more than one possible.  matterhorn-engage-theodul-plugin-timeline-  engage_timeline  timeline    Videodisplay  Implementation of the video display.  Currently only one plugin per player possible, but in the future more video displays should be possible.  matterhorn-engage-theodul-plugin-video-  engage_video  video    Description/Label  A plugin below the video display, good to show simple information about the video, like a title and the creator.  Only one plugin per player possible.  matterhorn-engage-theodul-plugin-description  engage_description  description    Tab  Shows a tab in the tab view at the bottom of the player.  Optional plugin, more than one possible.  matterhorn-engage-theodul-plugin-tab-  engage_tab  tab    Custom  A custom plugin without a relationship to an UI element.  Good for a custom REST endpoint, global data representation or to load custom JS code or libraries.  Optional plugin, more than one possible.  No connection to a preserved UI element.  matterhorn-engage-theodul-plugin-custom-     The following listing shows the directory structure of a plugin module:  |-src\n|---main\n|-----java\n|-------org\n|---------opencastproject\n|-----------engage\n|-------------theodul\n|---------------plugin\n|-----------------controls  #Simple Java class, and optional REST endpoint\n|-----resources\n|-------OSGI-INF            #OSGi information about the plugin\n|-------static              #web ressources, contains the main.js entry point of the plugin\n|---------images            #plugin ressources\n|---------js                #plugin js libs\n|-----------bootstrap\n|-----------jqueryui\n|---test                    #Jasmine test ressources\n|-----resources\n|-------js\n|---------engage            #Test Wrapper of the core\n|---------lib               #Required test libs\n|---------spec              #Jasmine test specs  The main JavaScript entry point of the plugin is main.js in the static folder. This contains the RequireJS module definition of the plugin and the main logic. All other plugin logic can be implemented as a RequireJS module and loaded in the main module. The main module should have a dependency to the core, the Engage object. With this object you have access to main features of the core. See the Core Reference for more information about that.  After the initialization process of the plugin, the plugin returns a plugin object with information about the plugin, like the type, the name, the ui template etc. This object is used by the core to decide about the UI type/location of plugin. The Core Reference describes the plugin object, before and after it is being processed by the core.  Have a look to the code of a plugin to get an impression about the plugin implementation.",
            "title": "Plugins"
        },
        {
            "location": "/modules/player.architecture/#model-view-controller-support",
            "text": "The Theodul player supports MVC design patterns for each plugin based on methods and objects of the BackboneJS library. It is not necessary to design a plugin in MVC style but it is highly recommended. An overview of the methods and objects of the BackboneJS library is listed on the official website of BackboneJS.  Each plugin with a visual component has a reference to its view container and its template to fill the view container. Have a look at the Core Reference how to access the container and the template data. With this information the plugin can create a Backbone view with a reference to the to div container and a render function to compile the template.  The next step is the creation of a model, which is being bound to the view. An usual way is to create a Backbone model, which is being passed by the view. In the initialization function of the view, the view binds the model change event to his render function:  Bind the \"change\" event always to the render function of a view  // bind the render function always to the view\n_.bindAll(this, \"render\");\n// listen for changes of the model and bind the render function to this\nthis.model.bind(\"change\", this.render);  The model can only be visible by the plugin itself or it can be added to the global Engage model of the core. Adding the model to the Engage model has the advantage, that on the one hand data can be used by other plugins and on the other hand it is able to listen to change- or add-events. So other plugins are able to listen to a change of data in another model and can react to it by e.g. re-render its view. This feature is e.g. used by the \"mhConnection\" custom plugin. The plugin receives data of Matterhorn endpoints and saves them to a model, which is being added to the Engage Model. Each time the plugin gets newer endpoint data and updates its model's data, each plugin gets a notification and can re-render its view.  A typical way to add a model to the Engage model is to add the model in the initialization function of the plugin after all other initializations. Here is an example of the video plugin:",
            "title": "Model View Controller Support"
        },
        {
            "location": "/modules/player.architecture/#add-a-custom-model-to-the-engage-model",
            "text": "Engage.model.set(\"videoDataModel\", new VideoDataModel(videoDisplays, videoSources, duration));  In the same initialization function an event handler should be added to notice the addition of the model. Has the model successfully been added, a view with this model and other data can be created:  Model Event Handler  Engage.model.on(\"change:videoDataModel\", function() {\n   new VideoDataView(this.get(\"videoDataModel\"), plugin.template, videojs_swf);\n});  If another plugin wants to use the defined \"videoDataModel\" model, it has to list it in its own initialization process:  Engage.model.on(\"change:videoDataModel\", function() {\n   initCount -= 1;\n   if (initCount === 0) {\n      initPlugin();\n   }\n});  Have a look at the full implementation of the VideoJS Plugin and the Controls Plugin to get an idea how the Backbone MVC design works. For completeness' sake, the \"Controller\" does not have an extra Object in the Backbone MVC design. The \"Controller\" is usually used as the render function in the view. This function can be very complex and should link to other functions, which are short and easy to be tested by the Jasmine Test Framework.",
            "title": "Add a custom model to the Engage Model"
        },
        {
            "location": "/modules/player.configuration/",
            "text": "Opencast 2.0 Player Configuration\n\n\nThe Opencast 2.0 Player (aka Theodul Pass Player) is the new default player in 2.0. The old engage player from 1.x is still available too.\n\n\nThe configurations for the player are done for each tenant. So the configuration keys are located in \n<felix_home>/etc/load/org.opencastproject.organization-mh_default_org.cfg\n.\n\n\nSelect the Opencast 2.0 Player\n\n\nTo activate the player set:\n\n\nprop.player=/engage/theodul/ui/core.html\n\n\n\nConfiguration\n\n\nLogo\n\n\nThe logo in the top right can easily be replaced by changing the path or URL for logo small.\n\n\nprop.logo_player=/engage/ui/img/mh_logos/OpencastLogo.png\n\n\n\nOptions:\n\n\n\n\nAny URL or local path to a PNG, GIF, JPG image. Default displayed hight in the browser 36px.\n\n\n\n\nPosition of the controls\n\n\nThe basic controls for the player can be placed over or under the video display.\n\n\nprop.player.positioncontrols=bottom\n\n\n\nOptions:\n\n\n\n\ntop\n\n\nbottom\n\n\n\n\nMain video flavor\n\n\nThe default flavor of the master video (the video on the \"left side\" in the video display). This source also provides the audio. You can change this to every falvor that your installation might provide. If no mastervideotype was selected, or the mastervideotype is not available the videos are taken in their sequence within the mediapackage.\n\n\nprop.player.mastervideotype=presenter/delivery\n\n\n\nOptions (default flavors):\n\n\n\n\npresenter/delivery\n\n\npresentation/delivery\n\n\n\n\nShow Embed links\n\n\nThe player can show a dialog with links to the current video that can be embeded into other websites. This function can be disabled\n\n\nprop.show_embed_links=true\n\n\n\nOptions:\n\n\n\n\ntrue\n\n\nfalse\n\n\n\n\nLink to Media Module\n\n\nIf you don't want to use the Opencast Media Module the link within the player back to the overview of the recordings can be disabled\n\n\nprop.link_mediamodule=true\n\n\n\nOptions:\n\n\n\n\ntrue\n\n\nfalse\n\n\n\n\nKeyboard Shortcuts\n\n\nThe keyboard shortcuts in the player can be customized\n\n\nprop.player.shortcut.playPause=space\nprop.player.shortcut.seekRight=right\nprop.player.shortcut.seekLeft=left\nprop.player.shortcut.playbackrateIncrease=mod+9\nprop.player.shortcut.playbackrateDecrease=mod+8\nprop.player.shortcut.muteToggle=m\nprop.player.shortcut.volUp=9\nprop.player.shortcut.volDown=8\nprop.player.shortcut.fullscreenEnable=mod+enter\nprop.player.shortcut.fullscreenCancel=escape\nprop.player.shortcut.jumpToBegin=backspace\nprop.player.shortcut.prevChapter=pagedown\nprop.player.shortcut.nextChapter=pageup",
            "title": "Player - Configuration"
        },
        {
            "location": "/modules/player.configuration/#opencast-20-player-configuration",
            "text": "The Opencast 2.0 Player (aka Theodul Pass Player) is the new default player in 2.0. The old engage player from 1.x is still available too.  The configurations for the player are done for each tenant. So the configuration keys are located in  <felix_home>/etc/load/org.opencastproject.organization-mh_default_org.cfg .",
            "title": "Opencast 2.0 Player Configuration"
        },
        {
            "location": "/modules/player.configuration/#select-the-opencast-20-player",
            "text": "To activate the player set:  prop.player=/engage/theodul/ui/core.html",
            "title": "Select the Opencast 2.0 Player"
        },
        {
            "location": "/modules/player.configuration/#configuration",
            "text": "",
            "title": "Configuration"
        },
        {
            "location": "/modules/player.configuration/#logo",
            "text": "The logo in the top right can easily be replaced by changing the path or URL for logo small.  prop.logo_player=/engage/ui/img/mh_logos/OpencastLogo.png  Options:   Any URL or local path to a PNG, GIF, JPG image. Default displayed hight in the browser 36px.",
            "title": "Logo"
        },
        {
            "location": "/modules/player.configuration/#position-of-the-controls",
            "text": "The basic controls for the player can be placed over or under the video display.  prop.player.positioncontrols=bottom  Options:   top  bottom",
            "title": "Position of the controls"
        },
        {
            "location": "/modules/player.configuration/#main-video-flavor",
            "text": "The default flavor of the master video (the video on the \"left side\" in the video display). This source also provides the audio. You can change this to every falvor that your installation might provide. If no mastervideotype was selected, or the mastervideotype is not available the videos are taken in their sequence within the mediapackage.  prop.player.mastervideotype=presenter/delivery  Options (default flavors):   presenter/delivery  presentation/delivery",
            "title": "Main video flavor"
        },
        {
            "location": "/modules/player.configuration/#show-embed-links",
            "text": "The player can show a dialog with links to the current video that can be embeded into other websites. This function can be disabled  prop.show_embed_links=true  Options:   true  false",
            "title": "Show Embed links"
        },
        {
            "location": "/modules/player.configuration/#link-to-media-module",
            "text": "If you don't want to use the Opencast Media Module the link within the player back to the overview of the recordings can be disabled  prop.link_mediamodule=true  Options:   true  false",
            "title": "Link to Media Module"
        },
        {
            "location": "/modules/player.configuration/#keyboard-shortcuts",
            "text": "The keyboard shortcuts in the player can be customized  prop.player.shortcut.playPause=space\nprop.player.shortcut.seekRight=right\nprop.player.shortcut.seekLeft=left\nprop.player.shortcut.playbackrateIncrease=mod+9\nprop.player.shortcut.playbackrateDecrease=mod+8\nprop.player.shortcut.muteToggle=m\nprop.player.shortcut.volUp=9\nprop.player.shortcut.volDown=8\nprop.player.shortcut.fullscreenEnable=mod+enter\nprop.player.shortcut.fullscreenCancel=escape\nprop.player.shortcut.jumpToBegin=backspace\nprop.player.shortcut.prevChapter=pagedown\nprop.player.shortcut.nextChapter=pageup",
            "title": "Keyboard Shortcuts"
        },
        {
            "location": "/modules/player.core.reference/",
            "text": "Core Reference\n\n\nEngage Core\n\n\nRequireJS Path\n\n\n'engage/engage_core'\n\n\n\nInherited object functions of the BackboneJS view, see http://backbonejs.org/#View\n\n\nAdded object functions and properties:\n\n\n\n\n\n\n\n\nName\n\n\nParameters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nlog(value):void\n\n\nvalue:String\n\n\nfunction\n\n\nfunction to log via the core cross browser\n\n\n\n\n\n\nEvent:EngageEvent\n\n\nnone\n\n\nproperty\n\n\nReturns the EngageEvent object prototype, the see EngageEvent Object for more information\n\n\n\n\n\n\ntrigger(event):void\n\n\nevent:EngageEvent\n\n\nfunction\n\n\ntriggers an EngageEvent\n\n\n\n\n\n\non(event, handler, context):void\n\n\nevent:EngageEvent, handler:function, context:object\n\n\nfunction\n\n\ninstall an event handler on a EngageEvent\n\n\n\n\n\n\nmodel:EngageModel\n\n\nnone\n\n\nproperty\n\n\nReturns the singleton engage model for this session, see EngageModel for more information's\n\n\n\n\n\n\ngetPluginPath(pluginName):String\n\n\npluginName:String\n\n\nfunction\n\n\nReturns the absolute path of a plugin by name.\n\n\n\n\n\n\n\n\nEngageEvent Object\n\n\n\n\n\n\n\n\nName\n\n\nParamters\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nEngageEvent(name, description, type)\n\n\nname:String, description:String, type:String\n\n\nconstructor\n\n\nCreate a new unbound EngageEvent, with a name, description and a type. For Example: var myEvent = new EngageEvent('play', 'plays the video', 'trigger')\n\n\n\n\n\n\ngetName:String\n\n\nnone\n\n\nfunction\n\n\nGets the name\n\n\n\n\n\n\ngetDescription:String\n\n\nnone\n\n\nfunction\n\n\nGets the description\n\n\n\n\n\n\ngetType:String\n\n\nnone\n\n\nfunction\n\n\nGets the Type, can be a \"handler\", \"trigger\" or \"both\"\n\n\n\n\n\n\ntoString:String\n\n\nnone\n\n\nfunction\n\n\nBuild a string that describes the event\n\n\n\n\n\n\n\n\nEngage Model\n\n\nInherited object functions of the BackboneJS model, see http://backbonejs.org/#Model, how to use BackboneJS models. This model is a global singleton object and can be used by each plugin to add new models which can be used by another plugin again.\n\n\nNo special functions are added, but the model is filled with some default data. This default data can be used by each plugin, which has a reference to the EngageModel.\n\n\n\n\n\n\n\n\nProperty Name\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\npluginsInfo\n\n\nBackbone Model\n\n\nContains Information's of each plugin\n\n\n\n\n\n\npluginModels\n\n\nBackbone Collection\n\n\nContains the plugin models\n\n\n\n\n\n\nurlParameters\n\n\nObject\n\n\nContains the data of the URL parameters.\n\n\n\n\n\n\n\n\nPlugin Object\n\n\nEach plugin \nmust\n create and return a object with some properties which are set by the plugin itself. It is recommend to keep a reference to the object because some properties are set by the core after the plugin is processed.\n\n\n\n\n\n\n\n\nProperty Name\n\n\nType\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nname\n\n\nString\n\n\nName of the plugin, e.g. \"Engage Controls\". \nThis property is set by the plugin.\n\n\n\n\n\n\ntype\n\n\nString\n\n\nType of the plugin, e.g. \"engage_controls\", see the plugin table in Architecture for the other plugin types. \nThis property is set by the plugin.\n\n\n\n\n\n\nversion\n\n\nString\n\n\nVersion of plugin. \nThis property is set by the plugin.\n\n\n\n\n\n\nstyles\n\n\nArray of Strings\n\n\nArray of the paths of css files relative to the static folder of each plugin . \nThis property is set by the plugin.\n\n\n\n\n\n\ntemplate\n\n\nString\n\n\nBefore the plugin object is returned by the plugin logic, the template property contains the path to the template relative to the static folder. \nThe path property is set first by the plugin\n. After the plugin object is returned and the Theodul core processed the plugin, the template property is filled with the real template data and can be used to re-render the view.\n\n\n\n\n\n\ncontainer\n\n\nString\n\n\nContains the ID of the HTML div container, which contains the rendered template. This can be used to re-render the view. \nThis property is set by the core.\n\n\n\n\n\n\npluginPath\n\n\nString\n\n\nContains the absolute path of the plugin.  \nThis property is set by the core.\n\n\n\n\n\n\nevents\n\n\nObject\n\n\nContains all events which are used of this plugin. Each handled and each triggered event.",
            "title": "Player - Core Reference"
        },
        {
            "location": "/modules/player.core.reference/#core-reference",
            "text": "",
            "title": "Core Reference"
        },
        {
            "location": "/modules/player.core.reference/#engage-core",
            "text": "RequireJS Path  'engage/engage_core'  Inherited object functions of the BackboneJS view, see http://backbonejs.org/#View  Added object functions and properties:     Name  Parameters  Type  Description      log(value):void  value:String  function  function to log via the core cross browser    Event:EngageEvent  none  property  Returns the EngageEvent object prototype, the see EngageEvent Object for more information    trigger(event):void  event:EngageEvent  function  triggers an EngageEvent    on(event, handler, context):void  event:EngageEvent, handler:function, context:object  function  install an event handler on a EngageEvent    model:EngageModel  none  property  Returns the singleton engage model for this session, see EngageModel for more information's    getPluginPath(pluginName):String  pluginName:String  function  Returns the absolute path of a plugin by name.",
            "title": "Engage Core"
        },
        {
            "location": "/modules/player.core.reference/#engageevent-object",
            "text": "Name  Paramters  Type  Description      EngageEvent(name, description, type)  name:String, description:String, type:String  constructor  Create a new unbound EngageEvent, with a name, description and a type. For Example: var myEvent = new EngageEvent('play', 'plays the video', 'trigger')    getName:String  none  function  Gets the name    getDescription:String  none  function  Gets the description    getType:String  none  function  Gets the Type, can be a \"handler\", \"trigger\" or \"both\"    toString:String  none  function  Build a string that describes the event",
            "title": "EngageEvent Object"
        },
        {
            "location": "/modules/player.core.reference/#engage-model",
            "text": "Inherited object functions of the BackboneJS model, see http://backbonejs.org/#Model, how to use BackboneJS models. This model is a global singleton object and can be used by each plugin to add new models which can be used by another plugin again.  No special functions are added, but the model is filled with some default data. This default data can be used by each plugin, which has a reference to the EngageModel.     Property Name  Type  Description      pluginsInfo  Backbone Model  Contains Information's of each plugin    pluginModels  Backbone Collection  Contains the plugin models    urlParameters  Object  Contains the data of the URL parameters.",
            "title": "Engage Model"
        },
        {
            "location": "/modules/player.core.reference/#plugin-object",
            "text": "Each plugin  must  create and return a object with some properties which are set by the plugin itself. It is recommend to keep a reference to the object because some properties are set by the core after the plugin is processed.     Property Name  Type  Description      name  String  Name of the plugin, e.g. \"Engage Controls\".  This property is set by the plugin.    type  String  Type of the plugin, e.g. \"engage_controls\", see the plugin table in Architecture for the other plugin types.  This property is set by the plugin.    version  String  Version of plugin.  This property is set by the plugin.    styles  Array of Strings  Array of the paths of css files relative to the static folder of each plugin .  This property is set by the plugin.    template  String  Before the plugin object is returned by the plugin logic, the template property contains the path to the template relative to the static folder.  The path property is set first by the plugin . After the plugin object is returned and the Theodul core processed the plugin, the template property is filled with the real template data and can be used to re-render the view.    container  String  Contains the ID of the HTML div container, which contains the rendered template. This can be used to re-render the view.  This property is set by the core.    pluginPath  String  Contains the absolute path of the plugin.   This property is set by the core.    events  Object  Contains all events which are used of this plugin. Each handled and each triggered event.",
            "title": "Plugin Object"
        },
        {
            "location": "/modules/player.events/",
            "text": "Theodul Pass Player - Events\n\n\nA Theodul Pass Player plugin can trigger and/or subscribe to events.\n\n\nAn event is defined in the events section of the plugin and looks like this:\n\n\nNAME: new Engage.Event(\"MODULE:NAME\", \"DESCRIPTION\", \"OPTION\")\n\n\n\nThe event has the event name \"MODULE:NAME\", the description DESCRIPTION and one of the options \"trigger\", \"handler\" or \"both\" as OPTION. When the plugin just triggers the event, the option is \"trigger\", when it just handles the events the option is \"handler\" and when it does both - trigger and handle it - the option is \"both\".\n\n\nAn event can be triggered via\n\n\nEngage.trigger(plugin.events.NAME.getName(), [parameter(s)]);\n\n\n\nand can be subscribed to via\n\n\nEngage.on(plugin.events.NAME.getName(), function () {});\n\n\n\nThe following list contains all events of the Core + of all official plugins, sorted alphabetically after \"Event name\" for version 1.0 of Feb 12, 2015.\n\n\nCurrently official plugins are\n\n\n\n\nControls\n\n\nMHConnection\n\n\nNotifications\n\n\nUsertracking\n\n\nDescription\n\n\nDescription (Tab)\n\n\nSlide text (Tab)\n\n\nShortcuts (Tab)\n\n\nTimeline statistics\n\n\nVideodisplay\n\n\n\n\n\n\n\n\n\n\nName\n\n\nEvent name\n\n\nAdditional parameters\n\n\nDescription\n\n\nTriggered in\n\n\nHandled in\n\n\n\n\n\n\n\n\n\n\ncoreInit\n\n\nCore:init\n\n\n\n\n\n\nCore\n\n\n\n\n\n\n\n\nplugin_load_done\n\n\nCore:plugin_load_done\n\n\n\n\n\n\nCore\n\n\nCore, Controls, MHConnection, Notifications, Usertracking, Description, Description (Tab), Slide text (Tab), Shortcuts (Tab), Timeline statistics, Videodisplay\n\n\n\n\n\n\ntimelineplugin_closed\n\n\nEngage:timelineplugin_closed\n\n\nNote: No \"Engage Event\", just use as string, example: Engage.on(\"Engage:timelineplugin_closed\", function() {});\n\n\nwhen the timeline plugin container closed\n\n\nCore\n\n\n\n\n\n\n\n\ntimelineplugin_opened\n\n\nEngage:timelineplugin_opened\n\n\nNote: No \"Engage Event\", just use as string, example: Engage.on(\"Engage:timelineplugin_opened\", function() {});\n\n\nwhen the timeline plugin container opened\n\n\nCore\n\n\nTimeline statistics\n\n\n\n\n\n\ngetMediaInfo\n\n\nMhConnection:getMediaInfo\n\n\n\n\n\n\n\n\nMHConnection\n\n\n\n\n\n\ngetMediaPackage\n\n\nMhConnection:getMediaPackage\n\n\n\n\n\n\n\n\nMHConnection\n\n\n\n\n\n\nmediaPackageModelError\n\n\nMhConnection:mediaPackageModelError\n\n\n\n\n\n\nMHConnection\n\n\nCore, Controls, Notifications, Usertracking, Description, Description (Tab), Slide text (Tab), Shortcuts (Tab), Timeline statistics, Videodisplay\n\n\n\n\n\n\ncustomError\n\n\nNotification:customError\n\n\nmsg: The message to display\n\n\nan error occurred\n\n\nCore, Controls, Videodisplay\n\n\nNotifications\n\n\n\n\n\n\ncustomNotification\n\n\nNotification:customNotification\n\n\nmsg: The message to display\n\n\na custom message\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\ncustomOKMessage\n\n\nNotification:customOKMessage\n\n\nmsg: The message to display\n\n\na custom message with an OK button\n\n\nControls\n\n\nNotifications\n\n\n\n\n\n\ncustomSuccess\n\n\nNotification:customSuccess\n\n\nmsg: The message to display\n\n\na custom success message\n\n\nCore, Controls\n\n\nNotifications\n\n\n\n\n\n\nsegmentMouseout\n\n\nSegment:mouseOut\n\n\nno: Segment number\n\n\nthe mouse is off a segment\n\n\nControls, Slide text (Tab)\n\n\nControls, Slide text (Tab)\n\n\n\n\n\n\nsegmentMouseover\n\n\nSegment:mouseOver\n\n\nno: Segment number\n\n\nthe mouse is over a segment\n\n\nControls, Slide text (Tab)\n\n\nControls, Slide text (Tab)\n\n\n\n\n\n\nsliderMousein\n\n\nSlider:mouseIn\n\n\n\n\nthe mouse entered the slider\n\n\nControls\n\n\n\n\n\n\n\n\nsliderMouseout\n\n\nSlider:mouseOut\n\n\n\n\nthe mouse is off the slider\n\n\nControls\n\n\n\n\n\n\n\n\nsliderMousemove\n\n\nSlider:mouseMoved\n\n\ntimeInMs: The time on the hovered position in ms\n\n\nthe mouse is moving over the slider\n\n\nControls\n\n\n\n\n\n\n\n\nsliderStart\n\n\nSlider:start\n\n\n\n\nslider started\n\n\nControls\n\n\n\n\n\n\n\n\nsliderStop\n\n\nSlider:stop\n\n\ntime: The time the slider stopped at\n\n\nslider stopped\n\n\nControls\n\n\nVideodisplay\n\n\n\n\n\n\naspectRatioSet\n\n\nVideo:aspectRatioSet\n\n\nas: (array) as[0] = width, as[1] = height, as[2] = aspect ratio in %\n\n\nthe aspect ratio has been calculated\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\naudioCodecNotSupported\n\n\nVideo:audioCodecNotSupported\n\n\n\n\nwhen the audio codec seems not to be supported by the browser\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\nautoplay\n\n\nVideo:autoplay\n\n\n\n\nautoplay the video\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nbufferedAndAutoplaying\n\n\nVideo:bufferedAndAutoplaying\n\n\n\n\nbuffering successful, was playing, autoplaying now\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\nbufferedButNotAutoplaying\n\n\nVideo:bufferedButNotAutoplaying\n\n\n\n\nbuffering successful, was not playing, not autoplaying now\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\nbuffering\n\n\nVideo:buffering\n\n\n\n\nvideo is buffering\n\n\nVideodisplay\n\n\nNotifications\n\n\n\n\n\n\nended\n\n\nVideo:ended\n\n\ntriggeredByMaster: Whether or not the event has been triggered by master\n\n\nvideo ended\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\nfullscreenCancel\n\n\nVideo:fullscreenCancel\n\n\n\n\ncancel fullscreen\n\n\nControls, Videodisplay\n\n\nVideodisplay\n\n\n\n\n\n\nfullscreenChange\n\n\nVideo:fullscreenChange\n\n\n\n\na fullscreen change happened\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\nfullscreenEnable\n\n\nVideo:fullscreenEnable\n\n\n\n\nenable fullscreen\n\n\nControls, Core\n\n\nControls, Videodisplay\n\n\n\n\n\n\nisAudioOnly\n\n\nVideo:isAudioOnly\n\n\naudio: true if audio only, false else\n\n\nwhether it's audio only or not\n\n\nVideodisplay\n\n\nControls, Notifications\n\n\n\n\n\n\ninitialSeek\n\n\nVideo:initialSeek\n\n\ntime: The time to seek to\n\n\nSeeks initially after all plugins have been loaded after a short delay\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nmute\n\n\nVideo:mute\n\n\n\n\nmute\n\n\nVideodisplay\n\n\nVideodisplay\n\n\n\n\n\n\nmuteToggle\n\n\nVideo:muteToggle\n\n\n\n\ntoggle mute and unmute\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nnextChapter\n\n\nVideo:nextChapter\n\n\n\n\nCore\n\n\n\n\n\n\n\n\n\n\nnumberOfVideodisplaysSet\n\n\nVideo:numberOfVideodisplaysSet\n\n\nno: Number of videodisplays\n\n\nthe number of videodisplays has been set\n\n\nVideodisplay\n\n\n\n\n\n\n\n\npause\n\n\nVideo:pause\n\n\ntriggeredByMaster: Whether or not the event has been triggered by master\n\n\npauses the video\n\n\n\n\n\n\n\n\n\n\nCore, Controls, Videodisplay\n\n\nControls, Videodisplay\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplay\n\n\nVideo:play\n\n\ntriggeredByMaster: Whether or not the event has been triggered by master\n\n\nplays the video\n\n\nCore, Controls, Videodisplay\n\n\nControls,Videodisplay\n\n\n\n\n\n\nplayPause\n\n\nVideo:playPause\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\npreviousChapter\n\n\nVideo:previousChapter\n\n\n\n\n\n\nCore\n\n\n\n\n\n\n\n\nplaybackRateChanged\n\n\nVideo:playbackRateChanged\n\n\nrate: The video playback rate (0.0-x, default: 1.0)\n\n\nThe video playback rate changed\n\n\nControls\n\n\nControls, Videodisplay\n\n\n\n\n\n\nplaybackRateIncrease\n\n\nVideo:playbackRateIncrease\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nplaybackRateDecrease\n\n\nVideo:playbackRateDecrease\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nplayerLoaded\n\n\nVideo:playerLoaded\n\n\n\n\nplayer loaded successfully\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nready\n\n\nVideo:ready\n\n\n\n\nall videos loaded successfully\n\n\nVideodisplay\n\n\nControls, Notifications\n\n\n\n\n\n\nseek\n\n\nVideo:seek\n\n\ntime: Current time in seconds  seek video to a given position in seconds\n\n\nCore, Controls, Slide text (Tab)\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nseekLeft\n\n\nVideo:seekLeft\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nseekRight\n\n\nVideo:seekRight\n\n\n\n\n\n\nCore\n\n\nVideodisplay\n\n\n\n\n\n\nsynchronizing\n\n\nVideo:synchronizing\n\n\n\n\nsynchronizing videos with the master video\n\n\nVideodisplay\n\n\n\n\n\n\n\n\ntimeupdate\n\n\nVideo:timeupdate\n\n\ntime: Current time in seconds, triggeredByMaster: Whether or not the event has been triggered by master\n\n\na timeupdate happened\n\n\nVideodisplay\n\n\nControls, Usertracking\n\n\n\n\n\n\nqualitySet\n\n\nVideo:qualitySet\n\n\nquality: the quality that has been set a video quality has been set\n\n\nControls\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nunmute\n\n\nVideo:unmute\n\n\n\n\nunmute\n\n\nControls\n\n\nControls\n\n\n\n\n\n\nusingFlash\n\n\nVideo:usingFlash\n\n\nflash: true if flash is being used, false else\n\n\nflash is being used\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\nvideoFormatsFound\n\n\nVideo:videoFormatsFound\n\n\nformat: array of video formats if different video formats (qualities) have been found\n\n\nVideodisplay\n\n\nControls\n\n\n\n\n\n\n\n\nvolumechange\n\n\nVideo:volumechange\n\n\nvol: Current volume (0 is off (muted), 1.0 is all the way up, 0.5 is half way)\n\n\na volume change happened\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nvolumeDown\n\n\nVideo:volumeDown\n\n\n\n\n\n\nCore\n\n\nControls\n\n\n\n\n\n\nvolumeGet\n\n\nVideo:volumeGet\n\n\ncallback: A callback function with the current volume as a parameter\n\n\nget the volume\n\n\nVideodisplay\n\n\n\n\n\n\n\n\nvolumeSet\n\n\nVideo:volumeSet\n\n\npercentAsDecimal: Volume to set (0 is off (muted), 1.0 is all the way up, 0.5 is half way)\n\n\nset the volume\n\n\nControls\n\n\nControls, Videodisplay\n\n\n\n\n\n\nvolumeUp\n\n\nVideo:volumeUp\n\n\n\n\n\n\nCore\n\n\nControls",
            "title": "Player - Events"
        },
        {
            "location": "/modules/player.events/#theodul-pass-player-events",
            "text": "A Theodul Pass Player plugin can trigger and/or subscribe to events.  An event is defined in the events section of the plugin and looks like this:  NAME: new Engage.Event(\"MODULE:NAME\", \"DESCRIPTION\", \"OPTION\")  The event has the event name \"MODULE:NAME\", the description DESCRIPTION and one of the options \"trigger\", \"handler\" or \"both\" as OPTION. When the plugin just triggers the event, the option is \"trigger\", when it just handles the events the option is \"handler\" and when it does both - trigger and handle it - the option is \"both\".  An event can be triggered via  Engage.trigger(plugin.events.NAME.getName(), [parameter(s)]);  and can be subscribed to via  Engage.on(plugin.events.NAME.getName(), function () {});  The following list contains all events of the Core + of all official plugins, sorted alphabetically after \"Event name\" for version 1.0 of Feb 12, 2015.  Currently official plugins are   Controls  MHConnection  Notifications  Usertracking  Description  Description (Tab)  Slide text (Tab)  Shortcuts (Tab)  Timeline statistics  Videodisplay      Name  Event name  Additional parameters  Description  Triggered in  Handled in      coreInit  Core:init    Core     plugin_load_done  Core:plugin_load_done    Core  Core, Controls, MHConnection, Notifications, Usertracking, Description, Description (Tab), Slide text (Tab), Shortcuts (Tab), Timeline statistics, Videodisplay    timelineplugin_closed  Engage:timelineplugin_closed  Note: No \"Engage Event\", just use as string, example: Engage.on(\"Engage:timelineplugin_closed\", function() {});  when the timeline plugin container closed  Core     timelineplugin_opened  Engage:timelineplugin_opened  Note: No \"Engage Event\", just use as string, example: Engage.on(\"Engage:timelineplugin_opened\", function() {});  when the timeline plugin container opened  Core  Timeline statistics    getMediaInfo  MhConnection:getMediaInfo     MHConnection    getMediaPackage  MhConnection:getMediaPackage     MHConnection    mediaPackageModelError  MhConnection:mediaPackageModelError    MHConnection  Core, Controls, Notifications, Usertracking, Description, Description (Tab), Slide text (Tab), Shortcuts (Tab), Timeline statistics, Videodisplay    customError  Notification:customError  msg: The message to display  an error occurred  Core, Controls, Videodisplay  Notifications    customNotification  Notification:customNotification  msg: The message to display  a custom message  Videodisplay  Notifications    customOKMessage  Notification:customOKMessage  msg: The message to display  a custom message with an OK button  Controls  Notifications    customSuccess  Notification:customSuccess  msg: The message to display  a custom success message  Core, Controls  Notifications    segmentMouseout  Segment:mouseOut  no: Segment number  the mouse is off a segment  Controls, Slide text (Tab)  Controls, Slide text (Tab)    segmentMouseover  Segment:mouseOver  no: Segment number  the mouse is over a segment  Controls, Slide text (Tab)  Controls, Slide text (Tab)    sliderMousein  Slider:mouseIn   the mouse entered the slider  Controls     sliderMouseout  Slider:mouseOut   the mouse is off the slider  Controls     sliderMousemove  Slider:mouseMoved  timeInMs: The time on the hovered position in ms  the mouse is moving over the slider  Controls     sliderStart  Slider:start   slider started  Controls     sliderStop  Slider:stop  time: The time the slider stopped at  slider stopped  Controls  Videodisplay    aspectRatioSet  Video:aspectRatioSet  as: (array) as[0] = width, as[1] = height, as[2] = aspect ratio in %  the aspect ratio has been calculated  Videodisplay  Controls    audioCodecNotSupported  Video:audioCodecNotSupported   when the audio codec seems not to be supported by the browser  Videodisplay  Notifications    autoplay  Video:autoplay   autoplay the video  Core  Videodisplay    bufferedAndAutoplaying  Video:bufferedAndAutoplaying   buffering successful, was playing, autoplaying now  Videodisplay  Notifications    bufferedButNotAutoplaying  Video:bufferedButNotAutoplaying   buffering successful, was not playing, not autoplaying now  Videodisplay  Notifications    buffering  Video:buffering   video is buffering  Videodisplay  Notifications    ended  Video:ended  triggeredByMaster: Whether or not the event has been triggered by master  video ended  Videodisplay  Controls    fullscreenCancel  Video:fullscreenCancel   cancel fullscreen  Controls, Videodisplay  Videodisplay    fullscreenChange  Video:fullscreenChange   a fullscreen change happened  Videodisplay  Controls    fullscreenEnable  Video:fullscreenEnable   enable fullscreen  Controls, Core  Controls, Videodisplay    isAudioOnly  Video:isAudioOnly  audio: true if audio only, false else  whether it's audio only or not  Videodisplay  Controls, Notifications    initialSeek  Video:initialSeek  time: The time to seek to  Seeks initially after all plugins have been loaded after a short delay  Core  Videodisplay    mute  Video:mute   mute  Videodisplay  Videodisplay    muteToggle  Video:muteToggle   toggle mute and unmute  Core  Videodisplay    nextChapter  Video:nextChapter   Core      numberOfVideodisplaysSet  Video:numberOfVideodisplaysSet  no: Number of videodisplays  the number of videodisplays has been set  Videodisplay     pause  Video:pause  triggeredByMaster: Whether or not the event has been triggered by master  pauses the video      Core, Controls, Videodisplay  Controls, Videodisplay        play  Video:play  triggeredByMaster: Whether or not the event has been triggered by master  plays the video  Core, Controls, Videodisplay  Controls,Videodisplay    playPause  Video:playPause    Core  Videodisplay    previousChapter  Video:previousChapter    Core     playbackRateChanged  Video:playbackRateChanged  rate: The video playback rate (0.0-x, default: 1.0)  The video playback rate changed  Controls  Controls, Videodisplay    playbackRateIncrease  Video:playbackRateIncrease    Core  Videodisplay    playbackRateDecrease  Video:playbackRateDecrease    Core  Videodisplay    playerLoaded  Video:playerLoaded   player loaded successfully  Videodisplay     ready  Video:ready   all videos loaded successfully  Videodisplay  Controls, Notifications    seek  Video:seek  time: Current time in seconds  seek video to a given position in seconds  Core, Controls, Slide text (Tab)  Videodisplay     seekLeft  Video:seekLeft    Core  Videodisplay    seekRight  Video:seekRight    Core  Videodisplay    synchronizing  Video:synchronizing   synchronizing videos with the master video  Videodisplay     timeupdate  Video:timeupdate  time: Current time in seconds, triggeredByMaster: Whether or not the event has been triggered by master  a timeupdate happened  Videodisplay  Controls, Usertracking    qualitySet  Video:qualitySet  quality: the quality that has been set a video quality has been set  Controls  Videodisplay     unmute  Video:unmute   unmute  Controls  Controls    usingFlash  Video:usingFlash  flash: true if flash is being used, false else  flash is being used  Videodisplay  Controls    videoFormatsFound  Video:videoFormatsFound  format: array of video formats if different video formats (qualities) have been found  Videodisplay  Controls     volumechange  Video:volumechange  vol: Current volume (0 is off (muted), 1.0 is all the way up, 0.5 is half way)  a volume change happened  Videodisplay     volumeDown  Video:volumeDown    Core  Controls    volumeGet  Video:volumeGet  callback: A callback function with the current volume as a parameter  get the volume  Videodisplay     volumeSet  Video:volumeSet  percentAsDecimal: Volume to set (0 is off (muted), 1.0 is all the way up, 0.5 is half way)  set the volume  Controls  Controls, Videodisplay    volumeUp  Video:volumeUp    Core  Controls",
            "title": "Theodul Pass Player - Events"
        },
        {
            "location": "/modules/player.storage/",
            "text": "How to store data in the browser persistently\n\n\nThe Theodul Pass Player uses basil.js for storing persistent data such as the volume and the playback rate.\n\n\nBasil.js unifies localstorage, cookies and session storage and provides an easy-to-use JavaScript API.\n\n\nExample Usage\n\n\nIn your plugin you just have to require the basil lib which is being distributed globally:\n\n\ndefine([..., \"basil\", ...], function(..., Basil, ...) {\n    ...\n}\n\n\n\nAfter that basil needs to be set up:\n\n\nvar basilOptions = {\n    namespace: 'mhStorage'\n};\nBasil = new window.Basil(basilOptions);\n\n\n\nThe default plugins have \"mhStorage\" as their namespace, feel free to set your own. The default storage is the localstorage; if the localstorage is not available, a cookie is being used and so on.\n\n\nAfter setting up basil, the usage is straightforward:\n\n\nBasil.set(\"someKey\", \"someValue); // set a value\nBasil.get(\"someKey\"); // get a value",
            "title": "Player - Storage"
        },
        {
            "location": "/modules/player.storage/#how-to-store-data-in-the-browser-persistently",
            "text": "The Theodul Pass Player uses basil.js for storing persistent data such as the volume and the playback rate.  Basil.js unifies localstorage, cookies and session storage and provides an easy-to-use JavaScript API.",
            "title": "How to store data in the browser persistently"
        },
        {
            "location": "/modules/player.storage/#example-usage",
            "text": "In your plugin you just have to require the basil lib which is being distributed globally:  define([..., \"basil\", ...], function(..., Basil, ...) {\n    ...\n}  After that basil needs to be set up:  var basilOptions = {\n    namespace: 'mhStorage'\n};\nBasil = new window.Basil(basilOptions);  The default plugins have \"mhStorage\" as their namespace, feel free to set your own. The default storage is the localstorage; if the localstorage is not available, a cookie is being used and so on.  After setting up basil, the usage is straightforward:  Basil.set(\"someKey\", \"someValue); // set a value\nBasil.get(\"someKey\"); // get a value",
            "title": "Example Usage"
        },
        {
            "location": "/modules/player.plugins/",
            "text": "Non-standard plugins\n\n\nThis page lists non-standard (3rd-party) plugins for the Matterhorn Engage Player in Matterhorn version 2.x (Theodul Pass Player).\n\n\nTo add one of the plugins to an existing installation, the normal approach is the following:\n\n\n\n\nDownload the jar file of the plugin\n\n\nCopy it into the Matterhorn \"/lib\" folder\n\n\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nAuthor\n\n\nLicense\n\n\nDownload\n\n\n\n\n\n\n\n\n\n\nDownload\n\n\nLists the available the video and audio sources in a tab.\n\n\nHenning Str\u00fcber, Denis Meyer\n\n\nGNU LGPL v2 or v3\n\n\nhttps://bitbucket.org/CallToPower/theodul-download-plugin\n\n\n\n\n\n\nSnow Showcase\n\n\nLet it snow in the player!\n\n\nDenis Meyer\n\n\nGNU LGPL v2 or v3\n\n\nhttps://bitbucket.org/CallToPower/theodul-snowshowcase-plugin",
            "title": "Player - Plugins"
        },
        {
            "location": "/modules/player.plugins/#non-standard-plugins",
            "text": "This page lists non-standard (3rd-party) plugins for the Matterhorn Engage Player in Matterhorn version 2.x (Theodul Pass Player).  To add one of the plugins to an existing installation, the normal approach is the following:   Download the jar file of the plugin  Copy it into the Matterhorn \"/lib\" folder      Name  Description  Author  License  Download      Download  Lists the available the video and audio sources in a tab.  Henning Str\u00fcber, Denis Meyer  GNU LGPL v2 or v3  https://bitbucket.org/CallToPower/theodul-download-plugin    Snow Showcase  Let it snow in the player!  Denis Meyer  GNU LGPL v2 or v3  https://bitbucket.org/CallToPower/theodul-snowshowcase-plugin",
            "title": "Non-standard plugins"
        },
        {
            "location": "/modules/player.plugin.development/",
            "text": "How To Create A New Plugin\n\n\nPlugin Archetype\n\n\nThe \nMaven Archetype Plugin\n provides a convenient mechanism for automatically generating projects. Project templates are called Archetypes and they are basically maven artifacts of a special kind of packaging, \u2018maven-archetype\u2019.\n\n\nWith the Theodul Plugin Archetype you can create a new plugin project in no time and start writing the plugin\u2019s business logic right away, without caring about the POM or SCR component declarations.\n\n\nInstallation\n\n\nThe Theodul Plugin Archetype is included in the Matterhorn source code (Theodul Player branch) in the modules directory. To make the artifact available on your system you need to install it like any other atrifacts. In the Matterhorn source directory type:\n\n\n> cd modules/matterhorn-engage-theodul-plugin-archetype\n> mvn install\n\n\n\nAfter successful build and installation the archetype is available in your system.\n\n\nGenerating a new plugin\n\n\nTo generate a new plugin project simply go to the modules directory inside the Matterhorn source directory and type:\n\n\n> mvn archetype:generate -DarchetypeGroupId=org.opencastproject -DarchetypeArtifactId=matterhorn-theodul-plugin\n\n\n\nProvided the archetype is installed maven will now ask you for the properties configuration for the new project:\n\n\n[INFO] Generating project in Interactive mode\n[INFO] Archetype [org.opencastproject:matterhorn-theodul-plugin:1.5-SNAPSHOT] found in catalog local\nDefine value for property 'groupId': : org.opencastproject\nDefine value for property 'artifactId': : matterhorn-engage-theodul-plugin-test\nDefine value for property 'version': 1.0-SNAPSHOT: : 1.5-SNAPSHOT\nDefine value for property 'package': org.opencastproject: : org.opencastproject.engage.theodul.plugin.custom.test\nDefine value for property 'plugin_description': : A test plugin\nDefine value for property 'plugin_name': : testName \nDefine value for property 'plugin_type': : custom\nDefine value for property 'plugin_version': : 0.1\nDefine value for property 'plugin_rest': : false\nConfirm properties configuration:\ngroupId: org.opencastproject\nartifactId: matterhorn-engage-theodul-plugin-test\nversion: 1.5-SNAPSHOT\npackage: org.opencastproject.engage.theodul.plugin.test\nplugin_description: A test plugin\nplugin_name: test\nplugin_rest: true\n Y: : y\n[INFO] ----------------------------------------------------------------------------\n[INFO] Using following parameters for creating project from Archetype: matterhorn-theodul-plugin:1.5-SNAPSHOT\n[INFO] ----------------------------------------------------------------------------\n[INFO] Parameter: groupId, Value: org.opencastproject\n[INFO] Parameter: artifactId, Value: matterhorn-engage-theodul-plugin-test\n[INFO] Parameter: version, Value: 1.5-SNAPSHOT\n[INFO] Parameter: package, Value: org.opencastproject.engage.theodul.plugin.test\n[INFO] Parameter: packageInPathFormat, Value: org/opencastproject/engage/theodul/plugin/test\n[INFO] Parameter: package, Value: org.opencastproject.engage.theodul.plugin.test\n[INFO] Parameter: version, Value: 1.5-SNAPSHOT\n[INFO] Parameter: plugin_description, Value: A test plugin\n[INFO] Parameter: plugin_name, Value: test\n[INFO] Parameter: groupId, Value: org.opencastproject\n[INFO] Parameter: plugin_rest, Value: true\n[INFO] Parameter: artifactId, Value: matterhorn-engage-theodul-plugin-test\n[INFO] project created from Archetype in dir: /home/wulff/code/UOS/plugin-archetype/test/matterhorn-engage-theodul-plugin-test\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 3:39.195s\n[INFO] Finished at: Thu Jan 23 15:48:37 CET 2014\n[INFO] Final Memory: 15M/308M\n[INFO] ------------------------------------------------------------------------\n\n\n\nThere you go, the newly created plugin project is waiting to be filled with life in the directory that is named after the atrifactId you entered before.\n\n\nProject Properties\n\n\nIn addition to the above explanation, here is a description of the properties you have to specify when generating a new project with the Theodul Plugin Archetype:\n\n\ngroupId\n\n\nMaven group ID. For the Matterhorn developers this is\n\n\norg.opencastproject\n\n\n\nartifactId\n\n\nMaven artifact ID. Name by which your project is identified as an artifact by maven. Think of it as the project name. It will also be used as the name for your projects root directory. During the course of the Theodul project the following naming scheme came up:\n\n\nmatterhorn-engage-theodul-plugin-<plugin type>-<plugin name>\n\n\n\nversion\n\n\nThe project version. For Matterhorn developers: simply put in the version of the Matterhorn source tree your are working on.\n\n\npackage\n\n\nThe Java package in which the source for the back end part of your plugin will live. The following scheme is used by the Theodul developers:\n\n\norg.opencastproject.engage.theodul.plugin.<plugin type>.<plugin name>\n\n\n\nplugin_version\n\n\nThe version of the plugin itself. This is not to be confused with the maven project version which will, for instance, be updated when the Matterhorn version changes.\n\n\nplugin_type\n\n\nThe type of the plugin to be created. See https://opencast.jira.com/wiki/display/MH/Architecture\nPossible types are: custom, controls, timeline, video, description, tab\n\n\nplugin_name\n\n\nThe name by which your plugin will be registered by the plugin manager when running.\n\n\nplugin_description\n\n\n(optional) A short description of the plugin. The description will be provided by the \nplugin list endpoint\n together with the other plugin data.\n\n\nplugin_rest\n\n\n(boolean) Whether or not the plugin should provide a Matterhorn Rest endpoint. If set to true, the Java class that makes up the back end part of your plugin will be augmented with the annotations necessary to work as a Rest endpoint provider in Matterhorn. Also an example endpoint (GET:sayHello) will be generated.\n\n\nExample Plugin\n\n\nHave a look at the \nsnow showcase example plugin (custom)\n.\n\n\nDebugging\n\n\nTo display debug information in the developer console, add the following parameters to the URL:\n\n\nDisplay debug information\n\n\n&debug=true\n\n\n\nDisplay event debug information\n\n\n&debugEvents=true",
            "title": "Player - Plugin Development"
        },
        {
            "location": "/modules/player.plugin.development/#how-to-create-a-new-plugin",
            "text": "",
            "title": "How To Create A New Plugin"
        },
        {
            "location": "/modules/player.plugin.development/#plugin-archetype",
            "text": "The  Maven Archetype Plugin  provides a convenient mechanism for automatically generating projects. Project templates are called Archetypes and they are basically maven artifacts of a special kind of packaging, \u2018maven-archetype\u2019.  With the Theodul Plugin Archetype you can create a new plugin project in no time and start writing the plugin\u2019s business logic right away, without caring about the POM or SCR component declarations.",
            "title": "Plugin Archetype"
        },
        {
            "location": "/modules/player.plugin.development/#installation",
            "text": "The Theodul Plugin Archetype is included in the Matterhorn source code (Theodul Player branch) in the modules directory. To make the artifact available on your system you need to install it like any other atrifacts. In the Matterhorn source directory type:  > cd modules/matterhorn-engage-theodul-plugin-archetype\n> mvn install  After successful build and installation the archetype is available in your system.",
            "title": "Installation"
        },
        {
            "location": "/modules/player.plugin.development/#generating-a-new-plugin",
            "text": "To generate a new plugin project simply go to the modules directory inside the Matterhorn source directory and type:  > mvn archetype:generate -DarchetypeGroupId=org.opencastproject -DarchetypeArtifactId=matterhorn-theodul-plugin  Provided the archetype is installed maven will now ask you for the properties configuration for the new project:  [INFO] Generating project in Interactive mode\n[INFO] Archetype [org.opencastproject:matterhorn-theodul-plugin:1.5-SNAPSHOT] found in catalog local\nDefine value for property 'groupId': : org.opencastproject\nDefine value for property 'artifactId': : matterhorn-engage-theodul-plugin-test\nDefine value for property 'version': 1.0-SNAPSHOT: : 1.5-SNAPSHOT\nDefine value for property 'package': org.opencastproject: : org.opencastproject.engage.theodul.plugin.custom.test\nDefine value for property 'plugin_description': : A test plugin\nDefine value for property 'plugin_name': : testName \nDefine value for property 'plugin_type': : custom\nDefine value for property 'plugin_version': : 0.1\nDefine value for property 'plugin_rest': : false\nConfirm properties configuration:\ngroupId: org.opencastproject\nartifactId: matterhorn-engage-theodul-plugin-test\nversion: 1.5-SNAPSHOT\npackage: org.opencastproject.engage.theodul.plugin.test\nplugin_description: A test plugin\nplugin_name: test\nplugin_rest: true\n Y: : y\n[INFO] ----------------------------------------------------------------------------\n[INFO] Using following parameters for creating project from Archetype: matterhorn-theodul-plugin:1.5-SNAPSHOT\n[INFO] ----------------------------------------------------------------------------\n[INFO] Parameter: groupId, Value: org.opencastproject\n[INFO] Parameter: artifactId, Value: matterhorn-engage-theodul-plugin-test\n[INFO] Parameter: version, Value: 1.5-SNAPSHOT\n[INFO] Parameter: package, Value: org.opencastproject.engage.theodul.plugin.test\n[INFO] Parameter: packageInPathFormat, Value: org/opencastproject/engage/theodul/plugin/test\n[INFO] Parameter: package, Value: org.opencastproject.engage.theodul.plugin.test\n[INFO] Parameter: version, Value: 1.5-SNAPSHOT\n[INFO] Parameter: plugin_description, Value: A test plugin\n[INFO] Parameter: plugin_name, Value: test\n[INFO] Parameter: groupId, Value: org.opencastproject\n[INFO] Parameter: plugin_rest, Value: true\n[INFO] Parameter: artifactId, Value: matterhorn-engage-theodul-plugin-test\n[INFO] project created from Archetype in dir: /home/wulff/code/UOS/plugin-archetype/test/matterhorn-engage-theodul-plugin-test\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 3:39.195s\n[INFO] Finished at: Thu Jan 23 15:48:37 CET 2014\n[INFO] Final Memory: 15M/308M\n[INFO] ------------------------------------------------------------------------  There you go, the newly created plugin project is waiting to be filled with life in the directory that is named after the atrifactId you entered before.",
            "title": "Generating a new plugin"
        },
        {
            "location": "/modules/player.plugin.development/#project-properties",
            "text": "In addition to the above explanation, here is a description of the properties you have to specify when generating a new project with the Theodul Plugin Archetype:",
            "title": "Project Properties"
        },
        {
            "location": "/modules/player.plugin.development/#groupid",
            "text": "Maven group ID. For the Matterhorn developers this is  org.opencastproject",
            "title": "groupId"
        },
        {
            "location": "/modules/player.plugin.development/#artifactid",
            "text": "Maven artifact ID. Name by which your project is identified as an artifact by maven. Think of it as the project name. It will also be used as the name for your projects root directory. During the course of the Theodul project the following naming scheme came up:  matterhorn-engage-theodul-plugin-<plugin type>-<plugin name>",
            "title": "artifactId"
        },
        {
            "location": "/modules/player.plugin.development/#version",
            "text": "The project version. For Matterhorn developers: simply put in the version of the Matterhorn source tree your are working on.",
            "title": "version"
        },
        {
            "location": "/modules/player.plugin.development/#package",
            "text": "The Java package in which the source for the back end part of your plugin will live. The following scheme is used by the Theodul developers:  org.opencastproject.engage.theodul.plugin.<plugin type>.<plugin name>",
            "title": "package"
        },
        {
            "location": "/modules/player.plugin.development/#plugin_version",
            "text": "The version of the plugin itself. This is not to be confused with the maven project version which will, for instance, be updated when the Matterhorn version changes.",
            "title": "plugin_version"
        },
        {
            "location": "/modules/player.plugin.development/#plugin_type",
            "text": "The type of the plugin to be created. See https://opencast.jira.com/wiki/display/MH/Architecture\nPossible types are: custom, controls, timeline, video, description, tab",
            "title": "plugin_type"
        },
        {
            "location": "/modules/player.plugin.development/#plugin_name",
            "text": "The name by which your plugin will be registered by the plugin manager when running.",
            "title": "plugin_name"
        },
        {
            "location": "/modules/player.plugin.development/#plugin_description",
            "text": "(optional) A short description of the plugin. The description will be provided by the  plugin list endpoint  together with the other plugin data.",
            "title": "plugin_description"
        },
        {
            "location": "/modules/player.plugin.development/#plugin_rest",
            "text": "(boolean) Whether or not the plugin should provide a Matterhorn Rest endpoint. If set to true, the Java class that makes up the back end part of your plugin will be augmented with the annotations necessary to work as a Rest endpoint provider in Matterhorn. Also an example endpoint (GET:sayHello) will be generated.",
            "title": "plugin_rest"
        },
        {
            "location": "/modules/player.plugin.development/#example-plugin",
            "text": "Have a look at the  snow showcase example plugin (custom) .",
            "title": "Example Plugin"
        },
        {
            "location": "/modules/player.plugin.development/#debugging",
            "text": "To display debug information in the developer console, add the following parameters to the URL:  Display debug information  &debug=true  Display event debug information  &debugEvents=true",
            "title": "Debugging"
        },
        {
            "location": "/modules/player.testing/",
            "text": "How To Test With Phantom.js and Jasmine\n\n\nIntegration Of Jasmine Into The Build Process (Maven)\n\n\nJasmine\n is integrated with the \njasmine-maven-plugin\n into the maven build process. Therefore only the pom.xml file will be enhanced by the following code, which specifies the \njasmine-maven-plugin\n as plugin for the build process. The configuration of the jasmine-maven-plugin is also done in this file. The meaning of every configuration parameter can be looked up on the jasmine-maven-plugin project page under this \nlink\n. The following configuration uses a the specRunnerTemplate  REQUIRE_JS in order to function properly with \nRequireJS\n. Further information about spec runner templates can be found \nhere\n. On the next build the needed dependencies will be automatically resolved just like it is in the nature of maven.\n\n\npom.xml\n\n\n<build>\n<plugins>\n    ...\n      <plugin>\n        <groupId>com.github.searls</groupId>\n        <artifactId>jasmine-maven-plugin</artifactId>\n        <version>1.3.1.2</version>\n        <executions>\n          <execution>\n            <goals>\n              <goal>test</goal>\n            </goals>\n          </execution>\n        </executions>\n        <configuration>\n          <preloadSources>\n            <source>${project.basedir}/src/test/resources/js/lib/require.js</source>\n          </preloadSources>\n          <jsSrcDir>${project.basedir}/src/main/resources/static</jsSrcDir>\n          <sourceIncludes>\n            <include>**/*.js</include>\n            <include>**/*.coffee</include>\n          </sourceIncludes>\n          <jsTestSrcDir>${project.basedir}/src/test/resources/js/spec</jsTestSrcDir>\n          <specIncludes>\n            <include>**/spec_helper.js</include>\n            <include>**/*.js</include>\n            <include>**/*.coffee</include>\n          </specIncludes>\n          <specRunnerTemplate>REQUIRE_JS</specRunnerTemplate>\n          <format>progress</format>\n        </configuration>\n      </plugin>\n  </plugins>\n</build>\n\n\n\nTesting The Engage Core\n\n\nThis chapter gives an overview over the directory structure used for testing the theodul engage core module, the configuration for the specs in the \nspec_helper.js\n and how to write specs for the core.\n\n\nDirectory Structure\n\n\nThe test relevant files are located in the \nsrc/test/resources/ui/js/spec\n tree. Files that filename ends on \n_spec.js\n are considered as files with executable tests. The \nspec_helper.js\n in configured in the \npom.xml\n for the initial setup.\n\n\nDirectory Structure Testing Engage Core\n\n\n|-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------spec    #Tests the *_spec.js and the helper file spec_helper.js\n\n\n\nSpec Helper\n\n\nThe file \nspec_helper.js\n takes over the configuration of RequireJS which is usually done by the engage_init.js. The paths differ slighty from the player has at runtime.\n\n\nspec_helper for engage_core module\n\n\n/*global requirejs*/\nrequirejs.config({\n  baseUrl: 'src/js/lib',\n  paths: {\n    require: 'require',\n    jquery: 'jquery',\n    underscore: 'underscore',\n    backbone: 'backbone',\n    engage: '../engage',\n    plugins: '../engage/plugin/*/static'\n  },\n  shim: {\n    'backbone': {\n      //script dependencies\n      deps: ['underscore', 'jquery'],\n      //global variable\n      exports: 'Backbone'\n    },\n    'underscore': {\n      //global variable\n      exports: '_'\n    }\n  }\n});\nvar PLUGIN_MANAGER_PATH = '/engage/theodul/manager/list.json';\nvar PLUGIN_PATH = '/engage/theodul/plugin/';\n\n\n\nWriting Specs\n\n\nTODO\n\n\nTesting Engage Plugins\n\n\nThis chapter gives an overview over the directory structure used for testing a theodul engage plugin module, the configuration for the specs in the spec_helper.js and how to write specs for a plugin.\n\n\nDirectory Structure\n\n\nThe test relevant files are located in the \nsrc/test/resources/ui/js/spec\n tree. Files that filename ends on \n_spec.js\n are considered as files with executable tests. The \nspec_helper.js\n in configured in the \npom.xml\n for the initial setup. In the directory \ntest/resources/ui/js/engage\n is a mockup of the theodul engage core module in order to be able to test the plugin module independent. The directory \ntest/resources/ui/js/lib\n provides the libraries which are provides by the engage core module at runtime of the player, as well to be able to test the plugin module independently.\n\n\nDirectory Structure Testing Plugins\n\n\n|-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------engage  #Mockup of the engage_core.js and engage_model.js\n|-----------lib     #Libraries that are used and provided by the core (A copy of the lib directory in the engage core module)\n|-----------spec    #Tests the *_spec.js and the helper file spec_helper.js\n\n\n\nSpec Helper\n\n\nThe file \nspec_helper.js\n takes over the configuration of RequireJS which is usually done by the engage_init.js. The paths differ slighty from the player uses at runtime.\n\n\n/*global requirejs*/\nrequirejs.config({\n  baseUrl: 'src/',\n  paths: {\n    require: 'test/resources/js/lib/require',\n    jquery: 'test/resources/js/lib/jquery',\n    underscore: 'test/resources/js/lib/underscore',\n    backbone: 'test/resources/js/lib/backbone',\n    engage: 'test/resources/js/engage'\n  },\n  shim: {\n    'backbone': {\n      //script dependencies\n      deps: ['underscore', 'jquery'],\n      //global variable\n      exports: 'Backbone'\n    },\n    'underscore': {\n      //global variable\n      exports: '_'\n    }\n  }\n});\n\n\n\nWriting Specs\n\n\nTODO\n\n\nRunning The Tests\n\n\nNow you can start the build process and the jasmine specs will be executed. Each . stands for a successful test. F stands for a failure and will stop the build process like it is specified in the configuration. The example output shows a manipulated version of the tests for the theodul engage core in order to illustrate a failing test. Normally all three tests should succeed at this point.\n\n\nTesting on build\n\n\nmvn install -DdeployTo=${FELIX_HOME}\n    // some output before\n    [INFO]\n    -------------------------------------------------------\n     J A S M I N E   S P E C S\n    -------------------------------------------------------\n    [INFO]\n    F..\n\n    1 failure:\n\n      1.) EngageCore it should have a model <<< FAILURE!\n\n        * Expected { cid : 'c3', ... _pending : false } not to be defined.\n\n    Results: 3 specs, 1 failures\n    // some output before\n\n\n\nThe jasmine-maven-plugin can also be executed manually and show the result in a browser. This can be achieved by the following command:\n\n\nManual testing\n\n\nmvn jasmine:bdd\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Building matterhorn-engage-theodul-core 1.5-SNAPSHOT\n    [INFO] ------------------------------------------------------------------------\n    [INFO]\n    [INFO] --- jasmine-maven-plugin:1.3.1.2:bdd (default-cli) @ matterhorn-engage-theodul-core ---\n    2014-01-28 14:33:30.722:INFO:oejs.Server:jetty-8.1.10.v20130312\n    2014-01-28 14:33:30.746:INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:8234\n    [INFO]\n\n    Server started--it's time to spec some JavaScript! You can run your specs as you develop by visiting this URL in a web browser:\n\n    http://localhost:8234\n\n    The server will monitor these two directories for scripts that you add, remove, and change:\n\n    source directory: src/main/resources/ui\n\n    spec directory: src/test/resources/ui/js/spec\n\n    Just leave this process running as you test-drive your code, refreshing your browser window to re-run your specs.\n    You can kill the server with Ctrl-C when you're done.\n\n\n\nIn a browser you should see an output like it is shown on the next screenshot.",
            "title": "Player - Testing"
        },
        {
            "location": "/modules/player.testing/#how-to-test-with-phantomjs-and-jasmine",
            "text": "",
            "title": "How To Test With Phantom.js and Jasmine"
        },
        {
            "location": "/modules/player.testing/#integration-of-jasmine-into-the-build-process-maven",
            "text": "Jasmine  is integrated with the  jasmine-maven-plugin  into the maven build process. Therefore only the pom.xml file will be enhanced by the following code, which specifies the  jasmine-maven-plugin  as plugin for the build process. The configuration of the jasmine-maven-plugin is also done in this file. The meaning of every configuration parameter can be looked up on the jasmine-maven-plugin project page under this  link . The following configuration uses a the specRunnerTemplate  REQUIRE_JS in order to function properly with  RequireJS . Further information about spec runner templates can be found  here . On the next build the needed dependencies will be automatically resolved just like it is in the nature of maven.  pom.xml  <build>\n<plugins>\n    ...\n      <plugin>\n        <groupId>com.github.searls</groupId>\n        <artifactId>jasmine-maven-plugin</artifactId>\n        <version>1.3.1.2</version>\n        <executions>\n          <execution>\n            <goals>\n              <goal>test</goal>\n            </goals>\n          </execution>\n        </executions>\n        <configuration>\n          <preloadSources>\n            <source>${project.basedir}/src/test/resources/js/lib/require.js</source>\n          </preloadSources>\n          <jsSrcDir>${project.basedir}/src/main/resources/static</jsSrcDir>\n          <sourceIncludes>\n            <include>**/*.js</include>\n            <include>**/*.coffee</include>\n          </sourceIncludes>\n          <jsTestSrcDir>${project.basedir}/src/test/resources/js/spec</jsTestSrcDir>\n          <specIncludes>\n            <include>**/spec_helper.js</include>\n            <include>**/*.js</include>\n            <include>**/*.coffee</include>\n          </specIncludes>\n          <specRunnerTemplate>REQUIRE_JS</specRunnerTemplate>\n          <format>progress</format>\n        </configuration>\n      </plugin>\n  </plugins>\n</build>",
            "title": "Integration Of Jasmine Into The Build Process (Maven)"
        },
        {
            "location": "/modules/player.testing/#testing-the-engage-core",
            "text": "This chapter gives an overview over the directory structure used for testing the theodul engage core module, the configuration for the specs in the  spec_helper.js  and how to write specs for the core.",
            "title": "Testing The Engage Core"
        },
        {
            "location": "/modules/player.testing/#directory-structure",
            "text": "The test relevant files are located in the  src/test/resources/ui/js/spec  tree. Files that filename ends on  _spec.js  are considered as files with executable tests. The  spec_helper.js  in configured in the  pom.xml  for the initial setup.  Directory Structure Testing Engage Core  |-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------spec    #Tests the *_spec.js and the helper file spec_helper.js",
            "title": "Directory Structure"
        },
        {
            "location": "/modules/player.testing/#spec-helper",
            "text": "The file  spec_helper.js  takes over the configuration of RequireJS which is usually done by the engage_init.js. The paths differ slighty from the player has at runtime.  spec_helper for engage_core module  /*global requirejs*/\nrequirejs.config({\n  baseUrl: 'src/js/lib',\n  paths: {\n    require: 'require',\n    jquery: 'jquery',\n    underscore: 'underscore',\n    backbone: 'backbone',\n    engage: '../engage',\n    plugins: '../engage/plugin/*/static'\n  },\n  shim: {\n    'backbone': {\n      //script dependencies\n      deps: ['underscore', 'jquery'],\n      //global variable\n      exports: 'Backbone'\n    },\n    'underscore': {\n      //global variable\n      exports: '_'\n    }\n  }\n});\nvar PLUGIN_MANAGER_PATH = '/engage/theodul/manager/list.json';\nvar PLUGIN_PATH = '/engage/theodul/plugin/';",
            "title": "Spec Helper"
        },
        {
            "location": "/modules/player.testing/#writing-specs",
            "text": "TODO",
            "title": "Writing Specs"
        },
        {
            "location": "/modules/player.testing/#testing-engage-plugins",
            "text": "This chapter gives an overview over the directory structure used for testing a theodul engage plugin module, the configuration for the specs in the spec_helper.js and how to write specs for a plugin.",
            "title": "Testing Engage Plugins"
        },
        {
            "location": "/modules/player.testing/#directory-structure_1",
            "text": "The test relevant files are located in the  src/test/resources/ui/js/spec  tree. Files that filename ends on  _spec.js  are considered as files with executable tests. The  spec_helper.js  in configured in the  pom.xml  for the initial setup. In the directory  test/resources/ui/js/engage  is a mockup of the theodul engage core module in order to be able to test the plugin module independent. The directory  test/resources/ui/js/lib  provides the libraries which are provides by the engage core module at runtime of the player, as well to be able to test the plugin module independently.  Directory Structure Testing Plugins  |-src\n|---main\n|-----java          #Java impl of the plugin manager\n|-----resources\n|-------ui          #UI of the core, core.html and engage_init.js\n|---------css       #Global CSS Styles\n|---------js        #JavaScript logic\n|-----------engage  #Core logic, engage_core.js and engage_model.js\n|-----------lib     #External libraries, backbone.js, jquery.js, require.js and underscore.js\n|---test            #Unit Tests\n|-----resources\n|-------ui          #JavaScript Unit Tests\n|---------js\n|-----------engage  #Mockup of the engage_core.js and engage_model.js\n|-----------lib     #Libraries that are used and provided by the core (A copy of the lib directory in the engage core module)\n|-----------spec    #Tests the *_spec.js and the helper file spec_helper.js",
            "title": "Directory Structure"
        },
        {
            "location": "/modules/player.testing/#spec-helper_1",
            "text": "The file  spec_helper.js  takes over the configuration of RequireJS which is usually done by the engage_init.js. The paths differ slighty from the player uses at runtime.  /*global requirejs*/\nrequirejs.config({\n  baseUrl: 'src/',\n  paths: {\n    require: 'test/resources/js/lib/require',\n    jquery: 'test/resources/js/lib/jquery',\n    underscore: 'test/resources/js/lib/underscore',\n    backbone: 'test/resources/js/lib/backbone',\n    engage: 'test/resources/js/engage'\n  },\n  shim: {\n    'backbone': {\n      //script dependencies\n      deps: ['underscore', 'jquery'],\n      //global variable\n      exports: 'Backbone'\n    },\n    'underscore': {\n      //global variable\n      exports: '_'\n    }\n  }\n});",
            "title": "Spec Helper"
        },
        {
            "location": "/modules/player.testing/#writing-specs_1",
            "text": "TODO",
            "title": "Writing Specs"
        },
        {
            "location": "/modules/player.testing/#running-the-tests",
            "text": "Now you can start the build process and the jasmine specs will be executed. Each . stands for a successful test. F stands for a failure and will stop the build process like it is specified in the configuration. The example output shows a manipulated version of the tests for the theodul engage core in order to illustrate a failing test. Normally all three tests should succeed at this point.  Testing on build  mvn install -DdeployTo=${FELIX_HOME}\n    // some output before\n    [INFO]\n    -------------------------------------------------------\n     J A S M I N E   S P E C S\n    -------------------------------------------------------\n    [INFO]\n    F..\n\n    1 failure:\n\n      1.) EngageCore it should have a model <<< FAILURE!\n\n        * Expected { cid : 'c3', ... _pending : false } not to be defined.\n\n    Results: 3 specs, 1 failures\n    // some output before  The jasmine-maven-plugin can also be executed manually and show the result in a browser. This can be achieved by the following command:  Manual testing  mvn jasmine:bdd\n    [INFO] Scanning for projects...\n    [INFO]\n    [INFO] ------------------------------------------------------------------------\n    [INFO] Building matterhorn-engage-theodul-core 1.5-SNAPSHOT\n    [INFO] ------------------------------------------------------------------------\n    [INFO]\n    [INFO] --- jasmine-maven-plugin:1.3.1.2:bdd (default-cli) @ matterhorn-engage-theodul-core ---\n    2014-01-28 14:33:30.722:INFO:oejs.Server:jetty-8.1.10.v20130312\n    2014-01-28 14:33:30.746:INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:8234\n    [INFO]\n\n    Server started--it's time to spec some JavaScript! You can run your specs as you develop by visiting this URL in a web browser:\n\n    http://localhost:8234\n\n    The server will monitor these two directories for scripts that you add, remove, and change:\n\n    source directory: src/main/resources/ui\n\n    spec directory: src/test/resources/ui/js/spec\n\n    Just leave this process running as you test-drive your code, refreshing your browser window to re-run your specs.\n    You can kill the server with Ctrl-C when you're done.  In a browser you should see an output like it is shown on the next screenshot.",
            "title": "Running The Tests"
        },
        {
            "location": "/modules/player.configuration/",
            "text": "Opencast 2.0 Player Configuration\n\n\nThe Opencast 2.0 Player (aka Theodul Pass Player) is the new default player in 2.0. The old engage player from 1.x is still available too.\n\n\nThe configurations for the player are done for each tenant. So the configuration keys are located in \n<felix_home>/etc/load/org.opencastproject.organization-mh_default_org.cfg\n.\n\n\nSelect the Opencast 2.0 Player\n\n\nTo activate the player set:\n\n\nprop.player=/engage/theodul/ui/core.html\n\n\n\nConfiguration\n\n\nLogo\n\n\nThe logo in the top right can easily be replaced by changing the path or URL for logo small.\n\n\nprop.logo_player=/engage/ui/img/mh_logos/OpencastLogo.png\n\n\n\nOptions:\n\n\n\n\nAny URL or local path to a PNG, GIF, JPG image. Default displayed hight in the browser 36px.\n\n\n\n\nPosition of the controls\n\n\nThe basic controls for the player can be placed over or under the video display.\n\n\nprop.player.positioncontrols=bottom\n\n\n\nOptions:\n\n\n\n\ntop\n\n\nbottom\n\n\n\n\nMain video flavor\n\n\nThe default flavor of the master video (the video on the \"left side\" in the video display). This source also provides the audio. You can change this to every falvor that your installation might provide. If no mastervideotype was selected, or the mastervideotype is not available the videos are taken in their sequence within the mediapackage.\n\n\nprop.player.mastervideotype=presenter/delivery\n\n\n\nOptions (default flavors):\n\n\n\n\npresenter/delivery\n\n\npresentation/delivery\n\n\n\n\nShow Embed links\n\n\nThe player can show a dialog with links to the current video that can be embeded into other websites. This function can be disabled\n\n\nprop.show_embed_links=true\n\n\n\nOptions:\n\n\n\n\ntrue\n\n\nfalse\n\n\n\n\nLink to Media Module\n\n\nIf you don't want to use the Opencast Media Module the link within the player back to the overview of the recordings can be disabled\n\n\nprop.link_mediamodule=true\n\n\n\nOptions:\n\n\n\n\ntrue\n\n\nfalse\n\n\n\n\nKeyboard Shortcuts\n\n\nThe keyboard shortcuts in the player can be customized\n\n\nprop.player.shortcut.playPause=space\nprop.player.shortcut.seekRight=right\nprop.player.shortcut.seekLeft=left\nprop.player.shortcut.playbackrateIncrease=mod+9\nprop.player.shortcut.playbackrateDecrease=mod+8\nprop.player.shortcut.muteToggle=m\nprop.player.shortcut.volUp=9\nprop.player.shortcut.volDown=8\nprop.player.shortcut.fullscreenEnable=mod+enter\nprop.player.shortcut.fullscreenCancel=escape\nprop.player.shortcut.jumpToBegin=backspace\nprop.player.shortcut.prevChapter=pagedown\nprop.player.shortcut.nextChapter=pageup",
            "title": "Player - Configuration"
        },
        {
            "location": "/modules/player.configuration/#opencast-20-player-configuration",
            "text": "The Opencast 2.0 Player (aka Theodul Pass Player) is the new default player in 2.0. The old engage player from 1.x is still available too.  The configurations for the player are done for each tenant. So the configuration keys are located in  <felix_home>/etc/load/org.opencastproject.organization-mh_default_org.cfg .",
            "title": "Opencast 2.0 Player Configuration"
        },
        {
            "location": "/modules/player.configuration/#select-the-opencast-20-player",
            "text": "To activate the player set:  prop.player=/engage/theodul/ui/core.html",
            "title": "Select the Opencast 2.0 Player"
        },
        {
            "location": "/modules/player.configuration/#configuration",
            "text": "",
            "title": "Configuration"
        },
        {
            "location": "/modules/player.configuration/#logo",
            "text": "The logo in the top right can easily be replaced by changing the path or URL for logo small.  prop.logo_player=/engage/ui/img/mh_logos/OpencastLogo.png  Options:   Any URL or local path to a PNG, GIF, JPG image. Default displayed hight in the browser 36px.",
            "title": "Logo"
        },
        {
            "location": "/modules/player.configuration/#position-of-the-controls",
            "text": "The basic controls for the player can be placed over or under the video display.  prop.player.positioncontrols=bottom  Options:   top  bottom",
            "title": "Position of the controls"
        },
        {
            "location": "/modules/player.configuration/#main-video-flavor",
            "text": "The default flavor of the master video (the video on the \"left side\" in the video display). This source also provides the audio. You can change this to every falvor that your installation might provide. If no mastervideotype was selected, or the mastervideotype is not available the videos are taken in their sequence within the mediapackage.  prop.player.mastervideotype=presenter/delivery  Options (default flavors):   presenter/delivery  presentation/delivery",
            "title": "Main video flavor"
        },
        {
            "location": "/modules/player.configuration/#show-embed-links",
            "text": "The player can show a dialog with links to the current video that can be embeded into other websites. This function can be disabled  prop.show_embed_links=true  Options:   true  false",
            "title": "Show Embed links"
        },
        {
            "location": "/modules/player.configuration/#link-to-media-module",
            "text": "If you don't want to use the Opencast Media Module the link within the player back to the overview of the recordings can be disabled  prop.link_mediamodule=true  Options:   true  false",
            "title": "Link to Media Module"
        },
        {
            "location": "/modules/player.configuration/#keyboard-shortcuts",
            "text": "The keyboard shortcuts in the player can be customized  prop.player.shortcut.playPause=space\nprop.player.shortcut.seekRight=right\nprop.player.shortcut.seekLeft=left\nprop.player.shortcut.playbackrateIncrease=mod+9\nprop.player.shortcut.playbackrateDecrease=mod+8\nprop.player.shortcut.muteToggle=m\nprop.player.shortcut.volUp=9\nprop.player.shortcut.volDown=8\nprop.player.shortcut.fullscreenEnable=mod+enter\nprop.player.shortcut.fullscreenCancel=escape\nprop.player.shortcut.jumpToBegin=backspace\nprop.player.shortcut.prevChapter=pagedown\nprop.player.shortcut.nextChapter=pageup",
            "title": "Keyboard Shortcuts"
        },
        {
            "location": "/modules/player.url.parameter/",
            "text": "Theodul Pass Player - URL Parameters\n\n\nURL Parameters\n\n\n\n\ntime\n\n\nPossible values\n\n\nMinutes (with value X) and seconds (with value Y)\n\n\nXmYs\n\n\nYsXm\n\n\nXmY\n\n\nMinutes (with value X) only\n\n\nXm\n\n\nSeconds (with value Y) only\n\n\nYs\n\n\nY\n\n\n\n\n\n\nDefault value\n\n\n-\n\n\n\n\n\n\nDescription\n\n\nSeeks intially automatically to a specified time\n\n\nautomatically plays the video from the specified time on\n\n\n\n\n\n\nautoplay\n\n\nPossible values\n\n\ntrue\n\n\nfalse\n\n\n\n\n\n\nDefault value\n\n\nfalse\n\n\n\n\n\n\nDescription\n\n\nAutomatically starts playing the video after a short delay\n\n\n\n\n\n\nquality\n\n\nPossible values\n\n\nlow\n\n\nmedium\n\n\nhigh\n\n\n\n\n\n\nDefault value\n\n\nmedium\n\n\n\n\n\n\nDescription\n\n\nSets a video quality if the video has been encoded in multiple qualities\n\n\n\n\n\n\nmode\n\n\nPossible values\n\n\ndesktop\n\n\nembed\n\n\nmobile\n\n\n\n\n\n\nDefault value\n\n\ndesktop\n\n\n\n\n\n\nDescription\n\n\nSets the player mode manually\n\n\n\n\n\n\nbrowser\n\n\nPossible values\n\n\nall\n\n\ndefault\n\n\n\n\n\n\nDefault value\n\n\ndefault\n\n\n\n\n\n\nDescription\n\n\nif your browser is not supported, try the new player with this flag activated \n\n\noverwrites filtering for supported browsers with parameter set to \"all\"\n\n\nresets the setting with \"default\"\n\n\nthe value is permanently stored for the browser in the local storage\n\n\n\n\n\n\n\n\nExample\n\n\nhttp://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&time=3m30s\n\n\nDeveloper URL Parameters\n\n\n\n\ndebug\n\n\nPossible values\n\n\ntrue\n\n\nfalse\n\n\n\n\n\n\nDefault value\n\n\nfalse\n\n\n\n\n\n\nDescription\n\n\nprints debug output to the developer console\n\n\n\n\n\n\ndebugEvents\n\n\nPossible values\n\n\ntrue\n\n\nfalse\n\n\n\n\n\n\nDefault value\n\n\nfalse\n\n\n\n\n\n\nDescription\n\n\nprints debug output to the developer console when an event occurs\n\n\n\n\n\n\nformat\n\n\nPossible Values\n\n\nhls\n: Apple HTTP Live Streaming\n\n\ndash\n: MPEG DASH\n\n\nrtmp\n: Adobe RTMP (Flash)\n\n\nmp4\n: MP4 videos (no streaming)\n\n\nwebm\n: WebM videos (no streaming)\n\n\naudio\n: audio only (no streaming)\n\n\ndefault\n: reset to defaults\n\n\n\n\n\n\nDefault value\n\n\ndefault\n\n\n\n\n\n\nDescription \n\n\nsets the preferred (streaming) format\n\n\nif not available, the defaults will be selected\n\n\nthe value is permanently stored for the browser in the local storage\n\n\n\n\n\n\n\n\nExample\n\n\nhttp://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&debug=true&debugEvents=true",
            "title": "Player - URL Parameters"
        },
        {
            "location": "/modules/player.url.parameter/#theodul-pass-player-url-parameters",
            "text": "",
            "title": "Theodul Pass Player - URL Parameters"
        },
        {
            "location": "/modules/player.url.parameter/#url-parameters",
            "text": "time  Possible values  Minutes (with value X) and seconds (with value Y)  XmYs  YsXm  XmY  Minutes (with value X) only  Xm  Seconds (with value Y) only  Ys  Y    Default value  -    Description  Seeks intially automatically to a specified time  automatically plays the video from the specified time on    autoplay  Possible values  true  false    Default value  false    Description  Automatically starts playing the video after a short delay    quality  Possible values  low  medium  high    Default value  medium    Description  Sets a video quality if the video has been encoded in multiple qualities    mode  Possible values  desktop  embed  mobile    Default value  desktop    Description  Sets the player mode manually    browser  Possible values  all  default    Default value  default    Description  if your browser is not supported, try the new player with this flag activated   overwrites filtering for supported browsers with parameter set to \"all\"  resets the setting with \"default\"  the value is permanently stored for the browser in the local storage",
            "title": "URL Parameters"
        },
        {
            "location": "/modules/player.url.parameter/#example",
            "text": "http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&time=3m30s",
            "title": "Example"
        },
        {
            "location": "/modules/player.url.parameter/#developer-url-parameters",
            "text": "debug  Possible values  true  false    Default value  false    Description  prints debug output to the developer console    debugEvents  Possible values  true  false    Default value  false    Description  prints debug output to the developer console when an event occurs    format  Possible Values  hls : Apple HTTP Live Streaming  dash : MPEG DASH  rtmp : Adobe RTMP (Flash)  mp4 : MP4 videos (no streaming)  webm : WebM videos (no streaming)  audio : audio only (no streaming)  default : reset to defaults    Default value  default    Description   sets the preferred (streaming) format  if not available, the defaults will be selected  the value is permanently stored for the browser in the local storage",
            "title": "Developer URL Parameters"
        },
        {
            "location": "/modules/player.url.parameter/#example_1",
            "text": "http://YOUR.SERVER:8080/engage/theodul/ui/core.html?id=SOME-ID&debug=true&debugEvents=true",
            "title": "Example"
        },
        {
            "location": "/modules/searchindex/",
            "text": "Search Index Configuration\n\n\nMatterhorn has Solr included by default. This guide is only needed, if you want to run Solr on a separate server.\n\n\nThe software versions in these instructions are not the only versions that will work, they are just the version tested when this document was written.  Newer versions of both Tomcat and Solr are highly recommended.\n\n\nIntroduction\n\n\nMatterhorn services use filesystem, relational database, and/or search indexes to store and retrieve information. In order to cluster services across multiple servers, we must provide shared storage solutions for each of these technologies. We do this with NFS or ZFS for filesystems, JDBC for relational databases, and solr for search indexes. If you plan on clustering either the workflow service or the search service, you must configure Matterhorn to use remote solr servers as described below, otherwise no further action is required.\n\n\nObtaining the software\n\n\nSolr runs in any modern servlet environment such as Apache Tomcat 7. Download and unpack Tomcat.\n\n\n$ curl -O http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.5-beta/bin/apache-tomcat-7.0.5.zip\n$ unzip apache-tomcat-7.0.5.zip\n\n\n\nDownload solr from the closest mirror and unpack the zip file. Make sure the permissions are set properly (the zip file doesn't retain proper unix permissions)\n\n\n$ curl -O http://archive.apache.org/dist/lucene/solr/1.4.1/apache-solr-1.4.1.zip\n$ unzip apache-solr-1.4.1.zip\n$ chmod 755 apache-tomcat-7.0.5/bin/*\n\n\n\nDeploy solr to tomcat\n\n\nCopy the solr example war file to tomcat's webapps directory and expand the war file.\n\n\n$ unzip apache-solr-1.4.1/example/webapps/solr.war -d apache-tomcat-7.0.5/webapps/solr/\n\n\n\nConfigure solr\n\n\nAdd the solr config files to the solr webapp in tomcat. If you are setting up the search service, use the solr config from the search module.\n\n\n$ cd apache-tomcat-7.0.5\n$ cp -R [matterhorn source]/modules/matterhorn-search-service-impl/src/main/resources/solr solr\n\n\n\nAlternatively, if this is the solr index supporting the workflow service, copy those files instead:\n\n\n$ cd apache-tomcat-7.0.5\n$ cp -R [matterhorn source]/modules/matterhorn-workflow-service-impl/src/main/resources/solr solr\n\n\n\nEdit the dataDir setting in solr/conf/solrconfig.xml to specify the directory you want to use for the index files.\n\n\nDependency of the workflow index\n\n\nThe index has a dependency on a Matterhorn class. The easiest way of getting rid of this dependency is providing a .jar file with that class within a directory named lib in the solr folder (you may need to create it if it does not exist). The .jar file can be the compiled matterhorn-solr bundle. Placing the jar in the main Tomcat lib directory does not work.\n\n\nStart the server\n\n\n$ bin/startup.sh\nUsing CATALINA_BASE:   /Users/josh/Desktop/apache-tomcat-7.0.5\nUsing CATALINA_HOME:   /Users/josh/Desktop/apache-tomcat-7.0.5\nUsing CATALINA_TMPDIR: /Users/josh/Desktop/apache-tomcat-7.0.5/temp\nUsing JRE_HOME:        /System/Library/Frameworks/JavaVM.framework/Versions/CurrentJDK/Home\n\n\n\nYou should see that the solr server is running on http://localhost:8080/solr\n\n\n\n\nYou can use the admin screen to monitor the server or make ad-hoc queries:\n\n\n\n\n\n\nSecure the solr server\n\n\nJust like with a relational database server, it is critical that you limit access to the solr server. Matterhorn's communication with solr servers is unauthenticated, so you must secure a firewall on the solr servers that accepts HTTP requests only from Matterhorn servers. If these servers were publicly accessible, anyone could make changes to Matterhorn data from outside Matterhorn itself.\n\n\nConfigure Matterhorn\n\n\nSet the URL to this solr server in Matterhorn's config.properties file:\n\n\norg.opencastproject.search.solr.url=http://your.solr.server.edu:8080/solr/\n\n\n\nIf this solr server is supporting clustered workflow services:\n\n\norg.opencastproject.workflow.solr.url==http://your.solr.server.edu:8080/solr/\n\n\n\nIt is important to understand that a solr server provides exactly one schema, and one schema only. If you want to cluster both the workflow service and the search service, you will need two separate solr servers. These solr servers can run on the same machine, but each will needs its own servlet container and port.",
            "title": "Search Index"
        },
        {
            "location": "/modules/searchindex/#search-index-configuration",
            "text": "Matterhorn has Solr included by default. This guide is only needed, if you want to run Solr on a separate server.  The software versions in these instructions are not the only versions that will work, they are just the version tested when this document was written.  Newer versions of both Tomcat and Solr are highly recommended.",
            "title": "Search Index Configuration"
        },
        {
            "location": "/modules/searchindex/#introduction",
            "text": "Matterhorn services use filesystem, relational database, and/or search indexes to store and retrieve information. In order to cluster services across multiple servers, we must provide shared storage solutions for each of these technologies. We do this with NFS or ZFS for filesystems, JDBC for relational databases, and solr for search indexes. If you plan on clustering either the workflow service or the search service, you must configure Matterhorn to use remote solr servers as described below, otherwise no further action is required.",
            "title": "Introduction"
        },
        {
            "location": "/modules/searchindex/#obtaining-the-software",
            "text": "Solr runs in any modern servlet environment such as Apache Tomcat 7. Download and unpack Tomcat.  $ curl -O http://archive.apache.org/dist/tomcat/tomcat-7/v7.0.5-beta/bin/apache-tomcat-7.0.5.zip\n$ unzip apache-tomcat-7.0.5.zip  Download solr from the closest mirror and unpack the zip file. Make sure the permissions are set properly (the zip file doesn't retain proper unix permissions)  $ curl -O http://archive.apache.org/dist/lucene/solr/1.4.1/apache-solr-1.4.1.zip\n$ unzip apache-solr-1.4.1.zip\n$ chmod 755 apache-tomcat-7.0.5/bin/*",
            "title": "Obtaining the software"
        },
        {
            "location": "/modules/searchindex/#deploy-solr-to-tomcat",
            "text": "Copy the solr example war file to tomcat's webapps directory and expand the war file.  $ unzip apache-solr-1.4.1/example/webapps/solr.war -d apache-tomcat-7.0.5/webapps/solr/",
            "title": "Deploy solr to tomcat"
        },
        {
            "location": "/modules/searchindex/#configure-solr",
            "text": "Add the solr config files to the solr webapp in tomcat. If you are setting up the search service, use the solr config from the search module.  $ cd apache-tomcat-7.0.5\n$ cp -R [matterhorn source]/modules/matterhorn-search-service-impl/src/main/resources/solr solr  Alternatively, if this is the solr index supporting the workflow service, copy those files instead:  $ cd apache-tomcat-7.0.5\n$ cp -R [matterhorn source]/modules/matterhorn-workflow-service-impl/src/main/resources/solr solr  Edit the dataDir setting in solr/conf/solrconfig.xml to specify the directory you want to use for the index files.",
            "title": "Configure solr"
        },
        {
            "location": "/modules/searchindex/#dependency-of-the-workflow-index",
            "text": "The index has a dependency on a Matterhorn class. The easiest way of getting rid of this dependency is providing a .jar file with that class within a directory named lib in the solr folder (you may need to create it if it does not exist). The .jar file can be the compiled matterhorn-solr bundle. Placing the jar in the main Tomcat lib directory does not work.",
            "title": "Dependency of the workflow index"
        },
        {
            "location": "/modules/searchindex/#start-the-server",
            "text": "$ bin/startup.sh\nUsing CATALINA_BASE:   /Users/josh/Desktop/apache-tomcat-7.0.5\nUsing CATALINA_HOME:   /Users/josh/Desktop/apache-tomcat-7.0.5\nUsing CATALINA_TMPDIR: /Users/josh/Desktop/apache-tomcat-7.0.5/temp\nUsing JRE_HOME:        /System/Library/Frameworks/JavaVM.framework/Versions/CurrentJDK/Home  You should see that the solr server is running on http://localhost:8080/solr   You can use the admin screen to monitor the server or make ad-hoc queries:",
            "title": "Start the server"
        },
        {
            "location": "/modules/searchindex/#secure-the-solr-server",
            "text": "Just like with a relational database server, it is critical that you limit access to the solr server. Matterhorn's communication with solr servers is unauthenticated, so you must secure a firewall on the solr servers that accepts HTTP requests only from Matterhorn servers. If these servers were publicly accessible, anyone could make changes to Matterhorn data from outside Matterhorn itself.",
            "title": "Secure the solr server"
        },
        {
            "location": "/modules/searchindex/#configure-matterhorn",
            "text": "Set the URL to this solr server in Matterhorn's config.properties file:  org.opencastproject.search.solr.url=http://your.solr.server.edu:8080/solr/  If this solr server is supporting clustered workflow services:  org.opencastproject.workflow.solr.url==http://your.solr.server.edu:8080/solr/  It is important to understand that a solr server provides exactly one schema, and one schema only. If you want to cluster both the workflow service and the search service, you will need two separate solr servers. These solr servers can run on the same machine, but each will needs its own servlet container and port.",
            "title": "Configure Matterhorn"
        },
        {
            "location": "/modules/textextraction/",
            "text": "Text Extraction Configuration\n\n\nHow the text extraction process works\n\n\nThe sequence of the Matterhorn services used during slide detection and text extraction is the following:\n\n\n  -----> Segmentation -----> TextAnalyzerService ----------------->\n                                /             \\\n                               /               \\\n                     TextExtractor          DictionaryService\n                  (OCR with Tesseract)   (Filter extracted texts)\n\n\n\n\nThe segmentation will define the frames which are passed to the text analyzer. For extraction a frame from the end of a\nsegment is used to make sure that most of a slides text is visible.\n\n\nThe frame is then exported as TIFF image and passed to the text extraction service which calles an OCR engine to get the\ntext output. For this, the Tesseract OCR engine is used by default.\n\n\nAfter the text extraction is done, the analysis service will pass the recognized text to the dictionary service which\nmay filter it to remove messed up words, unknown words, single characters or other things depending on the actual\nimplementation and configuration.\n\n\nFinally, the the extracted text is attached to the Mediapackage as MPEG 7 XML and the Matterhorn workflow continues.\n\n\nConfiguration\n\n\nThis section describes the configuration of all involved tools and services. As this guide the configuration is for the\nGerman language but the configuration for other languages should be equivalent and if not obvious, the differences will\nbe pointed out.\n\n\nOCR Engine: Tesseract\n\n\nTesseract is the default OCR engine used by Matterhorn. It will accept an image file and write the extracted text to an\noutput file. The command line arguments for this will be handles by Matterhorn. But apart from this, it is possible to\npass additional arguments to tesseract defining the internally used dictionary, box files and the layout analysis.\n\n\nFor example, for OCR on slides with German language, you want to run something like this:\n\n\n   tesseract in.tif out.txt -l deu -psm 3\n\n\n\n\n\n\nThe arguments \nin.tif\n and \nout.txt\n are automatically set by Matterhorn.\n\n\nThe argument \n-l deu\n will specify the language files used by tesseract.  This time \ndeu\n is used for German\n   language. Multiple languages may be specified, separated by plus characters. Please make sure that you have\n  installed the language pack you want to use. Using yum, this can be done by running something like \nyum install\n  tesseract-langpack-deu\n.\n\n\nFinally \n-psm 3\n will specify the layout analysis tesseract will do. The value \n3\n means \nFully automatic page\n   segmentation, but no orientation and script detection\n which is actually the default. Hence in this case, the\n  argument could simply be omitted. If you know more about this input videos, you might want to use different options\n  here (not likely).\n\n\n\n\nIn Matterhorn you can modify this options in the config.properties file setting the following option:\n\n\n   org.opencastproject.textanalyzer.tesseract.options=-l deu -psm 3\n\n\n\n\nIt is highly recommended to configure Tesseract to use your local language. It will improve the recognition a lot and\nonly this will enable the recognition of special characters specific to your local language.\n\n\nEncoding (Image Preprocessing)\n\n\nThe text extraction works best if there is a high contrast between text and background and additionally, the text is not\ntoo thin. Ideally, this means that you have black and white images.\n\n\nAt this point it is probably worth noting that despite what is often said and could also be found in the documentation\nfor Matterhorn, it does not matter for Tesseract if it is black text on a white background or if the colors are inverted\n(white on black). Because of the way Tesseract works, that does not matter.\n\n\nA lot of lecture slides are unfortunately not designed this way. Lecturers use colors, background images, etc. That is\nwhy, to get a better result, it is a good idea to do some image preprocessing steps. Some easy ones can be included\ndirectly into the image extraction step using FFmpeg.\n\n\nFor this, edit the \n/etc/matterhorn/encoding/matterhorn-images.properties\n and modify the command for the image\nextraction:\n\n\n   profile.text-analysis.http.ffmpeg.command = -ss #{time} -i #{in.video.path}\n       -filter:v boxblur=1:1,curves=all=0.4/0#{space}0.6/1\n      -frames:v 1 -pix_fmt:v gray -r 1 #{out.dir}/#{out.name}#{out.suffix}\n\n\n\n\nThis profile would, for example, create a gray, high contrast image. The additional light blur will reduce or remove\nnoise and thicken the normal letters.\n\n\nThe kind of preprocessing you should use highly depends on the input material. Interesting filters to try out for your\nmaterial are among others the blur filters, the denoise filters, the curves filter and in some cases the color-channel\nmixer.\n\n\nDictionaryService (Filtering)\n\n\nThe filtering you want to do on the recognized texts highly depends on what you want to use the recognized texts for.\nFor searching, you might want a higher degree of filtering, for users you might also want to present text with slight\nerrors, for testing and debugging, you want no filtering at all.\n\n\nStarting with version 1.6, Matterhorn provides three different kinds of implementation for filtering which can be just\nswapped out at any time:\n\n\n\n\nmatterhorn-dictionary-none\n\n\nmatterhorn-dictionary-regexp (default)\n\n\nmatterhorn-dictionary-hunspell\n\n\n\n\nNo Filtering (matterhorn-dictionary-none)\n\n\nThe \nmatterhorn-dictionary-none\n module is the simplest one. It will just let the recognized texts pass through\nunmodified. There is no additional configuration needed or even possible. Of course, this is also the fastest one.\n\n\nUsing a Regular Expression (matterhorn-dictionary-regexp)\n\n\nStarting with 1.6, this is the default implementation for the DictionaryService. It is quite fast and easy to configure,\nbut is limited in terms of filtering capabilities as it will in most cases not check it a word makes sense or even if it\nmakes sense in this context.\n\n\nThe default expression for this module is \n\\w+\n which will let upper- and lowercase characters as well as digits pass\nthrough, but will block all other characters. For the German language for example, this would mean that all special\ncharacters would be blocked as well. So you want to configure Matterhorn to let them pass as well.\n\n\nYou can do that by modifying the \npattern\n in\n\netc/services/org.opencastproject.dictionary.regexp.DictionaryServiceImpl.properties\n:\n\n\nFor German, a suitable pattern could be:\n\n\n   pattern=[\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df][\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df]+[-.,:;!?]*\n\n\n\n\nThis will for example let all words pass which contain upper- and lowercase [a-z], digits and German special characters\nas well as punctuation at the end of a words. Additionally, it is required that the words are at least two characters\nlong which will filter out most of the common noise.\n\n\nA similar pattern that could be used for Spanish would be:\n\n\n   pattern=[\u00bf\u00a1(]*[\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1][\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1]+[)-.,:;!?]*\n\n\n\n\nUsing a Spell Checker (matterhorn-dictionary-hunspell)\n\n\nLast, the \nmatterhorn-dictionary-hunspell\n will check words based on a spell checker and a dictionary. As spell checker,\nthe tool \nhunspell\n is used which is one of the most common spell checkers on Linux and should be available from the\nsystem repositories for most common operating systems.\n\n\nFor the Hunspell based DictionaryService, there are two configuration options.  One is for the binary and one for the\narguments to use for filtering.\n\n\nBy default Matterhorn will just call \nhunspell\n without an absolute path. This will work as long as hunspell is in the\nsystems path which should be the case unless you have built and installed it manually. In that case, the binary can be\nconfigured using the following option in the \nconfig.properties\n file:\n\n\n   org.opencastproject.dictionary.hunspell.binary=/usr/bin/hunspell\n\n\n\n\nWhile most people wont need the binary path configuration, most people will need the filtering option which can be used\nfor setting the languages.  Configuration for this can be done using the following key in the \nconfig.properties\n file:\n\n\n   org.opencastproject.dictionary.hunspell.command=-d de_DE,en_GB,en_US -G\n\n\n\n\nNote that equivalent to the tesseract configuration, again the necessary languages have to be installed in the system.\nFor German, you would on RedHat based systems for example install the \nhunspell-de\n package from the system\nrepositories.\n\n\nFor Hunspell, you can also create custom dictionaries or add custom words to the existing ones. This might be\ninteresting for technical terms.\n\n\nGetting Matterhorn with Specific Implementations\n\n\nBuilding Matterhorn from Source\n\n\nStarting with 1.6, a default build of Matterhorn will build Matterhorn with text extraction and the RegExp based\nDictionaryService implementation. But replacing this with another implementation is not difficult. There is an\nalternatives profile in that main pom.xml which can be used, but it is probably easier, to build the desired module\ndirectly.\n\n\nAs an example, lets say that you want to replace the default RegExp based DictionaryService with the Hunspell based one.\nFirst of all, you would simply build Matterhorn the same way you always do running:\n\n\n   mvn clean install -Ddeplayto=/some/path/\n\n\n\n\nThis means that you would end up with all Matterhorn modules in the directory:\n\n\n   /some/path/lib/matterhorn/\n\n\n\n\nThis includes the \nmatterhorn-dictionary-regexp-X.Y.Z.jar\n which we want to replace. Thus you can simply delete the file\nrunning:\n\n\n   rm /some/path/lib/matterhorn/matterhorn-dictionary-regexp-*.jar\n\n\n\n\nNow switch to the \nmodules/matterhorn-dictionary-hunspell\n subdirectory of your Matterhorn source code and run:\n\n\n   mvn clean install -Ddeplayto=/some/path/\n\n\n\n\nThis will build the curremt module only and will put the resulting JAR file in the target directory where all your other\nJARs already are.\n\n\nApart from the configuration descriped above, you are now ready to go.\n\n\nInstalling Specific Implementations from the RPM Repository\n\n\nIf you do not have an advanced knowledge of the structure of Matterhorn and the way RPM packages work, what you want to\ndo is basically the same thing you would so when building Matterhorn from source: First install a default installation,\nthen replace the module we want to replace.\n\n\nThus we start by installing Matterhorn the way we always do by running:\n\n\n   yum install opencast-matterhorn16\n\n\n\n\nThis will install Matterhorn with all its dependencies, including all necessary modules (especially the RegExp based\nDictionaryService). As we don't want this particular module, we will just remove it again by running:\n\n\n   yum remove opencast-matterhorn16-module-dictionary-regexp\n\n\n\n\nYou will notice that yum wants to remove a profile and distribution package as well. Do not worry about that, that is\nthe way it should work. The profile and distribution packages do nothing except for making sure that a given set of\nmodule-packages are installed. As you removed one, this set is not given anymore and yum will remove these metapackages\nas well.\n\n\nSo we now have a system with one missing module: The DictionaryService implementation. For this we now choose another\none and install it using:\n\n\n   yum install opencast-matterhorn16-module-dictionary-hunspell\n\n\n\n\nThat is it.",
            "title": "Text Extraction"
        },
        {
            "location": "/modules/textextraction/#text-extraction-configuration",
            "text": "",
            "title": "Text Extraction Configuration"
        },
        {
            "location": "/modules/textextraction/#how-the-text-extraction-process-works",
            "text": "The sequence of the Matterhorn services used during slide detection and text extraction is the following:    -----> Segmentation -----> TextAnalyzerService ----------------->\n                                /             \\\n                               /               \\\n                     TextExtractor          DictionaryService\n                  (OCR with Tesseract)   (Filter extracted texts)  The segmentation will define the frames which are passed to the text analyzer. For extraction a frame from the end of a\nsegment is used to make sure that most of a slides text is visible.  The frame is then exported as TIFF image and passed to the text extraction service which calles an OCR engine to get the\ntext output. For this, the Tesseract OCR engine is used by default.  After the text extraction is done, the analysis service will pass the recognized text to the dictionary service which\nmay filter it to remove messed up words, unknown words, single characters or other things depending on the actual\nimplementation and configuration.  Finally, the the extracted text is attached to the Mediapackage as MPEG 7 XML and the Matterhorn workflow continues.",
            "title": "How the text extraction process works"
        },
        {
            "location": "/modules/textextraction/#configuration",
            "text": "This section describes the configuration of all involved tools and services. As this guide the configuration is for the\nGerman language but the configuration for other languages should be equivalent and if not obvious, the differences will\nbe pointed out.",
            "title": "Configuration"
        },
        {
            "location": "/modules/textextraction/#ocr-engine-tesseract",
            "text": "Tesseract is the default OCR engine used by Matterhorn. It will accept an image file and write the extracted text to an\noutput file. The command line arguments for this will be handles by Matterhorn. But apart from this, it is possible to\npass additional arguments to tesseract defining the internally used dictionary, box files and the layout analysis.  For example, for OCR on slides with German language, you want to run something like this:     tesseract in.tif out.txt -l deu -psm 3   The arguments  in.tif  and  out.txt  are automatically set by Matterhorn.  The argument  -l deu  will specify the language files used by tesseract.  This time  deu  is used for German\n   language. Multiple languages may be specified, separated by plus characters. Please make sure that you have\n  installed the language pack you want to use. Using yum, this can be done by running something like  yum install\n  tesseract-langpack-deu .  Finally  -psm 3  will specify the layout analysis tesseract will do. The value  3  means  Fully automatic page\n   segmentation, but no orientation and script detection  which is actually the default. Hence in this case, the\n  argument could simply be omitted. If you know more about this input videos, you might want to use different options\n  here (not likely).   In Matterhorn you can modify this options in the config.properties file setting the following option:     org.opencastproject.textanalyzer.tesseract.options=-l deu -psm 3  It is highly recommended to configure Tesseract to use your local language. It will improve the recognition a lot and\nonly this will enable the recognition of special characters specific to your local language.",
            "title": "OCR Engine: Tesseract"
        },
        {
            "location": "/modules/textextraction/#encoding-image-preprocessing",
            "text": "The text extraction works best if there is a high contrast between text and background and additionally, the text is not\ntoo thin. Ideally, this means that you have black and white images.  At this point it is probably worth noting that despite what is often said and could also be found in the documentation\nfor Matterhorn, it does not matter for Tesseract if it is black text on a white background or if the colors are inverted\n(white on black). Because of the way Tesseract works, that does not matter.  A lot of lecture slides are unfortunately not designed this way. Lecturers use colors, background images, etc. That is\nwhy, to get a better result, it is a good idea to do some image preprocessing steps. Some easy ones can be included\ndirectly into the image extraction step using FFmpeg.  For this, edit the  /etc/matterhorn/encoding/matterhorn-images.properties  and modify the command for the image\nextraction:     profile.text-analysis.http.ffmpeg.command = -ss #{time} -i #{in.video.path}\n       -filter:v boxblur=1:1,curves=all=0.4/0#{space}0.6/1\n      -frames:v 1 -pix_fmt:v gray -r 1 #{out.dir}/#{out.name}#{out.suffix}  This profile would, for example, create a gray, high contrast image. The additional light blur will reduce or remove\nnoise and thicken the normal letters.  The kind of preprocessing you should use highly depends on the input material. Interesting filters to try out for your\nmaterial are among others the blur filters, the denoise filters, the curves filter and in some cases the color-channel\nmixer.",
            "title": "Encoding (Image Preprocessing)"
        },
        {
            "location": "/modules/textextraction/#dictionaryservice-filtering",
            "text": "The filtering you want to do on the recognized texts highly depends on what you want to use the recognized texts for.\nFor searching, you might want a higher degree of filtering, for users you might also want to present text with slight\nerrors, for testing and debugging, you want no filtering at all.  Starting with version 1.6, Matterhorn provides three different kinds of implementation for filtering which can be just\nswapped out at any time:   matterhorn-dictionary-none  matterhorn-dictionary-regexp (default)  matterhorn-dictionary-hunspell",
            "title": "DictionaryService (Filtering)"
        },
        {
            "location": "/modules/textextraction/#no-filtering-matterhorn-dictionary-none",
            "text": "The  matterhorn-dictionary-none  module is the simplest one. It will just let the recognized texts pass through\nunmodified. There is no additional configuration needed or even possible. Of course, this is also the fastest one.",
            "title": "No Filtering (matterhorn-dictionary-none)"
        },
        {
            "location": "/modules/textextraction/#using-a-regular-expression-matterhorn-dictionary-regexp",
            "text": "Starting with 1.6, this is the default implementation for the DictionaryService. It is quite fast and easy to configure,\nbut is limited in terms of filtering capabilities as it will in most cases not check it a word makes sense or even if it\nmakes sense in this context.  The default expression for this module is  \\w+  which will let upper- and lowercase characters as well as digits pass\nthrough, but will block all other characters. For the German language for example, this would mean that all special\ncharacters would be blocked as well. So you want to configure Matterhorn to let them pass as well.  You can do that by modifying the  pattern  in etc/services/org.opencastproject.dictionary.regexp.DictionaryServiceImpl.properties :  For German, a suitable pattern could be:     pattern=[\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df][\\\\w\u00e4\u00f6\u00fc\u00c4\u00d6\u00dc\u00df]+[-.,:;!?]*  This will for example let all words pass which contain upper- and lowercase [a-z], digits and German special characters\nas well as punctuation at the end of a words. Additionally, it is required that the words are at least two characters\nlong which will filter out most of the common noise.  A similar pattern that could be used for Spanish would be:     pattern=[\u00bf\u00a1(]*[\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1][\\\\w\u00e1\u00e9\u00ed\u00f3\u00fa\u00c1\u00c9\u00cd\u00d3\u00da\u00fc\u00dc\u00f1\u00d1]+[)-.,:;!?]*",
            "title": "Using a Regular Expression (matterhorn-dictionary-regexp)"
        },
        {
            "location": "/modules/textextraction/#using-a-spell-checker-matterhorn-dictionary-hunspell",
            "text": "Last, the  matterhorn-dictionary-hunspell  will check words based on a spell checker and a dictionary. As spell checker,\nthe tool  hunspell  is used which is one of the most common spell checkers on Linux and should be available from the\nsystem repositories for most common operating systems.  For the Hunspell based DictionaryService, there are two configuration options.  One is for the binary and one for the\narguments to use for filtering.  By default Matterhorn will just call  hunspell  without an absolute path. This will work as long as hunspell is in the\nsystems path which should be the case unless you have built and installed it manually. In that case, the binary can be\nconfigured using the following option in the  config.properties  file:     org.opencastproject.dictionary.hunspell.binary=/usr/bin/hunspell  While most people wont need the binary path configuration, most people will need the filtering option which can be used\nfor setting the languages.  Configuration for this can be done using the following key in the  config.properties  file:     org.opencastproject.dictionary.hunspell.command=-d de_DE,en_GB,en_US -G  Note that equivalent to the tesseract configuration, again the necessary languages have to be installed in the system.\nFor German, you would on RedHat based systems for example install the  hunspell-de  package from the system\nrepositories.  For Hunspell, you can also create custom dictionaries or add custom words to the existing ones. This might be\ninteresting for technical terms.",
            "title": "Using a Spell Checker (matterhorn-dictionary-hunspell)"
        },
        {
            "location": "/modules/textextraction/#getting-matterhorn-with-specific-implementations",
            "text": "",
            "title": "Getting Matterhorn with Specific Implementations"
        },
        {
            "location": "/modules/textextraction/#building-matterhorn-from-source",
            "text": "Starting with 1.6, a default build of Matterhorn will build Matterhorn with text extraction and the RegExp based\nDictionaryService implementation. But replacing this with another implementation is not difficult. There is an\nalternatives profile in that main pom.xml which can be used, but it is probably easier, to build the desired module\ndirectly.  As an example, lets say that you want to replace the default RegExp based DictionaryService with the Hunspell based one.\nFirst of all, you would simply build Matterhorn the same way you always do running:     mvn clean install -Ddeplayto=/some/path/  This means that you would end up with all Matterhorn modules in the directory:     /some/path/lib/matterhorn/  This includes the  matterhorn-dictionary-regexp-X.Y.Z.jar  which we want to replace. Thus you can simply delete the file\nrunning:     rm /some/path/lib/matterhorn/matterhorn-dictionary-regexp-*.jar  Now switch to the  modules/matterhorn-dictionary-hunspell  subdirectory of your Matterhorn source code and run:     mvn clean install -Ddeplayto=/some/path/  This will build the curremt module only and will put the resulting JAR file in the target directory where all your other\nJARs already are.  Apart from the configuration descriped above, you are now ready to go.",
            "title": "Building Matterhorn from Source"
        },
        {
            "location": "/modules/textextraction/#installing-specific-implementations-from-the-rpm-repository",
            "text": "If you do not have an advanced knowledge of the structure of Matterhorn and the way RPM packages work, what you want to\ndo is basically the same thing you would so when building Matterhorn from source: First install a default installation,\nthen replace the module we want to replace.  Thus we start by installing Matterhorn the way we always do by running:     yum install opencast-matterhorn16  This will install Matterhorn with all its dependencies, including all necessary modules (especially the RegExp based\nDictionaryService). As we don't want this particular module, we will just remove it again by running:     yum remove opencast-matterhorn16-module-dictionary-regexp  You will notice that yum wants to remove a profile and distribution package as well. Do not worry about that, that is\nthe way it should work. The profile and distribution packages do nothing except for making sure that a given set of\nmodule-packages are installed. As you removed one, this set is not given anymore and yum will remove these metapackages\nas well.  So we now have a system with one missing module: The DictionaryService implementation. For this we now choose another\none and install it using:     yum install opencast-matterhorn16-module-dictionary-hunspell  That is it.",
            "title": "Installing Specific Implementations from the RPM Repository"
        },
        {
            "location": "/modules/videoeditor.setup/",
            "text": "Video Editor: Setup\n\n\nInstallation\n\n\nSince Matterhorn 2.0 the videoeditor modules use ffmpeg for the prcessing. An ffmpeg version > 2.4 is hardly recommended-\n\n\nConfiguration\n\n\nUI Config File Parameters\n\n\nCurrently there are two config file parameters for UI options.\n\n\nThe config file can be found at \netc/load/org.opencastproject.organization-mh_default_org.cfg\n\n\n\n\nprop.adminui.prePostRoll\n\n\nChange the duration of the pre and post roll (in seconds)\n\n\nprop.adminui.minSegmentLength\n\n\nChange the minimum required segment length (in seconds)\n\n\n\n\nSilence Detection Config Parameters\n\n\nThe settings regarding the sensitivity of the silence detection can be changed in \netc/services/org.opencastproject.silencedetection.impl.SilenceDetectionServiceImpl.properties\n.\n\n\n\n\nsilence.pre.length\n\n\nDuration of silence that should be included at the beginning of  a new voice segment. This is to avoid that a cut seems to sudden.\n\n\nDefault: 2000 (2s)\n\n\nsilence.threshold.db\n\n\nSilence threshold in decibel (e.g. -50 for loud classrooms, -35 for silent indoor location).\n\n\nDefault: -40\n\n\nsilence.min.length\n\n\nMinimum duration in milliseconds to detect a sequence as silence.\n\n\nDefault: 10000 (10s)\n\n\nvoice.min.length\n\n\nMinimum segment duration in milliseconds to start a new voice containing sequence after a silent sequence.\n\n\nDefault: 60000 (1min)\n\n\n\n\nVideo Editor Config Parameters\n\n\nThe ffmpeg properties for the Video Editor can be modified in etc/services/org.opencastproject.videoeditor.impl.VideoEditorServiceImpl.properties. Usually there should be no reason to touch this file.",
            "title": "Video Editor - Setup"
        },
        {
            "location": "/modules/videoeditor.setup/#video-editor-setup",
            "text": "",
            "title": "Video Editor: Setup"
        },
        {
            "location": "/modules/videoeditor.setup/#installation",
            "text": "Since Matterhorn 2.0 the videoeditor modules use ffmpeg for the prcessing. An ffmpeg version > 2.4 is hardly recommended-",
            "title": "Installation"
        },
        {
            "location": "/modules/videoeditor.setup/#configuration",
            "text": "",
            "title": "Configuration"
        },
        {
            "location": "/modules/videoeditor.setup/#ui-config-file-parameters",
            "text": "Currently there are two config file parameters for UI options.  The config file can be found at  etc/load/org.opencastproject.organization-mh_default_org.cfg   prop.adminui.prePostRoll  Change the duration of the pre and post roll (in seconds)  prop.adminui.minSegmentLength  Change the minimum required segment length (in seconds)",
            "title": "UI Config File Parameters"
        },
        {
            "location": "/modules/videoeditor.setup/#silence-detection-config-parameters",
            "text": "The settings regarding the sensitivity of the silence detection can be changed in  etc/services/org.opencastproject.silencedetection.impl.SilenceDetectionServiceImpl.properties .   silence.pre.length  Duration of silence that should be included at the beginning of  a new voice segment. This is to avoid that a cut seems to sudden.  Default: 2000 (2s)  silence.threshold.db  Silence threshold in decibel (e.g. -50 for loud classrooms, -35 for silent indoor location).  Default: -40  silence.min.length  Minimum duration in milliseconds to detect a sequence as silence.  Default: 10000 (10s)  voice.min.length  Minimum segment duration in milliseconds to start a new voice containing sequence after a silent sequence.  Default: 60000 (1min)",
            "title": "Silence Detection Config Parameters"
        },
        {
            "location": "/modules/videoeditor.setup/#video-editor-config-parameters",
            "text": "The ffmpeg properties for the Video Editor can be modified in etc/services/org.opencastproject.videoeditor.impl.VideoEditorServiceImpl.properties. Usually there should be no reason to touch this file.",
            "title": "Video Editor Config Parameters"
        },
        {
            "location": "/modules/videoeditor.manual/",
            "text": "Video editor: Manual\n\n\nBrowser compatibility: This editor was designed and tested for Firefox and Google Chrome. It should work with Safari\nin principle but is not extensively tested.\n\n\nOverview\n\n\n\n\nPlayer Buttons\n\n\n\n\n\n\nPlay/Pause\n\n\nPlays or pauses the video\n\n\n\n\n\n\nPrevious Marker\n\n\nJumps to the previous chapter beginning\n\n\n\n\n\n\nPrevious Frame\n\n\nSeeks one frame backwards\n\n\n\n\n\n\nSplit at current time\n\n\nInserts a new marker at the current position in the video\n\n\n\n\n\n\nPlay at current playhead with pre roll and post roll excluding removed items\n\n\nPlays the currently selected segment with a certain amount of time before and after it, deleted segments being excluded\n\n\n\n\n\n\nNext Frame\n\n\nSeeks one frame forward\n\n\n\n\n\n\nNext Marker\n\n\nJumps to the next chapter beginning\n\n\n\n\n\n\n\n\nSegment Overview\n\n\nThere are two colors to display the different states of the segment:\n\n\n\n\nRed\n\n\nThe segment is marked as \"remove\"\n\n\nThe segment will be cut out in the following processing\n\n\n\n\n\n\nGreen\n\n\nThe segment is marked as \"keep\"\n\n\nThe segment will be kept in the following processing\n\n\nThe segment is currently selected\n\n\n\n\n\n\nWhite\n\n\nThe segment is as \"keep\"\n\n\nThe segment will be kept in the following processing\n\n\nThe segment is currently not selected\n\n\n\n\n\n\n\n\nOn the one hand the segments are being displayed directly beneath the player above the waveform display:\n\n\n\n\nOn the other hand there is a segment list:\n\n\n\n\n\n\nClear segment list\n\n\nClears the segment list, removes all segments\n\n\n\n\n\n\nRe-add the item\n\n\nRe-adds the removed item (marks it as \"keep\") to not remove the item on processing\n\n\n\n\n\n\nRemove this item\n\n\nRemoves the item (marks it as \"remove\") to remove the item on processing\n\n\n\n\n\n\nSet start time of the segment\n\n\nSets a new start time of the segment\n\n\n\n\n\n\nSet end time of the segment\n\n\nSets a new end time of the segment\n\n\n\n\n\n\n\n\nZooming The Waveform\n\n\nFor more easy and precise cutting the waveform can be zoomed in via the zoom scrubber:\n\n\n\n\nWhen zoomed in you can click directly into the waveform to seek exactly to the time you clicked:\n\n\n\n\n\n\nZoom in the waveform:\n    \n\n\n\n\n\n\nClick at a point you want to seek to:\n    \n\n\n\n\n\n\nThe player seeks exactly to the time you wanted to seek to:\n    \n\n\n\n\n\n\nShortcuts\n\n\nMany shortcuts are mapped for nearly every operation:",
            "title": "Video Editor"
        },
        {
            "location": "/modules/videoeditor.manual/#video-editor-manual",
            "text": "Browser compatibility: This editor was designed and tested for Firefox and Google Chrome. It should work with Safari\nin principle but is not extensively tested.",
            "title": "Video editor: Manual"
        },
        {
            "location": "/modules/videoeditor.manual/#overview",
            "text": "",
            "title": "Overview"
        },
        {
            "location": "/modules/videoeditor.manual/#player-buttons",
            "text": "Play/Pause  Plays or pauses the video    Previous Marker  Jumps to the previous chapter beginning    Previous Frame  Seeks one frame backwards    Split at current time  Inserts a new marker at the current position in the video    Play at current playhead with pre roll and post roll excluding removed items  Plays the currently selected segment with a certain amount of time before and after it, deleted segments being excluded    Next Frame  Seeks one frame forward    Next Marker  Jumps to the next chapter beginning",
            "title": "Player Buttons"
        },
        {
            "location": "/modules/videoeditor.manual/#segment-overview",
            "text": "There are two colors to display the different states of the segment:   Red  The segment is marked as \"remove\"  The segment will be cut out in the following processing    Green  The segment is marked as \"keep\"  The segment will be kept in the following processing  The segment is currently selected    White  The segment is as \"keep\"  The segment will be kept in the following processing  The segment is currently not selected     On the one hand the segments are being displayed directly beneath the player above the waveform display:   On the other hand there is a segment list:    Clear segment list  Clears the segment list, removes all segments    Re-add the item  Re-adds the removed item (marks it as \"keep\") to not remove the item on processing    Remove this item  Removes the item (marks it as \"remove\") to remove the item on processing    Set start time of the segment  Sets a new start time of the segment    Set end time of the segment  Sets a new end time of the segment",
            "title": "Segment Overview"
        },
        {
            "location": "/modules/videoeditor.manual/#zooming-the-waveform",
            "text": "For more easy and precise cutting the waveform can be zoomed in via the zoom scrubber:   When zoomed in you can click directly into the waveform to seek exactly to the time you clicked:    Zoom in the waveform:\n        Click at a point you want to seek to:\n        The player seeks exactly to the time you wanted to seek to:",
            "title": "Zooming The Waveform"
        },
        {
            "location": "/modules/videoeditor.manual/#shortcuts",
            "text": "Many shortcuts are mapped for nearly every operation:",
            "title": "Shortcuts"
        },
        {
            "location": "/modules/videoeditor.architecture/",
            "text": "Video Editor: Architecture\n\n\nModules Of The Videoeditor\n\n\nThe Videoeditor consists of the following moduls. Additional to this there is a Workflow Operation Handler within the Conductor module that provides the UI elements for the Video Editor. \n\n\n\n\nmatterhorn-silencedetection-api\n\n\nAPI for the silence detection\n\n\nmatterhorn-silencedetection-impl\n\n\nImplementation of the silence detection service\n\n\nProvides a SMIL file that can be used by the Video Editor UI or the Video Editor service to create a new cutted file.\n\n\nmatterhorn-silencedetection-remote\n\n\nRemote implementation of the silence detection service to enable load balancing in a distributed setup.\n\n\nmatterhorn-smil-api\n\n\nAPI for the SMIL service\n\n\nmatterhorn-smil-impl\n\n\nThe SMIL service allows creation and manipulation of SMIL files. This is more or less a helper class to create consistent SMIL files.\n\n\nmatterhorn-videoeditor-api\n\n\nThe API for the Video Editor which takes a SMIL file as an input to create a cutted version of the media files.\n\n\nmatterhorn-videoeditor-impl\n\n\nThe Video Editor service creates new media files that will be cutted based on the information provided in a SMIL file. In the current implementation GStreamer with the gnonlin module is used to process the files.\n\n\nmatterhorn-videoeditor-remote\n\n\nRemote implementation of the video editor service to enable load balancing in a distributed setup.\n\n\n\n\nSeveral other changes have been made on other Matterhorn modules to provide a better user experience for the video editor (i.e. byte-range request on the working-file-repository).\n\n\nEdit List Format\n\n\nThe video editor uses SMIL 3.0 as a standardized Data format for the edit lists (cutting information). Some conventions and namespace extensions have been made to make sure that Matterhorn is able to find the files.\n\n\n\n\nAs we usually have two (or more) parallel media files, these files are grouped in a \n<par>\n-element which forms a segment that should be included in the resulting video.  This means the included \n<video>\n-files will be played in parallel.\n\n\nThe clipBegin and clipEnd attributes a provided as milliseconds. Usually these should be identical for all \n<videos>\n within a \n<par>\n.\nFor each segment a \n<par>\n is created.\n\n\nIn the result of the silence detection segments with silence are omitted within the SMIL files, so only segments within the SMIL doc will be in the resulting video.\n\n\nThe segments within the SMIL file will be in the order they are written down. If the sequence of the segments is changed, the sequence within the resulting video is changed too.\n\n\n\n\nExample SMIL file\n\n\n<smil xmlns=\"http://www.w3.org/ns/SMIL\" baseProfile=\"Language\" version=\"3.0\" xml:id=\"s-524c7815-4520-48e4-bb5e-94dcfdb3229f\">\n    <head xml:id=\"h-03b31c8d-68cf-49ea-8bae-d94abddf8f09\">\n        <meta name=\"track-duration\" content=\"6000841ms\" xml:id=\"meta-32069ddb-351d-4dca-a742-b9be490080f8\"/>\n        <paramGroup xml:id=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\">\n            <param value=\"9f373445-5f46-4bdd-8d93-dca5e1094c38\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-d509b427-b239-4c4b-985a-f8b4ea31bbfb\"/>\n            <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-411e0015-af0e-463c-898d-9a2bc594df46\"/>\n            <param value=\"presenter/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-5ea022cd-189d-420f-9cea-4f6775af285e\"/>\n        </paramGroup>\n        <paramGroup xml:id=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\">\n            <param value=\"9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-c3c427ad-ef8a-4a71-9b0c-9208dd8a6bed\"/>\n            <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-c15e1ed7-f773-456d-a007-fc237d9e0665\"/>\n            <param value=\"presentation/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-97d5b5ac-1258-4267-a013-dc3882d7e242\"/>\n        </paramGroup>\n    </head>\n    <body xml:id=\"b-c233c9ef-42d9-4f50-a1d2-29e3bbff003d\">\n        <par xml:id=\"par-7955133a-bcbe-40f8-87fd-47e78b3357c0\">\n            <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" paramGroup=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-61f5d0ee-dd36-4b1d-af3d-3f09f8807179\"/>\n            <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" paramGroup=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-c68260e7-fd0d-4df6-8696-cc475ab3b3f8\"/>\n        </par>\n    </body> \n</smil>\n\n\n\nWorkflow Operations\n\n\nWaveform Operation\n\n\nThe \nwaveform\n operation creates an image showing the temporal audio activity within the recording. This is be done with a probably well known waveform (see example image). \n\n\n\n\nThe operation does not need an additional module, as it is not very work intensive to create such an image. The operation needs and audio-only file to create the image and it provides an PNG image.\n\n\nInput parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be used if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example).\n\n\nThe output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too.\n\n\nWaveform Operation Template\n\n\n<operation\n  id=\"waveform\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Generating waveform\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/audio</configuration>\n    <configuration key=\"target-flavor\">*/waveform</configuration>\n  </configurations>\n</operation>\n\n\n\nSilence Operation\n\n\nThe \nsilence\n operation performs a silence detection on an audio-only input file. The operation needs the silence detection API and impl (or remote in a distributed system) modules to be installed to process the request.\n\n\nThe input parameters are source-flavors that takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type, and reference-tracks-flavour where the subtype of the media files that should be included in the provided SMIL file will be set. The * should not be modified here. In most cases it is not important which reference-tracks-flavour is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality.\n\n\nThe output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced. \n\n\nThe output of this operation is a SMIL file (see the example above).\n\n\nSilence Operation Template\n\n\n<operation\n  id=\"silence\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Executing silence detection\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/audio</configuration>\n    <configuration key=\"smil-flavor-subtype\">smil</configuration>\n    <configuration key=\"reference-tracks-flavor\">*/preview</configuration>\n  </configurations>\n</operation>\n\n\n\nEditor Operation\n\n\nThe \neditor\n operation provides the UI for editing trim hold state and processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed.\n\n\nThe input parameters are:\n\n\n\n\nsource-flavors: the subtype of all media files in the best available quality and in a codec that can be processed by the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only the subtype is important. All needed videos should be available within this flavor.\n\n\npreview-flavours: the subtype of the media files that should be used for the preview player. This is an HTML5 player so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors.\n\n\nsmil-flavors: the smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil will be favored, if this is not available the first in the list will be used.\n\n\nskipped-flavors: the flavor of the files that should be used if this workflow-operation is skipped.\n\n\n\n\nThe output parameters are:\n - target-smil-flavor: only a unique flavor is allowed here, as this is the file that the editor UI writes and that will be taken for processing the edited files afterwards.\n - target-flavor-subtype: the flavor-subtype that will be used for all media files created in this operation.\n\n\nEditor Operation Template\n\n\n<operation\n  id=\"editor\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Waiting for user to review / video edit recording\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/work</configuration>\n    <configuration key=\"preview-flavors\">*/preview</configuration>\n    <configuration key=\"skipped-flavors\">*/preview</configuration>\n    <configuration key=\"smil-flavors\">*/smil</configuration>\n    <configuration key=\"target-smil-flavor\">episode/smil</configuration>\n    <configuration key=\"target-flavor-subtype\">trimmed</configuration>\n  </configurations>\n</operation>\n\n\n\nIncluding The Video Editor To The Workflow Definition File\n\n\nIncluding the Video Editor with the silence detection into the needs some changes in the default workflow. Several of the steps here are inherited from the trim-operations and the workflow it was included too. We assume that you set ${trimHold} variable like in the current workflow definitions with trimming.\n\n\n\n\nThe prepare-av operations has to be adopted. Gstreamer/gnonlin is kind of picky on the codec that it supports. So the media file has to be re-encoded in the beginning of the workflow. The prepare-av encoding profiles (av.work and mux-av.work) have been updated in the Video Editor branch for this. Within the prepare-av operation in the workflow-definition XML-file rewriting the file should be forced:\n\n\n\n\nChanges in the workflow definition\n\n\n<configuration key=\"rewrite\">true</configuration>\n\n\n<configuration key=\"promiscuous-audio-muxing\">true</configuration>\n\n\n\n\nThe preview videos have to be created. These can be in H.264 (for Safari, IE, Chrome) or WebM (for Firefox, Opera or Chrome) codec. Encoding profiles for WebM are provided in the video editor branch and are used in the examples. This operation should be after the prepare-av operation.\n\n\n\n\nWorkflow operation to create WebM preview videos\n\n\n<operation\n  id=\"compose\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Encoding presenter (camera) video for videoeditor preview\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/preview</configuration>\n    <configuration key=\"encoding-profile\">webm-preview.http</configuration>\n  </configurations>\n</operation>\n\n\n\n\n\n\n\nAn audio-only file has to be composed for the waveform and silence operation. This operation should be after the prepare-av operation.\nWorkflow operation to compose the audio-only file(s)\n\n\n\n  \n\n    \n/work\n\n    \n/audio\n\n    \naudio.wav\n\n  \n\n\n\n\n\n\n\n\nThe waveform operation should be included. See above for the XML-code for this operation. The audio-only file should already be available.\n\n\n\n\nThe silence detection should be done. See above for the XML-code for this operation. The audio-only file should already be available.\n\n\nAfter all previous operations have been done the editor can be included. See above for the XML-code for this operation. \n\n\nYou may consider to tag the trimmed files for archiving. Then you should include this operation after the editor:\n\n\n\n\nTagging trimmed files for the archive\n\n\n<operation\n  id=\"tag\"\n  description=\"Tagging media for archival\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/trimmed</configuration>\n    <configuration key=\"target-tags\">+archive</configuration>\n  </configurations>\n</operation>\n\n\n\nYou could check, if you want to archive the source media too, or remove the source-flavors from the previous tagging operations.\n\n\n\n\nThe rest of the workflow definition can be kept as it is, the input flavor subtype for the trimmed files in other operations is \"/trimmed\" if you follow the naming in this example. \n\n\n\n\nThe default \ncompose-distribute-publish.xml\n workflow definition within the Video Editor branch has already been updated to include the editor instead of the trim-hold state. The trim operation is not overwritten with the video editor but could still be used.",
            "title": "Video Editor - Architecture"
        },
        {
            "location": "/modules/videoeditor.architecture/#video-editor-architecture",
            "text": "",
            "title": "Video Editor: Architecture"
        },
        {
            "location": "/modules/videoeditor.architecture/#modules-of-the-videoeditor",
            "text": "The Videoeditor consists of the following moduls. Additional to this there is a Workflow Operation Handler within the Conductor module that provides the UI elements for the Video Editor.    matterhorn-silencedetection-api  API for the silence detection  matterhorn-silencedetection-impl  Implementation of the silence detection service  Provides a SMIL file that can be used by the Video Editor UI or the Video Editor service to create a new cutted file.  matterhorn-silencedetection-remote  Remote implementation of the silence detection service to enable load balancing in a distributed setup.  matterhorn-smil-api  API for the SMIL service  matterhorn-smil-impl  The SMIL service allows creation and manipulation of SMIL files. This is more or less a helper class to create consistent SMIL files.  matterhorn-videoeditor-api  The API for the Video Editor which takes a SMIL file as an input to create a cutted version of the media files.  matterhorn-videoeditor-impl  The Video Editor service creates new media files that will be cutted based on the information provided in a SMIL file. In the current implementation GStreamer with the gnonlin module is used to process the files.  matterhorn-videoeditor-remote  Remote implementation of the video editor service to enable load balancing in a distributed setup.   Several other changes have been made on other Matterhorn modules to provide a better user experience for the video editor (i.e. byte-range request on the working-file-repository).",
            "title": "Modules Of The Videoeditor"
        },
        {
            "location": "/modules/videoeditor.architecture/#edit-list-format",
            "text": "The video editor uses SMIL 3.0 as a standardized Data format for the edit lists (cutting information). Some conventions and namespace extensions have been made to make sure that Matterhorn is able to find the files.   As we usually have two (or more) parallel media files, these files are grouped in a  <par> -element which forms a segment that should be included in the resulting video.  This means the included  <video> -files will be played in parallel.  The clipBegin and clipEnd attributes a provided as milliseconds. Usually these should be identical for all  <videos>  within a  <par> .\nFor each segment a  <par>  is created.  In the result of the silence detection segments with silence are omitted within the SMIL files, so only segments within the SMIL doc will be in the resulting video.  The segments within the SMIL file will be in the order they are written down. If the sequence of the segments is changed, the sequence within the resulting video is changed too.   Example SMIL file  <smil xmlns=\"http://www.w3.org/ns/SMIL\" baseProfile=\"Language\" version=\"3.0\" xml:id=\"s-524c7815-4520-48e4-bb5e-94dcfdb3229f\">\n    <head xml:id=\"h-03b31c8d-68cf-49ea-8bae-d94abddf8f09\">\n        <meta name=\"track-duration\" content=\"6000841ms\" xml:id=\"meta-32069ddb-351d-4dca-a742-b9be490080f8\"/>\n        <paramGroup xml:id=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\">\n            <param value=\"9f373445-5f46-4bdd-8d93-dca5e1094c38\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-d509b427-b239-4c4b-985a-f8b4ea31bbfb\"/>\n            <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-411e0015-af0e-463c-898d-9a2bc594df46\"/>\n            <param value=\"presenter/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-5ea022cd-189d-420f-9cea-4f6775af285e\"/>\n        </paramGroup>\n        <paramGroup xml:id=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\">\n            <param value=\"9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f\" name=\"track-id\" valuetype=\"data\" xml:id=\"param-c3c427ad-ef8a-4a71-9b0c-9208dd8a6bed\"/>\n            <param value=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" name=\"track-src\" valuetype=\"data\" xml:id=\"param-c15e1ed7-f773-456d-a007-fc237d9e0665\"/>\n            <param value=\"presentation/preview\" name=\"track-flavor\" valuetype=\"data\" xml:id=\"param-97d5b5ac-1258-4267-a013-dc3882d7e242\"/>\n        </paramGroup>\n    </head>\n    <body xml:id=\"b-c233c9ef-42d9-4f50-a1d2-29e3bbff003d\">\n        <par xml:id=\"par-7955133a-bcbe-40f8-87fd-47e78b3357c0\">\n            <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9f373445-5f46-4bdd-8d93-dca5e1094c38/lecturer.mp4\" paramGroup=\"pg-bb1e4ab7-08e8-4ae7-9da8-1f6d46b56387\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-61f5d0ee-dd36-4b1d-af3d-3f09f8807179\"/>\n            <video src=\"http://my.server.tld/files/mediapackage/98c91b97-51de-46ae-992d-c497798f16c8/9af21dad-cb92-4e18-bc4c-b8c9b7ce4e2f/screen.mp4\" paramGroup=\"pg-35035f9c-ab9a-49a7-9ef8-9825190b949b\" clipEnd=\"5522400ms\" clipBegin=\"157880ms\" xml:id=\"v-c68260e7-fd0d-4df6-8696-cc475ab3b3f8\"/>\n        </par>\n    </body> \n</smil>",
            "title": "Edit List Format"
        },
        {
            "location": "/modules/videoeditor.architecture/#workflow-operations",
            "text": "",
            "title": "Workflow Operations"
        },
        {
            "location": "/modules/videoeditor.architecture/#waveform-operation",
            "text": "The  waveform  operation creates an image showing the temporal audio activity within the recording. This is be done with a probably well known waveform (see example image).    The operation does not need an additional module, as it is not very work intensive to create such an image. The operation needs and audio-only file to create the image and it provides an PNG image.  Input parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be used if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example).  The output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too.  Waveform Operation Template  <operation\n  id=\"waveform\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Generating waveform\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/audio</configuration>\n    <configuration key=\"target-flavor\">*/waveform</configuration>\n  </configurations>\n</operation>",
            "title": "Waveform Operation"
        },
        {
            "location": "/modules/videoeditor.architecture/#silence-operation",
            "text": "The  silence  operation performs a silence detection on an audio-only input file. The operation needs the silence detection API and impl (or remote in a distributed system) modules to be installed to process the request.  The input parameters are source-flavors that takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type, and reference-tracks-flavour where the subtype of the media files that should be included in the provided SMIL file will be set. The * should not be modified here. In most cases it is not important which reference-tracks-flavour is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality.  The output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced.   The output of this operation is a SMIL file (see the example above).  Silence Operation Template  <operation\n  id=\"silence\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Executing silence detection\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/audio</configuration>\n    <configuration key=\"smil-flavor-subtype\">smil</configuration>\n    <configuration key=\"reference-tracks-flavor\">*/preview</configuration>\n  </configurations>\n</operation>",
            "title": "Silence Operation"
        },
        {
            "location": "/modules/videoeditor.architecture/#editor-operation",
            "text": "The  editor  operation provides the UI for editing trim hold state and processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed.  The input parameters are:   source-flavors: the subtype of all media files in the best available quality and in a codec that can be processed by the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only the subtype is important. All needed videos should be available within this flavor.  preview-flavours: the subtype of the media files that should be used for the preview player. This is an HTML5 player so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors.  smil-flavors: the smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil will be favored, if this is not available the first in the list will be used.  skipped-flavors: the flavor of the files that should be used if this workflow-operation is skipped.   The output parameters are:\n - target-smil-flavor: only a unique flavor is allowed here, as this is the file that the editor UI writes and that will be taken for processing the edited files afterwards.\n - target-flavor-subtype: the flavor-subtype that will be used for all media files created in this operation.  Editor Operation Template  <operation\n  id=\"editor\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Waiting for user to review / video edit recording\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/work</configuration>\n    <configuration key=\"preview-flavors\">*/preview</configuration>\n    <configuration key=\"skipped-flavors\">*/preview</configuration>\n    <configuration key=\"smil-flavors\">*/smil</configuration>\n    <configuration key=\"target-smil-flavor\">episode/smil</configuration>\n    <configuration key=\"target-flavor-subtype\">trimmed</configuration>\n  </configurations>\n</operation>",
            "title": "Editor Operation"
        },
        {
            "location": "/modules/videoeditor.architecture/#including-the-video-editor-to-the-workflow-definition-file",
            "text": "Including the Video Editor with the silence detection into the needs some changes in the default workflow. Several of the steps here are inherited from the trim-operations and the workflow it was included too. We assume that you set ${trimHold} variable like in the current workflow definitions with trimming.   The prepare-av operations has to be adopted. Gstreamer/gnonlin is kind of picky on the codec that it supports. So the media file has to be re-encoded in the beginning of the workflow. The prepare-av encoding profiles (av.work and mux-av.work) have been updated in the Video Editor branch for this. Within the prepare-av operation in the workflow-definition XML-file rewriting the file should be forced:   Changes in the workflow definition  <configuration key=\"rewrite\">true</configuration>  <configuration key=\"promiscuous-audio-muxing\">true</configuration>   The preview videos have to be created. These can be in H.264 (for Safari, IE, Chrome) or WebM (for Firefox, Opera or Chrome) codec. Encoding profiles for WebM are provided in the video editor branch and are used in the examples. This operation should be after the prepare-av operation.   Workflow operation to create WebM preview videos  <operation\n  id=\"compose\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Encoding presenter (camera) video for videoeditor preview\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/preview</configuration>\n    <configuration key=\"encoding-profile\">webm-preview.http</configuration>\n  </configurations>\n</operation>    An audio-only file has to be composed for the waveform and silence operation. This operation should be after the prepare-av operation.\nWorkflow operation to compose the audio-only file(s)  \n   \n     /work \n     /audio \n     audio.wav \n       The waveform operation should be included. See above for the XML-code for this operation. The audio-only file should already be available.   The silence detection should be done. See above for the XML-code for this operation. The audio-only file should already be available.  After all previous operations have been done the editor can be included. See above for the XML-code for this operation.   You may consider to tag the trimmed files for archiving. Then you should include this operation after the editor:   Tagging trimmed files for the archive  <operation\n  id=\"tag\"\n  description=\"Tagging media for archival\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/trimmed</configuration>\n    <configuration key=\"target-tags\">+archive</configuration>\n  </configurations>\n</operation>  You could check, if you want to archive the source media too, or remove the source-flavors from the previous tagging operations.   The rest of the workflow definition can be kept as it is, the input flavor subtype for the trimmed files in other operations is \"/trimmed\" if you follow the naming in this example.    The default  compose-distribute-publish.xml  workflow definition within the Video Editor branch has already been updated to include the editor instead of the trim-hold state. The trim operation is not overwritten with the video editor but could still be used.",
            "title": "Including The Video Editor To The Workflow Definition File"
        },
        {
            "location": "/modules/videosegmentation/",
            "text": "Video Segmentation Configuration\n\n\nWhat is Video Segmentation\n\n\nVideo segmentation is a way of dividing a movie into meaningful segments. In the context of lecture capture,\nsegmentation is best applied to captured screen presentation, that the presenter goes through slide after slide.\n\n\nAs a result, video segmentation returns the exact timepoints of slide changes on the timeline, which allows for\nsophisticated ways for the learner to browse the lecture content, as shown in the slides section of the Matterhorn Media\nPlayer.\n\n\nHow the video segmentation process works\n\n\nFor detecting new scenes, Matterhorn uses the scene detection build into the FFmpeg select filter. The basic idea behind\nthis filter is to compare to consecutive frames and decide if the second frame belongs to a new scene based on the\ndifference.\n\n\nConfiguration\n\n\nThe value for the frame difference as well as the minimum length for a segment can be configured in\n\netc/services/org.opencastproject.videosegmenter.ffmpeg.VideoSegmenterServiceImpl.properties\n.\n\n\nThe two options that can be set are the minimum length of a segment (defaults to 5 sec).\n\n\nstabilitythreshold = 5\n\n\n\nThe percentage of pixels that may change between tow frames without considering them different (defaults to 0.05).\n\n\nchangesthreshold = 0.05",
            "title": "Video Segmentation"
        },
        {
            "location": "/modules/videosegmentation/#video-segmentation-configuration",
            "text": "",
            "title": "Video Segmentation Configuration"
        },
        {
            "location": "/modules/videosegmentation/#what-is-video-segmentation",
            "text": "Video segmentation is a way of dividing a movie into meaningful segments. In the context of lecture capture,\nsegmentation is best applied to captured screen presentation, that the presenter goes through slide after slide.  As a result, video segmentation returns the exact timepoints of slide changes on the timeline, which allows for\nsophisticated ways for the learner to browse the lecture content, as shown in the slides section of the Matterhorn Media\nPlayer.",
            "title": "What is Video Segmentation"
        },
        {
            "location": "/modules/videosegmentation/#how-the-video-segmentation-process-works",
            "text": "For detecting new scenes, Matterhorn uses the scene detection build into the FFmpeg select filter. The basic idea behind\nthis filter is to compare to consecutive frames and decide if the second frame belongs to a new scene based on the\ndifference.",
            "title": "How the video segmentation process works"
        },
        {
            "location": "/modules/videosegmentation/#configuration",
            "text": "The value for the frame difference as well as the minimum length for a segment can be configured in etc/services/org.opencastproject.videosegmenter.ffmpeg.VideoSegmenterServiceImpl.properties .  The two options that can be set are the minimum length of a segment (defaults to 5 sec).  stabilitythreshold = 5  The percentage of pixels that may change between tow frames without considering them different (defaults to 0.05).  changesthreshold = 0.05",
            "title": "Configuration"
        },
        {
            "location": "/modules/youtubepublication/",
            "text": "YouTube Publication Configuration\n\n\nThis page documents the configuration for Matterhorn module\n\nmatterhorn-publication-service-youtube-v3\n.\n\n\nCreate new Google Project\n\n\n\n\nLogin to Google account\n\n\nNavigate to the \nGoogle Developers Console\n\n\nClick \nCreate Project\n and follow the instructions\n\n\nOn your new projects page, choose \nAPIs & auth\n then \nConsent screen\n\nin the navigation pane\n\n\nSet the \nPRODUCT NAME\n and the \nEMAIL ADDRESS\n\n\n\n\nEnable API\n\n\n\n\nChoose \nAPIs\n in the navigation pane\n\n\nUse the filter to find and enable \nYouTube Data API v3\n\n\n\n\nRegister an Application\n\n\n\n\nChoose \nCredentials\n in the navigation pane\n\n\nClick \nCreate new Client ID\n for OAuth\n\n\nChoose \nInstalled application\n for the application type\nand \nOther\n for the installed application type\n\n\nAccept with \nCreate Client ID\n\n\n\n\nSave Client ID in JSON Format\n\n\n\n\nDownload the client information in JSON format by clicking \nDownload JSON\n\n\nSave the JSON file to\n\n${bundles.configuration.location}/youtube-v3/client-secrets-youtube-v3.json\n\n(Usually this is \netc/youtube-v3/client-secrets-youtube-v3.json\n)\n\n\n\n\nGenerate OAuth Tokens\n\n\n\n\nStart Matterhorn\n\n\nFollow the request URL appearing in the Matterhorn console output and click\n\nAccept\n\n\nThe resulting website will say \nReceived verification code. Closing...\n\n\n\n\nThe generated token is saved at\n\n${org.opencastproject.storage.dir}/youtube-v3/data-store/store\n\n(Usually this is \nwork/opencast/youtube-v3/data-store/store\n).\nIf the file is not found or invalid a new request URL will be generated.\nBoth paths for the JSON file and the token file can be altered in the\nservice properties file at \netc/services/org.opencastproject.publication.\nyoutube.YouTubePublicationServiceImpl.properties",
            "title": "YouTube publication"
        },
        {
            "location": "/modules/youtubepublication/#youtube-publication-configuration",
            "text": "This page documents the configuration for Matterhorn module matterhorn-publication-service-youtube-v3 .",
            "title": "YouTube Publication Configuration"
        },
        {
            "location": "/modules/youtubepublication/#create-new-google-project",
            "text": "Login to Google account  Navigate to the  Google Developers Console  Click  Create Project  and follow the instructions  On your new projects page, choose  APIs & auth  then  Consent screen \nin the navigation pane  Set the  PRODUCT NAME  and the  EMAIL ADDRESS",
            "title": "Create new Google Project"
        },
        {
            "location": "/modules/youtubepublication/#enable-api",
            "text": "Choose  APIs  in the navigation pane  Use the filter to find and enable  YouTube Data API v3",
            "title": "Enable API"
        },
        {
            "location": "/modules/youtubepublication/#register-an-application",
            "text": "Choose  Credentials  in the navigation pane  Click  Create new Client ID  for OAuth  Choose  Installed application  for the application type\nand  Other  for the installed application type  Accept with  Create Client ID",
            "title": "Register an Application"
        },
        {
            "location": "/modules/youtubepublication/#save-client-id-in-json-format",
            "text": "Download the client information in JSON format by clicking  Download JSON  Save the JSON file to ${bundles.configuration.location}/youtube-v3/client-secrets-youtube-v3.json \n(Usually this is  etc/youtube-v3/client-secrets-youtube-v3.json )",
            "title": "Save Client ID in JSON Format"
        },
        {
            "location": "/modules/youtubepublication/#generate-oauth-tokens",
            "text": "Start Matterhorn  Follow the request URL appearing in the Matterhorn console output and click Accept  The resulting website will say  Received verification code. Closing...   The generated token is saved at ${org.opencastproject.storage.dir}/youtube-v3/data-store/store \n(Usually this is  work/opencast/youtube-v3/data-store/store ).\nIf the file is not found or invalid a new request URL will be generated.\nBoth paths for the JSON file and the token file can be altered in the\nservice properties file at  etc/services/org.opencastproject.publication.\nyoutube.YouTubePublicationServiceImpl.properties",
            "title": "Generate OAuth Tokens"
        },
        {
            "location": "/upgrade/",
            "text": "Upgrading Matterhorn to 2.0\n\n\nDatabase Migration\n\n\nYou will find the database migration script in /docs/upgrade/1.6_to_2.0/\n.sql\n\n\nRebuilding Search Indices\n\n\nTo update the search indices:\n\n\n\n\nShutdown Matterhorn\n\n\nUpgrade the database, if not already done\n\n\n\n\nDelete (or move) your search indices\n\n\n\n\n${org.opencastproject.storage.dir}/searchindex\n\n\n${org.opencastproject.storage.dir}/seriesindex\n\n\n${org.opencastproject.storage.dir}/schedulerindex\n\n\n\n\n\n\n\n\nRestart Matterhorn. Rebuilding the indices can take quite a while depending on the number of recordings in your system.\n\n\n\n\n\n\nUpdating Existing Workflow Definitions\n\n\nExisting workflows will not work with the new admin UI in Matterhorn 2.0. They still work with the old admin ui that is still available. \n\n\nThe new admin UI needs an \"admin-ng\" tag in the workflow.\n\n\nThe new admin UI does not support hold-states anymore.\n\n\nConfiguration changes",
            "title": "Upgrading Home"
        },
        {
            "location": "/upgrade/#upgrading-matterhorn-to-20",
            "text": "",
            "title": "Upgrading Matterhorn to 2.0"
        },
        {
            "location": "/upgrade/#database-migration",
            "text": "You will find the database migration script in /docs/upgrade/1.6_to_2.0/ .sql",
            "title": "Database Migration"
        },
        {
            "location": "/upgrade/#rebuilding-search-indices",
            "text": "To update the search indices:   Shutdown Matterhorn  Upgrade the database, if not already done   Delete (or move) your search indices   ${org.opencastproject.storage.dir}/searchindex  ${org.opencastproject.storage.dir}/seriesindex  ${org.opencastproject.storage.dir}/schedulerindex     Restart Matterhorn. Rebuilding the indices can take quite a while depending on the number of recordings in your system.",
            "title": "Rebuilding Search Indices"
        },
        {
            "location": "/upgrade/#updating-existing-workflow-definitions",
            "text": "Existing workflows will not work with the new admin UI in Matterhorn 2.0. They still work with the old admin ui that is still available.   The new admin UI needs an \"admin-ng\" tag in the workflow.  The new admin UI does not support hold-states anymore.",
            "title": "Updating Existing Workflow Definitions"
        },
        {
            "location": "/upgrade/#configuration-changes",
            "text": "",
            "title": "Configuration changes"
        },
        {
            "location": "/workflowoperationhandlers/",
            "text": "Workflow Operation Handler\n\n\nIntroduction\n\n\nWorkflows are the central element to define how a media package is being processed by the Matterhorn services. Their definitions consist of a list of workflow operations, which basically map a piece of configuration to Matterhorn code:\n\n\n<definition xmlns=\"http://workflow.opencastproject.org\">\n    ....\n    <operation\n      id=\"tag\"\n      <configurations>\n        <configuration key=\"source-flavors\">presentation/trimmed</configuration>\n        <configuration key=\"target-flavor\">presentation/tagged</configuration>\n      </configurations>\n   </operation>\n   ...\n</definition>\n\n\n\nDefault Workflow Operations\n\n\nThe following table contains the workflow operations that are available in an out-of-the-box Matterhorn installation:\n\n\n\n\n\n\n\n\nOperation Handler\n\n\nDescription\n\n\nDetails\n\n\n\n\n\n\n\n\n\n\nanalyze-audio\n\n\nAnalyze first audio stream\n\n\nDocumentation\n\n\n\n\n\n\nappend\n\n\nHold for user to select workflow to continue with\n\n\nDocumentation\n\n\n\n\n\n\narchive\n\n\nArchive the current state of the mediapackage\n\n\nDocumentation\n\n\n\n\n\n\ncaption\n\n\nWaiting for user to upload captions\n\n\nDocumentation\n\n\n\n\n\n\ncleanup\n\n\nCleanup the working file repository\n\n\n\n\n\n\n\n\ncompose\n\n\nEncode media files using FFmpeg\n\n\nDocumentation\n\n\n\n\n\n\ncomposite\n\n\nCompose two videos on one canvas.\n\n\nDocumentation\n\n\n\n\n\n\nconcat\n\n\nConcatenate multiple video tracks into one video track\n\n\nDocumentation\n\n\n\n\n\n\ndefaults\n\n\nApplies default workflow configuration values\n\n\nDocumentation\n\n\n\n\n\n\neditor\n\n\nWaiting for user to review, then cut video based on edit-list\n\n\nDocumentation\n\n\n\n\n\n\nemail\n\n\nSends email notifications at any part of a workflow\n\n\nDocumentation\n\n\n\n\n\n\nextract-text\n\n\nExtracting text from presentation segments\n\n\nDocumentation\n\n\n\n\n\n\nhttp-notify\n\n\nNotifies an HTTP endpoint about the process of the workflow\n\n\nDocumentation\n\n\n\n\n\n\nimage\n\n\nExtract images from a video using FFmpeg\n\n\nDocumentation\n\n\n\n\n\n\nimage-to-video\n\n\nCreate a video track from a source image\n\n\nDocumentation\n\n\n\n\n\n\nincident\n\n\nTesting incidents on a dummy job\n\n\nDocumentation\n\n\n\n\n\n\ningest-download\n\n\nDownload files from external URL for ingest\n\n\nDocumentation\n\n\n\n\n\n\ninspect\n\n\nInspect the media (check if it is valid)\n\n\nDocumentation\n\n\n\n\n\n\nnormalize-audio\n\n\nNormalize first audio stream\n\n\nDocumentation\n\n\n\n\n\n\npost-mediapackage\n\n\nSend mediapackage to remote service\n\n\nDocumentation\n\n\n\n\n\n\nprepare-av\n\n\nPreparing audio and video work versions\n\n\nDocumentation\n\n\n\n\n\n\npublish-engage\n\n\nDistribute and publish media to the engage player\n\n\nDocumentation\n\n\n\n\n\n\nrepublish\n\n\nRepublishes elements to search\n\n\nDocumentation\n\n\n\n\n\n\nsegment-video\n\n\nExtracting segments from presentation\n\n\nDocumentation\n\n\n\n\n\n\nsegmentpreviews\n\n\nExtract segment images from a video using FFmpeg\n\n\nDocumentation\n\n\n\n\n\n\nseries\n\n\nApply series to the mediapackage\n\n\nDocumentation\n\n\n\n\n\n\nsilence\n\n\nSilence detection on audio of the mediapackage\n\n\nDocumentation\n\n\n\n\n\n\ntag\n\n\nModify the tag sets of media package elements\n\n\nDocumentation\n\n\n\n\n\n\ntrim\n\n\nWaiting for user to review, then trim the recording\n\n\nDocumentation\n\n\n\n\n\n\nwaveform\n\n\nCreate a waveform image of the audio of the mediapackage\n\n\nDocumentation\n\n\n\n\n\n\nzip\n\n\nCreate zipped archive of the current state of the mediapackage\n\n\nDocumentation",
            "title": "Workflow Operation Handler Overview"
        },
        {
            "location": "/workflowoperationhandlers/#workflow-operation-handler",
            "text": "",
            "title": "Workflow Operation Handler"
        },
        {
            "location": "/workflowoperationhandlers/#introduction",
            "text": "Workflows are the central element to define how a media package is being processed by the Matterhorn services. Their definitions consist of a list of workflow operations, which basically map a piece of configuration to Matterhorn code:  <definition xmlns=\"http://workflow.opencastproject.org\">\n    ....\n    <operation\n      id=\"tag\"\n      <configurations>\n        <configuration key=\"source-flavors\">presentation/trimmed</configuration>\n        <configuration key=\"target-flavor\">presentation/tagged</configuration>\n      </configurations>\n   </operation>\n   ...\n</definition>",
            "title": "Introduction"
        },
        {
            "location": "/workflowoperationhandlers/#default-workflow-operations",
            "text": "The following table contains the workflow operations that are available in an out-of-the-box Matterhorn installation:     Operation Handler  Description  Details      analyze-audio  Analyze first audio stream  Documentation    append  Hold for user to select workflow to continue with  Documentation    archive  Archive the current state of the mediapackage  Documentation    caption  Waiting for user to upload captions  Documentation    cleanup  Cleanup the working file repository     compose  Encode media files using FFmpeg  Documentation    composite  Compose two videos on one canvas.  Documentation    concat  Concatenate multiple video tracks into one video track  Documentation    defaults  Applies default workflow configuration values  Documentation    editor  Waiting for user to review, then cut video based on edit-list  Documentation    email  Sends email notifications at any part of a workflow  Documentation    extract-text  Extracting text from presentation segments  Documentation    http-notify  Notifies an HTTP endpoint about the process of the workflow  Documentation    image  Extract images from a video using FFmpeg  Documentation    image-to-video  Create a video track from a source image  Documentation    incident  Testing incidents on a dummy job  Documentation    ingest-download  Download files from external URL for ingest  Documentation    inspect  Inspect the media (check if it is valid)  Documentation    normalize-audio  Normalize first audio stream  Documentation    post-mediapackage  Send mediapackage to remote service  Documentation    prepare-av  Preparing audio and video work versions  Documentation    publish-engage  Distribute and publish media to the engage player  Documentation    republish  Republishes elements to search  Documentation    segment-video  Extracting segments from presentation  Documentation    segmentpreviews  Extract segment images from a video using FFmpeg  Documentation    series  Apply series to the mediapackage  Documentation    silence  Silence detection on audio of the mediapackage  Documentation    tag  Modify the tag sets of media package elements  Documentation    trim  Waiting for user to review, then trim the recording  Documentation    waveform  Create a waveform image of the audio of the mediapackage  Documentation    zip  Create zipped archive of the current state of the mediapackage  Documentation",
            "title": "Default Workflow Operations"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/",
            "text": "AnalyzeAudioWorkflowOperationHandler\n\n\nDescription\n\n\nThe AnalyzeAudioiWorkflowOperationHandler analyzes the first audio stream of a video or audio track through SoX (http://sox.sourceforge.net/) and writes the result back to the given track.\n\n\nThis workflow operation handler can be used with audio and/or video files. At least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs:\n\n\nUsed with Audio only file (forceTranscode is deactivated):\n\n\n\n\nAnalyze the given audio file with SoX\n\n\nWrite analyzed audio metadata back to the given track's mediapackage.\n\n\n\n\nUsed with Video file or with Audio only file with forceTranscode activated:\n\n\n\n\nExtract audio file encoded as FLAC audio and save it temporary in a collection\n\n\nAnalyze the previous encoded audio file with SoX\n\n\nWrite analyzed audio metadata back to the given track's mediapackage.\n\n\nDelete the temporary encoded FLAC audio file\n\n\n\n\nExample result track:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<track type=\"presentation/audio\" id=\"audio\">\n    <mimetype>video/x-flac</mimetype>\n    <tags />\n    <url>fooVideo.flac</url>\n    <checksum type=\"md5\">46cb2e9df2e73756b0d96c33b1aaf055</checksum>\n    <duration>65680</duration>\n    <audio id=\"audio-1\">\n        <device />\n        <encoder type=\"ADPCM\" />\n        <bitdepth>16</bitdepth>\n        <channels>2</channels>\n        <bitrate>62500.0</bitrate>\n        <peakleveldb>-30</peakleveldb> <!-- NEW -->\n        <rmsleveldb>-20</rmsleveldb> <!-- NEW -->\n        <rmspeakdb>-10</rmspeakdb> <!-- NEW -->\n    </audio>\n</track>\n\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"presentation/work,presenter/work\"\n\n\nThe \"flavors\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor\n\n\n\"presentation/work\"\n\n\nThe \"flavor\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags\n\n\n\"engage,atom,rss\"\n\n\nThe \"tag\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nforce-transcode\n\n\n\"true\" or \"false\"\n\n\nWhether to force transcoding the audio stream\n\n\n\n\n\n\n\n\n(This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format)\n\n\nFALSE\n\n\n\n\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"analyze-audio\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Analyze audio stream\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"force-transcode\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Analyze audio WOH"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#analyzeaudioworkflowoperationhandler",
            "text": "",
            "title": "AnalyzeAudioWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#description",
            "text": "The AnalyzeAudioiWorkflowOperationHandler analyzes the first audio stream of a video or audio track through SoX (http://sox.sourceforge.net/) and writes the result back to the given track.  This workflow operation handler can be used with audio and/or video files. At least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs:",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#used-with-audio-only-file-forcetranscode-is-deactivated",
            "text": "Analyze the given audio file with SoX  Write analyzed audio metadata back to the given track's mediapackage.",
            "title": "Used with Audio only file (forceTranscode is deactivated):"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#used-with-video-file-or-with-audio-only-file-with-forcetranscode-activated",
            "text": "Extract audio file encoded as FLAC audio and save it temporary in a collection  Analyze the previous encoded audio file with SoX  Write analyzed audio metadata back to the given track's mediapackage.  Delete the temporary encoded FLAC audio file   Example result track:  <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<track type=\"presentation/audio\" id=\"audio\">\n    <mimetype>video/x-flac</mimetype>\n    <tags />\n    <url>fooVideo.flac</url>\n    <checksum type=\"md5\">46cb2e9df2e73756b0d96c33b1aaf055</checksum>\n    <duration>65680</duration>\n    <audio id=\"audio-1\">\n        <device />\n        <encoder type=\"ADPCM\" />\n        <bitdepth>16</bitdepth>\n        <channels>2</channels>\n        <bitrate>62500.0</bitrate>\n        <peakleveldb>-30</peakleveldb> <!-- NEW -->\n        <rmsleveldb>-20</rmsleveldb> <!-- NEW -->\n        <rmspeakdb>-10</rmspeakdb> <!-- NEW -->\n    </audio>\n</track>",
            "title": "Used with Video file or with Audio only file with forceTranscode activated:"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  \"presentation/work,presenter/work\"  The \"flavors\" of the track to use as a source input  EMPTY    source-flavor  \"presentation/work\"  The \"flavor\" of the track to use as a source input  EMPTY    source-tags  \"engage,atom,rss\"  The \"tag\" of the track to use as a source input  EMPTY    force-transcode  \"true\" or \"false\"  Whether to force transcoding the audio stream     (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format)  FALSE",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/analyzeaudio-woh/#operation-example",
            "text": "<operation\n  id=\"analyze-audio\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Analyze audio stream\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"force-transcode\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/append-woh/",
            "text": "AppendWorkflowHandler\n\n\n\n\nThis operations has been deprecated with opencast 2.0\n\n\n\n\nDescription\n\n\nThe AppendWorkflowOperation can be used to select additional workflows which should be appended to the current one. This\nbasically means that it can be used to build a workflow selection workflow, making it possible to select workflows after\nthe media was ingested.\n\n\nOperation Example\n\n\nthis example shows a complete workflow selection workflow:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<definition xmlns=\"http://workflow.opencastproject.org\">\n  <id>default</id>\n  <description>Puts mediapackages on hold</description>\n  <operations>\n    <operation\n      id=\"append\"\n      fail-on-error=\"true\"\n      description=\"Hold for workflow selection\">\n    </operation>\n  </operations>\n</definition>",
            "title": "Append WOH"
        },
        {
            "location": "/workflowoperationhandlers/append-woh/#appendworkflowhandler",
            "text": "This operations has been deprecated with opencast 2.0",
            "title": "AppendWorkflowHandler"
        },
        {
            "location": "/workflowoperationhandlers/append-woh/#description",
            "text": "The AppendWorkflowOperation can be used to select additional workflows which should be appended to the current one. This\nbasically means that it can be used to build a workflow selection workflow, making it possible to select workflows after\nthe media was ingested.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/append-woh/#operation-example",
            "text": "this example shows a complete workflow selection workflow:  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<definition xmlns=\"http://workflow.opencastproject.org\">\n  <id>default</id>\n  <description>Puts mediapackages on hold</description>\n  <operations>\n    <operation\n      id=\"append\"\n      fail-on-error=\"true\"\n      description=\"Hold for workflow selection\">\n    </operation>\n  </operations>\n</definition>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/archive-woh/",
            "text": "ArchiveWorkflowHandler\n\n\nDescription\n\n\nThe ArchiveWorkflowHandler will archive the current state of the mediapackage.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-tags\n\n\ntext\n\n\nSpecifies which media should be archived.\n\n\n\n\n\n\nsource-flavors\n\n\npresenter/source\n\n\nFlavors that should be archived, separated by \",\"\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      if=\"${archiveOp}\"\n      id=\"archive\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Archiving\">\n      <configurations>\n            <configuration key=\"source-tags\">archive</configuration>\n      </configurations>\n</operation>",
            "title": "Archive WOH"
        },
        {
            "location": "/workflowoperationhandlers/archive-woh/#archiveworkflowhandler",
            "text": "",
            "title": "ArchiveWorkflowHandler"
        },
        {
            "location": "/workflowoperationhandlers/archive-woh/#description",
            "text": "The ArchiveWorkflowHandler will archive the current state of the mediapackage.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/archive-woh/#parameter-table",
            "text": "configuration keys  example  description      source-tags  text  Specifies which media should be archived.    source-flavors  presenter/source  Flavors that should be archived, separated by \",\"",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/archive-woh/#operation-example",
            "text": "<operation\n      if=\"${archiveOp}\"\n      id=\"archive\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Archiving\">\n      <configurations>\n            <configuration key=\"source-tags\">archive</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/caption-woh/",
            "text": "CaptionWorkflowOperation\n\n\nDescription\n\n\nTheCaptionWorkflowOperation waits for user to upload caption files which will be added to the media.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\ntarget-tags\n\n\nengage\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"caption\"\n      if=\"${captionHold}\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Waiting for user to upload captions\">\n      <configurations>\n            <configuration key=\"target-tags\">engage,archive</configuration>\n      </configurations>\n</operation>",
            "title": "Caption WOH"
        },
        {
            "location": "/workflowoperationhandlers/caption-woh/#captionworkflowoperation",
            "text": "",
            "title": "CaptionWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/caption-woh/#description",
            "text": "TheCaptionWorkflowOperation waits for user to upload caption files which will be added to the media.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/caption-woh/#parameter-table",
            "text": "configuration keys  example  description      target-tags  engage  Specifies which media should be processed.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/caption-woh/#operation-example",
            "text": "<operation\n      id=\"caption\"\n      if=\"${captionHold}\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Waiting for user to upload captions\">\n      <configurations>\n            <configuration key=\"target-tags\">engage,archive</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/",
            "text": "ComposeWorkflowHandler\n\n\nDescription\n\n\nThe ComposeWorkflowHandler is used to encode media files to different formats using FFmpeg.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/work\n\n\nWhich media should be encoded\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/delivery\n\n\nSpecifies the flavor of the new media\n\n\n\n\n\n\nsource-tags\n\n\nsometag\n\n\nTags of media to encode\n\n\n\n\n\n\ntarget-tags\n\n\nsometag\n\n\nSpecifies the tags of the new media\n\n\n\n\n\n\nencoding-profile   webm-hd\n\n\nSpecifies the encoding profile to use\n\n\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n    id=\"compose\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encoding presenter (camera) video to Flash download\">\n    <configurations>\n        <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n        <configuration key=\"target-flavor\">presenter/delivery</configuration>\n        <configuration key=\"target-tags\">engage</configuration>\n        <configuration key=\"encoding-profile\">flash.http</configuration>\n    </configurations>\n</operation>",
            "title": "Compose WOH"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/#composeworkflowhandler",
            "text": "",
            "title": "ComposeWorkflowHandler"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/#description",
            "text": "The ComposeWorkflowHandler is used to encode media files to different formats using FFmpeg.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/work  Which media should be encoded    target-flavor  presenter/delivery  Specifies the flavor of the new media    source-tags  sometag  Tags of media to encode    target-tags  sometag  Specifies the tags of the new media    encoding-profile   webm-hd  Specifies the encoding profile to use",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/compose-woh/#operation-example",
            "text": "<operation\n    id=\"compose\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Encoding presenter (camera) video to Flash download\">\n    <configurations>\n        <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n        <configuration key=\"target-flavor\">presenter/delivery</configuration>\n        <configuration key=\"target-tags\">engage</configuration>\n        <configuration key=\"encoding-profile\">flash.http</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/",
            "text": "Composite workflow Operation Handler\n\n\nDescription\n\n\nThe CompositeWorkflowOperationHandler is used to composite two videos (upper and lower) and an optionally watermark into one video, including encoding to different formats. The audio track is always taken from the lower video. Everything is done using FFmpeg. The composition can be done in various layout formats e.g. side by side or picture in picture. The layout has to be defined in JSON format and is described in section \"Layout Definition\". For some general information about layouts see Matterhorn Composer Layout Module.\n\n\nThe internal ffmpeg command is using the following filters: scale for scaling the videos, pad for defining the output dimension including the background color, movie for adding additional videos and images and overlay for aligning the videos and images to the output dimension. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide\n\n\nSample complex composite filter command\n\n\n-filter:v \"[in]scale=640:480,pad=1920:1080:20:20:black[lower];movie=test.mp4,scale=640:480[upper];movie=watermark.jpg[watermark];[lower][upper]overlay=200:200[video];[video][watermark]overlay=main_w-overlay_w-20:20[out]\" sidebyside.mp4\n\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nvalue type (EBNF)\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-tags-upper\n\n\nString , { \",\" , String }\n\n\ncomp,rss\n\n\nThe \"tag\" of the upper track to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor-upper\n\n\nMediaPackageElementFlavor\n\n\npresenter/trimmed\n\n\nThe \"flavor\" of the upper track to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags-lower\n\n\nString , { \",\" , String }\n\n\ncomp,rss\n\n\nThe \"tag\" of the lower track to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor-lower\n\n\nMediaPackageElementFlavor\n\n\npresenter/trimmed\n\n\nThe \"flavor\" of the lower track to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags-watermark\n\n\nString , { \",\" , String }\n\n\nbranding\n\n\nThe \"tag\" of the attachment image to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor-watermark\n\n\nMediaPackageElementFlavor\n\n\nimage/work\n\n\nThe \"flavor\" of the attachment image to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\nsource-url-watermark\n\n\nURL\n\n\nfile:///Users/me/logo.jpg\n\n\nThe \"URL\" of the fallback image to use as a source input.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\nString , { \",\" , String }\n\n\ncomposite,rss,atom,archive\n\n\nThe tags to apply to the compound video track.\n\n\nEMPTY\n\n\n\n\n\n\n* \ntarget-flavor\n\n\nMediaPackageElementFlavor\n\n\ncomposite/delivery\n\n\nThe flavor to apply to the compound video track.\n\n\nEMPTY\n\n\n\n\n\n\n* \nencoding-profile\n\n\nString\n\n\ncomposite\n\n\nThe encoding profile to use.\n\n\nEMPTY\n\n\n\n\n\n\n* \noutput-resolution\n\n\nwidth , \"x\" , height\n\n\n1900x1080\n\n\nThe resulting resolution of the compound video e.g. 1900x1080.\n\n\nEMPTY\n\n\n\n\n\n\noutput-background\n\n\nString\n\n\nred\n\n\nThe resulting background color of the compound video http://www.ffmpeg.org/ffmpeg-utils.html#Color.\n\n\nblack\n\n\n\n\n\n\n* \nlayout\n\n\nname\n\n\nJson , \";\" , Json , [ \";\" , Json ]\n\n\ntopleft\n\n\nThe layout name to use or a semi-colon separated JSON layout definition (lower video, upper video, optional watermark). If a layout name is given than the corresponding layout-{name} key must be defined.\n\n\n\n\n\n\nlayout-{name}\n\n\nJson , \";\" , Json , [ \";\" , Json ]\n\n\nDefine semi-colon separated JSON layouts (lower video, upper video, optional watermark) to provide by name.\n\n\nEMPTY\n\n\n\n\n\n\n\n\n\n\n* \nmandatory\n\n\nLayout Definition\n\n\nThe layout definitions are provided as JSON. Each definition consist of the layout specifications for the lower and upper video and an optional specification for the watermark. The specifications have to be separated by comma.\n\n\nIt is always ensured that the media does not exceed the canvas. Offset and scaling is adjusted appropriately.\n\n\nA single layout is specified as follows:\n\n\n{\n  // How much of the canvas shall be covered. [0.0 - 1.0] \n  // 1.0 means that the media is scaled to cover the complete width of the canvas keeping the aspect ratio.\n  \"horizontalCoverage\": Double,\n  // The offset between the anchor points of the media and the canvas\n  \"anchorOffset\": {\n    // The anchor point of the media. [0.0 - 1.0]\n    // (0.0, 0.0) is the upper left corner, (1.0, 1.0) is the lower right corner.\n    // (0.5, 0.5) is the center.\n    \"referring\": {\n      \"left\": Double,\n      \"top\": Double\n    },\n    // The anchor point of the canvas.\n    \"reference\": {\n      \"left\": Double,\n      \"top\": Double\n    },\n    // The offset between the two anchor points.\n    \"offset\": {\n      \"y\": Integer,\n      \"x\": Integer\n    }\n  }\n}\n\n// Example. \n// The media is scaled to cover the whole width of the canvas and is placed in the upper left corner.\n{\n  \"horizontalCoverage\": 1.0,\n  \"anchorOffset\": {\n    \"referring\": {\n      \"left\": 0.0,\n      \"top\": 0.0\n    },\n    \"offset\": {\n      \"y\": 0,\n      \"x\": 0\n    },\n    \"reference\": {\n      \"left\": 0.0,\n      \"top\": 0.0\n    }\n  }\n}\n\n// Example.\n// The media is scaled to cover 20% of the width of the canvas and is placed in the lower right corner \n// with an offset of -10px on both x and y axis so that it does not touch the canvas' border.\n{\n  \"horizontalCoverage\": 0.2,\n  \"anchorOffset\": {\n    \"referring\": {\n      \"left\": 1.0,\n      \"top\": 1.0\n    },\n    \"offset\": {\n      \"y\": -10,\n      \"x\": -10\n    },\n    \"reference\": {\n      \"left\": 1.0,\n      \"top\": 1.0\n    }\n  }\n}\n\n\n\nOperation Example\n\n\n<operation\n  id=\"composite\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Composite\">\n  <configurations>\n    <configuration key=\"source-flavor-upper\">presentation/trimmed</configuration>\n    <configuration key=\"source-flavor-lower\">presenter/trimmed</configuration>\n    <configuration key=\"source-tags-upper\">comp,rss</configuration>\n    <configuration key=\"source-tags-lower\">comp,rss</configuration>\n    <configuration key=\"source-tags-watermark\">branding</configuration>\n    <configuration key=\"source-flavor-watermark\">image/work</configuration>\n    <configuration key=\"source-url-watermark\">file:///Users/me/logo.jpg</configuration>\n    <configuration key=\"encoding-profile\">composite</configuration>\n    <configuration key=\"target-tags\">composite,rss,atom,archive</configuration>\n    <configuration key=\"target-flavor\">composite/delivery</configuration>\n    <configuration key=\"output-resolution\">1900x1080</configuration>\n    <configuration key=\"output-background\">red</configuration>\n    <configuration key=\"layout\">topleft</configuration>\n    <configuration key=\"layout-topleft\">\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}};\n      {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":0.0,\"top\":0.0}}};\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":1.0,\"top\":0.0}}}\n    </configuration>\n    <configuration key=\"layout-topright\">\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}};\n      {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":0.0}}};\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":0.0,\"top\":0.0}}}\n    </configuration>\n  </configurations>\n</operation>",
            "title": "Composite WOH"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#composite-workflow-operation-handler",
            "text": "",
            "title": "Composite workflow Operation Handler"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#description",
            "text": "The CompositeWorkflowOperationHandler is used to composite two videos (upper and lower) and an optionally watermark into one video, including encoding to different formats. The audio track is always taken from the lower video. Everything is done using FFmpeg. The composition can be done in various layout formats e.g. side by side or picture in picture. The layout has to be defined in JSON format and is described in section \"Layout Definition\". For some general information about layouts see Matterhorn Composer Layout Module.  The internal ffmpeg command is using the following filters: scale for scaling the videos, pad for defining the output dimension including the background color, movie for adding additional videos and images and overlay for aligning the videos and images to the output dimension. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#sample-complex-composite-filter-command",
            "text": "-filter:v \"[in]scale=640:480,pad=1920:1080:20:20:black[lower];movie=test.mp4,scale=640:480[upper];movie=watermark.jpg[watermark];[lower][upper]overlay=200:200[video];[video][watermark]overlay=main_w-overlay_w-20:20[out]\" sidebyside.mp4",
            "title": "Sample complex composite filter command"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  value type (EBNF)  example  description  default value      source-tags-upper  String , { \",\" , String }  comp,rss  The \"tag\" of the upper track to use as a source input.  EMPTY    source-flavor-upper  MediaPackageElementFlavor  presenter/trimmed  The \"flavor\" of the upper track to use as a source input.  EMPTY    source-tags-lower  String , { \",\" , String }  comp,rss  The \"tag\" of the lower track to use as a source input.  EMPTY    source-flavor-lower  MediaPackageElementFlavor  presenter/trimmed  The \"flavor\" of the lower track to use as a source input.  EMPTY    source-tags-watermark  String , { \",\" , String }  branding  The \"tag\" of the attachment image to use as a source input.  EMPTY    source-flavor-watermark  MediaPackageElementFlavor  image/work  The \"flavor\" of the attachment image to use as a source input.  EMPTY    source-url-watermark  URL  file:///Users/me/logo.jpg  The \"URL\" of the fallback image to use as a source input.  EMPTY    target-tags  String , { \",\" , String }  composite,rss,atom,archive  The tags to apply to the compound video track.  EMPTY    *  target-flavor  MediaPackageElementFlavor  composite/delivery  The flavor to apply to the compound video track.  EMPTY    *  encoding-profile  String  composite  The encoding profile to use.  EMPTY    *  output-resolution  width , \"x\" , height  1900x1080  The resulting resolution of the compound video e.g. 1900x1080.  EMPTY    output-background  String  red  The resulting background color of the compound video http://www.ffmpeg.org/ffmpeg-utils.html#Color.  black    *  layout  name  Json , \";\" , Json , [ \";\" , Json ]  topleft  The layout name to use or a semi-colon separated JSON layout definition (lower video, upper video, optional watermark). If a layout name is given than the corresponding layout-{name} key must be defined.    layout-{name}  Json , \";\" , Json , [ \";\" , Json ]  Define semi-colon separated JSON layouts (lower video, upper video, optional watermark) to provide by name.  EMPTY      *  mandatory",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#layout-definition",
            "text": "The layout definitions are provided as JSON. Each definition consist of the layout specifications for the lower and upper video and an optional specification for the watermark. The specifications have to be separated by comma.  It is always ensured that the media does not exceed the canvas. Offset and scaling is adjusted appropriately.  A single layout is specified as follows:  {\n  // How much of the canvas shall be covered. [0.0 - 1.0] \n  // 1.0 means that the media is scaled to cover the complete width of the canvas keeping the aspect ratio.\n  \"horizontalCoverage\": Double,\n  // The offset between the anchor points of the media and the canvas\n  \"anchorOffset\": {\n    // The anchor point of the media. [0.0 - 1.0]\n    // (0.0, 0.0) is the upper left corner, (1.0, 1.0) is the lower right corner.\n    // (0.5, 0.5) is the center.\n    \"referring\": {\n      \"left\": Double,\n      \"top\": Double\n    },\n    // The anchor point of the canvas.\n    \"reference\": {\n      \"left\": Double,\n      \"top\": Double\n    },\n    // The offset between the two anchor points.\n    \"offset\": {\n      \"y\": Integer,\n      \"x\": Integer\n    }\n  }\n}\n\n// Example. \n// The media is scaled to cover the whole width of the canvas and is placed in the upper left corner.\n{\n  \"horizontalCoverage\": 1.0,\n  \"anchorOffset\": {\n    \"referring\": {\n      \"left\": 0.0,\n      \"top\": 0.0\n    },\n    \"offset\": {\n      \"y\": 0,\n      \"x\": 0\n    },\n    \"reference\": {\n      \"left\": 0.0,\n      \"top\": 0.0\n    }\n  }\n}\n\n// Example.\n// The media is scaled to cover 20% of the width of the canvas and is placed in the lower right corner \n// with an offset of -10px on both x and y axis so that it does not touch the canvas' border.\n{\n  \"horizontalCoverage\": 0.2,\n  \"anchorOffset\": {\n    \"referring\": {\n      \"left\": 1.0,\n      \"top\": 1.0\n    },\n    \"offset\": {\n      \"y\": -10,\n      \"x\": -10\n    },\n    \"reference\": {\n      \"left\": 1.0,\n      \"top\": 1.0\n    }\n  }\n}",
            "title": "Layout Definition"
        },
        {
            "location": "/workflowoperationhandlers/composite-woh/#operation-example",
            "text": "<operation\n  id=\"composite\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Composite\">\n  <configurations>\n    <configuration key=\"source-flavor-upper\">presentation/trimmed</configuration>\n    <configuration key=\"source-flavor-lower\">presenter/trimmed</configuration>\n    <configuration key=\"source-tags-upper\">comp,rss</configuration>\n    <configuration key=\"source-tags-lower\">comp,rss</configuration>\n    <configuration key=\"source-tags-watermark\">branding</configuration>\n    <configuration key=\"source-flavor-watermark\">image/work</configuration>\n    <configuration key=\"source-url-watermark\">file:///Users/me/logo.jpg</configuration>\n    <configuration key=\"encoding-profile\">composite</configuration>\n    <configuration key=\"target-tags\">composite,rss,atom,archive</configuration>\n    <configuration key=\"target-flavor\">composite/delivery</configuration>\n    <configuration key=\"output-resolution\">1900x1080</configuration>\n    <configuration key=\"output-background\">red</configuration>\n    <configuration key=\"layout\">topleft</configuration>\n    <configuration key=\"layout-topleft\">\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}};\n      {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":0.0,\"top\":0.0}}};\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":1.0,\"top\":0.0}}}\n    </configuration>\n    <configuration key=\"layout-topright\">\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":1.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":1.0}}};\n      {\"horizontalCoverage\":0.2,\"anchorOffset\":{\"referring\":{\"left\":1.0,\"top\":0.0},\"offset\":{\"y\":-20,\"x\":-20},\"reference\":{\"left\":1.0,\"top\":0.0}}};\n      {\"horizontalCoverage\":1.0,\"anchorOffset\":{\"referring\":{\"left\":0.0,\"top\":0.0},\"offset\":{\"y\":20,\"x\":20},\"reference\":{\"left\":0.0,\"top\":0.0}}}\n    </configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/",
            "text": "Concat workflow operation handler\n\n\n FFMPEG 1.1 is required for the encoding profile related to this operation! \n\n\nOverview\n\n\nThe \"concat\" operation handler has been created to concatenate multiple video tracks into one video track. The concatenation process uses the ffmpeg scale filter which is always re-encoding the videos, this means the resulting video has most likely a loss of quality.\n\n\n\n\nThe internal ffmpeg command is using the following filters:  scale, pad and setdar for scaling all videos to a similar size including letterboxing, aevalsrc for creating silent audio streams and of course the concat for the actual concatenation step. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide\n\n\nSample complex concat filter command\n\n\n-filter_complex \"[0:v]scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[b];[1:v]scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[c];[2:v]scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[d];aevalsrc=0::d=1[silent];[b][0:a][c][silent][d][2:a]concat=n=3:v=1:a=1[v][a]\" -map '[v]' -map '[a]'\n\n\n\nUsage\n\n\nThis operation is quite similar to the compose operation. The only difference is that the input properties are not only limited to one \"source-flavor\" and \"source-tag\". The operation supports multiple flavor and tags as input.  To add multiple source, add different key with the prefix \"source-flavor-\"/\"source-tag-\" and an incremental number starting with 0. For example:\n\n\n\n\nsource-flavor-0\n\n\nsource-flavor-1\n\n\nsource-flavor-..\n\n\n\n\nConfiguration keys\n\n\n\n\n\n\n\n\nKey\n\n\nRequired\n\n\nDescription\n\n\nDefault Value\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nsource-flavor-part-X\n\n\nfalse\n\n\nAn iterative list of part/flavor to use as input track.\n\n\nNULL\n\n\n\n\n\n\n\n\npresenter/trimmed\n\n\nsource-tag-part-X\n\n\nfalse\n\n\nAn iterative list of part/tag to use as input track.\n\n\nNULL\n\n\n\n\n\n\nsource-to-concate\n\n\nsource-flavor-part-X-mandatory\n\n\nfalse\n\n\nDefine the flavor part-X as an optional track for concatenation.\n\n\nfalse\n\n\n\n\n\n\nsource-tag-part-X-mandatory\n\n\nfalse\n\n\nDefine the tag part-X as an optional track for concatenation.\n\n\nfalse\n\n\ntrue\n\n\n\n\n\n\nencoding-profile\n\n\ntrue\n\n\nDefine the encoding-profile to use for the concatenation operation. See example of profile below.\n\n\nNULL\n\n\nconcat\n\n\n\n\n\n\ntarget-flavor\n\n\ntrue\n\n\nDefine the flavor(s) to add to the output track.\n\n\nNULL\n\n\npresenter/concat\n\n\n\n\n\n\ntarget-tags\n\n\nfalse\n\n\nDefine the tag(s) to add to the output track\n\n\nNULL\n\n\nengage-download\n\n\n\n\n\n\noutput-resolution\n\n\ntrue\n\n\nDefine the output resolution in width, height or take it from one of the given parts\n\n\nNULL\n\n\n1900x1080, part-1\n\n\n\n\n\n\n\n\nExample\n\n\nExample of an concat operation in a workflow definition.\n\n\n<!-- Add intro and outro part to the presenter track -->\n<operation\n  id=\"concat\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Concatenate the presenter track and the intro/outro videos.\">\n  <configurations>\n    <configuration key=\"source-flavor-part-0\">intro/source</configuration>\n    <configuration key=\"source-flavor-part-1\">presenter/trimmed</configuration>\n    <configuration key=\"source-flavor-part-1-mandatory\">true</configuration>\n    <configuration key=\"source-flavor-part-2\">outro/source</configuration>\n    <configuration key=\"target-flavor\">presenter/concat</configuration>\n    <configuration key=\"target-tags\">engage-download,engage-streaming</configuration>\n    <configuration key=\"encoding-profile\">concat</configuration>\n    <configuration key=\"output-resolution\">1920x1080</configuration>\n  </configurations>\n</operation>\n\n\n\nEncoding profile\n\n\nThe encoding profile command must contain the the #{concatCommand} parameter.\n\n\n# Concat\nprofile.concat.name = concat\nprofile.concat.input = visual\nprofile.concat.output = visual\nprofile.concat.suffix = -concatenated.mp4\nprofile.concat.mimetype = video/mp4\nprofile.concat.ffmpeg.command = #{concatCommand} -acodec libfaac -b:a 128k -vcodec mpeg4 -b:v 1200k\n-flags +aic+mv4 #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Concat WOH"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#concat-workflow-operation-handler",
            "text": "FFMPEG 1.1 is required for the encoding profile related to this operation!",
            "title": "Concat workflow operation handler"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#overview",
            "text": "The \"concat\" operation handler has been created to concatenate multiple video tracks into one video track. The concatenation process uses the ffmpeg scale filter which is always re-encoding the videos, this means the resulting video has most likely a loss of quality.   The internal ffmpeg command is using the following filters:  scale, pad and setdar for scaling all videos to a similar size including letterboxing, aevalsrc for creating silent audio streams and of course the concat for the actual concatenation step. More info can be found here: https://trac.ffmpeg.org/wiki/FilteringGuide",
            "title": "Overview"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#sample-complex-concat-filter-command",
            "text": "-filter_complex \"[0:v]scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[b];[1:v]scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[c];[2:v]scale=iw*min(640/iw\\,480/ih):ih*min(640/iw\\,480/ih),pad=640:480:(ow-iw)/2:(oh-ih)/2,setdar=4:3[d];aevalsrc=0::d=1[silent];[b][0:a][c][silent][d][2:a]concat=n=3:v=1:a=1[v][a]\" -map '[v]' -map '[a]'",
            "title": "Sample complex concat filter command"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#usage",
            "text": "This operation is quite similar to the compose operation. The only difference is that the input properties are not only limited to one \"source-flavor\" and \"source-tag\". The operation supports multiple flavor and tags as input.  To add multiple source, add different key with the prefix \"source-flavor-\"/\"source-tag-\" and an incremental number starting with 0. For example:   source-flavor-0  source-flavor-1  source-flavor-..",
            "title": "Usage"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#configuration-keys",
            "text": "Key  Required  Description  Default Value  Example      source-flavor-part-X  false  An iterative list of part/flavor to use as input track.  NULL     presenter/trimmed  source-tag-part-X  false  An iterative list of part/tag to use as input track.  NULL    source-to-concate  source-flavor-part-X-mandatory  false  Define the flavor part-X as an optional track for concatenation.  false    source-tag-part-X-mandatory  false  Define the tag part-X as an optional track for concatenation.  false  true    encoding-profile  true  Define the encoding-profile to use for the concatenation operation. See example of profile below.  NULL  concat    target-flavor  true  Define the flavor(s) to add to the output track.  NULL  presenter/concat    target-tags  false  Define the tag(s) to add to the output track  NULL  engage-download    output-resolution  true  Define the output resolution in width, height or take it from one of the given parts  NULL  1900x1080, part-1",
            "title": "Configuration keys"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#example",
            "text": "Example of an concat operation in a workflow definition.  <!-- Add intro and outro part to the presenter track -->\n<operation\n  id=\"concat\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Concatenate the presenter track and the intro/outro videos.\">\n  <configurations>\n    <configuration key=\"source-flavor-part-0\">intro/source</configuration>\n    <configuration key=\"source-flavor-part-1\">presenter/trimmed</configuration>\n    <configuration key=\"source-flavor-part-1-mandatory\">true</configuration>\n    <configuration key=\"source-flavor-part-2\">outro/source</configuration>\n    <configuration key=\"target-flavor\">presenter/concat</configuration>\n    <configuration key=\"target-tags\">engage-download,engage-streaming</configuration>\n    <configuration key=\"encoding-profile\">concat</configuration>\n    <configuration key=\"output-resolution\">1920x1080</configuration>\n  </configurations>\n</operation>",
            "title": "Example"
        },
        {
            "location": "/workflowoperationhandlers/concat-woh/#encoding-profile",
            "text": "The encoding profile command must contain the the #{concatCommand} parameter.  # Concat\nprofile.concat.name = concat\nprofile.concat.input = visual\nprofile.concat.output = visual\nprofile.concat.suffix = -concatenated.mp4\nprofile.concat.mimetype = video/mp4\nprofile.concat.ffmpeg.command = #{concatCommand} -acodec libfaac -b:a 128k -vcodec mpeg4 -b:v 1200k\n-flags +aic+mv4 #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Encoding profile"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/",
            "text": "DefaultsWorkflowOperation\n\n\nDescription\n\n\nThe DefaultsWorkflowOperationHandler is used to define default workflow configuration values that are in effect in cases where a workflow instance is started without the user interface being invoked, with the result that no configuration of the workflow instance has taken place. The defaults specified by this handler will be applied for configuration keys that have not been specified but won't overwrite existing values.\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nkey\n\n\nhello world\n\n\nThis would set the workflow configuration \"key\" to the value \"hello world\" if - and only if - the key is undefined.\n\n\n-\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"defaults\"\n  description=\"Applying default values\">\n  <configurations>\n    <configuration key=\"key\">hello world</configuration>\n  </configurations>\n</operation>",
            "title": "Defaults WOH"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/#defaultsworkflowoperation",
            "text": "",
            "title": "DefaultsWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/#description",
            "text": "The DefaultsWorkflowOperationHandler is used to define default workflow configuration values that are in effect in cases where a workflow instance is started without the user interface being invoked, with the result that no configuration of the workflow instance has taken place. The defaults specified by this handler will be applied for configuration keys that have not been specified but won't overwrite existing values.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  example  description  default value      key  hello world  This would set the workflow configuration \"key\" to the value \"hello world\" if - and only if - the key is undefined.  -",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/defaults-woh/#operation-example",
            "text": "<operation\n  id=\"defaults\"\n  description=\"Applying default values\">\n  <configurations>\n    <configuration key=\"key\">hello world</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/",
            "text": "VideoEditorWorkflowOperationHandler\n\n\nDescription\n\n\nThe editor operation provides the UI for editing trim hold state and processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"*/work\"\n\n\nthe subtype of all media files in the best available quality and in a codec that can be processed by the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only the subtype is important. All needed videos should be available within this flavor\n\n\nEMPTY\n\n\n\n\n\n\npreview-flavors\n\n\n\"*/preview\"\n\n\nthe subtype of the media files that should be used for the preview player. This is an HTML5 player so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors.\n\n\nEMPTY\n\n\n\n\n\n\nsmil-flavors\n\n\n\"*/smil\"\n\n\nthe smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil will be favored, if this is not available the first in the list will be used.\n\n\nEMPTY\n\n\n\n\n\n\nskipped-flavors\n\n\n\"*/work\"\n\n\nthe subtype of all media files that should be used in the following processing, if the editor operation was skipped\n\n\nEMPTY\n\n\n\n\n\n\n\n\nVideo Editor UI\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"editor\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Waiting for user to review / video edit recording\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/work</configuration>\n    <configuration key=\"preview-flavors\">*/preview</configuration>\n    <configuration key=\"skipped-flavors\">*/work</configuration>\n    <configuration key=\"smil-flavors\">*/smil</configuration>\n    <configuration key=\"target-smil-flavor\">episode/smil</configuration>\n    <configuration key=\"target-flavor-subtype\">trimmed</configuration>\n  </configurations>\n</operation>",
            "title": "Editor WOH"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#videoeditorworkflowoperationhandler",
            "text": "",
            "title": "VideoEditorWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#description",
            "text": "The editor operation provides the UI for editing trim hold state and processes the edited files. This operation needs the videoeditor API and impl (or remote on distributed systems) to be installed.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  \"*/work\"  the subtype of all media files in the best available quality and in a codec that can be processed by the videoeditor modules. The *-should usually not be changed, as tracks can be excluded in the editor UI too, only the subtype is important. All needed videos should be available within this flavor  EMPTY    preview-flavors  \"*/preview\"  the subtype of the media files that should be used for the preview player. This is an HTML5 player so the coded can be H.264 or WebM based on the browser. The main flavor should be the same as in source-flavors.  EMPTY    smil-flavors  \"*/smil\"  the smil file(s) that should be used as a proposal within the editor UI. If * is used presenter/smil will be favored, if this is not available the first in the list will be used.  EMPTY    skipped-flavors  \"*/work\"  the subtype of all media files that should be used in the following processing, if the editor operation was skipped  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#video-editor-ui",
            "text": "",
            "title": "Video Editor UI"
        },
        {
            "location": "/workflowoperationhandlers/editor-woh/#operation-example",
            "text": "<operation\n  id=\"editor\"\n  if=\"${trimHold}\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Waiting for user to review / video edit recording\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/work</configuration>\n    <configuration key=\"preview-flavors\">*/preview</configuration>\n    <configuration key=\"skipped-flavors\">*/work</configuration>\n    <configuration key=\"smil-flavors\">*/smil</configuration>\n    <configuration key=\"target-smil-flavor\">episode/smil</configuration>\n    <configuration key=\"target-flavor-subtype\">trimmed</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/email-woh/",
            "text": "EmailWorkflowOperation\n\n\nDescription\n\n\nThe EmailWorkflowOperationHandler queries the SMTP Service to send an email with the provided parameters. It is useful to send email notifications that some operation(s) have been completed or that some error(s) occurred in a workflow.\nThe mail body consists of a single line of the form: \n (\n).\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nto\n\n\n\"my-email-account@my-email-domain.org\"\n\n\nIt specifies the field \"to\" of the email, i.e. the email account the email will be sent to.\n\n\nEMPTY\n\n\n\n\n\n\nsubject\n\n\nOperation has been completed\n\n\nSpecifies the mail subject\n\n\nEMPTY\n\n\n\n\n\n\n\n\nSome other email parameters can be customized in the SMTP Service configuration\n\n\nOperation Example\n\n\n<operation\n    id=\"send-email\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Sends email\">\n    <configurations>\n        <configuration key=\"to\">root@localhost</configuration>\n        <configuration key=\"subject\">Failure processing a mediapackage</configuration>\n    </configurations>\n</operation>",
            "title": "Email WOH"
        },
        {
            "location": "/workflowoperationhandlers/email-woh/#emailworkflowoperation",
            "text": "",
            "title": "EmailWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/email-woh/#description",
            "text": "The EmailWorkflowOperationHandler queries the SMTP Service to send an email with the provided parameters. It is useful to send email notifications that some operation(s) have been completed or that some error(s) occurred in a workflow.\nThe mail body consists of a single line of the form:   ( ).",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/email-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      to  \"my-email-account@my-email-domain.org\"  It specifies the field \"to\" of the email, i.e. the email account the email will be sent to.  EMPTY    subject  Operation has been completed  Specifies the mail subject  EMPTY     Some other email parameters can be customized in the SMTP Service configuration",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/email-woh/#operation-example",
            "text": "<operation\n    id=\"send-email\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Sends email\">\n    <configurations>\n        <configuration key=\"to\">root@localhost</configuration>\n        <configuration key=\"subject\">Failure processing a mediapackage</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/",
            "text": "ExtractTextWorkflowOperation\n\n\nDescription\n\n\nThe ExtractTextWorkflowOperation will try to extract test from a video using Tesseract OCR.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresentation/work\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\nsource-tags\n\n\ntext\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-tags\n\n\nengage\n\n\nSpecifies the tags for the produces media.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"extract-text\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Extracting text from presentation segments\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-tags\">engage,archive</configuration>\n      </configurations>\n</operation>",
            "title": "Extract Text WOH"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/#extracttextworkflowoperation",
            "text": "",
            "title": "ExtractTextWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/#description",
            "text": "The ExtractTextWorkflowOperation will try to extract test from a video using Tesseract OCR.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presentation/work  Specifies which media should be processed.    source-tags  text  Specifies which media should be processed.    target-tags  engage  Specifies the tags for the produces media.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/extracttext-woh/#operation-example",
            "text": "<operation\n      id=\"extract-text\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Extracting text from presentation segments\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-tags\">engage,archive</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/",
            "text": "HttpNotificationWorkflowOperation\n\n\nDescription\n\n\nMatterhorn can through this operation notify any HTTP endpoint about the process of the workflow.\n\n\nParameter Table\n\n\nA parameter that is always posted is the workflow instance identifier in the parameter named \nworkflowInstanceId\n containing the current workflow\u2019s identifier.\n\n\n\n\n\n\n\n\nKey\n\n\nRequired\n\n\nDescription\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nurl\n\n\ntrue\n\n\nThe target url to notify\n\n\nhttp://test.ch\n\n\n\n\n\n\nsubject\n\n\nfalse\n\n\nThe name of the event to notify from. The following events are planned: importing_started, imported, prepared, processing_started, published\n\n\nimporting_started\n\n\n\n\n\n\nmessage\n\n\nfalse\n\n\nData supporting the notification. Think of this as the body of an e-mail\n\n\ninternal::25\n\n\n\n\n\n\nmethod\n\n\nfalse\n\n\nSupported methods are \"put\", \"post\". If no method is specified, \"post\" is used by default\n\n\npost\n\n\n\n\n\n\nmax-retry\n\n\nfalse\n\n\nThe maximal number of notification attempts. The default value is 5\n\n\n5\n\n\n\n\n\n\ntimeout\n\n\nfalse\n\n\nThe timeout in seconds for the notification request: The default value is 10\n\n\n10\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"http-notify\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"error\"\n  description=\"Notify test\">\n  <configurations>\n    <configuration key=\"url\">http://www.test.ch</configuration>\n    <configuration key=\"subject\">importing-started</configuration>\n    <configuration key=\u201cmessage\u201d>internal::25</configuration>\n    <configuration key=\u201cmethod\u201d>put</configuration>\n    <configuration key=\"max-retry\">3</configuration>\n    <configuration key=\"timeout\">5</configuration>\n  </configurations>\n</operation>",
            "title": "HTTP Notify WOH"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/#httpnotificationworkflowoperation",
            "text": "",
            "title": "HttpNotificationWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/#description",
            "text": "Matterhorn can through this operation notify any HTTP endpoint about the process of the workflow.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/#parameter-table",
            "text": "A parameter that is always posted is the workflow instance identifier in the parameter named  workflowInstanceId  containing the current workflow\u2019s identifier.     Key  Required  Description  Example      url  true  The target url to notify  http://test.ch    subject  false  The name of the event to notify from. The following events are planned: importing_started, imported, prepared, processing_started, published  importing_started    message  false  Data supporting the notification. Think of this as the body of an e-mail  internal::25    method  false  Supported methods are \"put\", \"post\". If no method is specified, \"post\" is used by default  post    max-retry  false  The maximal number of notification attempts. The default value is 5  5    timeout  false  The timeout in seconds for the notification request: The default value is 10  10",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/httpnotify-woh/#operation-example",
            "text": "<operation\n  id=\"http-notify\"\n  fail-on-error=\"false\"\n  exception-handler-workflow=\"error\"\n  description=\"Notify test\">\n  <configurations>\n    <configuration key=\"url\">http://www.test.ch</configuration>\n    <configuration key=\"subject\">importing-started</configuration>\n    <configuration key=\u201cmessage\u201d>internal::25</configuration>\n    <configuration key=\u201cmethod\u201d>put</configuration>\n    <configuration key=\"max-retry\">3</configuration>\n    <configuration key=\"timeout\">5</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/",
            "text": "ImageWorkflowOperation\n\n\nDescription\n\n\nThe ImageWorkflowOperation will extract a still image from a video using FFmpeg and a given encoding profile.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/source\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/work\n\n\nSpecifies the flavor the new files will get.\n\n\n\n\n\n\nsource-tags\n\n\nengage\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-tags\n\n\nengage\n\n\nSpecifies the tags the new files will get.\n\n\n\n\n\n\nencoding-profile\n\n\nsearch-cover.http\n\n\nThe encoding profile to use.\n\n\n\n\n\n\ntime\n\n\n1\n\n\nTime in seconds where the image should be taken.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encoding presenter (camera) to search result preview image\">\n      <configurations>\n            <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-flavor\">presenter/search+preview</configuration>\n            <configuration key=\"target-tags\">engage</configuration>\n            <configuration key=\"encoding-profile\">search-cover.http</configuration>\n            <configuration key=\"time\">1</configuration>\n      </configurations>\n</operation>",
            "title": "Image WOH"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#imageworkflowoperation",
            "text": "",
            "title": "ImageWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#description",
            "text": "The ImageWorkflowOperation will extract a still image from a video using FFmpeg and a given encoding profile.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/source  Specifies which media should be processed.    target-flavor  presenter/work  Specifies the flavor the new files will get.    source-tags  engage  Specifies which media should be processed.    target-tags  engage  Specifies the tags the new files will get.    encoding-profile  search-cover.http  The encoding profile to use.    time  1  Time in seconds where the image should be taken.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/image-woh/#operation-example",
            "text": "<operation\n      id=\"image\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Encoding presenter (camera) to search result preview image\">\n      <configurations>\n            <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-flavor\">presenter/search+preview</configuration>\n            <configuration key=\"target-tags\">engage</configuration>\n            <configuration key=\"encoding-profile\">search-cover.http</configuration>\n            <configuration key=\"time\">1</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/",
            "text": "ImageToVideo Workflow Operation Handler\n\n\nDescription\n\n\nThe ImageToVideo Workflow Operation Handler allows to create a video track from a source image.\n\n\nParameters table\n\n\nTags and flavors can be used in combination. But combined they should match one image.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-tag\n*\n\n\nintro/source\n\n\nThe \"tag\" of the image to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor\n*\n\n\nintro\n\n\nThe \"flavor\" of the image to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\ncomposite,rss,atom,archive\n\n\nThe tags to apply to the output video track\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\nintro/work\n\n\nThe flavor to apply to the output video track\n\n\nEMPTY\n\n\n\n\n\n\nduration\n*\n\n\n5\n\n\nThe length of the output video in seconds.\n\n\nEMPTY\n\n\n\n\n\n\nprofile\n*\n\n\nimage-movie\n\n\nDefine the encoding-profile to use to create the output video. See example of profile below.\n\n\nEMPTY\n\n\n\n\n\n\n\n\n* \nmandatory\n\n\nOperation example\n\n\n<operation\n  id=\"image-to-video\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Composite\">\n  <configurations>\n    <configuration key=\"source-tag\">presentation/trimmed</configuration>\n    <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n    <configuration key=\"target-tags\">comp</configuration>\n    <configuration key=\"target-flavor\">intro/work</configuration>\n    <configuration key=\"duration\">10</configuration>\n<configuration key=\"profile\">image-movie</configuration>\n  </configurations>\n</operation>\n\n\n\nEncoding profile example\n\n\n# Image to video\nprofile.image-movie.name = image to video\nprofile.image-movie.input = image\nprofile.image-movie.output = visual\nprofile.image-movie.suffix = -image-video.mp4\nprofile.image-movie.mimetype = video/mp4\nprofile.image-movie.ffmpeg.command = -loop 1 -i #{in.video.path} -c:v libx264 -r 25 -t #{time} -pix_fmt yuv420p #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Image to Video WOH"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#imagetovideo-workflow-operation-handler",
            "text": "",
            "title": "ImageToVideo Workflow Operation Handler"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#description",
            "text": "The ImageToVideo Workflow Operation Handler allows to create a video track from a source image.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#parameters-table",
            "text": "Tags and flavors can be used in combination. But combined they should match one image.     configuration keys  example  description  default value      source-tag *  intro/source  The \"tag\" of the image to use as a source input  EMPTY    source-flavor *  intro  The \"flavor\" of the image to use as a source input  EMPTY    target-tags  composite,rss,atom,archive  The tags to apply to the output video track  EMPTY    target-flavor  intro/work  The flavor to apply to the output video track  EMPTY    duration *  5  The length of the output video in seconds.  EMPTY    profile *  image-movie  Define the encoding-profile to use to create the output video. See example of profile below.  EMPTY     *  mandatory",
            "title": "Parameters table"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#operation-example",
            "text": "<operation\n  id=\"image-to-video\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Composite\">\n  <configurations>\n    <configuration key=\"source-tag\">presentation/trimmed</configuration>\n    <configuration key=\"source-flavor\">presenter/trimmed</configuration>\n    <configuration key=\"target-tags\">comp</configuration>\n    <configuration key=\"target-flavor\">intro/work</configuration>\n    <configuration key=\"duration\">10</configuration>\n<configuration key=\"profile\">image-movie</configuration>\n  </configurations>\n</operation>",
            "title": "Operation example"
        },
        {
            "location": "/workflowoperationhandlers/imagetovideo-woh/#encoding-profile-example",
            "text": "# Image to video\nprofile.image-movie.name = image to video\nprofile.image-movie.input = image\nprofile.image-movie.output = visual\nprofile.image-movie.suffix = -image-video.mp4\nprofile.image-movie.mimetype = video/mp4\nprofile.image-movie.ffmpeg.command = -loop 1 -i #{in.video.path} -c:v libx264 -r 25 -t #{time} -pix_fmt yuv420p #{out.dir}/#{out.name}#{out.suffix}",
            "title": "Encoding profile example"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/",
            "text": "IncidentCreatorWorkflowOperationHandler\n\n\nDescription\n\n\nThe IncidentCreatorWorkflowOperationHandler creates an incident on a dummy job used for integration testing.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\ncode\n\n\n2\n\n\nThe code number of the incident to produce.\n\n\n1\n\n\n\n\n\n\nseverity\n\n\nWARNING\n\n\nThe severity. See Incident.Severity enum.\n\n\nINFO\n\n\n\n\n\n\ndetails\n\n\n\"tagged,+rss\" / \"-rss,+tagged\"\n\n\nSome details: title=content;title=content;...\n\n\nEMPTY\n\n\n\n\n\n\nparams\n\n\n\"presentation/tagged\"\n\n\nSome params: key=value;key=value;...\n\n\nEMPTY\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"incident\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Provoke a job incident\">\n  <configurations>\n    <configuration key=\"code\">3</configuration>\n    <configuration key=\"severity\">INFO</configuration>\n    <configuration key=\"details\">exception=content;id=325</configuration>\n    <configuration key=\"params\">track=track-1;profile=full</configuration>\n  </configurations>\n</operation>",
            "title": "Incident WOH"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/#incidentcreatorworkflowoperationhandler",
            "text": "",
            "title": "IncidentCreatorWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/#description",
            "text": "The IncidentCreatorWorkflowOperationHandler creates an incident on a dummy job used for integration testing.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      code  2  The code number of the incident to produce.  1    severity  WARNING  The severity. See Incident.Severity enum.  INFO    details  \"tagged,+rss\" / \"-rss,+tagged\"  Some details: title=content;title=content;...  EMPTY    params  \"presentation/tagged\"  Some params: key=value;key=value;...  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/incident-woh/#operation-example",
            "text": "<operation\n  id=\"incident\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Provoke a job incident\">\n  <configurations>\n    <configuration key=\"code\">3</configuration>\n    <configuration key=\"severity\">INFO</configuration>\n    <configuration key=\"details\">exception=content;id=325</configuration>\n    <configuration key=\"params\">track=track-1;profile=full</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/",
            "text": "IngestDownloadWorkflowOperationHandler\n\n\nDescription\n\n\nWith the IngestDownloadWorkflowOperationHandler it's possible to initially download external URI's from mediapackage elements and store them to the working file repository. The external element URI's are then rewritten to the stored working file repository URI.\n\n\nIn case of having external element URI's showing to a different Matterhorn working file repository, it's also possible to delete them after downloading it by activating the \"delete-external\" option.\n\n\nThis operation is originally implemented to get rid of remaining files on ingest working file repositories.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\ndelete-external\n\n\n\"true\"\n\n\nWhether to try to delete external working file repository URIs.\n\n\nFALSE\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"ingest-download\"\n  fail-on-error=\"false\"\n  description=\"Downloads external artifacts to the working file repository\">\n  <configurations>\n    <configuration key=\"delete-external\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Ingest-Download WOH"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/#ingestdownloadworkflowoperationhandler",
            "text": "",
            "title": "IngestDownloadWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/#description",
            "text": "With the IngestDownloadWorkflowOperationHandler it's possible to initially download external URI's from mediapackage elements and store them to the working file repository. The external element URI's are then rewritten to the stored working file repository URI.  In case of having external element URI's showing to a different Matterhorn working file repository, it's also possible to delete them after downloading it by activating the \"delete-external\" option.  This operation is originally implemented to get rid of remaining files on ingest working file repositories.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      delete-external  \"true\"  Whether to try to delete external working file repository URIs.  FALSE",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/ingestdownload-woh/#operation-example",
            "text": "<operation\n  id=\"ingest-download\"\n  fail-on-error=\"false\"\n  description=\"Downloads external artifacts to the working file repository\">\n  <configurations>\n    <configuration key=\"delete-external\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/",
            "text": "InspectWorkflowOperation\n\n\nDescription\n\n\nThe InspectWorkflowOperation is used to inspect all tracks of a media package. It tries to verify if they are valid media tracks.\n\n\nOperation Example\n\n\n<operation\n    id=\"inspect\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Inspecting the media package\">\n</operation>",
            "title": "Inspect WOH"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#inspectworkflowoperation",
            "text": "",
            "title": "InspectWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#description",
            "text": "The InspectWorkflowOperation is used to inspect all tracks of a media package. It tries to verify if they are valid media tracks.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/inspect-woh/#operation-example",
            "text": "<operation\n    id=\"inspect\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"error\"\n    description=\"Inspecting the media package\">\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/",
            "text": "NormalizeAudioWorkflowOperationHandler\n\n\nDescription\n\n\nThe NormalizeAudioiWorkflowOperationHandler normalizes the first audio stream of a video or audio track through SoX (http://sox.sourceforge.net/), it creates a new track with a reference to the original track which can be flavored and tagged.\nThis workflow operation handler can be used with audio and/or video files, at least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs:\n\n\nUsed with Audio only file (forceTranscode is deactivated):\n\n\n\n\nCheck if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.\n\n\nRun audio normalization with original audio file.\n\n\nReplace the normalized audio file with the original.\n\n\nWrite analyzed audio metadata to the track's mediapackage.\n\n\nDelete all used temporary files\n\n\n\n\nUsed with Audio only file and forceTranscode activated:\n\n\n\n\nCheck if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.\n\n\n(forceTranscode step) Encode audio to FLAC. (Must be used when given audio file format is not supported by SoX)\n\n\nRun audio normalization with original audio file or encoded FLAC audio file.\n\n\n(forceTranscode step) Mux normalized audio file back to the original audio container by replacing it with the original audio stream.\n\n\nWrite analyzed audio metadata to the track's mediapackage.\n\n\nDelete all used temporary files\n\n\n\n\nUsed with Video file:\n\n\n\n\nExtract audio file encoded as FLAC audio and save it temporary in a collection\n\n\nCheck if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.\n\n\nRun audio normalization with extracted audio file.\n\n\nMux normalized audio file back to the original video container by replacing it with original audio stream.\n\n\nWrite analyzed audio metadata to the track's mediapackage.\n\n\nDelete all used temporary files\n\n\n\n\nExample result track:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<track ref=\"track:track-2\" type=\"presenter/normalized\" id=\"70626874-17d2-480d-9d30-c10f0824961c\">\n    <mimetype>audio/x-flv</mimetype>\n    <tags>\n        <tag>norm</tag>\n    </tags>\n    <url>http://localhost:8080/files/mediapackage/8a510168-9102-425f-81e9-0943774dd229/70626874-17d2-480d-9d30-c10f0824961c/demo_slide_video_6min_buss.flv</url>\n    <checksum type=\"md5\">4e30d7d4305b0793f301816e796471db</checksum>\n    <duration>414407</duration>\n    <audio id=\"audio-1\">\n        <device/>\n        <encoder type=\"MPEG Audio\"/>\n        <bitdepth>16</bitdepth>\n        <channels>2</channels>\n        <bitrate>64000.0</bitrate>\n        <peakleveldb>-4.03</peakleveldb> <!-- NEW -->\n        <rmsleveldb>-30.54</rmsleveldb> <!-- NEW -->\n        <rmspeakdb>-10.85</rmspeakdb> <!-- NEW -->\n    </audio>\n</track>\n\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"presentation/work,presenter/work\"\n\n\nThe \"flavors\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavor\n\n\n\"presentation/work\"\n\n\nThe \"flavor\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags\n\n\n\"engage,atom,rss\"\n\n\nThe \"tag\" of the track to use as a source input\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\n\"presentation/normalized\"\n\n\nThe flavor to apply to the normalized file\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\n\"norm\"\n\n\nThe tags to apply to the normalized file\n\n\nEMPTY\n\n\n\n\n\n\ntarget-decibel\n*\n\n\n-30.4\n\n\nThe target RMS Level Decibel\n\n\nEMPTY\n\n\n\n\n\n\nforce-transcode\n\n\n\"true\" or \"false\"\n\n\nWhether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format)\n\n\nFALSE\n\n\n\n\n\n\n\n\n* \nrequired keys\n\n\nOperation Example\n\n\n<operation\n  id=\"normalize-audio\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Normalize audio stream\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/normalized</configuration>\n    <configuration key=\"target-tags\">norm</configuration>\n    <configuration key=\"target-decibel\">-30</configuration>\n    <configuration key=\"force-transcode\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Normalize Audio WOH"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#normalizeaudioworkflowoperationhandler",
            "text": "",
            "title": "NormalizeAudioWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#description",
            "text": "The NormalizeAudioiWorkflowOperationHandler normalizes the first audio stream of a video or audio track through SoX (http://sox.sourceforge.net/), it creates a new track with a reference to the original track which can be flavored and tagged.\nThis workflow operation handler can be used with audio and/or video files, at least one audio stream must be available otherwise nothing happens. Here are the internal steps done by the different inputs:",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#used-with-audio-only-file-forcetranscode-is-deactivated",
            "text": "Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.  Run audio normalization with original audio file.  Replace the normalized audio file with the original.  Write analyzed audio metadata to the track's mediapackage.  Delete all used temporary files",
            "title": "Used with Audio only file (forceTranscode is deactivated):"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#used-with-audio-only-file-and-forcetranscode-activated",
            "text": "Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.  (forceTranscode step) Encode audio to FLAC. (Must be used when given audio file format is not supported by SoX)  Run audio normalization with original audio file or encoded FLAC audio file.  (forceTranscode step) Mux normalized audio file back to the original audio container by replacing it with the original audio stream.  Write analyzed audio metadata to the track's mediapackage.  Delete all used temporary files",
            "title": "Used with Audio only file and forceTranscode activated:"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#used-with-video-file",
            "text": "Extract audio file encoded as FLAC audio and save it temporary in a collection  Check if necessary RMS Lev dB value is already in the track's metadata. If not run audio analyzation.  Run audio normalization with extracted audio file.  Mux normalized audio file back to the original video container by replacing it with original audio stream.  Write analyzed audio metadata to the track's mediapackage.  Delete all used temporary files   Example result track:  <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<track ref=\"track:track-2\" type=\"presenter/normalized\" id=\"70626874-17d2-480d-9d30-c10f0824961c\">\n    <mimetype>audio/x-flv</mimetype>\n    <tags>\n        <tag>norm</tag>\n    </tags>\n    <url>http://localhost:8080/files/mediapackage/8a510168-9102-425f-81e9-0943774dd229/70626874-17d2-480d-9d30-c10f0824961c/demo_slide_video_6min_buss.flv</url>\n    <checksum type=\"md5\">4e30d7d4305b0793f301816e796471db</checksum>\n    <duration>414407</duration>\n    <audio id=\"audio-1\">\n        <device/>\n        <encoder type=\"MPEG Audio\"/>\n        <bitdepth>16</bitdepth>\n        <channels>2</channels>\n        <bitrate>64000.0</bitrate>\n        <peakleveldb>-4.03</peakleveldb> <!-- NEW -->\n        <rmsleveldb>-30.54</rmsleveldb> <!-- NEW -->\n        <rmspeakdb>-10.85</rmspeakdb> <!-- NEW -->\n    </audio>\n</track>",
            "title": "Used with Video file:"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  \"presentation/work,presenter/work\"  The \"flavors\" of the track to use as a source input  EMPTY    source-flavor  \"presentation/work\"  The \"flavor\" of the track to use as a source input  EMPTY    source-tags  \"engage,atom,rss\"  The \"tag\" of the track to use as a source input  EMPTY    target-flavor  \"presentation/normalized\"  The flavor to apply to the normalized file  EMPTY    target-tags  \"norm\"  The tags to apply to the normalized file  EMPTY    target-decibel *  -30.4  The target RMS Level Decibel  EMPTY    force-transcode  \"true\" or \"false\"  Whether to force transcoding the audio stream (This is needed when trying to strip an audio stream from an audio only video container, because SoX can not handle video formats, so it must be encoded to an audio format)  FALSE     *  required keys",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/normalizeaudio-woh/#operation-example",
            "text": "<operation\n  id=\"normalize-audio\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Normalize audio stream\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor\">*/normalized</configuration>\n    <configuration key=\"target-tags\">norm</configuration>\n    <configuration key=\"target-decibel\">-30</configuration>\n    <configuration key=\"force-transcode\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/",
            "text": "PostMediapackageWorkflowHandler\n\n\nDescription\n\n\nThis Workflow Operation Handler can be used to send a POST request containing an XML/JSON representation of the Mediapackage processed by the workflow to an external webservice. The service supports HTTP Basic and Digest Authentication.\n\n\nOptions\n\n\n<!--\n    This operation will send a POST request containing the Mediapackage to an\n    external webservice.\n-->\n<operation\n    id=\"post-mediapackage\"\n    fail-on-error=\"false\"\n    exception-handler-workflow=\"error\"\n    description=\"Sending MediaPackage to Lernfunk3\">\n    <configurations>\n        <!-- target url -->\n        <configuration key=\"url\">http://example.com:5000/</configuration>\n        <!-- export format: xml or json -->\n        <configuration key=\"format\">xml</configuration>\n        <!--\n            Disable this on a productive system. If enabled, request bodies\n            etc. will be written to log. If disabled, only errors will be\n            logged.\n        -->\n        <configuration key=\"debug\">no</configuration>\n        <!-- Type of Mediapackage to send (possible values: workflow, search; default: search) -->\n        <configuration key=\"mediapackage.type\">search</configuration>\n        <!-- enable authentication (simple/digest will be detected automatically) -->\n        <configuration key=\"auth.enabled\">yes</configuration>\n        <!-- username for authentication -->\n        <configuration key=\"auth.username\">exportuser</configuration>\n        <!-- password for authentication -->\n        <configuration key=\"auth.password\">secret</configuration>\n        <!-- fields with keys beginning with + will be added to the message body -->\n        <configuration key=\"+source_system\">video.example.com</configuration>\n    </configurations>\n</operation>",
            "title": "Post Media Package WOH"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/#postmediapackageworkflowhandler",
            "text": "",
            "title": "PostMediapackageWorkflowHandler"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/#description",
            "text": "This Workflow Operation Handler can be used to send a POST request containing an XML/JSON representation of the Mediapackage processed by the workflow to an external webservice. The service supports HTTP Basic and Digest Authentication.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/postmediapackage-woh/#options",
            "text": "<!--\n    This operation will send a POST request containing the Mediapackage to an\n    external webservice.\n-->\n<operation\n    id=\"post-mediapackage\"\n    fail-on-error=\"false\"\n    exception-handler-workflow=\"error\"\n    description=\"Sending MediaPackage to Lernfunk3\">\n    <configurations>\n        <!-- target url -->\n        <configuration key=\"url\">http://example.com:5000/</configuration>\n        <!-- export format: xml or json -->\n        <configuration key=\"format\">xml</configuration>\n        <!--\n            Disable this on a productive system. If enabled, request bodies\n            etc. will be written to log. If disabled, only errors will be\n            logged.\n        -->\n        <configuration key=\"debug\">no</configuration>\n        <!-- Type of Mediapackage to send (possible values: workflow, search; default: search) -->\n        <configuration key=\"mediapackage.type\">search</configuration>\n        <!-- enable authentication (simple/digest will be detected automatically) -->\n        <configuration key=\"auth.enabled\">yes</configuration>\n        <!-- username for authentication -->\n        <configuration key=\"auth.username\">exportuser</configuration>\n        <!-- password for authentication -->\n        <configuration key=\"auth.password\">secret</configuration>\n        <!-- fields with keys beginning with + will be added to the message body -->\n        <configuration key=\"+source_system\">video.example.com</configuration>\n    </configurations>\n</operation>",
            "title": "Options"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/",
            "text": "PrepareAVWorkflowOperation\n\n\nDescription\n\n\nThe PrepareAVWorkflowOperation works is like this: \n\n\nIf there are two tracks with the same flavor, and one of them contains a video stream only, while the other contains an audio stream only, the implementation will call the composer's \"mux\" method, with the result that the audio will be muxed with the video, using the video's movie container. \n\n\nIf it there is one track with a certain flavor, the \"encode\" method is called which will rewrite (vs. encode) the file using the same container and codec (-vcodec copy, -a codec copy), while the container format is determined by ffmpeg via the file's extension. The reason for doing this is that many media files are in a poor state with regard to their compatibility (most often, the stream's codec contains differing information from the container), so we are basically asking ffmepg to rewrite the whole thing, which will in many cases eliminate problems that would otherwhise occur later in the pipeline (encoding to flash, mjpeg etc.). \n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/source\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/work\n\n\nSpecifies the flavor the new files will get.\n\n\n\n\n\n\nmux-encoding-profile\n\n\nmux-av.work\n\n\nThe encoding profile to use for media that needs to be muxed (default is 'mux-av.work')\n\n\n\n\n\n\naudio-video-encoding-profile\n\n\nav.work\n\n\nThe encoding profile to use for media that is audio-video already and needs to be re-encodend (default is av.work)\n\n\n\n\n\n\nvideo-encoding-profile\n\n\nvideo-only.work\n\n\nThe encoding profile to use for media that is only video and needs to be re-encodend (default is video-only.work)\n\n\n\n\n\n\naudio-encoding-profile\n\n\naudio-only.work\n\n\nThe encoding profile to use for media that is only audio and needs to be re-encodend (default is audio-only.work)\n\n\n\n\n\n\nrewrite\n\n\ntrue\n\n\nShould files be rewritten\n\n\n\n\n\n\npromiscuous-audio-muxing\n\n\ntrue\n\n\nIf there is no matching flavor to mux, try other flavors as well\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"prepare-av\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Preparing presenter audio and video work versions\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/source</configuration>\n    <configuration key=\"target-flavor\">presenter/work</configuration>\n    <configuration key=\"rewrite\">false</configuration>\n    <configuration key=\"promiscuous-audio-muxing\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Prepare A/V WOH"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#prepareavworkflowoperation",
            "text": "",
            "title": "PrepareAVWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#description",
            "text": "The PrepareAVWorkflowOperation works is like this:   If there are two tracks with the same flavor, and one of them contains a video stream only, while the other contains an audio stream only, the implementation will call the composer's \"mux\" method, with the result that the audio will be muxed with the video, using the video's movie container.   If it there is one track with a certain flavor, the \"encode\" method is called which will rewrite (vs. encode) the file using the same container and codec (-vcodec copy, -a codec copy), while the container format is determined by ffmpeg via the file's extension. The reason for doing this is that many media files are in a poor state with regard to their compatibility (most often, the stream's codec contains differing information from the container), so we are basically asking ffmepg to rewrite the whole thing, which will in many cases eliminate problems that would otherwhise occur later in the pipeline (encoding to flash, mjpeg etc.).",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/source  Specifies which media should be processed.    target-flavor  presenter/work  Specifies the flavor the new files will get.    mux-encoding-profile  mux-av.work  The encoding profile to use for media that needs to be muxed (default is 'mux-av.work')    audio-video-encoding-profile  av.work  The encoding profile to use for media that is audio-video already and needs to be re-encodend (default is av.work)    video-encoding-profile  video-only.work  The encoding profile to use for media that is only video and needs to be re-encodend (default is video-only.work)    audio-encoding-profile  audio-only.work  The encoding profile to use for media that is only audio and needs to be re-encodend (default is audio-only.work)    rewrite  true  Should files be rewritten    promiscuous-audio-muxing  true  If there is no matching flavor to mux, try other flavors as well",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/prepareav-woh/#operation-example",
            "text": "<operation\n  id=\"prepare-av\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Preparing presenter audio and video work versions\">\n  <configurations>\n    <configuration key=\"source-flavor\">presenter/source</configuration>\n    <configuration key=\"target-flavor\">presenter/work</configuration>\n    <configuration key=\"rewrite\">false</configuration>\n    <configuration key=\"promiscuous-audio-muxing\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/publishengage-woh/",
            "text": "PublishEngageWorkflowOperation\n\n\nDescription\n\n\nThe PublishEngageWorkflowOperation will bring your media to the engage distribution channels (streaming, progressive download, \u2026)\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\ndownload-source-tags\n\n\nengage\n\n\nSpecifies which media should be published to progressive download.\n\n\n\n\n\n\nstreaming-source-tags\n\n\nengage\n\n\nSpecifies which media should be published to the streaming server.\n\n\n\n\n\n\ncheck-availability\n\n\ntrue\n\n\nIf the opertion should check if the media if rechable.\n\n\n\n\n\n\ndownload-source-flavors\n\n\n\n\n\n\n\n\n\n\ndownload-target-subflavors\n\n\n\n\n\n\n\n\n\n\ndownload-target-tags\n\n\n\n\n\n\n\n\n\n\nstreaming-tagret-tags\n\n\n\n\n\n\n\n\n\n\nstreaming-source-flavors\n\n\n\n\n\n\n\n\n\n\nstreaming-target-flavors\n\n\n\n\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"publish-engage\"\n      max-attempts=\"2\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Distribute and publish to engage player\">\n      <configurations>\n            <configuration key=\"download-source-tags\">engage,atom,rss</configuration>\n            <configuration key=\"streaming-source-tags\">engage</configuration>\n            <configuration key=\"check-availability\">true</configuration>\n      </configurations>\n</operation>",
            "title": "Publish Engage WOH"
        },
        {
            "location": "/workflowoperationhandlers/publishengage-woh/#publishengageworkflowoperation",
            "text": "",
            "title": "PublishEngageWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/publishengage-woh/#description",
            "text": "The PublishEngageWorkflowOperation will bring your media to the engage distribution channels (streaming, progressive download, \u2026)",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/publishengage-woh/#parameter-table",
            "text": "configuration keys  example  description      download-source-tags  engage  Specifies which media should be published to progressive download.    streaming-source-tags  engage  Specifies which media should be published to the streaming server.    check-availability  true  If the opertion should check if the media if rechable.    download-source-flavors      download-target-subflavors      download-target-tags      streaming-tagret-tags      streaming-source-flavors      streaming-target-flavors",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/publishengage-woh/#operation-example",
            "text": "<operation\n      id=\"publish-engage\"\n      max-attempts=\"2\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Distribute and publish to engage player\">\n      <configurations>\n            <configuration key=\"download-source-tags\">engage,atom,rss</configuration>\n            <configuration key=\"streaming-source-tags\">engage</configuration>\n            <configuration key=\"check-availability\">true</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/republish-woh/",
            "text": "RepublishWorkflowOperation\n\n\nDescription\n\n\nThe republish workflow operation handler will take a mediapackage from the archive and republish just its metadata. This is achieved by publishing the archived elements as specified in the \"source-flavor\" option and merging them with what had been published to search before. Alternatively, \"merge\" can be set to false which will result in the operation replacing what is in search.\n\n\nThis way one is able to use the archive's mediapackage editor to make changes to a recording's metadata and then use the \"republish\" workflow operation to publish the updated metadata to the search index. Note that you would want to distribute the catalogs to download before publishing because the search service will try to download them.\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"dublincore/episode\"\n\n\nSelect all media package elements with any of these (comma separated) flavors. If no source flavor is specified, all archived elements will be republished, including tracks and attachments.\n\n\nEMPTY\n\n\n\n\n\n\nsource-tags\n\n\n\"engage, publish\"\n\n\nOnly select media package elements that are tagged with any of these (comma separated) tags.\n\n\nEMPTY\n\n\n\n\n\n\nmerge\n\n\n\"true\" or \"false\"\n\n\nIndicates whether the republished mediapackage elements should be merged with what has been published to search so far. If set to \"true\", mediapackage elements that are selected (by means of flavor and tags) will replace what is in search. If set to \"false\", the mediapackage in search will be replaced completely.\n\n\ntrue\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"republish\"\n  max-attempts=\"2\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Republishing metadata\">\n  <configurations>\n    <configuration key=\"source-flavors\">dublincore/*</configuration>    <configuration key=\"source-tags\">engage,atom</configuration>\n    <configuration key=\"merge\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Republish WOH"
        },
        {
            "location": "/workflowoperationhandlers/republish-woh/#republishworkflowoperation",
            "text": "",
            "title": "RepublishWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/republish-woh/#description",
            "text": "The republish workflow operation handler will take a mediapackage from the archive and republish just its metadata. This is achieved by publishing the archived elements as specified in the \"source-flavor\" option and merging them with what had been published to search before. Alternatively, \"merge\" can be set to false which will result in the operation replacing what is in search.  This way one is able to use the archive's mediapackage editor to make changes to a recording's metadata and then use the \"republish\" workflow operation to publish the updated metadata to the search index. Note that you would want to distribute the catalogs to download before publishing because the search service will try to download them.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/republish-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  example  description  default value      source-flavors  \"dublincore/episode\"  Select all media package elements with any of these (comma separated) flavors. If no source flavor is specified, all archived elements will be republished, including tracks and attachments.  EMPTY    source-tags  \"engage, publish\"  Only select media package elements that are tagged with any of these (comma separated) tags.  EMPTY    merge  \"true\" or \"false\"  Indicates whether the republished mediapackage elements should be merged with what has been published to search so far. If set to \"true\", mediapackage elements that are selected (by means of flavor and tags) will replace what is in search. If set to \"false\", the mediapackage in search will be replaced completely.  true",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/republish-woh/#operation-example",
            "text": "<operation\n  id=\"republish\"\n  max-attempts=\"2\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Republishing metadata\">\n  <configurations>\n    <configuration key=\"source-flavors\">dublincore/*</configuration>    <configuration key=\"source-tags\">engage,atom</configuration>\n    <configuration key=\"merge\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/",
            "text": "SegmentpreviewsWorkflowOperation\n\n\nDescription\n\n\nThe SegmentpreviewsWorkflowOperation will extract still images from a video using FFmpeg, a given encoding profile and previous discovered segments.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresenter/source\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-flavor\n\n\npresenter/work\n\n\nSpecifies the flavor the new files will get.\n\n\n\n\n\n\nsource-tags\n\n\nengage\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\ntarget-tags\n\n\nengage\n\n\nSpecifies the tags the new files will get.\n\n\n\n\n\n\nencoding-profile\n\n\nsearch-cover.http\n\n\nThe encoding profile to use.\n\n\n\n\n\n\nreference-flavor\n\n\npresentation/work\n\n\nFlavor of the segments to use.\n\n\n\n\n\n\nreference-tags\n\n\nengage\n\n\nTags of the segments to use.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"segmentpreviews\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Encoding presentation (screen) to segment preview image\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-flavor\">presentation/segment+preview</configuration>\n            <configuration key=\"reference-flavor\">presentation/delivery</configuration>\n            <configuration key=\"reference-tags\">engage</configuration>\n            <configuration key=\"target-tags\">engage</configuration>\n            <configuration key=\"encoding-profile\">player-slides.http</configuration>\n      </configurations>\n</operation>",
            "title": "Segment Previews WOH"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/#segmentpreviewsworkflowoperation",
            "text": "",
            "title": "SegmentpreviewsWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/#description",
            "text": "The SegmentpreviewsWorkflowOperation will extract still images from a video using FFmpeg, a given encoding profile and previous discovered segments.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presenter/source  Specifies which media should be processed.    target-flavor  presenter/work  Specifies the flavor the new files will get.    source-tags  engage  Specifies which media should be processed.    target-tags  engage  Specifies the tags the new files will get.    encoding-profile  search-cover.http  The encoding profile to use.    reference-flavor  presentation/work  Flavor of the segments to use.    reference-tags  engage  Tags of the segments to use.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/segmentpreviews-woh/#operation-example",
            "text": "<operation\n      id=\"segmentpreviews\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Encoding presentation (screen) to segment preview image\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n            <configuration key=\"source-tags\"></configuration>\n            <configuration key=\"target-flavor\">presentation/segment+preview</configuration>\n            <configuration key=\"reference-flavor\">presentation/delivery</configuration>\n            <configuration key=\"reference-tags\">engage</configuration>\n            <configuration key=\"target-tags\">engage</configuration>\n            <configuration key=\"encoding-profile\">player-slides.http</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/",
            "text": "SegmentVideoWorkflowOperation\n\n\nDescription\n\n\nThe SegmentVideoWorkflowOperation will try to identify and mark different segments of a video. A new segment is created when a major change in the video occurs. This might be the case for example if the video is a screenrecording and the slides which were shown change.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\n\n\n\n\n\n\n\n\nsource-flavor\n\n\npresentation/trimmed\n\n\nSpecifies which media should be processed.\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"segment-video\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Extracting segments from presentation\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n      </configurations>\n</operation>",
            "title": "Segment Video WOH"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/#segmentvideoworkflowoperation",
            "text": "",
            "title": "SegmentVideoWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/#description",
            "text": "The SegmentVideoWorkflowOperation will try to identify and mark different segments of a video. A new segment is created when a major change in the video occurs. This might be the case for example if the video is a screenrecording and the slides which were shown change.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/#parameter-table",
            "text": "configuration keys  example  description      source-flavor  presentation/trimmed  Specifies which media should be processed.",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/segmentvideo-woh/#operation-example",
            "text": "<operation\n      id=\"segment-video\"\n      fail-on-error=\"false\"\n      exception-handler-workflow=\"error\"\n      description=\"Extracting segments from presentation\">\n      <configurations>\n            <configuration key=\"source-flavor\">presentation/trimmed</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/",
            "text": "SeriesWorkflowOperationHandler\n\n\nDescription\n\n\nThe SeriesWorkflowOperation will apply a series to the mediapackage.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nseries\n\n\n\"0d06537e-09d3-420c-8314-a21e45c5d032\"\n\n\nThe optional series identifier. If empty the current series of the medipackage will be taken.\n\n\nEMPTY\n\n\n\n\n\n\nattach\n\n\n\"creativecommons/*,dublincore/*\"\n\n\nThe flavors of the series catalogs to attach to the mediapackage.\n\n\nEMPTY\n\n\n\n\n\n\napply-acl\n\n\n\"true\"|\"false\"\n\n\nWhether the ACL should be applied or not.\n\n\n\"false\"\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n      id=\"series\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Applying series to mediapackage\">\n      <configurations>\n        <configuration key=\"series\">0d06537e-09d3-420c-8314-a21e45c5d032</configuration>\n        <configuration key=\"attach\">*</configuration>\n        <configuration key=\"apply-acl\">true</configuration>\n      </configurations>\n</operation>",
            "title": "Series WOH"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#seriesworkflowoperationhandler",
            "text": "",
            "title": "SeriesWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#description",
            "text": "The SeriesWorkflowOperation will apply a series to the mediapackage.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      series  \"0d06537e-09d3-420c-8314-a21e45c5d032\"  The optional series identifier. If empty the current series of the medipackage will be taken.  EMPTY    attach  \"creativecommons/*,dublincore/*\"  The flavors of the series catalogs to attach to the mediapackage.  EMPTY    apply-acl  \"true\"|\"false\"  Whether the ACL should be applied or not.  \"false\"",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/series-woh/#operation-example",
            "text": "<operation\n      id=\"series\"\n      fail-on-error=\"true\"\n      exception-handler-workflow=\"error\"\n      description=\"Applying series to mediapackage\">\n      <configurations>\n        <configuration key=\"series\">0d06537e-09d3-420c-8314-a21e45c5d032</configuration>\n        <configuration key=\"attach\">*</configuration>\n        <configuration key=\"apply-acl\">true</configuration>\n      </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/",
            "text": "SilenceDetectionWorkflowOperationHandler\n\n\nDescription\n\n\nThe \nsilence\n operation performs a silence detection on an audio-only input file. The operation needs the silence detection API and impl (or remote in a distributed system) modules to be installed to process the request.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"*/audio\"\n\n\nThe input parameter source-flavors takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type\n\n\nEMPTY\n\n\n\n\n\n\nreference-tracks-flavour\n\n\n\"*/preview\"\n\n\nThe input parameter reference-tracks-flavour is the subtype of the media files that should be included in the provided SMIL file. The * should not be modified here. In most cases it is not important which reference-tracks-flavour is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality.\n\n\nEMPTY\n\n\n\n\n\n\nsmil-flavor-subtype\n\n\n\"smil\"\n\n\nThe output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced.\n\n\nEMPTY\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"silence\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Executing silence detection\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/audio</configuration>\n    <configuration key=\"smil-flavor-subtype\">smil</configuration>\n    <configuration key=\"reference-tracks-flavor\">*/preview</configuration>\n  </configurations>\n</operation>",
            "title": "Silence WOH"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/#silencedetectionworkflowoperationhandler",
            "text": "",
            "title": "SilenceDetectionWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/#description",
            "text": "The  silence  operation performs a silence detection on an audio-only input file. The operation needs the silence detection API and impl (or remote in a distributed system) modules to be installed to process the request.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  \"*/audio\"  The input parameter source-flavors takes one flavor/sub-type or multiple input flavors with the *-operator followed by the sub-type  EMPTY    reference-tracks-flavour  \"*/preview\"  The input parameter reference-tracks-flavour is the subtype of the media files that should be included in the provided SMIL file. The * should not be modified here. In most cases it is not important which reference-tracks-flavour is selected as long as all relevant flavors are available within this feature. \"preview\" is not a bad choice as all files available within the video editor UI are also available with this flavor, unlike \"source\" where not all flavors may be available, as some recorders record all streams to one file and the tracks are separated afterwards. The editor operation afterwards will anyway try to select the best available quality.  EMPTY    smil-flavor-subtype  \"smil\"  The output parameter is smil-flavor-subtype which provides the modificatory for the flavor subtype after this operation. The main flavor will be consistent and only the subtype will be replaced.  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/silence-woh/#operation-example",
            "text": "<operation\n  id=\"silence\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Executing silence detection\">\n  <configurations>\n    <configuration key=\"source-flavors\">*/audio</configuration>\n    <configuration key=\"smil-flavor-subtype\">smil</configuration>\n    <configuration key=\"reference-tracks-flavor\">*/preview</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/",
            "text": "TagWorkflowOperation\n\n\nDescription\n\n\nWith the TagWorkflowOperationHandler it's possible to select various media package elements and then modify their tag set and / or set their flavor.\n\n\nSo for example it's possible to pick up elements like the dublin core catalogs that have been added to the media package at the beginning of the workflow and tag them, so they can be picked up by operations later on.\n\n\nParameter Table\n\n\nTags and flavors can be used in combination.\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-tags\n\n\n\"engage,atom,rss,-publish\"\n\n\nTag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavors\n\n\n\"presentation/trimmed\"\n\n\nTag any media package elements with one of these (comma separated) flavors.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-tags\n\n\n\"tagged,+rss\" / \"-rss,+tagged\"\n\n\nApply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags.\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\n\"presentation/tagged\"\n\n\nApply these flavor to any media package elements\n\n\nEMPTY\n\n\n\n\n\n\ncopy\n\n\n\"true\" or \"false\"\n\n\nIndicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise.\n\n\nFALSE\n\n\n\n\n\n\n\n\nTarget Tags Example\n\n\n\n\n\n\n\n\nTarget-Tags\n\n\nPreexisting Tags\n\n\nResulting Tags\n\n\n\n\n\n\n\n\n\n\nrss\n\n\nengage\n\n\nrss\n\n\n\n\n\n\n+rss\n\n\nengage\n\n\nengage,rss\n\n\n\n\n\n\n-rss\n\n\nengage,rss\n\n\nengage\n\n\n\n\n\n\ntagged,+rss\n\n\nengage\n\n\ntagged\n\n\n\n\n\n\n-rss,+tagged\n\n\nengage,rss\n\n\nengage,tagged\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"tag\"\n  max-attempts=\"2\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Tagging media package elements\">\n  <configurations>\n    <configuration key=\"source-tags\">engage,atom,-publish</configuration>\n    <configuration key=\"source-flavors\">presentation/trimmed</configuration>\n    <configuration key=\"target-tags\">-atom,+rss</configuration>\n    <configuration key=\"target-flavor\">presentation/tagged</configuration>\n    <configuration key=\"copy\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Tag WOH"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#tagworkflowoperation",
            "text": "",
            "title": "TagWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#description",
            "text": "With the TagWorkflowOperationHandler it's possible to select various media package elements and then modify their tag set and / or set their flavor.  So for example it's possible to pick up elements like the dublin core catalogs that have been added to the media package at the beginning of the workflow and tag them, so they can be picked up by operations later on.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#parameter-table",
            "text": "Tags and flavors can be used in combination.     configuration keys  example  description  default value      source-tags  \"engage,atom,rss,-publish\"  Tag any media package elements with one of these (comma separated) tags. If a source-tag starts with a '-', media package elements with this tag will be excluded.  EMPTY    source-flavors  \"presentation/trimmed\"  Tag any media package elements with one of these (comma separated) flavors.  EMPTY    target-tags  \"tagged,+rss\" / \"-rss,+tagged\"  Apply these (comma separated) tags to any media package elements. If a target-tag starts with a '-', it will be removed from preexisting tags, if a target-tag starts with a '+', it will be added to preexisting tags. If there is no prefix, all preexisting tags are removed and replaced by the target-tags.  EMPTY    target-flavor  \"presentation/tagged\"  Apply these flavor to any media package elements  EMPTY    copy  \"true\" or \"false\"  Indicates if matching elements will be cloned before tagging is applied or whether tagging is applied to the original element. Set to \"true\" to create a copy first, \"false\" otherwise.  FALSE",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#target-tags-example",
            "text": "Target-Tags  Preexisting Tags  Resulting Tags      rss  engage  rss    +rss  engage  engage,rss    -rss  engage,rss  engage    tagged,+rss  engage  tagged    -rss,+tagged  engage,rss  engage,tagged",
            "title": "Target Tags Example"
        },
        {
            "location": "/workflowoperationhandlers/tag-woh/#operation-example",
            "text": "<operation\n  id=\"tag\"\n  max-attempts=\"2\"\n  fail-on-error=\"true\"\n  exception-handler-workflow=\"error\"\n  description=\"Tagging media package elements\">\n  <configurations>\n    <configuration key=\"source-tags\">engage,atom,-publish</configuration>\n    <configuration key=\"source-flavors\">presentation/trimmed</configuration>\n    <configuration key=\"target-tags\">-atom,+rss</configuration>\n    <configuration key=\"target-flavor\">presentation/tagged</configuration>\n    <configuration key=\"copy\">true</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/",
            "text": "TrimWorkflowOperationHandler\n\n\nDescription\n\n\nThe TrimWorkflowOperationHandler makes it possible to remove the undesired parts of the media at the beginning and the end of the recordings.\n\n\nThis operation UI also allows users to select/deselect tracks for being further processed and distributed (e.g. one could remove the presenter track if its quality does not meet the required standards). The recording metadata fields (e.g. title, presenter, series, etc.) may be also be edited in the UI provided.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nduration-threshold\n\n\n\"100\"\n\n\nIf the trimming \"out point\" is beyond a certain track's duration, this parameter specifies the maximum allowed difference between them (in milliseconds).\n\n\n0\n\n\n\n\n\n\nencoding-profile\n\n\n\"trim.master\"\n\n\nThe encoding profile used to encode the trimmed tracks.\n\n\nEMPTY\n\n\n\n\n\n\nsource-flavors\n\n\n\"presentation/trimmed\"\n\n\nIndicates the flavor(s) that will be trimmed by this operation..\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor-subtype\n\n\n\"master\"\n\n\nThe flavors of the elements created after the trim will be modified by changing the second half of the flavor with the value of this parameter. E.g., if it is set to \"trimmed\", a source track's flavor \"presenter/work\" would become \"presenter/trimmed\".\n\n\nEMPTY\n\n\n\n\n\n\n\n\nDuration Threshold Tag\n\n\nThe \"duration-threshold\" parameter  accepts a threshold value in milliseconds. It is meant to deal with length differences between the tracks in a mediapackage (which in theory should have the same length). Since all the tracks in the mediapackage are trimmed at the same time points, the trimming point may be within a certain track's duration, but outside another. If the difference between the trim point and the track length is shorter than the threshold, then the outpoint is adjusted to the length of the track, for that track only. For instance, if the trim point is at 5'31'' but one of the tracks is 5'30'' long, with a threshold of 2000 (2 seconds), the shorter track will be trimmed to 5'30 instead, thus not failing. In the end, when some tracks are longer and others slightly shorter than the trim point, you will end up with a set of tracks that are trimmed either at the exact point or not shorter than \n milliseconds\n\n\nThe parameter is currently in the default workflow, but commented. The threshold is 0 by default, i.e. no difference between the trim outpoint and the track length is allowed.\n\n\nCapture UI\n\n\n\n\nOperation Example\n\n\n<operation\n id=\"trim\"\n retry-strategy=\"hold\"\n fail-on-error=\"true\"\n exception-handler-workflow=\"error\"\n description=\"trimming and master generation\">\n  <configurations>\n    <configuration key=\"duration-threshold\">1000</configuration>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor-subtype\">master</configuration>\n    <configuration key=\"encoding-profile\">trim.master</configuration>\n  </configurations>\n</operation>",
            "title": "Trim WOH"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/#trimworkflowoperationhandler",
            "text": "",
            "title": "TrimWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/#description",
            "text": "The TrimWorkflowOperationHandler makes it possible to remove the undesired parts of the media at the beginning and the end of the recordings.  This operation UI also allows users to select/deselect tracks for being further processed and distributed (e.g. one could remove the presenter track if its quality does not meet the required standards). The recording metadata fields (e.g. title, presenter, series, etc.) may be also be edited in the UI provided.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      duration-threshold  \"100\"  If the trimming \"out point\" is beyond a certain track's duration, this parameter specifies the maximum allowed difference between them (in milliseconds).  0    encoding-profile  \"trim.master\"  The encoding profile used to encode the trimmed tracks.  EMPTY    source-flavors  \"presentation/trimmed\"  Indicates the flavor(s) that will be trimmed by this operation..  EMPTY    target-flavor-subtype  \"master\"  The flavors of the elements created after the trim will be modified by changing the second half of the flavor with the value of this parameter. E.g., if it is set to \"trimmed\", a source track's flavor \"presenter/work\" would become \"presenter/trimmed\".  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/#duration-threshold-tag",
            "text": "The \"duration-threshold\" parameter  accepts a threshold value in milliseconds. It is meant to deal with length differences between the tracks in a mediapackage (which in theory should have the same length). Since all the tracks in the mediapackage are trimmed at the same time points, the trimming point may be within a certain track's duration, but outside another. If the difference between the trim point and the track length is shorter than the threshold, then the outpoint is adjusted to the length of the track, for that track only. For instance, if the trim point is at 5'31'' but one of the tracks is 5'30'' long, with a threshold of 2000 (2 seconds), the shorter track will be trimmed to 5'30 instead, thus not failing. In the end, when some tracks are longer and others slightly shorter than the trim point, you will end up with a set of tracks that are trimmed either at the exact point or not shorter than   milliseconds  The parameter is currently in the default workflow, but commented. The threshold is 0 by default, i.e. no difference between the trim outpoint and the track length is allowed.",
            "title": "Duration Threshold Tag"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/#capture-ui",
            "text": "",
            "title": "Capture UI"
        },
        {
            "location": "/workflowoperationhandlers/trim-woh/#operation-example",
            "text": "<operation\n id=\"trim\"\n retry-strategy=\"hold\"\n fail-on-error=\"true\"\n exception-handler-workflow=\"error\"\n description=\"trimming and master generation\">\n  <configurations>\n    <configuration key=\"duration-threshold\">1000</configuration>\n    <configuration key=\"source-flavor\">*/work</configuration>\n    <configuration key=\"target-flavor-subtype\">master</configuration>\n    <configuration key=\"encoding-profile\">trim.master</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/",
            "text": "WaveformWorkflowOperationHandler\n\n\nDescription\n\n\nThe waveform operation creates an image showing the temporal audio activity within the recording. This is be done with a probably well known waveform (see example image).\n\n\nThe operation does not need an additional module, as it is not very work intensive to create such an image. The operation needs and audio-only file to create the image and it provides an PNG image.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nsource-flavors\n\n\n\"*/audio\"\n\n\nInput parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be used if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example).\n\n\nEMPTY\n\n\n\n\n\n\ntarget-flavor\n\n\n\"*/waveform\"\n\n\nThe output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too.\n\n\nEMPTY\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n  id=\"waveform\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Generating waveform\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/audio</configuration>\n    <configuration key=\"target-flavor\">*/waveform</configuration>\n  </configurations>\n</operation>",
            "title": "Waveform WOH"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/#waveformworkflowoperationhandler",
            "text": "",
            "title": "WaveformWorkflowOperationHandler"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/#description",
            "text": "The waveform operation creates an image showing the temporal audio activity within the recording. This is be done with a probably well known waveform (see example image). \nThe operation does not need an additional module, as it is not very work intensive to create such an image. The operation needs and audio-only file to create the image and it provides an PNG image.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      source-flavors  \"*/audio\"  Input parameter is the source-flavor of the audio files for which a waveform should be created. The *-operator can be used if the waveform should be created for all flavors with a certain subtypes (like \"audio\" in our example).  EMPTY    target-flavor  \"*/waveform\"  The output-parameter is target-flavor which should use the *-operator if it was used in the source-flavor too.  EMPTY",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/waveform-woh/#operation-example",
            "text": "<operation\n  id=\"waveform\"\n  if=\"${trimHold}\"\n  fail-on-error=\"false\"\n  description=\"Generating waveform\">\n  <configurations>\n    <configuration key=\"source-flavor\">*/audio</configuration>\n    <configuration key=\"target-flavor\">*/waveform</configuration>\n  </configurations>\n</operation>",
            "title": "Operation Example"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/",
            "text": "ZipWorkflowOperation\n\n\nDescription\n\n\nThe ZipWorkflowOperationHandler creates a zip archive including all elements from the current mediapackage that are specified in the operation configuration. It then adds the archive to the as an attachment with the given flavor and tags to the mediapackage.\n\n\nParameter Table\n\n\n\n\n\n\n\n\nconfiguration keys\n\n\nexample\n\n\ndescription\n\n\ndefault value\n\n\n\n\n\n\n\n\n\n\nzip-collection\n\n\nzips\n\n\nA comma separated list of flavors to preserve from deleting.\n\n\nzip\n\n\n\n\n\n\ninclude-flavors\n\n\n\"\n/source,dublincore/\n\"\n\n\nWhich elements to include in the archive. This configuration parameter accepts exact flavors like \"presenter/source\" as well as wildcard flavor definitions like \"*/source\".\n\n\n(all)\n\n\n\n\n\n\ntarget-flavor\n\n\n\"archive/zip\"\n\n\nThe flavor of the created attachment.\n\n\narchive/zip\n\n\n\n\n\n\ntarget-tags\n\n\n\"archive\"\n\n\nThe tags to apply to the attachment.\n\n\n-\n\n\n\n\n\n\ncompression\n\n\n\"true\"\n\n\nWhether to compress the archive content. Usually, for media content this doesn't reduce size of the archive by a lot but adds significant processing time by the compression.\n\n\nFALSE\n\n\n\n\n\n\n\n\nOperation Example\n\n\n<operation\n    id=\"zip\"\n    description=\"Creating zipped recording archive\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"cleanup\">\n    <configurations>\n      <configuration key=\"zip-collection\">failed.zips</configuration>\n      <configuration key=\"include-flavors\">*/source,dublincore/*</configuration>\n      <configuration key=\"target-flavor\">all/zip</configuration>\n      <configuration key=\"compression\">false</configuration>\n    </configurations>\n</operation>",
            "title": "Zip WOH"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/#zipworkflowoperation",
            "text": "",
            "title": "ZipWorkflowOperation"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/#description",
            "text": "The ZipWorkflowOperationHandler creates a zip archive including all elements from the current mediapackage that are specified in the operation configuration. It then adds the archive to the as an attachment with the given flavor and tags to the mediapackage.",
            "title": "Description"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/#parameter-table",
            "text": "configuration keys  example  description  default value      zip-collection  zips  A comma separated list of flavors to preserve from deleting.  zip    include-flavors  \" /source,dublincore/ \"  Which elements to include in the archive. This configuration parameter accepts exact flavors like \"presenter/source\" as well as wildcard flavor definitions like \"*/source\".  (all)    target-flavor  \"archive/zip\"  The flavor of the created attachment.  archive/zip    target-tags  \"archive\"  The tags to apply to the attachment.  -    compression  \"true\"  Whether to compress the archive content. Usually, for media content this doesn't reduce size of the archive by a lot but adds significant processing time by the compression.  FALSE",
            "title": "Parameter Table"
        },
        {
            "location": "/workflowoperationhandlers/zip-woh/#operation-example",
            "text": "<operation\n    id=\"zip\"\n    description=\"Creating zipped recording archive\"\n    fail-on-error=\"true\"\n    exception-handler-workflow=\"cleanup\">\n    <configurations>\n      <configuration key=\"zip-collection\">failed.zips</configuration>\n      <configuration key=\"include-flavors\">*/source,dublincore/*</configuration>\n      <configuration key=\"target-flavor\">all/zip</configuration>\n      <configuration key=\"compression\">false</configuration>\n    </configurations>\n</operation>",
            "title": "Operation Example"
        }
    ]
}